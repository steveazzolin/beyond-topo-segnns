
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 13:55:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/03/2024 01:55:44 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 01:55:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:04 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:56:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.8968
Train Loss: 0.4539
ID Validation ACCURACY: 0.8960
ID Validation Loss: 0.4728
ID Test ACCURACY: 0.8980
ID Test Loss: 0.4583
OOD Validation ACCURACY: 0.9250
OOD Validation Loss: 0.4294
OOD Test ACCURACY: 0.8670
OOD Test Loss: 0.4421

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8993
Train Loss: 0.4320
ID Validation ACCURACY: 0.8943
ID Validation Loss: 0.4504
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4388
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3461
OOD Test ACCURACY: 0.8433
OOD Test Loss: 0.4945

[0m[1;37mINFO[0m: [1mChartInfo 0.8980 0.8670 0.8977 0.8433 0.8943 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.687
WIoU for r=0.3 = 0.649
F1 for r=0.6 = 0.604
WIoU for r=0.6 = 0.693
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.687
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.687
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.509
WIoU for r=0.3 = 0.418
F1 for r=0.6 = 0.622
WIoU for r=0.6 = 0.523
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.521
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.521


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.6871062499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6487587499999999
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.466
SUFF++ for r=0.3 class 0 = 0.479 +- 0.290 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 1 = 0.6 +- 0.290 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 2 = 0.457 +- 0.290 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all KL = 0.502 +- 0.290 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all L1 = 0.512 +- 0.153 (in-sample avg dev_std = 0.509)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.60430875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6925275000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.679
SUFF++ for r=0.6 class 0 = 0.554 +- 0.285 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 1 = 0.61 +- 0.285 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 2 = 0.563 +- 0.285 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all KL = 0.551 +- 0.285 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all L1 = 0.576 +- 0.156 (in-sample avg dev_std = 0.518)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.47565125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6865287499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.835
SUFF++ for r=0.9 class 0 = 0.784 +- 0.215 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.78 +- 0.215 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.814 +- 0.215 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.84 +- 0.215 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.178 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.396
Model XAI F1 of binarized graphs for r=0.3 =  0.5094875
Model XAI WIoU of binarized graphs for r=0.3 =  0.41823875
len(reference) = 790
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.358
SUFF++ for r=0.3 class 0 = 0.539 +- 0.195 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 1 = 0.546 +- 0.195 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 2 = 0.566 +- 0.195 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all KL = 0.666 +- 0.195 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all L1 = 0.55 +- 0.122 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.744
Model XAI F1 of binarized graphs for r=0.6 =  0.6222175
Model XAI WIoU of binarized graphs for r=0.6 =  0.52292625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0 = 0.517 +- 0.246 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 class 1 = 0.69 +- 0.246 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 class 2 = 0.687 +- 0.246 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all KL = 0.661 +- 0.246 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all L1 = 0.63 +- 0.194 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  0.592135
Model XAI WIoU of binarized graphs for r=0.9 =  0.5212475000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.861
SUFF++ for r=0.9 class 0 = 0.729 +- 0.143 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.829 +- 0.143 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.143 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.892 +- 0.143 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.802 +- 0.132 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.658
Model XAI F1 of binarized graphs for r=0.3 =  0.6871062499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6487587499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.355
NEC for r=0.3 class 0 = 0.574 +- 0.314 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 1 = 0.47 +- 0.314 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 2 = 0.636 +- 0.314 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all KL = 0.558 +- 0.314 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all L1 = 0.56 +- 0.170 (in-sample avg dev_std = 0.374)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.60430875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6925275000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.459
NEC for r=0.6 class 0 = 0.577 +- 0.304 (in-sample avg dev_std = 0.463)
NEC for r=0.6 class 1 = 0.48 +- 0.304 (in-sample avg dev_std = 0.463)
NEC for r=0.6 class 2 = 0.644 +- 0.304 (in-sample avg dev_std = 0.463)
NEC for r=0.6 all KL = 0.573 +- 0.304 (in-sample avg dev_std = 0.463)
NEC for r=0.6 all L1 = 0.568 +- 0.153 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.47565125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6865287499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.529
NEC for r=0.9 class 0 = 0.533 +- 0.310 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 1 = 0.447 +- 0.310 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 2 = 0.594 +- 0.310 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all KL = 0.52 +- 0.310 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all L1 = 0.525 +- 0.151 (in-sample avg dev_std = 0.509)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.6865287499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.533 +- 0.313 (in-sample avg dev_std = 0.502)
NEC for r=1.0 class 1 = 0.447 +- 0.313 (in-sample avg dev_std = 0.502)
NEC for r=1.0 class 2 = 0.58 +- 0.313 (in-sample avg dev_std = 0.502)
NEC for r=1.0 all KL = 0.515 +- 0.313 (in-sample avg dev_std = 0.502)
NEC for r=1.0 all L1 = 0.521 +- 0.156 (in-sample avg dev_std = 0.502)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.4
Model XAI F1 of binarized graphs for r=0.3 =  0.5094875
Model XAI WIoU of binarized graphs for r=0.3 =  0.41823875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.503 +- 0.231 (in-sample avg dev_std = 0.358)
NEC for r=0.3 class 1 = 0.48 +- 0.231 (in-sample avg dev_std = 0.358)
NEC for r=0.3 class 2 = 0.53 +- 0.231 (in-sample avg dev_std = 0.358)
NEC for r=0.3 all KL = 0.387 +- 0.231 (in-sample avg dev_std = 0.358)
NEC for r=0.3 all L1 = 0.505 +- 0.152 (in-sample avg dev_std = 0.358)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.744
Model XAI F1 of binarized graphs for r=0.6 =  0.6222175
Model XAI WIoU of binarized graphs for r=0.6 =  0.52292625
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.55
NEC for r=0.6 class 0 = 0.506 +- 0.306 (in-sample avg dev_std = 0.525)
NEC for r=0.6 class 1 = 0.349 +- 0.306 (in-sample avg dev_std = 0.525)
NEC for r=0.6 class 2 = 0.656 +- 0.306 (in-sample avg dev_std = 0.525)
NEC for r=0.6 all KL = 0.497 +- 0.306 (in-sample avg dev_std = 0.525)
NEC for r=0.6 all L1 = 0.507 +- 0.196 (in-sample avg dev_std = 0.525)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  0.592135
Model XAI WIoU of binarized graphs for r=0.9 =  0.5212475000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.643
NEC for r=0.9 class 0 = 0.459 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 1 = 0.33 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 2 = 0.564 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all KL = 0.432 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all L1 = 0.453 +- 0.161 (in-sample avg dev_std = 0.541)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.52118
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.658
NEC for r=1.0 class 0 = 0.463 +- 0.251 (in-sample avg dev_std = 0.541)
NEC for r=1.0 class 1 = 0.319 +- 0.251 (in-sample avg dev_std = 0.541)
NEC for r=1.0 class 2 = 0.517 +- 0.251 (in-sample avg dev_std = 0.541)
NEC for r=1.0 all KL = 0.412 +- 0.251 (in-sample avg dev_std = 0.541)
NEC for r=1.0 all L1 = 0.435 +- 0.156 (in-sample avg dev_std = 0.541)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 13:58:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:34 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:36 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:38 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 01:58:40 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9056
Train Loss: 0.4272
ID Validation ACCURACY: 0.9053
ID Validation Loss: 0.4435
ID Test ACCURACY: 0.9047
ID Test Loss: 0.4311
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3362
OOD Test ACCURACY: 0.8143
OOD Test Loss: 0.5784

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8627
Train Loss: 0.4791
ID Validation ACCURACY: 0.8573
ID Validation Loss: 0.5013
ID Test ACCURACY: 0.8640
ID Test Loss: 0.4705
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3364
OOD Test ACCURACY: 0.7200
OOD Test Loss: 0.6881

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.8143 0.8640 0.7200 0.8573 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.698
WIoU for r=0.3 = 0.665
F1 for r=0.6 = 0.601
WIoU for r=0.6 = 0.754
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.760
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.761
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.416
WIoU for r=0.3 = 0.288
F1 for r=0.6 = 0.567
WIoU for r=0.6 = 0.420
F1 for r=0.9 = 0.587
WIoU for r=0.9 = 0.447
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.446


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  0.6979837499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6648649999999999
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.471
SUFF++ for r=0.3 class 0 = 0.457 +- 0.270 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 1 = 0.532 +- 0.270 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 2 = 0.446 +- 0.270 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all KL = 0.437 +- 0.270 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all L1 = 0.478 +- 0.150 (in-sample avg dev_std = 0.533)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.6007625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7535599999999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.691
SUFF++ for r=0.6 class 0 = 0.587 +- 0.285 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 1 = 0.672 +- 0.285 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 2 = 0.571 +- 0.285 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all KL = 0.591 +- 0.285 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all L1 = 0.61 +- 0.182 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.4742975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7596674999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0 = 0.838 +- 0.155 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.837 +- 0.155 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.155 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.899 +- 0.155 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.846 +- 0.157 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.356
Model XAI F1 of binarized graphs for r=0.3 =  0.41562875
Model XAI WIoU of binarized graphs for r=0.3 =  0.28757375
len(reference) = 770
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.328
SUFF++ for r=0.3 class 0 = 0.566 +- 0.180 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 1 = 0.564 +- 0.180 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 2 = 0.556 +- 0.180 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all KL = 0.708 +- 0.180 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all L1 = 0.562 +- 0.125 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  0.5672425
Model XAI WIoU of binarized graphs for r=0.6 =  0.420295
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.56
SUFF++ for r=0.6 class 0 = 0.578 +- 0.220 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 class 1 = 0.717 +- 0.220 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 class 2 = 0.592 +- 0.220 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 all KL = 0.71 +- 0.220 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.6 all L1 = 0.627 +- 0.168 (in-sample avg dev_std = 0.408)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  0.5868312499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.446505
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.743
SUFF++ for r=0.9 class 0 = 0.705 +- 0.157 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 1 = 0.947 +- 0.157 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 2 = 0.735 +- 0.157 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all KL = 0.868 +- 0.157 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.195 (in-sample avg dev_std = 0.251)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  0.6979837499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6648649999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.586 +- 0.290 (in-sample avg dev_std = 0.445)
NEC for r=0.3 class 1 = 0.534 +- 0.290 (in-sample avg dev_std = 0.445)
NEC for r=0.3 class 2 = 0.639 +- 0.290 (in-sample avg dev_std = 0.445)
NEC for r=0.3 all KL = 0.607 +- 0.290 (in-sample avg dev_std = 0.445)
NEC for r=0.3 all L1 = 0.587 +- 0.158 (in-sample avg dev_std = 0.445)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.6007625
Model XAI WIoU of binarized graphs for r=0.6 =  0.7535599999999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.448
NEC for r=0.6 class 0 = 0.547 +- 0.292 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 1 = 0.512 +- 0.292 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 2 = 0.638 +- 0.292 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all KL = 0.592 +- 0.292 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all L1 = 0.567 +- 0.165 (in-sample avg dev_std = 0.485)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.4742975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7596674999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.512
NEC for r=0.9 class 0 = 0.511 +- 0.296 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 1 = 0.475 +- 0.296 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 2 = 0.59 +- 0.296 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all KL = 0.542 +- 0.296 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all L1 = 0.526 +- 0.168 (in-sample avg dev_std = 0.526)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7605137500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.542
NEC for r=1.0 class 0 = 0.49 +- 0.305 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 1 = 0.45 +- 0.305 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 2 = 0.58 +- 0.305 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all KL = 0.526 +- 0.305 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all L1 = 0.508 +- 0.171 (in-sample avg dev_std = 0.531)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.365
Model XAI F1 of binarized graphs for r=0.3 =  0.41562875
Model XAI WIoU of binarized graphs for r=0.3 =  0.28757375
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.312
NEC for r=0.3 class 0 = 0.443 +- 0.220 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 1 = 0.461 +- 0.220 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 2 = 0.485 +- 0.220 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all KL = 0.322 +- 0.220 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all L1 = 0.463 +- 0.154 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  0.5672425
Model XAI WIoU of binarized graphs for r=0.6 =  0.420295
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.477
NEC for r=0.6 class 0 = 0.493 +- 0.269 (in-sample avg dev_std = 0.471)
NEC for r=0.6 class 1 = 0.389 +- 0.269 (in-sample avg dev_std = 0.471)
NEC for r=0.6 class 2 = 0.588 +- 0.269 (in-sample avg dev_std = 0.471)
NEC for r=0.6 all KL = 0.433 +- 0.269 (in-sample avg dev_std = 0.471)
NEC for r=0.6 all L1 = 0.492 +- 0.172 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  0.5868312499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.446505
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.467 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=0.9 class 1 = 0.27 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=0.9 class 2 = 0.547 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=0.9 all KL = 0.444 +- 0.250 (in-sample avg dev_std = 0.546)
NEC for r=0.9 all L1 = 0.431 +- 0.189 (in-sample avg dev_std = 0.546)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.837
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.44589625000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0 = 0.428 +- 0.242 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 1 = 0.25 +- 0.242 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 2 = 0.531 +- 0.242 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all KL = 0.412 +- 0.242 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all L1 = 0.406 +- 0.185 (in-sample avg dev_std = 0.531)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:00:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/03/2024 02:00:50 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:05 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:07 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:09 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:01:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 148...
[0m[1;37mINFO[0m: [1mCheckpoint 148: 
-----------------------------------
Train ACCURACY: 0.8979
Train Loss: 0.4554
ID Validation ACCURACY: 0.9007
ID Validation Loss: 0.4713
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4600
OOD Validation ACCURACY: 0.9250
OOD Validation Loss: 0.3755
OOD Test ACCURACY: 0.7887
OOD Test Loss: 0.5524

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ACCURACY: 0.8457
Train Loss: 0.5385
ID Validation ACCURACY: 0.8423
ID Validation Loss: 0.5652
ID Test ACCURACY: 0.8493
ID Test Loss: 0.5441
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.3443
OOD Test ACCURACY: 0.7603
OOD Test Loss: 0.6086

[0m[1;37mINFO[0m: [1mChartInfo 0.8977 0.7887 0.8493 0.7603 0.8423 0.9310[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.718
WIoU for r=0.3 = 0.671
F1 for r=0.6 = 0.606
WIoU for r=0.6 = 0.762
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.766
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.765
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.451
WIoU for r=0.3 = 0.325
F1 for r=0.6 = 0.614
WIoU for r=0.6 = 0.478
F1 for r=0.9 = 0.591
WIoU for r=0.9 = 0.483
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.481


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  0.7182862499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6712275
len(reference) = 795
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.463
SUFF++ for r=0.3 class 0 = 0.485 +- 0.273 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 1 = 0.555 +- 0.273 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 2 = 0.475 +- 0.273 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all KL = 0.503 +- 0.273 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all L1 = 0.505 +- 0.144 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.859
Model XAI F1 of binarized graphs for r=0.6 =  0.6064075
Model XAI WIoU of binarized graphs for r=0.6 =  0.7621162499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.699
SUFF++ for r=0.6 class 0 = 0.586 +- 0.269 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 class 1 = 0.647 +- 0.269 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 class 2 = 0.65 +- 0.269 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all KL = 0.65 +- 0.269 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all L1 = 0.628 +- 0.190 (in-sample avg dev_std = 0.430)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47517375
Model XAI WIoU of binarized graphs for r=0.9 =  0.765675
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF++ for r=0.9 class 0 = 0.801 +- 0.144 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1 = 0.816 +- 0.144 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 2 = 0.868 +- 0.144 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.899 +- 0.144 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.157 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.285
Model XAI F1 of binarized graphs for r=0.3 =  0.45093000000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.32531625
len(reference) = 786
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.316
SUFF++ for r=0.3 class 0 = 0.587 +- 0.193 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 1 = 0.572 +- 0.193 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 2 = 0.584 +- 0.193 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all KL = 0.711 +- 0.193 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all L1 = 0.581 +- 0.127 (in-sample avg dev_std = 0.416)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  0.614325
Model XAI WIoU of binarized graphs for r=0.6 =  0.47790875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.56
SUFF++ for r=0.6 class 0 = 0.513 +- 0.225 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 1 = 0.638 +- 0.225 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 2 = 0.698 +- 0.225 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all KL = 0.679 +- 0.225 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all L1 = 0.616 +- 0.186 (in-sample avg dev_std = 0.413)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  0.59134625
Model XAI WIoU of binarized graphs for r=0.9 =  0.48251875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.729
SUFF++ for r=0.9 class 0 = 0.657 +- 0.160 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1 = 0.932 +- 0.160 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 2 = 0.813 +- 0.160 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.867 +- 0.160 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.798 +- 0.182 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  0.7182862499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6712275
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.364
NEC for r=0.3 class 0 = 0.566 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.3 class 1 = 0.481 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.3 class 2 = 0.605 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.3 all KL = 0.542 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.3 all L1 = 0.551 +- 0.172 (in-sample avg dev_std = 0.397)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.859
Model XAI F1 of binarized graphs for r=0.6 =  0.6064075
Model XAI WIoU of binarized graphs for r=0.6 =  0.7621162499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.547 +- 0.305 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 1 = 0.483 +- 0.305 (in-sample avg dev_std = 0.443)
NEC for r=0.6 class 2 = 0.613 +- 0.305 (in-sample avg dev_std = 0.443)
NEC for r=0.6 all KL = 0.54 +- 0.305 (in-sample avg dev_std = 0.443)
NEC for r=0.6 all L1 = 0.548 +- 0.166 (in-sample avg dev_std = 0.443)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47517375
Model XAI WIoU of binarized graphs for r=0.9 =  0.765675
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.513
NEC for r=0.9 class 0 = 0.502 +- 0.294 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 1 = 0.459 +- 0.294 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 2 = 0.561 +- 0.294 (in-sample avg dev_std = 0.486)
NEC for r=0.9 all KL = 0.488 +- 0.294 (in-sample avg dev_std = 0.486)
NEC for r=0.9 all L1 = 0.508 +- 0.158 (in-sample avg dev_std = 0.486)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7646250000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.516
NEC for r=1.0 class 0 = 0.495 +- 0.291 (in-sample avg dev_std = 0.497)
NEC for r=1.0 class 1 = 0.458 +- 0.291 (in-sample avg dev_std = 0.497)
NEC for r=1.0 class 2 = 0.551 +- 0.291 (in-sample avg dev_std = 0.497)
NEC for r=1.0 all KL = 0.48 +- 0.291 (in-sample avg dev_std = 0.497)
NEC for r=1.0 all L1 = 0.502 +- 0.150 (in-sample avg dev_std = 0.497)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.286
Model XAI F1 of binarized graphs for r=0.3 =  0.45093000000000005
Model XAI WIoU of binarized graphs for r=0.3 =  0.32531625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.322
NEC for r=0.3 class 0 = 0.418 +- 0.221 (in-sample avg dev_std = 0.352)
NEC for r=0.3 class 1 = 0.421 +- 0.221 (in-sample avg dev_std = 0.352)
NEC for r=0.3 class 2 = 0.46 +- 0.221 (in-sample avg dev_std = 0.352)
NEC for r=0.3 all KL = 0.304 +- 0.221 (in-sample avg dev_std = 0.352)
NEC for r=0.3 all L1 = 0.433 +- 0.163 (in-sample avg dev_std = 0.352)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.595
Model XAI F1 of binarized graphs for r=0.6 =  0.614325
Model XAI WIoU of binarized graphs for r=0.6 =  0.47790875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.498
NEC for r=0.6 class 0 = 0.545 +- 0.272 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 1 = 0.481 +- 0.272 (in-sample avg dev_std = 0.501)
NEC for r=0.6 class 2 = 0.638 +- 0.272 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all KL = 0.529 +- 0.272 (in-sample avg dev_std = 0.501)
NEC for r=0.6 all L1 = 0.556 +- 0.155 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  0.59134625
Model XAI WIoU of binarized graphs for r=0.9 =  0.48251875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.607
NEC for r=0.9 class 0 = 0.462 +- 0.254 (in-sample avg dev_std = 0.549)
NEC for r=0.9 class 1 = 0.359 +- 0.254 (in-sample avg dev_std = 0.549)
NEC for r=0.9 class 2 = 0.525 +- 0.254 (in-sample avg dev_std = 0.549)
NEC for r=0.9 all KL = 0.451 +- 0.254 (in-sample avg dev_std = 0.549)
NEC for r=0.9 all L1 = 0.45 +- 0.146 (in-sample avg dev_std = 0.549)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.793
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.4814275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.626
NEC for r=1.0 class 0 = 0.442 +- 0.248 (in-sample avg dev_std = 0.543)
NEC for r=1.0 class 1 = 0.335 +- 0.248 (in-sample avg dev_std = 0.543)
NEC for r=1.0 class 2 = 0.5 +- 0.248 (in-sample avg dev_std = 0.543)
NEC for r=1.0 all KL = 0.424 +- 0.248 (in-sample avg dev_std = 0.543)
NEC for r=1.0 all L1 = 0.428 +- 0.146 (in-sample avg dev_std = 0.543)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.502, 0.551, 0.84, 1.0], 'all_L1': [0.512, 0.576, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.437, 0.591, 0.899, 1.0], 'all_L1': [0.478, 0.61, 0.846, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.503, 0.65, 0.899, 1.0], 'all_L1': [0.505, 0.628, 0.829, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.558, 0.573, 0.52, 0.515], 'all_L1': [0.56, 0.568, 0.525, 0.521]}), defaultdict(<class 'list'>, {'all_KL': [0.607, 0.592, 0.542, 0.526], 'all_L1': [0.587, 0.567, 0.526, 0.508]}), defaultdict(<class 'list'>, {'all_KL': [0.542, 0.54, 0.488, 0.48], 'all_L1': [0.551, 0.548, 0.508, 0.502]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.666, 0.661, 0.892, 1.0], 'all_L1': [0.55, 0.63, 0.802, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.708, 0.71, 0.868, 1.0], 'all_L1': [0.562, 0.627, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.711, 0.679, 0.867, 1.0], 'all_L1': [0.581, 0.616, 0.798, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.387, 0.497, 0.432, 0.412], 'all_L1': [0.505, 0.507, 0.453, 0.435]}), defaultdict(<class 'list'>, {'all_KL': [0.322, 0.433, 0.444, 0.412], 'all_L1': [0.463, 0.492, 0.431, 0.406]}), defaultdict(<class 'list'>, {'all_KL': [0.304, 0.529, 0.451, 0.424], 'all_L1': [0.433, 0.556, 0.45, 0.428]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.498 +- 0.015, 0.605 +- 0.022, 0.823 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.481 +- 0.031, 0.597 +- 0.041, 0.879 +- 0.028, 1.000 +- 0.000
suff++_acc_int  =  0.466 +- 0.003, 0.690 +- 0.008, 0.853 +- 0.014
nec class all_L1  =  0.566 +- 0.015, 0.561 +- 0.009, 0.520 +- 0.008, 0.510 +- 0.008
nec class all_KL  =  0.569 +- 0.028, 0.568 +- 0.021, 0.517 +- 0.022, 0.507 +- 0.020
nec_acc_int  =  0.354 +- 0.008, 0.451 +- 0.006, 0.518 +- 0.008, 0.531 +- 0.011

Eval split test
suff++ class all_L1  =  0.564 +- 0.013, 0.624 +- 0.006, 0.798 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.695 +- 0.021, 0.683 +- 0.020, 0.876 +- 0.012, 1.000 +- 0.000
suff++_acc_int  =  0.334 +- 0.017, 0.596 +- 0.052, 0.778 +- 0.059
nec class all_L1  =  0.467 +- 0.030, 0.518 +- 0.027, 0.445 +- 0.010, 0.423 +- 0.012
nec class all_KL  =  0.338 +- 0.036, 0.486 +- 0.040, 0.442 +- 0.008, 0.416 +- 0.006
nec_acc_int  =  0.326 +- 0.014, 0.508 +- 0.031, 0.625 +- 0.015, 0.640 +- 0.013


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.532 +- 0.003, 0.583 +- 0.008, 0.671 +- 0.011, 0.755 +- 0.004
Faith. Armon (L1)= 		  =  0.530 +- 0.004, 0.582 +- 0.007, 0.637 +- 0.008, 0.676 +- 0.007
Faith. GMean (L1)= 	  =  0.531 +- 0.003, 0.582 +- 0.007, 0.654 +- 0.010, 0.714 +- 0.006
Faith. Aritm (KL)= 		  =  0.525 +- 0.004, 0.583 +- 0.015, 0.698 +- 0.017, 0.753 +- 0.010
Faith. Armon (KL)= 		  =  0.519 +- 0.008, 0.581 +- 0.014, 0.650 +- 0.019, 0.673 +- 0.017
Faith. GMean (KL)= 	  =  0.522 +- 0.006, 0.582 +- 0.014, 0.674 +- 0.017, 0.712 +- 0.014

Eval split test
Faith. Aritm (L1)= 		  =  0.516 +- 0.009, 0.571 +- 0.011, 0.621 +- 0.007, 0.711 +- 0.006
Faith. Armon (L1)= 		  =  0.510 +- 0.013, 0.566 +- 0.014, 0.571 +- 0.009, 0.594 +- 0.012
Faith. GMean (L1)= 	  =  0.513 +- 0.011, 0.569 +- 0.012, 0.596 +- 0.008, 0.650 +- 0.010
Faith. Aritm (KL)= 		  =  0.516 +- 0.008, 0.585 +- 0.014, 0.659 +- 0.002, 0.708 +- 0.003
Faith. Armon (KL)= 		  =  0.453 +- 0.027, 0.567 +- 0.023, 0.588 +- 0.005, 0.588 +- 0.006
Faith. GMean (KL)= 	  =  0.483 +- 0.018, 0.576 +- 0.018, 0.622 +- 0.002, 0.645 +- 0.004
Computed for split load_split = id



Completed in  0:07:39.415497  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis soft

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:03:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/03/2024 02:03:50 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:05 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:07 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:09 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:04:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.8709
Train Loss: 0.4743
ID Validation ACCURACY: 0.8763
ID Validation Loss: 0.4900
ID Test ACCURACY: 0.8777
ID Test Loss: 0.4670
OOD Validation ACCURACY: 0.8980
OOD Validation Loss: 0.4776
OOD Test ACCURACY: 0.7360
OOD Test Loss: 0.6860

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8434
Train Loss: 0.5282
ID Validation ACCURACY: 0.8487
ID Validation Loss: 0.5363
ID Test ACCURACY: 0.8490
ID Test Loss: 0.5228
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4800
OOD Test ACCURACY: 0.8710
OOD Test Loss: 0.4490

[0m[1;37mINFO[0m: [1mChartInfo 0.8777 0.7360 0.8490 0.8710 0.8487 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.631
WIoU for r=0.3 = 0.564
F1 for r=0.6 = 0.569
WIoU for r=0.6 = 0.628
F1 for r=0.9 = 0.472
WIoU for r=0.9 = 0.641
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.642
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.328
WIoU for r=0.3 = 0.218
F1 for r=0.6 = 0.456
WIoU for r=0.6 = 0.319
F1 for r=0.9 = 0.552
WIoU for r=0.9 = 0.381
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.385


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  0.63065125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5642287500000001
len(reference) = 780
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.423
SUFF++ for r=0.3 class 0 = 0.447 +- 0.251 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 1 = 0.478 +- 0.251 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 2 = 0.434 +- 0.251 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all KL = 0.459 +- 0.251 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all L1 = 0.453 +- 0.130 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  0.5688
Model XAI WIoU of binarized graphs for r=0.6 =  0.62794125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.631
SUFF++ for r=0.6 class 0 = 0.56 +- 0.255 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.632 +- 0.255 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.518 +- 0.255 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.6 +- 0.255 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.57 +- 0.155 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  0.47204125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6405325000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.79
SUFF++ for r=0.9 class 0 = 0.772 +- 0.224 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.9 class 1 = 0.768 +- 0.224 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.9 class 2 = 0.725 +- 0.224 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.9 all KL = 0.823 +- 0.224 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.9 all L1 = 0.755 +- 0.187 (in-sample avg dev_std = 0.336)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.321
Model XAI F1 of binarized graphs for r=0.3 =  0.32841000000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.21846625000000003
len(reference) = 735
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.318
SUFF++ for r=0.3 class 0 = 0.561 +- 0.197 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 class 1 = 0.572 +- 0.197 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 class 2 = 0.551 +- 0.197 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all KL = 0.615 +- 0.197 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all L1 = 0.561 +- 0.116 (in-sample avg dev_std = 0.553)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.296
Model XAI F1 of binarized graphs for r=0.6 =  0.4559225
Model XAI WIoU of binarized graphs for r=0.6 =  0.318735
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.323
SUFF++ for r=0.6 class 0 = 0.554 +- 0.200 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 class 1 = 0.575 +- 0.200 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 class 2 = 0.584 +- 0.200 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all KL = 0.702 +- 0.200 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all L1 = 0.571 +- 0.143 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  0.55165
Model XAI WIoU of binarized graphs for r=0.9 =  0.3812825
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.587
SUFF++ for r=0.9 class 0 = 0.719 +- 0.199 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.199 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 class 2 = 0.702 +- 0.199 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 all KL = 0.831 +- 0.199 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 all L1 = 0.774 +- 0.187 (in-sample avg dev_std = 0.327)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  0.63065125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5642287500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.364
NEC for r=0.3 class 0 = 0.563 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 1 = 0.468 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 2 = 0.592 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all KL = 0.517 +- 0.269 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all L1 = 0.541 +- 0.155 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  0.5688
Model XAI WIoU of binarized graphs for r=0.6 =  0.62794125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.488
NEC for r=0.6 class 0 = 0.54 +- 0.290 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 1 = 0.377 +- 0.290 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 2 = 0.61 +- 0.290 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all KL = 0.482 +- 0.290 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all L1 = 0.509 +- 0.183 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  0.47204125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6405325000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.555
NEC for r=0.9 class 0 = 0.501 +- 0.310 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 1 = 0.358 +- 0.310 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 2 = 0.599 +- 0.310 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all KL = 0.457 +- 0.310 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all L1 = 0.487 +- 0.189 (in-sample avg dev_std = 0.485)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.88
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.6421399999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.548
NEC for r=1.0 class 0 = 0.516 +- 0.316 (in-sample avg dev_std = 0.497)
NEC for r=1.0 class 1 = 0.358 +- 0.316 (in-sample avg dev_std = 0.497)
NEC for r=1.0 class 2 = 0.595 +- 0.316 (in-sample avg dev_std = 0.497)
NEC for r=1.0 all KL = 0.468 +- 0.316 (in-sample avg dev_std = 0.497)
NEC for r=1.0 all L1 = 0.49 +- 0.191 (in-sample avg dev_std = 0.497)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.312
Model XAI F1 of binarized graphs for r=0.3 =  0.32841000000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.21846625000000003
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.315
NEC for r=0.3 class 0 = 0.313 +- 0.212 (in-sample avg dev_std = 0.348)
NEC for r=0.3 class 1 = 0.277 +- 0.212 (in-sample avg dev_std = 0.348)
NEC for r=0.3 class 2 = 0.315 +- 0.212 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all KL = 0.216 +- 0.212 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all L1 = 0.302 +- 0.185 (in-sample avg dev_std = 0.348)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.296
Model XAI F1 of binarized graphs for r=0.6 =  0.4559225
Model XAI WIoU of binarized graphs for r=0.6 =  0.318735
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.339
NEC for r=0.6 class 0 = 0.398 +- 0.189 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 1 = 0.338 +- 0.189 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 2 = 0.341 +- 0.189 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all KL = 0.229 +- 0.189 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all L1 = 0.359 +- 0.144 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  0.55165
Model XAI WIoU of binarized graphs for r=0.9 =  0.3812825
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.557
NEC for r=0.9 class 0 = 0.443 +- 0.237 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 1 = 0.169 +- 0.237 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 2 = 0.406 +- 0.237 (in-sample avg dev_std = 0.436)
NEC for r=0.9 all KL = 0.29 +- 0.237 (in-sample avg dev_std = 0.436)
NEC for r=0.9 all L1 = 0.342 +- 0.194 (in-sample avg dev_std = 0.436)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.755
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.38474125000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.628
NEC for r=1.0 class 0 = 0.443 +- 0.240 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 1 = 0.151 +- 0.240 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 2 = 0.476 +- 0.240 (in-sample avg dev_std = 0.447)
NEC for r=1.0 all KL = 0.31 +- 0.240 (in-sample avg dev_std = 0.447)
NEC for r=1.0 all L1 = 0.36 +- 0.199 (in-sample avg dev_std = 0.447)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:06:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:34 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:37 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:38 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:06:40 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 125...
[0m[1;37mINFO[0m: [1mCheckpoint 125: 
-----------------------------------
Train ACCURACY: 0.8998
Train Loss: 0.4565
ID Validation ACCURACY: 0.9003
ID Validation Loss: 0.4767
ID Test ACCURACY: 0.8993
ID Test Loss: 0.4616
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3332
OOD Test ACCURACY: 0.7457
OOD Test Loss: 0.6591

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.8521
Train Loss: 0.4997
ID Validation ACCURACY: 0.8527
ID Validation Loss: 0.5099
ID Test ACCURACY: 0.8513
ID Test Loss: 0.5037
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3200
OOD Test ACCURACY: 0.4697
OOD Test Loss: 1.1723

[0m[1;37mINFO[0m: [1mChartInfo 0.8993 0.7457 0.8513 0.4697 0.8527 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.694
WIoU for r=0.3 = 0.670
F1 for r=0.6 = 0.612
WIoU for r=0.6 = 0.772
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.778
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.778
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.458
WIoU for r=0.3 = 0.381
F1 for r=0.6 = 0.659
WIoU for r=0.6 = 0.505
F1 for r=0.9 = 0.589
WIoU for r=0.9 = 0.529
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.529


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.689
Model XAI F1 of binarized graphs for r=0.3 =  0.69392
Model XAI WIoU of binarized graphs for r=0.3 =  0.66989375
len(reference) = 797
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.478
SUFF++ for r=0.3 class 0 = 0.474 +- 0.283 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 1 = 0.579 +- 0.283 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 2 = 0.451 +- 0.283 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all KL = 0.484 +- 0.283 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all L1 = 0.501 +- 0.140 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.6118125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7723475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0 = 0.555 +- 0.289 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1 = 0.708 +- 0.289 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 2 = 0.597 +- 0.289 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.597 +- 0.289 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.621 +- 0.177 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.4753462500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.7780775
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0 = 0.782 +- 0.169 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 1 = 0.821 +- 0.169 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 2 = 0.841 +- 0.169 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all KL = 0.877 +- 0.169 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.159 (in-sample avg dev_std = 0.254)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.386
Model XAI F1 of binarized graphs for r=0.3 =  0.45753625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3805225
len(reference) = 784
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.326
SUFF++ for r=0.3 class 0 = 0.582 +- 0.200 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 1 = 0.59 +- 0.200 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 2 = 0.587 +- 0.200 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all KL = 0.707 +- 0.200 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all L1 = 0.586 +- 0.113 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  0.65876875
Model XAI WIoU of binarized graphs for r=0.6 =  0.5050162499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.606
SUFF++ for r=0.6 class 0 = 0.524 +- 0.244 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 class 1 = 0.771 +- 0.244 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 class 2 = 0.584 +- 0.244 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 all KL = 0.653 +- 0.244 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 all L1 = 0.624 +- 0.196 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.771
Model XAI F1 of binarized graphs for r=0.9 =  0.58880375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5290637499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.73
SUFF++ for r=0.9 class 0 = 0.67 +- 0.190 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.190 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 2 = 0.741 +- 0.190 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all KL = 0.841 +- 0.190 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all L1 = 0.766 +- 0.205 (in-sample avg dev_std = 0.316)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.689
Model XAI F1 of binarized graphs for r=0.3 =  0.69392
Model XAI WIoU of binarized graphs for r=0.3 =  0.66989375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.355
NEC for r=0.3 class 0 = 0.556 +- 0.292 (in-sample avg dev_std = 0.444)
NEC for r=0.3 class 1 = 0.604 +- 0.292 (in-sample avg dev_std = 0.444)
NEC for r=0.3 class 2 = 0.615 +- 0.292 (in-sample avg dev_std = 0.444)
NEC for r=0.3 all KL = 0.604 +- 0.292 (in-sample avg dev_std = 0.444)
NEC for r=0.3 all L1 = 0.592 +- 0.149 (in-sample avg dev_std = 0.444)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.6118125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7723475
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.446
NEC for r=0.6 class 0 = 0.51 +- 0.309 (in-sample avg dev_std = 0.491)
NEC for r=0.6 class 1 = 0.565 +- 0.309 (in-sample avg dev_std = 0.491)
NEC for r=0.6 class 2 = 0.597 +- 0.309 (in-sample avg dev_std = 0.491)
NEC for r=0.6 all KL = 0.587 +- 0.309 (in-sample avg dev_std = 0.491)
NEC for r=0.6 all L1 = 0.558 +- 0.166 (in-sample avg dev_std = 0.491)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.4753462500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.7780775
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.479 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=0.9 class 1 = 0.508 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=0.9 class 2 = 0.554 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=0.9 all KL = 0.523 +- 0.305 (in-sample avg dev_std = 0.508)
NEC for r=0.9 all L1 = 0.515 +- 0.162 (in-sample avg dev_std = 0.508)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7780775
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.56
NEC for r=1.0 class 0 = 0.466 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 1 = 0.49 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 2 = 0.525 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all KL = 0.501 +- 0.306 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all L1 = 0.494 +- 0.160 (in-sample avg dev_std = 0.515)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.389
Model XAI F1 of binarized graphs for r=0.3 =  0.45753625
Model XAI WIoU of binarized graphs for r=0.3 =  0.3805225
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.404
NEC for r=0.3 class 0 = 0.377 +- 0.255 (in-sample avg dev_std = 0.324)
NEC for r=0.3 class 1 = 0.469 +- 0.255 (in-sample avg dev_std = 0.324)
NEC for r=0.3 class 2 = 0.497 +- 0.255 (in-sample avg dev_std = 0.324)
NEC for r=0.3 all KL = 0.322 +- 0.255 (in-sample avg dev_std = 0.324)
NEC for r=0.3 all L1 = 0.447 +- 0.184 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  0.65876875
Model XAI WIoU of binarized graphs for r=0.6 =  0.5050162499999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.523
NEC for r=0.6 class 0 = 0.457 +- 0.278 (in-sample avg dev_std = 0.523)
NEC for r=0.6 class 1 = 0.458 +- 0.278 (in-sample avg dev_std = 0.523)
NEC for r=0.6 class 2 = 0.607 +- 0.278 (in-sample avg dev_std = 0.523)
NEC for r=0.6 all KL = 0.509 +- 0.278 (in-sample avg dev_std = 0.523)
NEC for r=0.6 all L1 = 0.509 +- 0.154 (in-sample avg dev_std = 0.523)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.771
Model XAI F1 of binarized graphs for r=0.9 =  0.58880375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5290637499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.575
NEC for r=0.9 class 0 = 0.434 +- 0.243 (in-sample avg dev_std = 0.517)
NEC for r=0.9 class 1 = 0.426 +- 0.243 (in-sample avg dev_std = 0.517)
NEC for r=0.9 class 2 = 0.516 +- 0.243 (in-sample avg dev_std = 0.517)
NEC for r=0.9 all KL = 0.441 +- 0.243 (in-sample avg dev_std = 0.517)
NEC for r=0.9 all L1 = 0.459 +- 0.134 (in-sample avg dev_std = 0.517)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.776
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.52914625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.594
NEC for r=1.0 class 0 = 0.418 +- 0.229 (in-sample avg dev_std = 0.505)
NEC for r=1.0 class 1 = 0.406 +- 0.229 (in-sample avg dev_std = 0.505)
NEC for r=1.0 class 2 = 0.501 +- 0.229 (in-sample avg dev_std = 0.505)
NEC for r=1.0 all KL = 0.405 +- 0.229 (in-sample avg dev_std = 0.505)
NEC for r=1.0 all L1 = 0.442 +- 0.131 (in-sample avg dev_std = 0.505)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:08:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/03/2024 02:08:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:00 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:09:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ACCURACY: 0.8432
Train Loss: 0.5515
ID Validation ACCURACY: 0.8457
ID Validation Loss: 0.5506
ID Test ACCURACY: 0.8443
ID Test Loss: 0.5672
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.3364
OOD Test ACCURACY: 0.6663
OOD Test Loss: 0.8704

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ACCURACY: 0.7446
Train Loss: 0.6561
ID Validation ACCURACY: 0.7423
ID Validation Loss: 0.6758
ID Test ACCURACY: 0.7500
ID Test Loss: 0.6538
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3339
OOD Test ACCURACY: 0.4593
OOD Test Loss: 1.0915

[0m[1;37mINFO[0m: [1mChartInfo 0.8443 0.6663 0.7500 0.4593 0.7423 0.9307[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.649
WIoU for r=0.3 = 0.574
F1 for r=0.6 = 0.585
WIoU for r=0.6 = 0.645
F1 for r=0.9 = 0.469
WIoU for r=0.9 = 0.638
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.638
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.396
WIoU for r=0.3 = 0.289
F1 for r=0.6 = 0.526
WIoU for r=0.6 = 0.395
F1 for r=0.9 = 0.587
WIoU for r=0.9 = 0.425
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.424


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  0.6492574999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.57435375
len(reference) = 791
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.477
SUFF++ for r=0.3 class 0 = 0.489 +- 0.277 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.581 +- 0.277 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.502 +- 0.277 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.55 +- 0.277 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.160 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.78
Model XAI F1 of binarized graphs for r=0.6 =  0.58491375
Model XAI WIoU of binarized graphs for r=0.6 =  0.644515
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0 = 0.592 +- 0.265 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 1 = 0.656 +- 0.265 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 2 = 0.603 +- 0.265 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all KL = 0.63 +- 0.265 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all L1 = 0.617 +- 0.181 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  0.46850875000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.6381975
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.803
SUFF++ for r=0.9 class 0 = 0.767 +- 0.188 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 1 = 0.795 +- 0.188 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 2 = 0.741 +- 0.188 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all KL = 0.841 +- 0.188 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all L1 = 0.767 +- 0.192 (in-sample avg dev_std = 0.252)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.326
Model XAI F1 of binarized graphs for r=0.3 =  0.39603375
Model XAI WIoU of binarized graphs for r=0.3 =  0.28881625
len(reference) = 777
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.336
SUFF++ for r=0.3 class 0 = 0.613 +- 0.136 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.3 class 1 = 0.614 +- 0.136 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.3 class 2 = 0.614 +- 0.136 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.3 all KL = 0.773 +- 0.136 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.3 all L1 = 0.614 +- 0.104 (in-sample avg dev_std = 0.402)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.311
Model XAI F1 of binarized graphs for r=0.6 =  0.525595
Model XAI WIoU of binarized graphs for r=0.6 =  0.394665
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.386
SUFF++ for r=0.6 class 0 = 0.592 +- 0.256 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 1 = 0.665 +- 0.256 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 2 = 0.652 +- 0.256 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all KL = 0.641 +- 0.256 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all L1 = 0.636 +- 0.175 (in-sample avg dev_std = 0.480)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.67
Model XAI F1 of binarized graphs for r=0.9 =  0.586865
Model XAI WIoU of binarized graphs for r=0.9 =  0.42533625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.631
SUFF++ for r=0.9 class 0 = 0.71 +- 0.180 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 1 = 0.976 +- 0.180 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 2 = 0.692 +- 0.180 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all KL = 0.868 +- 0.180 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all L1 = 0.789 +- 0.196 (in-sample avg dev_std = 0.299)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.625
Model XAI F1 of binarized graphs for r=0.3 =  0.6492574999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.57435375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.43
NEC for r=0.3 class 0 = 0.532 +- 0.305 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 1 = 0.468 +- 0.305 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 2 = 0.582 +- 0.305 (in-sample avg dev_std = 0.411)
NEC for r=0.3 all KL = 0.492 +- 0.305 (in-sample avg dev_std = 0.411)
NEC for r=0.3 all L1 = 0.528 +- 0.170 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  0.58491375
Model XAI WIoU of binarized graphs for r=0.6 =  0.644515
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.535
NEC for r=0.6 class 0 = 0.5 +- 0.312 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 1 = 0.475 +- 0.312 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 2 = 0.561 +- 0.312 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all KL = 0.524 +- 0.312 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all L1 = 0.513 +- 0.178 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  0.46850875000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.6381975
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.588
NEC for r=0.9 class 0 = 0.444 +- 0.292 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 1 = 0.45 +- 0.292 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 2 = 0.534 +- 0.292 (in-sample avg dev_std = 0.481)
NEC for r=0.9 all KL = 0.473 +- 0.292 (in-sample avg dev_std = 0.481)
NEC for r=0.9 all L1 = 0.477 +- 0.165 (in-sample avg dev_std = 0.481)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.6381975
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.609
NEC for r=1.0 class 0 = 0.441 +- 0.285 (in-sample avg dev_std = 0.485)
NEC for r=1.0 class 1 = 0.441 +- 0.285 (in-sample avg dev_std = 0.485)
NEC for r=1.0 class 2 = 0.531 +- 0.285 (in-sample avg dev_std = 0.485)
NEC for r=1.0 all KL = 0.462 +- 0.285 (in-sample avg dev_std = 0.485)
NEC for r=1.0 all L1 = 0.472 +- 0.162 (in-sample avg dev_std = 0.485)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.324
Model XAI F1 of binarized graphs for r=0.3 =  0.39603375
Model XAI WIoU of binarized graphs for r=0.3 =  0.28881625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.39 +- 0.171 (in-sample avg dev_std = 0.309)
NEC for r=0.3 class 1 = 0.385 +- 0.171 (in-sample avg dev_std = 0.309)
NEC for r=0.3 class 2 = 0.356 +- 0.171 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all KL = 0.207 +- 0.171 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all L1 = 0.377 +- 0.141 (in-sample avg dev_std = 0.309)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.311
Model XAI F1 of binarized graphs for r=0.6 =  0.525595
Model XAI WIoU of binarized graphs for r=0.6 =  0.394665
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.498
NEC for r=0.6 class 0 = 0.514 +- 0.305 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 1 = 0.418 +- 0.305 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 2 = 0.493 +- 0.305 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all KL = 0.502 +- 0.305 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all L1 = 0.476 +- 0.203 (in-sample avg dev_std = 0.538)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.67
Model XAI F1 of binarized graphs for r=0.9 =  0.586865
Model XAI WIoU of binarized graphs for r=0.9 =  0.42533625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.617
NEC for r=0.9 class 0 = 0.429 +- 0.183 (in-sample avg dev_std = 0.396)
NEC for r=0.9 class 1 = 0.185 +- 0.183 (in-sample avg dev_std = 0.396)
NEC for r=0.9 class 2 = 0.486 +- 0.183 (in-sample avg dev_std = 0.396)
NEC for r=0.9 all KL = 0.302 +- 0.183 (in-sample avg dev_std = 0.396)
NEC for r=0.9 all L1 = 0.37 +- 0.187 (in-sample avg dev_std = 0.396)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.668
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.42442
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.633
NEC for r=1.0 class 0 = 0.402 +- 0.166 (in-sample avg dev_std = 0.379)
NEC for r=1.0 class 1 = 0.175 +- 0.166 (in-sample avg dev_std = 0.379)
NEC for r=1.0 class 2 = 0.459 +- 0.166 (in-sample avg dev_std = 0.379)
NEC for r=1.0 all KL = 0.261 +- 0.166 (in-sample avg dev_std = 0.379)
NEC for r=1.0 all L1 = 0.348 +- 0.175 (in-sample avg dev_std = 0.379)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.459, 0.6, 0.823, 1.0], 'all_L1': [0.453, 0.57, 0.755, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.484, 0.597, 0.877, 1.0], 'all_L1': [0.501, 0.621, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.55, 0.63, 0.841, 1.0], 'all_L1': [0.524, 0.617, 0.767, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.517, 0.482, 0.457, 0.468], 'all_L1': [0.541, 0.509, 0.487, 0.49]}), defaultdict(<class 'list'>, {'all_KL': [0.604, 0.587, 0.523, 0.501], 'all_L1': [0.592, 0.558, 0.515, 0.494]}), defaultdict(<class 'list'>, {'all_KL': [0.492, 0.524, 0.473, 0.462], 'all_L1': [0.528, 0.513, 0.477, 0.472]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.615, 0.702, 0.831, 1.0], 'all_L1': [0.561, 0.571, 0.774, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.707, 0.653, 0.841, 1.0], 'all_L1': [0.586, 0.624, 0.766, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.773, 0.641, 0.868, 1.0], 'all_L1': [0.614, 0.636, 0.789, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.216, 0.229, 0.29, 0.31], 'all_L1': [0.302, 0.359, 0.342, 0.36]}), defaultdict(<class 'list'>, {'all_KL': [0.322, 0.509, 0.441, 0.405], 'all_L1': [0.447, 0.509, 0.459, 0.442]}), defaultdict(<class 'list'>, {'all_KL': [0.207, 0.502, 0.302, 0.261], 'all_L1': [0.377, 0.476, 0.37, 0.348]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.493 +- 0.030, 0.603 +- 0.023, 0.779 +- 0.026, 1.000 +- 0.000
suff++ class all_KL  =  0.498 +- 0.038, 0.609 +- 0.015, 0.847 +- 0.022, 1.000 +- 0.000
suff++_acc_int  =  0.459 +- 0.026, 0.677 +- 0.035, 0.816 +- 0.028
nec class all_L1  =  0.554 +- 0.028, 0.527 +- 0.022, 0.493 +- 0.016, 0.485 +- 0.010
nec class all_KL  =  0.538 +- 0.048, 0.531 +- 0.043, 0.484 +- 0.028, 0.477 +- 0.017
nec_acc_int  =  0.383 +- 0.033, 0.490 +- 0.036, 0.558 +- 0.023, 0.573 +- 0.026

Eval split test
suff++ class all_L1  =  0.587 +- 0.022, 0.610 +- 0.028, 0.776 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.698 +- 0.065, 0.665 +- 0.026, 0.847 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.327 +- 0.007, 0.438 +- 0.121, 0.649 +- 0.060
nec class all_L1  =  0.375 +- 0.059, 0.448 +- 0.064, 0.390 +- 0.050, 0.383 +- 0.042
nec class all_KL  =  0.248 +- 0.052, 0.413 +- 0.130, 0.344 +- 0.069, 0.325 +- 0.060
nec_acc_int  =  0.359 +- 0.036, 0.453 +- 0.081, 0.583 +- 0.025, 0.618 +- 0.017


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.523 +- 0.020, 0.565 +- 0.020, 0.636 +- 0.021, 0.743 +- 0.005
Faith. Armon (L1)= 		  =  0.521 +- 0.021, 0.562 +- 0.020, 0.604 +- 0.020, 0.653 +- 0.009
Faith. GMean (L1)= 	  =  0.522 +- 0.020, 0.563 +- 0.020, 0.620 +- 0.020, 0.697 +- 0.007
Faith. Aritm (KL)= 		  =  0.518 +- 0.023, 0.570 +- 0.021, 0.666 +- 0.025, 0.738 +- 0.009
Faith. Armon (KL)= 		  =  0.514 +- 0.021, 0.566 +- 0.024, 0.616 +- 0.029, 0.646 +- 0.016
Faith. GMean (KL)= 	  =  0.516 +- 0.022, 0.568 +- 0.023, 0.640 +- 0.027, 0.691 +- 0.012

Eval split test
Faith. Aritm (L1)= 		  =  0.481 +- 0.036, 0.529 +- 0.046, 0.583 +- 0.022, 0.692 +- 0.021
Faith. Armon (L1)= 		  =  0.456 +- 0.047, 0.515 +- 0.053, 0.517 +- 0.042, 0.553 +- 0.043
Faith. GMean (L1)= 	  =  0.468 +- 0.042, 0.522 +- 0.049, 0.549 +- 0.033, 0.618 +- 0.033
Faith. Aritm (KL)= 		  =  0.473 +- 0.042, 0.539 +- 0.052, 0.595 +- 0.034, 0.663 +- 0.030
Faith. Armon (KL)= 		  =  0.363 +- 0.056, 0.493 +- 0.105, 0.486 +- 0.066, 0.488 +- 0.067
Faith. GMean (KL)= 	  =  0.414 +- 0.047, 0.515 +- 0.081, 0.537 +- 0.051, 0.568 +- 0.052
Computed for split load_split = id



Completed in  0:07:25.324367  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis soft2

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:11:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:11:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.8878
Train Loss: 0.4544
ID Validation ACCURACY: 0.8893
ID Validation Loss: 0.4385
ID Test ACCURACY: 0.8823
ID Test Loss: 0.4727
OOD Validation ACCURACY: 0.8807
OOD Validation Loss: 0.5301
OOD Test ACCURACY: 0.8880
OOD Test Loss: 0.4310

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8450
Train Loss: 0.5156
ID Validation ACCURACY: 0.8467
ID Validation Loss: 0.5045
ID Test ACCURACY: 0.8373
ID Test Loss: 0.5404
OOD Validation ACCURACY: 0.9113
OOD Validation Loss: 0.5421
OOD Test ACCURACY: 0.7887
OOD Test Loss: 0.5771

[0m[1;37mINFO[0m: [1mChartInfo 0.8823 0.8880 0.8373 0.7887 0.8467 0.9113[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.700
WIoU for r=0.3 = 0.668
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.754
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.762
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.762
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.797
WIoU for r=0.3 = 0.885
F1 for r=0.6 = 0.565
WIoU for r=0.6 = 0.907
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.907
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.907


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.551
Model XAI F1 of binarized graphs for r=0.3 =  0.70030125
Model XAI WIoU of binarized graphs for r=0.3 =  0.66757875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.499
SUFF++ for r=0.3 class 0 = 0.534 +- 0.283 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 1 = 0.563 +- 0.283 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 2 = 0.498 +- 0.283 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all KL = 0.45 +- 0.283 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all L1 = 0.532 +- 0.175 (in-sample avg dev_std = 0.565)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.866
Model XAI F1 of binarized graphs for r=0.6 =  0.6156225
Model XAI WIoU of binarized graphs for r=0.6 =  0.7539637499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.716
SUFF++ for r=0.6 class 0 = 0.602 +- 0.287 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.695 +- 0.287 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.649 +- 0.287 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.633 +- 0.287 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.187 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.762045
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0 = 0.807 +- 0.192 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1 = 0.796 +- 0.192 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 2 = 0.833 +- 0.192 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.87 +- 0.192 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.192 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.614
Model XAI F1 of binarized graphs for r=0.3 =  0.7974700000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8853762499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.575
SUFF++ for r=0.3 class 0 = 0.578 +- 0.298 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 class 1 = 0.672 +- 0.298 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 class 2 = 0.604 +- 0.298 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all KL = 0.554 +- 0.298 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all L1 = 0.619 +- 0.206 (in-sample avg dev_std = 0.553)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9073699999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.829
SUFF++ for r=0.6 class 0 = 0.783 +- 0.259 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.259 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 2 = 0.797 +- 0.259 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.786 +- 0.259 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.793 +- 0.158 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.9073699999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.889
SUFF++ for r=0.9 class 0 = 0.924 +- 0.066 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1 = 0.928 +- 0.066 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 2 = 0.954 +- 0.066 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.97 +- 0.066 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.084 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  0.70030125
Model XAI WIoU of binarized graphs for r=0.3 =  0.66757875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.548 +- 0.290 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 1 = 0.52 +- 0.290 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 2 = 0.589 +- 0.290 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all KL = 0.6 +- 0.290 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all L1 = 0.552 +- 0.166 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.866
Model XAI F1 of binarized graphs for r=0.6 =  0.6156225
Model XAI WIoU of binarized graphs for r=0.6 =  0.7539637499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.511
NEC for r=0.6 class 0 = 0.523 +- 0.305 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.463 +- 0.305 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.614 +- 0.305 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.551 +- 0.305 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.533 +- 0.172 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.762045
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.552
NEC for r=0.9 class 0 = 0.463 +- 0.302 (in-sample avg dev_std = 0.532)
NEC for r=0.9 class 1 = 0.426 +- 0.302 (in-sample avg dev_std = 0.532)
NEC for r=0.9 class 2 = 0.558 +- 0.302 (in-sample avg dev_std = 0.532)
NEC for r=0.9 all KL = 0.485 +- 0.302 (in-sample avg dev_std = 0.532)
NEC for r=0.9 all L1 = 0.482 +- 0.172 (in-sample avg dev_std = 0.532)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.904
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.762045
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.562
NEC for r=1.0 class 0 = 0.478 +- 0.302 (in-sample avg dev_std = 0.535)
NEC for r=1.0 class 1 = 0.423 +- 0.302 (in-sample avg dev_std = 0.535)
NEC for r=1.0 class 2 = 0.549 +- 0.302 (in-sample avg dev_std = 0.535)
NEC for r=1.0 all KL = 0.485 +- 0.302 (in-sample avg dev_std = 0.535)
NEC for r=1.0 all L1 = 0.483 +- 0.170 (in-sample avg dev_std = 0.535)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.614
Model XAI F1 of binarized graphs for r=0.3 =  0.7974700000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8853762499999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.358
NEC for r=0.3 class 0 = 0.612 +- 0.248 (in-sample avg dev_std = 0.501)
NEC for r=0.3 class 1 = 0.555 +- 0.248 (in-sample avg dev_std = 0.501)
NEC for r=0.3 class 2 = 0.657 +- 0.248 (in-sample avg dev_std = 0.501)
NEC for r=0.3 all KL = 0.664 +- 0.248 (in-sample avg dev_std = 0.501)
NEC for r=0.3 all L1 = 0.608 +- 0.129 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9073699999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.514
NEC for r=0.6 class 0 = 0.477 +- 0.314 (in-sample avg dev_std = 0.535)
NEC for r=0.6 class 1 = 0.429 +- 0.314 (in-sample avg dev_std = 0.535)
NEC for r=0.6 class 2 = 0.596 +- 0.314 (in-sample avg dev_std = 0.535)
NEC for r=0.6 all KL = 0.538 +- 0.314 (in-sample avg dev_std = 0.535)
NEC for r=0.6 all L1 = 0.5 +- 0.179 (in-sample avg dev_std = 0.535)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.9073699999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.617
NEC for r=0.9 class 0 = 0.355 +- 0.326 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 1 = 0.323 +- 0.326 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 2 = 0.476 +- 0.326 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all KL = 0.42 +- 0.326 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all L1 = 0.384 +- 0.200 (in-sample avg dev_std = 0.571)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.9073699999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.631
NEC for r=1.0 class 0 = 0.356 +- 0.317 (in-sample avg dev_std = 0.572)
NEC for r=1.0 class 1 = 0.32 +- 0.317 (in-sample avg dev_std = 0.572)
NEC for r=1.0 class 2 = 0.46 +- 0.317 (in-sample avg dev_std = 0.572)
NEC for r=1.0 all KL = 0.414 +- 0.317 (in-sample avg dev_std = 0.572)
NEC for r=1.0 all L1 = 0.378 +- 0.191 (in-sample avg dev_std = 0.572)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:14:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:14:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ACCURACY: 0.8784
Train Loss: 0.4820
ID Validation ACCURACY: 0.8830
ID Validation Loss: 0.4654
ID Test ACCURACY: 0.8753
ID Test Loss: 0.5047
OOD Validation ACCURACY: 0.9043
OOD Validation Loss: 0.5256
OOD Test ACCURACY: 0.8643
OOD Test Loss: 0.5038

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.8803
Train Loss: 0.4530
ID Validation ACCURACY: 0.8810
ID Validation Loss: 0.4393
ID Test ACCURACY: 0.8757
ID Test Loss: 0.4738
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.4912
OOD Test ACCURACY: 0.7467
OOD Test Loss: 0.7928

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8643 0.8757 0.7467 0.8810 0.9260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.741
WIoU for r=0.3 = 0.713
F1 for r=0.6 = 0.623
WIoU for r=0.6 = 0.799
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.803
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.803
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.570
WIoU for r=0.3 = 0.423
F1 for r=0.6 = 0.555
WIoU for r=0.6 = 0.500
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.477
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.477


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  0.74119
Model XAI WIoU of binarized graphs for r=0.3 =  0.71332
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.492
SUFF++ for r=0.3 class 0 = 0.523 +- 0.302 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 1 = 0.635 +- 0.302 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 2 = 0.453 +- 0.302 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all KL = 0.538 +- 0.302 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all L1 = 0.538 +- 0.166 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.866
Model XAI F1 of binarized graphs for r=0.6 =  0.6234274999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.799105
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.731
SUFF++ for r=0.6 class 0 = 0.655 +- 0.271 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 class 1 = 0.659 +- 0.271 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 class 2 = 0.634 +- 0.271 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 all KL = 0.652 +- 0.271 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.192 (in-sample avg dev_std = 0.453)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.480965
Model XAI WIoU of binarized graphs for r=0.9 =  0.8025512499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.84
SUFF++ for r=0.9 class 0 = 0.774 +- 0.195 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1 = 0.775 +- 0.195 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 2 = 0.864 +- 0.195 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.867 +- 0.195 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.804 +- 0.190 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.5
Model XAI F1 of binarized graphs for r=0.3 =  0.570385
Model XAI WIoU of binarized graphs for r=0.3 =  0.42287125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.483
SUFF++ for r=0.3 class 0 = 0.499 +- 0.236 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 1 = 0.673 +- 0.236 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 2 = 0.57 +- 0.236 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all KL = 0.614 +- 0.236 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all L1 = 0.582 +- 0.159 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.5002637499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.653
SUFF++ for r=0.6 class 0 = 0.595 +- 0.337 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.337 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 2 = 0.574 +- 0.337 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 all KL = 0.562 +- 0.337 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 all L1 = 0.611 +- 0.189 (in-sample avg dev_std = 0.575)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.47712499999999997
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.702 +- 0.305 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 1 = 0.712 +- 0.305 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 2 = 0.803 +- 0.305 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all KL = 0.772 +- 0.305 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all L1 = 0.739 +- 0.213 (in-sample avg dev_std = 0.301)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  0.74119
Model XAI WIoU of binarized graphs for r=0.3 =  0.71332
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.438
NEC for r=0.3 class 0 = 0.521 +- 0.322 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 1 = 0.413 +- 0.322 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 2 = 0.562 +- 0.322 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all KL = 0.486 +- 0.322 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all L1 = 0.498 +- 0.181 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.866
Model XAI F1 of binarized graphs for r=0.6 =  0.6234274999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.799105
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.494
NEC for r=0.6 class 0 = 0.528 +- 0.319 (in-sample avg dev_std = 0.468)
NEC for r=0.6 class 1 = 0.458 +- 0.319 (in-sample avg dev_std = 0.468)
NEC for r=0.6 class 2 = 0.634 +- 0.319 (in-sample avg dev_std = 0.468)
NEC for r=0.6 all KL = 0.555 +- 0.319 (in-sample avg dev_std = 0.468)
NEC for r=0.6 all L1 = 0.539 +- 0.178 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.480965
Model XAI WIoU of binarized graphs for r=0.9 =  0.8025512499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.56
NEC for r=0.9 class 0 = 0.468 +- 0.304 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 1 = 0.421 +- 0.304 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 2 = 0.555 +- 0.304 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all KL = 0.47 +- 0.304 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all L1 = 0.481 +- 0.162 (in-sample avg dev_std = 0.509)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.8025275000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.565
NEC for r=1.0 class 0 = 0.471 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 1 = 0.413 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 2 = 0.553 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all KL = 0.47 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all L1 = 0.479 +- 0.161 (in-sample avg dev_std = 0.515)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.5
Model XAI F1 of binarized graphs for r=0.3 =  0.570385
Model XAI WIoU of binarized graphs for r=0.3 =  0.42287125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.402
NEC for r=0.3 class 0 = 0.518 +- 0.288 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 1 = 0.442 +- 0.288 (in-sample avg dev_std = 0.438)
NEC for r=0.3 class 2 = 0.502 +- 0.288 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all KL = 0.445 +- 0.288 (in-sample avg dev_std = 0.438)
NEC for r=0.3 all L1 = 0.487 +- 0.181 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.5002637499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.523
NEC for r=0.6 class 0 = 0.507 +- 0.302 (in-sample avg dev_std = 0.583)
NEC for r=0.6 class 1 = 0.409 +- 0.302 (in-sample avg dev_std = 0.583)
NEC for r=0.6 class 2 = 0.626 +- 0.302 (in-sample avg dev_std = 0.583)
NEC for r=0.6 all KL = 0.555 +- 0.302 (in-sample avg dev_std = 0.583)
NEC for r=0.6 all L1 = 0.513 +- 0.174 (in-sample avg dev_std = 0.583)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.47712499999999997
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.604
NEC for r=0.9 class 0 = 0.447 +- 0.290 (in-sample avg dev_std = 0.511)
NEC for r=0.9 class 1 = 0.4 +- 0.290 (in-sample avg dev_std = 0.511)
NEC for r=0.9 class 2 = 0.492 +- 0.290 (in-sample avg dev_std = 0.511)
NEC for r=0.9 all KL = 0.429 +- 0.290 (in-sample avg dev_std = 0.511)
NEC for r=0.9 all L1 = 0.446 +- 0.171 (in-sample avg dev_std = 0.511)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.875
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.47712499999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0 = 0.461 +- 0.290 (in-sample avg dev_std = 0.519)
NEC for r=1.0 class 1 = 0.392 +- 0.290 (in-sample avg dev_std = 0.519)
NEC for r=1.0 class 2 = 0.484 +- 0.290 (in-sample avg dev_std = 0.519)
NEC for r=1.0 all KL = 0.436 +- 0.290 (in-sample avg dev_std = 0.519)
NEC for r=1.0 all L1 = 0.445 +- 0.169 (in-sample avg dev_std = 0.519)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:16:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:16:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.8847
Train Loss: 0.4814
ID Validation ACCURACY: 0.8943
ID Validation Loss: 0.4807
ID Test ACCURACY: 0.8903
ID Test Loss: 0.4892
OOD Validation ACCURACY: 0.9203
OOD Validation Loss: 0.4674
OOD Test ACCURACY: 0.6230
OOD Test Loss: 1.2096

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.8847
Train Loss: 0.4814
ID Validation ACCURACY: 0.8943
ID Validation Loss: 0.4807
ID Test ACCURACY: 0.8903
ID Test Loss: 0.4892
OOD Validation ACCURACY: 0.9203
OOD Validation Loss: 0.4674
OOD Test ACCURACY: 0.6230
OOD Test Loss: 1.2096

[0m[1;37mINFO[0m: [1mChartInfo 0.8903 0.6230 0.8903 0.6230 0.8943 0.9203[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.671
WIoU for r=0.3 = 0.585
F1 for r=0.6 = 0.619
WIoU for r=0.6 = 0.671
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.661
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.659
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.068
WIoU for r=0.3 = 0.047
F1 for r=0.6 = 0.380
WIoU for r=0.6 = 0.245
F1 for r=0.9 = 0.421
WIoU for r=0.9 = 0.294
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.292


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  0.67094
Model XAI WIoU of binarized graphs for r=0.3 =  0.58513625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.413
SUFF++ for r=0.3 class 0 = 0.487 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 class 1 = 0.598 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 all KL = 0.534 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 all L1 = 0.519 +- 0.159 (in-sample avg dev_std = 0.450)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.885
Model XAI F1 of binarized graphs for r=0.6 =  0.61931375
Model XAI WIoU of binarized graphs for r=0.6 =  0.6713025
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.673
SUFF++ for r=0.6 class 0 = 0.577 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 1 = 0.609 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 2 = 0.595 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all KL = 0.586 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all L1 = 0.594 +- 0.186 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.901
Model XAI F1 of binarized graphs for r=0.9 =  0.48103875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6609475
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.819
SUFF++ for r=0.9 class 0 = 0.773 +- 0.207 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 1 = 0.714 +- 0.207 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 2 = 0.8 +- 0.207 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all KL = 0.83 +- 0.207 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all L1 = 0.762 +- 0.198 (in-sample avg dev_std = 0.275)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.34
Model XAI F1 of binarized graphs for r=0.3 =  0.06783125
Model XAI WIoU of binarized graphs for r=0.3 =  0.04655374999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.332
SUFF++ for r=0.3 class 0 = 0.618 +- 0.151 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 class 1 = 0.645 +- 0.151 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 class 2 = 0.632 +- 0.151 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 all KL = 0.765 +- 0.151 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 all L1 = 0.632 +- 0.096 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.533
Model XAI F1 of binarized graphs for r=0.6 =  0.38010625000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.24529499999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.422
SUFF++ for r=0.6 class 0 = 0.423 +- 0.239 (in-sample avg dev_std = 0.590)
SUFF++ for r=0.6 class 1 = 0.417 +- 0.239 (in-sample avg dev_std = 0.590)
SUFF++ for r=0.6 class 2 = 0.459 +- 0.239 (in-sample avg dev_std = 0.590)
SUFF++ for r=0.6 all KL = 0.401 +- 0.239 (in-sample avg dev_std = 0.590)
SUFF++ for r=0.6 all L1 = 0.433 +- 0.140 (in-sample avg dev_std = 0.590)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  0.42134
Model XAI WIoU of binarized graphs for r=0.9 =  0.29393875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
SUFF++ for r=0.9 class 0 = 0.464 +- 0.353 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.9 class 1 = 0.547 +- 0.353 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.9 class 2 = 0.666 +- 0.353 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.9 all KL = 0.519 +- 0.353 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.9 all L1 = 0.56 +- 0.252 (in-sample avg dev_std = 0.410)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  0.67094
Model XAI WIoU of binarized graphs for r=0.3 =  0.58513625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.392
NEC for r=0.3 class 0 = 0.538 +- 0.266 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 1 = 0.42 +- 0.266 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 2 = 0.539 +- 0.266 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all KL = 0.472 +- 0.266 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all L1 = 0.499 +- 0.163 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.885
Model XAI F1 of binarized graphs for r=0.6 =  0.61931375
Model XAI WIoU of binarized graphs for r=0.6 =  0.6713025
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.585 +- 0.307 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 1 = 0.47 +- 0.307 (in-sample avg dev_std = 0.459)
NEC for r=0.6 class 2 = 0.63 +- 0.307 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all KL = 0.574 +- 0.307 (in-sample avg dev_std = 0.459)
NEC for r=0.6 all L1 = 0.561 +- 0.169 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.901
Model XAI F1 of binarized graphs for r=0.9 =  0.48103875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6609475
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.579
NEC for r=0.9 class 0 = 0.522 +- 0.284 (in-sample avg dev_std = 0.494)
NEC for r=0.9 class 1 = 0.429 +- 0.284 (in-sample avg dev_std = 0.494)
NEC for r=0.9 class 2 = 0.564 +- 0.284 (in-sample avg dev_std = 0.494)
NEC for r=0.9 all KL = 0.486 +- 0.284 (in-sample avg dev_std = 0.494)
NEC for r=0.9 all L1 = 0.504 +- 0.146 (in-sample avg dev_std = 0.494)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.901
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.65948125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.578
NEC for r=1.0 class 0 = 0.511 +- 0.291 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 1 = 0.427 +- 0.291 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 2 = 0.561 +- 0.291 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all KL = 0.481 +- 0.291 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all L1 = 0.499 +- 0.154 (in-sample avg dev_std = 0.490)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.34
Model XAI F1 of binarized graphs for r=0.3 =  0.06783125
Model XAI WIoU of binarized graphs for r=0.3 =  0.04655374999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.404
NEC for r=0.3 class 0 = 0.457 +- 0.215 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1 = 0.39 +- 0.215 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 2 = 0.429 +- 0.215 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.301 +- 0.215 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.425 +- 0.116 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.534
Model XAI F1 of binarized graphs for r=0.6 =  0.38010625000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.24529499999999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.408
NEC for r=0.6 class 0 = 0.58 +- 0.242 (in-sample avg dev_std = 0.533)
NEC for r=0.6 class 1 = 0.624 +- 0.242 (in-sample avg dev_std = 0.533)
NEC for r=0.6 class 2 = 0.602 +- 0.242 (in-sample avg dev_std = 0.533)
NEC for r=0.6 all KL = 0.624 +- 0.242 (in-sample avg dev_std = 0.533)
NEC for r=0.6 all L1 = 0.602 +- 0.149 (in-sample avg dev_std = 0.533)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  0.42134
Model XAI WIoU of binarized graphs for r=0.9 =  0.29393875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.484
NEC for r=0.9 class 0 = 0.592 +- 0.256 (in-sample avg dev_std = 0.563)
NEC for r=0.9 class 1 = 0.557 +- 0.256 (in-sample avg dev_std = 0.563)
NEC for r=0.9 class 2 = 0.433 +- 0.256 (in-sample avg dev_std = 0.563)
NEC for r=0.9 all KL = 0.616 +- 0.256 (in-sample avg dev_std = 0.563)
NEC for r=0.9 all L1 = 0.527 +- 0.170 (in-sample avg dev_std = 0.563)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.595
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.29195375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.517
NEC for r=1.0 class 0 = 0.581 +- 0.255 (in-sample avg dev_std = 0.580)
NEC for r=1.0 class 1 = 0.55 +- 0.255 (in-sample avg dev_std = 0.580)
NEC for r=1.0 class 2 = 0.398 +- 0.255 (in-sample avg dev_std = 0.580)
NEC for r=1.0 all KL = 0.618 +- 0.255 (in-sample avg dev_std = 0.580)
NEC for r=1.0 all L1 = 0.51 +- 0.175 (in-sample avg dev_std = 0.580)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.45, 0.633, 0.87, 1.0], 'all_L1': [0.532, 0.649, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.538, 0.652, 0.867, 1.0], 'all_L1': [0.538, 0.649, 0.804, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.534, 0.586, 0.83, 1.0], 'all_L1': [0.519, 0.594, 0.762, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.6, 0.551, 0.485, 0.485], 'all_L1': [0.552, 0.533, 0.482, 0.483]}), defaultdict(<class 'list'>, {'all_KL': [0.486, 0.555, 0.47, 0.47], 'all_L1': [0.498, 0.539, 0.481, 0.479]}), defaultdict(<class 'list'>, {'all_KL': [0.472, 0.574, 0.486, 0.481], 'all_L1': [0.499, 0.561, 0.504, 0.499]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.554, 0.786, 0.97, 1.0], 'all_L1': [0.619, 0.793, 0.935, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.614, 0.562, 0.772, 1.0], 'all_L1': [0.582, 0.611, 0.739, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.765, 0.401, 0.519, 1.0], 'all_L1': [0.632, 0.433, 0.56, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.664, 0.538, 0.42, 0.414], 'all_L1': [0.608, 0.5, 0.384, 0.378]}), defaultdict(<class 'list'>, {'all_KL': [0.445, 0.555, 0.429, 0.436], 'all_L1': [0.487, 0.513, 0.446, 0.445]}), defaultdict(<class 'list'>, {'all_KL': [0.301, 0.624, 0.616, 0.618], 'all_L1': [0.425, 0.602, 0.527, 0.51]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.530 +- 0.008, 0.631 +- 0.026, 0.793 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.507 +- 0.041, 0.624 +- 0.028, 0.856 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.468 +- 0.039, 0.707 +- 0.024, 0.835 +- 0.012
nec class all_L1  =  0.516 +- 0.025, 0.544 +- 0.012, 0.489 +- 0.011, 0.487 +- 0.009
nec class all_KL  =  0.519 +- 0.057, 0.560 +- 0.010, 0.480 +- 0.007, 0.479 +- 0.006
nec_acc_int  =  0.393 +- 0.036, 0.502 +- 0.007, 0.564 +- 0.011, 0.568 +- 0.007

Eval split test
suff++ class all_L1  =  0.611 +- 0.021, 0.612 +- 0.147, 0.745 +- 0.153, 1.000 +- 0.000
suff++ class all_KL  =  0.644 +- 0.089, 0.583 +- 0.158, 0.754 +- 0.185, 1.000 +- 0.000
suff++_acc_int  =  0.463 +- 0.100, 0.635 +- 0.167, 0.727 +- 0.146
nec class all_L1  =  0.507 +- 0.076, 0.538 +- 0.045, 0.452 +- 0.059, 0.444 +- 0.054
nec class all_KL  =  0.470 +- 0.149, 0.572 +- 0.037, 0.488 +- 0.090, 0.489 +- 0.091
nec_acc_int  =  0.388 +- 0.021, 0.482 +- 0.052, 0.568 +- 0.060, 0.586 +- 0.050


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.523 +- 0.014, 0.587 +- 0.007, 0.641 +- 0.006, 0.743 +- 0.004
Faith. Armon (L1)= 		  =  0.523 +- 0.014, 0.584 +- 0.005, 0.605 +- 0.002, 0.655 +- 0.008
Faith. GMean (L1)= 	  =  0.523 +- 0.014, 0.586 +- 0.006, 0.622 +- 0.002, 0.698 +- 0.006
Faith. Aritm (KL)= 		  =  0.513 +- 0.009, 0.592 +- 0.010, 0.668 +- 0.008, 0.739 +- 0.003
Faith. Armon (KL)= 		  =  0.509 +- 0.006, 0.590 +- 0.008, 0.615 +- 0.006, 0.647 +- 0.006
Faith. GMean (KL)= 	  =  0.511 +- 0.007, 0.591 +- 0.009, 0.641 +- 0.006, 0.692 +- 0.005

Eval split test
Faith. Aritm (L1)= 		  =  0.559 +- 0.039, 0.575 +- 0.054, 0.599 +- 0.048, 0.722 +- 0.027
Faith. Armon (L1)= 		  =  0.551 +- 0.045, 0.558 +- 0.045, 0.548 +- 0.006, 0.613 +- 0.052
Faith. GMean (L1)= 	  =  0.555 +- 0.042, 0.567 +- 0.049, 0.572 +- 0.023, 0.665 +- 0.041
Faith. Aritm (KL)= 		  =  0.557 +- 0.037, 0.578 +- 0.063, 0.621 +- 0.054, 0.745 +- 0.046
Faith. Armon (KL)= 		  =  0.517 +- 0.070, 0.562 +- 0.061, 0.567 +- 0.014, 0.652 +- 0.079
Faith. GMean (KL)= 	  =  0.536 +- 0.053, 0.570 +- 0.062, 0.593 +- 0.032, 0.697 +- 0.064
Computed for split load_split = id



Completed in  0:06:57.767197  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis soft

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:19:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:19:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 195...
[0m[1;37mINFO[0m: [1mCheckpoint 195: 
-----------------------------------
Train ACCURACY: 0.8743
Train Loss: 0.4732
ID Validation ACCURACY: 0.8853
ID Validation Loss: 0.4560
ID Test ACCURACY: 0.8697
ID Test Loss: 0.4917
OOD Validation ACCURACY: 0.8343
OOD Validation Loss: 0.5612
OOD Test ACCURACY: 0.8893
OOD Test Loss: 0.4192

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8004
Train Loss: 0.6273
ID Validation ACCURACY: 0.8100
ID Validation Loss: 0.6255
ID Test ACCURACY: 0.7973
ID Test Loss: 0.6458
OOD Validation ACCURACY: 0.8957
OOD Validation Loss: 0.6177
OOD Test ACCURACY: 0.5720
OOD Test Loss: 3.3166

[0m[1;37mINFO[0m: [1mChartInfo 0.8697 0.8893 0.7973 0.5720 0.8100 0.8957[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.717
WIoU for r=0.3 = 0.686
F1 for r=0.6 = 0.624
WIoU for r=0.6 = 0.797
F1 for r=0.9 = 0.480
WIoU for r=0.9 = 0.798
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.798
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.733
WIoU for r=0.3 = 0.820
F1 for r=0.6 = 0.542
WIoU for r=0.6 = 0.782
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.754


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.71676625
Model XAI WIoU of binarized graphs for r=0.3 =  0.68580375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.486
SUFF++ for r=0.3 class 0 = 0.527 +- 0.276 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 1 = 0.642 +- 0.276 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.276 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all KL = 0.528 +- 0.276 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all L1 = 0.559 +- 0.164 (in-sample avg dev_std = 0.509)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  0.62441
Model XAI WIoU of binarized graphs for r=0.6 =  0.7973362500000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.761
SUFF++ for r=0.6 class 0 = 0.605 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 1 = 0.715 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 2 = 0.69 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all KL = 0.674 +- 0.270 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all L1 = 0.67 +- 0.211 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.48045000000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.79764375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF++ for r=0.9 class 0 = 0.765 +- 0.182 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1 = 0.8 +- 0.182 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.182 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.87 +- 0.182 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.805 +- 0.183 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.738
Model XAI F1 of binarized graphs for r=0.3 =  0.732815
Model XAI WIoU of binarized graphs for r=0.3 =  0.81956375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.63
SUFF++ for r=0.3 class 0 = 0.534 +- 0.311 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 class 1 = 0.714 +- 0.311 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 class 2 = 0.558 +- 0.311 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 all KL = 0.519 +- 0.311 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 all L1 = 0.604 +- 0.210 (in-sample avg dev_std = 0.525)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.54158125
Model XAI WIoU of binarized graphs for r=0.6 =  0.78219375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.741
SUFF++ for r=0.6 class 0 = 0.638 +- 0.301 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.742 +- 0.301 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.671 +- 0.301 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.649 +- 0.301 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.179 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.42356875000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7541249999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0 = 0.775 +- 0.144 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.811 +- 0.144 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.902 +- 0.144 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.883 +- 0.144 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.83 +- 0.133 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.71676625
Model XAI WIoU of binarized graphs for r=0.3 =  0.68580375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.374
NEC for r=0.3 class 0 = 0.556 +- 0.298 (in-sample avg dev_std = 0.426)
NEC for r=0.3 class 1 = 0.499 +- 0.298 (in-sample avg dev_std = 0.426)
NEC for r=0.3 class 2 = 0.593 +- 0.298 (in-sample avg dev_std = 0.426)
NEC for r=0.3 all KL = 0.582 +- 0.298 (in-sample avg dev_std = 0.426)
NEC for r=0.3 all L1 = 0.549 +- 0.172 (in-sample avg dev_std = 0.426)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  0.62441
Model XAI WIoU of binarized graphs for r=0.6 =  0.7973362500000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.525 +- 0.299 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 1 = 0.492 +- 0.299 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 2 = 0.576 +- 0.299 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all KL = 0.564 +- 0.299 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all L1 = 0.531 +- 0.161 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.48045000000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.79764375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0 = 0.472 +- 0.266 (in-sample avg dev_std = 0.513)
NEC for r=0.9 class 1 = 0.432 +- 0.266 (in-sample avg dev_std = 0.513)
NEC for r=0.9 class 2 = 0.485 +- 0.266 (in-sample avg dev_std = 0.513)
NEC for r=0.9 all KL = 0.454 +- 0.266 (in-sample avg dev_std = 0.513)
NEC for r=0.9 all L1 = 0.463 +- 0.151 (in-sample avg dev_std = 0.513)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.875
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.79764375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.618
NEC for r=1.0 class 0 = 0.465 +- 0.264 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 1 = 0.427 +- 0.264 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 2 = 0.471 +- 0.264 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all KL = 0.443 +- 0.264 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all L1 = 0.454 +- 0.147 (in-sample avg dev_std = 0.516)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.729
Model XAI F1 of binarized graphs for r=0.3 =  0.732815
Model XAI WIoU of binarized graphs for r=0.3 =  0.81956375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.449
NEC for r=0.3 class 0 = 0.587 +- 0.259 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 1 = 0.472 +- 0.259 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 2 = 0.598 +- 0.259 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all KL = 0.647 +- 0.259 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all L1 = 0.551 +- 0.147 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.54158125
Model XAI WIoU of binarized graphs for r=0.6 =  0.78219375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.546
NEC for r=0.6 class 0 = 0.484 +- 0.353 (in-sample avg dev_std = 0.565)
NEC for r=0.6 class 1 = 0.466 +- 0.353 (in-sample avg dev_std = 0.565)
NEC for r=0.6 class 2 = 0.567 +- 0.353 (in-sample avg dev_std = 0.565)
NEC for r=0.6 all KL = 0.543 +- 0.353 (in-sample avg dev_std = 0.565)
NEC for r=0.6 all L1 = 0.506 +- 0.215 (in-sample avg dev_std = 0.565)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.42356875000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7541249999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.645
NEC for r=0.9 class 0 = 0.383 +- 0.336 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 1 = 0.406 +- 0.336 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 2 = 0.423 +- 0.336 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all KL = 0.44 +- 0.336 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all L1 = 0.404 +- 0.204 (in-sample avg dev_std = 0.576)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.892
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7536799999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.659
NEC for r=1.0 class 0 = 0.366 +- 0.324 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 1 = 0.399 +- 0.324 (in-sample avg dev_std = 0.565)
NEC for r=1.0 class 2 = 0.398 +- 0.324 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all KL = 0.423 +- 0.324 (in-sample avg dev_std = 0.565)
NEC for r=1.0 all L1 = 0.388 +- 0.197 (in-sample avg dev_std = 0.565)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:21:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:21:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8734
Train Loss: 0.4805
ID Validation ACCURACY: 0.8770
ID Validation Loss: 0.4683
ID Test ACCURACY: 0.8733
ID Test Loss: 0.4995
OOD Validation ACCURACY: 0.8767
OOD Validation Loss: 0.5309
OOD Test ACCURACY: 0.7990
OOD Test Loss: 0.5842

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8549
Train Loss: 0.4957
ID Validation ACCURACY: 0.8533
ID Validation Loss: 0.4909
ID Test ACCURACY: 0.8500
ID Test Loss: 0.5206
OOD Validation ACCURACY: 0.9047
OOD Validation Loss: 0.5059
OOD Test ACCURACY: 0.8737
OOD Test Loss: 0.5147

[0m[1;37mINFO[0m: [1mChartInfo 0.8733 0.7990 0.8500 0.8737 0.8533 0.9047[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.707
WIoU for r=0.3 = 0.664
F1 for r=0.6 = 0.612
WIoU for r=0.6 = 0.730
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.739
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.739
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.754
WIoU for r=0.3 = 0.844
F1 for r=0.6 = 0.561
WIoU for r=0.6 = 0.895
F1 for r=0.9 = 0.423
WIoU for r=0.9 = 0.895
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.895


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  0.70694875
Model XAI WIoU of binarized graphs for r=0.3 =  0.66427375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.5
SUFF++ for r=0.3 class 0 = 0.519 +- 0.284 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 class 1 = 0.642 +- 0.284 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 class 2 = 0.501 +- 0.284 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 all KL = 0.567 +- 0.284 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 all L1 = 0.555 +- 0.146 (in-sample avg dev_std = 0.492)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.6116675
Model XAI WIoU of binarized graphs for r=0.6 =  0.729675
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.747
SUFF++ for r=0.6 class 0 = 0.564 +- 0.244 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 1 = 0.721 +- 0.244 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 2 = 0.726 +- 0.244 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all KL = 0.683 +- 0.244 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all L1 = 0.67 +- 0.181 (in-sample avg dev_std = 0.403)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.48108874999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.738935
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.82
SUFF++ for r=0.9 class 0 = 0.728 +- 0.199 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.808 +- 0.199 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.853 +- 0.199 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.862 +- 0.199 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.796 +- 0.190 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.7540975
Model XAI WIoU of binarized graphs for r=0.3 =  0.84369625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0 = 0.472 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 1 = 0.65 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 2 = 0.508 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all KL = 0.536 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all L1 = 0.545 +- 0.170 (in-sample avg dev_std = 0.541)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  0.56061125
Model XAI WIoU of binarized graphs for r=0.6 =  0.89523375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.749
SUFF++ for r=0.6 class 0 = 0.507 +- 0.234 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1 = 0.682 +- 0.234 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 2 = 0.657 +- 0.234 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.658 +- 0.234 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.617 +- 0.165 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  0.4234675
Model XAI WIoU of binarized graphs for r=0.9 =  0.89523375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.822
SUFF++ for r=0.9 class 0 = 0.806 +- 0.126 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.816 +- 0.126 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.881 +- 0.126 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.914 +- 0.126 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.834 +- 0.165 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  0.70694875
Model XAI WIoU of binarized graphs for r=0.3 =  0.66427375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.413
NEC for r=0.3 class 0 = 0.502 +- 0.294 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 1 = 0.493 +- 0.294 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 2 = 0.573 +- 0.294 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all KL = 0.512 +- 0.294 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all L1 = 0.522 +- 0.165 (in-sample avg dev_std = 0.453)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.6116675
Model XAI WIoU of binarized graphs for r=0.6 =  0.729675
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.507
NEC for r=0.6 class 0 = 0.51 +- 0.309 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 1 = 0.495 +- 0.309 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 2 = 0.582 +- 0.309 (in-sample avg dev_std = 0.464)
NEC for r=0.6 all KL = 0.558 +- 0.309 (in-sample avg dev_std = 0.464)
NEC for r=0.6 all L1 = 0.529 +- 0.161 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.48108874999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.738935
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.611
NEC for r=0.9 class 0 = 0.451 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 1 = 0.436 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 2 = 0.487 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all KL = 0.448 +- 0.273 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all L1 = 0.458 +- 0.148 (in-sample avg dev_std = 0.485)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7389199999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.621
NEC for r=1.0 class 0 = 0.454 +- 0.274 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 1 = 0.433 +- 0.274 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 2 = 0.473 +- 0.274 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all KL = 0.444 +- 0.274 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all L1 = 0.453 +- 0.149 (in-sample avg dev_std = 0.490)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.7540975
Model XAI WIoU of binarized graphs for r=0.3 =  0.84369625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.369
NEC for r=0.3 class 0 = 0.536 +- 0.290 (in-sample avg dev_std = 0.434)
NEC for r=0.3 class 1 = 0.477 +- 0.290 (in-sample avg dev_std = 0.434)
NEC for r=0.3 class 2 = 0.52 +- 0.290 (in-sample avg dev_std = 0.434)
NEC for r=0.3 all KL = 0.514 +- 0.290 (in-sample avg dev_std = 0.434)
NEC for r=0.3 all L1 = 0.511 +- 0.159 (in-sample avg dev_std = 0.434)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  0.56061125
Model XAI WIoU of binarized graphs for r=0.6 =  0.89523375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.585
NEC for r=0.6 class 0 = 0.421 +- 0.307 (in-sample avg dev_std = 0.470)
NEC for r=0.6 class 1 = 0.358 +- 0.307 (in-sample avg dev_std = 0.470)
NEC for r=0.6 class 2 = 0.518 +- 0.307 (in-sample avg dev_std = 0.470)
NEC for r=0.6 all KL = 0.405 +- 0.307 (in-sample avg dev_std = 0.470)
NEC for r=0.6 all L1 = 0.432 +- 0.175 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  0.4234675
Model XAI WIoU of binarized graphs for r=0.9 =  0.89523375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.638
NEC for r=0.9 class 0 = 0.404 +- 0.275 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 1 = 0.343 +- 0.275 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 2 = 0.427 +- 0.275 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all KL = 0.362 +- 0.275 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all L1 = 0.391 +- 0.158 (in-sample avg dev_std = 0.496)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.794
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.89523375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.653
NEC for r=1.0 class 0 = 0.391 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 class 1 = 0.343 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 class 2 = 0.42 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 all KL = 0.357 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 all L1 = 0.384 +- 0.157 (in-sample avg dev_std = 0.496)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:23:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:23:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 152...
[0m[1;37mINFO[0m: [1mCheckpoint 152: 
-----------------------------------
Train ACCURACY: 0.8806
Train Loss: 0.4872
ID Validation ACCURACY: 0.8817
ID Validation Loss: 0.4866
ID Test ACCURACY: 0.8797
ID Test Loss: 0.4972
OOD Validation ACCURACY: 0.9163
OOD Validation Loss: 0.5643
OOD Test ACCURACY: 0.8280
OOD Test Loss: 0.6076

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.8256
Train Loss: 0.5574
ID Validation ACCURACY: 0.8207
ID Validation Loss: 0.5714
ID Test ACCURACY: 0.8177
ID Test Loss: 0.5844
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.5094
OOD Test ACCURACY: 0.6773
OOD Test Loss: 0.9533

[0m[1;37mINFO[0m: [1mChartInfo 0.8797 0.8280 0.8177 0.6773 0.8207 0.9293[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.651
WIoU for r=0.3 = 0.579
F1 for r=0.6 = 0.607
WIoU for r=0.6 = 0.688
F1 for r=0.9 = 0.478
WIoU for r=0.9 = 0.684
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.684
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.642
WIoU for r=0.3 = 0.732
F1 for r=0.6 = 0.527
WIoU for r=0.6 = 0.726
F1 for r=0.9 = 0.415
WIoU for r=0.9 = 0.728
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.728


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.65133125
Model XAI WIoU of binarized graphs for r=0.3 =  0.578825
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.418
SUFF++ for r=0.3 class 0 = 0.408 +- 0.289 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 1 = 0.508 +- 0.289 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 2 = 0.476 +- 0.289 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all KL = 0.463 +- 0.289 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all L1 = 0.464 +- 0.147 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.60674875
Model XAI WIoU of binarized graphs for r=0.6 =  0.68809
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.7
SUFF++ for r=0.6 class 0 = 0.617 +- 0.243 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 1 = 0.628 +- 0.243 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 2 = 0.609 +- 0.243 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all KL = 0.641 +- 0.243 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all L1 = 0.618 +- 0.156 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.4781975
Model XAI WIoU of binarized graphs for r=0.9 =  0.6839300000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.793
SUFF++ for r=0.9 class 0 = 0.699 +- 0.225 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.9 class 1 = 0.737 +- 0.225 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.9 class 2 = 0.661 +- 0.225 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.9 all KL = 0.744 +- 0.225 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.9 all L1 = 0.699 +- 0.157 (in-sample avg dev_std = 0.401)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.479
Model XAI F1 of binarized graphs for r=0.3 =  0.6424587500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7322574999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.514
SUFF++ for r=0.3 class 0 = 0.536 +- 0.248 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 1 = 0.598 +- 0.248 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 2 = 0.55 +- 0.248 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all KL = 0.603 +- 0.248 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all L1 = 0.562 +- 0.155 (in-sample avg dev_std = 0.533)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  0.52716125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7256900000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.652
SUFF++ for r=0.6 class 0 = 0.588 +- 0.288 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.288 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 2 = 0.594 +- 0.288 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all KL = 0.651 +- 0.288 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all L1 = 0.615 +- 0.175 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  0.4148625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.7283875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.796
SUFF++ for r=0.9 class 0 = 0.768 +- 0.129 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 1 = 0.747 +- 0.129 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 2 = 0.739 +- 0.129 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all KL = 0.847 +- 0.129 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all L1 = 0.751 +- 0.156 (in-sample avg dev_std = 0.249)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.65133125
Model XAI WIoU of binarized graphs for r=0.3 =  0.578825
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.409
NEC for r=0.3 class 0 = 0.639 +- 0.305 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1 = 0.555 +- 0.305 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 2 = 0.5 +- 0.305 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.557 +- 0.305 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.565 +- 0.180 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.60674875
Model XAI WIoU of binarized graphs for r=0.6 =  0.68809
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.469
NEC for r=0.6 class 0 = 0.609 +- 0.304 (in-sample avg dev_std = 0.437)
NEC for r=0.6 class 1 = 0.504 +- 0.304 (in-sample avg dev_std = 0.437)
NEC for r=0.6 class 2 = 0.5 +- 0.304 (in-sample avg dev_std = 0.437)
NEC for r=0.6 all KL = 0.527 +- 0.304 (in-sample avg dev_std = 0.437)
NEC for r=0.6 all L1 = 0.538 +- 0.158 (in-sample avg dev_std = 0.437)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.4781975
Model XAI WIoU of binarized graphs for r=0.9 =  0.6839300000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.523
NEC for r=0.9 class 0 = 0.54 +- 0.286 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 1 = 0.484 +- 0.286 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 2 = 0.482 +- 0.286 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all KL = 0.473 +- 0.286 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all L1 = 0.502 +- 0.153 (in-sample avg dev_std = 0.456)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.6839300000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.54 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=1.0 class 1 = 0.472 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=1.0 class 2 = 0.479 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=1.0 all KL = 0.466 +- 0.278 (in-sample avg dev_std = 0.467)
NEC for r=1.0 all L1 = 0.497 +- 0.147 (in-sample avg dev_std = 0.467)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.481
Model XAI F1 of binarized graphs for r=0.3 =  0.6424587500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7322574999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.383
NEC for r=0.3 class 0 = 0.582 +- 0.287 (in-sample avg dev_std = 0.456)
NEC for r=0.3 class 1 = 0.565 +- 0.287 (in-sample avg dev_std = 0.456)
NEC for r=0.3 class 2 = 0.501 +- 0.287 (in-sample avg dev_std = 0.456)
NEC for r=0.3 all KL = 0.506 +- 0.287 (in-sample avg dev_std = 0.456)
NEC for r=0.3 all L1 = 0.549 +- 0.154 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  0.52716125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7256900000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.486
NEC for r=0.6 class 0 = 0.557 +- 0.307 (in-sample avg dev_std = 0.476)
NEC for r=0.6 class 1 = 0.436 +- 0.307 (in-sample avg dev_std = 0.476)
NEC for r=0.6 class 2 = 0.455 +- 0.307 (in-sample avg dev_std = 0.476)
NEC for r=0.6 all KL = 0.455 +- 0.307 (in-sample avg dev_std = 0.476)
NEC for r=0.6 all L1 = 0.482 +- 0.180 (in-sample avg dev_std = 0.476)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  0.4148625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.7283875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.463 +- 0.321 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 1 = 0.399 +- 0.321 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 2 = 0.38 +- 0.321 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all KL = 0.386 +- 0.321 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all L1 = 0.414 +- 0.183 (in-sample avg dev_std = 0.482)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.826
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7283875000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.559
NEC for r=1.0 class 0 = 0.461 +- 0.315 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 1 = 0.401 +- 0.315 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 2 = 0.382 +- 0.315 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all KL = 0.387 +- 0.315 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all L1 = 0.414 +- 0.177 (in-sample avg dev_std = 0.490)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.528, 0.674, 0.87, 1.0], 'all_L1': [0.559, 0.67, 0.805, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.567, 0.683, 0.862, 1.0], 'all_L1': [0.555, 0.67, 0.796, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.463, 0.641, 0.744, 1.0], 'all_L1': [0.464, 0.618, 0.699, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.582, 0.564, 0.454, 0.443], 'all_L1': [0.549, 0.531, 0.463, 0.454]}), defaultdict(<class 'list'>, {'all_KL': [0.512, 0.558, 0.448, 0.444], 'all_L1': [0.522, 0.529, 0.458, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.557, 0.527, 0.473, 0.466], 'all_L1': [0.565, 0.538, 0.502, 0.497]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.519, 0.649, 0.883, 1.0], 'all_L1': [0.604, 0.685, 0.83, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.536, 0.658, 0.914, 1.0], 'all_L1': [0.545, 0.617, 0.834, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.603, 0.651, 0.847, 1.0], 'all_L1': [0.562, 0.615, 0.751, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.647, 0.543, 0.44, 0.423], 'all_L1': [0.551, 0.506, 0.404, 0.388]}), defaultdict(<class 'list'>, {'all_KL': [0.514, 0.405, 0.362, 0.357], 'all_L1': [0.511, 0.432, 0.391, 0.384]}), defaultdict(<class 'list'>, {'all_KL': [0.506, 0.455, 0.386, 0.387], 'all_L1': [0.549, 0.482, 0.414, 0.414]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.526 +- 0.044, 0.653 +- 0.025, 0.767 +- 0.048, 1.000 +- 0.000
suff++ class all_KL  =  0.519 +- 0.043, 0.666 +- 0.018, 0.825 +- 0.058, 1.000 +- 0.000
suff++_acc_int  =  0.468 +- 0.036, 0.736 +- 0.026, 0.823 +- 0.026
nec class all_L1  =  0.545 +- 0.018, 0.533 +- 0.004, 0.474 +- 0.020, 0.468 +- 0.021
nec class all_KL  =  0.550 +- 0.029, 0.550 +- 0.016, 0.458 +- 0.011, 0.451 +- 0.011
nec_acc_int  =  0.399 +- 0.017, 0.493 +- 0.017, 0.580 +- 0.040, 0.591 +- 0.040

Eval split test
suff++ class all_L1  =  0.570 +- 0.025, 0.639 +- 0.033, 0.805 +- 0.038, 1.000 +- 0.000
suff++ class all_KL  =  0.553 +- 0.036, 0.653 +- 0.004, 0.881 +- 0.027, 1.000 +- 0.000
suff++_acc_int  =  0.577 +- 0.048, 0.714 +- 0.044, 0.828 +- 0.029
nec class all_L1  =  0.537 +- 0.018, 0.473 +- 0.031, 0.403 +- 0.009, 0.395 +- 0.013
nec class all_KL  =  0.556 +- 0.065, 0.468 +- 0.057, 0.396 +- 0.033, 0.389 +- 0.027
nec_acc_int  =  0.400 +- 0.035, 0.539 +- 0.041, 0.608 +- 0.048, 0.623 +- 0.046


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.536 +- 0.016, 0.593 +- 0.010, 0.620 +- 0.014, 0.734 +- 0.010
Faith. Armon (L1)= 		  =  0.534 +- 0.018, 0.586 +- 0.008, 0.585 +- 0.003, 0.637 +- 0.019
Faith. GMean (L1)= 	  =  0.535 +- 0.017, 0.589 +- 0.009, 0.602 +- 0.007, 0.684 +- 0.015
Faith. Aritm (KL)= 		  =  0.535 +- 0.019, 0.608 +- 0.017, 0.642 +- 0.024, 0.726 +- 0.005
Faith. Armon (KL)= 		  =  0.532 +- 0.020, 0.602 +- 0.017, 0.588 +- 0.008, 0.622 +- 0.010
Faith. GMean (KL)= 	  =  0.534 +- 0.019, 0.605 +- 0.017, 0.614 +- 0.015, 0.672 +- 0.008

Eval split test
Faith. Aritm (L1)= 		  =  0.554 +- 0.020, 0.556 +- 0.029, 0.604 +- 0.015, 0.698 +- 0.007
Faith. Armon (L1)= 		  =  0.553 +- 0.020, 0.544 +- 0.030, 0.537 +- 0.005, 0.567 +- 0.014
Faith. GMean (L1)= 	  =  0.553 +- 0.020, 0.550 +- 0.030, 0.569 +- 0.009, 0.629 +- 0.011
Faith. Aritm (KL)= 		  =  0.554 +- 0.024, 0.560 +- 0.027, 0.639 +- 0.018, 0.694 +- 0.013
Faith. Armon (KL)= 		  =  0.550 +- 0.021, 0.543 +- 0.037, 0.545 +- 0.030, 0.560 +- 0.028
Faith. GMean (KL)= 	  =  0.552 +- 0.022, 0.551 +- 0.032, 0.590 +- 0.024, 0.623 +- 0.022
Computed for split load_split = id



Completed in  0:07:04.823724  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis soft2

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:26:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:38 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:40 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:41 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:43 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:26:44 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.7672
Train Loss: 0.5551
ID Validation ACCURACY: 0.6643
ID Validation Loss: 0.9002
ID Test ACCURACY: 0.6661
ID Test Loss: 0.8892
OOD Validation ACCURACY: 0.5591
OOD Validation Loss: 1.2675
OOD Test ACCURACY: 0.5024
OOD Test Loss: 1.7031

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 10...
[0m[1;37mINFO[0m: [1mCheckpoint 10: 
-----------------------------------
Train ACCURACY: 0.7517
Train Loss: 0.5953
ID Validation ACCURACY: 0.6498
ID Validation Loss: 0.8769
ID Test ACCURACY: 0.6823
ID Test Loss: 0.8682
OOD Validation ACCURACY: 0.5933
OOD Validation Loss: 1.0848
OOD Test ACCURACY: 0.5628
OOD Test Loss: 1.2855

[0m[1;37mINFO[0m: [1mChartInfo 0.6661 0.5024 0.6823 0.5628 0.6498 0.5933[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.575
SUFF++ for r=0.3 class 0 = 0.712 +- 0.091 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 class 1 = 0.749 +- 0.091 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 class 2 = 0.743 +- 0.091 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all KL = 0.884 +- 0.091 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all L1 = 0.738 +- 0.099 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.62
SUFF++ for r=0.6 class 0 = 0.781 +- 0.091 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 class 1 = 0.771 +- 0.091 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 class 2 = 0.782 +- 0.091 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 all KL = 0.896 +- 0.091 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 all L1 = 0.776 +- 0.110 (in-sample avg dev_std = 0.256)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.642
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.639
SUFF++ for r=0.9 class 0 = 0.894 +- 0.040 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1 = 0.88 +- 0.040 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 2 = 0.905 +- 0.040 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.973 +- 0.040 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.89 +- 0.087 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.522
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.517
SUFF++ for r=0.3 class 0 = 0.766 +- 0.071 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 1 = 0.756 +- 0.071 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 2 = 0.753 +- 0.071 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all KL = 0.907 +- 0.071 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all L1 = 0.757 +- 0.089 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.507
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.495
SUFF++ for r=0.6 class 0 = 0.841 +- 0.063 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.6 class 1 = 0.797 +- 0.063 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.6 class 2 = 0.803 +- 0.063 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.6 all KL = 0.931 +- 0.063 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.6 all L1 = 0.81 +- 0.109 (in-sample avg dev_std = 0.189)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.493
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.492
SUFF++ for r=0.9 class 0 = 0.907 +- 0.033 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1 = 0.851 +- 0.033 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.033 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.967 +- 0.033 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.871 +- 0.094 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.614
NEC for r=0.3 class 0 = 0.225 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 1 = 0.19 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 2 = 0.21 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all KL = 0.064 +- 0.079 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all L1 = 0.204 +- 0.112 (in-sample avg dev_std = 0.161)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.626
NEC for r=0.6 class 0 = 0.182 +- 0.075 (in-sample avg dev_std = 0.157)
NEC for r=0.6 class 1 = 0.17 +- 0.075 (in-sample avg dev_std = 0.157)
NEC for r=0.6 class 2 = 0.16 +- 0.075 (in-sample avg dev_std = 0.157)
NEC for r=0.6 all KL = 0.056 +- 0.075 (in-sample avg dev_std = 0.157)
NEC for r=0.6 all L1 = 0.17 +- 0.111 (in-sample avg dev_std = 0.157)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.642
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.641
NEC for r=0.9 class 0 = 0.124 +- 0.047 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1 = 0.121 +- 0.047 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 2 = 0.109 +- 0.047 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.029 +- 0.047 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.118 +- 0.090 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.661
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.649
NEC for r=1.0 class 0 = 0.106 +- 0.041 (in-sample avg dev_std = 0.098)
NEC for r=1.0 class 1 = 0.105 +- 0.041 (in-sample avg dev_std = 0.098)
NEC for r=1.0 class 2 = 0.097 +- 0.041 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all KL = 0.023 +- 0.041 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all L1 = 0.103 +- 0.082 (in-sample avg dev_std = 0.098)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.522
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.538
NEC for r=0.3 class 0 = 0.205 +- 0.069 (in-sample avg dev_std = 0.155)
NEC for r=0.3 class 1 = 0.213 +- 0.069 (in-sample avg dev_std = 0.155)
NEC for r=0.3 class 2 = 0.204 +- 0.069 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all KL = 0.065 +- 0.069 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all L1 = 0.209 +- 0.105 (in-sample avg dev_std = 0.155)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.507
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.513
NEC for r=0.6 class 0 = 0.132 +- 0.057 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 1 = 0.165 +- 0.057 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 2 = 0.157 +- 0.057 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all KL = 0.045 +- 0.057 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all L1 = 0.155 +- 0.107 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.493
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.5
NEC for r=0.9 class 0 = 0.085 +- 0.035 (in-sample avg dev_std = 0.096)
NEC for r=0.9 class 1 = 0.127 +- 0.035 (in-sample avg dev_std = 0.096)
NEC for r=0.9 class 2 = 0.113 +- 0.035 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all KL = 0.026 +- 0.035 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all L1 = 0.113 +- 0.091 (in-sample avg dev_std = 0.096)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.501
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.506
NEC for r=1.0 class 0 = 0.078 +- 0.035 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1 = 0.116 +- 0.035 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 2 = 0.101 +- 0.035 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.024 +- 0.035 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.103 +- 0.087 (in-sample avg dev_std = 0.092)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:29:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:29:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ACCURACY: 0.9633
Train Loss: 0.1184
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.0649
ID Test ACCURACY: 0.6643
ID Test Loss: 1.2212
OOD Validation ACCURACY: 0.6336
OOD Validation Loss: 1.4475
OOD Test ACCURACY: 0.5704
OOD Test Loss: 2.0339

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ACCURACY: 0.8467
Train Loss: 0.3895
ID Validation ACCURACY: 0.6913
ID Validation Loss: 0.7960
ID Test ACCURACY: 0.6859
ID Test Loss: 0.8403
OOD Validation ACCURACY: 0.6392
OOD Validation Loss: 0.9527
OOD Test ACCURACY: 0.5992
OOD Test Loss: 1.0972

[0m[1;37mINFO[0m: [1mChartInfo 0.6643 0.5704 0.6859 0.5992 0.6913 0.6392[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.609
SUFF++ for r=0.3 class 0 = 0.676 +- 0.200 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 class 1 = 0.781 +- 0.200 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 class 2 = 0.673 +- 0.200 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all KL = 0.774 +- 0.200 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all L1 = 0.725 +- 0.180 (in-sample avg dev_std = 0.386)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.662
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.736 +- 0.193 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 1 = 0.826 +- 0.193 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 2 = 0.732 +- 0.193 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all KL = 0.818 +- 0.193 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all L1 = 0.778 +- 0.175 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.879 +- 0.089 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 1 = 0.896 +- 0.089 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 2 = 0.869 +- 0.089 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all KL = 0.944 +- 0.089 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.128 (in-sample avg dev_std = 0.170)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
SUFF++ for r=0.3 class 0 = 0.742 +- 0.160 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 1 = 0.822 +- 0.160 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 2 = 0.732 +- 0.160 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all KL = 0.864 +- 0.160 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all L1 = 0.779 +- 0.171 (in-sample avg dev_std = 0.266)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.575
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.56
SUFF++ for r=0.6 class 0 = 0.775 +- 0.144 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 class 1 = 0.85 +- 0.144 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 class 2 = 0.767 +- 0.144 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 all KL = 0.882 +- 0.144 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 all L1 = 0.81 +- 0.164 (in-sample avg dev_std = 0.254)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.579
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.572
SUFF++ for r=0.9 class 0 = 0.87 +- 0.088 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1 = 0.891 +- 0.088 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 2 = 0.857 +- 0.088 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.944 +- 0.088 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.133 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.628
NEC for r=0.3 class 0 = 0.264 +- 0.185 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 1 = 0.171 +- 0.185 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 2 = 0.238 +- 0.185 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all KL = 0.136 +- 0.185 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all L1 = 0.212 +- 0.193 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.662
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.658
NEC for r=0.6 class 0 = 0.21 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 1 = 0.149 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 2 = 0.185 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all KL = 0.107 +- 0.149 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all L1 = 0.174 +- 0.169 (in-sample avg dev_std = 0.235)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.672
NEC for r=0.9 class 0 = 0.145 +- 0.101 (in-sample avg dev_std = 0.165)
NEC for r=0.9 class 1 = 0.101 +- 0.101 (in-sample avg dev_std = 0.165)
NEC for r=0.9 class 2 = 0.136 +- 0.101 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all KL = 0.059 +- 0.101 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all L1 = 0.122 +- 0.134 (in-sample avg dev_std = 0.165)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.703
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.685
NEC for r=1.0 class 0 = 0.12 +- 0.109 (in-sample avg dev_std = 0.149)
NEC for r=1.0 class 1 = 0.093 +- 0.109 (in-sample avg dev_std = 0.149)
NEC for r=1.0 class 2 = 0.121 +- 0.109 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all KL = 0.053 +- 0.109 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all L1 = 0.107 +- 0.131 (in-sample avg dev_std = 0.149)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0 = 0.265 +- 0.161 (in-sample avg dev_std = 0.229)
NEC for r=0.3 class 1 = 0.166 +- 0.161 (in-sample avg dev_std = 0.229)
NEC for r=0.3 class 2 = 0.241 +- 0.161 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all KL = 0.121 +- 0.161 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all L1 = 0.21 +- 0.177 (in-sample avg dev_std = 0.229)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.575
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.568
NEC for r=0.6 class 0 = 0.191 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.6 class 1 = 0.131 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.6 class 2 = 0.188 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all KL = 0.082 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all L1 = 0.161 +- 0.162 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.579
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.576
NEC for r=0.9 class 0 = 0.148 +- 0.117 (in-sample avg dev_std = 0.153)
NEC for r=0.9 class 1 = 0.112 +- 0.117 (in-sample avg dev_std = 0.153)
NEC for r=0.9 class 2 = 0.138 +- 0.117 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all KL = 0.063 +- 0.117 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all L1 = 0.128 +- 0.152 (in-sample avg dev_std = 0.153)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.564
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.574
NEC for r=1.0 class 0 = 0.133 +- 0.125 (in-sample avg dev_std = 0.160)
NEC for r=1.0 class 1 = 0.109 +- 0.125 (in-sample avg dev_std = 0.160)
NEC for r=1.0 class 2 = 0.135 +- 0.125 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all KL = 0.064 +- 0.125 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all L1 = 0.121 +- 0.151 (in-sample avg dev_std = 0.160)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:32:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:37 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:32:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ACCURACY: 0.7618
Train Loss: 0.5846
ID Validation ACCURACY: 0.6841
ID Validation Loss: 0.7982
ID Test ACCURACY: 0.6588
ID Test Loss: 0.8352
OOD Validation ACCURACY: 0.6106
OOD Validation Loss: 0.9726
OOD Test ACCURACY: 0.5635
OOD Test Loss: 1.2248

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ACCURACY: 0.7351
Train Loss: 0.6277
ID Validation ACCURACY: 0.6751
ID Validation Loss: 0.7789
ID Test ACCURACY: 0.6552
ID Test Loss: 0.7893
OOD Validation ACCURACY: 0.6347
OOD Validation Loss: 0.8596
OOD Test ACCURACY: 0.5992
OOD Test Loss: 0.9286

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5635 0.6552 0.5992 0.6751 0.6347[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.597
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0 = 0.774 +- 0.067 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 class 1 = 0.841 +- 0.067 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 class 2 = 0.816 +- 0.067 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 all KL = 0.944 +- 0.067 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 all L1 = 0.818 +- 0.090 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.63
SUFF++ for r=0.6 class 0 = 0.784 +- 0.064 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 1 = 0.848 +- 0.064 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 2 = 0.82 +- 0.064 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all KL = 0.944 +- 0.064 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.092 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.666
SUFF++ for r=0.9 class 0 = 0.872 +- 0.032 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 class 1 = 0.898 +- 0.032 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 class 2 = 0.9 +- 0.032 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 all KL = 0.978 +- 0.032 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 all L1 = 0.892 +- 0.071 (in-sample avg dev_std = 0.114)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.563
SUFF++ for r=0.3 class 0 = 0.822 +- 0.047 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 1 = 0.867 +- 0.047 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 2 = 0.835 +- 0.047 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 all KL = 0.964 +- 0.047 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 all L1 = 0.847 +- 0.088 (in-sample avg dev_std = 0.131)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.578
SUFF++ for r=0.6 class 0 = 0.818 +- 0.050 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 1 = 0.841 +- 0.050 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 2 = 0.817 +- 0.050 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all KL = 0.952 +- 0.050 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.088 (in-sample avg dev_std = 0.155)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.571
SUFF++ for r=0.9 class 0 = 0.882 +- 0.030 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 1 = 0.875 +- 0.030 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 2 = 0.879 +- 0.030 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all KL = 0.975 +- 0.030 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.077 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.597
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.58
NEC for r=0.3 class 0 = 0.183 +- 0.068 (in-sample avg dev_std = 0.118)
NEC for r=0.3 class 1 = 0.119 +- 0.068 (in-sample avg dev_std = 0.118)
NEC for r=0.3 class 2 = 0.166 +- 0.068 (in-sample avg dev_std = 0.118)
NEC for r=0.3 all KL = 0.037 +- 0.068 (in-sample avg dev_std = 0.118)
NEC for r=0.3 all L1 = 0.148 +- 0.104 (in-sample avg dev_std = 0.118)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.645
NEC for r=0.6 class 0 = 0.174 +- 0.048 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1 = 0.11 +- 0.048 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 2 = 0.143 +- 0.048 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.032 +- 0.048 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.135 +- 0.090 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.66
NEC for r=0.9 class 0 = 0.133 +- 0.032 (in-sample avg dev_std = 0.087)
NEC for r=0.9 class 1 = 0.089 +- 0.032 (in-sample avg dev_std = 0.087)
NEC for r=0.9 class 2 = 0.103 +- 0.032 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all KL = 0.019 +- 0.032 (in-sample avg dev_std = 0.087)
NEC for r=0.9 all L1 = 0.104 +- 0.077 (in-sample avg dev_std = 0.087)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.681
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0 = 0.126 +- 0.038 (in-sample avg dev_std = 0.089)
NEC for r=1.0 class 1 = 0.086 +- 0.038 (in-sample avg dev_std = 0.089)
NEC for r=1.0 class 2 = 0.097 +- 0.038 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all KL = 0.019 +- 0.038 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all L1 = 0.099 +- 0.078 (in-sample avg dev_std = 0.089)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.573
NEC for r=0.3 class 0 = 0.168 +- 0.046 (in-sample avg dev_std = 0.108)
NEC for r=0.3 class 1 = 0.132 +- 0.046 (in-sample avg dev_std = 0.108)
NEC for r=0.3 class 2 = 0.16 +- 0.046 (in-sample avg dev_std = 0.108)
NEC for r=0.3 all KL = 0.032 +- 0.046 (in-sample avg dev_std = 0.108)
NEC for r=0.3 all L1 = 0.148 +- 0.092 (in-sample avg dev_std = 0.108)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.593
NEC for r=0.6 class 0 = 0.154 +- 0.046 (in-sample avg dev_std = 0.113)
NEC for r=0.6 class 1 = 0.141 +- 0.046 (in-sample avg dev_std = 0.113)
NEC for r=0.6 class 2 = 0.152 +- 0.046 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all KL = 0.034 +- 0.046 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all L1 = 0.147 +- 0.093 (in-sample avg dev_std = 0.113)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.585
NEC for r=0.9 class 0 = 0.118 +- 0.033 (in-sample avg dev_std = 0.089)
NEC for r=0.9 class 1 = 0.123 +- 0.033 (in-sample avg dev_std = 0.089)
NEC for r=0.9 class 2 = 0.118 +- 0.033 (in-sample avg dev_std = 0.089)
NEC for r=0.9 all KL = 0.025 +- 0.033 (in-sample avg dev_std = 0.089)
NEC for r=0.9 all L1 = 0.12 +- 0.081 (in-sample avg dev_std = 0.089)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.569
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.58
NEC for r=1.0 class 0 = 0.111 +- 0.036 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1 = 0.115 +- 0.036 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 2 = 0.107 +- 0.036 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.024 +- 0.036 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.112 +- 0.083 (in-sample avg dev_std = 0.090)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.884, 0.896, 0.973, 1.0], 'all_L1': [0.738, 0.776, 0.89, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.774, 0.818, 0.944, 1.0], 'all_L1': [0.725, 0.778, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.944, 0.944, 0.978, 1.0], 'all_L1': [0.818, 0.824, 0.892, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.064, 0.056, 0.029, 0.023], 'all_L1': [0.204, 0.17, 0.118, 0.103]}), defaultdict(<class 'list'>, {'all_KL': [0.136, 0.107, 0.059, 0.053], 'all_L1': [0.212, 0.174, 0.122, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.032, 0.019, 0.019], 'all_L1': [0.148, 0.135, 0.104, 0.099]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.907, 0.931, 0.967, 1.0], 'all_L1': [0.757, 0.81, 0.871, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.864, 0.882, 0.944, 1.0], 'all_L1': [0.779, 0.81, 0.877, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.964, 0.952, 0.975, 1.0], 'all_L1': [0.847, 0.829, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.065, 0.045, 0.026, 0.024], 'all_L1': [0.209, 0.155, 0.113, 0.103]}), defaultdict(<class 'list'>, {'all_KL': [0.121, 0.082, 0.063, 0.064], 'all_L1': [0.21, 0.161, 0.128, 0.121]}), defaultdict(<class 'list'>, {'all_KL': [0.032, 0.034, 0.025, 0.024], 'all_L1': [0.148, 0.147, 0.12, 0.112]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.760 +- 0.041, 0.793 +- 0.022, 0.889 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.867 +- 0.070, 0.886 +- 0.052, 0.965 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.583 +- 0.019, 0.630 +- 0.008, 0.660 +- 0.015
nec class all_L1  =  0.188 +- 0.028, 0.160 +- 0.018, 0.115 +- 0.008, 0.103 +- 0.003
nec class all_KL  =  0.079 +- 0.042, 0.065 +- 0.031, 0.036 +- 0.017, 0.032 +- 0.015
nec_acc_int  =  0.607 +- 0.020, 0.643 +- 0.013, 0.658 +- 0.013, 0.670 +- 0.015

Eval split test
suff++ class all_L1  =  0.794 +- 0.038, 0.816 +- 0.009, 0.875 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.912 +- 0.041, 0.922 +- 0.029, 0.962 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.540 +- 0.019, 0.545 +- 0.036, 0.545 +- 0.037
nec class all_L1  =  0.189 +- 0.029, 0.154 +- 0.006, 0.120 +- 0.006, 0.112 +- 0.007
nec class all_KL  =  0.073 +- 0.037, 0.054 +- 0.021, 0.038 +- 0.018, 0.037 +- 0.019
nec_acc_int  =  0.550 +- 0.016, 0.558 +- 0.033, 0.554 +- 0.038, 0.553 +- 0.033


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.474 +- 0.006, 0.476 +- 0.003, 0.502 +- 0.003, 0.552 +- 0.002
Faith. Armon (L1)= 		  =  0.299 +- 0.035, 0.265 +- 0.024, 0.203 +- 0.012, 0.187 +- 0.005
Faith. GMean (L1)= 	  =  0.376 +- 0.020, 0.355 +- 0.015, 0.319 +- 0.010, 0.321 +- 0.005
Faith. Aritm (KL)= 		  =  0.473 +- 0.015, 0.476 +- 0.010, 0.500 +- 0.001, 0.516 +- 0.008
Faith. Armon (KL)= 		  =  0.141 +- 0.067, 0.119 +- 0.053, 0.068 +- 0.031, 0.061 +- 0.028
Faith. GMean (KL)= 	  =  0.250 +- 0.057, 0.231 +- 0.050, 0.180 +- 0.042, 0.173 +- 0.041

Eval split test
Faith. Aritm (L1)= 		  =  0.492 +- 0.006, 0.485 +- 0.002, 0.498 +- 0.004, 0.556 +- 0.004
Faith. Armon (L1)= 		  =  0.303 +- 0.036, 0.260 +- 0.008, 0.212 +- 0.010, 0.201 +- 0.012
Faith. GMean (L1)= 	  =  0.385 +- 0.022, 0.355 +- 0.005, 0.324 +- 0.009, 0.334 +- 0.011
Faith. Aritm (KL)= 		  =  0.492 +- 0.005, 0.488 +- 0.004, 0.500 +- 0.003, 0.519 +- 0.009
Faith. Armon (KL)= 		  =  0.132 +- 0.062, 0.101 +- 0.036, 0.073 +- 0.032, 0.071 +- 0.035
Faith. GMean (KL)= 	  =  0.247 +- 0.060, 0.218 +- 0.038, 0.186 +- 0.041, 0.188 +- 0.046
Computed for split load_split = id



Completed in  0:08:57.464752  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length soft

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:36:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:36:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 25...
[0m[1;37mINFO[0m: [1mCheckpoint 25: 
-----------------------------------
Train ACCURACY: 0.9251
Train Loss: 0.1978
ID Validation ACCURACY: 0.7076
ID Validation Loss: 1.0759
ID Test ACCURACY: 0.6588
ID Test Loss: 1.1808
OOD Validation ACCURACY: 0.6286
OOD Validation Loss: 1.5172
OOD Test ACCURACY: 0.5305
OOD Test Loss: 2.3347

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.7749
Train Loss: 0.5249
ID Validation ACCURACY: 0.6625
ID Validation Loss: 0.8097
ID Test ACCURACY: 0.6679
ID Test Loss: 0.8311
OOD Validation ACCURACY: 0.6527
OOD Validation Loss: 0.9349
OOD Test ACCURACY: 0.5868
OOD Test Loss: 1.1151

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5305 0.6679 0.5868 0.6625 0.6527[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0 = 0.689 +- 0.181 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 class 1 = 0.771 +- 0.181 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 class 2 = 0.665 +- 0.181 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 all KL = 0.785 +- 0.181 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 all L1 = 0.722 +- 0.167 (in-sample avg dev_std = 0.375)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.651
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.794 +- 0.162 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 class 1 = 0.826 +- 0.162 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 class 2 = 0.712 +- 0.162 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 all KL = 0.845 +- 0.162 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.166 (in-sample avg dev_std = 0.312)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.678
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.668
SUFF++ for r=0.9 class 0 = 0.875 +- 0.095 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 class 1 = 0.907 +- 0.095 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.095 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 all KL = 0.947 +- 0.095 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 all L1 = 0.887 +- 0.130 (in-sample avg dev_std = 0.175)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.528
SUFF++ for r=0.3 class 0 = 0.724 +- 0.138 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 class 1 = 0.794 +- 0.138 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 class 2 = 0.745 +- 0.138 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all KL = 0.86 +- 0.138 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all L1 = 0.764 +- 0.154 (in-sample avg dev_std = 0.282)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.55
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.536
SUFF++ for r=0.6 class 0 = 0.82 +- 0.134 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 class 1 = 0.835 +- 0.134 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 class 2 = 0.771 +- 0.134 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all KL = 0.885 +- 0.134 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all L1 = 0.815 +- 0.161 (in-sample avg dev_std = 0.252)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.529
SUFF++ for r=0.9 class 0 = 0.92 +- 0.069 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.9 class 1 = 0.903 +- 0.069 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.069 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.9 all KL = 0.959 +- 0.069 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.9 all L1 = 0.897 +- 0.124 (in-sample avg dev_std = 0.140)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.619
NEC for r=0.3 class 0 = 0.23 +- 0.169 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1 = 0.172 +- 0.169 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 2 = 0.272 +- 0.169 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.122 +- 0.169 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.214 +- 0.177 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.651
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0 = 0.175 +- 0.148 (in-sample avg dev_std = 0.208)
NEC for r=0.6 class 1 = 0.135 +- 0.148 (in-sample avg dev_std = 0.208)
NEC for r=0.6 class 2 = 0.217 +- 0.148 (in-sample avg dev_std = 0.208)
NEC for r=0.6 all KL = 0.095 +- 0.148 (in-sample avg dev_std = 0.208)
NEC for r=0.6 all L1 = 0.167 +- 0.167 (in-sample avg dev_std = 0.208)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.677
NEC for r=0.9 class 0 = 0.127 +- 0.094 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1 = 0.099 +- 0.094 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 2 = 0.143 +- 0.094 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.051 +- 0.094 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.118 +- 0.137 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.686
NEC for r=1.0 class 0 = 0.115 +- 0.087 (in-sample avg dev_std = 0.137)
NEC for r=1.0 class 1 = 0.085 +- 0.087 (in-sample avg dev_std = 0.137)
NEC for r=1.0 class 2 = 0.127 +- 0.087 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all KL = 0.043 +- 0.087 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all L1 = 0.104 +- 0.128 (in-sample avg dev_std = 0.137)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0 = 0.235 +- 0.131 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1 = 0.179 +- 0.131 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 2 = 0.22 +- 0.131 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.101 +- 0.131 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.204 +- 0.161 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.55
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.549
NEC for r=0.6 class 0 = 0.149 +- 0.132 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1 = 0.142 +- 0.132 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 2 = 0.198 +- 0.132 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.083 +- 0.132 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.157 +- 0.165 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.536
NEC for r=0.9 class 0 = 0.091 +- 0.082 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 1 = 0.1 +- 0.082 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 2 = 0.149 +- 0.082 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all KL = 0.045 +- 0.082 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all L1 = 0.11 +- 0.136 (in-sample avg dev_std = 0.128)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.526
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.537
NEC for r=1.0 class 0 = 0.09 +- 0.092 (in-sample avg dev_std = 0.141)
NEC for r=1.0 class 1 = 0.102 +- 0.092 (in-sample avg dev_std = 0.141)
NEC for r=1.0 class 2 = 0.146 +- 0.092 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all KL = 0.05 +- 0.092 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all L1 = 0.11 +- 0.140 (in-sample avg dev_std = 0.141)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:39:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:39:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 19...
[0m[1;37mINFO[0m: [1mCheckpoint 19: 
-----------------------------------
Train ACCURACY: 0.9046
Train Loss: 0.2530
ID Validation ACCURACY: 0.7040
ID Validation Loss: 0.8805
ID Test ACCURACY: 0.6931
ID Test Loss: 0.9511
OOD Validation ACCURACY: 0.6437
OOD Validation Loss: 1.1092
OOD Test ACCURACY: 0.5978
OOD Test Loss: 1.3265

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 12...
[0m[1;37mINFO[0m: [1mCheckpoint 12: 
-----------------------------------
Train ACCURACY: 0.8143
Train Loss: 0.4391
ID Validation ACCURACY: 0.6877
ID Validation Loss: 0.8378
ID Test ACCURACY: 0.6661
ID Test Loss: 0.8714
OOD Validation ACCURACY: 0.6493
OOD Validation Loss: 1.0084
OOD Test ACCURACY: 0.6156
OOD Test Loss: 1.1535

[0m[1;37mINFO[0m: [1mChartInfo 0.6931 0.5978 0.6661 0.6156 0.6877 0.6493[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.609
SUFF++ for r=0.3 class 0 = 0.671 +- 0.135 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.3 class 1 = 0.779 +- 0.135 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.3 class 2 = 0.71 +- 0.135 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.3 all KL = 0.845 +- 0.135 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.3 all L1 = 0.734 +- 0.139 (in-sample avg dev_std = 0.307)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0 = 0.746 +- 0.128 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 class 1 = 0.82 +- 0.128 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 class 2 = 0.764 +- 0.128 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all KL = 0.878 +- 0.128 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.145 (in-sample avg dev_std = 0.273)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.684
SUFF++ for r=0.9 class 0 = 0.866 +- 0.050 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.050 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 2 = 0.871 +- 0.050 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all KL = 0.96 +- 0.050 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.105 (in-sample avg dev_std = 0.137)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0 = 0.737 +- 0.107 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 1 = 0.81 +- 0.107 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 2 = 0.753 +- 0.107 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all KL = 0.897 +- 0.107 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all L1 = 0.777 +- 0.137 (in-sample avg dev_std = 0.233)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.583
SUFF++ for r=0.6 class 0 = 0.794 +- 0.092 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 1 = 0.838 +- 0.092 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 2 = 0.781 +- 0.092 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all KL = 0.917 +- 0.092 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all L1 = 0.812 +- 0.130 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.61
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.593
SUFF++ for r=0.9 class 0 = 0.851 +- 0.056 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.056 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.056 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 all KL = 0.958 +- 0.056 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 all L1 = 0.869 +- 0.112 (in-sample avg dev_std = 0.127)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.641
NEC for r=0.3 class 0 = 0.262 +- 0.127 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 1 = 0.177 +- 0.127 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 2 = 0.237 +- 0.127 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all KL = 0.099 +- 0.127 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all L1 = 0.215 +- 0.153 (in-sample avg dev_std = 0.210)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.663
NEC for r=0.6 class 0 = 0.192 +- 0.102 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.136 +- 0.102 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.185 +- 0.102 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.068 +- 0.102 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.163 +- 0.135 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.685
NEC for r=0.9 class 0 = 0.146 +- 0.067 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1 = 0.095 +- 0.067 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 2 = 0.132 +- 0.067 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.039 +- 0.067 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.118 +- 0.112 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0 = 0.122 +- 0.065 (in-sample avg dev_std = 0.120)
NEC for r=1.0 class 1 = 0.085 +- 0.065 (in-sample avg dev_std = 0.120)
NEC for r=1.0 class 2 = 0.111 +- 0.065 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all KL = 0.034 +- 0.065 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all L1 = 0.101 +- 0.103 (in-sample avg dev_std = 0.120)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.561
NEC for r=0.3 class 0 = 0.242 +- 0.103 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 1 = 0.174 +- 0.103 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 2 = 0.222 +- 0.103 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all KL = 0.082 +- 0.103 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all L1 = 0.203 +- 0.142 (in-sample avg dev_std = 0.179)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.596
NEC for r=0.6 class 0 = 0.176 +- 0.085 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 1 = 0.144 +- 0.085 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 2 = 0.183 +- 0.085 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all KL = 0.06 +- 0.085 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all L1 = 0.162 +- 0.131 (in-sample avg dev_std = 0.153)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.61
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.597
NEC for r=0.9 class 0 = 0.143 +- 0.062 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 1 = 0.106 +- 0.062 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 2 = 0.143 +- 0.062 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all KL = 0.039 +- 0.062 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all L1 = 0.125 +- 0.117 (in-sample avg dev_std = 0.118)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.6
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.594
NEC for r=1.0 class 0 = 0.131 +- 0.061 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 1 = 0.099 +- 0.061 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 2 = 0.132 +- 0.061 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all KL = 0.037 +- 0.061 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all L1 = 0.115 +- 0.117 (in-sample avg dev_std = 0.116)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:41:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/03/2024 02:41:57 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/03/2024 02:41:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/03/2024 02:41:59 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/03/2024 02:41:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:01 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:42:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0004
ID Validation ACCURACY: 0.6895
ID Validation Loss: 2.1344
ID Test ACCURACY: 0.6733
ID Test Loss: 2.2496
OOD Validation ACCURACY: 0.6095
OOD Validation Loss: 2.7135
OOD Test ACCURACY: 0.5621
OOD Test Loss: 3.4487

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 8...
[0m[1;37mINFO[0m: [1mCheckpoint 8: 
-----------------------------------
Train ACCURACY: 0.7587
Train Loss: 0.5808
ID Validation ACCURACY: 0.6643
ID Validation Loss: 0.8080
ID Test ACCURACY: 0.6877
ID Test Loss: 0.8180
OOD Validation ACCURACY: 0.6353
OOD Validation Loss: 0.9284
OOD Test ACCURACY: 0.5951
OOD Test Loss: 1.0428

[0m[1;37mINFO[0m: [1mChartInfo 0.6733 0.5621 0.6877 0.5951 0.6643 0.6353[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.664
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0 = 0.608 +- 0.334 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 1 = 0.695 +- 0.334 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 2 = 0.66 +- 0.334 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all KL = 0.444 +- 0.334 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all L1 = 0.664 +- 0.219 (in-sample avg dev_std = 0.611)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.636
SUFF++ for r=0.6 class 0 = 0.693 +- 0.316 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 1 = 0.782 +- 0.316 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 2 = 0.754 +- 0.316 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all KL = 0.641 +- 0.316 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all L1 = 0.753 +- 0.228 (in-sample avg dev_std = 0.455)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.678
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.669
SUFF++ for r=0.9 class 0 = 0.85 +- 0.170 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 1 = 0.88 +- 0.170 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 2 = 0.868 +- 0.170 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all KL = 0.889 +- 0.170 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all L1 = 0.869 +- 0.178 (in-sample avg dev_std = 0.251)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.517
SUFF++ for r=0.3 class 0 = 0.572 +- 0.297 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 class 1 = 0.608 +- 0.297 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 class 2 = 0.644 +- 0.297 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 all KL = 0.423 +- 0.297 (in-sample avg dev_std = 0.607)
SUFF++ for r=0.3 all L1 = 0.607 +- 0.207 (in-sample avg dev_std = 0.607)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.549
SUFF++ for r=0.6 class 0 = 0.695 +- 0.285 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 1 = 0.723 +- 0.285 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 2 = 0.701 +- 0.285 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all KL = 0.63 +- 0.285 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all L1 = 0.71 +- 0.213 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.573
SUFF++ for r=0.9 class 0 = 0.853 +- 0.136 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1 = 0.881 +- 0.136 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.136 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.906 +- 0.136 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.867 +- 0.161 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.664
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.628
NEC for r=0.3 class 0 = 0.277 +- 0.332 (in-sample avg dev_std = 0.391)
NEC for r=0.3 class 1 = 0.207 +- 0.332 (in-sample avg dev_std = 0.391)
NEC for r=0.3 class 2 = 0.242 +- 0.332 (in-sample avg dev_std = 0.391)
NEC for r=0.3 all KL = 0.286 +- 0.332 (in-sample avg dev_std = 0.391)
NEC for r=0.3 all L1 = 0.234 +- 0.255 (in-sample avg dev_std = 0.391)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.644
NEC for r=0.6 class 0 = 0.213 +- 0.281 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 1 = 0.164 +- 0.281 (in-sample avg dev_std = 0.327)
NEC for r=0.6 class 2 = 0.193 +- 0.281 (in-sample avg dev_std = 0.327)
NEC for r=0.6 all KL = 0.202 +- 0.281 (in-sample avg dev_std = 0.327)
NEC for r=0.6 all L1 = 0.184 +- 0.229 (in-sample avg dev_std = 0.327)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.66
NEC for r=0.9 class 0 = 0.13 +- 0.168 (in-sample avg dev_std = 0.228)
NEC for r=0.9 class 1 = 0.11 +- 0.168 (in-sample avg dev_std = 0.228)
NEC for r=0.9 class 2 = 0.125 +- 0.168 (in-sample avg dev_std = 0.228)
NEC for r=0.9 all KL = 0.093 +- 0.168 (in-sample avg dev_std = 0.228)
NEC for r=0.9 all L1 = 0.119 +- 0.178 (in-sample avg dev_std = 0.228)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.686
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.673
NEC for r=1.0 class 0 = 0.102 +- 0.153 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 1 = 0.092 +- 0.153 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 2 = 0.107 +- 0.153 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all KL = 0.07 +- 0.153 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all L1 = 0.099 +- 0.164 (in-sample avg dev_std = 0.194)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0 = 0.303 +- 0.339 (in-sample avg dev_std = 0.426)
NEC for r=0.3 class 1 = 0.303 +- 0.339 (in-sample avg dev_std = 0.426)
NEC for r=0.3 class 2 = 0.333 +- 0.339 (in-sample avg dev_std = 0.426)
NEC for r=0.3 all KL = 0.37 +- 0.339 (in-sample avg dev_std = 0.426)
NEC for r=0.3 all L1 = 0.31 +- 0.262 (in-sample avg dev_std = 0.426)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.558
NEC for r=0.6 class 0 = 0.213 +- 0.258 (in-sample avg dev_std = 0.303)
NEC for r=0.6 class 1 = 0.208 +- 0.258 (in-sample avg dev_std = 0.303)
NEC for r=0.6 class 2 = 0.251 +- 0.258 (in-sample avg dev_std = 0.303)
NEC for r=0.6 all KL = 0.206 +- 0.258 (in-sample avg dev_std = 0.303)
NEC for r=0.6 all L1 = 0.22 +- 0.231 (in-sample avg dev_std = 0.303)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.567
NEC for r=0.9 class 0 = 0.129 +- 0.132 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1 = 0.107 +- 0.132 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 2 = 0.149 +- 0.132 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.075 +- 0.132 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.123 +- 0.164 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.565
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.119 +- 0.116 (in-sample avg dev_std = 0.169)
NEC for r=1.0 class 1 = 0.094 +- 0.116 (in-sample avg dev_std = 0.169)
NEC for r=1.0 class 2 = 0.135 +- 0.116 (in-sample avg dev_std = 0.169)
NEC for r=1.0 all KL = 0.064 +- 0.116 (in-sample avg dev_std = 0.169)
NEC for r=1.0 all L1 = 0.111 +- 0.154 (in-sample avg dev_std = 0.169)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.785, 0.845, 0.947, 1.0], 'all_L1': [0.722, 0.786, 0.887, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.845, 0.878, 0.96, 1.0], 'all_L1': [0.734, 0.786, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.444, 0.641, 0.889, 1.0], 'all_L1': [0.664, 0.753, 0.869, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.122, 0.095, 0.051, 0.043], 'all_L1': [0.214, 0.167, 0.118, 0.104]}), defaultdict(<class 'list'>, {'all_KL': [0.099, 0.068, 0.039, 0.034], 'all_L1': [0.215, 0.163, 0.118, 0.101]}), defaultdict(<class 'list'>, {'all_KL': [0.286, 0.202, 0.093, 0.07], 'all_L1': [0.234, 0.184, 0.119, 0.099]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.86, 0.885, 0.959, 1.0], 'all_L1': [0.764, 0.815, 0.897, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.897, 0.917, 0.958, 1.0], 'all_L1': [0.777, 0.812, 0.869, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.423, 0.63, 0.906, 1.0], 'all_L1': [0.607, 0.71, 0.867, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.101, 0.083, 0.045, 0.05], 'all_L1': [0.204, 0.157, 0.11, 0.11]}), defaultdict(<class 'list'>, {'all_KL': [0.082, 0.06, 0.039, 0.037], 'all_L1': [0.203, 0.162, 0.125, 0.115]}), defaultdict(<class 'list'>, {'all_KL': [0.37, 0.206, 0.075, 0.064], 'all_L1': [0.31, 0.22, 0.123, 0.111]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.707 +- 0.031, 0.775 +- 0.016, 0.879 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.691 +- 0.177, 0.788 +- 0.105, 0.932 +- 0.031, 1.000 +- 0.000
suff++_acc_int  =  0.590 +- 0.015, 0.640 +- 0.012, 0.674 +- 0.007
nec class all_L1  =  0.221 +- 0.009, 0.171 +- 0.009, 0.118 +- 0.000, 0.101 +- 0.002
nec class all_KL  =  0.169 +- 0.083, 0.122 +- 0.058, 0.061 +- 0.023, 0.049 +- 0.015
nec_acc_int  =  0.629 +- 0.009, 0.657 +- 0.009, 0.674 +- 0.011, 0.682 +- 0.006

Eval split test
suff++ class all_L1  =  0.716 +- 0.077, 0.779 +- 0.049, 0.878 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.727 +- 0.215, 0.811 +- 0.128, 0.941 +- 0.025, 1.000 +- 0.000
suff++_acc_int  =  0.531 +- 0.013, 0.556 +- 0.020, 0.565 +- 0.027
nec class all_L1  =  0.239 +- 0.050, 0.180 +- 0.029, 0.119 +- 0.007, 0.112 +- 0.002
nec class all_KL  =  0.184 +- 0.132, 0.116 +- 0.064, 0.053 +- 0.016, 0.050 +- 0.011
nec_acc_int  =  0.546 +- 0.011, 0.567 +- 0.020, 0.567 +- 0.025, 0.565 +- 0.023


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.464 +- 0.011, 0.473 +- 0.003, 0.499 +- 0.004, 0.551 +- 0.001
Faith. Armon (L1)= 		  =  0.336 +- 0.007, 0.280 +- 0.011, 0.209 +- 0.001, 0.184 +- 0.003
Faith. GMean (L1)= 	  =  0.395 +- 0.002, 0.364 +- 0.006, 0.323 +- 0.001, 0.318 +- 0.003
Faith. Aritm (KL)= 		  =  0.430 +- 0.047, 0.455 +- 0.024, 0.497 +- 0.004, 0.525 +- 0.008
Faith. Armon (KL)= 		  =  0.245 +- 0.074, 0.201 +- 0.077, 0.113 +- 0.040, 0.093 +- 0.028
Faith. GMean (KL)= 	  =  0.318 +- 0.028, 0.296 +- 0.048, 0.234 +- 0.040, 0.219 +- 0.034

Eval split test
Faith. Aritm (L1)= 		  =  0.477 +- 0.014, 0.479 +- 0.010, 0.498 +- 0.004, 0.556 +- 0.001
Faith. Armon (L1)= 		  =  0.351 +- 0.042, 0.290 +- 0.033, 0.210 +- 0.010, 0.201 +- 0.003
Faith. GMean (L1)= 	  =  0.409 +- 0.018, 0.372 +- 0.017, 0.323 +- 0.007, 0.335 +- 0.003
Faith. Aritm (KL)= 		  =  0.456 +- 0.042, 0.463 +- 0.032, 0.497 +- 0.005, 0.525 +- 0.006
Faith. Armon (KL)= 		  =  0.242 +- 0.109, 0.192 +- 0.086, 0.100 +- 0.028, 0.096 +- 0.020
Faith. GMean (KL)= 	  =  0.321 +- 0.054, 0.289 +- 0.053, 0.221 +- 0.029, 0.223 +- 0.025
Computed for split load_split = id



Completed in  0:08:54.167900  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length soft2

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:45:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:45:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0032
ID Validation ACCURACY: 0.9194
ID Validation Loss: 0.3259
ID Test ACCURACY: 0.9078
ID Test Loss: 0.3725
OOD Validation ACCURACY: 0.8785
OOD Validation Loss: 0.5291
OOD Test ACCURACY: 0.8275
OOD Test Loss: 1.1676

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9168
ID Validation Loss: 0.4630
ID Test ACCURACY: 0.9162
ID Test Loss: 0.5222
OOD Validation ACCURACY: 0.8849
OOD Validation Loss: 0.6479
OOD Test ACCURACY: 0.8320
OOD Test Loss: 1.2339

[0m[1;37mINFO[0m: [1mChartInfo 0.9078 0.8275 0.9162 0.8320 0.9168 0.8849[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 02:45:26 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.8
SUFF++ for r=0.6 class 0.0 = 0.726 +- 0.300 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 1.0 = 0.823 +- 0.300 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all KL = 0.632 +- 0.300 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all L1 = 0.783 +- 0.193 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.89
SUFF++ for r=0.9 class 0.0 = 0.96 +- 0.076 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.076 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all KL = 0.983 +- 0.076 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.087 (in-sample avg dev_std = 0.080)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.761
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.711
SUFF++ for r=0.3 class 0.0 = 0.688 +- 0.317 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 class 1.0 = 0.827 +- 0.317 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all KL = 0.628 +- 0.317 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.3 all L1 = 0.76 +- 0.209 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.79
SUFF++ for r=0.6 class 0.0 = 0.776 +- 0.312 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 1.0 = 0.877 +- 0.312 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all KL = 0.717 +- 0.312 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all L1 = 0.828 +- 0.198 (in-sample avg dev_std = 0.432)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.846
SUFF++ for r=0.9 class 0.0 = 0.934 +- 0.152 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.152 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all KL = 0.931 +- 0.152 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.113 (in-sample avg dev_std = 0.232)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.875
NEC for r=0.6 class 0.0 = 0.121 +- 0.194 (in-sample avg dev_std = 0.138)
NEC for r=0.6 class 1.0 = 0.058 +- 0.194 (in-sample avg dev_std = 0.138)
NEC for r=0.6 all KL = 0.084 +- 0.194 (in-sample avg dev_std = 0.138)
NEC for r=0.6 all L1 = 0.084 +- 0.170 (in-sample avg dev_std = 0.138)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.898
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.891
NEC for r=0.9 class 0.0 = 0.043 +- 0.082 (in-sample avg dev_std = 0.082)
NEC for r=0.9 class 1.0 = 0.019 +- 0.082 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all KL = 0.019 +- 0.082 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all L1 = 0.029 +- 0.088 (in-sample avg dev_std = 0.082)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.898
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.891
NEC for r=1.0 class 0.0 = 0.043 +- 0.082 (in-sample avg dev_std = 0.082)
NEC for r=1.0 class 1.0 = 0.019 +- 0.082 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all KL = 0.019 +- 0.082 (in-sample avg dev_std = 0.082)
NEC for r=1.0 all L1 = 0.029 +- 0.088 (in-sample avg dev_std = 0.082)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.761
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.775
NEC for r=0.3 class 0.0 = 0.187 +- 0.254 (in-sample avg dev_std = 0.259)
NEC for r=0.3 class 1.0 = 0.098 +- 0.254 (in-sample avg dev_std = 0.259)
NEC for r=0.3 all KL = 0.148 +- 0.254 (in-sample avg dev_std = 0.259)
NEC for r=0.3 all L1 = 0.141 +- 0.221 (in-sample avg dev_std = 0.259)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.834
NEC for r=0.6 class 0.0 = 0.112 +- 0.192 (in-sample avg dev_std = 0.179)
NEC for r=0.6 class 1.0 = 0.067 +- 0.192 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all KL = 0.084 +- 0.192 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all L1 = 0.089 +- 0.179 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.852
NEC for r=0.9 class 0.0 = 0.043 +- 0.091 (in-sample avg dev_std = 0.103)
NEC for r=0.9 class 1.0 = 0.022 +- 0.091 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all KL = 0.022 +- 0.091 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all L1 = 0.032 +- 0.094 (in-sample avg dev_std = 0.103)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.858
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.853
NEC for r=1.0 class 0.0 = 0.033 +- 0.066 (in-sample avg dev_std = 0.081)
NEC for r=1.0 class 1.0 = 0.017 +- 0.066 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all KL = 0.014 +- 0.066 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all L1 = 0.024 +- 0.076 (in-sample avg dev_std = 0.081)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:47:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9206
ID Validation Loss: 0.4503
ID Test ACCURACY: 0.9155
ID Test Loss: 0.5412
OOD Validation ACCURACY: 0.8852
OOD Validation Loss: 0.6649
OOD Test ACCURACY: 0.8272
OOD Test Loss: 1.4120

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9179
ID Validation Loss: 0.4392
ID Test ACCURACY: 0.9164
ID Test Loss: 0.5223
OOD Validation ACCURACY: 0.8865
OOD Validation Loss: 0.6349
OOD Test ACCURACY: 0.8309
OOD Test Loss: 1.3175

[0m[1;37mINFO[0m: [1mChartInfo 0.9155 0.8272 0.9164 0.8309 0.9179 0.8865[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 02:47:17 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.855
SUFF++ for r=0.6 class 0.0 = 0.831 +- 0.340 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 class 1.0 = 0.869 +- 0.340 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 all KL = 0.693 +- 0.340 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.6 all L1 = 0.853 +- 0.181 (in-sample avg dev_std = 0.453)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.91
SUFF++ for r=0.9 class 0.0 = 0.95 +- 0.124 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 class 1.0 = 0.993 +- 0.124 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all KL = 0.976 +- 0.124 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all L1 = 0.974 +- 0.108 (in-sample avg dev_std = 0.104)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.788
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.735
SUFF++ for r=0.3 class 0.0 = 0.745 +- 0.351 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 class 1.0 = 0.762 +- 0.351 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all KL = 0.537 +- 0.351 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all L1 = 0.754 +- 0.214 (in-sample avg dev_std = 0.568)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.802
SUFF++ for r=0.6 class 0.0 = 0.846 +- 0.316 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 class 1.0 = 0.866 +- 0.316 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 all KL = 0.749 +- 0.316 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.198 (in-sample avg dev_std = 0.395)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.948 +- 0.131 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 class 1.0 = 0.967 +- 0.131 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all KL = 0.949 +- 0.131 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.099 (in-sample avg dev_std = 0.195)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.879
NEC for r=0.6 class 0.0 = 0.124 +- 0.237 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.036 +- 0.237 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.083 +- 0.237 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.073 +- 0.196 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.912
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.892
NEC for r=0.9 class 0.0 = 0.059 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 1.0 = 0.01 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all KL = 0.03 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all L1 = 0.03 +- 0.124 (in-sample avg dev_std = 0.114)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.912
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.892
NEC for r=1.0 class 0.0 = 0.059 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=1.0 class 1.0 = 0.01 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all KL = 0.03 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all L1 = 0.03 +- 0.124 (in-sample avg dev_std = 0.114)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.788
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.78
NEC for r=0.3 class 0.0 = 0.173 +- 0.296 (in-sample avg dev_std = 0.309)
NEC for r=0.3 class 1.0 = 0.115 +- 0.296 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all KL = 0.179 +- 0.296 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all L1 = 0.143 +- 0.231 (in-sample avg dev_std = 0.309)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.827
NEC for r=0.6 class 0.0 = 0.088 +- 0.214 (in-sample avg dev_std = 0.225)
NEC for r=0.6 class 1.0 = 0.07 +- 0.214 (in-sample avg dev_std = 0.225)
NEC for r=0.6 all KL = 0.089 +- 0.214 (in-sample avg dev_std = 0.225)
NEC for r=0.6 all L1 = 0.078 +- 0.175 (in-sample avg dev_std = 0.225)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.836
NEC for r=0.9 class 0.0 = 0.034 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=0.9 class 1.0 = 0.022 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all KL = 0.02 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all L1 = 0.028 +- 0.090 (in-sample avg dev_std = 0.092)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.837
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0.0 = 0.027 +- 0.075 (in-sample avg dev_std = 0.083)
NEC for r=1.0 class 1.0 = 0.018 +- 0.075 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all KL = 0.015 +- 0.075 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all L1 = 0.022 +- 0.076 (in-sample avg dev_std = 0.083)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:49:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing mitigation soft
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing mitigation soft
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:49:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9225
ID Validation Loss: 0.4287
ID Test ACCURACY: 0.9187
ID Test Loss: 0.4887
OOD Validation ACCURACY: 0.8800
OOD Validation Loss: 0.6407
OOD Test ACCURACY: 0.8245
OOD Test Loss: 1.1679

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0038
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.3001
ID Test ACCURACY: 0.9144
ID Test Loss: 0.3537
OOD Validation ACCURACY: 0.8849
OOD Validation Loss: 0.4337
OOD Test ACCURACY: 0.8320
OOD Test Loss: 0.7293

[0m[1;37mINFO[0m: [1mChartInfo 0.9187 0.8245 0.9144 0.8320 0.9172 0.8849[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 02:49:08 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.822
SUFF++ for r=0.6 class 0.0 = 0.791 +- 0.340 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 1.0 = 0.859 +- 0.340 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all KL = 0.652 +- 0.340 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all L1 = 0.831 +- 0.192 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.104 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 class 1.0 = 0.99 +- 0.104 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all KL = 0.98 +- 0.104 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all L1 = 0.976 +- 0.096 (in-sample avg dev_std = 0.086)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.772
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.745
SUFF++ for r=0.3 class 0.0 = 0.735 +- 0.330 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 1.0 = 0.81 +- 0.330 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all KL = 0.612 +- 0.330 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all L1 = 0.774 +- 0.211 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.799
SUFF++ for r=0.6 class 0.0 = 0.817 +- 0.300 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 1.0 = 0.89 +- 0.300 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all KL = 0.764 +- 0.300 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all L1 = 0.855 +- 0.197 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.841
SUFF++ for r=0.9 class 0.0 = 0.932 +- 0.137 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.137 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all KL = 0.943 +- 0.137 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.109 (in-sample avg dev_std = 0.214)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.85
NEC for r=0.6 class 0.0 = 0.12 +- 0.255 (in-sample avg dev_std = 0.224)
NEC for r=0.6 class 1.0 = 0.063 +- 0.255 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all KL = 0.112 +- 0.255 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all L1 = 0.087 +- 0.196 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.044 +- 0.148 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 1.0 = 0.021 +- 0.148 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all KL = 0.03 +- 0.148 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all L1 = 0.03 +- 0.125 (in-sample avg dev_std = 0.123)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.044 +- 0.148 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1.0 = 0.021 +- 0.148 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.03 +- 0.148 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.03 +- 0.125 (in-sample avg dev_std = 0.123)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.772
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.791
NEC for r=0.3 class 0.0 = 0.197 +- 0.287 (in-sample avg dev_std = 0.297)
NEC for r=0.3 class 1.0 = 0.097 +- 0.287 (in-sample avg dev_std = 0.297)
NEC for r=0.3 all KL = 0.174 +- 0.287 (in-sample avg dev_std = 0.297)
NEC for r=0.3 all L1 = 0.145 +- 0.230 (in-sample avg dev_std = 0.297)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.822
NEC for r=0.6 class 0.0 = 0.107 +- 0.200 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 1.0 = 0.052 +- 0.200 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all KL = 0.082 +- 0.200 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all L1 = 0.079 +- 0.174 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.84
NEC for r=0.9 class 0.0 = 0.046 +- 0.112 (in-sample avg dev_std = 0.118)
NEC for r=0.9 class 1.0 = 0.022 +- 0.112 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all KL = 0.026 +- 0.112 (in-sample avg dev_std = 0.118)
NEC for r=0.9 all L1 = 0.033 +- 0.110 (in-sample avg dev_std = 0.118)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.845
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.841
NEC for r=1.0 class 0.0 = 0.034 +- 0.094 (in-sample avg dev_std = 0.110)
NEC for r=1.0 class 1.0 = 0.019 +- 0.094 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all KL = 0.019 +- 0.094 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all L1 = 0.026 +- 0.092 (in-sample avg dev_std = 0.110)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.632, 0.983, 1.0], 'all_L1': [0.783, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.693, 0.976, 1.0], 'all_L1': [0.853, 0.974, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.652, 0.98, 1.0], 'all_L1': [0.831, 0.976, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.084, 0.019, 0.019], 'all_L1': [0.084, 0.029, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.083, 0.03, 0.03], 'all_L1': [0.073, 0.03, 0.03]}), defaultdict(<class 'list'>, {'all_KL': [0.112, 0.03, 0.03], 'all_L1': [0.087, 0.03, 0.03]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.628, 0.717, 0.931, 1.0], 'all_L1': [0.76, 0.828, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.537, 0.749, 0.949, 1.0], 'all_L1': [0.754, 0.857, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.612, 0.764, 0.943, 1.0], 'all_L1': [0.774, 0.855, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.148, 0.084, 0.022, 0.014], 'all_L1': [0.141, 0.089, 0.032, 0.024]}), defaultdict(<class 'list'>, {'all_KL': [0.179, 0.089, 0.02, 0.015], 'all_L1': [0.143, 0.078, 0.028, 0.022]}), defaultdict(<class 'list'>, {'all_KL': [0.174, 0.082, 0.026, 0.019], 'all_L1': [0.145, 0.079, 0.033, 0.026]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.822 +- 0.029, 0.974 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.659 +- 0.025, 0.980 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.826 +- 0.023, 0.894 +- 0.012
nec class all_L1  =  0.081 +- 0.006, 0.030 +- 0.000, 0.030 +- 0.000
nec class all_KL  =  0.093 +- 0.013, 0.026 +- 0.005, 0.026 +- 0.005
nec_acc_int  =  0.868 +- 0.013, 0.884 +- 0.010, 0.884 +- 0.010

Eval split test
suff++ class all_L1  =  0.763 +- 0.008, 0.847 +- 0.013, 0.951 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.592 +- 0.040, 0.743 +- 0.020, 0.941 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.730 +- 0.014, 0.797 +- 0.005, 0.840 +- 0.006
nec class all_L1  =  0.143 +- 0.002, 0.082 +- 0.005, 0.031 +- 0.002, 0.024 +- 0.002
nec class all_KL  =  0.167 +- 0.014, 0.085 +- 0.003, 0.023 +- 0.002, 0.016 +- 0.002
nec_acc_int  =  0.782 +- 0.007, 0.828 +- 0.005, 0.842 +- 0.007, 0.844 +- 0.007


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.452 +- 0.013, 0.502 +- 0.001, 0.515 +- 0.000
Faith. Armon (L1)= 		  =  0.148 +- 0.010, 0.058 +- 0.001, 0.058 +- 0.001
Faith. GMean (L1)= 	  =  0.258 +- 0.008, 0.170 +- 0.002, 0.172 +- 0.001
Faith. Aritm (KL)= 		  =  0.376 +- 0.013, 0.503 +- 0.002, 0.513 +- 0.003
Faith. Armon (KL)= 		  =  0.163 +- 0.020, 0.051 +- 0.010, 0.051 +- 0.010
Faith. GMean (KL)= 	  =  0.247 +- 0.017, 0.160 +- 0.016, 0.161 +- 0.017

Eval split test
Faith. Aritm (L1)= 		  =  0.453 +- 0.005, 0.464 +- 0.004, 0.491 +- 0.002, 0.512 +- 0.001
Faith. Armon (L1)= 		  =  0.241 +- 0.003, 0.149 +- 0.008, 0.060 +- 0.004, 0.047 +- 0.003
Faith. GMean (L1)= 	  =  0.330 +- 0.003, 0.263 +- 0.006, 0.172 +- 0.006, 0.155 +- 0.005
Faith. Aritm (KL)= 		  =  0.380 +- 0.015, 0.414 +- 0.010, 0.482 +- 0.004, 0.508 +- 0.001
Faith. Armon (KL)= 		  =  0.260 +- 0.014, 0.153 +- 0.005, 0.044 +- 0.005, 0.031 +- 0.004
Faith. GMean (KL)= 	  =  0.314 +- 0.009, 0.251 +- 0.005, 0.146 +- 0.008, 0.126 +- 0.008
Computed for split load_split = id



Completed in  0:05:36.190312  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length soft

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:51:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:29 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:51:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9196
ID Validation Loss: 0.4367
ID Test ACCURACY: 0.9138
ID Test Loss: 0.4945
OOD Validation ACCURACY: 0.8809
OOD Validation Loss: 0.6402
OOD Test ACCURACY: 0.8217
OOD Test Loss: 1.1569

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0026
ID Validation ACCURACY: 0.9162
ID Validation Loss: 0.3546
ID Test ACCURACY: 0.9100
ID Test Loss: 0.3990
OOD Validation ACCURACY: 0.8839
OOD Validation Loss: 0.5714
OOD Test ACCURACY: 0.8350
OOD Test Loss: 1.3166

[0m[1;37mINFO[0m: [1mChartInfo 0.9138 0.8217 0.9100 0.8350 0.9162 0.8839[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 02:51:31 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.819
SUFF++ for r=0.6 class 0.0 = 0.783 +- 0.339 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 1.0 = 0.848 +- 0.339 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all KL = 0.653 +- 0.339 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.202 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.139 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.139 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.973 +- 0.139 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.113 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.717
SUFF++ for r=0.3 class 0.0 = 0.723 +- 0.329 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 class 1.0 = 0.839 +- 0.329 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all KL = 0.642 +- 0.329 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all L1 = 0.783 +- 0.215 (in-sample avg dev_std = 0.499)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.792
SUFF++ for r=0.6 class 0.0 = 0.819 +- 0.303 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 1.0 = 0.892 +- 0.303 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all KL = 0.76 +- 0.303 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.196 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.837
SUFF++ for r=0.9 class 0.0 = 0.952 +- 0.139 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.139 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all KL = 0.944 +- 0.139 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all L1 = 0.959 +- 0.093 (in-sample avg dev_std = 0.207)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.861
NEC for r=0.6 class 0.0 = 0.116 +- 0.243 (in-sample avg dev_std = 0.197)
NEC for r=0.6 class 1.0 = 0.059 +- 0.243 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all KL = 0.102 +- 0.243 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all L1 = 0.083 +- 0.187 (in-sample avg dev_std = 0.197)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.873
NEC for r=0.9 class 0.0 = 0.037 +- 0.139 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.015 +- 0.139 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.027 +- 0.139 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.024 +- 0.104 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.037 +- 0.139 (in-sample avg dev_std = 0.094)
NEC for r=1.0 class 1.0 = 0.015 +- 0.139 (in-sample avg dev_std = 0.094)
NEC for r=1.0 all KL = 0.027 +- 0.139 (in-sample avg dev_std = 0.094)
NEC for r=1.0 all L1 = 0.024 +- 0.104 (in-sample avg dev_std = 0.094)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.771
NEC for r=0.3 class 0.0 = 0.207 +- 0.291 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 1.0 = 0.106 +- 0.291 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all KL = 0.173 +- 0.291 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all L1 = 0.155 +- 0.244 (in-sample avg dev_std = 0.290)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.814
NEC for r=0.6 class 0.0 = 0.103 +- 0.206 (in-sample avg dev_std = 0.221)
NEC for r=0.6 class 1.0 = 0.055 +- 0.206 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all KL = 0.085 +- 0.206 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all L1 = 0.079 +- 0.170 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.842
NEC for r=0.9 class 0.0 = 0.031 +- 0.087 (in-sample avg dev_std = 0.102)
NEC for r=0.9 class 1.0 = 0.018 +- 0.087 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all KL = 0.019 +- 0.087 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all L1 = 0.024 +- 0.084 (in-sample avg dev_std = 0.102)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.845
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.84
NEC for r=1.0 class 0.0 = 0.027 +- 0.077 (in-sample avg dev_std = 0.089)
NEC for r=1.0 class 1.0 = 0.015 +- 0.077 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all KL = 0.015 +- 0.077 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all L1 = 0.021 +- 0.078 (in-sample avg dev_std = 0.089)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:53:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9998
Train Loss: 0.0029
ID Validation ACCURACY: 0.9206
ID Validation Loss: 0.3234
ID Test ACCURACY: 0.9136
ID Test Loss: 0.3726
OOD Validation ACCURACY: 0.8803
OOD Validation Loss: 0.5368
OOD Test ACCURACY: 0.8217
OOD Test Loss: 1.2218

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.9997
Train Loss: 0.0027
ID Validation ACCURACY: 0.9151
ID Validation Loss: 0.3383
ID Test ACCURACY: 0.9127
ID Test Loss: 0.3847
OOD Validation ACCURACY: 0.8847
OOD Validation Loss: 0.5245
OOD Test ACCURACY: 0.8251
OOD Test Loss: 1.1179

[0m[1;37mINFO[0m: [1mChartInfo 0.9136 0.8217 0.9127 0.8251 0.9151 0.8847[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 02:53:26 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.825
SUFF++ for r=0.6 class 0.0 = 0.765 +- 0.298 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 1.0 = 0.826 +- 0.298 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all KL = 0.665 +- 0.298 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all L1 = 0.801 +- 0.191 (in-sample avg dev_std = 0.476)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.917
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.906
SUFF++ for r=0.9 class 0.0 = 0.945 +- 0.106 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1.0 = 0.986 +- 0.106 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.978 +- 0.106 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.110 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.784
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.733
SUFF++ for r=0.3 class 0.0 = 0.766 +- 0.284 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 class 1.0 = 0.865 +- 0.284 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all KL = 0.736 +- 0.284 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.3 all L1 = 0.818 +- 0.201 (in-sample avg dev_std = 0.431)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.819
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.791
SUFF++ for r=0.6 class 0.0 = 0.844 +- 0.251 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.6 class 1.0 = 0.898 +- 0.251 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.6 all KL = 0.829 +- 0.251 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.6 all L1 = 0.872 +- 0.191 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.835
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0.0 = 0.947 +- 0.123 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.123 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.951 +- 0.123 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.108 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.87
NEC for r=0.6 class 0.0 = 0.159 +- 0.242 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 1.0 = 0.069 +- 0.242 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all KL = 0.117 +- 0.242 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all L1 = 0.106 +- 0.198 (in-sample avg dev_std = 0.200)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.893
NEC for r=0.9 class 0.0 = 0.058 +- 0.122 (in-sample avg dev_std = 0.078)
NEC for r=0.9 class 1.0 = 0.015 +- 0.122 (in-sample avg dev_std = 0.078)
NEC for r=0.9 all KL = 0.026 +- 0.122 (in-sample avg dev_std = 0.078)
NEC for r=0.9 all L1 = 0.033 +- 0.121 (in-sample avg dev_std = 0.078)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.909
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.893
NEC for r=1.0 class 0.0 = 0.058 +- 0.122 (in-sample avg dev_std = 0.078)
NEC for r=1.0 class 1.0 = 0.015 +- 0.122 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all KL = 0.026 +- 0.122 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all L1 = 0.033 +- 0.121 (in-sample avg dev_std = 0.078)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.784
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.765
NEC for r=0.3 class 0.0 = 0.172 +- 0.251 (in-sample avg dev_std = 0.212)
NEC for r=0.3 class 1.0 = 0.083 +- 0.251 (in-sample avg dev_std = 0.212)
NEC for r=0.3 all KL = 0.124 +- 0.251 (in-sample avg dev_std = 0.212)
NEC for r=0.3 all L1 = 0.126 +- 0.219 (in-sample avg dev_std = 0.212)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.819
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.81
NEC for r=0.6 class 0.0 = 0.095 +- 0.183 (in-sample avg dev_std = 0.166)
NEC for r=0.6 class 1.0 = 0.065 +- 0.183 (in-sample avg dev_std = 0.166)
NEC for r=0.6 all KL = 0.072 +- 0.183 (in-sample avg dev_std = 0.166)
NEC for r=0.6 all L1 = 0.079 +- 0.172 (in-sample avg dev_std = 0.166)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.835
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.829
NEC for r=0.9 class 0.0 = 0.038 +- 0.090 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 1.0 = 0.03 +- 0.090 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all KL = 0.023 +- 0.090 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all L1 = 0.034 +- 0.103 (in-sample avg dev_std = 0.114)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.835
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.832
NEC for r=1.0 class 0.0 = 0.022 +- 0.074 (in-sample avg dev_std = 0.098)
NEC for r=1.0 class 1.0 = 0.026 +- 0.074 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all KL = 0.014 +- 0.074 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all L1 = 0.024 +- 0.084 (in-sample avg dev_std = 0.098)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May  3 14:55:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing mitigation soft2
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing mitigation soft2
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9206
ID Validation Loss: 0.4320
ID Test ACCURACY: 0.9191
ID Test Loss: 0.4856
OOD Validation ACCURACY: 0.8806
OOD Validation Loss: 0.6343
OOD Test ACCURACY: 0.8193
OOD Test Loss: 1.4156

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9997
Train Loss: 0.0018
ID Validation ACCURACY: 0.9144
ID Validation Loss: 0.3698
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4182
OOD Validation ACCURACY: 0.8838
OOD Validation Loss: 0.5446
OOD Test ACCURACY: 0.8271
OOD Test Loss: 1.1067

[0m[1;37mINFO[0m: [1mChartInfo 0.9191 0.8193 0.9130 0.8271 0.9144 0.8838[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/03/2024 02:55:18 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.818
SUFF++ for r=0.6 class 0.0 = 0.762 +- 0.330 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1.0 = 0.886 +- 0.330 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.698 +- 0.330 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.834 +- 0.203 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.894
SUFF++ for r=0.9 class 0.0 = 0.96 +- 0.096 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 class 1.0 = 0.987 +- 0.096 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all KL = 0.981 +- 0.096 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.098 (in-sample avg dev_std = 0.095)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.779
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.719
SUFF++ for r=0.3 class 0.0 = 0.699 +- 0.347 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 1.0 = 0.818 +- 0.347 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 all KL = 0.575 +- 0.347 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 all L1 = 0.761 +- 0.219 (in-sample avg dev_std = 0.546)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.79
SUFF++ for r=0.6 class 0.0 = 0.802 +- 0.313 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 1.0 = 0.895 +- 0.313 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all KL = 0.74 +- 0.313 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all L1 = 0.85 +- 0.200 (in-sample avg dev_std = 0.414)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.827
SUFF++ for r=0.9 class 0.0 = 0.928 +- 0.166 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.166 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all KL = 0.925 +- 0.166 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.126 (in-sample avg dev_std = 0.231)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.859
NEC for r=0.6 class 0.0 = 0.152 +- 0.236 (in-sample avg dev_std = 0.240)
NEC for r=0.6 class 1.0 = 0.048 +- 0.236 (in-sample avg dev_std = 0.240)
NEC for r=0.6 all KL = 0.103 +- 0.236 (in-sample avg dev_std = 0.240)
NEC for r=0.6 all L1 = 0.091 +- 0.192 (in-sample avg dev_std = 0.240)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.887
NEC for r=0.9 class 0.0 = 0.04 +- 0.104 (in-sample avg dev_std = 0.083)
NEC for r=0.9 class 1.0 = 0.016 +- 0.104 (in-sample avg dev_std = 0.083)
NEC for r=0.9 all KL = 0.021 +- 0.104 (in-sample avg dev_std = 0.083)
NEC for r=0.9 all L1 = 0.026 +- 0.100 (in-sample avg dev_std = 0.083)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.895
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.887
NEC for r=1.0 class 0.0 = 0.04 +- 0.104 (in-sample avg dev_std = 0.083)
NEC for r=1.0 class 1.0 = 0.016 +- 0.104 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all KL = 0.021 +- 0.104 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all L1 = 0.026 +- 0.100 (in-sample avg dev_std = 0.083)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.779
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.769
NEC for r=0.3 class 0.0 = 0.211 +- 0.305 (in-sample avg dev_std = 0.280)
NEC for r=0.3 class 1.0 = 0.09 +- 0.305 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all KL = 0.179 +- 0.305 (in-sample avg dev_std = 0.280)
NEC for r=0.3 all L1 = 0.149 +- 0.247 (in-sample avg dev_std = 0.280)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.818
NEC for r=0.6 class 0.0 = 0.115 +- 0.216 (in-sample avg dev_std = 0.205)
NEC for r=0.6 class 1.0 = 0.053 +- 0.216 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all KL = 0.091 +- 0.216 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all L1 = 0.083 +- 0.181 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.828
NEC for r=0.9 class 0.0 = 0.044 +- 0.124 (in-sample avg dev_std = 0.115)
NEC for r=0.9 class 1.0 = 0.029 +- 0.124 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all KL = 0.029 +- 0.124 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all L1 = 0.036 +- 0.119 (in-sample avg dev_std = 0.115)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.834
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.832
NEC for r=1.0 class 0.0 = 0.035 +- 0.083 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.015 +- 0.083 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.016 +- 0.083 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.025 +- 0.090 (in-sample avg dev_std = 0.092)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.653, 0.973, 1.0], 'all_L1': [0.821, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.665, 0.978, 1.0], 'all_L1': [0.801, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.698, 0.981, 1.0], 'all_L1': [0.834, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.102, 0.027, 0.027], 'all_L1': [0.083, 0.024, 0.024]}), defaultdict(<class 'list'>, {'all_KL': [0.117, 0.026, 0.026], 'all_L1': [0.106, 0.033, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.021, 0.021], 'all_L1': [0.091, 0.026, 0.026]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.642, 0.76, 0.944, 1.0], 'all_L1': [0.783, 0.857, 0.959, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.736, 0.829, 0.951, 1.0], 'all_L1': [0.818, 0.872, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.575, 0.74, 0.925, 1.0], 'all_L1': [0.761, 0.85, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.173, 0.085, 0.019, 0.015], 'all_L1': [0.155, 0.079, 0.024, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.124, 0.072, 0.023, 0.014], 'all_L1': [0.126, 0.079, 0.034, 0.024]}), defaultdict(<class 'list'>, {'all_KL': [0.179, 0.091, 0.029, 0.016], 'all_L1': [0.149, 0.083, 0.036, 0.025]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.819 +- 0.014, 0.972 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.672 +- 0.019, 0.977 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.821 +- 0.003, 0.894 +- 0.010
nec class all_L1  =  0.093 +- 0.010, 0.028 +- 0.004, 0.028 +- 0.004
nec class all_KL  =  0.107 +- 0.007, 0.025 +- 0.003, 0.025 +- 0.003
nec_acc_int  =  0.863 +- 0.005, 0.884 +- 0.008, 0.884 +- 0.008

Eval split test
suff++ class all_L1  =  0.787 +- 0.023, 0.860 +- 0.009, 0.951 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.651 +- 0.066, 0.776 +- 0.038, 0.940 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.723 +- 0.007, 0.791 +- 0.001, 0.831 +- 0.004
nec class all_L1  =  0.143 +- 0.012, 0.080 +- 0.002, 0.031 +- 0.005, 0.023 +- 0.002
nec class all_KL  =  0.159 +- 0.025, 0.083 +- 0.008, 0.024 +- 0.004, 0.015 +- 0.001
nec_acc_int  =  0.768 +- 0.003, 0.814 +- 0.003, 0.833 +- 0.006, 0.835 +- 0.004


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.456 +- 0.005, 0.500 +- 0.001, 0.514 +- 0.002
Faith. Armon (L1)= 		  =  0.167 +- 0.015, 0.054 +- 0.007, 0.054 +- 0.007
Faith. GMean (L1)= 	  =  0.276 +- 0.012, 0.164 +- 0.011, 0.166 +- 0.011
Faith. Aritm (KL)= 		  =  0.390 +- 0.009, 0.501 +- 0.001, 0.512 +- 0.001
Faith. Armon (KL)= 		  =  0.185 +- 0.010, 0.048 +- 0.005, 0.048 +- 0.005
Faith. GMean (KL)= 	  =  0.268 +- 0.009, 0.155 +- 0.008, 0.157 +- 0.009

Eval split test
Faith. Aritm (L1)= 		  =  0.465 +- 0.007, 0.470 +- 0.004, 0.491 +- 0.002, 0.512 +- 0.001
Faith. Armon (L1)= 		  =  0.242 +- 0.017, 0.147 +- 0.003, 0.061 +- 0.010, 0.046 +- 0.003
Faith. GMean (L1)= 	  =  0.335 +- 0.011, 0.263 +- 0.002, 0.172 +- 0.014, 0.153 +- 0.006
Faith. Aritm (KL)= 		  =  0.405 +- 0.022, 0.430 +- 0.015, 0.482 +- 0.004, 0.507 +- 0.000
Faith. Armon (KL)= 		  =  0.253 +- 0.029, 0.149 +- 0.012, 0.046 +- 0.008, 0.030 +- 0.002
Faith. GMean (KL)= 	  =  0.319 +- 0.013, 0.253 +- 0.006, 0.149 +- 0.012, 0.122 +- 0.003
Computed for split load_split = id



Completed in  0:05:46.001888  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length soft2
DONE all :)
