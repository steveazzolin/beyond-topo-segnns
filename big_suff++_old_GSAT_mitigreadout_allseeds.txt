
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:11:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:11:38 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:11:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:11:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:11:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:11:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:12:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.9317
Train Loss: 0.3185
ID Validation ACCURACY: 0.9307
ID Validation Loss: 0.3316
ID Test ACCURACY: 0.9283
ID Test Loss: 0.3227
OOD Validation ACCURACY: 0.7380
OOD Validation Loss: 0.8407
OOD Test ACCURACY: 0.5787
OOD Test Loss: 1.3688

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ACCURACY: 0.9291
Train Loss: 0.3281
ID Validation ACCURACY: 0.9273
ID Validation Loss: 0.3407
ID Test ACCURACY: 0.9273
ID Test Loss: 0.3333
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3224
OOD Test ACCURACY: 0.5867
OOD Test Loss: 1.3358

[0m[1;37mINFO[0m: [1mChartInfo 0.9283 0.5787 0.9273 0.5867 0.9273 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.681
WIoU for r=0.3 = 0.557
F1 for r=0.6 = 0.591
WIoU for r=0.6 = 0.478
F1 for r=0.9 = 0.467
WIoU for r=0.9 = 0.348
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.328
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.524
WIoU for r=0.3 = 0.401
F1 for r=0.6 = 0.658
WIoU for r=0.6 = 0.522
F1 for r=0.9 = 0.590
WIoU for r=0.9 = 0.435
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.404


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.507
Model XAI F1 of binarized graphs for r=0.3 =  0.6810075000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.55689
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.47
SUFF++ for r=0.3 class 0 = 0.375 +- 0.273 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 class 1 = 0.446 +- 0.273 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.273 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 all KL = 0.386 +- 0.273 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.3 all L1 = 0.452 +- 0.178 (in-sample avg dev_std = 0.566)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  0.59141375
Model XAI WIoU of binarized graphs for r=0.6 =  0.47775625000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.667
SUFF++ for r=0.6 class 0 = 0.391 +- 0.292 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 1 = 0.574 +- 0.292 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 2 = 0.657 +- 0.292 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all KL = 0.517 +- 0.292 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all L1 = 0.544 +- 0.226 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.46709500000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.34835625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.837
SUFF++ for r=0.9 class 0 = 0.658 +- 0.196 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 1 = 0.79 +- 0.196 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 2 = 0.831 +- 0.196 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all KL = 0.805 +- 0.196 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all L1 = 0.762 +- 0.166 (in-sample avg dev_std = 0.317)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.294
Model XAI F1 of binarized graphs for r=0.3 =  0.5237875
Model XAI WIoU of binarized graphs for r=0.3 =  0.40091875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.3
SUFF++ for r=0.3 class 0 = 0.442 +- 0.254 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 class 1 = 0.466 +- 0.254 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 class 2 = 0.457 +- 0.254 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 all KL = 0.398 +- 0.254 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 all L1 = 0.455 +- 0.147 (in-sample avg dev_std = 0.616)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  0.6582012499999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.52166125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0 = 0.492 +- 0.286 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 class 1 = 0.603 +- 0.286 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 class 2 = 0.866 +- 0.286 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 all KL = 0.644 +- 0.286 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 all L1 = 0.654 +- 0.237 (in-sample avg dev_std = 0.431)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.705
Model XAI F1 of binarized graphs for r=0.9 =  0.58955375
Model XAI WIoU of binarized graphs for r=0.9 =  0.43473875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0 = 0.669 +- 0.167 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.847 +- 0.167 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.801 +- 0.167 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.846 +- 0.167 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.771 +- 0.176 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.6810075000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.55689
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.66 +- 0.252 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 1 = 0.6 +- 0.252 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 2 = 0.602 +- 0.252 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all KL = 0.688 +- 0.252 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all L1 = 0.62 +- 0.154 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  0.59141375
Model XAI WIoU of binarized graphs for r=0.6 =  0.47775625000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.388
NEC for r=0.6 class 0 = 0.583 +- 0.263 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 1 = 0.584 +- 0.263 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 2 = 0.652 +- 0.263 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all KL = 0.68 +- 0.263 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all L1 = 0.607 +- 0.157 (in-sample avg dev_std = 0.538)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.46709500000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.34835625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.48
NEC for r=0.9 class 0 = 0.625 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 class 1 = 0.548 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 class 2 = 0.58 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 all KL = 0.682 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 all L1 = 0.584 +- 0.162 (in-sample avg dev_std = 0.633)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32819000000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.534
NEC for r=1.0 class 0 = 0.554 +- 0.251 (in-sample avg dev_std = 0.654)
NEC for r=1.0 class 1 = 0.497 +- 0.251 (in-sample avg dev_std = 0.654)
NEC for r=1.0 class 2 = 0.574 +- 0.251 (in-sample avg dev_std = 0.654)
NEC for r=1.0 all KL = 0.608 +- 0.251 (in-sample avg dev_std = 0.654)
NEC for r=1.0 all L1 = 0.542 +- 0.171 (in-sample avg dev_std = 0.654)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.294
Model XAI F1 of binarized graphs for r=0.3 =  0.5237875
Model XAI WIoU of binarized graphs for r=0.3 =  0.40091875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.618 +- 0.278 (in-sample avg dev_std = 0.499)
NEC for r=0.3 class 1 = 0.552 +- 0.278 (in-sample avg dev_std = 0.499)
NEC for r=0.3 class 2 = 0.578 +- 0.278 (in-sample avg dev_std = 0.499)
NEC for r=0.3 all KL = 0.62 +- 0.278 (in-sample avg dev_std = 0.499)
NEC for r=0.3 all L1 = 0.583 +- 0.191 (in-sample avg dev_std = 0.499)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  0.6582012499999998
Model XAI WIoU of binarized graphs for r=0.6 =  0.52166125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.612 +- 0.236 (in-sample avg dev_std = 0.610)
NEC for r=0.6 class 1 = 0.588 +- 0.236 (in-sample avg dev_std = 0.610)
NEC for r=0.6 class 2 = 0.617 +- 0.236 (in-sample avg dev_std = 0.610)
NEC for r=0.6 all KL = 0.704 +- 0.236 (in-sample avg dev_std = 0.610)
NEC for r=0.6 all L1 = 0.606 +- 0.150 (in-sample avg dev_std = 0.610)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.705
Model XAI F1 of binarized graphs for r=0.9 =  0.58955375
Model XAI WIoU of binarized graphs for r=0.9 =  0.43473875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.554
NEC for r=0.9 class 0 = 0.543 +- 0.239 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 1 = 0.391 +- 0.239 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 2 = 0.537 +- 0.239 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all KL = 0.515 +- 0.239 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all L1 = 0.492 +- 0.152 (in-sample avg dev_std = 0.537)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.582
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.40385875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.559
NEC for r=1.0 class 0 = 0.443 +- 0.235 (in-sample avg dev_std = 0.487)
NEC for r=1.0 class 1 = 0.215 +- 0.235 (in-sample avg dev_std = 0.487)
NEC for r=1.0 class 2 = 0.503 +- 0.235 (in-sample avg dev_std = 0.487)
NEC for r=1.0 all KL = 0.383 +- 0.235 (in-sample avg dev_std = 0.487)
NEC for r=1.0 all L1 = 0.39 +- 0.201 (in-sample avg dev_std = 0.487)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:14:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:32 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:45 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:47 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:50 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:14:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 56...
[0m[1;37mINFO[0m: [1mCheckpoint 56: 
-----------------------------------
Train ACCURACY: 0.9309
Train Loss: 0.3133
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3230
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3198
OOD Validation ACCURACY: 0.7460
OOD Validation Loss: 0.7757
OOD Test ACCURACY: 0.5250
OOD Test Loss: 1.4601

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 77...
[0m[1;37mINFO[0m: [1mCheckpoint 77: 
-----------------------------------
Train ACCURACY: 0.9315
Train Loss: 0.3139
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3286
ID Test ACCURACY: 0.9293
ID Test Loss: 0.3177
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.3256
OOD Test ACCURACY: 0.5230
OOD Test Loss: 1.9314

[0m[1;37mINFO[0m: [1mChartInfo 0.9287 0.5250 0.9293 0.5230 0.9297 0.9310[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.711
WIoU for r=0.3 = 0.583
F1 for r=0.6 = 0.613
WIoU for r=0.6 = 0.494
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.350
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.326
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.297
WIoU for r=0.3 = 0.208
F1 for r=0.6 = 0.583
WIoU for r=0.6 = 0.453
F1 for r=0.9 = 0.588
WIoU for r=0.9 = 0.428
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.400


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.556
Model XAI F1 of binarized graphs for r=0.3 =  0.7112950000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.58282375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.463
SUFF++ for r=0.3 class 0 = 0.376 +- 0.282 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 1 = 0.552 +- 0.282 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 2 = 0.503 +- 0.282 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all KL = 0.384 +- 0.282 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all L1 = 0.479 +- 0.197 (in-sample avg dev_std = 0.567)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  0.6130325
Model XAI WIoU of binarized graphs for r=0.6 =  0.49401375000000003
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.647
SUFF++ for r=0.6 class 0 = 0.412 +- 0.301 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 class 1 = 0.643 +- 0.301 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 class 2 = 0.567 +- 0.301 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 all KL = 0.475 +- 0.301 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 all L1 = 0.543 +- 0.213 (in-sample avg dev_std = 0.530)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.47448375
Model XAI WIoU of binarized graphs for r=0.9 =  0.35010374999999994
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0 = 0.661 +- 0.200 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 1 = 0.868 +- 0.200 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 2 = 0.799 +- 0.200 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all KL = 0.825 +- 0.200 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all L1 = 0.778 +- 0.175 (in-sample avg dev_std = 0.292)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.29725625
Model XAI WIoU of binarized graphs for r=0.3 =  0.2082725
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.336
SUFF++ for r=0.3 class 0 = 0.583 +- 0.265 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 class 1 = 0.638 +- 0.265 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 class 2 = 0.616 +- 0.265 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 all KL = 0.585 +- 0.265 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.3 all L1 = 0.612 +- 0.152 (in-sample avg dev_std = 0.435)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.48
Model XAI F1 of binarized graphs for r=0.6 =  0.58332375
Model XAI WIoU of binarized graphs for r=0.6 =  0.45264124999999994
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.461
SUFF++ for r=0.6 class 0 = 0.493 +- 0.260 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 1 = 0.58 +- 0.260 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 2 = 0.566 +- 0.260 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all KL = 0.505 +- 0.260 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all L1 = 0.546 +- 0.210 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.704
Model XAI F1 of binarized graphs for r=0.9 =  0.58843
Model XAI WIoU of binarized graphs for r=0.9 =  0.42841999999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.646
SUFF++ for r=0.9 class 0 = 0.651 +- 0.220 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 1 = 0.856 +- 0.220 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 2 = 0.666 +- 0.220 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all KL = 0.768 +- 0.220 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all L1 = 0.722 +- 0.203 (in-sample avg dev_std = 0.352)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.559
Model XAI F1 of binarized graphs for r=0.3 =  0.7112950000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.58282375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.334
NEC for r=0.3 class 0 = 0.668 +- 0.263 (in-sample avg dev_std = 0.479)
NEC for r=0.3 class 1 = 0.596 +- 0.263 (in-sample avg dev_std = 0.479)
NEC for r=0.3 class 2 = 0.636 +- 0.263 (in-sample avg dev_std = 0.479)
NEC for r=0.3 all KL = 0.719 +- 0.263 (in-sample avg dev_std = 0.479)
NEC for r=0.3 all L1 = 0.633 +- 0.176 (in-sample avg dev_std = 0.479)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  0.6130325
Model XAI WIoU of binarized graphs for r=0.6 =  0.49401375000000003
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.377
NEC for r=0.6 class 0 = 0.615 +- 0.259 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 1 = 0.575 +- 0.259 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 2 = 0.629 +- 0.259 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all KL = 0.703 +- 0.259 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all L1 = 0.606 +- 0.178 (in-sample avg dev_std = 0.541)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.47448375
Model XAI WIoU of binarized graphs for r=0.9 =  0.35010374999999994
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.459
NEC for r=0.9 class 0 = 0.626 +- 0.249 (in-sample avg dev_std = 0.623)
NEC for r=0.9 class 1 = 0.525 +- 0.249 (in-sample avg dev_std = 0.623)
NEC for r=0.9 class 2 = 0.602 +- 0.249 (in-sample avg dev_std = 0.623)
NEC for r=0.9 all KL = 0.659 +- 0.249 (in-sample avg dev_std = 0.623)
NEC for r=0.9 all L1 = 0.584 +- 0.175 (in-sample avg dev_std = 0.623)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32550375000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.519
NEC for r=1.0 class 0 = 0.579 +- 0.243 (in-sample avg dev_std = 0.662)
NEC for r=1.0 class 1 = 0.475 +- 0.243 (in-sample avg dev_std = 0.662)
NEC for r=1.0 class 2 = 0.579 +- 0.243 (in-sample avg dev_std = 0.662)
NEC for r=1.0 all KL = 0.629 +- 0.243 (in-sample avg dev_std = 0.662)
NEC for r=1.0 all L1 = 0.544 +- 0.185 (in-sample avg dev_std = 0.662)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.29725625
Model XAI WIoU of binarized graphs for r=0.3 =  0.2082725
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.497 +- 0.305 (in-sample avg dev_std = 0.408)
NEC for r=0.3 class 1 = 0.368 +- 0.305 (in-sample avg dev_std = 0.408)
NEC for r=0.3 class 2 = 0.433 +- 0.305 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all KL = 0.452 +- 0.305 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all L1 = 0.434 +- 0.190 (in-sample avg dev_std = 0.408)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.475
Model XAI F1 of binarized graphs for r=0.6 =  0.58332375
Model XAI WIoU of binarized graphs for r=0.6 =  0.45264124999999994
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.637 +- 0.240 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 1 = 0.601 +- 0.240 (in-sample avg dev_std = 0.574)
NEC for r=0.6 class 2 = 0.608 +- 0.240 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all KL = 0.68 +- 0.240 (in-sample avg dev_std = 0.574)
NEC for r=0.6 all L1 = 0.615 +- 0.139 (in-sample avg dev_std = 0.574)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.702
Model XAI F1 of binarized graphs for r=0.9 =  0.58843
Model XAI WIoU of binarized graphs for r=0.9 =  0.42841999999999997
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.514
NEC for r=0.9 class 0 = 0.562 +- 0.208 (in-sample avg dev_std = 0.601)
NEC for r=0.9 class 1 = 0.479 +- 0.208 (in-sample avg dev_std = 0.601)
NEC for r=0.9 class 2 = 0.548 +- 0.208 (in-sample avg dev_std = 0.601)
NEC for r=0.9 all KL = 0.598 +- 0.208 (in-sample avg dev_std = 0.601)
NEC for r=0.9 all L1 = 0.53 +- 0.142 (in-sample avg dev_std = 0.601)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.527
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39950625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.513
NEC for r=1.0 class 0 = 0.474 +- 0.226 (in-sample avg dev_std = 0.558)
NEC for r=1.0 class 1 = 0.298 +- 0.226 (in-sample avg dev_std = 0.558)
NEC for r=1.0 class 2 = 0.505 +- 0.226 (in-sample avg dev_std = 0.558)
NEC for r=1.0 all KL = 0.472 +- 0.226 (in-sample avg dev_std = 0.558)
NEC for r=1.0 all L1 = 0.428 +- 0.190 (in-sample avg dev_std = 0.558)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:17:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:39 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:41 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:43 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:45 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:17:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9322
Train Loss: 0.3072
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3220
ID Test ACCURACY: 0.9283
ID Test Loss: 0.3118
OOD Validation ACCURACY: 0.5597
OOD Validation Loss: 1.9919
OOD Test ACCURACY: 0.6200
OOD Test Loss: 1.2815

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3340
ID Validation ACCURACY: 0.9270
ID Validation Loss: 0.3459
ID Test ACCURACY: 0.9270
ID Test Loss: 0.3377
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3470
OOD Test ACCURACY: 0.7067
OOD Test Loss: 0.9028

[0m[1;37mINFO[0m: [1mChartInfo 0.9283 0.6200 0.9270 0.7067 0.9270 0.9307[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.687
WIoU for r=0.3 = 0.569
F1 for r=0.6 = 0.584
WIoU for r=0.6 = 0.474
F1 for r=0.9 = 0.462
WIoU for r=0.9 = 0.347
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.331
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.363
WIoU for r=0.3 = 0.261
F1 for r=0.6 = 0.654
WIoU for r=0.6 = 0.508
F1 for r=0.9 = 0.591
WIoU for r=0.9 = 0.433
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.403


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.461
Model XAI F1 of binarized graphs for r=0.3 =  0.6873524999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.568545
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.462
SUFF++ for r=0.3 class 0 = 0.396 +- 0.285 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 class 1 = 0.449 +- 0.285 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 class 2 = 0.564 +- 0.285 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 all KL = 0.409 +- 0.285 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.3 all L1 = 0.472 +- 0.174 (in-sample avg dev_std = 0.550)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.58392125
Model XAI WIoU of binarized graphs for r=0.6 =  0.47413875000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.657
SUFF++ for r=0.6 class 0 = 0.438 +- 0.286 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 1 = 0.632 +- 0.286 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 2 = 0.692 +- 0.286 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all KL = 0.553 +- 0.286 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all L1 = 0.591 +- 0.219 (in-sample avg dev_std = 0.480)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  0.4619
Model XAI WIoU of binarized graphs for r=0.9 =  0.3471775
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.795
SUFF++ for r=0.9 class 0 = 0.595 +- 0.226 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 class 1 = 0.797 +- 0.226 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.226 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 all KL = 0.788 +- 0.226 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 all L1 = 0.753 +- 0.200 (in-sample avg dev_std = 0.328)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.259
Model XAI F1 of binarized graphs for r=0.3 =  0.36343000000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.26069875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.297
SUFF++ for r=0.3 class 0 = 0.421 +- 0.258 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 class 1 = 0.458 +- 0.258 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 class 2 = 0.479 +- 0.258 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all KL = 0.414 +- 0.258 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all L1 = 0.453 +- 0.133 (in-sample avg dev_std = 0.562)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  0.654075
Model XAI WIoU of binarized graphs for r=0.6 =  0.507545
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.574
SUFF++ for r=0.6 class 0 = 0.515 +- 0.269 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 1 = 0.602 +- 0.269 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 2 = 0.727 +- 0.269 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all KL = 0.608 +- 0.269 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all L1 = 0.615 +- 0.229 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  0.590915
Model XAI WIoU of binarized graphs for r=0.9 =  0.4329775
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.683
SUFF++ for r=0.9 class 0 = 0.654 +- 0.177 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 1 = 0.915 +- 0.177 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 2 = 0.763 +- 0.177 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all KL = 0.838 +- 0.177 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all L1 = 0.775 +- 0.181 (in-sample avg dev_std = 0.288)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.6873524999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.568545
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.349
NEC for r=0.3 class 0 = 0.641 +- 0.263 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 1 = 0.579 +- 0.263 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 2 = 0.585 +- 0.263 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all KL = 0.669 +- 0.263 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all L1 = 0.601 +- 0.163 (in-sample avg dev_std = 0.489)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.685
Model XAI F1 of binarized graphs for r=0.6 =  0.58392125
Model XAI WIoU of binarized graphs for r=0.6 =  0.47413875000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.362
NEC for r=0.6 class 0 = 0.621 +- 0.260 (in-sample avg dev_std = 0.536)
NEC for r=0.6 class 1 = 0.588 +- 0.260 (in-sample avg dev_std = 0.536)
NEC for r=0.6 class 2 = 0.645 +- 0.260 (in-sample avg dev_std = 0.536)
NEC for r=0.6 all KL = 0.711 +- 0.260 (in-sample avg dev_std = 0.536)
NEC for r=0.6 all L1 = 0.618 +- 0.163 (in-sample avg dev_std = 0.536)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  0.4619
Model XAI WIoU of binarized graphs for r=0.9 =  0.3471775
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.503
NEC for r=0.9 class 0 = 0.639 +- 0.243 (in-sample avg dev_std = 0.642)
NEC for r=0.9 class 1 = 0.507 +- 0.243 (in-sample avg dev_std = 0.642)
NEC for r=0.9 class 2 = 0.548 +- 0.243 (in-sample avg dev_std = 0.642)
NEC for r=0.9 all KL = 0.666 +- 0.243 (in-sample avg dev_std = 0.642)
NEC for r=0.9 all L1 = 0.564 +- 0.170 (in-sample avg dev_std = 0.642)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.33141999999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.572 +- 0.230 (in-sample avg dev_std = 0.671)
NEC for r=1.0 class 1 = 0.476 +- 0.230 (in-sample avg dev_std = 0.671)
NEC for r=1.0 class 2 = 0.59 +- 0.230 (in-sample avg dev_std = 0.671)
NEC for r=1.0 all KL = 0.646 +- 0.230 (in-sample avg dev_std = 0.671)
NEC for r=1.0 all L1 = 0.546 +- 0.175 (in-sample avg dev_std = 0.671)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.26
Model XAI F1 of binarized graphs for r=0.3 =  0.36343000000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.26069875
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.277
NEC for r=0.3 class 0 = 0.623 +- 0.274 (in-sample avg dev_std = 0.465)
NEC for r=0.3 class 1 = 0.554 +- 0.274 (in-sample avg dev_std = 0.465)
NEC for r=0.3 class 2 = 0.568 +- 0.274 (in-sample avg dev_std = 0.465)
NEC for r=0.3 all KL = 0.612 +- 0.274 (in-sample avg dev_std = 0.465)
NEC for r=0.3 all L1 = 0.582 +- 0.175 (in-sample avg dev_std = 0.465)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.571
Model XAI F1 of binarized graphs for r=0.6 =  0.654075
Model XAI WIoU of binarized graphs for r=0.6 =  0.507545
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.433
NEC for r=0.6 class 0 = 0.598 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.6 class 1 = 0.541 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.6 class 2 = 0.62 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.6 all KL = 0.661 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.6 all L1 = 0.587 +- 0.159 (in-sample avg dev_std = 0.580)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  0.590915
Model XAI WIoU of binarized graphs for r=0.9 =  0.4329775
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.547
NEC for r=0.9 class 0 = 0.513 +- 0.234 (in-sample avg dev_std = 0.539)
NEC for r=0.9 class 1 = 0.374 +- 0.234 (in-sample avg dev_std = 0.539)
NEC for r=0.9 class 2 = 0.532 +- 0.234 (in-sample avg dev_std = 0.539)
NEC for r=0.9 all KL = 0.487 +- 0.234 (in-sample avg dev_std = 0.539)
NEC for r=0.9 all L1 = 0.475 +- 0.162 (in-sample avg dev_std = 0.539)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.624
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.40290875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.575
NEC for r=1.0 class 0 = 0.431 +- 0.231 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 1 = 0.233 +- 0.231 (in-sample avg dev_std = 0.507)
NEC for r=1.0 class 2 = 0.512 +- 0.231 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all KL = 0.388 +- 0.231 (in-sample avg dev_std = 0.507)
NEC for r=1.0 all L1 = 0.395 +- 0.189 (in-sample avg dev_std = 0.507)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:20:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:13 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:27 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:20:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.9306
Train Loss: 0.3148
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3268
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3208
OOD Validation ACCURACY: 0.7540
OOD Validation Loss: 0.6430
OOD Test ACCURACY: 0.6030
OOD Test Loss: 1.2621

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 49...
[0m[1;37mINFO[0m: [1mCheckpoint 49: 
-----------------------------------
Train ACCURACY: 0.9300
Train Loss: 0.3287
ID Validation ACCURACY: 0.9290
ID Validation Loss: 0.3392
ID Test ACCURACY: 0.9273
ID Test Loss: 0.3336
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3413
OOD Test ACCURACY: 0.5520
OOD Test Loss: 1.3589

[0m[1;37mINFO[0m: [1mChartInfo 0.9287 0.6030 0.9273 0.5520 0.9290 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.696
WIoU for r=0.3 = 0.572
F1 for r=0.6 = 0.593
WIoU for r=0.6 = 0.476
F1 for r=0.9 = 0.469
WIoU for r=0.9 = 0.346
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.326
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.363
WIoU for r=0.3 = 0.263
F1 for r=0.6 = 0.651
WIoU for r=0.6 = 0.506
F1 for r=0.9 = 0.590
WIoU for r=0.9 = 0.430
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.400


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.6960487499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5718975000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.447
SUFF++ for r=0.3 class 0 = 0.409 +- 0.289 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 class 1 = 0.526 +- 0.289 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 class 2 = 0.601 +- 0.289 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 all KL = 0.435 +- 0.289 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 all L1 = 0.515 +- 0.184 (in-sample avg dev_std = 0.525)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.647
Model XAI F1 of binarized graphs for r=0.6 =  0.5930599999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.47607875000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.607
SUFF++ for r=0.6 class 0 = 0.398 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 class 1 = 0.572 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 class 2 = 0.639 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 all KL = 0.481 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 all L1 = 0.54 +- 0.216 (in-sample avg dev_std = 0.529)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.869
Model XAI F1 of binarized graphs for r=0.9 =  0.46922375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.34637375000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.815
SUFF++ for r=0.9 class 0 = 0.641 +- 0.202 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.9 class 1 = 0.793 +- 0.202 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.9 class 2 = 0.875 +- 0.202 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.9 all KL = 0.809 +- 0.202 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.9 all L1 = 0.773 +- 0.178 (in-sample avg dev_std = 0.312)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.36345
Model XAI WIoU of binarized graphs for r=0.3 =  0.26312
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.342
SUFF++ for r=0.3 class 0 = 0.548 +- 0.270 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 class 1 = 0.626 +- 0.270 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 class 2 = 0.603 +- 0.270 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 all KL = 0.547 +- 0.270 (in-sample avg dev_std = 0.453)
SUFF++ for r=0.3 all L1 = 0.592 +- 0.142 (in-sample avg dev_std = 0.453)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.431
Model XAI F1 of binarized graphs for r=0.6 =  0.6514862499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.5061950000000001
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.503
SUFF++ for r=0.6 class 0 = 0.441 +- 0.259 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 1 = 0.496 +- 0.259 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 2 = 0.594 +- 0.259 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all KL = 0.479 +- 0.259 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all L1 = 0.511 +- 0.197 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  0.5897987499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.42999000000000004
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.696
SUFF++ for r=0.9 class 0 = 0.61 +- 0.205 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 class 1 = 0.654 +- 0.205 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 class 2 = 0.745 +- 0.205 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 all KL = 0.747 +- 0.205 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.9 all L1 = 0.67 +- 0.180 (in-sample avg dev_std = 0.364)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  0.6960487499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5718975000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.642 +- 0.300 (in-sample avg dev_std = 0.488)
NEC for r=0.3 class 1 = 0.552 +- 0.300 (in-sample avg dev_std = 0.488)
NEC for r=0.3 class 2 = 0.472 +- 0.300 (in-sample avg dev_std = 0.488)
NEC for r=0.3 all KL = 0.638 +- 0.300 (in-sample avg dev_std = 0.488)
NEC for r=0.3 all L1 = 0.553 +- 0.193 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  0.5930599999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.47607875000000005
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.404
NEC for r=0.6 class 0 = 0.611 +- 0.265 (in-sample avg dev_std = 0.553)
NEC for r=0.6 class 1 = 0.614 +- 0.265 (in-sample avg dev_std = 0.553)
NEC for r=0.6 class 2 = 0.608 +- 0.265 (in-sample avg dev_std = 0.553)
NEC for r=0.6 all KL = 0.698 +- 0.265 (in-sample avg dev_std = 0.553)
NEC for r=0.6 all L1 = 0.611 +- 0.157 (in-sample avg dev_std = 0.553)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.46922375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.34637375000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.486
NEC for r=0.9 class 0 = 0.628 +- 0.236 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 1 = 0.565 +- 0.236 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 2 = 0.53 +- 0.236 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all KL = 0.68 +- 0.236 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all L1 = 0.573 +- 0.166 (in-sample avg dev_std = 0.624)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32567125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.505
NEC for r=1.0 class 0 = 0.581 +- 0.240 (in-sample avg dev_std = 0.667)
NEC for r=1.0 class 1 = 0.514 +- 0.240 (in-sample avg dev_std = 0.667)
NEC for r=1.0 class 2 = 0.587 +- 0.240 (in-sample avg dev_std = 0.667)
NEC for r=1.0 all KL = 0.658 +- 0.240 (in-sample avg dev_std = 0.667)
NEC for r=1.0 all L1 = 0.561 +- 0.174 (in-sample avg dev_std = 0.667)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.344
Model XAI F1 of binarized graphs for r=0.3 =  0.36345
Model XAI WIoU of binarized graphs for r=0.3 =  0.26312
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.315
NEC for r=0.3 class 0 = 0.538 +- 0.315 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 1 = 0.359 +- 0.315 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 2 = 0.446 +- 0.315 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all KL = 0.468 +- 0.315 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all L1 = 0.449 +- 0.190 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.428
Model XAI F1 of binarized graphs for r=0.6 =  0.6514862499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.5061950000000001
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.467
NEC for r=0.6 class 0 = 0.612 +- 0.240 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 1 = 0.638 +- 0.240 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 2 = 0.561 +- 0.240 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all KL = 0.672 +- 0.240 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all L1 = 0.603 +- 0.138 (in-sample avg dev_std = 0.540)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  0.5897987499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.42999000000000004
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.49
NEC for r=0.9 class 0 = 0.576 +- 0.225 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 1 = 0.525 +- 0.225 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 2 = 0.475 +- 0.225 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all KL = 0.514 +- 0.225 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all L1 = 0.526 +- 0.132 (in-sample avg dev_std = 0.551)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.608
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39971874999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.552
NEC for r=1.0 class 0 = 0.5 +- 0.216 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 1 = 0.338 +- 0.216 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 2 = 0.537 +- 0.216 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all KL = 0.491 +- 0.216 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all L1 = 0.461 +- 0.173 (in-sample avg dev_std = 0.562)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:23:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:05 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:18 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:20 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:22 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:23:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ACCURACY: 0.9304
Train Loss: 0.3199
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3312
ID Test ACCURACY: 0.9283
ID Test Loss: 0.3283
OOD Validation ACCURACY: 0.6773
OOD Validation Loss: 0.7848
OOD Test ACCURACY: 0.6223
OOD Test Loss: 1.2025

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 12...
[0m[1;37mINFO[0m: [1mCheckpoint 12: 
-----------------------------------
Train ACCURACY: 0.9073
Train Loss: 0.3770
ID Validation ACCURACY: 0.9063
ID Validation Loss: 0.3827
ID Test ACCURACY: 0.9077
ID Test Loss: 0.3822
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3143
OOD Test ACCURACY: 0.5000
OOD Test Loss: 1.8784

[0m[1;37mINFO[0m: [1mChartInfo 0.9283 0.6223 0.9077 0.5000 0.9063 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.705
WIoU for r=0.3 = 0.585
F1 for r=0.6 = 0.602
WIoU for r=0.6 = 0.492
F1 for r=0.9 = 0.472
WIoU for r=0.9 = 0.353
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.330
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.342
WIoU for r=0.3 = 0.241
F1 for r=0.6 = 0.637
WIoU for r=0.6 = 0.493
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.432
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.400


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.498
Model XAI F1 of binarized graphs for r=0.3 =  0.7052425
Model XAI WIoU of binarized graphs for r=0.3 =  0.58472875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.486
SUFF++ for r=0.3 class 0 = 0.392 +- 0.274 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 1 = 0.45 +- 0.274 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 2 = 0.515 +- 0.274 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all KL = 0.372 +- 0.274 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all L1 = 0.454 +- 0.179 (in-sample avg dev_std = 0.594)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  0.601695
Model XAI WIoU of binarized graphs for r=0.6 =  0.49164250000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.65
SUFF++ for r=0.6 class 0 = 0.436 +- 0.288 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 1 = 0.582 +- 0.288 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 2 = 0.596 +- 0.288 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all KL = 0.505 +- 0.288 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all L1 = 0.54 +- 0.212 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.4720325
Model XAI WIoU of binarized graphs for r=0.9 =  0.35331
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0 = 0.654 +- 0.199 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.828 +- 0.199 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.199 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.829 +- 0.199 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.781 +- 0.169 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.252
Model XAI F1 of binarized graphs for r=0.3 =  0.34242625
Model XAI WIoU of binarized graphs for r=0.3 =  0.24100749999999999
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.307
SUFF++ for r=0.3 class 0 = 0.453 +- 0.248 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 class 1 = 0.476 +- 0.248 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 class 2 = 0.481 +- 0.248 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all KL = 0.424 +- 0.248 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all L1 = 0.47 +- 0.154 (in-sample avg dev_std = 0.624)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.526
Model XAI F1 of binarized graphs for r=0.6 =  0.6369612499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.49281624999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.51
SUFF++ for r=0.6 class 0 = 0.456 +- 0.258 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 1 = 0.541 +- 0.258 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 2 = 0.594 +- 0.258 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 all KL = 0.493 +- 0.258 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 all L1 = 0.53 +- 0.203 (in-sample avg dev_std = 0.542)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  0.59173125
Model XAI WIoU of binarized graphs for r=0.9 =  0.43235375000000004
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.646
SUFF++ for r=0.9 class 0 = 0.665 +- 0.179 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.813 +- 0.179 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.731 +- 0.179 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.822 +- 0.179 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.735 +- 0.188 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.7052425
Model XAI WIoU of binarized graphs for r=0.3 =  0.58472875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.324
NEC for r=0.3 class 0 = 0.662 +- 0.261 (in-sample avg dev_std = 0.538)
NEC for r=0.3 class 1 = 0.608 +- 0.261 (in-sample avg dev_std = 0.538)
NEC for r=0.3 class 2 = 0.617 +- 0.261 (in-sample avg dev_std = 0.538)
NEC for r=0.3 all KL = 0.714 +- 0.261 (in-sample avg dev_std = 0.538)
NEC for r=0.3 all L1 = 0.629 +- 0.170 (in-sample avg dev_std = 0.538)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  0.601695
Model XAI WIoU of binarized graphs for r=0.6 =  0.49164250000000004
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.382
NEC for r=0.6 class 0 = 0.616 +- 0.257 (in-sample avg dev_std = 0.550)
NEC for r=0.6 class 1 = 0.627 +- 0.257 (in-sample avg dev_std = 0.550)
NEC for r=0.6 class 2 = 0.65 +- 0.257 (in-sample avg dev_std = 0.550)
NEC for r=0.6 all KL = 0.711 +- 0.257 (in-sample avg dev_std = 0.550)
NEC for r=0.6 all L1 = 0.632 +- 0.155 (in-sample avg dev_std = 0.550)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.4720325
Model XAI WIoU of binarized graphs for r=0.9 =  0.35331
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.506
NEC for r=0.9 class 0 = 0.62 +- 0.227 (in-sample avg dev_std = 0.647)
NEC for r=0.9 class 1 = 0.533 +- 0.227 (in-sample avg dev_std = 0.647)
NEC for r=0.9 class 2 = 0.577 +- 0.227 (in-sample avg dev_std = 0.647)
NEC for r=0.9 all KL = 0.691 +- 0.227 (in-sample avg dev_std = 0.647)
NEC for r=0.9 all L1 = 0.576 +- 0.162 (in-sample avg dev_std = 0.647)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.32994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.51
NEC for r=1.0 class 0 = 0.589 +- 0.231 (in-sample avg dev_std = 0.702)
NEC for r=1.0 class 1 = 0.497 +- 0.231 (in-sample avg dev_std = 0.702)
NEC for r=1.0 class 2 = 0.592 +- 0.231 (in-sample avg dev_std = 0.702)
NEC for r=1.0 all KL = 0.694 +- 0.231 (in-sample avg dev_std = 0.702)
NEC for r=1.0 all L1 = 0.56 +- 0.184 (in-sample avg dev_std = 0.702)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.25
Model XAI F1 of binarized graphs for r=0.3 =  0.34242625
Model XAI WIoU of binarized graphs for r=0.3 =  0.24100749999999999
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.308
NEC for r=0.3 class 0 = 0.616 +- 0.297 (in-sample avg dev_std = 0.522)
NEC for r=0.3 class 1 = 0.49 +- 0.297 (in-sample avg dev_std = 0.522)
NEC for r=0.3 class 2 = 0.548 +- 0.297 (in-sample avg dev_std = 0.522)
NEC for r=0.3 all KL = 0.579 +- 0.297 (in-sample avg dev_std = 0.522)
NEC for r=0.3 all L1 = 0.552 +- 0.212 (in-sample avg dev_std = 0.522)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.525
Model XAI F1 of binarized graphs for r=0.6 =  0.6369612499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.49281624999999996
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.498
NEC for r=0.6 class 0 = 0.619 +- 0.250 (in-sample avg dev_std = 0.545)
NEC for r=0.6 class 1 = 0.595 +- 0.250 (in-sample avg dev_std = 0.545)
NEC for r=0.6 class 2 = 0.615 +- 0.250 (in-sample avg dev_std = 0.545)
NEC for r=0.6 all KL = 0.67 +- 0.250 (in-sample avg dev_std = 0.545)
NEC for r=0.6 all L1 = 0.61 +- 0.156 (in-sample avg dev_std = 0.545)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  0.59173125
Model XAI WIoU of binarized graphs for r=0.9 =  0.43235375000000004
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.536
NEC for r=0.9 class 0 = 0.536 +- 0.237 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 1 = 0.399 +- 0.237 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 2 = 0.543 +- 0.237 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all KL = 0.493 +- 0.237 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all L1 = 0.494 +- 0.154 (in-sample avg dev_std = 0.534)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.621
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39997625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.561
NEC for r=1.0 class 0 = 0.489 +- 0.218 (in-sample avg dev_std = 0.539)
NEC for r=1.0 class 1 = 0.345 +- 0.218 (in-sample avg dev_std = 0.539)
NEC for r=1.0 class 2 = 0.517 +- 0.218 (in-sample avg dev_std = 0.539)
NEC for r=1.0 all KL = 0.468 +- 0.218 (in-sample avg dev_std = 0.539)
NEC for r=1.0 all L1 = 0.452 +- 0.164 (in-sample avg dev_std = 0.539)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.386, 0.517, 0.805, 1.0], 'all_L1': [0.452, 0.544, 0.762, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.384, 0.475, 0.825, 1.0], 'all_L1': [0.479, 0.543, 0.778, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.409, 0.553, 0.788, 1.0], 'all_L1': [0.472, 0.591, 0.753, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.435, 0.481, 0.809, 1.0], 'all_L1': [0.515, 0.54, 0.773, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.372, 0.505, 0.829, 1.0], 'all_L1': [0.454, 0.54, 0.781, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.688, 0.68, 0.682, 0.608], 'all_L1': [0.62, 0.607, 0.584, 0.542]}), defaultdict(<class 'list'>, {'all_KL': [0.719, 0.703, 0.659, 0.629], 'all_L1': [0.633, 0.606, 0.584, 0.544]}), defaultdict(<class 'list'>, {'all_KL': [0.669, 0.711, 0.666, 0.646], 'all_L1': [0.601, 0.618, 0.564, 0.546]}), defaultdict(<class 'list'>, {'all_KL': [0.638, 0.698, 0.68, 0.658], 'all_L1': [0.553, 0.611, 0.573, 0.561]}), defaultdict(<class 'list'>, {'all_KL': [0.714, 0.711, 0.691, 0.694], 'all_L1': [0.629, 0.632, 0.576, 0.56]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.398, 0.644, 0.846, 1.0], 'all_L1': [0.455, 0.654, 0.771, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.585, 0.505, 0.768, 1.0], 'all_L1': [0.612, 0.546, 0.722, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.414, 0.608, 0.838, 1.0], 'all_L1': [0.453, 0.615, 0.775, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.547, 0.479, 0.747, 1.0], 'all_L1': [0.592, 0.511, 0.67, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.424, 0.493, 0.822, 1.0], 'all_L1': [0.47, 0.53, 0.735, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.62, 0.704, 0.515, 0.383], 'all_L1': [0.583, 0.606, 0.492, 0.39]}), defaultdict(<class 'list'>, {'all_KL': [0.452, 0.68, 0.598, 0.472], 'all_L1': [0.434, 0.615, 0.53, 0.428]}), defaultdict(<class 'list'>, {'all_KL': [0.612, 0.661, 0.487, 0.388], 'all_L1': [0.582, 0.587, 0.475, 0.395]}), defaultdict(<class 'list'>, {'all_KL': [0.468, 0.672, 0.514, 0.491], 'all_L1': [0.449, 0.603, 0.526, 0.461]}), defaultdict(<class 'list'>, {'all_KL': [0.579, 0.67, 0.493, 0.468], 'all_L1': [0.552, 0.61, 0.494, 0.452]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.474 +- 0.023, 0.552 +- 0.020, 0.769 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.397 +- 0.022, 0.506 +- 0.028, 0.811 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.466 +- 0.013, 0.646 +- 0.021, 0.829 +- 0.022
nec class all_L1  =  0.607 +- 0.029, 0.615 +- 0.010, 0.576 +- 0.007, 0.551 +- 0.008
nec class all_KL  =  0.686 +- 0.030, 0.701 +- 0.011, 0.676 +- 0.012, 0.647 +- 0.029
nec_acc_int  =  0.337 +- 0.009, 0.383 +- 0.014, 0.487 +- 0.017, 0.520 +- 0.011

Eval split test
suff++ class all_L1  =  0.516 +- 0.070, 0.571 +- 0.054, 0.735 +- 0.038, 1.000 +- 0.000
suff++ class all_KL  =  0.474 +- 0.077, 0.546 +- 0.067, 0.804 +- 0.039, 1.000 +- 0.000
suff++_acc_int  =  0.317 +- 0.019, 0.541 +- 0.068, 0.672 +- 0.022
nec class all_L1  =  0.520 +- 0.065, 0.604 +- 0.009, 0.503 +- 0.021, 0.425 +- 0.029
nec class all_KL  =  0.546 +- 0.072, 0.677 +- 0.015, 0.521 +- 0.040, 0.440 +- 0.046
nec_acc_int  =  0.318 +- 0.025, 0.458 +- 0.025, 0.528 +- 0.024, 0.552 +- 0.021


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.541 +- 0.008, 0.583 +- 0.011, 0.673 +- 0.008, 0.775 +- 0.004
Faith. Armon (L1)= 		  =  0.532 +- 0.008, 0.581 +- 0.012, 0.659 +- 0.008, 0.710 +- 0.007
Faith. GMean (L1)= 	  =  0.536 +- 0.007, 0.582 +- 0.012, 0.666 +- 0.008, 0.742 +- 0.006
Faith. Aritm (KL)= 		  =  0.541 +- 0.006, 0.603 +- 0.016, 0.743 +- 0.010, 0.823 +- 0.014
Faith. Armon (KL)= 		  =  0.502 +- 0.010, 0.587 +- 0.020, 0.737 +- 0.010, 0.785 +- 0.021
Faith. GMean (KL)= 	  =  0.521 +- 0.005, 0.595 +- 0.018, 0.740 +- 0.010, 0.804 +- 0.018

Eval split test
Faith. Aritm (L1)= 		  =  0.518 +- 0.004, 0.588 +- 0.026, 0.619 +- 0.012, 0.713 +- 0.014
Faith. Armon (L1)= 		  =  0.509 +- 0.001, 0.586 +- 0.027, 0.596 +- 0.009, 0.596 +- 0.028
Faith. GMean (L1)= 	  =  0.514 +- 0.002, 0.587 +- 0.026, 0.607 +- 0.009, 0.652 +- 0.022
Faith. Aritm (KL)= 		  =  0.510 +- 0.006, 0.612 +- 0.037, 0.663 +- 0.019, 0.720 +- 0.023
Faith. Armon (KL)= 		  =  0.497 +- 0.009, 0.603 +- 0.043, 0.631 +- 0.023, 0.610 +- 0.044
Faith. GMean (KL)= 	  =  0.503 +- 0.007, 0.607 +- 0.040, 0.647 +- 0.020, 0.663 +- 0.035
Computed for split load_split = id



Completed in  0:14:29.563814  for GSATGIN GOODMotif/basis



DONE GSAT GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:26:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:26:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.9301
Train Loss: 0.3224
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.3055
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3402
OOD Validation ACCURACY: 0.7387
OOD Validation Loss: 0.6602
OOD Test ACCURACY: 0.6417
OOD Test Loss: 1.1222

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 28...
[0m[1;37mINFO[0m: [1mCheckpoint 28: 
-----------------------------------
Train ACCURACY: 0.9281
Train Loss: 0.3370
ID Validation ACCURACY: 0.9327
ID Validation Loss: 0.3225
ID Test ACCURACY: 0.9240
ID Test Loss: 0.3558
OOD Validation ACCURACY: 0.9200
OOD Validation Loss: 0.4528
OOD Test ACCURACY: 0.6980
OOD Test Loss: 1.4036

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.6417 0.9240 0.6980 0.9327 0.9200[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.717
WIoU for r=0.3 = 0.601
F1 for r=0.6 = 0.592
WIoU for r=0.6 = 0.474
F1 for r=0.9 = 0.466
WIoU for r=0.9 = 0.344
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.330
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.686
WIoU for r=0.3 = 0.551
F1 for r=0.6 = 0.513
WIoU for r=0.6 = 0.377
F1 for r=0.9 = 0.399
WIoU for r=0.9 = 0.273
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.265


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.426
Model XAI F1 of binarized graphs for r=0.3 =  0.71667
Model XAI WIoU of binarized graphs for r=0.3 =  0.60144125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.444
SUFF++ for r=0.3 class 0 = 0.419 +- 0.274 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 1 = 0.505 +- 0.274 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 2 = 0.491 +- 0.274 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all KL = 0.38 +- 0.274 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all L1 = 0.472 +- 0.185 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  0.59162625
Model XAI WIoU of binarized graphs for r=0.6 =  0.47407250000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.652
SUFF++ for r=0.6 class 0 = 0.431 +- 0.307 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.307 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.631 +- 0.307 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.57 +- 0.307 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.612 +- 0.230 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.46625875000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.34398874999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0 = 0.615 +- 0.219 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 1 = 0.842 +- 0.219 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 2 = 0.783 +- 0.219 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all KL = 0.782 +- 0.219 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all L1 = 0.747 +- 0.186 (in-sample avg dev_std = 0.341)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.496
Model XAI F1 of binarized graphs for r=0.3 =  0.68614875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5508675000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.544
SUFF++ for r=0.3 class 0 = 0.435 +- 0.320 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 class 1 = 0.64 +- 0.320 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 class 2 = 0.634 +- 0.320 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all KL = 0.509 +- 0.320 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all L1 = 0.572 +- 0.242 (in-sample avg dev_std = 0.500)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.755
Model XAI F1 of binarized graphs for r=0.6 =  0.5133225
Model XAI WIoU of binarized graphs for r=0.6 =  0.37650625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.693
SUFF++ for r=0.6 class 0 = 0.454 +- 0.227 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 1 = 0.821 +- 0.227 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 2 = 0.69 +- 0.227 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all KL = 0.672 +- 0.227 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all L1 = 0.659 +- 0.206 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  0.3989425
Model XAI WIoU of binarized graphs for r=0.9 =  0.272865
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.663
SUFF++ for r=0.9 class 0 = 0.529 +- 0.239 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 class 1 = 0.763 +- 0.239 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 class 2 = 0.805 +- 0.239 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 all KL = 0.736 +- 0.239 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 all L1 = 0.701 +- 0.210 (in-sample avg dev_std = 0.347)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.428
Model XAI F1 of binarized graphs for r=0.3 =  0.71667
Model XAI WIoU of binarized graphs for r=0.3 =  0.60144125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.337
NEC for r=0.3 class 0 = 0.641 +- 0.304 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 1 = 0.506 +- 0.304 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 2 = 0.681 +- 0.304 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all KL = 0.703 +- 0.304 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all L1 = 0.609 +- 0.205 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  0.59162625
Model XAI WIoU of binarized graphs for r=0.6 =  0.47407250000000006
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.394
NEC for r=0.6 class 0 = 0.597 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 1 = 0.444 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 2 = 0.658 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all KL = 0.651 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all L1 = 0.566 +- 0.211 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.46625875000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.34398874999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.503
NEC for r=0.9 class 0 = 0.612 +- 0.239 (in-sample avg dev_std = 0.626)
NEC for r=0.9 class 1 = 0.469 +- 0.239 (in-sample avg dev_std = 0.626)
NEC for r=0.9 class 2 = 0.586 +- 0.239 (in-sample avg dev_std = 0.626)
NEC for r=0.9 all KL = 0.643 +- 0.239 (in-sample avg dev_std = 0.626)
NEC for r=0.9 all L1 = 0.556 +- 0.167 (in-sample avg dev_std = 0.626)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.3296275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.559
NEC for r=1.0 class 0 = 0.553 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 1 = 0.407 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 2 = 0.591 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all KL = 0.598 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all L1 = 0.516 +- 0.181 (in-sample avg dev_std = 0.655)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.496
Model XAI F1 of binarized graphs for r=0.3 =  0.68614875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5508675000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.417
NEC for r=0.3 class 0 = 0.637 +- 0.232 (in-sample avg dev_std = 0.578)
NEC for r=0.3 class 1 = 0.518 +- 0.232 (in-sample avg dev_std = 0.578)
NEC for r=0.3 class 2 = 0.614 +- 0.232 (in-sample avg dev_std = 0.578)
NEC for r=0.3 all KL = 0.718 +- 0.232 (in-sample avg dev_std = 0.578)
NEC for r=0.3 all L1 = 0.588 +- 0.166 (in-sample avg dev_std = 0.578)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.755
Model XAI F1 of binarized graphs for r=0.6 =  0.5133225
Model XAI WIoU of binarized graphs for r=0.6 =  0.37650625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.572 +- 0.274 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 1 = 0.432 +- 0.274 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 2 = 0.643 +- 0.274 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all KL = 0.617 +- 0.274 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all L1 = 0.548 +- 0.185 (in-sample avg dev_std = 0.562)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  0.3989425
Model XAI WIoU of binarized graphs for r=0.9 =  0.272865
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.534
NEC for r=0.9 class 0 = 0.625 +- 0.311 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 1 = 0.429 +- 0.311 (in-sample avg dev_std = 0.576)
NEC for r=0.9 class 2 = 0.494 +- 0.311 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all KL = 0.588 +- 0.311 (in-sample avg dev_std = 0.576)
NEC for r=0.9 all L1 = 0.514 +- 0.189 (in-sample avg dev_std = 0.576)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.665
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26548625000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.566
NEC for r=1.0 class 0 = 0.528 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 1 = 0.407 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 2 = 0.377 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all KL = 0.463 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all L1 = 0.436 +- 0.166 (in-sample avg dev_std = 0.531)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:29:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:29:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9294
Train Loss: 0.3188
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3050
ID Test ACCURACY: 0.9253
ID Test Loss: 0.3427
OOD Validation ACCURACY: 0.9233
OOD Validation Loss: 0.3537
OOD Test ACCURACY: 0.5027
OOD Test Loss: 1.2959

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ACCURACY: 0.9271
Train Loss: 0.3300
ID Validation ACCURACY: 0.9323
ID Validation Loss: 0.3113
ID Test ACCURACY: 0.9240
ID Test Loss: 0.3472
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.3600
OOD Test ACCURACY: 0.5900
OOD Test Loss: 1.4067

[0m[1;37mINFO[0m: [1mChartInfo 0.9253 0.5027 0.9240 0.5900 0.9323 0.9297[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.681
WIoU for r=0.3 = 0.567
F1 for r=0.6 = 0.576
WIoU for r=0.6 = 0.456
F1 for r=0.9 = 0.458
WIoU for r=0.9 = 0.335
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.329
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.633
WIoU for r=0.3 = 0.516
F1 for r=0.6 = 0.497
WIoU for r=0.6 = 0.369
F1 for r=0.9 = 0.398
WIoU for r=0.9 = 0.269
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.262


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.429
Model XAI F1 of binarized graphs for r=0.3 =  0.68094125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5674275
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.407
SUFF++ for r=0.3 class 0 = 0.404 +- 0.287 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 1 = 0.414 +- 0.287 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 class 2 = 0.512 +- 0.287 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all KL = 0.39 +- 0.287 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.3 all L1 = 0.443 +- 0.173 (in-sample avg dev_std = 0.551)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  0.5759274999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.45621875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.418 +- 0.277 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.639 +- 0.277 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.706 +- 0.277 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.554 +- 0.277 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.587 +- 0.209 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  0.4577737500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.3345274999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0 = 0.564 +- 0.225 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 class 1 = 0.811 +- 0.225 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 class 2 = 0.846 +- 0.225 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 all KL = 0.778 +- 0.225 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 all L1 = 0.74 +- 0.192 (in-sample avg dev_std = 0.354)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.63324625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5162574999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.477
SUFF++ for r=0.3 class 0 = 0.428 +- 0.319 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 1 = 0.58 +- 0.319 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 2 = 0.557 +- 0.319 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 all KL = 0.523 +- 0.319 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 all L1 = 0.523 +- 0.229 (in-sample avg dev_std = 0.481)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  0.49685
Model XAI WIoU of binarized graphs for r=0.6 =  0.36898875000000003
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0 = 0.486 +- 0.233 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1 = 0.723 +- 0.233 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.233 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.722 +- 0.233 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.663 +- 0.201 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.645
Model XAI F1 of binarized graphs for r=0.9 =  0.39836125
Model XAI WIoU of binarized graphs for r=0.9 =  0.26933625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.708
SUFF++ for r=0.9 class 0 = 0.482 +- 0.247 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 1 = 0.678 +- 0.247 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 2 = 0.85 +- 0.247 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all KL = 0.741 +- 0.247 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all L1 = 0.672 +- 0.222 (in-sample avg dev_std = 0.304)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.431
Model XAI F1 of binarized graphs for r=0.3 =  0.68094125
Model XAI WIoU of binarized graphs for r=0.3 =  0.5674275
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.322
NEC for r=0.3 class 0 = 0.597 +- 0.282 (in-sample avg dev_std = 0.504)
NEC for r=0.3 class 1 = 0.607 +- 0.282 (in-sample avg dev_std = 0.504)
NEC for r=0.3 class 2 = 0.654 +- 0.282 (in-sample avg dev_std = 0.504)
NEC for r=0.3 all KL = 0.68 +- 0.282 (in-sample avg dev_std = 0.504)
NEC for r=0.3 all L1 = 0.619 +- 0.173 (in-sample avg dev_std = 0.504)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  0.5759274999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.45621875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.362
NEC for r=0.6 class 0 = 0.576 +- 0.275 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 1 = 0.571 +- 0.275 (in-sample avg dev_std = 0.543)
NEC for r=0.6 class 2 = 0.662 +- 0.275 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all KL = 0.677 +- 0.275 (in-sample avg dev_std = 0.543)
NEC for r=0.6 all L1 = 0.603 +- 0.161 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  0.4577737500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.3345274999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.496
NEC for r=0.9 class 0 = 0.605 +- 0.246 (in-sample avg dev_std = 0.625)
NEC for r=0.9 class 1 = 0.509 +- 0.246 (in-sample avg dev_std = 0.625)
NEC for r=0.9 class 2 = 0.572 +- 0.246 (in-sample avg dev_std = 0.625)
NEC for r=0.9 all KL = 0.638 +- 0.246 (in-sample avg dev_std = 0.625)
NEC for r=0.9 all L1 = 0.562 +- 0.161 (in-sample avg dev_std = 0.625)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.32874749999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.539
NEC for r=1.0 class 0 = 0.553 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 class 1 = 0.475 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 class 2 = 0.562 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 all KL = 0.598 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 all L1 = 0.53 +- 0.167 (in-sample avg dev_std = 0.658)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.63324625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5162574999999999
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.377
NEC for r=0.3 class 0 = 0.561 +- 0.291 (in-sample avg dev_std = 0.573)
NEC for r=0.3 class 1 = 0.497 +- 0.291 (in-sample avg dev_std = 0.573)
NEC for r=0.3 class 2 = 0.677 +- 0.291 (in-sample avg dev_std = 0.573)
NEC for r=0.3 all KL = 0.61 +- 0.291 (in-sample avg dev_std = 0.573)
NEC for r=0.3 all L1 = 0.578 +- 0.150 (in-sample avg dev_std = 0.573)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  0.49685
Model XAI WIoU of binarized graphs for r=0.6 =  0.36898875000000003
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.44
NEC for r=0.6 class 0 = 0.57 +- 0.275 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 1 = 0.442 +- 0.275 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 2 = 0.602 +- 0.275 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all KL = 0.55 +- 0.275 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all L1 = 0.537 +- 0.159 (in-sample avg dev_std = 0.541)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.645
Model XAI F1 of binarized graphs for r=0.9 =  0.39836125
Model XAI WIoU of binarized graphs for r=0.9 =  0.26933625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.565 +- 0.307 (in-sample avg dev_std = 0.549)
NEC for r=0.9 class 1 = 0.443 +- 0.307 (in-sample avg dev_std = 0.549)
NEC for r=0.9 class 2 = 0.495 +- 0.307 (in-sample avg dev_std = 0.549)
NEC for r=0.9 all KL = 0.536 +- 0.307 (in-sample avg dev_std = 0.549)
NEC for r=0.9 all L1 = 0.5 +- 0.171 (in-sample avg dev_std = 0.549)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.526
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26152749999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.504
NEC for r=1.0 class 0 = 0.464 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 1 = 0.465 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 2 = 0.312 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all KL = 0.44 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all L1 = 0.414 +- 0.166 (in-sample avg dev_std = 0.478)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:31:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:31:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9308
Train Loss: 0.3191
ID Validation ACCURACY: 0.9370
ID Validation Loss: 0.3044
ID Test ACCURACY: 0.9263
ID Test Loss: 0.3380
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.3803
OOD Test ACCURACY: 0.6390
OOD Test Loss: 1.0273

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 41...
[0m[1;37mINFO[0m: [1mCheckpoint 41: 
-----------------------------------
Train ACCURACY: 0.9197
Train Loss: 0.3431
ID Validation ACCURACY: 0.9267
ID Validation Loss: 0.3258
ID Test ACCURACY: 0.9177
ID Test Loss: 0.3707
OOD Validation ACCURACY: 0.9290
OOD Validation Loss: 0.3668
OOD Test ACCURACY: 0.7483
OOD Test Loss: 1.8033

[0m[1;37mINFO[0m: [1mChartInfo 0.9263 0.6390 0.9177 0.7483 0.9267 0.9290[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.702
WIoU for r=0.3 = 0.579
F1 for r=0.6 = 0.573
WIoU for r=0.6 = 0.450
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.349
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.329
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.677
WIoU for r=0.3 = 0.544
F1 for r=0.6 = 0.523
WIoU for r=0.6 = 0.384
F1 for r=0.9 = 0.411
WIoU for r=0.9 = 0.281
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.264


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.441
Model XAI F1 of binarized graphs for r=0.3 =  0.7018137499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.579065
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.415
SUFF++ for r=0.3 class 0 = 0.379 +- 0.255 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 class 1 = 0.432 +- 0.255 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 class 2 = 0.49 +- 0.255 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 all KL = 0.393 +- 0.255 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 all L1 = 0.433 +- 0.155 (in-sample avg dev_std = 0.556)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  0.5733849999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.45047625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.442 +- 0.258 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 class 1 = 0.571 +- 0.258 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 class 2 = 0.665 +- 0.258 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 all KL = 0.535 +- 0.258 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 all L1 = 0.559 +- 0.192 (in-sample avg dev_std = 0.499)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.47448875
Model XAI WIoU of binarized graphs for r=0.9 =  0.34942875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0 = 0.67 +- 0.180 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 1 = 0.816 +- 0.180 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 2 = 0.803 +- 0.180 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 all KL = 0.814 +- 0.180 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.161 (in-sample avg dev_std = 0.311)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.479
Model XAI F1 of binarized graphs for r=0.3 =  0.6768700000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.54437125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.522
SUFF++ for r=0.3 class 0 = 0.433 +- 0.290 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 class 1 = 0.512 +- 0.290 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 class 2 = 0.564 +- 0.290 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 all KL = 0.437 +- 0.290 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 all L1 = 0.504 +- 0.208 (in-sample avg dev_std = 0.575)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  0.52257
Model XAI WIoU of binarized graphs for r=0.6 =  0.38445
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.487 +- 0.236 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1 = 0.716 +- 0.236 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 2 = 0.73 +- 0.236 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.663 +- 0.236 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.647 +- 0.185 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.724
Model XAI F1 of binarized graphs for r=0.9 =  0.41138374999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.28105375000000005
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.669
SUFF++ for r=0.9 class 0 = 0.467 +- 0.245 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 1 = 0.741 +- 0.245 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 2 = 0.809 +- 0.245 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all KL = 0.75 +- 0.245 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all L1 = 0.675 +- 0.211 (in-sample avg dev_std = 0.295)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.442
Model XAI F1 of binarized graphs for r=0.3 =  0.7018137499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.579065
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.294
NEC for r=0.3 class 0 = 0.695 +- 0.265 (in-sample avg dev_std = 0.491)
NEC for r=0.3 class 1 = 0.546 +- 0.265 (in-sample avg dev_std = 0.491)
NEC for r=0.3 class 2 = 0.658 +- 0.265 (in-sample avg dev_std = 0.491)
NEC for r=0.3 all KL = 0.678 +- 0.265 (in-sample avg dev_std = 0.491)
NEC for r=0.3 all L1 = 0.632 +- 0.168 (in-sample avg dev_std = 0.491)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  0.5733849999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.45047625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.368
NEC for r=0.6 class 0 = 0.621 +- 0.269 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 1 = 0.548 +- 0.269 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 2 = 0.66 +- 0.269 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all KL = 0.671 +- 0.269 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all L1 = 0.609 +- 0.164 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.47448875
Model XAI WIoU of binarized graphs for r=0.9 =  0.34942875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.602 +- 0.228 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 1 = 0.508 +- 0.228 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 2 = 0.578 +- 0.228 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all KL = 0.626 +- 0.228 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all L1 = 0.562 +- 0.152 (in-sample avg dev_std = 0.631)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.32868875000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.553 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 class 1 = 0.459 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 class 2 = 0.559 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 all KL = 0.567 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 all L1 = 0.523 +- 0.163 (in-sample avg dev_std = 0.641)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.48
Model XAI F1 of binarized graphs for r=0.3 =  0.6768700000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.54437125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.625 +- 0.237 (in-sample avg dev_std = 0.587)
NEC for r=0.3 class 1 = 0.646 +- 0.237 (in-sample avg dev_std = 0.587)
NEC for r=0.3 class 2 = 0.696 +- 0.237 (in-sample avg dev_std = 0.587)
NEC for r=0.3 all KL = 0.747 +- 0.237 (in-sample avg dev_std = 0.587)
NEC for r=0.3 all L1 = 0.656 +- 0.133 (in-sample avg dev_std = 0.587)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  0.52257
Model XAI WIoU of binarized graphs for r=0.6 =  0.38445
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.435
NEC for r=0.6 class 0 = 0.59 +- 0.289 (in-sample avg dev_std = 0.559)
NEC for r=0.6 class 1 = 0.514 +- 0.289 (in-sample avg dev_std = 0.559)
NEC for r=0.6 class 2 = 0.621 +- 0.289 (in-sample avg dev_std = 0.559)
NEC for r=0.6 all KL = 0.622 +- 0.289 (in-sample avg dev_std = 0.559)
NEC for r=0.6 all L1 = 0.574 +- 0.165 (in-sample avg dev_std = 0.559)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.724
Model XAI F1 of binarized graphs for r=0.9 =  0.41138374999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.28105375000000005
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.609 +- 0.303 (in-sample avg dev_std = 0.523)
NEC for r=0.9 class 1 = 0.433 +- 0.303 (in-sample avg dev_std = 0.523)
NEC for r=0.9 class 2 = 0.468 +- 0.303 (in-sample avg dev_std = 0.523)
NEC for r=0.9 all KL = 0.504 +- 0.303 (in-sample avg dev_std = 0.523)
NEC for r=0.9 all L1 = 0.501 +- 0.176 (in-sample avg dev_std = 0.523)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.66
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26439750000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.488 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 1 = 0.411 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 2 = 0.384 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all KL = 0.404 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all L1 = 0.427 +- 0.151 (in-sample avg dev_std = 0.475)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:34:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:34:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9309
Train Loss: 0.3182
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.3060
ID Test ACCURACY: 0.9263
ID Test Loss: 0.3404
OOD Validation ACCURACY: 0.9267
OOD Validation Loss: 0.3565
OOD Test ACCURACY: 0.7483
OOD Test Loss: 0.8473

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 44...
[0m[1;37mINFO[0m: [1mCheckpoint 44: 
-----------------------------------
Train ACCURACY: 0.9266
Train Loss: 0.3333
ID Validation ACCURACY: 0.9320
ID Validation Loss: 0.3169
ID Test ACCURACY: 0.9243
ID Test Loss: 0.3533
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.3816
OOD Test ACCURACY: 0.7223
OOD Test Loss: 1.4805

[0m[1;37mINFO[0m: [1mChartInfo 0.9263 0.7483 0.9243 0.7223 0.9320 0.9297[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.671
WIoU for r=0.3 = 0.545
F1 for r=0.6 = 0.592
WIoU for r=0.6 = 0.469
F1 for r=0.9 = 0.466
WIoU for r=0.9 = 0.340
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.328
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.527
WIoU for r=0.3 = 0.407
F1 for r=0.6 = 0.463
WIoU for r=0.6 = 0.331
F1 for r=0.9 = 0.395
WIoU for r=0.9 = 0.266
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.261


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.41
Model XAI F1 of binarized graphs for r=0.3 =  0.6707912500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.54540375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.41
SUFF++ for r=0.3 class 0 = 0.4 +- 0.265 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 class 1 = 0.394 +- 0.265 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 class 2 = 0.497 +- 0.265 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all KL = 0.416 +- 0.265 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all L1 = 0.43 +- 0.152 (in-sample avg dev_std = 0.524)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.735
Model XAI F1 of binarized graphs for r=0.6 =  0.59174
Model XAI WIoU of binarized graphs for r=0.6 =  0.46887749999999995
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0 = 0.484 +- 0.264 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 1 = 0.584 +- 0.264 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 2 = 0.658 +- 0.264 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all KL = 0.547 +- 0.264 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all L1 = 0.575 +- 0.181 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.46595249999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.3404125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.851
SUFF++ for r=0.9 class 0 = 0.652 +- 0.177 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 1 = 0.825 +- 0.177 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 2 = 0.776 +- 0.177 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all KL = 0.816 +- 0.177 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all L1 = 0.751 +- 0.154 (in-sample avg dev_std = 0.321)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.5269637500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.40651875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.452
SUFF++ for r=0.3 class 0 = 0.404 +- 0.296 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 class 1 = 0.489 +- 0.296 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 class 2 = 0.515 +- 0.296 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 all KL = 0.456 +- 0.296 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.3 all L1 = 0.47 +- 0.193 (in-sample avg dev_std = 0.504)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.685
Model XAI F1 of binarized graphs for r=0.6 =  0.4630375000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.3311125
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.636
SUFF++ for r=0.6 class 0 = 0.466 +- 0.215 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 1 = 0.654 +- 0.215 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 2 = 0.673 +- 0.215 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all KL = 0.673 +- 0.215 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all L1 = 0.599 +- 0.183 (in-sample avg dev_std = 0.406)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.636
Model XAI F1 of binarized graphs for r=0.9 =  0.39482625
Model XAI WIoU of binarized graphs for r=0.9 =  0.2657375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.639
SUFF++ for r=0.9 class 0 = 0.617 +- 0.166 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 1 = 0.721 +- 0.166 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 2 = 0.802 +- 0.166 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all KL = 0.785 +- 0.166 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all L1 = 0.715 +- 0.149 (in-sample avg dev_std = 0.316)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.6707912500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.54540375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.296
NEC for r=0.3 class 0 = 0.646 +- 0.251 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 1 = 0.64 +- 0.251 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 2 = 0.653 +- 0.251 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all KL = 0.672 +- 0.251 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all L1 = 0.646 +- 0.134 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.738
Model XAI F1 of binarized graphs for r=0.6 =  0.59174
Model XAI WIoU of binarized graphs for r=0.6 =  0.46887749999999995
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.418
NEC for r=0.6 class 0 = 0.575 +- 0.269 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 1 = 0.524 +- 0.269 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 2 = 0.63 +- 0.269 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all KL = 0.629 +- 0.269 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all L1 = 0.576 +- 0.178 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  0.46595249999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.3404125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.506
NEC for r=0.9 class 0 = 0.603 +- 0.214 (in-sample avg dev_std = 0.590)
NEC for r=0.9 class 1 = 0.517 +- 0.214 (in-sample avg dev_std = 0.590)
NEC for r=0.9 class 2 = 0.564 +- 0.214 (in-sample avg dev_std = 0.590)
NEC for r=0.9 all KL = 0.59 +- 0.214 (in-sample avg dev_std = 0.590)
NEC for r=0.9 all L1 = 0.561 +- 0.143 (in-sample avg dev_std = 0.590)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.32846000000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.542
NEC for r=1.0 class 0 = 0.549 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 class 1 = 0.468 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 class 2 = 0.565 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 all KL = 0.575 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 all L1 = 0.527 +- 0.167 (in-sample avg dev_std = 0.646)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.5269637500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.40651875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.357
NEC for r=0.3 class 0 = 0.65 +- 0.287 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 1 = 0.558 +- 0.287 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 2 = 0.701 +- 0.287 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all KL = 0.675 +- 0.287 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all L1 = 0.635 +- 0.164 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.685
Model XAI F1 of binarized graphs for r=0.6 =  0.4630375000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.3311125
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.441
NEC for r=0.6 class 0 = 0.528 +- 0.261 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 1 = 0.497 +- 0.261 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 2 = 0.615 +- 0.261 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all KL = 0.518 +- 0.261 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all L1 = 0.547 +- 0.162 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.636
Model XAI F1 of binarized graphs for r=0.9 =  0.39482625
Model XAI WIoU of binarized graphs for r=0.9 =  0.2657375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.58 +- 0.283 (in-sample avg dev_std = 0.538)
NEC for r=0.9 class 1 = 0.445 +- 0.283 (in-sample avg dev_std = 0.538)
NEC for r=0.9 class 2 = 0.503 +- 0.283 (in-sample avg dev_std = 0.538)
NEC for r=0.9 all KL = 0.53 +- 0.283 (in-sample avg dev_std = 0.538)
NEC for r=0.9 all L1 = 0.508 +- 0.169 (in-sample avg dev_std = 0.538)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.751
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26060125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0 = 0.504 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 class 1 = 0.405 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 class 2 = 0.419 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 all KL = 0.431 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 all L1 = 0.441 +- 0.155 (in-sample avg dev_std = 0.494)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:37:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:37:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9288
Train Loss: 0.3202
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3069
ID Test ACCURACY: 0.9253
ID Test Loss: 0.3425
OOD Validation ACCURACY: 0.9070
OOD Validation Loss: 0.4360
OOD Test ACCURACY: 0.6230
OOD Test Loss: 1.1103

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ACCURACY: 0.9275
Train Loss: 0.3347
ID Validation ACCURACY: 0.9320
ID Validation Loss: 0.3170
ID Test ACCURACY: 0.9240
ID Test Loss: 0.3484
OOD Validation ACCURACY: 0.9283
OOD Validation Loss: 0.3823
OOD Test ACCURACY: 0.6687
OOD Test Loss: 1.1273

[0m[1;37mINFO[0m: [1mChartInfo 0.9253 0.6230 0.9240 0.6687 0.9320 0.9283[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.702
WIoU for r=0.3 = 0.581
F1 for r=0.6 = 0.585
WIoU for r=0.6 = 0.461
F1 for r=0.9 = 0.471
WIoU for r=0.9 = 0.346
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.330
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.720
WIoU for r=0.3 = 0.604
F1 for r=0.6 = 0.555
WIoU for r=0.6 = 0.413
F1 for r=0.9 = 0.420
WIoU for r=0.9 = 0.290
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.268


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.436
Model XAI F1 of binarized graphs for r=0.3 =  0.7019175
Model XAI WIoU of binarized graphs for r=0.3 =  0.58067875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.423
SUFF++ for r=0.3 class 0 = 0.398 +- 0.256 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 1 = 0.459 +- 0.256 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 2 = 0.492 +- 0.256 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all KL = 0.409 +- 0.256 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all L1 = 0.449 +- 0.156 (in-sample avg dev_std = 0.584)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  0.5851762500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.46084374999999994
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.664
SUFF++ for r=0.6 class 0 = 0.448 +- 0.253 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 class 1 = 0.641 +- 0.253 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.253 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 all KL = 0.578 +- 0.253 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 all L1 = 0.588 +- 0.198 (in-sample avg dev_std = 0.441)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.4705975
Model XAI WIoU of binarized graphs for r=0.9 =  0.3463275
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0 = 0.625 +- 0.199 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 1 = 0.789 +- 0.199 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 2 = 0.8 +- 0.199 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all KL = 0.793 +- 0.199 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all L1 = 0.738 +- 0.178 (in-sample avg dev_std = 0.319)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.720165
Model XAI WIoU of binarized graphs for r=0.3 =  0.60378375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0 = 0.432 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 class 1 = 0.562 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 class 2 = 0.546 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 all KL = 0.462 +- 0.301 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.3 all L1 = 0.514 +- 0.229 (in-sample avg dev_std = 0.529)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.4132725
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.729
SUFF++ for r=0.6 class 0 = 0.484 +- 0.209 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 1 = 0.717 +- 0.209 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 2 = 0.736 +- 0.209 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all KL = 0.677 +- 0.209 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all L1 = 0.648 +- 0.175 (in-sample avg dev_std = 0.407)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.41962375
Model XAI WIoU of binarized graphs for r=0.9 =  0.29021375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.776
SUFF++ for r=0.9 class 0 = 0.604 +- 0.191 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 1 = 0.718 +- 0.191 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 class 2 = 0.842 +- 0.191 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 all KL = 0.784 +- 0.191 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.9 all L1 = 0.722 +- 0.172 (in-sample avg dev_std = 0.310)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.435
Model XAI F1 of binarized graphs for r=0.3 =  0.7019175
Model XAI WIoU of binarized graphs for r=0.3 =  0.58067875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.325
NEC for r=0.3 class 0 = 0.656 +- 0.255 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 1 = 0.546 +- 0.255 (in-sample avg dev_std = 0.492)
NEC for r=0.3 class 2 = 0.665 +- 0.255 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all KL = 0.661 +- 0.255 (in-sample avg dev_std = 0.492)
NEC for r=0.3 all L1 = 0.622 +- 0.168 (in-sample avg dev_std = 0.492)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  0.5851762500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.46084374999999994
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.398
NEC for r=0.6 class 0 = 0.618 +- 0.283 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 1 = 0.495 +- 0.283 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 2 = 0.64 +- 0.283 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all KL = 0.645 +- 0.283 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all L1 = 0.584 +- 0.175 (in-sample avg dev_std = 0.522)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.4705975
Model XAI WIoU of binarized graphs for r=0.9 =  0.3463275
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.515
NEC for r=0.9 class 0 = 0.605 +- 0.232 (in-sample avg dev_std = 0.623)
NEC for r=0.9 class 1 = 0.517 +- 0.232 (in-sample avg dev_std = 0.623)
NEC for r=0.9 class 2 = 0.559 +- 0.232 (in-sample avg dev_std = 0.623)
NEC for r=0.9 all KL = 0.626 +- 0.232 (in-sample avg dev_std = 0.623)
NEC for r=0.9 all L1 = 0.56 +- 0.151 (in-sample avg dev_std = 0.623)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.3296125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.553 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 1 = 0.464 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 2 = 0.564 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all KL = 0.597 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all L1 = 0.527 +- 0.174 (in-sample avg dev_std = 0.655)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.720165
Model XAI WIoU of binarized graphs for r=0.3 =  0.60378375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.416
NEC for r=0.3 class 0 = 0.659 +- 0.216 (in-sample avg dev_std = 0.583)
NEC for r=0.3 class 1 = 0.61 +- 0.216 (in-sample avg dev_std = 0.583)
NEC for r=0.3 class 2 = 0.709 +- 0.216 (in-sample avg dev_std = 0.583)
NEC for r=0.3 all KL = 0.756 +- 0.216 (in-sample avg dev_std = 0.583)
NEC for r=0.3 all L1 = 0.659 +- 0.117 (in-sample avg dev_std = 0.583)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.4132725
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.435
NEC for r=0.6 class 0 = 0.585 +- 0.268 (in-sample avg dev_std = 0.557)
NEC for r=0.6 class 1 = 0.49 +- 0.268 (in-sample avg dev_std = 0.557)
NEC for r=0.6 class 2 = 0.641 +- 0.268 (in-sample avg dev_std = 0.557)
NEC for r=0.6 all KL = 0.618 +- 0.268 (in-sample avg dev_std = 0.557)
NEC for r=0.6 all L1 = 0.571 +- 0.161 (in-sample avg dev_std = 0.557)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.41962375
Model XAI WIoU of binarized graphs for r=0.9 =  0.29021375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.603 +- 0.290 (in-sample avg dev_std = 0.598)
NEC for r=0.9 class 1 = 0.427 +- 0.290 (in-sample avg dev_std = 0.598)
NEC for r=0.9 class 2 = 0.533 +- 0.290 (in-sample avg dev_std = 0.598)
NEC for r=0.9 all KL = 0.579 +- 0.290 (in-sample avg dev_std = 0.598)
NEC for r=0.9 all L1 = 0.519 +- 0.178 (in-sample avg dev_std = 0.598)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.634
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26802875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.469 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 1 = 0.443 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 2 = 0.344 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all KL = 0.417 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all L1 = 0.418 +- 0.154 (in-sample avg dev_std = 0.458)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.38, 0.57, 0.782, 1.0], 'all_L1': [0.472, 0.612, 0.747, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.39, 0.554, 0.778, 1.0], 'all_L1': [0.443, 0.587, 0.74, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.393, 0.535, 0.814, 1.0], 'all_L1': [0.433, 0.559, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.416, 0.547, 0.816, 1.0], 'all_L1': [0.43, 0.575, 0.751, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.409, 0.578, 0.793, 1.0], 'all_L1': [0.449, 0.588, 0.738, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.703, 0.651, 0.643, 0.598], 'all_L1': [0.609, 0.566, 0.556, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.68, 0.677, 0.638, 0.598], 'all_L1': [0.619, 0.603, 0.562, 0.53]}), defaultdict(<class 'list'>, {'all_KL': [0.678, 0.671, 0.626, 0.567], 'all_L1': [0.632, 0.609, 0.562, 0.523]}), defaultdict(<class 'list'>, {'all_KL': [0.672, 0.629, 0.59, 0.575], 'all_L1': [0.646, 0.576, 0.561, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.661, 0.645, 0.626, 0.597], 'all_L1': [0.622, 0.584, 0.56, 0.527]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.509, 0.672, 0.736, 1.0], 'all_L1': [0.572, 0.659, 0.701, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.523, 0.722, 0.741, 1.0], 'all_L1': [0.523, 0.663, 0.672, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.437, 0.663, 0.75, 1.0], 'all_L1': [0.504, 0.647, 0.675, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.456, 0.673, 0.785, 1.0], 'all_L1': [0.47, 0.599, 0.715, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.462, 0.677, 0.784, 1.0], 'all_L1': [0.514, 0.648, 0.722, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.718, 0.617, 0.588, 0.463], 'all_L1': [0.588, 0.548, 0.514, 0.436]}), defaultdict(<class 'list'>, {'all_KL': [0.61, 0.55, 0.536, 0.44], 'all_L1': [0.578, 0.537, 0.5, 0.414]}), defaultdict(<class 'list'>, {'all_KL': [0.747, 0.622, 0.504, 0.404], 'all_L1': [0.656, 0.574, 0.501, 0.427]}), defaultdict(<class 'list'>, {'all_KL': [0.675, 0.518, 0.53, 0.431], 'all_L1': [0.635, 0.547, 0.508, 0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.756, 0.618, 0.579, 0.417], 'all_L1': [0.659, 0.571, 0.519, 0.418]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.445 +- 0.015, 0.584 +- 0.017, 0.748 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.398 +- 0.013, 0.557 +- 0.016, 0.797 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.420 +- 0.013, 0.644 +- 0.013, 0.845 +- 0.013
nec class all_L1  =  0.626 +- 0.013, 0.588 +- 0.016, 0.560 +- 0.002, 0.525 +- 0.005
nec class all_KL  =  0.679 +- 0.014, 0.655 +- 0.017, 0.625 +- 0.019, 0.587 +- 0.013
nec_acc_int  =  0.315 +- 0.017, 0.388 +- 0.020, 0.509 +- 0.009, 0.545 +- 0.008

Eval split test
suff++ class all_L1  =  0.517 +- 0.033, 0.643 +- 0.023, 0.697 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.477 +- 0.033, 0.681 +- 0.021, 0.759 +- 0.021, 1.000 +- 0.000
suff++_acc_int  =  0.505 +- 0.034, 0.678 +- 0.032, 0.691 +- 0.048
nec class all_L1  =  0.623 +- 0.034, 0.555 +- 0.015, 0.508 +- 0.007, 0.427 +- 0.010
nec class all_KL  =  0.701 +- 0.054, 0.585 +- 0.043, 0.547 +- 0.032, 0.431 +- 0.020
nec_acc_int  =  0.383 +- 0.028, 0.443 +- 0.010, 0.535 +- 0.003, 0.545 +- 0.025


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.536 +- 0.003, 0.586 +- 0.006, 0.654 +- 0.005, 0.762 +- 0.002
Faith. Armon (L1)= 		  =  0.520 +- 0.006, 0.585 +- 0.006, 0.641 +- 0.004, 0.688 +- 0.004
Faith. GMean (L1)= 	  =  0.528 +- 0.005, 0.586 +- 0.006, 0.647 +- 0.004, 0.724 +- 0.003
Faith. Aritm (KL)= 		  =  0.538 +- 0.004, 0.606 +- 0.010, 0.711 +- 0.006, 0.794 +- 0.007
Faith. Armon (KL)= 		  =  0.501 +- 0.008, 0.601 +- 0.010, 0.700 +- 0.008, 0.740 +- 0.011
Faith. GMean (KL)= 	  =  0.519 +- 0.005, 0.604 +- 0.010, 0.705 +- 0.007, 0.766 +- 0.009

Eval split test
Faith. Aritm (L1)= 		  =  0.570 +- 0.015, 0.599 +- 0.014, 0.603 +- 0.014, 0.714 +- 0.005
Faith. Armon (L1)= 		  =  0.563 +- 0.016, 0.596 +- 0.013, 0.588 +- 0.012, 0.599 +- 0.010
Faith. GMean (L1)= 	  =  0.567 +- 0.015, 0.598 +- 0.013, 0.595 +- 0.013, 0.654 +- 0.008
Faith. Aritm (KL)= 		  =  0.589 +- 0.020, 0.633 +- 0.019, 0.653 +- 0.019, 0.715 +- 0.010
Faith. Armon (KL)= 		  =  0.566 +- 0.018, 0.628 +- 0.023, 0.636 +- 0.022, 0.602 +- 0.020
Faith. GMean (KL)= 	  =  0.577 +- 0.018, 0.631 +- 0.021, 0.644 +- 0.021, 0.656 +- 0.015
Computed for split load_split = id



Completed in  0:13:30.613319  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:40:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:28 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:41 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:43 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:46 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:50 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:40:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ACCURACY: 0.9271
Train Loss: 0.3266
ID Validation ACCURACY: 0.9333
ID Validation Loss: 0.3011
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3266
OOD Validation ACCURACY: 0.8727
OOD Validation Loss: 0.5282
OOD Test ACCURACY: 0.4900
OOD Test Loss: 2.9279

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9250
Train Loss: 0.3374
ID Validation ACCURACY: 0.9317
ID Validation Loss: 0.3128
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3355
OOD Validation ACCURACY: 0.9080
OOD Validation Loss: 0.4881
OOD Test ACCURACY: 0.5520
OOD Test Loss: 1.7201

[0m[1;37mINFO[0m: [1mChartInfo 0.9287 0.4900 0.9257 0.5520 0.9317 0.9080[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.736
WIoU for r=0.3 = 0.622
F1 for r=0.6 = 0.636
WIoU for r=0.6 = 0.515
F1 for r=0.9 = 0.511
WIoU for r=0.9 = 0.387
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.372
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.317
WIoU for r=0.3 = 0.205
F1 for r=0.6 = 0.179
WIoU for r=0.6 = 0.110
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.076
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.069


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.506
Model XAI F1 of binarized graphs for r=0.3 =  0.736055
Model XAI WIoU of binarized graphs for r=0.3 =  0.62213
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.443
SUFF++ for r=0.3 class 0 = 0.471 +- 0.275 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 1 = 0.525 +- 0.275 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.275 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all KL = 0.518 +- 0.275 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all L1 = 0.509 +- 0.167 (in-sample avg dev_std = 0.515)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.725
Model XAI F1 of binarized graphs for r=0.6 =  0.6361275
Model XAI WIoU of binarized graphs for r=0.6 =  0.5145649999999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.695
SUFF++ for r=0.6 class 0 = 0.541 +- 0.258 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 1 = 0.601 +- 0.258 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 2 = 0.709 +- 0.258 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all KL = 0.659 +- 0.258 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all L1 = 0.617 +- 0.205 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.51087625
Model XAI WIoU of binarized graphs for r=0.9 =  0.38717625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0 = 0.739 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1 = 0.841 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 2 = 0.867 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.88 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.174 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.3174675
Model XAI WIoU of binarized graphs for r=0.3 =  0.204955
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.539
SUFF++ for r=0.3 class 0 = 0.576 +- 0.241 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 1 = 0.605 +- 0.241 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 2 = 0.646 +- 0.241 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all KL = 0.702 +- 0.241 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all L1 = 0.608 +- 0.123 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  0.17947375000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.10989374999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.556
SUFF++ for r=0.6 class 0 = 0.545 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 1 = 0.584 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 2 = 0.598 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all KL = 0.646 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all L1 = 0.575 +- 0.118 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  0.12439250000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07565625000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.556
SUFF++ for r=0.9 class 0 = 0.773 +- 0.108 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 1 = 0.759 +- 0.108 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 2 = 0.782 +- 0.108 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all KL = 0.889 +- 0.108 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all L1 = 0.771 +- 0.130 (in-sample avg dev_std = 0.191)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.501
Model XAI F1 of binarized graphs for r=0.3 =  0.736055
Model XAI WIoU of binarized graphs for r=0.3 =  0.62213
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.328
NEC for r=0.3 class 0 = 0.597 +- 0.303 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1 = 0.536 +- 0.303 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 2 = 0.613 +- 0.303 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.565 +- 0.303 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.583 +- 0.175 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.73
Model XAI F1 of binarized graphs for r=0.6 =  0.6361275
Model XAI WIoU of binarized graphs for r=0.6 =  0.5145649999999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0 = 0.578 +- 0.277 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 1 = 0.537 +- 0.277 (in-sample avg dev_std = 0.479)
NEC for r=0.6 class 2 = 0.642 +- 0.277 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all KL = 0.597 +- 0.277 (in-sample avg dev_std = 0.479)
NEC for r=0.6 all L1 = 0.586 +- 0.173 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.51087625
Model XAI WIoU of binarized graphs for r=0.9 =  0.38717625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.484
NEC for r=0.9 class 0 = 0.579 +- 0.237 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 1 = 0.517 +- 0.237 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 2 = 0.592 +- 0.237 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all KL = 0.582 +- 0.237 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all L1 = 0.563 +- 0.151 (in-sample avg dev_std = 0.570)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.37217625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.524
NEC for r=1.0 class 0 = 0.558 +- 0.245 (in-sample avg dev_std = 0.627)
NEC for r=1.0 class 1 = 0.497 +- 0.245 (in-sample avg dev_std = 0.627)
NEC for r=1.0 class 2 = 0.588 +- 0.245 (in-sample avg dev_std = 0.627)
NEC for r=1.0 all KL = 0.614 +- 0.245 (in-sample avg dev_std = 0.627)
NEC for r=1.0 all L1 = 0.549 +- 0.169 (in-sample avg dev_std = 0.627)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  0.3174675
Model XAI WIoU of binarized graphs for r=0.3 =  0.204955
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.468 +- 0.245 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 1 = 0.461 +- 0.245 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 2 = 0.428 +- 0.245 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all KL = 0.327 +- 0.245 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all L1 = 0.453 +- 0.219 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  0.17947375000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.10989374999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.392
NEC for r=0.6 class 0 = 0.411 +- 0.160 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 1 = 0.306 +- 0.160 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 2 = 0.413 +- 0.160 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all KL = 0.24 +- 0.160 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all L1 = 0.376 +- 0.161 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.631
Model XAI F1 of binarized graphs for r=0.9 =  0.12439250000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07565625000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.424
NEC for r=0.9 class 0 = 0.318 +- 0.131 (in-sample avg dev_std = 0.235)
NEC for r=0.9 class 1 = 0.276 +- 0.131 (in-sample avg dev_std = 0.235)
NEC for r=0.9 class 2 = 0.348 +- 0.131 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all KL = 0.158 +- 0.131 (in-sample avg dev_std = 0.235)
NEC for r=0.9 all L1 = 0.313 +- 0.173 (in-sample avg dev_std = 0.235)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.502
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06884625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.398
NEC for r=1.0 class 0 = 0.263 +- 0.178 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 1 = 0.315 +- 0.178 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 2 = 0.27 +- 0.178 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all KL = 0.152 +- 0.178 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all L1 = 0.283 +- 0.188 (in-sample avg dev_std = 0.175)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:46:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:04 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:46:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 0.9269
Train Loss: 0.3318
ID Validation ACCURACY: 0.9343
ID Validation Loss: 0.3073
ID Test ACCURACY: 0.9293
ID Test Loss: 0.3342
OOD Validation ACCURACY: 0.8717
OOD Validation Loss: 0.5372
OOD Test ACCURACY: 0.4823
OOD Test Loss: 1.7079

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 148...
[0m[1;37mINFO[0m: [1mCheckpoint 148: 
-----------------------------------
Train ACCURACY: 0.9254
Train Loss: 0.3369
ID Validation ACCURACY: 0.9323
ID Validation Loss: 0.3113
ID Test ACCURACY: 0.9290
ID Test Loss: 0.3369
OOD Validation ACCURACY: 0.9010
OOD Validation Loss: 0.4831
OOD Test ACCURACY: 0.4413
OOD Test Loss: 1.7290

[0m[1;37mINFO[0m: [1mChartInfo 0.9293 0.4823 0.9290 0.4413 0.9323 0.9010[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.608
F1 for r=0.6 = 0.645
WIoU for r=0.6 = 0.523
F1 for r=0.9 = 0.517
WIoU for r=0.9 = 0.394
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.374
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.321
WIoU for r=0.3 = 0.206
F1 for r=0.6 = 0.180
WIoU for r=0.6 = 0.109
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.075
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.068


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  0.7264099999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.607515
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.46
SUFF++ for r=0.3 class 0 = 0.504 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 class 1 = 0.574 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 class 2 = 0.556 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 all KL = 0.574 +- 0.257 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 all L1 = 0.544 +- 0.156 (in-sample avg dev_std = 0.487)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.816
Model XAI F1 of binarized graphs for r=0.6 =  0.6450824999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.5232725
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.705
SUFF++ for r=0.6 class 0 = 0.559 +- 0.250 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 1 = 0.628 +- 0.250 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 2 = 0.751 +- 0.250 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all KL = 0.681 +- 0.250 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all L1 = 0.646 +- 0.202 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.921
Model XAI F1 of binarized graphs for r=0.9 =  0.516945
Model XAI WIoU of binarized graphs for r=0.9 =  0.39419875000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0 = 0.784 +- 0.161 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 class 1 = 0.85 +- 0.161 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 class 2 = 0.871 +- 0.161 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all KL = 0.895 +- 0.161 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.9 all L1 = 0.835 +- 0.158 (in-sample avg dev_std = 0.216)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  0.32051625
Model XAI WIoU of binarized graphs for r=0.3 =  0.20579375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0 = 0.594 +- 0.202 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 1 = 0.607 +- 0.202 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 2 = 0.642 +- 0.202 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all KL = 0.737 +- 0.202 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all L1 = 0.614 +- 0.124 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  0.17978375
Model XAI WIoU of binarized graphs for r=0.6 =  0.10940749999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.59
SUFF++ for r=0.6 class 0 = 0.585 +- 0.225 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 1 = 0.634 +- 0.225 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 2 = 0.605 +- 0.225 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all KL = 0.719 +- 0.225 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all L1 = 0.608 +- 0.118 (in-sample avg dev_std = 0.416)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  0.12449875000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07513875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.617
SUFF++ for r=0.9 class 0 = 0.743 +- 0.183 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 1 = 0.726 +- 0.183 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 2 = 0.739 +- 0.183 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all KL = 0.856 +- 0.183 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all L1 = 0.736 +- 0.154 (in-sample avg dev_std = 0.172)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  0.7264099999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.607515
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.306
NEC for r=0.3 class 0 = 0.589 +- 0.318 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 1 = 0.483 +- 0.318 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 2 = 0.583 +- 0.318 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all KL = 0.523 +- 0.318 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all L1 = 0.553 +- 0.192 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.816
Model XAI F1 of binarized graphs for r=0.6 =  0.6450824999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.5232725
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.382
NEC for r=0.6 class 0 = 0.588 +- 0.266 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 1 = 0.53 +- 0.266 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 2 = 0.653 +- 0.266 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all KL = 0.613 +- 0.266 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all L1 = 0.591 +- 0.160 (in-sample avg dev_std = 0.493)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.516945
Model XAI WIoU of binarized graphs for r=0.9 =  0.39419875000000004
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.492
NEC for r=0.9 class 0 = 0.568 +- 0.250 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 1 = 0.493 +- 0.250 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 2 = 0.582 +- 0.250 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all KL = 0.562 +- 0.250 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all L1 = 0.548 +- 0.165 (in-sample avg dev_std = 0.550)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.3735625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.52
NEC for r=1.0 class 0 = 0.557 +- 0.263 (in-sample avg dev_std = 0.591)
NEC for r=1.0 class 1 = 0.471 +- 0.263 (in-sample avg dev_std = 0.591)
NEC for r=1.0 class 2 = 0.599 +- 0.263 (in-sample avg dev_std = 0.591)
NEC for r=1.0 all KL = 0.583 +- 0.263 (in-sample avg dev_std = 0.591)
NEC for r=1.0 all L1 = 0.543 +- 0.178 (in-sample avg dev_std = 0.591)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  0.32051625
Model XAI WIoU of binarized graphs for r=0.3 =  0.20579375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.349
NEC for r=0.3 class 0 = 0.446 +- 0.209 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 1 = 0.451 +- 0.209 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 2 = 0.424 +- 0.209 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all KL = 0.297 +- 0.209 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all L1 = 0.441 +- 0.185 (in-sample avg dev_std = 0.219)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  0.17978375
Model XAI WIoU of binarized graphs for r=0.6 =  0.10940749999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.39
NEC for r=0.6 class 0 = 0.356 +- 0.127 (in-sample avg dev_std = 0.232)
NEC for r=0.6 class 1 = 0.35 +- 0.127 (in-sample avg dev_std = 0.232)
NEC for r=0.6 class 2 = 0.399 +- 0.127 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all KL = 0.208 +- 0.127 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all L1 = 0.368 +- 0.128 (in-sample avg dev_std = 0.232)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  0.12449875000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07513875
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.453
NEC for r=0.9 class 0 = 0.338 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1 = 0.357 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 2 = 0.389 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.185 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.361 +- 0.134 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.48
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06820999999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.443
NEC for r=1.0 class 0 = 0.303 +- 0.185 (in-sample avg dev_std = 0.202)
NEC for r=1.0 class 1 = 0.385 +- 0.185 (in-sample avg dev_std = 0.202)
NEC for r=1.0 class 2 = 0.364 +- 0.185 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all KL = 0.187 +- 0.185 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all L1 = 0.35 +- 0.147 (in-sample avg dev_std = 0.202)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:51:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:51:51 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:05 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:08 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:10 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:14 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:52:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9257
Train Loss: 0.3361
ID Validation ACCURACY: 0.9333
ID Validation Loss: 0.3077
ID Test ACCURACY: 0.9270
ID Test Loss: 0.3376
OOD Validation ACCURACY: 0.8420
OOD Validation Loss: 0.5515
OOD Test ACCURACY: 0.4797
OOD Test Loss: 2.8706

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ACCURACY: 0.9263
Train Loss: 0.3241
ID Validation ACCURACY: 0.9327
ID Validation Loss: 0.3015
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3264
OOD Validation ACCURACY: 0.9020
OOD Validation Loss: 0.4748
OOD Test ACCURACY: 0.4983
OOD Test Loss: 2.8719

[0m[1;37mINFO[0m: [1mChartInfo 0.9270 0.4797 0.9280 0.4983 0.9327 0.9020[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.738
WIoU for r=0.3 = 0.623
F1 for r=0.6 = 0.647
WIoU for r=0.6 = 0.527
F1 for r=0.9 = 0.518
WIoU for r=0.9 = 0.393
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.370
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.317
WIoU for r=0.3 = 0.200
F1 for r=0.6 = 0.180
WIoU for r=0.6 = 0.107
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.074
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.067


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.7383962500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6228512500000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.427
SUFF++ for r=0.3 class 0 = 0.459 +- 0.276 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 1 = 0.533 +- 0.276 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 2 = 0.568 +- 0.276 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all KL = 0.528 +- 0.276 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all L1 = 0.52 +- 0.163 (in-sample avg dev_std = 0.515)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  0.6473224999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.52664125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.7
SUFF++ for r=0.6 class 0 = 0.601 +- 0.259 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 class 1 = 0.59 +- 0.259 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 class 2 = 0.738 +- 0.259 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all KL = 0.665 +- 0.259 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.207 (in-sample avg dev_std = 0.430)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.51768
Model XAI WIoU of binarized graphs for r=0.9 =  0.39266625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0 = 0.783 +- 0.174 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1 = 0.854 +- 0.174 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 2 = 0.866 +- 0.174 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.886 +- 0.174 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.834 +- 0.157 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  0.31706249999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.20024375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0 = 0.599 +- 0.215 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 1 = 0.614 +- 0.215 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 2 = 0.663 +- 0.215 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all KL = 0.726 +- 0.215 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all L1 = 0.624 +- 0.130 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  0.17987874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.10706875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.586
SUFF++ for r=0.6 class 0 = 0.586 +- 0.230 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 1 = 0.621 +- 0.230 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 2 = 0.625 +- 0.230 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all KL = 0.703 +- 0.230 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all L1 = 0.61 +- 0.116 (in-sample avg dev_std = 0.420)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.582
Model XAI F1 of binarized graphs for r=0.9 =  0.12449875000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07358625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.54
SUFF++ for r=0.9 class 0 = 0.779 +- 0.067 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 class 1 = 0.821 +- 0.067 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 class 2 = 0.779 +- 0.067 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all KL = 0.91 +- 0.067 (in-sample avg dev_std = 0.189)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.115 (in-sample avg dev_std = 0.189)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.465
Model XAI F1 of binarized graphs for r=0.3 =  0.7383962500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6228512500000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.319
NEC for r=0.3 class 0 = 0.626 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 1 = 0.535 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 2 = 0.585 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all KL = 0.561 +- 0.311 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all L1 = 0.583 +- 0.179 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  0.6473224999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.52664125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0 = 0.633 +- 0.295 (in-sample avg dev_std = 0.495)
NEC for r=0.6 class 1 = 0.498 +- 0.295 (in-sample avg dev_std = 0.495)
NEC for r=0.6 class 2 = 0.633 +- 0.295 (in-sample avg dev_std = 0.495)
NEC for r=0.6 all KL = 0.638 +- 0.295 (in-sample avg dev_std = 0.495)
NEC for r=0.6 all L1 = 0.589 +- 0.183 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.51768
Model XAI WIoU of binarized graphs for r=0.9 =  0.39266625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.488
NEC for r=0.9 class 0 = 0.599 +- 0.253 (in-sample avg dev_std = 0.589)
NEC for r=0.9 class 1 = 0.501 +- 0.253 (in-sample avg dev_std = 0.589)
NEC for r=0.9 class 2 = 0.589 +- 0.253 (in-sample avg dev_std = 0.589)
NEC for r=0.9 all KL = 0.622 +- 0.253 (in-sample avg dev_std = 0.589)
NEC for r=0.9 all L1 = 0.564 +- 0.167 (in-sample avg dev_std = 0.589)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.3704925
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.523
NEC for r=1.0 class 0 = 0.573 +- 0.268 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 1 = 0.462 +- 0.268 (in-sample avg dev_std = 0.617)
NEC for r=1.0 class 2 = 0.577 +- 0.268 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all KL = 0.616 +- 0.268 (in-sample avg dev_std = 0.617)
NEC for r=1.0 all L1 = 0.539 +- 0.187 (in-sample avg dev_std = 0.617)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  0.31706249999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.20024375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.503 +- 0.239 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 1 = 0.436 +- 0.239 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 2 = 0.428 +- 0.239 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all KL = 0.337 +- 0.239 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all L1 = 0.456 +- 0.214 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  0.17987874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.10706875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.392
NEC for r=0.6 class 0 = 0.365 +- 0.143 (in-sample avg dev_std = 0.251)
NEC for r=0.6 class 1 = 0.323 +- 0.143 (in-sample avg dev_std = 0.251)
NEC for r=0.6 class 2 = 0.395 +- 0.143 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all KL = 0.218 +- 0.143 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all L1 = 0.36 +- 0.143 (in-sample avg dev_std = 0.251)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.577
Model XAI F1 of binarized graphs for r=0.9 =  0.12449875000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.07358625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.416
NEC for r=0.9 class 0 = 0.285 +- 0.126 (in-sample avg dev_std = 0.216)
NEC for r=0.9 class 1 = 0.293 +- 0.126 (in-sample avg dev_std = 0.216)
NEC for r=0.9 class 2 = 0.286 +- 0.126 (in-sample avg dev_std = 0.216)
NEC for r=0.9 all KL = 0.142 +- 0.126 (in-sample avg dev_std = 0.216)
NEC for r=0.9 all L1 = 0.288 +- 0.176 (in-sample avg dev_std = 0.216)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.476
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06688
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.408
NEC for r=1.0 class 0 = 0.234 +- 0.131 (in-sample avg dev_std = 0.202)
NEC for r=1.0 class 1 = 0.265 +- 0.131 (in-sample avg dev_std = 0.202)
NEC for r=1.0 class 2 = 0.238 +- 0.131 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all KL = 0.124 +- 0.131 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all L1 = 0.246 +- 0.170 (in-sample avg dev_std = 0.202)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 12:57:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 12:57:34 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 12:57:48 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 12:57:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 12:57:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 12:57:56 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 12:58:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ACCURACY: 0.9253
Train Loss: 0.3361
ID Validation ACCURACY: 0.9333
ID Validation Loss: 0.3074
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3393
OOD Validation ACCURACY: 0.8767
OOD Validation Loss: 0.4984
OOD Test ACCURACY: 0.4740
OOD Test Loss: 1.2039

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 55...
[0m[1;37mINFO[0m: [1mCheckpoint 55: 
-----------------------------------
Train ACCURACY: 0.9265
Train Loss: 0.3340
ID Validation ACCURACY: 0.9330
ID Validation Loss: 0.3130
ID Test ACCURACY: 0.9277
ID Test Loss: 0.3339
OOD Validation ACCURACY: 0.9093
OOD Validation Loss: 0.4747
OOD Test ACCURACY: 0.6587
OOD Test Loss: 1.0872

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.4740 0.9277 0.6587 0.9330 0.9093[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.729
WIoU for r=0.3 = 0.611
F1 for r=0.6 = 0.636
WIoU for r=0.6 = 0.513
F1 for r=0.9 = 0.518
WIoU for r=0.9 = 0.395
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.373
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.314
WIoU for r=0.3 = 0.199
F1 for r=0.6 = 0.178
WIoU for r=0.6 = 0.107
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.074
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.068


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.512
Model XAI F1 of binarized graphs for r=0.3 =  0.7287437500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6107462499999999
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.443
SUFF++ for r=0.3 class 0 = 0.468 +- 0.281 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.3 class 1 = 0.534 +- 0.281 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.3 class 2 = 0.523 +- 0.281 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.3 all KL = 0.457 +- 0.281 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.3 all L1 = 0.508 +- 0.192 (in-sample avg dev_std = 0.585)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.764
Model XAI F1 of binarized graphs for r=0.6 =  0.6358012500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.51273125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.667
SUFF++ for r=0.6 class 0 = 0.608 +- 0.298 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.532 +- 0.298 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.713 +- 0.298 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.601 +- 0.298 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.619 +- 0.226 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.51828875
Model XAI WIoU of binarized graphs for r=0.9 =  0.39511750000000007
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.865
SUFF++ for r=0.9 class 0 = 0.792 +- 0.183 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.81 +- 0.183 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.867 +- 0.183 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.873 +- 0.183 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.167 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  0.31437750000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.19946750000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.599 +- 0.267 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 1 = 0.581 +- 0.267 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 2 = 0.599 +- 0.267 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all KL = 0.651 +- 0.267 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all L1 = 0.593 +- 0.140 (in-sample avg dev_std = 0.443)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.603
Model XAI F1 of binarized graphs for r=0.6 =  0.17831
Model XAI WIoU of binarized graphs for r=0.6 =  0.10703625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.503
SUFF++ for r=0.6 class 0 = 0.602 +- 0.233 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 1 = 0.579 +- 0.233 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 2 = 0.622 +- 0.233 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all KL = 0.695 +- 0.233 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all L1 = 0.601 +- 0.124 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.536
Model XAI F1 of binarized graphs for r=0.9 =  0.12360375000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.07385625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.544
SUFF++ for r=0.9 class 0 = 0.695 +- 0.178 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1 = 0.647 +- 0.178 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 2 = 0.703 +- 0.178 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.815 +- 0.178 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.681 +- 0.154 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.514
Model XAI F1 of binarized graphs for r=0.3 =  0.7287437500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6107462499999999
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.331
NEC for r=0.3 class 0 = 0.586 +- 0.323 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 1 = 0.53 +- 0.323 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 2 = 0.621 +- 0.323 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all KL = 0.605 +- 0.323 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all L1 = 0.58 +- 0.221 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.767
Model XAI F1 of binarized graphs for r=0.6 =  0.6358012500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.51273125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.397
NEC for r=0.6 class 0 = 0.564 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.6 class 1 = 0.557 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.6 class 2 = 0.633 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.6 all KL = 0.643 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.6 all L1 = 0.585 +- 0.194 (in-sample avg dev_std = 0.537)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.51828875
Model XAI WIoU of binarized graphs for r=0.9 =  0.39511750000000007
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.484
NEC for r=0.9 class 0 = 0.541 +- 0.245 (in-sample avg dev_std = 0.609)
NEC for r=0.9 class 1 = 0.563 +- 0.245 (in-sample avg dev_std = 0.609)
NEC for r=0.9 class 2 = 0.592 +- 0.245 (in-sample avg dev_std = 0.609)
NEC for r=0.9 all KL = 0.627 +- 0.245 (in-sample avg dev_std = 0.609)
NEC for r=0.9 all L1 = 0.565 +- 0.163 (in-sample avg dev_std = 0.609)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.37301249999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.5
NEC for r=1.0 class 0 = 0.548 +- 0.249 (in-sample avg dev_std = 0.656)
NEC for r=1.0 class 1 = 0.546 +- 0.249 (in-sample avg dev_std = 0.656)
NEC for r=1.0 class 2 = 0.612 +- 0.249 (in-sample avg dev_std = 0.656)
NEC for r=1.0 all KL = 0.667 +- 0.249 (in-sample avg dev_std = 0.656)
NEC for r=1.0 all L1 = 0.569 +- 0.174 (in-sample avg dev_std = 0.656)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.31437750000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.19946750000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.397 +- 0.248 (in-sample avg dev_std = 0.274)
NEC for r=0.3 class 1 = 0.408 +- 0.248 (in-sample avg dev_std = 0.274)
NEC for r=0.3 class 2 = 0.479 +- 0.248 (in-sample avg dev_std = 0.274)
NEC for r=0.3 all KL = 0.324 +- 0.248 (in-sample avg dev_std = 0.274)
NEC for r=0.3 all L1 = 0.427 +- 0.217 (in-sample avg dev_std = 0.274)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.601
Model XAI F1 of binarized graphs for r=0.6 =  0.17831
Model XAI WIoU of binarized graphs for r=0.6 =  0.10703625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.374
NEC for r=0.6 class 0 = 0.352 +- 0.182 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 1 = 0.374 +- 0.182 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 2 = 0.417 +- 0.182 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all KL = 0.256 +- 0.182 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all L1 = 0.38 +- 0.157 (in-sample avg dev_std = 0.241)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  0.12360375000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.07385625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.425
NEC for r=0.9 class 0 = 0.376 +- 0.213 (in-sample avg dev_std = 0.275)
NEC for r=0.9 class 1 = 0.42 +- 0.213 (in-sample avg dev_std = 0.275)
NEC for r=0.9 class 2 = 0.405 +- 0.213 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all KL = 0.261 +- 0.213 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all L1 = 0.4 +- 0.165 (in-sample avg dev_std = 0.275)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.485
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06763124999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.397
NEC for r=1.0 class 0 = 0.295 +- 0.184 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 1 = 0.385 +- 0.184 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 2 = 0.33 +- 0.184 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all KL = 0.196 +- 0.184 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all L1 = 0.337 +- 0.142 (in-sample avg dev_std = 0.239)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:03:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:34 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:36 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:39 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:42 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:03:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9259
Train Loss: 0.3359
ID Validation ACCURACY: 0.9330
ID Validation Loss: 0.3120
ID Test ACCURACY: 0.9290
ID Test Loss: 0.3412
OOD Validation ACCURACY: 0.8600
OOD Validation Loss: 0.5640
OOD Test ACCURACY: 0.4780
OOD Test Loss: 2.7135

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.9219
Train Loss: 0.3470
ID Validation ACCURACY: 0.9300
ID Validation Loss: 0.3120
ID Test ACCURACY: 0.9230
ID Test Loss: 0.3502
OOD Validation ACCURACY: 0.9030
OOD Validation Loss: 0.4639
OOD Test ACCURACY: 0.5370
OOD Test Loss: 1.5806

[0m[1;37mINFO[0m: [1mChartInfo 0.9290 0.4780 0.9230 0.5370 0.9300 0.9030[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.722
WIoU for r=0.3 = 0.601
F1 for r=0.6 = 0.645
WIoU for r=0.6 = 0.522
F1 for r=0.9 = 0.519
WIoU for r=0.9 = 0.392
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.369
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.286
WIoU for r=0.3 = 0.181
F1 for r=0.6 = 0.180
WIoU for r=0.6 = 0.106
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.073
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.067


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.501
Model XAI F1 of binarized graphs for r=0.3 =  0.72210875
Model XAI WIoU of binarized graphs for r=0.3 =  0.60081875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.435
SUFF++ for r=0.3 class 0 = 0.51 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 1 = 0.565 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 class 2 = 0.534 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all KL = 0.555 +- 0.281 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.3 all L1 = 0.536 +- 0.160 (in-sample avg dev_std = 0.501)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.64534875
Model XAI WIoU of binarized graphs for r=0.6 =  0.52156875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.718
SUFF++ for r=0.6 class 0 = 0.637 +- 0.239 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1 = 0.639 +- 0.239 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 2 = 0.708 +- 0.239 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.696 +- 0.239 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.662 +- 0.185 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.5193712500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.39201875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0 = 0.794 +- 0.172 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 1 = 0.859 +- 0.172 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 2 = 0.866 +- 0.172 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all KL = 0.897 +- 0.172 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.163 (in-sample avg dev_std = 0.225)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.538
Model XAI F1 of binarized graphs for r=0.3 =  0.28622625
Model XAI WIoU of binarized graphs for r=0.3 =  0.18122999999999997
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0 = 0.6 +- 0.208 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 1 = 0.603 +- 0.208 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 2 = 0.598 +- 0.208 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all KL = 0.717 +- 0.208 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all L1 = 0.6 +- 0.138 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.592
Model XAI F1 of binarized graphs for r=0.6 =  0.17966875000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.10581375000000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.581
SUFF++ for r=0.6 class 0 = 0.589 +- 0.156 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 1 = 0.628 +- 0.156 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 2 = 0.634 +- 0.156 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all KL = 0.788 +- 0.156 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all L1 = 0.617 +- 0.135 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  0.1244275
Model XAI WIoU of binarized graphs for r=0.9 =  0.07331375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.565
SUFF++ for r=0.9 class 0 = 0.841 +- 0.045 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 1 = 0.851 +- 0.045 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 class 2 = 0.845 +- 0.045 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all KL = 0.956 +- 0.045 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.9 all L1 = 0.846 +- 0.100 (in-sample avg dev_std = 0.159)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.502
Model XAI F1 of binarized graphs for r=0.3 =  0.72210875
Model XAI WIoU of binarized graphs for r=0.3 =  0.60081875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.303
NEC for r=0.3 class 0 = 0.573 +- 0.331 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 1 = 0.488 +- 0.331 (in-sample avg dev_std = 0.367)
NEC for r=0.3 class 2 = 0.595 +- 0.331 (in-sample avg dev_std = 0.367)
NEC for r=0.3 all KL = 0.532 +- 0.331 (in-sample avg dev_std = 0.367)
NEC for r=0.3 all L1 = 0.553 +- 0.196 (in-sample avg dev_std = 0.367)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.796
Model XAI F1 of binarized graphs for r=0.6 =  0.64534875
Model XAI WIoU of binarized graphs for r=0.6 =  0.52156875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.385
NEC for r=0.6 class 0 = 0.614 +- 0.279 (in-sample avg dev_std = 0.494)
NEC for r=0.6 class 1 = 0.504 +- 0.279 (in-sample avg dev_std = 0.494)
NEC for r=0.6 class 2 = 0.642 +- 0.279 (in-sample avg dev_std = 0.494)
NEC for r=0.6 all KL = 0.615 +- 0.279 (in-sample avg dev_std = 0.494)
NEC for r=0.6 all L1 = 0.588 +- 0.175 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  0.5193712500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.39201875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.486
NEC for r=0.9 class 0 = 0.579 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 1 = 0.493 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 2 = 0.583 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all KL = 0.572 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all L1 = 0.552 +- 0.166 (in-sample avg dev_std = 0.567)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.36891375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.527
NEC for r=1.0 class 0 = 0.556 +- 0.254 (in-sample avg dev_std = 0.599)
NEC for r=1.0 class 1 = 0.454 +- 0.254 (in-sample avg dev_std = 0.599)
NEC for r=1.0 class 2 = 0.595 +- 0.254 (in-sample avg dev_std = 0.599)
NEC for r=1.0 all KL = 0.578 +- 0.254 (in-sample avg dev_std = 0.599)
NEC for r=1.0 all L1 = 0.536 +- 0.179 (in-sample avg dev_std = 0.599)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  0.28622625
Model XAI WIoU of binarized graphs for r=0.3 =  0.18122999999999997
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.348
NEC for r=0.3 class 0 = 0.443 +- 0.219 (in-sample avg dev_std = 0.253)
NEC for r=0.3 class 1 = 0.441 +- 0.219 (in-sample avg dev_std = 0.253)
NEC for r=0.3 class 2 = 0.453 +- 0.219 (in-sample avg dev_std = 0.253)
NEC for r=0.3 all KL = 0.319 +- 0.219 (in-sample avg dev_std = 0.253)
NEC for r=0.3 all L1 = 0.445 +- 0.190 (in-sample avg dev_std = 0.253)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.591
Model XAI F1 of binarized graphs for r=0.6 =  0.17966875000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.10581375000000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.4
NEC for r=0.6 class 0 = 0.465 +- 0.162 (in-sample avg dev_std = 0.250)
NEC for r=0.6 class 1 = 0.393 +- 0.162 (in-sample avg dev_std = 0.250)
NEC for r=0.6 class 2 = 0.441 +- 0.162 (in-sample avg dev_std = 0.250)
NEC for r=0.6 all KL = 0.254 +- 0.162 (in-sample avg dev_std = 0.250)
NEC for r=0.6 all L1 = 0.433 +- 0.136 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.61
Model XAI F1 of binarized graphs for r=0.9 =  0.1244275
Model XAI WIoU of binarized graphs for r=0.9 =  0.07331375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.403
NEC for r=0.9 class 0 = 0.256 +- 0.078 (in-sample avg dev_std = 0.173)
NEC for r=0.9 class 1 = 0.226 +- 0.078 (in-sample avg dev_std = 0.173)
NEC for r=0.9 class 2 = 0.261 +- 0.078 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all KL = 0.091 +- 0.078 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all L1 = 0.247 +- 0.148 (in-sample avg dev_std = 0.173)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.484
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.0667525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.425
NEC for r=1.0 class 0 = 0.232 +- 0.068 (in-sample avg dev_std = 0.160)
NEC for r=1.0 class 1 = 0.227 +- 0.068 (in-sample avg dev_std = 0.160)
NEC for r=1.0 class 2 = 0.246 +- 0.068 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all KL = 0.084 +- 0.068 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all L1 = 0.235 +- 0.135 (in-sample avg dev_std = 0.160)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.518, 0.659, 0.88, 1.0], 'all_L1': [0.509, 0.617, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.574, 0.681, 0.895, 1.0], 'all_L1': [0.544, 0.646, 0.835, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.528, 0.665, 0.886, 1.0], 'all_L1': [0.52, 0.644, 0.834, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.457, 0.601, 0.873, 1.0], 'all_L1': [0.508, 0.619, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.555, 0.696, 0.897, 1.0], 'all_L1': [0.536, 0.662, 0.839, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.565, 0.597, 0.582, 0.614], 'all_L1': [0.583, 0.586, 0.563, 0.549]}), defaultdict(<class 'list'>, {'all_KL': [0.523, 0.613, 0.562, 0.583], 'all_L1': [0.553, 0.591, 0.548, 0.543]}), defaultdict(<class 'list'>, {'all_KL': [0.561, 0.638, 0.622, 0.616], 'all_L1': [0.583, 0.589, 0.564, 0.539]}), defaultdict(<class 'list'>, {'all_KL': [0.605, 0.643, 0.627, 0.667], 'all_L1': [0.58, 0.585, 0.565, 0.569]}), defaultdict(<class 'list'>, {'all_KL': [0.532, 0.615, 0.572, 0.578], 'all_L1': [0.553, 0.588, 0.552, 0.536]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.702, 0.646, 0.889, 1.0], 'all_L1': [0.608, 0.575, 0.771, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.737, 0.719, 0.856, 1.0], 'all_L1': [0.614, 0.608, 0.736, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.726, 0.703, 0.91, 1.0], 'all_L1': [0.624, 0.61, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.651, 0.695, 0.815, 1.0], 'all_L1': [0.593, 0.601, 0.681, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.717, 0.788, 0.956, 1.0], 'all_L1': [0.6, 0.617, 0.846, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.327, 0.24, 0.158, 0.152], 'all_L1': [0.453, 0.376, 0.313, 0.283]}), defaultdict(<class 'list'>, {'all_KL': [0.297, 0.208, 0.185, 0.187], 'all_L1': [0.441, 0.368, 0.361, 0.35]}), defaultdict(<class 'list'>, {'all_KL': [0.337, 0.218, 0.142, 0.124], 'all_L1': [0.456, 0.36, 0.288, 0.246]}), defaultdict(<class 'list'>, {'all_KL': [0.324, 0.256, 0.261, 0.196], 'all_L1': [0.427, 0.38, 0.4, 0.337]}), defaultdict(<class 'list'>, {'all_KL': [0.319, 0.254, 0.091, 0.084], 'all_L1': [0.445, 0.433, 0.247, 0.235]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.523 +- 0.014, 0.638 +- 0.017, 0.829 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.526 +- 0.040, 0.660 +- 0.032, 0.886 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.442 +- 0.011, 0.697 +- 0.017, 0.873 +- 0.005
nec class all_L1  =  0.570 +- 0.014, 0.588 +- 0.002, 0.558 +- 0.007, 0.547 +- 0.012
nec class all_KL  =  0.557 +- 0.029, 0.621 +- 0.017, 0.593 +- 0.027, 0.612 +- 0.032
nec_acc_int  =  0.317 +- 0.011, 0.390 +- 0.005, 0.487 +- 0.003, 0.519 +- 0.010

Eval split test
suff++ class all_L1  =  0.608 +- 0.011, 0.602 +- 0.015, 0.765 +- 0.055, 1.000 +- 0.000
suff++ class all_KL  =  0.707 +- 0.030, 0.710 +- 0.046, 0.885 +- 0.048, 1.000 +- 0.000
suff++_acc_int  =  0.546 +- 0.029, 0.563 +- 0.032, 0.564 +- 0.028
nec class all_L1  =  0.444 +- 0.010, 0.383 +- 0.026, 0.322 +- 0.054, 0.290 +- 0.047
nec class all_KL  =  0.321 +- 0.013, 0.235 +- 0.019, 0.167 +- 0.056, 0.149 +- 0.041
nec_acc_int  =  0.342 +- 0.006, 0.390 +- 0.009, 0.424 +- 0.016, 0.414 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.547 +- 0.003, 0.613 +- 0.009, 0.694 +- 0.003, 0.774 +- 0.006
Faith. Armon (L1)= 		  =  0.546 +- 0.003, 0.612 +- 0.009, 0.667 +- 0.004, 0.707 +- 0.010
Faith. GMean (L1)= 	  =  0.546 +- 0.003, 0.612 +- 0.009, 0.680 +- 0.003, 0.740 +- 0.008
Faith. Aritm (KL)= 		  =  0.542 +- 0.006, 0.641 +- 0.013, 0.740 +- 0.010, 0.806 +- 0.016
Faith. Armon (KL)= 		  =  0.539 +- 0.009, 0.639 +- 0.013, 0.710 +- 0.017, 0.759 +- 0.024
Faith. GMean (KL)= 	  =  0.540 +- 0.008, 0.640 +- 0.013, 0.725 +- 0.014, 0.782 +- 0.020

Eval split test
Faith. Aritm (L1)= 		  =  0.526 +- 0.010, 0.493 +- 0.017, 0.544 +- 0.003, 0.645 +- 0.023
Faith. Armon (L1)= 		  =  0.513 +- 0.010, 0.468 +- 0.021, 0.448 +- 0.043, 0.448 +- 0.056
Faith. GMean (L1)= 	  =  0.520 +- 0.010, 0.480 +- 0.019, 0.493 +- 0.024, 0.537 +- 0.043
Faith. Aritm (KL)= 		  =  0.514 +- 0.014, 0.473 +- 0.026, 0.526 +- 0.006, 0.574 +- 0.021
Faith. Armon (KL)= 		  =  0.441 +- 0.012, 0.353 +- 0.023, 0.276 +- 0.075, 0.256 +- 0.063
Faith. GMean (KL)= 	  =  0.476 +- 0.012, 0.408 +- 0.023, 0.378 +- 0.054, 0.381 +- 0.056
Computed for split load_split = id



Completed in  0:28:35.471474  for GSATGIN GOODMotif/size



DONE GSAT GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:09:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:09:29 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9472
Train Loss: 0.0807
ID Validation ACCURACY: 0.8638
ID Validation Loss: 0.5569
ID Test ACCURACY: 0.8542
ID Test Loss: 0.6640
OOD Validation ACCURACY: 0.8582
OOD Validation Loss: 1.2856
OOD Test ACCURACY: 0.8136
OOD Test Loss: 3.3019

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ACCURACY: 0.9439
Train Loss: 0.0928
ID Validation ACCURACY: 0.8502
ID Validation Loss: 0.4924
ID Test ACCURACY: 0.8523
ID Test Loss: 0.5678
OOD Validation ACCURACY: 0.8595
OOD Validation Loss: 0.9019
OOD Test ACCURACY: 0.8168
OOD Test Loss: 2.0206

[0m[1;37mINFO[0m: [1mChartInfo 0.8542 0.8136 0.8523 0.8168 0.8502 0.8595[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/07/2024 01:09:31 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.823
SUFF++ for r=0.6 class 0.0 = 0.856 +- 0.316 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 1.0 = 0.856 +- 0.316 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all KL = 0.75 +- 0.316 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all L1 = 0.856 +- 0.208 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.853
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.175 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.175 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.933 +- 0.175 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.926 +- 0.168 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.744
SUFF++ for r=0.3 class 0.0 = 0.781 +- 0.388 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 class 1.0 = 0.72 +- 0.388 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 all KL = 0.429 +- 0.388 (in-sample avg dev_std = 0.627)
SUFF++ for r=0.3 all L1 = 0.75 +- 0.205 (in-sample avg dev_std = 0.627)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.792
SUFF++ for r=0.6 class 0.0 = 0.893 +- 0.367 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 1.0 = 0.845 +- 0.367 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all KL = 0.715 +- 0.367 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all L1 = 0.868 +- 0.192 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
SUFF++ for r=0.9 class 0.0 = 0.945 +- 0.173 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.173 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.93 +- 0.173 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.137 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.85
NEC for r=0.6 class 0.0 = 0.127 +- 0.278 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 1.0 = 0.099 +- 0.278 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all KL = 0.134 +- 0.278 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all L1 = 0.111 +- 0.225 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.068 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1.0 = 0.049 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.055 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.057 +- 0.146 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.867
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.074 +- 0.162 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 1.0 = 0.046 +- 0.162 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all KL = 0.057 +- 0.162 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all L1 = 0.057 +- 0.150 (in-sample avg dev_std = 0.170)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.811
NEC for r=0.3 class 0.0 = 0.096 +- 0.293 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 1.0 = 0.126 +- 0.293 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all KL = 0.158 +- 0.293 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all L1 = 0.112 +- 0.214 (in-sample avg dev_std = 0.276)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.815
NEC for r=0.6 class 0.0 = 0.076 +- 0.260 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 1.0 = 0.093 +- 0.260 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all KL = 0.127 +- 0.260 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all L1 = 0.085 +- 0.177 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.83
NEC for r=0.9 class 0.0 = 0.069 +- 0.206 (in-sample avg dev_std = 0.187)
NEC for r=0.9 class 1.0 = 0.069 +- 0.206 (in-sample avg dev_std = 0.187)
NEC for r=0.9 all KL = 0.087 +- 0.206 (in-sample avg dev_std = 0.187)
NEC for r=0.9 all L1 = 0.069 +- 0.154 (in-sample avg dev_std = 0.187)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0.0 = 0.069 +- 0.189 (in-sample avg dev_std = 0.180)
NEC for r=1.0 class 1.0 = 0.066 +- 0.189 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all KL = 0.077 +- 0.189 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all L1 = 0.067 +- 0.158 (in-sample avg dev_std = 0.180)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:11:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:40 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 174...
[0m[1;37mINFO[0m: [1mCheckpoint 174: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0755
ID Validation ACCURACY: 0.8640
ID Validation Loss: 0.6847
ID Test ACCURACY: 0.8623
ID Test Loss: 0.7604
OOD Validation ACCURACY: 0.8614
OOD Validation Loss: 1.0820
OOD Test ACCURACY: 0.8157
OOD Test Loss: 2.1369

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0754
ID Validation ACCURACY: 0.8619
ID Validation Loss: 0.7617
ID Test ACCURACY: 0.8598
ID Test Loss: 0.8515
OOD Validation ACCURACY: 0.8642
OOD Validation Loss: 1.0488
OOD Test ACCURACY: 0.8181
OOD Test Loss: 2.0109

[0m[1;37mINFO[0m: [1mChartInfo 0.8623 0.8157 0.8598 0.8181 0.8619 0.8642[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/07/2024 01:11:41 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.79
SUFF++ for r=0.6 class 0.0 = 0.708 +- 0.384 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 class 1.0 = 0.862 +- 0.384 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 all KL = 0.602 +- 0.384 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.225 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.186 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 class 1.0 = 0.937 +- 0.186 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 all KL = 0.932 +- 0.186 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 all L1 = 0.938 +- 0.158 (in-sample avg dev_std = 0.187)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.794
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.707
SUFF++ for r=0.3 class 0.0 = 0.626 +- 0.385 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 class 1.0 = 0.807 +- 0.385 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 all KL = 0.437 +- 0.385 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 all L1 = 0.719 +- 0.228 (in-sample avg dev_std = 0.641)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.805
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.77
SUFF++ for r=0.6 class 0.0 = 0.75 +- 0.351 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1.0 = 0.892 +- 0.351 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.663 +- 0.351 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.823 +- 0.211 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
SUFF++ for r=0.9 class 0.0 = 0.893 +- 0.199 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.199 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all KL = 0.901 +- 0.199 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all L1 = 0.914 +- 0.169 (in-sample avg dev_std = 0.221)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.836
NEC for r=0.6 class 0.0 = 0.138 +- 0.260 (in-sample avg dev_std = 0.251)
NEC for r=0.6 class 1.0 = 0.072 +- 0.260 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all KL = 0.121 +- 0.260 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all L1 = 0.1 +- 0.203 (in-sample avg dev_std = 0.251)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.056 +- 0.178 (in-sample avg dev_std = 0.173)
NEC for r=0.9 class 1.0 = 0.055 +- 0.178 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all KL = 0.063 +- 0.178 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all L1 = 0.056 +- 0.151 (in-sample avg dev_std = 0.173)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0.0 = 0.047 +- 0.183 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 1.0 = 0.053 +- 0.183 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all KL = 0.06 +- 0.183 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all L1 = 0.051 +- 0.149 (in-sample avg dev_std = 0.176)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.794
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.769
NEC for r=0.3 class 0.0 = 0.275 +- 0.362 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1.0 = 0.092 +- 0.362 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.26 +- 0.362 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.18 +- 0.264 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.805
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.804
NEC for r=0.6 class 0.0 = 0.196 +- 0.273 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1.0 = 0.057 +- 0.273 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.153 +- 0.273 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.124 +- 0.215 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.826
NEC for r=0.9 class 0.0 = 0.1 +- 0.180 (in-sample avg dev_std = 0.191)
NEC for r=0.9 class 1.0 = 0.056 +- 0.180 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all KL = 0.076 +- 0.180 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all L1 = 0.077 +- 0.167 (in-sample avg dev_std = 0.191)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.841
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0.0 = 0.081 +- 0.141 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 1.0 = 0.049 +- 0.141 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all KL = 0.051 +- 0.141 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all L1 = 0.065 +- 0.148 (in-sample avg dev_std = 0.148)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:13:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.8408
ID Test ACCURACY: 0.8625
ID Test Loss: 0.9711
OOD Validation ACCURACY: 0.8587
OOD Validation Loss: 1.3017
OOD Test ACCURACY: 0.7962
OOD Test Loss: 2.1004

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9474
Train Loss: 0.0804
ID Validation ACCURACY: 0.8585
ID Validation Loss: 0.5789
ID Test ACCURACY: 0.8617
ID Test Loss: 0.6702
OOD Validation ACCURACY: 0.8607
OOD Validation Loss: 0.9609
OOD Test ACCURACY: 0.8074
OOD Test Loss: 1.7859

[0m[1;37mINFO[0m: [1mChartInfo 0.8625 0.7962 0.8617 0.8074 0.8585 0.8607[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/07/2024 01:13:53 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.829
SUFF++ for r=0.6 class 0.0 = 0.831 +- 0.384 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1.0 = 0.898 +- 0.384 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.713 +- 0.384 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.87 +- 0.203 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.883
SUFF++ for r=0.9 class 0.0 = 0.93 +- 0.202 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 1.0 = 0.936 +- 0.202 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all KL = 0.928 +- 0.202 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.175 (in-sample avg dev_std = 0.174)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.81
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.729
SUFF++ for r=0.3 class 0.0 = 0.677 +- 0.375 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 class 1.0 = 0.776 +- 0.375 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 all KL = 0.407 +- 0.375 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 all L1 = 0.728 +- 0.215 (in-sample avg dev_std = 0.640)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.766
SUFF++ for r=0.6 class 0.0 = 0.772 +- 0.362 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1.0 = 0.907 +- 0.362 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.708 +- 0.362 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.842 +- 0.215 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.804
SUFF++ for r=0.9 class 0.0 = 0.899 +- 0.215 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.215 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all KL = 0.906 +- 0.215 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all L1 = 0.928 +- 0.159 (in-sample avg dev_std = 0.224)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.105 +- 0.262 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 1.0 = 0.048 +- 0.262 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all KL = 0.103 +- 0.262 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all L1 = 0.072 +- 0.188 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.082 +- 0.204 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.049 +- 0.204 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.072 +- 0.204 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.063 +- 0.174 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.869
NEC for r=1.0 class 0.0 = 0.078 +- 0.195 (in-sample avg dev_std = 0.168)
NEC for r=1.0 class 1.0 = 0.045 +- 0.195 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all KL = 0.064 +- 0.195 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all L1 = 0.059 +- 0.171 (in-sample avg dev_std = 0.168)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.81
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.805
NEC for r=0.3 class 0.0 = 0.15 +- 0.286 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1.0 = 0.087 +- 0.286 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.155 +- 0.286 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.118 +- 0.220 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.799
NEC for r=0.6 class 0.0 = 0.133 +- 0.259 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 1.0 = 0.069 +- 0.259 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all KL = 0.126 +- 0.259 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all L1 = 0.1 +- 0.199 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.804
NEC for r=0.9 class 0.0 = 0.1 +- 0.219 (in-sample avg dev_std = 0.231)
NEC for r=0.9 class 1.0 = 0.055 +- 0.219 (in-sample avg dev_std = 0.231)
NEC for r=0.9 all KL = 0.094 +- 0.219 (in-sample avg dev_std = 0.231)
NEC for r=0.9 all L1 = 0.077 +- 0.173 (in-sample avg dev_std = 0.231)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.809
NEC for r=1.0 class 0.0 = 0.09 +- 0.187 (in-sample avg dev_std = 0.195)
NEC for r=1.0 class 1.0 = 0.047 +- 0.187 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all KL = 0.071 +- 0.187 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all L1 = 0.068 +- 0.164 (in-sample avg dev_std = 0.195)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:16:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:16:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8664
ID Validation Loss: 0.7891
ID Test ACCURACY: 0.8602
ID Test Loss: 0.8571
OOD Validation ACCURACY: 0.8539
OOD Validation Loss: 1.3496
OOD Test ACCURACY: 0.7823
OOD Test Loss: 3.4741

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 96...
[0m[1;37mINFO[0m: [1mCheckpoint 96: 
-----------------------------------
Train ACCURACY: 0.9474
Train Loss: 0.0816
ID Validation ACCURACY: 0.8564
ID Validation Loss: 0.6260
ID Test ACCURACY: 0.8576
ID Test Loss: 0.7197
OOD Validation ACCURACY: 0.8616
OOD Validation Loss: 1.2995
OOD Test ACCURACY: 0.8121
OOD Test Loss: 2.8311

[0m[1;37mINFO[0m: [1mChartInfo 0.8602 0.7823 0.8576 0.8121 0.8564 0.8616[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/07/2024 01:16:05 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.826
SUFF++ for r=0.6 class 0.0 = 0.856 +- 0.358 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 1.0 = 0.927 +- 0.358 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all KL = 0.784 +- 0.358 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all L1 = 0.897 +- 0.194 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.838
SUFF++ for r=0.9 class 0.0 = 0.891 +- 0.246 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.246 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.903 +- 0.246 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.914 +- 0.217 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.803
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.735
SUFF++ for r=0.3 class 0.0 = 0.691 +- 0.429 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 class 1.0 = 0.874 +- 0.429 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 all KL = 0.5 +- 0.429 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.3 all L1 = 0.786 +- 0.222 (in-sample avg dev_std = 0.591)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.762
SUFF++ for r=0.6 class 0.0 = 0.802 +- 0.370 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 1.0 = 0.951 +- 0.370 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all KL = 0.746 +- 0.370 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all L1 = 0.879 +- 0.196 (in-sample avg dev_std = 0.410)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.787
SUFF++ for r=0.9 class 0.0 = 0.893 +- 0.218 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 1.0 = 0.972 +- 0.218 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all KL = 0.907 +- 0.218 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.151 (in-sample avg dev_std = 0.227)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.124 +- 0.281 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 1.0 = 0.051 +- 0.281 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all KL = 0.108 +- 0.281 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all L1 = 0.081 +- 0.217 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.094 +- 0.220 (in-sample avg dev_std = 0.186)
NEC for r=0.9 class 1.0 = 0.043 +- 0.220 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all KL = 0.072 +- 0.220 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all L1 = 0.064 +- 0.190 (in-sample avg dev_std = 0.186)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.867
NEC for r=1.0 class 0.0 = 0.083 +- 0.199 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 1.0 = 0.036 +- 0.199 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all KL = 0.061 +- 0.199 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all L1 = 0.056 +- 0.167 (in-sample avg dev_std = 0.192)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.803
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.798
NEC for r=0.3 class 0.0 = 0.19 +- 0.366 (in-sample avg dev_std = 0.351)
NEC for r=0.3 class 1.0 = 0.074 +- 0.366 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all KL = 0.211 +- 0.366 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all L1 = 0.131 +- 0.246 (in-sample avg dev_std = 0.351)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.796
NEC for r=0.6 class 0.0 = 0.141 +- 0.295 (in-sample avg dev_std = 0.289)
NEC for r=0.6 class 1.0 = 0.043 +- 0.295 (in-sample avg dev_std = 0.289)
NEC for r=0.6 all KL = 0.145 +- 0.295 (in-sample avg dev_std = 0.289)
NEC for r=0.6 all L1 = 0.09 +- 0.198 (in-sample avg dev_std = 0.289)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.79
NEC for r=0.9 class 0.0 = 0.113 +- 0.214 (in-sample avg dev_std = 0.222)
NEC for r=0.9 class 1.0 = 0.026 +- 0.214 (in-sample avg dev_std = 0.222)
NEC for r=0.9 all KL = 0.088 +- 0.214 (in-sample avg dev_std = 0.222)
NEC for r=0.9 all L1 = 0.069 +- 0.162 (in-sample avg dev_std = 0.222)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.799
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0.0 = 0.091 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 1.0 = 0.027 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all KL = 0.066 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all L1 = 0.058 +- 0.143 (in-sample avg dev_std = 0.183)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:18:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:18:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:18:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9483
Train Loss: 0.0767
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.7098
ID Test ACCURACY: 0.8564
ID Test Loss: 0.8617
OOD Validation ACCURACY: 0.8566
OOD Validation Loss: 1.3829
OOD Test ACCURACY: 0.8027
OOD Test Loss: 3.1845

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.7238
ID Test ACCURACY: 0.8580
ID Test Loss: 0.8646
OOD Validation ACCURACY: 0.8584
OOD Validation Loss: 1.4575
OOD Test ACCURACY: 0.8023
OOD Test Loss: 3.6392

[0m[1;37mINFO[0m: [1mChartInfo 0.8564 0.8027 0.8580 0.8023 0.8630 0.8584[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 05/07/2024 01:18:18 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.828
SUFF++ for r=0.6 class 0.0 = 0.877 +- 0.359 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 class 1.0 = 0.855 +- 0.359 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all KL = 0.716 +- 0.359 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all L1 = 0.864 +- 0.199 (in-sample avg dev_std = 0.430)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.915 +- 0.210 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 class 1.0 = 0.95 +- 0.210 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all KL = 0.922 +- 0.210 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.178 (in-sample avg dev_std = 0.165)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.746
SUFF++ for r=0.3 class 0.0 = 0.739 +- 0.427 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 1.0 = 0.801 +- 0.427 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all KL = 0.487 +- 0.427 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all L1 = 0.771 +- 0.231 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.788
SUFF++ for r=0.6 class 0.0 = 0.825 +- 0.406 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 1.0 = 0.834 +- 0.406 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all KL = 0.622 +- 0.406 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.212 (in-sample avg dev_std = 0.492)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.265 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 1.0 = 0.926 +- 0.265 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all KL = 0.871 +- 0.265 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all L1 = 0.921 +- 0.168 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.868
NEC for r=0.6 class 0.0 = 0.085 +- 0.234 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 1.0 = 0.056 +- 0.234 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all KL = 0.089 +- 0.234 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all L1 = 0.068 +- 0.180 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.065 +- 0.199 (in-sample avg dev_std = 0.178)
NEC for r=0.9 class 1.0 = 0.048 +- 0.199 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all KL = 0.069 +- 0.199 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all L1 = 0.055 +- 0.162 (in-sample avg dev_std = 0.178)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.872
NEC for r=1.0 class 0.0 = 0.063 +- 0.169 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1.0 = 0.042 +- 0.169 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.055 +- 0.169 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.051 +- 0.152 (in-sample avg dev_std = 0.159)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.795
NEC for r=0.3 class 0.0 = 0.17 +- 0.382 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 1.0 = 0.129 +- 0.382 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all KL = 0.252 +- 0.382 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all L1 = 0.149 +- 0.256 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.816
NEC for r=0.6 class 0.0 = 0.116 +- 0.304 (in-sample avg dev_std = 0.292)
NEC for r=0.6 class 1.0 = 0.088 +- 0.304 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all KL = 0.162 +- 0.304 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all L1 = 0.102 +- 0.206 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.82
NEC for r=0.9 class 0.0 = 0.088 +- 0.251 (in-sample avg dev_std = 0.234)
NEC for r=0.9 class 1.0 = 0.067 +- 0.251 (in-sample avg dev_std = 0.234)
NEC for r=0.9 all KL = 0.105 +- 0.251 (in-sample avg dev_std = 0.234)
NEC for r=0.9 all L1 = 0.077 +- 0.187 (in-sample avg dev_std = 0.234)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.815
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.817
NEC for r=1.0 class 0.0 = 0.087 +- 0.236 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 1.0 = 0.058 +- 0.236 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all KL = 0.094 +- 0.236 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all L1 = 0.072 +- 0.177 (in-sample avg dev_std = 0.222)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.75, 0.933, 1.0], 'all_L1': [0.856, 0.926, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.602, 0.932, 1.0], 'all_L1': [0.798, 0.938, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.713, 0.928, 1.0], 'all_L1': [0.87, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.784, 0.903, 1.0], 'all_L1': [0.897, 0.914, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.922, 1.0], 'all_L1': [0.864, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.134, 0.055, 0.057], 'all_L1': [0.111, 0.057, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.121, 0.063, 0.06], 'all_L1': [0.1, 0.056, 0.051]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.072, 0.064], 'all_L1': [0.072, 0.063, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.108, 0.072, 0.061], 'all_L1': [0.081, 0.064, 0.056]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.069, 0.055], 'all_L1': [0.068, 0.055, 0.051]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.429, 0.715, 0.93, 1.0], 'all_L1': [0.75, 0.868, 0.939, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.437, 0.663, 0.901, 1.0], 'all_L1': [0.719, 0.823, 0.914, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.407, 0.708, 0.906, 1.0], 'all_L1': [0.728, 0.842, 0.928, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.5, 0.746, 0.907, 1.0], 'all_L1': [0.786, 0.879, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.487, 0.622, 0.871, 1.0], 'all_L1': [0.771, 0.83, 0.921, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.158, 0.127, 0.087, 0.077], 'all_L1': [0.112, 0.085, 0.069, 0.067]}), defaultdict(<class 'list'>, {'all_KL': [0.26, 0.153, 0.076, 0.051], 'all_L1': [0.18, 0.124, 0.077, 0.065]}), defaultdict(<class 'list'>, {'all_KL': [0.155, 0.126, 0.094, 0.071], 'all_L1': [0.118, 0.1, 0.077, 0.068]}), defaultdict(<class 'list'>, {'all_KL': [0.211, 0.145, 0.088, 0.066], 'all_L1': [0.131, 0.09, 0.069, 0.058]}), defaultdict(<class 'list'>, {'all_KL': [0.252, 0.162, 0.105, 0.094], 'all_L1': [0.149, 0.102, 0.077, 0.072]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.857 +- 0.033, 0.929 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.713 +- 0.061, 0.924 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.819 +- 0.015, 0.863 +- 0.016
nec class all_L1  =  0.086 +- 0.017, 0.059 +- 0.004, 0.055 +- 0.003
nec class all_KL  =  0.111 +- 0.015, 0.066 +- 0.006, 0.059 +- 0.003
nec_acc_int  =  0.856 +- 0.012, 0.865 +- 0.004, 0.866 +- 0.006

Eval split test
suff++ class all_L1  =  0.751 +- 0.025, 0.848 +- 0.022, 0.927 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.452 +- 0.036, 0.691 +- 0.043, 0.903 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.732 +- 0.014, 0.776 +- 0.012, 0.810 +- 0.014
nec class all_L1  =  0.138 +- 0.025, 0.100 +- 0.013, 0.074 +- 0.004, 0.066 +- 0.005
nec class all_KL  =  0.207 +- 0.045, 0.143 +- 0.014, 0.090 +- 0.009, 0.072 +- 0.014
nec_acc_int  =  0.796 +- 0.014, 0.806 +- 0.008, 0.814 +- 0.015, 0.820 +- 0.012


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.472 +- 0.014, 0.494 +- 0.003, 0.527 +- 0.002
Faith. Armon (L1)= 		  =  0.156 +- 0.027, 0.111 +- 0.007, 0.104 +- 0.006
Faith. GMean (L1)= 	  =  0.271 +- 0.024, 0.234 +- 0.007, 0.234 +- 0.007
Faith. Aritm (KL)= 		  =  0.412 +- 0.031, 0.495 +- 0.004, 0.530 +- 0.002
Faith. Armon (KL)= 		  =  0.191 +- 0.023, 0.123 +- 0.011, 0.112 +- 0.006
Faith. GMean (KL)= 	  =  0.280 +- 0.022, 0.247 +- 0.012, 0.244 +- 0.006

Eval split test
Faith. Aritm (L1)= 		  =  0.444 +- 0.015, 0.474 +- 0.006, 0.501 +- 0.003, 0.533 +- 0.002
Faith. Armon (L1)= 		  =  0.232 +- 0.034, 0.179 +- 0.021, 0.137 +- 0.007, 0.124 +- 0.008
Faith. GMean (L1)= 	  =  0.320 +- 0.027, 0.291 +- 0.016, 0.261 +- 0.006, 0.257 +- 0.009
Faith. Aritm (KL)= 		  =  0.330 +- 0.035, 0.417 +- 0.018, 0.496 +- 0.008, 0.536 +- 0.007
Faith. Armon (KL)= 		  =  0.282 +- 0.046, 0.236 +- 0.018, 0.163 +- 0.015, 0.134 +- 0.024
Faith. GMean (KL)= 	  =  0.305 +- 0.041, 0.313 +- 0.011, 0.285 +- 0.013, 0.267 +- 0.026
Computed for split load_split = id



Completed in  0:11:02.006681  for GSATvGIN GOODSST2/length



DONE GSAT GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:20:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/07/2024 01:20:57 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 01:20:59 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:00 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:02 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:21:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.4932
ID Test ACCURACY: 0.6588
ID Test Loss: 2.8260
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.9021
OOD Test ACCURACY: 0.5710
OOD Test Loss: 3.5556

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.4932
ID Test ACCURACY: 0.6588
ID Test Loss: 2.8260
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.9021
OOD Test ACCURACY: 0.5710
OOD Test Loss: 3.5556

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5710 0.6588 0.5710 0.7058 0.6471[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0 = 0.56 +- 0.329 (in-sample avg dev_std = 0.712)
SUFF++ for r=0.3 class 1 = 0.671 +- 0.329 (in-sample avg dev_std = 0.712)
SUFF++ for r=0.3 class 2 = 0.577 +- 0.329 (in-sample avg dev_std = 0.712)
SUFF++ for r=0.3 all KL = 0.326 +- 0.329 (in-sample avg dev_std = 0.712)
SUFF++ for r=0.3 all L1 = 0.618 +- 0.227 (in-sample avg dev_std = 0.712)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.712 +- 0.379 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.379 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 class 2 = 0.703 +- 0.379 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 all KL = 0.54 +- 0.379 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 all L1 = 0.751 +- 0.237 (in-sample avg dev_std = 0.569)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
SUFF++ for r=0.9 class 0 = 0.874 +- 0.232 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 1 = 0.891 +- 0.232 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 2 = 0.86 +- 0.232 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all KL = 0.858 +- 0.232 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.188 (in-sample avg dev_std = 0.315)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.522
SUFF++ for r=0.3 class 0 = 0.621 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 class 1 = 0.68 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 all KL = 0.373 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 all L1 = 0.648 +- 0.243 (in-sample avg dev_std = 0.688)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0 = 0.776 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 class 1 = 0.781 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 all KL = 0.629 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.241 (in-sample avg dev_std = 0.514)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.565
SUFF++ for r=0.9 class 0 = 0.858 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.871 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.874 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.197 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.652
NEC for r=0.3 class 0 = 0.234 +- 0.332 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 1 = 0.161 +- 0.332 (in-sample avg dev_std = 0.364)
NEC for r=0.3 class 2 = 0.217 +- 0.332 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all KL = 0.246 +- 0.332 (in-sample avg dev_std = 0.364)
NEC for r=0.3 all L1 = 0.194 +- 0.254 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.68
NEC for r=0.6 class 0 = 0.175 +- 0.324 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 1 = 0.122 +- 0.324 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 2 = 0.173 +- 0.324 (in-sample avg dev_std = 0.364)
NEC for r=0.6 all KL = 0.205 +- 0.324 (in-sample avg dev_std = 0.364)
NEC for r=0.6 all L1 = 0.149 +- 0.231 (in-sample avg dev_std = 0.364)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.678
NEC for r=0.9 class 0 = 0.124 +- 0.246 (in-sample avg dev_std = 0.304)
NEC for r=0.9 class 1 = 0.11 +- 0.246 (in-sample avg dev_std = 0.304)
NEC for r=0.9 class 2 = 0.146 +- 0.246 (in-sample avg dev_std = 0.304)
NEC for r=0.9 all KL = 0.137 +- 0.246 (in-sample avg dev_std = 0.304)
NEC for r=0.9 all L1 = 0.124 +- 0.201 (in-sample avg dev_std = 0.304)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.686
NEC for r=1.0 class 0 = 0.112 +- 0.218 (in-sample avg dev_std = 0.259)
NEC for r=1.0 class 1 = 0.105 +- 0.218 (in-sample avg dev_std = 0.259)
NEC for r=1.0 class 2 = 0.118 +- 0.218 (in-sample avg dev_std = 0.259)
NEC for r=1.0 all KL = 0.107 +- 0.218 (in-sample avg dev_std = 0.259)
NEC for r=1.0 all L1 = 0.11 +- 0.189 (in-sample avg dev_std = 0.259)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0 = 0.244 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 1 = 0.198 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 2 = 0.242 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all KL = 0.302 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all L1 = 0.221 +- 0.270 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.565
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.564
NEC for r=0.6 class 0 = 0.206 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 1 = 0.177 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 2 = 0.223 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all KL = 0.263 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all L1 = 0.196 +- 0.262 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0 = 0.169 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 1 = 0.149 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 2 = 0.169 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all KL = 0.159 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all L1 = 0.159 +- 0.225 (in-sample avg dev_std = 0.285)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.569
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.161 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 class 1 = 0.131 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 class 2 = 0.146 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all KL = 0.119 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all L1 = 0.142 +- 0.198 (in-sample avg dev_std = 0.252)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:24:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:27 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:30 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:30 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:24:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 47...
[0m[1;37mINFO[0m: [1mCheckpoint 47: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0026
ID Validation ACCURACY: 0.7022
ID Validation Loss: 1.9916
ID Test ACCURACY: 0.6625
ID Test Loss: 2.1428
OOD Validation ACCURACY: 0.6090
OOD Validation Loss: 2.2830
OOD Test ACCURACY: 0.5607
OOD Test Loss: 2.6565

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0020
ID Validation ACCURACY: 0.6661
ID Validation Loss: 2.4967
ID Test ACCURACY: 0.6390
ID Test Loss: 2.5469
OOD Validation ACCURACY: 0.6297
OOD Validation Loss: 2.7461
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.2086

[0m[1;37mINFO[0m: [1mChartInfo 0.6625 0.5607 0.6390 0.5635 0.6661 0.6297[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.566
SUFF++ for r=0.3 class 0 = 0.641 +- 0.301 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 1 = 0.673 +- 0.301 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 2 = 0.547 +- 0.301 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all KL = 0.445 +- 0.301 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all L1 = 0.63 +- 0.216 (in-sample avg dev_std = 0.628)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.623
SUFF++ for r=0.6 class 0 = 0.772 +- 0.316 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1 = 0.798 +- 0.316 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 2 = 0.68 +- 0.316 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.633 +- 0.316 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.759 +- 0.217 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.876 +- 0.197 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.889 +- 0.197 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.882 +- 0.197 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.887 +- 0.197 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.175 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.51
SUFF++ for r=0.3 class 0 = 0.687 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 1 = 0.703 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 2 = 0.661 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all KL = 0.527 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all L1 = 0.688 +- 0.231 (in-sample avg dev_std = 0.584)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.552
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.526
SUFF++ for r=0.6 class 0 = 0.781 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1 = 0.812 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.724 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.220 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.529
SUFF++ for r=0.9 class 0 = 0.864 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.893 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.180 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.621
NEC for r=0.3 class 0 = 0.241 +- 0.303 (in-sample avg dev_std = 0.354)
NEC for r=0.3 class 1 = 0.207 +- 0.303 (in-sample avg dev_std = 0.354)
NEC for r=0.3 class 2 = 0.286 +- 0.303 (in-sample avg dev_std = 0.354)
NEC for r=0.3 all KL = 0.255 +- 0.303 (in-sample avg dev_std = 0.354)
NEC for r=0.3 all L1 = 0.237 +- 0.252 (in-sample avg dev_std = 0.354)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.648
NEC for r=0.6 class 0 = 0.164 +- 0.267 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 1 = 0.138 +- 0.267 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 2 = 0.194 +- 0.267 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all KL = 0.174 +- 0.267 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all L1 = 0.16 +- 0.219 (in-sample avg dev_std = 0.318)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0 = 0.126 +- 0.212 (in-sample avg dev_std = 0.248)
NEC for r=0.9 class 1 = 0.112 +- 0.212 (in-sample avg dev_std = 0.248)
NEC for r=0.9 class 2 = 0.134 +- 0.212 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all KL = 0.115 +- 0.212 (in-sample avg dev_std = 0.248)
NEC for r=0.9 all L1 = 0.121 +- 0.192 (in-sample avg dev_std = 0.248)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.699
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.68
NEC for r=1.0 class 0 = 0.106 +- 0.184 (in-sample avg dev_std = 0.228)
NEC for r=1.0 class 1 = 0.108 +- 0.184 (in-sample avg dev_std = 0.228)
NEC for r=1.0 class 2 = 0.109 +- 0.184 (in-sample avg dev_std = 0.228)
NEC for r=1.0 all KL = 0.09 +- 0.184 (in-sample avg dev_std = 0.228)
NEC for r=1.0 all L1 = 0.108 +- 0.175 (in-sample avg dev_std = 0.228)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.54
NEC for r=0.3 class 0 = 0.261 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 1 = 0.223 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 2 = 0.247 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all KL = 0.296 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all L1 = 0.239 +- 0.259 (in-sample avg dev_std = 0.401)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.532
NEC for r=0.6 class 0 = 0.207 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.172 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.212 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.212 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.191 +- 0.240 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.18 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 1 = 0.15 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 2 = 0.176 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all KL = 0.149 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all L1 = 0.164 +- 0.213 (in-sample avg dev_std = 0.273)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.533
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.165 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1 = 0.135 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 2 = 0.159 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.117 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.149 +- 0.192 (in-sample avg dev_std = 0.241)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:27:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/07/2024 01:27:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 01:27:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 01:27:57 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 01:27:57 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 01:27:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:28:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.9121
ID Test ACCURACY: 0.6606
ID Test Loss: 2.3481
OOD Validation ACCURACY: 0.6006
OOD Validation Loss: 2.6995
OOD Test ACCURACY: 0.5271
OOD Test Loss: 4.1606

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0011
ID Validation ACCURACY: 0.6823
ID Validation Loss: 2.0777
ID Test ACCURACY: 0.6570
ID Test Loss: 2.3521
OOD Validation ACCURACY: 0.6342
OOD Validation Loss: 2.3260
OOD Test ACCURACY: 0.5546
OOD Test Loss: 3.2175

[0m[1;37mINFO[0m: [1mChartInfo 0.6606 0.5271 0.6570 0.5546 0.6823 0.6342[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0 = 0.659 +- 0.301 (in-sample avg dev_std = 0.671)
SUFF++ for r=0.3 class 1 = 0.637 +- 0.301 (in-sample avg dev_std = 0.671)
SUFF++ for r=0.3 class 2 = 0.552 +- 0.301 (in-sample avg dev_std = 0.671)
SUFF++ for r=0.3 all KL = 0.383 +- 0.301 (in-sample avg dev_std = 0.671)
SUFF++ for r=0.3 all L1 = 0.619 +- 0.213 (in-sample avg dev_std = 0.671)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0 = 0.806 +- 0.338 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.784 +- 0.338 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.702 +- 0.338 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.637 +- 0.338 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.235 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.678
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.674
SUFF++ for r=0.9 class 0 = 0.892 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all KL = 0.894 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.171 (in-sample avg dev_std = 0.264)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.465
SUFF++ for r=0.3 class 0 = 0.736 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 1 = 0.647 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all KL = 0.439 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all L1 = 0.654 +- 0.228 (in-sample avg dev_std = 0.636)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.488
SUFF++ for r=0.6 class 0 = 0.856 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 2 = 0.753 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.724 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.8 +- 0.224 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.505
SUFF++ for r=0.9 class 0 = 0.898 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 2 = 0.833 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all KL = 0.899 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all L1 = 0.876 +- 0.180 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.652
NEC for r=0.3 class 0 = 0.184 +- 0.293 (in-sample avg dev_std = 0.328)
NEC for r=0.3 class 1 = 0.191 +- 0.293 (in-sample avg dev_std = 0.328)
NEC for r=0.3 class 2 = 0.25 +- 0.293 (in-sample avg dev_std = 0.328)
NEC for r=0.3 all KL = 0.229 +- 0.293 (in-sample avg dev_std = 0.328)
NEC for r=0.3 all L1 = 0.205 +- 0.242 (in-sample avg dev_std = 0.328)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.666
NEC for r=0.6 class 0 = 0.127 +- 0.278 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 1 = 0.136 +- 0.278 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 2 = 0.211 +- 0.278 (in-sample avg dev_std = 0.338)
NEC for r=0.6 all KL = 0.184 +- 0.278 (in-sample avg dev_std = 0.338)
NEC for r=0.6 all L1 = 0.155 +- 0.224 (in-sample avg dev_std = 0.338)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0 = 0.122 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.13 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.16 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.126 +- 0.220 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.136 +- 0.198 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.681
NEC for r=1.0 class 0 = 0.12 +- 0.202 (in-sample avg dev_std = 0.242)
NEC for r=1.0 class 1 = 0.115 +- 0.202 (in-sample avg dev_std = 0.242)
NEC for r=1.0 class 2 = 0.146 +- 0.202 (in-sample avg dev_std = 0.242)
NEC for r=1.0 all KL = 0.107 +- 0.202 (in-sample avg dev_std = 0.242)
NEC for r=1.0 all L1 = 0.125 +- 0.187 (in-sample avg dev_std = 0.242)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.512
NEC for r=0.3 class 0 = 0.169 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1 = 0.209 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 2 = 0.256 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.247 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.21 +- 0.249 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.13 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 1 = 0.169 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 2 = 0.21 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all KL = 0.2 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all L1 = 0.169 +- 0.226 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.138 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.147 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.185 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.141 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.154 +- 0.211 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.527
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.509
NEC for r=1.0 class 0 = 0.134 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.14 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.171 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.121 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.146 +- 0.203 (in-sample avg dev_std = 0.246)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:31:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:26 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:30 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:31 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:31:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 45...
[0m[1;37mINFO[0m: [1mCheckpoint 45: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0008
ID Validation ACCURACY: 0.6931
ID Validation Loss: 1.9365
ID Test ACCURACY: 0.6318
ID Test Loss: 2.3364
OOD Validation ACCURACY: 0.6050
OOD Validation Loss: 2.4209
OOD Test ACCURACY: 0.5134
OOD Test Loss: 3.3352

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0010
ID Validation ACCURACY: 0.6516
ID Validation Loss: 2.3718
ID Test ACCURACY: 0.6462
ID Test Loss: 2.5842
OOD Validation ACCURACY: 0.6252
OOD Validation Loss: 2.5842
OOD Test ACCURACY: 0.5587
OOD Test Loss: 3.0403

[0m[1;37mINFO[0m: [1mChartInfo 0.6318 0.5134 0.6462 0.5587 0.6516 0.6252[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.575
SUFF++ for r=0.3 class 0 = 0.686 +- 0.306 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.306 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 class 2 = 0.568 +- 0.306 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all KL = 0.467 +- 0.306 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all L1 = 0.644 +- 0.217 (in-sample avg dev_std = 0.625)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0 = 0.779 +- 0.309 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 1 = 0.821 +- 0.309 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 2 = 0.74 +- 0.309 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all KL = 0.691 +- 0.309 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all L1 = 0.788 +- 0.220 (in-sample avg dev_std = 0.448)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0 = 0.897 +- 0.166 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1 = 0.901 +- 0.166 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 2 = 0.885 +- 0.166 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.906 +- 0.166 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.895 +- 0.155 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.46
SUFF++ for r=0.3 class 0 = 0.773 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 2 = 0.64 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all KL = 0.543 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all L1 = 0.693 +- 0.236 (in-sample avg dev_std = 0.565)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.494
SUFF++ for r=0.6 class 0 = 0.823 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 2 = 0.755 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all KL = 0.735 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.214 (in-sample avg dev_std = 0.421)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.5
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.496
SUFF++ for r=0.9 class 0 = 0.894 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all KL = 0.908 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all L1 = 0.868 +- 0.174 (in-sample avg dev_std = 0.232)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.637
NEC for r=0.3 class 0 = 0.247 +- 0.299 (in-sample avg dev_std = 0.370)
NEC for r=0.3 class 1 = 0.227 +- 0.299 (in-sample avg dev_std = 0.370)
NEC for r=0.3 class 2 = 0.258 +- 0.299 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all KL = 0.261 +- 0.299 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all L1 = 0.241 +- 0.249 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.658
NEC for r=0.6 class 0 = 0.192 +- 0.274 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 1 = 0.152 +- 0.274 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 2 = 0.17 +- 0.274 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all KL = 0.187 +- 0.274 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all L1 = 0.167 +- 0.230 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0 = 0.139 +- 0.223 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.127 +- 0.223 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.129 +- 0.223 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.125 +- 0.223 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.131 +- 0.198 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.692
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.667
NEC for r=1.0 class 0 = 0.131 +- 0.197 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 1 = 0.118 +- 0.197 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 2 = 0.116 +- 0.197 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all KL = 0.104 +- 0.197 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all L1 = 0.121 +- 0.182 (in-sample avg dev_std = 0.237)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.486
NEC for r=0.3 class 0 = 0.178 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.254 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.267 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.29 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.238 +- 0.256 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.5
NEC for r=0.6 class 0 = 0.164 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 1 = 0.209 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 2 = 0.217 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all KL = 0.211 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all L1 = 0.199 +- 0.233 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.5
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.138 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 1 = 0.171 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 2 = 0.175 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all KL = 0.131 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all L1 = 0.164 +- 0.206 (in-sample avg dev_std = 0.257)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.502
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.502
NEC for r=1.0 class 0 = 0.121 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 1 = 0.162 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 2 = 0.173 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all KL = 0.11 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all L1 = 0.154 +- 0.193 (in-sample avg dev_std = 0.233)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 13:34:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/07/2024 01:34:53 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 01:34:56 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 01:34:56 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 01:34:57 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 01:34:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 01:35:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 95...
[0m[1;37mINFO[0m: [1mCheckpoint 95: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.2470
ID Test ACCURACY: 0.6606
ID Test Loss: 2.5508
OOD Validation ACCURACY: 0.6134
OOD Validation Loss: 2.6879
OOD Test ACCURACY: 0.5374
OOD Test Loss: 3.7189

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0026
ID Validation ACCURACY: 0.6606
ID Validation Loss: 2.0494
ID Test ACCURACY: 0.6390
ID Test Loss: 2.2359
OOD Validation ACCURACY: 0.6275
OOD Validation Loss: 2.4516
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.1232

[0m[1;37mINFO[0m: [1mChartInfo 0.6606 0.5374 0.6390 0.5635 0.6606 0.6275[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0 = 0.593 +- 0.347 (in-sample avg dev_std = 0.637)
SUFF++ for r=0.3 class 1 = 0.739 +- 0.347 (in-sample avg dev_std = 0.637)
SUFF++ for r=0.3 class 2 = 0.62 +- 0.347 (in-sample avg dev_std = 0.637)
SUFF++ for r=0.3 all KL = 0.44 +- 0.347 (in-sample avg dev_std = 0.637)
SUFF++ for r=0.3 all L1 = 0.67 +- 0.238 (in-sample avg dev_std = 0.637)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0 = 0.727 +- 0.349 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 class 1 = 0.81 +- 0.349 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 class 2 = 0.71 +- 0.349 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 all KL = 0.604 +- 0.349 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.6 all L1 = 0.762 +- 0.235 (in-sample avg dev_std = 0.512)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.692
SUFF++ for r=0.9 class 0 = 0.861 +- 0.208 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.208 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 2 = 0.866 +- 0.208 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all KL = 0.868 +- 0.208 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all L1 = 0.875 +- 0.186 (in-sample avg dev_std = 0.295)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.658 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 all KL = 0.395 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 all L1 = 0.654 +- 0.224 (in-sample avg dev_std = 0.662)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.518
SUFF++ for r=0.6 class 0 = 0.778 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.609 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.754 +- 0.229 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
SUFF++ for r=0.9 class 0 = 0.869 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 1 = 0.854 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all KL = 0.868 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.195 (in-sample avg dev_std = 0.298)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.646
NEC for r=0.3 class 0 = 0.238 +- 0.313 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 1 = 0.149 +- 0.313 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 2 = 0.212 +- 0.313 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all KL = 0.228 +- 0.313 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all L1 = 0.188 +- 0.249 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0 = 0.182 +- 0.283 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 1 = 0.123 +- 0.283 (in-sample avg dev_std = 0.311)
NEC for r=0.6 class 2 = 0.18 +- 0.283 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all KL = 0.175 +- 0.283 (in-sample avg dev_std = 0.311)
NEC for r=0.6 all L1 = 0.153 +- 0.237 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.675
NEC for r=0.9 class 0 = 0.142 +- 0.226 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.122 +- 0.226 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.117 +- 0.226 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.122 +- 0.226 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.125 +- 0.201 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.667
NEC for r=1.0 class 0 = 0.138 +- 0.213 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.117 +- 0.213 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.113 +- 0.213 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.106 +- 0.213 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.121 +- 0.200 (in-sample avg dev_std = 0.246)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0 = 0.214 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 1 = 0.18 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 2 = 0.234 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all KL = 0.257 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all L1 = 0.202 +- 0.258 (in-sample avg dev_std = 0.384)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.538
NEC for r=0.6 class 0 = 0.184 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.164 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.205 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.216 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.179 +- 0.243 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.534
NEC for r=0.9 class 0 = 0.147 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 1 = 0.147 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 2 = 0.155 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all KL = 0.144 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all L1 = 0.149 +- 0.215 (in-sample avg dev_std = 0.285)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.531
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.138 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 1 = 0.135 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 2 = 0.15 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all KL = 0.117 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all L1 = 0.139 +- 0.195 (in-sample avg dev_std = 0.255)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.326, 0.54, 0.858, 1.0], 'all_L1': [0.618, 0.751, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.445, 0.633, 0.887, 1.0], 'all_L1': [0.63, 0.759, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.383, 0.637, 0.894, 1.0], 'all_L1': [0.619, 0.766, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.467, 0.691, 0.906, 1.0], 'all_L1': [0.644, 0.788, 0.895, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.44, 0.604, 0.868, 1.0], 'all_L1': [0.67, 0.762, 0.875, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.246, 0.205, 0.137, 0.107], 'all_L1': [0.194, 0.149, 0.124, 0.11]}), defaultdict(<class 'list'>, {'all_KL': [0.255, 0.174, 0.115, 0.09], 'all_L1': [0.237, 0.16, 0.121, 0.108]}), defaultdict(<class 'list'>, {'all_KL': [0.229, 0.184, 0.126, 0.107], 'all_L1': [0.205, 0.155, 0.136, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.261, 0.187, 0.125, 0.104], 'all_L1': [0.241, 0.167, 0.131, 0.121]}), defaultdict(<class 'list'>, {'all_KL': [0.228, 0.175, 0.122, 0.106], 'all_L1': [0.188, 0.153, 0.125, 0.121]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.373, 0.629, 0.874, 1.0], 'all_L1': [0.648, 0.769, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.527, 0.724, 0.893, 1.0], 'all_L1': [0.688, 0.787, 0.866, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.724, 0.899, 1.0], 'all_L1': [0.654, 0.8, 0.876, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.543, 0.735, 0.908, 1.0], 'all_L1': [0.693, 0.782, 0.868, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.395, 0.609, 0.868, 1.0], 'all_L1': [0.654, 0.754, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.302, 0.263, 0.159, 0.119], 'all_L1': [0.221, 0.196, 0.159, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.296, 0.212, 0.149, 0.117], 'all_L1': [0.239, 0.191, 0.164, 0.149]}), defaultdict(<class 'list'>, {'all_KL': [0.247, 0.2, 0.141, 0.121], 'all_L1': [0.21, 0.169, 0.154, 0.146]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.211, 0.131, 0.11], 'all_L1': [0.238, 0.199, 0.164, 0.154]}), defaultdict(<class 'list'>, {'all_KL': [0.257, 0.216, 0.144, 0.117], 'all_L1': [0.202, 0.179, 0.149, 0.139]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.636 +- 0.019, 0.765 +- 0.012, 0.883 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.412 +- 0.051, 0.621 +- 0.049, 0.883 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.572 +- 0.009, 0.632 +- 0.007, 0.680 +- 0.006
nec class all_L1  =  0.213 +- 0.022, 0.157 +- 0.006, 0.127 +- 0.005, 0.117 +- 0.007
nec class all_KL  =  0.244 +- 0.013, 0.185 +- 0.011, 0.125 +- 0.007, 0.103 +- 0.006
nec_acc_int  =  0.641 +- 0.012, 0.660 +- 0.012, 0.674 +- 0.006, 0.676 +- 0.008

Eval split test
suff++ class all_L1  =  0.667 +- 0.019, 0.778 +- 0.016, 0.866 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.455 +- 0.069, 0.684 +- 0.054, 0.888 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.493 +- 0.025, 0.515 +- 0.022, 0.526 +- 0.024
nec class all_L1  =  0.222 +- 0.015, 0.187 +- 0.011, 0.158 +- 0.006, 0.146 +- 0.005
nec class all_KL  =  0.278 +- 0.022, 0.220 +- 0.022, 0.145 +- 0.009, 0.117 +- 0.004
nec_acc_int  =  0.528 +- 0.027, 0.527 +- 0.024, 0.528 +- 0.021, 0.529 +- 0.023


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.425 +- 0.014, 0.461 +- 0.009, 0.505 +- 0.005, 0.558 +- 0.003
Faith. Armon (L1)= 		  =  0.318 +- 0.024, 0.260 +- 0.009, 0.223 +- 0.008, 0.209 +- 0.011
Faith. GMean (L1)= 	  =  0.368 +- 0.019, 0.346 +- 0.009, 0.335 +- 0.008, 0.342 +- 0.010
Faith. Aritm (KL)= 		  =  0.328 +- 0.029, 0.403 +- 0.022, 0.504 +- 0.008, 0.551 +- 0.003
Faith. Armon (KL)= 		  =  0.305 +- 0.021, 0.284 +- 0.011, 0.219 +- 0.011, 0.186 +- 0.011
Faith. GMean (KL)= 	  =  0.316 +- 0.025, 0.338 +- 0.012, 0.332 +- 0.008, 0.320 +- 0.010

Eval split test
Faith. Aritm (L1)= 		  =  0.445 +- 0.016, 0.483 +- 0.009, 0.512 +- 0.004, 0.573 +- 0.003
Faith. Armon (L1)= 		  =  0.333 +- 0.019, 0.301 +- 0.015, 0.267 +- 0.008, 0.255 +- 0.008
Faith. GMean (L1)= 	  =  0.385 +- 0.018, 0.381 +- 0.011, 0.370 +- 0.007, 0.382 +- 0.007
Faith. Aritm (KL)= 		  =  0.367 +- 0.039, 0.452 +- 0.022, 0.517 +- 0.006, 0.558 +- 0.002
Faith. Armon (KL)= 		  =  0.344 +- 0.029, 0.332 +- 0.020, 0.249 +- 0.013, 0.209 +- 0.006
Faith. GMean (KL)= 	  =  0.355 +- 0.034, 0.387 +- 0.015, 0.358 +- 0.010, 0.342 +- 0.005
Computed for split load_split = id



Completed in  0:17:31.931025  for GSATvGIN GOODTwitter/length



DONE GSAT GOODTwitter/length
DONE all :)
Time to compute metrics!

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:18:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:31 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:33 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:33 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:34 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:36 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:18:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.4932
ID Test ACCURACY: 0.6588
ID Test Loss: 2.8260
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.9021
OOD Test ACCURACY: 0.5710
OOD Test Loss: 3.5556

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.4932
ID Test ACCURACY: 0.6588
ID Test Loss: 2.8260
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.9021
OOD Test ACCURACY: 0.5710
OOD Test Loss: 3.5556

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5710 0.6588 0.5710 0.7058 0.6471[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0 = 0.237 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1 = 0.175 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 2 = 0.24 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.272 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.21 +- 0.265 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0 = 0.186 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 1 = 0.141 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 2 = 0.173 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all KL = 0.214 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all L1 = 0.162 +- 0.238 (in-sample avg dev_std = 0.352)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.649
NEC for r=0.9 class 0 = 0.14 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 class 1 = 0.107 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 class 2 = 0.124 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all KL = 0.134 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all L1 = 0.12 +- 0.206 (in-sample avg dev_std = 0.267)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.657
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.647
NEC for r=1.0 class 0 = 0.128 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1 = 0.093 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 2 = 0.124 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.105 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.111 +- 0.196 (in-sample avg dev_std = 0.238)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0 = 0.244 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 1 = 0.198 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 2 = 0.242 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all KL = 0.302 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all L1 = 0.221 +- 0.270 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.565
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.564
NEC for r=0.6 class 0 = 0.206 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 1 = 0.177 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 2 = 0.223 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all KL = 0.263 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all L1 = 0.196 +- 0.262 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0 = 0.169 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 1 = 0.149 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 2 = 0.169 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all KL = 0.159 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all L1 = 0.159 +- 0.225 (in-sample avg dev_std = 0.285)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.569
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.161 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 class 1 = 0.131 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 class 2 = 0.146 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all KL = 0.119 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all L1 = 0.142 +- 0.198 (in-sample avg dev_std = 0.252)


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0 = 0.562 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 class 1 = 0.652 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 class 2 = 0.55 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 all KL = 0.283 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.215 (in-sample avg dev_std = 0.729)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.605
SUFF++ for r=0.6 class 0 = 0.724 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 1 = 0.775 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 2 = 0.722 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all KL = 0.535 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all L1 = 0.746 +- 0.236 (in-sample avg dev_std = 0.568)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.651
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.645
SUFF++ for r=0.9 class 0 = 0.852 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 1 = 0.896 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 2 = 0.884 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all KL = 0.855 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.187 (in-sample avg dev_std = 0.317)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.522
SUFF++ for r=0.3 class 0 = 0.621 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 class 1 = 0.68 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 all KL = 0.373 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 all L1 = 0.648 +- 0.243 (in-sample avg dev_std = 0.688)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0 = 0.776 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 class 1 = 0.781 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 all KL = 0.629 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.241 (in-sample avg dev_std = 0.514)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.565
SUFF++ for r=0.9 class 0 = 0.858 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.871 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.874 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.197 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:21:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:35 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:37 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:21:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 47...
[0m[1;37mINFO[0m: [1mCheckpoint 47: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0026
ID Validation ACCURACY: 0.7022
ID Validation Loss: 1.9916
ID Test ACCURACY: 0.6625
ID Test Loss: 2.1428
OOD Validation ACCURACY: 0.6090
OOD Validation Loss: 2.2830
OOD Test ACCURACY: 0.5607
OOD Test Loss: 2.6565

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0020
ID Validation ACCURACY: 0.6661
ID Validation Loss: 2.4967
ID Test ACCURACY: 0.6390
ID Test Loss: 2.5469
OOD Validation ACCURACY: 0.6297
OOD Validation Loss: 2.7461
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.2086

[0m[1;37mINFO[0m: [1mChartInfo 0.6625 0.5607 0.6390 0.5635 0.6661 0.6297[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0 = 0.237 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 1 = 0.186 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 2 = 0.289 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all KL = 0.249 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all L1 = 0.229 +- 0.251 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.63
NEC for r=0.6 class 0 = 0.185 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 1 = 0.139 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 2 = 0.207 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all KL = 0.188 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all L1 = 0.171 +- 0.230 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.655
NEC for r=0.9 class 0 = 0.145 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 1 = 0.109 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 2 = 0.138 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all KL = 0.12 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all L1 = 0.126 +- 0.193 (in-sample avg dev_std = 0.264)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.661
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.657
NEC for r=1.0 class 0 = 0.144 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 class 1 = 0.1 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 class 2 = 0.117 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all KL = 0.099 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all L1 = 0.116 +- 0.184 (in-sample avg dev_std = 0.247)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.54
NEC for r=0.3 class 0 = 0.261 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 1 = 0.223 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 2 = 0.247 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all KL = 0.296 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all L1 = 0.239 +- 0.259 (in-sample avg dev_std = 0.401)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.532
NEC for r=0.6 class 0 = 0.207 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.172 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.212 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.212 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.191 +- 0.240 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.18 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 1 = 0.15 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 2 = 0.176 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all KL = 0.149 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all L1 = 0.164 +- 0.213 (in-sample avg dev_std = 0.273)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.533
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.165 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1 = 0.135 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 2 = 0.159 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.117 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.149 +- 0.192 (in-sample avg dev_std = 0.241)


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.546
SUFF++ for r=0.3 class 0 = 0.647 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 class 1 = 0.671 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 all KL = 0.439 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 all L1 = 0.632 +- 0.215 (in-sample avg dev_std = 0.646)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.609
SUFF++ for r=0.6 class 0 = 0.789 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 1 = 0.803 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 2 = 0.696 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all KL = 0.659 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all L1 = 0.768 +- 0.224 (in-sample avg dev_std = 0.481)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.659
SUFF++ for r=0.9 class 0 = 0.869 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.868 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.881 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.173 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.51
SUFF++ for r=0.3 class 0 = 0.687 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 1 = 0.703 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 2 = 0.661 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all KL = 0.527 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all L1 = 0.688 +- 0.231 (in-sample avg dev_std = 0.584)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.552
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.526
SUFF++ for r=0.6 class 0 = 0.781 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1 = 0.812 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.724 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.220 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.529
SUFF++ for r=0.9 class 0 = 0.864 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.893 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.180 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:24:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:41 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:43 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:44 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:46 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:24:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.9121
ID Test ACCURACY: 0.6606
ID Test Loss: 2.3481
OOD Validation ACCURACY: 0.6006
OOD Validation Loss: 2.6995
OOD Test ACCURACY: 0.5271
OOD Test Loss: 4.1606

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0011
ID Validation ACCURACY: 0.6823
ID Validation Loss: 2.0777
ID Test ACCURACY: 0.6570
ID Test Loss: 2.3521
OOD Validation ACCURACY: 0.6342
OOD Validation Loss: 2.3260
OOD Test ACCURACY: 0.5546
OOD Test Loss: 3.2175

[0m[1;37mINFO[0m: [1mChartInfo 0.6606 0.5271 0.6570 0.5546 0.6823 0.6342[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.642
NEC for r=0.3 class 0 = 0.232 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 1 = 0.198 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 2 = 0.216 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all KL = 0.24 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all L1 = 0.212 +- 0.251 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0 = 0.161 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 1 = 0.163 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 2 = 0.148 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all KL = 0.187 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all L1 = 0.158 +- 0.223 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.652
NEC for r=0.9 class 0 = 0.117 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 class 1 = 0.12 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 class 2 = 0.109 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all KL = 0.112 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all L1 = 0.116 +- 0.184 (in-sample avg dev_std = 0.236)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.659
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.649
NEC for r=1.0 class 0 = 0.117 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 class 1 = 0.12 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 class 2 = 0.085 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 all KL = 0.097 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 all L1 = 0.109 +- 0.177 (in-sample avg dev_std = 0.226)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.512
NEC for r=0.3 class 0 = 0.169 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1 = 0.209 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 2 = 0.256 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.247 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.21 +- 0.249 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.13 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 1 = 0.169 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 2 = 0.21 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all KL = 0.2 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all L1 = 0.169 +- 0.226 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.138 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.147 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.185 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.141 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.154 +- 0.211 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.527
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.509
NEC for r=1.0 class 0 = 0.134 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.14 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.171 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.121 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.146 +- 0.203 (in-sample avg dev_std = 0.246)


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0 = 0.628 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 class 1 = 0.641 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 class 2 = 0.552 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 all KL = 0.366 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 all L1 = 0.612 +- 0.207 (in-sample avg dev_std = 0.681)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.613
SUFF++ for r=0.6 class 0 = 0.807 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 class 1 = 0.791 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 class 2 = 0.731 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 all KL = 0.652 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 all L1 = 0.778 +- 0.225 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.643
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.644
SUFF++ for r=0.9 class 0 = 0.892 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 1 = 0.874 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 2 = 0.899 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all KL = 0.892 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.177 (in-sample avg dev_std = 0.257)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.465
SUFF++ for r=0.3 class 0 = 0.736 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 1 = 0.647 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all KL = 0.439 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all L1 = 0.654 +- 0.228 (in-sample avg dev_std = 0.636)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.488
SUFF++ for r=0.6 class 0 = 0.856 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 2 = 0.753 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.724 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.8 +- 0.224 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.505
SUFF++ for r=0.9 class 0 = 0.898 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 2 = 0.833 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all KL = 0.899 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all L1 = 0.876 +- 0.180 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:28:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:28:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 45...
[0m[1;37mINFO[0m: [1mCheckpoint 45: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0008
ID Validation ACCURACY: 0.6931
ID Validation Loss: 1.9365
ID Test ACCURACY: 0.6318
ID Test Loss: 2.3364
OOD Validation ACCURACY: 0.6050
OOD Validation Loss: 2.4209
OOD Test ACCURACY: 0.5134
OOD Test Loss: 3.3352

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0010
ID Validation ACCURACY: 0.6516
ID Validation Loss: 2.3718
ID Test ACCURACY: 0.6462
ID Test Loss: 2.5842
OOD Validation ACCURACY: 0.6252
OOD Validation Loss: 2.5842
OOD Test ACCURACY: 0.5587
OOD Test Loss: 3.0403

[0m[1;37mINFO[0m: [1mChartInfo 0.6318 0.5134 0.6462 0.5587 0.6516 0.6252[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.598
NEC for r=0.3 class 0 = 0.236 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 1 = 0.195 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 2 = 0.27 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all KL = 0.245 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all L1 = 0.228 +- 0.244 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.622
NEC for r=0.6 class 0 = 0.191 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.137 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.183 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.19 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.164 +- 0.220 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.637
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.623
NEC for r=0.9 class 0 = 0.143 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 class 1 = 0.109 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 class 2 = 0.128 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all KL = 0.109 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all L1 = 0.123 +- 0.191 (in-sample avg dev_std = 0.247)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.632
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.626
NEC for r=1.0 class 0 = 0.137 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 1 = 0.095 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 2 = 0.122 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all KL = 0.091 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all L1 = 0.114 +- 0.181 (in-sample avg dev_std = 0.222)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.486
NEC for r=0.3 class 0 = 0.178 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.254 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.267 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.29 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.238 +- 0.256 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.5
NEC for r=0.6 class 0 = 0.164 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 1 = 0.209 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 2 = 0.217 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all KL = 0.211 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all L1 = 0.199 +- 0.233 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.5
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.138 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 1 = 0.171 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 2 = 0.175 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all KL = 0.131 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all L1 = 0.164 +- 0.206 (in-sample avg dev_std = 0.257)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.502
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.502
NEC for r=1.0 class 0 = 0.121 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 1 = 0.162 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 2 = 0.173 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all KL = 0.11 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all L1 = 0.154 +- 0.193 (in-sample avg dev_std = 0.233)


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.538
SUFF++ for r=0.3 class 0 = 0.692 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 class 1 = 0.671 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 class 2 = 0.543 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 all KL = 0.454 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 all L1 = 0.638 +- 0.217 (in-sample avg dev_std = 0.632)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.601
SUFF++ for r=0.6 class 0 = 0.756 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 1 = 0.807 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 2 = 0.727 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all KL = 0.653 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all L1 = 0.77 +- 0.222 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.638
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.625
SUFF++ for r=0.9 class 0 = 0.862 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 1 = 0.911 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 2 = 0.885 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all KL = 0.902 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.164 (in-sample avg dev_std = 0.263)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.46
SUFF++ for r=0.3 class 0 = 0.773 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 2 = 0.64 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all KL = 0.543 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all L1 = 0.693 +- 0.236 (in-sample avg dev_std = 0.565)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.494
SUFF++ for r=0.6 class 0 = 0.823 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 2 = 0.755 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all KL = 0.735 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.214 (in-sample avg dev_std = 0.421)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.5
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.496
SUFF++ for r=0.9 class 0 = 0.894 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all KL = 0.908 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all L1 = 0.868 +- 0.174 (in-sample avg dev_std = 0.232)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:31:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:12 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:14 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:15 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:31:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 95...
[0m[1;37mINFO[0m: [1mCheckpoint 95: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.2470
ID Test ACCURACY: 0.6606
ID Test Loss: 2.5508
OOD Validation ACCURACY: 0.6134
OOD Validation Loss: 2.6879
OOD Test ACCURACY: 0.5374
OOD Test Loss: 3.7189

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0026
ID Validation ACCURACY: 0.6606
ID Validation Loss: 2.0494
ID Test ACCURACY: 0.6390
ID Test Loss: 2.2359
OOD Validation ACCURACY: 0.6275
OOD Validation Loss: 2.4516
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.1232

[0m[1;37mINFO[0m: [1mChartInfo 0.6606 0.5374 0.6390 0.5635 0.6606 0.6275[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.605
NEC for r=0.3 class 0 = 0.294 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 1 = 0.148 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 2 = 0.237 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all KL = 0.24 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all L1 = 0.211 +- 0.260 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.623
NEC for r=0.6 class 0 = 0.211 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 class 1 = 0.119 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 class 2 = 0.171 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 all KL = 0.189 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 all L1 = 0.157 +- 0.233 (in-sample avg dev_std = 0.321)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.652
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.636
NEC for r=0.9 class 0 = 0.145 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 class 1 = 0.106 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 class 2 = 0.114 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all KL = 0.122 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all L1 = 0.118 +- 0.196 (in-sample avg dev_std = 0.261)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.659
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.636
NEC for r=1.0 class 0 = 0.13 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1 = 0.107 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 2 = 0.109 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.105 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.114 +- 0.186 (in-sample avg dev_std = 0.241)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0 = 0.214 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 1 = 0.18 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 2 = 0.234 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all KL = 0.257 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all L1 = 0.202 +- 0.258 (in-sample avg dev_std = 0.384)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.538
NEC for r=0.6 class 0 = 0.184 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.164 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.205 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.216 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.179 +- 0.243 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.534
NEC for r=0.9 class 0 = 0.147 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 1 = 0.147 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 2 = 0.155 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all KL = 0.144 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all L1 = 0.149 +- 0.215 (in-sample avg dev_std = 0.285)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.531
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.138 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 1 = 0.135 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 2 = 0.15 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all KL = 0.117 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all L1 = 0.139 +- 0.195 (in-sample avg dev_std = 0.255)


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.559
SUFF++ for r=0.3 class 0 = 0.556 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 class 1 = 0.731 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 class 2 = 0.59 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 all KL = 0.403 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 all L1 = 0.646 +- 0.228 (in-sample avg dev_std = 0.644)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.602
SUFF++ for r=0.6 class 0 = 0.692 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 2 = 0.725 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all KL = 0.566 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all L1 = 0.748 +- 0.231 (in-sample avg dev_std = 0.536)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.651
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.634
SUFF++ for r=0.9 class 0 = 0.862 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 1 = 0.892 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 2 = 0.892 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all KL = 0.868 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.175 (in-sample avg dev_std = 0.288)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.658 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 all KL = 0.395 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 all L1 = 0.654 +- 0.224 (in-sample avg dev_std = 0.662)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.518
SUFF++ for r=0.6 class 0 = 0.778 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.609 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.754 +- 0.229 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
SUFF++ for r=0.9 class 0 = 0.869 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 1 = 0.854 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all KL = 0.868 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.195 (in-sample avg dev_std = 0.298)


ratio=1.0



Zero intervened samples, skipping weight=1.0


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.272, 0.214, 0.134, 0.105], 'all_L1': [0.21, 0.162, 0.12, 0.111]}), defaultdict(<class 'list'>, {'all_KL': [0.249, 0.188, 0.12, 0.099], 'all_L1': [0.229, 0.171, 0.126, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.24, 0.187, 0.112, 0.097], 'all_L1': [0.212, 0.158, 0.116, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.245, 0.19, 0.109, 0.091], 'all_L1': [0.228, 0.164, 0.123, 0.114]}), defaultdict(<class 'list'>, {'all_KL': [0.24, 0.189, 0.122, 0.105], 'all_L1': [0.211, 0.157, 0.118, 0.114]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.283, 0.535, 0.855, 1.0], 'all_L1': [0.599, 0.746, 0.882, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.659, 0.881, 1.0], 'all_L1': [0.632, 0.768, 0.88, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.366, 0.652, 0.892, 1.0], 'all_L1': [0.612, 0.778, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.454, 0.653, 0.902, 1.0], 'all_L1': [0.638, 0.77, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.403, 0.566, 0.868, 1.0], 'all_L1': [0.646, 0.748, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.302, 0.263, 0.159, 0.119], 'all_L1': [0.221, 0.196, 0.159, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.296, 0.212, 0.149, 0.117], 'all_L1': [0.239, 0.191, 0.164, 0.149]}), defaultdict(<class 'list'>, {'all_KL': [0.247, 0.2, 0.141, 0.121], 'all_L1': [0.21, 0.169, 0.154, 0.146]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.211, 0.131, 0.11], 'all_L1': [0.238, 0.199, 0.164, 0.154]}), defaultdict(<class 'list'>, {'all_KL': [0.257, 0.216, 0.144, 0.117], 'all_L1': [0.202, 0.179, 0.149, 0.139]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.373, 0.629, 0.874, 1.0], 'all_L1': [0.648, 0.769, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.527, 0.724, 0.893, 1.0], 'all_L1': [0.688, 0.787, 0.866, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.724, 0.899, 1.0], 'all_L1': [0.654, 0.8, 0.876, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.543, 0.735, 0.908, 1.0], 'all_L1': [0.693, 0.782, 0.868, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.395, 0.609, 0.868, 1.0], 'all_L1': [0.654, 0.754, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
nec class all_L1  =  0.218 +- 0.009, 0.162 +- 0.005, 0.121 +- 0.004, 0.113 +- 0.002
nec class all_KL  =  0.249 +- 0.012, 0.194 +- 0.010, 0.119 +- 0.009, 0.099 +- 0.005
nec_acc_int  =  0.618 +- 0.015, 0.632 +- 0.010, 0.643 +- 0.012, 0.643 +- 0.011
suff++ class all_L1  =  0.625 +- 0.017, 0.762 +- 0.013, 0.885 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.389 +- 0.061, 0.613 +- 0.052, 0.880 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.550 +- 0.008, 0.606 +- 0.005, 0.641 +- 0.011

Eval split test
nec class all_L1  =  0.222 +- 0.015, 0.187 +- 0.011, 0.158 +- 0.006, 0.146 +- 0.005
nec class all_KL  =  0.278 +- 0.022, 0.220 +- 0.022, 0.145 +- 0.009, 0.117 +- 0.004
nec_acc_int  =  0.528 +- 0.027, 0.527 +- 0.024, 0.528 +- 0.021, 0.529 +- 0.023
suff++ class all_L1  =  0.667 +- 0.019, 0.778 +- 0.016, 0.866 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.455 +- 0.069, 0.684 +- 0.054, 0.888 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.493 +- 0.025, 0.515 +- 0.022, 0.526 +- 0.024


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.422 +- 0.011, 0.462 +- 0.007, 0.503 +- 0.002, 0.556 +- 0.001
Faith. Armon (L1)= 		  =  0.323 +- 0.011, 0.268 +- 0.007, 0.212 +- 0.005, 0.203 +- 0.004
Faith. GMean (L1)= 	  =  0.369 +- 0.011, 0.352 +- 0.007, 0.327 +- 0.005, 0.336 +- 0.004
Faith. Aritm (KL)= 		  =  0.319 +- 0.027, 0.403 +- 0.022, 0.499 +- 0.004, 0.550 +- 0.003
Faith. Armon (KL)= 		  =  0.301 +- 0.016, 0.293 +- 0.007, 0.210 +- 0.013, 0.181 +- 0.009
Faith. GMean (KL)= 	  =  0.310 +- 0.021, 0.344 +- 0.010, 0.324 +- 0.009, 0.315 +- 0.008

Eval split test
Faith. Aritm (L1)= 		  =  0.445 +- 0.016, 0.483 +- 0.009, 0.512 +- 0.004, 0.573 +- 0.003
Faith. Armon (L1)= 		  =  0.333 +- 0.019, 0.301 +- 0.015, 0.267 +- 0.008, 0.255 +- 0.008
Faith. GMean (L1)= 	  =  0.385 +- 0.018, 0.381 +- 0.011, 0.370 +- 0.007, 0.382 +- 0.007
Faith. Aritm (KL)= 		  =  0.367 +- 0.039, 0.452 +- 0.022, 0.517 +- 0.006, 0.558 +- 0.002
Faith. Armon (KL)= 		  =  0.344 +- 0.029, 0.332 +- 0.020, 0.249 +- 0.013, 0.209 +- 0.006
Faith. GMean (KL)= 	  =  0.355 +- 0.034, 0.387 +- 0.015, 0.358 +- 0.010, 0.342 +- 0.005
Computed for split load_split = id



Completed in  0:15:43.228889  for GSATvGIN GOODTwitter/length



DONE GSAT GOODTwitter/length
sasasa
sasa
Time to compute metrics!

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:37:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:30 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:33 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:34 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:36 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:37:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.4932
ID Test ACCURACY: 0.6588
ID Test Loss: 2.8260
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.9021
OOD Test ACCURACY: 0.5710
OOD Test Loss: 3.5556

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.4932
ID Test ACCURACY: 0.6588
ID Test Loss: 2.8260
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.9021
OOD Test ACCURACY: 0.5710
OOD Test Loss: 3.5556

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5710 0.6588 0.5710 0.7058 0.6471[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0 = 0.237 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1 = 0.175 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 2 = 0.24 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.272 +- 0.348 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.21 +- 0.265 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0 = 0.186 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 1 = 0.141 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 2 = 0.173 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all KL = 0.214 +- 0.319 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all L1 = 0.162 +- 0.238 (in-sample avg dev_std = 0.352)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.649
NEC for r=0.9 class 0 = 0.14 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 class 1 = 0.107 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 class 2 = 0.124 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all KL = 0.134 +- 0.244 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all L1 = 0.12 +- 0.206 (in-sample avg dev_std = 0.267)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.657
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.647
NEC for r=1.0 class 0 = 0.128 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1 = 0.093 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 2 = 0.124 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.105 +- 0.213 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.111 +- 0.196 (in-sample avg dev_std = 0.238)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0 = 0.244 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 1 = 0.198 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 2 = 0.242 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all KL = 0.302 +- 0.363 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all L1 = 0.221 +- 0.270 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.565
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.564
NEC for r=0.6 class 0 = 0.206 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 1 = 0.177 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 2 = 0.223 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all KL = 0.263 +- 0.345 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all L1 = 0.196 +- 0.262 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0 = 0.169 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 1 = 0.149 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 2 = 0.169 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all KL = 0.159 +- 0.247 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all L1 = 0.159 +- 0.225 (in-sample avg dev_std = 0.285)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.569
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.161 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 class 1 = 0.131 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 class 2 = 0.146 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all KL = 0.119 +- 0.198 (in-sample avg dev_std = 0.252)
NEC for r=1.0 all L1 = 0.142 +- 0.198 (in-sample avg dev_std = 0.252)


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0 = 0.562 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 class 1 = 0.652 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 class 2 = 0.55 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 all KL = 0.283 +- 0.295 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.215 (in-sample avg dev_std = 0.729)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.605
SUFF++ for r=0.6 class 0 = 0.724 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 1 = 0.775 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 2 = 0.722 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all KL = 0.535 +- 0.374 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all L1 = 0.746 +- 0.236 (in-sample avg dev_std = 0.568)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.651
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.645
SUFF++ for r=0.9 class 0 = 0.852 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 1 = 0.896 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 2 = 0.884 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all KL = 0.855 +- 0.232 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.187 (in-sample avg dev_std = 0.317)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.522
SUFF++ for r=0.3 class 0 = 0.621 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 class 1 = 0.68 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 all KL = 0.373 +- 0.352 (in-sample avg dev_std = 0.688)
SUFF++ for r=0.3 all L1 = 0.648 +- 0.243 (in-sample avg dev_std = 0.688)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0 = 0.776 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 class 1 = 0.781 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 all KL = 0.629 +- 0.358 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.241 (in-sample avg dev_std = 0.514)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.565
SUFF++ for r=0.9 class 0 = 0.858 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.871 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.874 +- 0.204 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.197 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:40:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:49 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:50 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:40:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 47...
[0m[1;37mINFO[0m: [1mCheckpoint 47: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0026
ID Validation ACCURACY: 0.7022
ID Validation Loss: 1.9916
ID Test ACCURACY: 0.6625
ID Test Loss: 2.1428
OOD Validation ACCURACY: 0.6090
OOD Validation Loss: 2.2830
OOD Test ACCURACY: 0.5607
OOD Test Loss: 2.6565

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0020
ID Validation ACCURACY: 0.6661
ID Validation Loss: 2.4967
ID Test ACCURACY: 0.6390
ID Test Loss: 2.5469
OOD Validation ACCURACY: 0.6297
OOD Validation Loss: 2.7461
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.2086

[0m[1;37mINFO[0m: [1mChartInfo 0.6625 0.5607 0.6390 0.5635 0.6661 0.6297[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0 = 0.237 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 1 = 0.186 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 2 = 0.289 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all KL = 0.249 +- 0.301 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all L1 = 0.229 +- 0.251 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.63
NEC for r=0.6 class 0 = 0.185 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 1 = 0.139 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 2 = 0.207 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all KL = 0.188 +- 0.274 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all L1 = 0.171 +- 0.230 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.655
NEC for r=0.9 class 0 = 0.145 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 1 = 0.109 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 class 2 = 0.138 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all KL = 0.12 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.9 all L1 = 0.126 +- 0.193 (in-sample avg dev_std = 0.264)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.661
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.657
NEC for r=1.0 class 0 = 0.144 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 class 1 = 0.1 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 class 2 = 0.117 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all KL = 0.099 +- 0.192 (in-sample avg dev_std = 0.247)
NEC for r=1.0 all L1 = 0.116 +- 0.184 (in-sample avg dev_std = 0.247)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.54
NEC for r=0.3 class 0 = 0.261 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 1 = 0.223 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 2 = 0.247 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all KL = 0.296 +- 0.327 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all L1 = 0.239 +- 0.259 (in-sample avg dev_std = 0.401)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.551
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.532
NEC for r=0.6 class 0 = 0.207 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.172 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.212 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.212 +- 0.288 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.191 +- 0.240 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.18 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 1 = 0.15 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 2 = 0.176 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all KL = 0.149 +- 0.226 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all L1 = 0.164 +- 0.213 (in-sample avg dev_std = 0.273)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.533
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.165 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1 = 0.135 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 2 = 0.159 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.117 +- 0.189 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.149 +- 0.192 (in-sample avg dev_std = 0.241)


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.546
SUFF++ for r=0.3 class 0 = 0.647 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 class 1 = 0.671 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 all KL = 0.439 +- 0.297 (in-sample avg dev_std = 0.646)
SUFF++ for r=0.3 all L1 = 0.632 +- 0.215 (in-sample avg dev_std = 0.646)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.609
SUFF++ for r=0.6 class 0 = 0.789 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 1 = 0.803 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 2 = 0.696 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all KL = 0.659 +- 0.320 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all L1 = 0.768 +- 0.224 (in-sample avg dev_std = 0.481)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.654
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.659
SUFF++ for r=0.9 class 0 = 0.869 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.868 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.881 +- 0.201 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.173 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.51
SUFF++ for r=0.3 class 0 = 0.687 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 1 = 0.703 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 2 = 0.661 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all KL = 0.527 +- 0.325 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all L1 = 0.688 +- 0.231 (in-sample avg dev_std = 0.584)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.552
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.526
SUFF++ for r=0.6 class 0 = 0.781 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1 = 0.812 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.724 +- 0.284 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.220 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.534
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.529
SUFF++ for r=0.9 class 0 = 0.864 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.893 +- 0.185 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.180 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:43:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:43:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:00 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:01 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:44:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.9121
ID Test ACCURACY: 0.6606
ID Test Loss: 2.3481
OOD Validation ACCURACY: 0.6006
OOD Validation Loss: 2.6995
OOD Test ACCURACY: 0.5271
OOD Test Loss: 4.1606

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0011
ID Validation ACCURACY: 0.6823
ID Validation Loss: 2.0777
ID Test ACCURACY: 0.6570
ID Test Loss: 2.3521
OOD Validation ACCURACY: 0.6342
OOD Validation Loss: 2.3260
OOD Test ACCURACY: 0.5546
OOD Test Loss: 3.2175

[0m[1;37mINFO[0m: [1mChartInfo 0.6606 0.5271 0.6570 0.5546 0.6823 0.6342[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.642
NEC for r=0.3 class 0 = 0.232 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 1 = 0.198 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 2 = 0.216 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all KL = 0.24 +- 0.309 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all L1 = 0.212 +- 0.251 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0 = 0.161 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 1 = 0.163 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 2 = 0.148 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all KL = 0.187 +- 0.284 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all L1 = 0.158 +- 0.223 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.644
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.652
NEC for r=0.9 class 0 = 0.117 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 class 1 = 0.12 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 class 2 = 0.109 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all KL = 0.112 +- 0.209 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all L1 = 0.116 +- 0.184 (in-sample avg dev_std = 0.236)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.659
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.649
NEC for r=1.0 class 0 = 0.117 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 class 1 = 0.12 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 class 2 = 0.085 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 all KL = 0.097 +- 0.191 (in-sample avg dev_std = 0.226)
NEC for r=1.0 all L1 = 0.109 +- 0.177 (in-sample avg dev_std = 0.226)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.512
NEC for r=0.3 class 0 = 0.169 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1 = 0.209 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 2 = 0.256 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.247 +- 0.308 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.21 +- 0.249 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.13 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 1 = 0.169 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 2 = 0.21 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all KL = 0.2 +- 0.286 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all L1 = 0.169 +- 0.226 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.138 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.147 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.185 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.141 +- 0.222 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.154 +- 0.211 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.527
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.509
NEC for r=1.0 class 0 = 0.134 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.14 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.171 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.121 +- 0.203 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.146 +- 0.203 (in-sample avg dev_std = 0.246)


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0 = 0.628 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 class 1 = 0.641 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 class 2 = 0.552 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 all KL = 0.366 +- 0.283 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 all L1 = 0.612 +- 0.207 (in-sample avg dev_std = 0.681)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.613
SUFF++ for r=0.6 class 0 = 0.807 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 class 1 = 0.791 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 class 2 = 0.731 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 all KL = 0.652 +- 0.337 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.6 all L1 = 0.778 +- 0.225 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.643
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.644
SUFF++ for r=0.9 class 0 = 0.892 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 1 = 0.874 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 2 = 0.899 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all KL = 0.892 +- 0.191 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.177 (in-sample avg dev_std = 0.257)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.465
SUFF++ for r=0.3 class 0 = 0.736 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 1 = 0.647 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all KL = 0.439 +- 0.323 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all L1 = 0.654 +- 0.228 (in-sample avg dev_std = 0.636)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.515
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.488
SUFF++ for r=0.6 class 0 = 0.856 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 2 = 0.753 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.724 +- 0.303 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.8 +- 0.224 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.519
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.505
SUFF++ for r=0.9 class 0 = 0.898 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 1 = 0.886 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 2 = 0.833 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all KL = 0.899 +- 0.183 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all L1 = 0.876 +- 0.180 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:47:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:16 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:18 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:20 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:22 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:47:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 45...
[0m[1;37mINFO[0m: [1mCheckpoint 45: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0008
ID Validation ACCURACY: 0.6931
ID Validation Loss: 1.9365
ID Test ACCURACY: 0.6318
ID Test Loss: 2.3364
OOD Validation ACCURACY: 0.6050
OOD Validation Loss: 2.4209
OOD Test ACCURACY: 0.5134
OOD Test Loss: 3.3352

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0010
ID Validation ACCURACY: 0.6516
ID Validation Loss: 2.3718
ID Test ACCURACY: 0.6462
ID Test Loss: 2.5842
OOD Validation ACCURACY: 0.6252
OOD Validation Loss: 2.5842
OOD Test ACCURACY: 0.5587
OOD Test Loss: 3.0403

[0m[1;37mINFO[0m: [1mChartInfo 0.6318 0.5134 0.6462 0.5587 0.6516 0.6252[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.598
NEC for r=0.3 class 0 = 0.236 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 1 = 0.195 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 2 = 0.27 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all KL = 0.245 +- 0.293 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all L1 = 0.228 +- 0.244 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.622
NEC for r=0.6 class 0 = 0.191 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.137 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.183 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.19 +- 0.279 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.164 +- 0.220 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.637
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.623
NEC for r=0.9 class 0 = 0.143 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 class 1 = 0.109 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 class 2 = 0.128 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all KL = 0.109 +- 0.197 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all L1 = 0.123 +- 0.191 (in-sample avg dev_std = 0.247)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.632
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.626
NEC for r=1.0 class 0 = 0.137 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 1 = 0.095 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 2 = 0.122 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all KL = 0.091 +- 0.176 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all L1 = 0.114 +- 0.181 (in-sample avg dev_std = 0.222)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.486
NEC for r=0.3 class 0 = 0.178 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.254 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.267 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.29 +- 0.318 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.238 +- 0.256 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.5
NEC for r=0.6 class 0 = 0.164 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 1 = 0.209 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 2 = 0.217 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all KL = 0.211 +- 0.277 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all L1 = 0.199 +- 0.233 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.5
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.138 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 1 = 0.171 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 2 = 0.175 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all KL = 0.131 +- 0.202 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all L1 = 0.164 +- 0.206 (in-sample avg dev_std = 0.257)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.502
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.502
NEC for r=1.0 class 0 = 0.121 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 1 = 0.162 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 2 = 0.173 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all KL = 0.11 +- 0.170 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all L1 = 0.154 +- 0.193 (in-sample avg dev_std = 0.233)


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.538
SUFF++ for r=0.3 class 0 = 0.692 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 class 1 = 0.671 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 class 2 = 0.543 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 all KL = 0.454 +- 0.306 (in-sample avg dev_std = 0.632)
SUFF++ for r=0.3 all L1 = 0.638 +- 0.217 (in-sample avg dev_std = 0.632)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.601
SUFF++ for r=0.6 class 0 = 0.756 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 1 = 0.807 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 2 = 0.727 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all KL = 0.653 +- 0.314 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all L1 = 0.77 +- 0.222 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.638
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.625
SUFF++ for r=0.9 class 0 = 0.862 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 1 = 0.911 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 2 = 0.885 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all KL = 0.902 +- 0.171 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.164 (in-sample avg dev_std = 0.263)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.49
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.46
SUFF++ for r=0.3 class 0 = 0.773 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 class 2 = 0.64 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all KL = 0.543 +- 0.328 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.3 all L1 = 0.693 +- 0.236 (in-sample avg dev_std = 0.565)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.494
SUFF++ for r=0.6 class 0 = 0.823 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 2 = 0.755 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all KL = 0.735 +- 0.272 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.214 (in-sample avg dev_std = 0.421)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.5
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.496
SUFF++ for r=0.9 class 0 = 0.894 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all KL = 0.908 +- 0.153 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all L1 = 0.868 +- 0.174 (in-sample avg dev_std = 0.232)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:50:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:28 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:30 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:31 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:31 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 95...
[0m[1;37mINFO[0m: [1mCheckpoint 95: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.2470
ID Test ACCURACY: 0.6606
ID Test Loss: 2.5508
OOD Validation ACCURACY: 0.6134
OOD Validation Loss: 2.6879
OOD Test ACCURACY: 0.5374
OOD Test Loss: 3.7189

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0026
ID Validation ACCURACY: 0.6606
ID Validation Loss: 2.0494
ID Test ACCURACY: 0.6390
ID Test Loss: 2.2359
OOD Validation ACCURACY: 0.6275
OOD Validation Loss: 2.4516
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.1232

[0m[1;37mINFO[0m: [1mChartInfo 0.6606 0.5374 0.6390 0.5635 0.6606 0.6275[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.605
NEC for r=0.3 class 0 = 0.294 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 1 = 0.148 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 class 2 = 0.237 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all KL = 0.24 +- 0.314 (in-sample avg dev_std = 0.340)
NEC for r=0.3 all L1 = 0.211 +- 0.260 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.623
NEC for r=0.6 class 0 = 0.211 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 class 1 = 0.119 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 class 2 = 0.171 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 all KL = 0.189 +- 0.296 (in-sample avg dev_std = 0.321)
NEC for r=0.6 all L1 = 0.157 +- 0.233 (in-sample avg dev_std = 0.321)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.652
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.636
NEC for r=0.9 class 0 = 0.145 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 class 1 = 0.106 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 class 2 = 0.114 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all KL = 0.122 +- 0.228 (in-sample avg dev_std = 0.261)
NEC for r=0.9 all L1 = 0.118 +- 0.196 (in-sample avg dev_std = 0.261)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.659
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.636
NEC for r=1.0 class 0 = 0.13 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1 = 0.107 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 2 = 0.109 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.105 +- 0.204 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.114 +- 0.186 (in-sample avg dev_std = 0.241)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0 = 0.214 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 1 = 0.18 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 2 = 0.234 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all KL = 0.257 +- 0.332 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all L1 = 0.202 +- 0.258 (in-sample avg dev_std = 0.384)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.538
NEC for r=0.6 class 0 = 0.184 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.164 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.205 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.216 +- 0.306 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.179 +- 0.243 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.534
NEC for r=0.9 class 0 = 0.147 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 1 = 0.147 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 2 = 0.155 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all KL = 0.144 +- 0.241 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all L1 = 0.149 +- 0.215 (in-sample avg dev_std = 0.285)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.531
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.138 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 1 = 0.135 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 2 = 0.15 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all KL = 0.117 +- 0.202 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all L1 = 0.139 +- 0.195 (in-sample avg dev_std = 0.255)


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.559
SUFF++ for r=0.3 class 0 = 0.556 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 class 1 = 0.731 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 class 2 = 0.59 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 all KL = 0.403 +- 0.316 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 all L1 = 0.646 +- 0.228 (in-sample avg dev_std = 0.644)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.602
SUFF++ for r=0.6 class 0 = 0.692 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 2 = 0.725 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all KL = 0.566 +- 0.352 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all L1 = 0.748 +- 0.231 (in-sample avg dev_std = 0.536)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.651
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.634
SUFF++ for r=0.9 class 0 = 0.862 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 1 = 0.892 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 2 = 0.892 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all KL = 0.868 +- 0.219 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.175 (in-sample avg dev_std = 0.288)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.658 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 all KL = 0.395 +- 0.327 (in-sample avg dev_std = 0.662)
SUFF++ for r=0.3 all L1 = 0.654 +- 0.224 (in-sample avg dev_std = 0.662)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.518
SUFF++ for r=0.6 class 0 = 0.778 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.609 +- 0.329 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.754 +- 0.229 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
SUFF++ for r=0.9 class 0 = 0.869 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 1 = 0.854 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all KL = 0.868 +- 0.216 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.195 (in-sample avg dev_std = 0.298)


ratio=1.0



Zero intervened samples, skipping weight=1.0


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.272, 0.214, 0.134, 0.105], 'all_L1': [0.21, 0.162, 0.12, 0.111]}), defaultdict(<class 'list'>, {'all_KL': [0.249, 0.188, 0.12, 0.099], 'all_L1': [0.229, 0.171, 0.126, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.24, 0.187, 0.112, 0.097], 'all_L1': [0.212, 0.158, 0.116, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.245, 0.19, 0.109, 0.091], 'all_L1': [0.228, 0.164, 0.123, 0.114]}), defaultdict(<class 'list'>, {'all_KL': [0.24, 0.189, 0.122, 0.105], 'all_L1': [0.211, 0.157, 0.118, 0.114]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.283, 0.535, 0.855, 1.0], 'all_L1': [0.599, 0.746, 0.882, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.659, 0.881, 1.0], 'all_L1': [0.632, 0.768, 0.88, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.366, 0.652, 0.892, 1.0], 'all_L1': [0.612, 0.778, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.454, 0.653, 0.902, 1.0], 'all_L1': [0.638, 0.77, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.403, 0.566, 0.868, 1.0], 'all_L1': [0.646, 0.748, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.302, 0.263, 0.159, 0.119], 'all_L1': [0.221, 0.196, 0.159, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.296, 0.212, 0.149, 0.117], 'all_L1': [0.239, 0.191, 0.164, 0.149]}), defaultdict(<class 'list'>, {'all_KL': [0.247, 0.2, 0.141, 0.121], 'all_L1': [0.21, 0.169, 0.154, 0.146]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.211, 0.131, 0.11], 'all_L1': [0.238, 0.199, 0.164, 0.154]}), defaultdict(<class 'list'>, {'all_KL': [0.257, 0.216, 0.144, 0.117], 'all_L1': [0.202, 0.179, 0.149, 0.139]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.373, 0.629, 0.874, 1.0], 'all_L1': [0.648, 0.769, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.527, 0.724, 0.893, 1.0], 'all_L1': [0.688, 0.787, 0.866, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.724, 0.899, 1.0], 'all_L1': [0.654, 0.8, 0.876, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.543, 0.735, 0.908, 1.0], 'all_L1': [0.693, 0.782, 0.868, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.395, 0.609, 0.868, 1.0], 'all_L1': [0.654, 0.754, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
nec class all_L1  =  0.218 +- 0.009, 0.162 +- 0.005, 0.121 +- 0.004, 0.113 +- 0.002
nec class all_KL  =  0.249 +- 0.012, 0.194 +- 0.010, 0.119 +- 0.009, 0.099 +- 0.005
nec_acc_int  =  0.618 +- 0.015, 0.632 +- 0.010, 0.643 +- 0.012, 0.643 +- 0.011
suff++ class all_L1  =  0.625 +- 0.017, 0.762 +- 0.013, 0.885 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.389 +- 0.061, 0.613 +- 0.052, 0.880 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.550 +- 0.008, 0.606 +- 0.005, 0.641 +- 0.011

Eval split test
nec class all_L1  =  0.222 +- 0.015, 0.187 +- 0.011, 0.158 +- 0.006, 0.146 +- 0.005
nec class all_KL  =  0.278 +- 0.022, 0.220 +- 0.022, 0.145 +- 0.009, 0.117 +- 0.004
nec_acc_int  =  0.528 +- 0.027, 0.527 +- 0.024, 0.528 +- 0.021, 0.529 +- 0.023
suff++ class all_L1  =  0.667 +- 0.019, 0.778 +- 0.016, 0.866 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.455 +- 0.069, 0.684 +- 0.054, 0.888 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.493 +- 0.025, 0.515 +- 0.022, 0.526 +- 0.024


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.422 +- 0.011, 0.462 +- 0.007, 0.503 +- 0.002, 0.556 +- 0.001
Faith. Armon (L1)= 		  =  0.323 +- 0.011, 0.268 +- 0.007, 0.212 +- 0.005, 0.203 +- 0.004
Faith. GMean (L1)= 	  =  0.369 +- 0.011, 0.352 +- 0.007, 0.327 +- 0.005, 0.336 +- 0.004
Faith. Aritm (KL)= 		  =  0.319 +- 0.027, 0.403 +- 0.022, 0.499 +- 0.004, 0.550 +- 0.003
Faith. Armon (KL)= 		  =  0.301 +- 0.016, 0.293 +- 0.007, 0.210 +- 0.013, 0.181 +- 0.009
Faith. GMean (KL)= 	  =  0.310 +- 0.021, 0.344 +- 0.010, 0.324 +- 0.009, 0.315 +- 0.008

Eval split test
Faith. Aritm (L1)= 		  =  0.445 +- 0.016, 0.483 +- 0.009, 0.512 +- 0.004, 0.573 +- 0.003
Faith. Armon (L1)= 		  =  0.333 +- 0.019, 0.301 +- 0.015, 0.267 +- 0.008, 0.255 +- 0.008
Faith. GMean (L1)= 	  =  0.385 +- 0.018, 0.381 +- 0.011, 0.370 +- 0.007, 0.382 +- 0.007
Faith. Aritm (KL)= 		  =  0.367 +- 0.039, 0.452 +- 0.022, 0.517 +- 0.006, 0.558 +- 0.002
Faith. Armon (KL)= 		  =  0.344 +- 0.029, 0.332 +- 0.020, 0.249 +- 0.013, 0.209 +- 0.006
Faith. GMean (KL)= 	  =  0.355 +- 0.034, 0.387 +- 0.015, 0.358 +- 0.010, 0.342 +- 0.005
Computed for split load_split = id



Completed in  0:16:15.124215  for GSATvGIN GOODTwitter/length



DONE GSAT GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:53:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 12:53:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ROC-AUC: 0.9213
Train Loss: 0.0885
ID Validation ROC-AUC: 0.8414
ID Validation Loss: 0.1273
ID Test ROC-AUC: 0.7885
ID Test Loss: 0.1135
OOD Validation ROC-AUC: 0.7416
OOD Validation Loss: 0.1219
OOD Test ROC-AUC: 0.6658
OOD Test Loss: 0.0954

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 108...
[0m[1;37mINFO[0m: [1mCheckpoint 108: 
-----------------------------------
Train ROC-AUC: 0.9328
Train Loss: 0.0914
ID Validation ROC-AUC: 0.8173
ID Validation Loss: 0.1397
ID Test ROC-AUC: 0.7987
ID Test Loss: 0.1216
OOD Validation ROC-AUC: 0.7790
OOD Validation Loss: 0.1193
OOD Test ROC-AUC: 0.6905
OOD Test Loss: 0.0920

[0m[1;37mINFO[0m: [1mChartInfo 0.7885 0.6658 0.7987 0.6905 0.8173 0.7790[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 12:54:10 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/08/2024 12:54:12 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.522
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.539
NEC for r=0.3 class 0.0 = 0.01 +- 0.075 (in-sample avg dev_std = 0.047)
NEC for r=0.3 class 1.0 = 0.033 +- 0.075 (in-sample avg dev_std = 0.047)
NEC for r=0.3 all KL = 0.014 +- 0.075 (in-sample avg dev_std = 0.047)
NEC for r=0.3 all L1 = 0.021 +- 0.073 (in-sample avg dev_std = 0.047)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.623
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
NEC for r=0.6 class 0.0 = 0.022 +- 0.088 (in-sample avg dev_std = 0.098)
NEC for r=0.6 class 1.0 = 0.073 +- 0.088 (in-sample avg dev_std = 0.098)
NEC for r=0.6 all KL = 0.029 +- 0.088 (in-sample avg dev_std = 0.098)
NEC for r=0.6 all L1 = 0.047 +- 0.101 (in-sample avg dev_std = 0.098)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0.0 = 0.029 +- 0.046 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 1.0 = 0.084 +- 0.046 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all KL = 0.02 +- 0.046 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all L1 = 0.057 +- 0.096 (in-sample avg dev_std = 0.088)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.709
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.68
NEC for r=1.0 class 0.0 = 0.026 +- 0.047 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1.0 = 0.074 +- 0.047 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.018 +- 0.047 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.05 +- 0.092 (in-sample avg dev_std = 0.090)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.554
NEC for r=0.3 class 0.0 = 0.006 +- 0.060 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 1.0 = 0.029 +- 0.060 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all KL = 0.011 +- 0.060 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all L1 = 0.018 +- 0.067 (in-sample avg dev_std = 0.053)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.53
NEC for r=0.6 class 0.0 = 0.022 +- 0.084 (in-sample avg dev_std = 0.068)
NEC for r=0.6 class 1.0 = 0.042 +- 0.084 (in-sample avg dev_std = 0.068)
NEC for r=0.6 all KL = 0.022 +- 0.084 (in-sample avg dev_std = 0.068)
NEC for r=0.6 all L1 = 0.032 +- 0.079 (in-sample avg dev_std = 0.068)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.546
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.544
NEC for r=0.9 class 0.0 = 0.036 +- 0.047 (in-sample avg dev_std = 0.068)
NEC for r=0.9 class 1.0 = 0.058 +- 0.047 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all KL = 0.018 +- 0.047 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all L1 = 0.047 +- 0.091 (in-sample avg dev_std = 0.068)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.561
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.55
NEC for r=1.0 class 0.0 = 0.027 +- 0.033 (in-sample avg dev_std = 0.058)
NEC for r=1.0 class 1.0 = 0.048 +- 0.033 (in-sample avg dev_std = 0.058)
NEC for r=1.0 all KL = 0.012 +- 0.033 (in-sample avg dev_std = 0.058)
NEC for r=1.0 all L1 = 0.037 +- 0.075 (in-sample avg dev_std = 0.058)


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.522
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.543
SUFF++ for r=0.3 class 0.0 = 0.974 +- 0.093 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.3 class 1.0 = 0.951 +- 0.093 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.3 all KL = 0.957 +- 0.093 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.3 all L1 = 0.962 +- 0.075 (in-sample avg dev_std = 0.133)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.623
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.603
SUFF++ for r=0.6 class 0.0 = 0.947 +- 0.107 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 1.0 = 0.908 +- 0.107 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all KL = 0.929 +- 0.107 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all L1 = 0.928 +- 0.093 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 271
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.666
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.047 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 class 1.0 = 0.91 +- 0.047 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all KL = 0.973 +- 0.047 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all L1 = 0.936 +- 0.096 (in-sample avg dev_std = 0.104)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.528
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.584
SUFF++ for r=0.3 class 0.0 = 0.991 +- 0.032 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.3 class 1.0 = 0.977 +- 0.032 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.3 all KL = 0.989 +- 0.032 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.3 all L1 = 0.984 +- 0.045 (in-sample avg dev_std = 0.059)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.51
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.562
SUFF++ for r=0.6 class 0.0 = 0.965 +- 0.076 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 class 1.0 = 0.944 +- 0.076 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 all KL = 0.96 +- 0.076 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 all L1 = 0.955 +- 0.077 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.546
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.541
SUFF++ for r=0.9 class 0.0 = 0.962 +- 0.055 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 class 1.0 = 0.936 +- 0.055 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all KL = 0.976 +- 0.055 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.090 (in-sample avg dev_std = 0.098)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:54:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:55 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:58 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 157...
[0m[1;37mINFO[0m: [1mCheckpoint 157: 
-----------------------------------
Train ROC-AUC: 0.9815
Train Loss: 0.0601
ID Validation ROC-AUC: 0.8516
ID Validation Loss: 0.1361
ID Test ROC-AUC: 0.8303
ID Test Loss: 0.1200
OOD Validation ROC-AUC: 0.7584
OOD Validation Loss: 0.1298
OOD Test ROC-AUC: 0.7363
OOD Test Loss: 0.1003

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.8880
Train Loss: 0.1085
ID Validation ROC-AUC: 0.8321
ID Validation Loss: 0.1476
ID Test ROC-AUC: 0.8109
ID Test Loss: 0.1260
OOD Validation ROC-AUC: 0.7838
OOD Validation Loss: 0.1166
OOD Test ROC-AUC: 0.6928
OOD Test Loss: 0.0948

[0m[1;37mINFO[0m: [1mChartInfo 0.8303 0.7363 0.8109 0.6928 0.8321 0.7838[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 12:55:08 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/08/2024 12:55:09 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
NEC for r=0.3 class 0.0 = 0.011 +- 0.081 (in-sample avg dev_std = 0.063)
NEC for r=0.3 class 1.0 = 0.051 +- 0.081 (in-sample avg dev_std = 0.063)
NEC for r=0.3 all KL = 0.021 +- 0.081 (in-sample avg dev_std = 0.063)
NEC for r=0.3 all L1 = 0.031 +- 0.090 (in-sample avg dev_std = 0.063)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.738
NEC for r=0.6 class 0.0 = 0.025 +- 0.110 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 1.0 = 0.14 +- 0.110 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all KL = 0.053 +- 0.110 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all L1 = 0.083 +- 0.144 (in-sample avg dev_std = 0.146)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.792
NEC for r=0.9 class 0.0 = 0.024 +- 0.132 (in-sample avg dev_std = 0.179)
NEC for r=0.9 class 1.0 = 0.153 +- 0.132 (in-sample avg dev_std = 0.179)
NEC for r=0.9 all KL = 0.052 +- 0.132 (in-sample avg dev_std = 0.179)
NEC for r=0.9 all L1 = 0.089 +- 0.150 (in-sample avg dev_std = 0.179)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.838
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.799
NEC for r=1.0 class 0.0 = 0.023 +- 0.109 (in-sample avg dev_std = 0.179)
NEC for r=1.0 class 1.0 = 0.146 +- 0.109 (in-sample avg dev_std = 0.179)
NEC for r=1.0 all KL = 0.047 +- 0.109 (in-sample avg dev_std = 0.179)
NEC for r=1.0 all L1 = 0.085 +- 0.137 (in-sample avg dev_std = 0.179)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.455
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0.0 = 0.006 +- 0.024 (in-sample avg dev_std = 0.028)
NEC for r=0.3 class 1.0 = 0.013 +- 0.024 (in-sample avg dev_std = 0.028)
NEC for r=0.3 all KL = 0.007 +- 0.024 (in-sample avg dev_std = 0.028)
NEC for r=0.3 all L1 = 0.01 +- 0.020 (in-sample avg dev_std = 0.028)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.581
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.632
NEC for r=0.6 class 0.0 = 0.009 +- 0.037 (in-sample avg dev_std = 0.057)
NEC for r=0.6 class 1.0 = 0.042 +- 0.037 (in-sample avg dev_std = 0.057)
NEC for r=0.6 all KL = 0.014 +- 0.037 (in-sample avg dev_std = 0.057)
NEC for r=0.6 all L1 = 0.025 +- 0.067 (in-sample avg dev_std = 0.057)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.698
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.689
NEC for r=0.9 class 0.0 = 0.008 +- 0.082 (in-sample avg dev_std = 0.108)
NEC for r=0.9 class 1.0 = 0.064 +- 0.082 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all KL = 0.023 +- 0.082 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all L1 = 0.036 +- 0.111 (in-sample avg dev_std = 0.108)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.725
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.699
NEC for r=1.0 class 0.0 = 0.007 +- 0.093 (in-sample avg dev_std = 0.128)
NEC for r=1.0 class 1.0 = 0.062 +- 0.093 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all KL = 0.024 +- 0.093 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all L1 = 0.035 +- 0.109 (in-sample avg dev_std = 0.128)


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.58
SUFF++ for r=0.3 class 0.0 = 0.98 +- 0.117 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 1.0 = 0.924 +- 0.117 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 all KL = 0.952 +- 0.117 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 all L1 = 0.952 +- 0.115 (in-sample avg dev_std = 0.131)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.71
SUFF++ for r=0.6 class 0.0 = 0.95 +- 0.175 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.6 class 1.0 = 0.804 +- 0.175 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.6 all KL = 0.884 +- 0.175 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.6 all L1 = 0.877 +- 0.172 (in-sample avg dev_std = 0.240)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.794
SUFF++ for r=0.9 class 0.0 = 0.972 +- 0.092 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1.0 = 0.867 +- 0.092 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.958 +- 0.092 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.92 +- 0.124 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.458
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.511
SUFF++ for r=0.3 class 0.0 = 0.991 +- 0.029 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.3 class 1.0 = 0.987 +- 0.029 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.3 all KL = 0.992 +- 0.029 (in-sample avg dev_std = 0.043)
SUFF++ for r=0.3 all L1 = 0.989 +- 0.023 (in-sample avg dev_std = 0.043)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.581
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.587
SUFF++ for r=0.6 class 0.0 = 0.984 +- 0.086 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.6 class 1.0 = 0.95 +- 0.086 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.6 all KL = 0.972 +- 0.086 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.6 all L1 = 0.967 +- 0.087 (in-sample avg dev_std = 0.102)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.683
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.042 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.042 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all KL = 0.987 +- 0.042 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.074 (in-sample avg dev_std = 0.099)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:55:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:55 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:04 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ROC-AUC: 0.9435
Train Loss: 0.0815
ID Validation ROC-AUC: 0.8481
ID Validation Loss: 0.1324
ID Test ROC-AUC: 0.8267
ID Test Loss: 0.1177
OOD Validation ROC-AUC: 0.7799
OOD Validation Loss: 0.1230
OOD Test ROC-AUC: 0.6955
OOD Test Loss: 0.0948

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 89...
[0m[1;37mINFO[0m: [1mCheckpoint 89: 
-----------------------------------
Train ROC-AUC: 0.8972
Train Loss: 0.1011
ID Validation ROC-AUC: 0.8092
ID Validation Loss: 0.1406
ID Test ROC-AUC: 0.7826
ID Test Loss: 0.1253
OOD Validation ROC-AUC: 0.7984
OOD Validation Loss: 0.1161
OOD Test ROC-AUC: 0.6964
OOD Test Loss: 0.0942

[0m[1;37mINFO[0m: [1mChartInfo 0.8267 0.6955 0.7826 0.6964 0.8092 0.7984[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 12:56:07 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/08/2024 12:56:09 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.623
NEC for r=0.3 class 0.0 = 0.006 +- 0.122 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 1.0 = 0.07 +- 0.122 (in-sample avg dev_std = 0.095)
NEC for r=0.3 all KL = 0.033 +- 0.122 (in-sample avg dev_std = 0.095)
NEC for r=0.3 all L1 = 0.038 +- 0.112 (in-sample avg dev_std = 0.095)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.708
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.694
NEC for r=0.6 class 0.0 = 0.033 +- 0.117 (in-sample avg dev_std = 0.154)
NEC for r=0.6 class 1.0 = 0.118 +- 0.117 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all KL = 0.056 +- 0.117 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all L1 = 0.076 +- 0.140 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.739
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.715
NEC for r=0.9 class 0.0 = 0.041 +- 0.143 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.118 +- 0.143 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.06 +- 0.143 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.079 +- 0.141 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.745
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.714
NEC for r=1.0 class 0.0 = 0.044 +- 0.136 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 1.0 = 0.11 +- 0.136 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all KL = 0.054 +- 0.136 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all L1 = 0.077 +- 0.148 (in-sample avg dev_std = 0.151)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
NEC for r=0.3 class 0.0 = 0.006 +- 0.036 (in-sample avg dev_std = 0.058)
NEC for r=0.3 class 1.0 = 0.016 +- 0.036 (in-sample avg dev_std = 0.058)
NEC for r=0.3 all KL = 0.008 +- 0.036 (in-sample avg dev_std = 0.058)
NEC for r=0.3 all L1 = 0.011 +- 0.028 (in-sample avg dev_std = 0.058)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0.0 = 0.016 +- 0.067 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 1.0 = 0.046 +- 0.067 (in-sample avg dev_std = 0.074)
NEC for r=0.6 all KL = 0.019 +- 0.067 (in-sample avg dev_std = 0.074)
NEC for r=0.6 all L1 = 0.031 +- 0.087 (in-sample avg dev_std = 0.074)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.691
NEC for r=0.9 class 0.0 = 0.015 +- 0.073 (in-sample avg dev_std = 0.111)
NEC for r=0.9 class 1.0 = 0.072 +- 0.073 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all KL = 0.028 +- 0.073 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all L1 = 0.043 +- 0.103 (in-sample avg dev_std = 0.111)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.676
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.684
NEC for r=1.0 class 0.0 = 0.019 +- 0.078 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1.0 = 0.068 +- 0.078 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.029 +- 0.078 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.044 +- 0.104 (in-sample avg dev_std = 0.123)


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0.0 = 0.975 +- 0.154 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 class 1.0 = 0.91 +- 0.154 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 all KL = 0.929 +- 0.154 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.3 all L1 = 0.942 +- 0.126 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.71
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0.0 = 0.907 +- 0.209 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 class 1.0 = 0.806 +- 0.209 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all KL = 0.812 +- 0.209 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.159 (in-sample avg dev_std = 0.341)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.727
SUFF++ for r=0.9 class 0.0 = 0.951 +- 0.137 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 class 1.0 = 0.879 +- 0.137 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all KL = 0.927 +- 0.137 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.9 all L1 = 0.915 +- 0.134 (in-sample avg dev_std = 0.195)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0.0 = 0.993 +- 0.041 (in-sample avg dev_std = 0.052)
SUFF++ for r=0.3 class 1.0 = 0.984 +- 0.041 (in-sample avg dev_std = 0.052)
SUFF++ for r=0.3 all KL = 0.991 +- 0.041 (in-sample avg dev_std = 0.052)
SUFF++ for r=0.3 all L1 = 0.988 +- 0.029 (in-sample avg dev_std = 0.052)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.617
SUFF++ for r=0.6 class 0.0 = 0.955 +- 0.126 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 1.0 = 0.925 +- 0.126 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all KL = 0.93 +- 0.126 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all L1 = 0.94 +- 0.100 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.669
SUFF++ for r=0.9 class 0.0 = 0.982 +- 0.077 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 class 1.0 = 0.935 +- 0.077 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all KL = 0.974 +- 0.077 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.105 (in-sample avg dev_std = 0.106)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:56:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:50 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:56:57 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:00 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ROC-AUC: 0.9729
Train Loss: 0.0709
ID Validation ROC-AUC: 0.8445
ID Validation Loss: 0.1377
ID Test ROC-AUC: 0.8332
ID Test Loss: 0.1176
OOD Validation ROC-AUC: 0.7414
OOD Validation Loss: 0.1357
OOD Test ROC-AUC: 0.7290
OOD Test Loss: 0.0969

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ROC-AUC: 0.9188
Train Loss: 0.0893
ID Validation ROC-AUC: 0.8160
ID Validation Loss: 0.1298
ID Test ROC-AUC: 0.7788
ID Test Loss: 0.1181
OOD Validation ROC-AUC: 0.7819
OOD Validation Loss: 0.1167
OOD Test ROC-AUC: 0.7264
OOD Test Loss: 0.0890

[0m[1;37mINFO[0m: [1mChartInfo 0.8332 0.7290 0.7788 0.7264 0.8160 0.7819[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 12:57:03 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/08/2024 12:57:05 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.576
NEC for r=0.3 class 0.0 = 0.007 +- 0.021 (in-sample avg dev_std = 0.024)
NEC for r=0.3 class 1.0 = 0.015 +- 0.021 (in-sample avg dev_std = 0.024)
NEC for r=0.3 all KL = 0.005 +- 0.021 (in-sample avg dev_std = 0.024)
NEC for r=0.3 all L1 = 0.011 +- 0.036 (in-sample avg dev_std = 0.024)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
NEC for r=0.6 class 0.0 = 0.007 +- 0.063 (in-sample avg dev_std = 0.053)
NEC for r=0.6 class 1.0 = 0.041 +- 0.063 (in-sample avg dev_std = 0.053)
NEC for r=0.6 all KL = 0.014 +- 0.063 (in-sample avg dev_std = 0.053)
NEC for r=0.6 all L1 = 0.024 +- 0.081 (in-sample avg dev_std = 0.053)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.761
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.744
NEC for r=0.9 class 0.0 = 0.003 +- 0.035 (in-sample avg dev_std = 0.055)
NEC for r=0.9 class 1.0 = 0.047 +- 0.035 (in-sample avg dev_std = 0.055)
NEC for r=0.9 all KL = 0.01 +- 0.035 (in-sample avg dev_std = 0.055)
NEC for r=0.9 all L1 = 0.025 +- 0.070 (in-sample avg dev_std = 0.055)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.765
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.733
NEC for r=1.0 class 0.0 = 0.003 +- 0.083 (in-sample avg dev_std = 0.098)
NEC for r=1.0 class 1.0 = 0.075 +- 0.083 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all KL = 0.021 +- 0.083 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all L1 = 0.039 +- 0.112 (in-sample avg dev_std = 0.098)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.553
NEC for r=0.3 class 0.0 = 0.015 +- 0.018 (in-sample avg dev_std = 0.017)
NEC for r=0.3 class 1.0 = 0.019 +- 0.018 (in-sample avg dev_std = 0.017)
NEC for r=0.3 all KL = 0.008 +- 0.018 (in-sample avg dev_std = 0.017)
NEC for r=0.3 all L1 = 0.017 +- 0.027 (in-sample avg dev_std = 0.017)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.613
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
NEC for r=0.6 class 0.0 = 0.006 +- 0.005 (in-sample avg dev_std = 0.008)
NEC for r=0.6 class 1.0 = 0.01 +- 0.005 (in-sample avg dev_std = 0.008)
NEC for r=0.6 all KL = 0.003 +- 0.005 (in-sample avg dev_std = 0.008)
NEC for r=0.6 all L1 = 0.008 +- 0.012 (in-sample avg dev_std = 0.008)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.591
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0.0 = 0.003 +- 0.003 (in-sample avg dev_std = 0.008)
NEC for r=0.9 class 1.0 = 0.007 +- 0.003 (in-sample avg dev_std = 0.008)
NEC for r=0.9 all KL = 0.001 +- 0.003 (in-sample avg dev_std = 0.008)
NEC for r=0.9 all L1 = 0.005 +- 0.010 (in-sample avg dev_std = 0.008)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.611
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0.0 = 0.003 +- 0.003 (in-sample avg dev_std = 0.007)
NEC for r=1.0 class 1.0 = 0.006 +- 0.003 (in-sample avg dev_std = 0.007)
NEC for r=1.0 all KL = 0.001 +- 0.003 (in-sample avg dev_std = 0.007)
NEC for r=1.0 all L1 = 0.005 +- 0.010 (in-sample avg dev_std = 0.007)


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.594
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.53
SUFF++ for r=0.3 class 0.0 = 0.992 +- 0.027 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.3 class 1.0 = 0.981 +- 0.027 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.3 all KL = 0.992 +- 0.027 (in-sample avg dev_std = 0.036)
SUFF++ for r=0.3 all L1 = 0.986 +- 0.039 (in-sample avg dev_std = 0.036)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.652
SUFF++ for r=0.6 class 0.0 = 0.992 +- 0.059 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 class 1.0 = 0.955 +- 0.059 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 all KL = 0.984 +- 0.059 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.6 all L1 = 0.973 +- 0.083 (in-sample avg dev_std = 0.068)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.761
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.732
SUFF++ for r=0.9 class 0.0 = 0.998 +- 0.046 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.046 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all KL = 0.99 +- 0.046 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all L1 = 0.976 +- 0.070 (in-sample avg dev_std = 0.079)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.542
SUFF++ for r=0.3 class 0.0 = 0.986 +- 0.016 (in-sample avg dev_std = 0.025)
SUFF++ for r=0.3 class 1.0 = 0.983 +- 0.016 (in-sample avg dev_std = 0.025)
SUFF++ for r=0.3 all KL = 0.993 +- 0.016 (in-sample avg dev_std = 0.025)
SUFF++ for r=0.3 all L1 = 0.984 +- 0.022 (in-sample avg dev_std = 0.025)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.579
SUFF++ for r=0.6 class 0.0 = 0.993 +- 0.019 (in-sample avg dev_std = 0.026)
SUFF++ for r=0.6 class 1.0 = 0.988 +- 0.019 (in-sample avg dev_std = 0.026)
SUFF++ for r=0.6 all KL = 0.995 +- 0.019 (in-sample avg dev_std = 0.026)
SUFF++ for r=0.6 all L1 = 0.991 +- 0.014 (in-sample avg dev_std = 0.026)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.591
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.586
SUFF++ for r=0.9 class 0.0 = 0.997 +- 0.002 (in-sample avg dev_std = 0.008)
SUFF++ for r=0.9 class 1.0 = 0.994 +- 0.002 (in-sample avg dev_std = 0.008)
SUFF++ for r=0.9 all KL = 0.999 +- 0.002 (in-sample avg dev_std = 0.008)
SUFF++ for r=0.9 all L1 = 0.995 +- 0.008 (in-sample avg dev_std = 0.008)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:57:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:49 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:53 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:00 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ROC-AUC: 0.9055
Train Loss: 0.0961
ID Validation ROC-AUC: 0.8504
ID Validation Loss: 0.1287
ID Test ROC-AUC: 0.8069
ID Test Loss: 0.1192
OOD Validation ROC-AUC: 0.7714
OOD Validation Loss: 0.1112
OOD Test ROC-AUC: 0.7293
OOD Test Loss: 0.0861

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ROC-AUC: 0.9404
Train Loss: 0.0874
ID Validation ROC-AUC: 0.8359
ID Validation Loss: 0.1400
ID Test ROC-AUC: 0.8053
ID Test Loss: 0.1279
OOD Validation ROC-AUC: 0.7931
OOD Validation Loss: 0.1205
OOD Test ROC-AUC: 0.6859
OOD Test Loss: 0.0967

[0m[1;37mINFO[0m: [1mChartInfo 0.8069 0.7293 0.8053 0.6859 0.8359 0.7931[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 12:58:03 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/08/2024 12:58:05 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.614
NEC for r=0.3 class 0.0 = 0.017 +- 0.066 (in-sample avg dev_std = 0.073)
NEC for r=0.3 class 1.0 = 0.048 +- 0.066 (in-sample avg dev_std = 0.073)
NEC for r=0.3 all KL = 0.018 +- 0.066 (in-sample avg dev_std = 0.073)
NEC for r=0.3 all L1 = 0.033 +- 0.086 (in-sample avg dev_std = 0.073)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.667
NEC for r=0.6 class 0.0 = 0.043 +- 0.080 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 1.0 = 0.074 +- 0.080 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all KL = 0.028 +- 0.080 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all L1 = 0.058 +- 0.108 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.678
NEC for r=0.9 class 0.0 = 0.055 +- 0.075 (in-sample avg dev_std = 0.129)
NEC for r=0.9 class 1.0 = 0.079 +- 0.075 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all KL = 0.029 +- 0.075 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all L1 = 0.067 +- 0.108 (in-sample avg dev_std = 0.129)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.727
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.691
NEC for r=1.0 class 0.0 = 0.052 +- 0.063 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.068 +- 0.063 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.024 +- 0.063 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.06 +- 0.097 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.543
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.594
NEC for r=0.3 class 0.0 = 0.01 +- 0.004 (in-sample avg dev_std = 0.011)
NEC for r=0.3 class 1.0 = 0.014 +- 0.004 (in-sample avg dev_std = 0.011)
NEC for r=0.3 all KL = 0.002 +- 0.004 (in-sample avg dev_std = 0.011)
NEC for r=0.3 all L1 = 0.012 +- 0.010 (in-sample avg dev_std = 0.011)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0.0 = 0.01 +- 0.036 (in-sample avg dev_std = 0.048)
NEC for r=0.6 class 1.0 = 0.03 +- 0.036 (in-sample avg dev_std = 0.048)
NEC for r=0.6 all KL = 0.008 +- 0.036 (in-sample avg dev_std = 0.048)
NEC for r=0.6 all L1 = 0.02 +- 0.054 (in-sample avg dev_std = 0.048)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.673
NEC for r=0.9 class 0.0 = 0.011 +- 0.012 (in-sample avg dev_std = 0.037)
NEC for r=0.9 class 1.0 = 0.021 +- 0.012 (in-sample avg dev_std = 0.037)
NEC for r=0.9 all KL = 0.004 +- 0.012 (in-sample avg dev_std = 0.037)
NEC for r=0.9 all L1 = 0.016 +- 0.030 (in-sample avg dev_std = 0.037)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.696
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.684
NEC for r=1.0 class 0.0 = 0.01 +- 0.019 (in-sample avg dev_std = 0.050)
NEC for r=1.0 class 1.0 = 0.023 +- 0.019 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all KL = 0.004 +- 0.019 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all L1 = 0.017 +- 0.041 (in-sample avg dev_std = 0.050)


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.586
SUFF++ for r=0.3 class 0.0 = 0.972 +- 0.094 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 class 1.0 = 0.936 +- 0.094 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 all KL = 0.957 +- 0.094 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.3 all L1 = 0.954 +- 0.086 (in-sample avg dev_std = 0.167)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
SUFF++ for r=0.6 class 0.0 = 0.93 +- 0.126 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 class 1.0 = 0.866 +- 0.126 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all KL = 0.913 +- 0.126 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all L1 = 0.898 +- 0.125 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.7
SUFF++ for r=0.9 class 0.0 = 0.939 +- 0.086 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 class 1.0 = 0.904 +- 0.086 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all KL = 0.956 +- 0.086 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all L1 = 0.921 +- 0.109 (in-sample avg dev_std = 0.169)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.537
SUFF++ for r=0.3 class 0.0 = 0.989 +- 0.003 (in-sample avg dev_std = 0.012)
SUFF++ for r=0.3 class 1.0 = 0.988 +- 0.003 (in-sample avg dev_std = 0.012)
SUFF++ for r=0.3 all KL = 0.998 +- 0.003 (in-sample avg dev_std = 0.012)
SUFF++ for r=0.3 all L1 = 0.988 +- 0.008 (in-sample avg dev_std = 0.012)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.6
SUFF++ for r=0.6 class 0.0 = 0.984 +- 0.037 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.037 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.6 all KL = 0.985 +- 0.037 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.6 all L1 = 0.973 +- 0.057 (in-sample avg dev_std = 0.075)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
SUFF++ for r=0.9 class 0.0 = 0.99 +- 0.028 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 class 1.0 = 0.97 +- 0.028 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 all KL = 0.993 +- 0.028 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 all L1 = 0.98 +- 0.049 (in-sample avg dev_std = 0.060)


ratio=1.0



Zero intervened samples, skipping weight=1.0


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.014, 0.029, 0.02, 0.018], 'all_L1': [0.021, 0.047, 0.057, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.021, 0.053, 0.052, 0.047], 'all_L1': [0.031, 0.083, 0.089, 0.085]}), defaultdict(<class 'list'>, {'all_KL': [0.033, 0.056, 0.06, 0.054], 'all_L1': [0.038, 0.076, 0.079, 0.077]}), defaultdict(<class 'list'>, {'all_KL': [0.005, 0.014, 0.01, 0.021], 'all_L1': [0.011, 0.024, 0.025, 0.039]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.028, 0.029, 0.024], 'all_L1': [0.033, 0.058, 0.067, 0.06]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.957, 0.929, 0.973, 1.0], 'all_L1': [0.962, 0.928, 0.936, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.952, 0.884, 0.958, 1.0], 'all_L1': [0.952, 0.877, 0.92, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.929, 0.812, 0.927, 1.0], 'all_L1': [0.942, 0.857, 0.915, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.992, 0.984, 0.99, 1.0], 'all_L1': [0.986, 0.973, 0.976, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.957, 0.913, 0.956, 1.0], 'all_L1': [0.954, 0.898, 0.921, 1.0], 0.0: [1.0], 1.0: [1.0]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.011, 0.022, 0.018, 0.012], 'all_L1': [0.018, 0.032, 0.047, 0.037]}), defaultdict(<class 'list'>, {'all_KL': [0.007, 0.014, 0.023, 0.024], 'all_L1': [0.01, 0.025, 0.036, 0.035]}), defaultdict(<class 'list'>, {'all_KL': [0.008, 0.019, 0.028, 0.029], 'all_L1': [0.011, 0.031, 0.043, 0.044]}), defaultdict(<class 'list'>, {'all_KL': [0.008, 0.003, 0.001, 0.001], 'all_L1': [0.017, 0.008, 0.005, 0.005]}), defaultdict(<class 'list'>, {'all_KL': [0.002, 0.008, 0.004, 0.004], 'all_L1': [0.012, 0.02, 0.016, 0.017]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.989, 0.96, 0.976, 1.0], 'all_L1': [0.984, 0.955, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.992, 0.972, 0.987, 1.0], 'all_L1': [0.989, 0.967, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.991, 0.93, 0.974, 1.0], 'all_L1': [0.988, 0.94, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.993, 0.995, 0.999, 1.0], 'all_L1': [0.984, 0.991, 0.995, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.998, 0.985, 0.993, 1.0], 'all_L1': [0.988, 0.973, 0.98, 1.0], 0.0: [1.0], 1.0: [1.0]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
nec class all_L1  =  0.027 +- 0.010, 0.058 +- 0.021, 0.063 +- 0.022, 0.062 +- 0.017
nec class all_KL  =  0.018 +- 0.009, 0.036 +- 0.016, 0.034 +- 0.019, 0.033 +- 0.015
nec_acc_int  =  0.594 +- 0.032, 0.681 +- 0.040, 0.718 +- 0.047, 0.723 +- 0.042
suff++ class all_L1  =  0.959 +- 0.015, 0.907 +- 0.041, 0.934 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.957 +- 0.020, 0.904 +- 0.057, 0.961 +- 0.021, 1.000 +- 0.000
suff++_acc_int  =  0.561 +- 0.022, 0.657 +- 0.035, 0.724 +- 0.042

Eval split test
nec class all_L1  =  0.014 +- 0.003, 0.023 +- 0.009, 0.029 +- 0.016, 0.028 +- 0.014
nec class all_KL  =  0.007 +- 0.003, 0.013 +- 0.007, 0.015 +- 0.011, 0.014 +- 0.011
nec_acc_int  =  0.567 +- 0.015, 0.601 +- 0.038, 0.641 +- 0.057, 0.644 +- 0.058
suff++ class all_L1  =  0.987 +- 0.002, 0.965 +- 0.017, 0.971 +- 0.016, 1.000 +- 0.000
suff++ class all_KL  =  0.993 +- 0.003, 0.968 +- 0.023, 0.986 +- 0.010, 1.000 +- 0.000
suff++_acc_int  =  0.542 +- 0.024, 0.589 +- 0.019, 0.629 +- 0.056


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.493 +- 0.003, 0.482 +- 0.011, 0.499 +- 0.004, 0.531 +- 0.008
Faith. Armon (L1)= 		  =  0.052 +- 0.018, 0.107 +- 0.037, 0.118 +- 0.039, 0.117 +- 0.030
Faith. GMean (L1)= 	  =  0.157 +- 0.031, 0.223 +- 0.041, 0.238 +- 0.045, 0.247 +- 0.034
Faith. Aritm (KL)= 		  =  0.488 +- 0.006, 0.470 +- 0.021, 0.498 +- 0.005, 0.516 +- 0.007
Faith. Armon (KL)= 		  =  0.036 +- 0.018, 0.069 +- 0.029, 0.065 +- 0.035, 0.063 +- 0.027
Faith. GMean (KL)= 	  =  0.127 +- 0.034, 0.174 +- 0.037, 0.173 +- 0.051, 0.177 +- 0.040

Eval split test
Faith. Aritm (L1)= 		  =  0.500 +- 0.001, 0.494 +- 0.005, 0.500 +- 0.002, 0.514 +- 0.007
Faith. Armon (L1)= 		  =  0.027 +- 0.006, 0.045 +- 0.017, 0.057 +- 0.031, 0.053 +- 0.027
Faith. GMean (L1)= 	  =  0.115 +- 0.014, 0.146 +- 0.031, 0.159 +- 0.054, 0.158 +- 0.051
Faith. Aritm (KL)= 		  =  0.500 +- 0.000, 0.491 +- 0.009, 0.500 +- 0.003, 0.507 +- 0.005
Faith. Armon (KL)= 		  =  0.014 +- 0.006, 0.026 +- 0.014, 0.029 +- 0.021, 0.027 +- 0.021
Faith. GMean (KL)= 	  =  0.082 +- 0.020, 0.108 +- 0.033, 0.109 +- 0.052, 0.106 +- 0.053
Computed for split load_split = id



Completed in  0:04:58.964068  for GSATvGIN GOODHIV/scaffold



DONE GSAT GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:59:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:54 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:17 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ROC-AUC: 0.9790
Train Loss: 0.1210
ID Validation ROC-AUC: 0.9202
ID Validation Loss: 0.2663
ID Test ROC-AUC: 0.9191
ID Test Loss: 0.2695
OOD Validation ROC-AUC: 0.6372
OOD Validation Loss: 0.5165
OOD Test ROC-AUC: 0.6873
OOD Test Loss: 0.6912

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 1...
[0m[1;37mINFO[0m: [1mCheckpoint 1: 
-----------------------------------
Train ROC-AUC: 0.8266
Train Loss: 0.7015
ID Validation ROC-AUC: 0.8256
ID Validation Loss: 0.7089
ID Test ROC-AUC: 0.8216
ID Test Loss: 0.7167
OOD Validation ROC-AUC: 0.7019
OOD Validation Loss: 0.4065
OOD Test ROC-AUC: 0.7079
OOD Test Loss: 0.4708

[0m[1;37mINFO[0m: [1mChartInfo 0.9191 0.6873 0.8216 0.7079 0.8256 0.7019[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/08/2024 01:01:01 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.815
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.747
NEC for r=0.3 class 0.0 = 0.313 +- 0.156 (in-sample avg dev_std = 0.281)
NEC for r=0.3 class 1.0 = 0.223 +- 0.156 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all KL = 0.147 +- 0.156 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all L1 = 0.234 +- 0.156 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.836
NEC for r=0.6 class 0.0 = 0.295 +- 0.175 (in-sample avg dev_std = 0.268)
NEC for r=0.6 class 1.0 = 0.141 +- 0.175 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all KL = 0.125 +- 0.175 (in-sample avg dev_std = 0.268)
NEC for r=0.6 all L1 = 0.16 +- 0.165 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.862
NEC for r=0.9 class 0.0 = 0.247 +- 0.145 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 1.0 = 0.105 +- 0.145 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all KL = 0.089 +- 0.145 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all L1 = 0.122 +- 0.149 (in-sample avg dev_std = 0.233)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.241 +- 0.154 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1.0 = 0.102 +- 0.154 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.091 +- 0.154 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.119 +- 0.149 (in-sample avg dev_std = 0.238)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
NEC for r=0.3 class 0.0 = 0.321 +- 0.177 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1.0 = 0.265 +- 0.177 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.167 +- 0.177 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.274 +- 0.162 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.687
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.654
NEC for r=0.6 class 0.0 = 0.275 +- 0.164 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 1.0 = 0.203 +- 0.164 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all KL = 0.137 +- 0.164 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all L1 = 0.215 +- 0.164 (in-sample avg dev_std = 0.278)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0.0 = 0.22 +- 0.144 (in-sample avg dev_std = 0.246)
NEC for r=0.9 class 1.0 = 0.165 +- 0.144 (in-sample avg dev_std = 0.246)
NEC for r=0.9 all KL = 0.104 +- 0.144 (in-sample avg dev_std = 0.246)
NEC for r=0.9 all L1 = 0.174 +- 0.157 (in-sample avg dev_std = 0.246)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0.0 = 0.21 +- 0.135 (in-sample avg dev_std = 0.229)
NEC for r=1.0 class 1.0 = 0.152 +- 0.135 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all KL = 0.095 +- 0.135 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all L1 = 0.162 +- 0.153 (in-sample avg dev_std = 0.229)


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.815
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.721
SUFF++ for r=0.3 class 0.0 = 0.622 +- 0.158 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 1.0 = 0.765 +- 0.158 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all KL = 0.827 +- 0.158 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all L1 = 0.748 +- 0.161 (in-sample avg dev_std = 0.337)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.809
SUFF++ for r=0.6 class 0.0 = 0.631 +- 0.178 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.178 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.6 all KL = 0.856 +- 0.178 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.178 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0.0 = 0.733 +- 0.174 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1.0 = 0.89 +- 0.174 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.905 +- 0.174 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.871 +- 0.168 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.621
SUFF++ for r=0.3 class 0.0 = 0.66 +- 0.165 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 1.0 = 0.719 +- 0.165 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all KL = 0.809 +- 0.165 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all L1 = 0.709 +- 0.154 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.687
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0.0 = 0.678 +- 0.176 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 class 1.0 = 0.764 +- 0.176 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 all KL = 0.821 +- 0.176 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 all L1 = 0.75 +- 0.178 (in-sample avg dev_std = 0.333)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.678
SUFF++ for r=0.9 class 0.0 = 0.755 +- 0.148 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 1.0 = 0.833 +- 0.148 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all KL = 0.895 +- 0.148 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all L1 = 0.82 +- 0.173 (in-sample avg dev_std = 0.234)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:04:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:31 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:07 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:18 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:31 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9730
Train Loss: 0.1349
ID Validation ROC-AUC: 0.9206
ID Validation Loss: 0.2729
ID Test ROC-AUC: 0.9183
ID Test Loss: 0.2776
OOD Validation ROC-AUC: 0.6535
OOD Validation Loss: 0.5572
OOD Test ROC-AUC: 0.7044
OOD Test Loss: 0.7172

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ROC-AUC: 0.8666
Train Loss: 0.3770
ID Validation ROC-AUC: 0.8640
ID Validation Loss: 0.3811
ID Test ROC-AUC: 0.8657
ID Test Loss: 0.3851
OOD Validation ROC-AUC: 0.6952
OOD Validation Loss: 0.3144
OOD Test ROC-AUC: 0.7141
OOD Test Loss: 0.5763

[0m[1;37mINFO[0m: [1mChartInfo 0.9183 0.7044 0.8657 0.7141 0.8640 0.6952[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:06:06 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/08/2024 01:06:12 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.773
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.747
NEC for r=0.3 class 0.0 = 0.21 +- 0.105 (in-sample avg dev_std = 0.204)
NEC for r=0.3 class 1.0 = 0.189 +- 0.105 (in-sample avg dev_std = 0.204)
NEC for r=0.3 all KL = 0.093 +- 0.105 (in-sample avg dev_std = 0.204)
NEC for r=0.3 all L1 = 0.191 +- 0.117 (in-sample avg dev_std = 0.204)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.848
NEC for r=0.6 class 0.0 = 0.207 +- 0.118 (in-sample avg dev_std = 0.173)
NEC for r=0.6 class 1.0 = 0.065 +- 0.118 (in-sample avg dev_std = 0.173)
NEC for r=0.6 all KL = 0.056 +- 0.118 (in-sample avg dev_std = 0.173)
NEC for r=0.6 all L1 = 0.082 +- 0.133 (in-sample avg dev_std = 0.173)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.873
NEC for r=0.9 class 0.0 = 0.198 +- 0.123 (in-sample avg dev_std = 0.159)
NEC for r=0.9 class 1.0 = 0.047 +- 0.123 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all KL = 0.048 +- 0.123 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all L1 = 0.065 +- 0.132 (in-sample avg dev_std = 0.159)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.175 +- 0.118 (in-sample avg dev_std = 0.150)
NEC for r=1.0 class 1.0 = 0.042 +- 0.118 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all KL = 0.043 +- 0.118 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all L1 = 0.057 +- 0.123 (in-sample avg dev_std = 0.150)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
NEC for r=0.3 class 0.0 = 0.242 +- 0.136 (in-sample avg dev_std = 0.229)
NEC for r=0.3 class 1.0 = 0.234 +- 0.136 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all KL = 0.114 +- 0.136 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all L1 = 0.236 +- 0.136 (in-sample avg dev_std = 0.229)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.675
NEC for r=0.6 class 0.0 = 0.18 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.6 class 1.0 = 0.135 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all KL = 0.098 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all L1 = 0.142 +- 0.164 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.707
NEC for r=0.9 class 0.0 = 0.166 +- 0.145 (in-sample avg dev_std = 0.199)
NEC for r=0.9 class 1.0 = 0.093 +- 0.145 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all KL = 0.074 +- 0.145 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all L1 = 0.105 +- 0.152 (in-sample avg dev_std = 0.199)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.724
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.704
NEC for r=1.0 class 0.0 = 0.162 +- 0.134 (in-sample avg dev_std = 0.189)
NEC for r=1.0 class 1.0 = 0.084 +- 0.134 (in-sample avg dev_std = 0.189)
NEC for r=1.0 all KL = 0.067 +- 0.134 (in-sample avg dev_std = 0.189)
NEC for r=1.0 all L1 = 0.097 +- 0.148 (in-sample avg dev_std = 0.189)


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.773
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.649
SUFF++ for r=0.3 class 0.0 = 0.636 +- 0.124 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.3 class 1.0 = 0.752 +- 0.124 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.3 all KL = 0.834 +- 0.124 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.3 all L1 = 0.739 +- 0.148 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.774
SUFF++ for r=0.6 class 0.0 = 0.688 +- 0.156 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 class 1.0 = 0.917 +- 0.156 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all KL = 0.908 +- 0.156 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.171 (in-sample avg dev_std = 0.209)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.85
SUFF++ for r=0.9 class 0.0 = 0.772 +- 0.121 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.121 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all KL = 0.952 +- 0.121 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.139 (in-sample avg dev_std = 0.141)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0.0 = 0.63 +- 0.145 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 1.0 = 0.697 +- 0.145 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 all KL = 0.804 +- 0.145 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 all L1 = 0.686 +- 0.138 (in-sample avg dev_std = 0.335)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.687
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.648
SUFF++ for r=0.6 class 0.0 = 0.733 +- 0.186 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.6 class 1.0 = 0.833 +- 0.186 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.6 all KL = 0.855 +- 0.186 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.204 (in-sample avg dev_std = 0.281)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.717
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
SUFF++ for r=0.9 class 0.0 = 0.812 +- 0.161 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 1.0 = 0.899 +- 0.161 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all KL = 0.916 +- 0.161 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.170 (in-sample avg dev_std = 0.205)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:09:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:32 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:10:09 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:10:23 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:10:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:10:57 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ROC-AUC: 0.9708
Train Loss: 0.1435
ID Validation ROC-AUC: 0.9211
ID Validation Loss: 0.2689
ID Test ROC-AUC: 0.9165
ID Test Loss: 0.2816
OOD Validation ROC-AUC: 0.6552
OOD Validation Loss: 0.4851
OOD Test ROC-AUC: 0.6967
OOD Test Loss: 0.6916

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 2...
[0m[1;37mINFO[0m: [1mCheckpoint 2: 
-----------------------------------
Train ROC-AUC: 0.8500
Train Loss: 0.3423
ID Validation ROC-AUC: 0.8488
ID Validation Loss: 0.3452
ID Test ROC-AUC: 0.8482
ID Test Loss: 0.3500
OOD Validation ROC-AUC: 0.7007
OOD Validation Loss: 0.2847
OOD Test ROC-AUC: 0.7132
OOD Test Loss: 0.5090

[0m[1;37mINFO[0m: [1mChartInfo 0.9165 0.6967 0.8482 0.7132 0.8488 0.7007[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:11:15 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/08/2024 01:11:22 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.655
NEC for r=0.3 class 0.0 = 0.242 +- 0.102 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 1.0 = 0.2 +- 0.102 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all KL = 0.094 +- 0.102 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all L1 = 0.205 +- 0.127 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.85
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.818
NEC for r=0.6 class 0.0 = 0.239 +- 0.097 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1.0 = 0.108 +- 0.097 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.067 +- 0.097 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.124 +- 0.140 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.859
NEC for r=0.9 class 0.0 = 0.201 +- 0.088 (in-sample avg dev_std = 0.160)
NEC for r=0.9 class 1.0 = 0.066 +- 0.088 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all KL = 0.044 +- 0.088 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all L1 = 0.082 +- 0.127 (in-sample avg dev_std = 0.160)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.193 +- 0.087 (in-sample avg dev_std = 0.150)
NEC for r=1.0 class 1.0 = 0.055 +- 0.087 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all KL = 0.037 +- 0.087 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all L1 = 0.071 +- 0.119 (in-sample avg dev_std = 0.150)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
NEC for r=0.3 class 0.0 = 0.249 +- 0.104 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1.0 = 0.205 +- 0.104 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.091 +- 0.104 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.212 +- 0.129 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.72
NEC for r=0.6 class 0.0 = 0.228 +- 0.119 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 1.0 = 0.167 +- 0.119 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all KL = 0.091 +- 0.119 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all L1 = 0.177 +- 0.152 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.734
NEC for r=0.9 class 0.0 = 0.186 +- 0.105 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1.0 = 0.114 +- 0.105 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.063 +- 0.105 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.126 +- 0.148 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.742
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.73
NEC for r=1.0 class 0.0 = 0.174 +- 0.101 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 1.0 = 0.097 +- 0.101 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all KL = 0.054 +- 0.101 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all L1 = 0.109 +- 0.138 (in-sample avg dev_std = 0.174)


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.648
SUFF++ for r=0.3 class 0.0 = 0.722 +- 0.098 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 1.0 = 0.771 +- 0.098 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all KL = 0.88 +- 0.098 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all L1 = 0.766 +- 0.126 (in-sample avg dev_std = 0.241)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.85
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.8
SUFF++ for r=0.6 class 0.0 = 0.666 +- 0.128 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 class 1.0 = 0.87 +- 0.128 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all KL = 0.903 +- 0.128 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all L1 = 0.846 +- 0.178 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0.0 = 0.754 +- 0.112 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 class 1.0 = 0.922 +- 0.112 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all KL = 0.943 +- 0.112 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.154 (in-sample avg dev_std = 0.165)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0.0 = 0.725 +- 0.099 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 1.0 = 0.765 +- 0.099 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all KL = 0.884 +- 0.099 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all L1 = 0.758 +- 0.124 (in-sample avg dev_std = 0.247)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.722
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
SUFF++ for r=0.6 class 0.0 = 0.688 +- 0.143 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 class 1.0 = 0.8 +- 0.143 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 all KL = 0.87 +- 0.143 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.186 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
SUFF++ for r=0.9 class 0.0 = 0.806 +- 0.117 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1.0 = 0.871 +- 0.117 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.926 +- 0.117 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.861 +- 0.166 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:14:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:14:43 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:16 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:28 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:41 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:00 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ROC-AUC: 0.9711
Train Loss: 0.1374
ID Validation ROC-AUC: 0.9175
ID Validation Loss: 0.2514
ID Test ROC-AUC: 0.9200
ID Test Loss: 0.2482
OOD Validation ROC-AUC: 0.6432
OOD Validation Loss: 0.4802
OOD Test ROC-AUC: 0.6930
OOD Test Loss: 0.6345

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ROC-AUC: 0.8717
Train Loss: 0.3270
ID Validation ROC-AUC: 0.8702
ID Validation Loss: 0.3310
ID Test ROC-AUC: 0.8707
ID Test Loss: 0.3340
OOD Validation ROC-AUC: 0.6958
OOD Validation Loss: 0.3030
OOD Test ROC-AUC: 0.7249
OOD Test Loss: 0.5231

[0m[1;37mINFO[0m: [1mChartInfo 0.9200 0.6930 0.8707 0.7249 0.8702 0.6958[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:16:18 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/08/2024 01:16:23 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.817
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.753
NEC for r=0.3 class 0.0 = 0.309 +- 0.131 (in-sample avg dev_std = 0.247)
NEC for r=0.3 class 1.0 = 0.199 +- 0.131 (in-sample avg dev_std = 0.247)
NEC for r=0.3 all KL = 0.105 +- 0.131 (in-sample avg dev_std = 0.247)
NEC for r=0.3 all L1 = 0.212 +- 0.147 (in-sample avg dev_std = 0.247)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.842
NEC for r=0.6 class 0.0 = 0.257 +- 0.136 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 1.0 = 0.135 +- 0.136 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all KL = 0.091 +- 0.136 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all L1 = 0.149 +- 0.148 (in-sample avg dev_std = 0.231)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.877
NEC for r=0.9 class 0.0 = 0.214 +- 0.112 (in-sample avg dev_std = 0.194)
NEC for r=0.9 class 1.0 = 0.084 +- 0.112 (in-sample avg dev_std = 0.194)
NEC for r=0.9 all KL = 0.062 +- 0.112 (in-sample avg dev_std = 0.194)
NEC for r=0.9 all L1 = 0.1 +- 0.133 (in-sample avg dev_std = 0.194)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.202 +- 0.117 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 1.0 = 0.077 +- 0.117 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all KL = 0.059 +- 0.117 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all L1 = 0.091 +- 0.129 (in-sample avg dev_std = 0.194)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.629
NEC for r=0.3 class 0.0 = 0.278 +- 0.160 (in-sample avg dev_std = 0.278)
NEC for r=0.3 class 1.0 = 0.252 +- 0.160 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all KL = 0.137 +- 0.160 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all L1 = 0.256 +- 0.169 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.676
NEC for r=0.6 class 0.0 = 0.243 +- 0.148 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1.0 = 0.197 +- 0.148 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.113 +- 0.148 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.204 +- 0.165 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.699
NEC for r=0.9 class 0.0 = 0.215 +- 0.141 (in-sample avg dev_std = 0.247)
NEC for r=0.9 class 1.0 = 0.157 +- 0.141 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all KL = 0.098 +- 0.141 (in-sample avg dev_std = 0.247)
NEC for r=0.9 all L1 = 0.167 +- 0.164 (in-sample avg dev_std = 0.247)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.702
NEC for r=1.0 class 0.0 = 0.201 +- 0.130 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1.0 = 0.14 +- 0.130 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.087 +- 0.130 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.15 +- 0.158 (in-sample avg dev_std = 0.238)


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.817
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.701
SUFF++ for r=0.3 class 0.0 = 0.625 +- 0.139 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.3 class 1.0 = 0.773 +- 0.139 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.3 all KL = 0.861 +- 0.139 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.3 all L1 = 0.756 +- 0.139 (in-sample avg dev_std = 0.320)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.813
SUFF++ for r=0.6 class 0.0 = 0.652 +- 0.149 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 class 1.0 = 0.843 +- 0.149 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 all KL = 0.874 +- 0.149 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.163 (in-sample avg dev_std = 0.287)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.759 +- 0.139 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 class 1.0 = 0.908 +- 0.139 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all KL = 0.925 +- 0.139 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all L1 = 0.89 +- 0.148 (in-sample avg dev_std = 0.201)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
SUFF++ for r=0.3 class 0.0 = 0.67 +- 0.155 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.3 class 1.0 = 0.717 +- 0.155 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.3 all KL = 0.822 +- 0.155 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.3 all L1 = 0.709 +- 0.144 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.666
SUFF++ for r=0.6 class 0.0 = 0.682 +- 0.163 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 1.0 = 0.764 +- 0.163 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all KL = 0.838 +- 0.163 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all L1 = 0.75 +- 0.176 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.699
SUFF++ for r=0.9 class 0.0 = 0.779 +- 0.146 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1.0 = 0.839 +- 0.146 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.898 +- 0.146 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.168 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:19:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:20:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:20:31 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:20:45 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:21:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ROC-AUC: 0.9717
Train Loss: 0.1380
ID Validation ROC-AUC: 0.9197
ID Validation Loss: 0.2550
ID Test ROC-AUC: 0.9210
ID Test Loss: 0.2563
OOD Validation ROC-AUC: 0.6324
OOD Validation Loss: 0.4871
OOD Test ROC-AUC: 0.6937
OOD Test Loss: 0.6380

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 2...
[0m[1;37mINFO[0m: [1mCheckpoint 2: 
-----------------------------------
Train ROC-AUC: 0.8312
Train Loss: 1.4697
ID Validation ROC-AUC: 0.8322
ID Validation Loss: 1.4867
ID Test ROC-AUC: 0.8295
ID Test Loss: 1.4988
OOD Validation ROC-AUC: 0.6988
OOD Validation Loss: 0.6555
OOD Test ROC-AUC: 0.7116
OOD Test Loss: 0.5724

[0m[1;37mINFO[0m: [1mChartInfo 0.9210 0.6937 0.8295 0.7116 0.8322 0.6988[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:21:22 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/08/2024 01:21:26 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.704
NEC for r=0.3 class 0.0 = 0.274 +- 0.129 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 1.0 = 0.234 +- 0.129 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all KL = 0.109 +- 0.129 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all L1 = 0.239 +- 0.128 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.805
NEC for r=0.6 class 0.0 = 0.23 +- 0.157 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 1.0 = 0.152 +- 0.157 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all KL = 0.11 +- 0.157 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all L1 = 0.162 +- 0.152 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.832
NEC for r=0.9 class 0.0 = 0.2 +- 0.131 (in-sample avg dev_std = 0.219)
NEC for r=0.9 class 1.0 = 0.114 +- 0.131 (in-sample avg dev_std = 0.219)
NEC for r=0.9 all KL = 0.076 +- 0.131 (in-sample avg dev_std = 0.219)
NEC for r=0.9 all L1 = 0.124 +- 0.141 (in-sample avg dev_std = 0.219)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.879
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.839
NEC for r=1.0 class 0.0 = 0.185 +- 0.119 (in-sample avg dev_std = 0.202)
NEC for r=1.0 class 1.0 = 0.107 +- 0.119 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all KL = 0.066 +- 0.119 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all L1 = 0.116 +- 0.132 (in-sample avg dev_std = 0.202)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.597
NEC for r=0.3 class 0.0 = 0.258 +- 0.143 (in-sample avg dev_std = 0.258)
NEC for r=0.3 class 1.0 = 0.271 +- 0.143 (in-sample avg dev_std = 0.258)
NEC for r=0.3 all KL = 0.129 +- 0.143 (in-sample avg dev_std = 0.258)
NEC for r=0.3 all L1 = 0.269 +- 0.144 (in-sample avg dev_std = 0.258)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.652
NEC for r=0.6 class 0.0 = 0.231 +- 0.173 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 1.0 = 0.216 +- 0.173 (in-sample avg dev_std = 0.287)
NEC for r=0.6 all KL = 0.139 +- 0.173 (in-sample avg dev_std = 0.287)
NEC for r=0.6 all L1 = 0.219 +- 0.171 (in-sample avg dev_std = 0.287)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.657
NEC for r=0.9 class 0.0 = 0.195 +- 0.159 (in-sample avg dev_std = 0.256)
NEC for r=0.9 class 1.0 = 0.18 +- 0.159 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all KL = 0.108 +- 0.159 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all L1 = 0.183 +- 0.162 (in-sample avg dev_std = 0.256)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.685
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.657
NEC for r=1.0 class 0.0 = 0.19 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 1.0 = 0.172 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all KL = 0.095 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all L1 = 0.175 +- 0.156 (in-sample avg dev_std = 0.239)


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.656
SUFF++ for r=0.3 class 0.0 = 0.672 +- 0.114 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.3 class 1.0 = 0.72 +- 0.114 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.3 all KL = 0.851 +- 0.114 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.3 all L1 = 0.714 +- 0.116 (in-sample avg dev_std = 0.315)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.775
SUFF++ for r=0.6 class 0.0 = 0.693 +- 0.157 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 class 1.0 = 0.829 +- 0.157 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all KL = 0.865 +- 0.157 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all L1 = 0.813 +- 0.172 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.827
SUFF++ for r=0.9 class 0.0 = 0.78 +- 0.133 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 class 1.0 = 0.884 +- 0.133 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all KL = 0.923 +- 0.133 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.151 (in-sample avg dev_std = 0.204)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0.0 = 0.682 +- 0.126 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.3 class 1.0 = 0.706 +- 0.126 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.3 all KL = 0.846 +- 0.126 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.3 all L1 = 0.702 +- 0.120 (in-sample avg dev_std = 0.329)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.621
SUFF++ for r=0.6 class 0.0 = 0.695 +- 0.171 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 1.0 = 0.747 +- 0.171 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all KL = 0.817 +- 0.171 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all L1 = 0.739 +- 0.175 (in-sample avg dev_std = 0.355)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.685
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.654
SUFF++ for r=0.9 class 0.0 = 0.779 +- 0.151 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1.0 = 0.826 +- 0.151 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.897 +- 0.151 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.819 +- 0.168 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.147, 0.125, 0.089, 0.091], 'all_L1': [0.234, 0.16, 0.122, 0.119]}), defaultdict(<class 'list'>, {'all_KL': [0.093, 0.056, 0.048, 0.043], 'all_L1': [0.191, 0.082, 0.065, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.094, 0.067, 0.044, 0.037], 'all_L1': [0.205, 0.124, 0.082, 0.071]}), defaultdict(<class 'list'>, {'all_KL': [0.105, 0.091, 0.062, 0.059], 'all_L1': [0.212, 0.149, 0.1, 0.091]}), defaultdict(<class 'list'>, {'all_KL': [0.109, 0.11, 0.076, 0.066], 'all_L1': [0.239, 0.162, 0.124, 0.116]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.827, 0.856, 0.905, 1.0], 'all_L1': [0.748, 0.824, 0.871, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.834, 0.908, 0.952, 1.0], 'all_L1': [0.739, 0.89, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.88, 0.903, 0.943, 1.0], 'all_L1': [0.766, 0.846, 0.902, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.861, 0.874, 0.925, 1.0], 'all_L1': [0.756, 0.82, 0.89, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.851, 0.865, 0.923, 1.0], 'all_L1': [0.714, 0.813, 0.872, 1.0], 0.0: [1.0], 1.0: [1.0]})]

Eval split test
nec = [defaultdict(<class 'list'>, {'all_KL': [0.167, 0.137, 0.104, 0.095], 'all_L1': [0.274, 0.215, 0.174, 0.162]}), defaultdict(<class 'list'>, {'all_KL': [0.114, 0.098, 0.074, 0.067], 'all_L1': [0.236, 0.142, 0.105, 0.097]}), defaultdict(<class 'list'>, {'all_KL': [0.091, 0.091, 0.063, 0.054], 'all_L1': [0.212, 0.177, 0.126, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.137, 0.113, 0.098, 0.087], 'all_L1': [0.256, 0.204, 0.167, 0.15]}), defaultdict(<class 'list'>, {'all_KL': [0.129, 0.139, 0.108, 0.095], 'all_L1': [0.269, 0.219, 0.183, 0.175]})]
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.809, 0.821, 0.895, 1.0], 'all_L1': [0.709, 0.75, 0.82, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.804, 0.855, 0.916, 1.0], 'all_L1': [0.686, 0.817, 0.885, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.884, 0.87, 0.926, 1.0], 'all_L1': [0.758, 0.782, 0.861, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.822, 0.838, 0.898, 1.0], 'all_L1': [0.709, 0.75, 0.829, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.846, 0.817, 0.897, 1.0], 'all_L1': [0.702, 0.739, 0.819, 1.0], 0.0: [1.0], 1.0: [1.0]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
nec class all_L1  =  0.216 +- 0.018, 0.135 +- 0.030, 0.099 +- 0.023, 0.091 +- 0.024
nec class all_KL  =  0.110 +- 0.020, 0.090 +- 0.026, 0.064 +- 0.017, 0.059 +- 0.019
nec_acc_int  =  0.721 +- 0.037, 0.830 +- 0.016, 0.861 +- 0.016, 0.864 +- 0.013
suff++ class all_L1  =  0.745 +- 0.018, 0.839 +- 0.028, 0.894 +- 0.023, 1.000 +- 0.000
suff++ class all_KL  =  0.851 +- 0.019, 0.881 +- 0.021, 0.930 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.675 +- 0.030, 0.794 +- 0.017, 0.850 +- 0.014

Eval split test
nec class all_L1  =  0.249 +- 0.023, 0.191 +- 0.029, 0.151 +- 0.030, 0.139 +- 0.030
nec class all_KL  =  0.128 +- 0.025, 0.116 +- 0.020, 0.089 +- 0.018, 0.080 +- 0.016
nec_acc_int  =  0.618 +- 0.015, 0.676 +- 0.025, 0.694 +- 0.027, 0.696 +- 0.024
suff++ class all_L1  =  0.713 +- 0.024, 0.768 +- 0.029, 0.843 +- 0.026, 1.000 +- 0.000
suff++ class all_KL  =  0.833 +- 0.029, 0.840 +- 0.020, 0.906 +- 0.012, 1.000 +- 0.000
suff++_acc_int  =  0.595 +- 0.018, 0.656 +- 0.022, 0.688 +- 0.020


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.480 +- 0.009, 0.487 +- 0.003, 0.496 +- 0.002, 0.545 +- 0.012
Faith. Armon (L1)= 		  =  0.335 +- 0.021, 0.231 +- 0.045, 0.177 +- 0.037, 0.166 +- 0.041
Faith. GMean (L1)= 	  =  0.401 +- 0.015, 0.334 +- 0.035, 0.294 +- 0.032, 0.298 +- 0.041
Faith. Aritm (KL)= 		  =  0.480 +- 0.009, 0.486 +- 0.003, 0.497 +- 0.003, 0.530 +- 0.010
Faith. Armon (KL)= 		  =  0.193 +- 0.030, 0.162 +- 0.042, 0.119 +- 0.029, 0.111 +- 0.034
Faith. GMean (KL)= 	  =  0.304 +- 0.024, 0.278 +- 0.038, 0.241 +- 0.030, 0.240 +- 0.039

Eval split test
Faith. Aritm (L1)= 		  =  0.481 +- 0.010, 0.479 +- 0.002, 0.497 +- 0.003, 0.569 +- 0.015
Faith. Armon (L1)= 		  =  0.369 +- 0.024, 0.305 +- 0.036, 0.254 +- 0.043, 0.242 +- 0.047
Faith. GMean (L1)= 	  =  0.421 +- 0.016, 0.382 +- 0.023, 0.354 +- 0.032, 0.370 +- 0.042
Faith. Aritm (KL)= 		  =  0.480 +- 0.011, 0.478 +- 0.002, 0.498 +- 0.003, 0.540 +- 0.008
Faith. Armon (KL)= 		  =  0.220 +- 0.037, 0.202 +- 0.030, 0.162 +- 0.029, 0.147 +- 0.028
Faith. GMean (KL)= 	  =  0.324 +- 0.029, 0.310 +- 0.023, 0.283 +- 0.027, 0.281 +- 0.030
Computed for split load_split = id



Completed in  0:25:45.166947  for GSATvGIN LBAPcore/assay



DONE GSAT LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:25:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:05 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:05 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:25:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9577
Train Loss: 0.1191
ID Validation ACCURACY: 0.8961
ID Validation Loss: 0.3648
ID Test ACCURACY: 0.8907
ID Test Loss: 0.3804
OOD Validation ACCURACY: 0.7797
OOD Validation Loss: 0.8828
OOD Test ACCURACY: 0.2677
OOD Test Loss: 6.4566

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9471
Train Loss: 0.1505
ID Validation ACCURACY: 0.8906
ID Validation Loss: 0.3662
ID Test ACCURACY: 0.8890
ID Test Loss: 0.3755
OOD Validation ACCURACY: 0.8057
OOD Validation Loss: 0.7317
OOD Test ACCURACY: 0.3631
OOD Test Loss: 4.0084

[0m[1;37mINFO[0m: [1mChartInfo 0.8907 0.2677 0.8890 0.3631 0.8906 0.8057[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
[1;31mERROR[0m: 05/08/2024 01:25:09 PM - utils.py - line 52 : [1mCUDA out of memory. Tried to allocate 1.60 GiB. GPU 2 has a total capacty of 11.92 GiB of which 820.69 MiB is free. Process 1382280 has 8.92 GiB memory in use. Including non-PyTorch memory, this process has 2.20 GiB memory in use. Of the allocated memory 1.65 GiB is allocated by PyTorch, and 41.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0m
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 639, in goodtg
    print(f'#E#{e}')
