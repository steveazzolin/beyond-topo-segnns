
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 20:30:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 08:30:59 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:19 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:31:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 88...
[0m[1;37mINFO[0m: [1mCheckpoint 88: 
-----------------------------------
Train ACCURACY: 0.9261
Train Loss: 0.3981
ID Validation ACCURACY: 0.9340
ID Validation Loss: 0.3829
ID Test ACCURACY: 0.9290
ID Test Loss: 0.4065
OOD Validation ACCURACY: 0.8517
OOD Validation Loss: 0.6682
OOD Test ACCURACY: 0.6323
OOD Test Loss: 1.5601

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 96...
[0m[1;37mINFO[0m: [1mCheckpoint 96: 
-----------------------------------
Train ACCURACY: 0.9214
Train Loss: 0.4024
ID Validation ACCURACY: 0.9290
ID Validation Loss: 0.3868
ID Test ACCURACY: 0.9230
ID Test Loss: 0.4084
OOD Validation ACCURACY: 0.8967
OOD Validation Loss: 0.6143
OOD Test ACCURACY: 0.7087
OOD Test Loss: 1.0598

[0m[1;37mINFO[0m: [1mChartInfo 0.9290 0.6323 0.9230 0.7087 0.9290 0.8967[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.463
WIoU for r=0.3 = 0.395
F1 for r=0.6 = 0.502
WIoU for r=0.6 = 0.493
F1 for r=0.9 = 0.496
WIoU for r=0.9 = 0.526
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.532
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.364
WIoU for r=0.3 = 0.486
F1 for r=0.6 = 0.283
WIoU for r=0.6 = 0.499
F1 for r=0.9 = 0.247
WIoU for r=0.9 = 0.504
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.503
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.184
WIoU for r=0.3 = 0.257
F1 for r=0.6 = 0.143
WIoU for r=0.6 = 0.257
F1 for r=0.9 = 0.119
WIoU for r=0.9 = 0.256
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.256


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.446
Model XAI F1 of binarized graphs for r=0.3 =  0.46258375
Model XAI WIoU of binarized graphs for r=0.3 =  0.39512250000000004
len(reference) = 724
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.386
SUFF++ for r=0.3 class 0 = 0.612 +- 0.176 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 class 1 = 0.65 +- 0.176 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 class 2 = 0.627 +- 0.176 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 all KL = 0.743 +- 0.176 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.3 all L1 = 0.629 +- 0.136 (in-sample avg dev_std = 0.450)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.507
Model XAI F1 of binarized graphs for r=0.6 =  0.50191375
Model XAI WIoU of binarized graphs for r=0.6 =  0.49261250000000006
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.466
SUFF++ for r=0.6 class 0 = 0.711 +- 0.196 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 1 = 0.751 +- 0.196 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 2 = 0.726 +- 0.196 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all KL = 0.817 +- 0.196 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all L1 = 0.729 +- 0.162 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.676
Model XAI F1 of binarized graphs for r=0.9 =  0.49632875
Model XAI WIoU of binarized graphs for r=0.9 =  0.52634
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.695
SUFF++ for r=0.9 class 0 = 0.778 +- 0.168 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 class 1 = 0.853 +- 0.168 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 class 2 = 0.841 +- 0.168 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 all KL = 0.882 +- 0.168 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.153 (in-sample avg dev_std = 0.331)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  0.36402
Model XAI WIoU of binarized graphs for r=0.3 =  0.48607625
len(reference) = 794
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.559
SUFF++ for r=0.3 class 0 = 0.606 +- 0.133 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 1 = 0.632 +- 0.133 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 class 2 = 0.625 +- 0.133 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all KL = 0.767 +- 0.133 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.3 all L1 = 0.621 +- 0.106 (in-sample avg dev_std = 0.399)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  0.28275375
Model XAI WIoU of binarized graphs for r=0.6 =  0.4991675000000001
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.574
SUFF++ for r=0.6 class 0 = 0.689 +- 0.152 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.6 class 1 = 0.676 +- 0.152 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.6 class 2 = 0.687 +- 0.152 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.6 all KL = 0.807 +- 0.152 (in-sample avg dev_std = 0.363)
SUFF++ for r=0.6 all L1 = 0.684 +- 0.133 (in-sample avg dev_std = 0.363)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.669
Model XAI F1 of binarized graphs for r=0.9 =  0.24741749999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.5035912499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.67
SUFF++ for r=0.9 class 0 = 0.817 +- 0.129 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 1 = 0.833 +- 0.129 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 2 = 0.813 +- 0.129 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all KL = 0.907 +- 0.129 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.127 (in-sample avg dev_std = 0.278)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.461
Model XAI F1 of binarized graphs for r=0.3 =  0.184055
Model XAI WIoU of binarized graphs for r=0.3 =  0.25674625
len(reference) = 799
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.438
SUFF++ for r=0.3 class 0 = 0.576 +- 0.191 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 class 1 = 0.586 +- 0.191 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 class 2 = 0.563 +- 0.191 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 all KL = 0.578 +- 0.191 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 all L1 = 0.575 +- 0.110 (in-sample avg dev_std = 0.578)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.47
Model XAI F1 of binarized graphs for r=0.6 =  0.14279624999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.25693875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.44
SUFF++ for r=0.6 class 0 = 0.562 +- 0.275 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 1 = 0.547 +- 0.275 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 2 = 0.546 +- 0.275 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all KL = 0.557 +- 0.275 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all L1 = 0.552 +- 0.178 (in-sample avg dev_std = 0.492)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.505
Model XAI F1 of binarized graphs for r=0.9 =  0.11866125
Model XAI WIoU of binarized graphs for r=0.9 =  0.25629125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.483
SUFF++ for r=0.9 class 0 = 0.693 +- 0.238 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 1 = 0.723 +- 0.238 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 2 = 0.697 +- 0.238 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all KL = 0.764 +- 0.238 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all L1 = 0.705 +- 0.187 (in-sample avg dev_std = 0.334)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.429
Model XAI F1 of binarized graphs for r=0.3 =  0.46258375
Model XAI WIoU of binarized graphs for r=0.3 =  0.39512250000000004
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.34
NEC for r=0.3 class 0 = 0.34 +- 0.227 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 1 = 0.252 +- 0.227 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 2 = 0.349 +- 0.227 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all KL = 0.201 +- 0.227 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all L1 = 0.314 +- 0.202 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.507
Model XAI F1 of binarized graphs for r=0.6 =  0.50191375
Model XAI WIoU of binarized graphs for r=0.6 =  0.49261250000000006
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0 = 0.313 +- 0.228 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 1 = 0.25 +- 0.228 (in-sample avg dev_std = 0.364)
NEC for r=0.6 class 2 = 0.341 +- 0.228 (in-sample avg dev_std = 0.364)
NEC for r=0.6 all KL = 0.219 +- 0.228 (in-sample avg dev_std = 0.364)
NEC for r=0.6 all L1 = 0.302 +- 0.195 (in-sample avg dev_std = 0.364)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.676
Model XAI F1 of binarized graphs for r=0.9 =  0.49632875
Model XAI WIoU of binarized graphs for r=0.9 =  0.52634
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.476
NEC for r=0.9 class 0 = 0.437 +- 0.293 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 1 = 0.258 +- 0.293 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 2 = 0.468 +- 0.293 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all KL = 0.334 +- 0.293 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all L1 = 0.389 +- 0.230 (in-sample avg dev_std = 0.443)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.5317349999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.568 +- 0.350 (in-sample avg dev_std = 0.524)
NEC for r=1.0 class 1 = 0.221 +- 0.350 (in-sample avg dev_std = 0.524)
NEC for r=1.0 class 2 = 0.53 +- 0.350 (in-sample avg dev_std = 0.524)
NEC for r=1.0 all KL = 0.454 +- 0.350 (in-sample avg dev_std = 0.524)
NEC for r=1.0 all L1 = 0.443 +- 0.264 (in-sample avg dev_std = 0.524)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  0.36402
Model XAI WIoU of binarized graphs for r=0.3 =  0.48607625
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.41 +- 0.177 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 1 = 0.296 +- 0.177 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 2 = 0.43 +- 0.177 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all KL = 0.224 +- 0.177 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all L1 = 0.378 +- 0.177 (in-sample avg dev_std = 0.290)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  0.28275375
Model XAI WIoU of binarized graphs for r=0.6 =  0.4991675000000001
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.444
NEC for r=0.6 class 0 = 0.31 +- 0.153 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 1 = 0.261 +- 0.153 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 2 = 0.323 +- 0.153 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all KL = 0.157 +- 0.153 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all L1 = 0.298 +- 0.136 (in-sample avg dev_std = 0.282)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.669
Model XAI F1 of binarized graphs for r=0.9 =  0.24741749999999998
Model XAI WIoU of binarized graphs for r=0.9 =  0.5035912499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.495
NEC for r=0.9 class 0 = 0.304 +- 0.202 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 1 = 0.244 +- 0.202 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 2 = 0.339 +- 0.202 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all KL = 0.178 +- 0.202 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all L1 = 0.295 +- 0.163 (in-sample avg dev_std = 0.270)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.873
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.5034474999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.529
NEC for r=1.0 class 0 = 0.462 +- 0.305 (in-sample avg dev_std = 0.261)
NEC for r=1.0 class 1 = 0.23 +- 0.305 (in-sample avg dev_std = 0.261)
NEC for r=1.0 class 2 = 0.436 +- 0.305 (in-sample avg dev_std = 0.261)
NEC for r=1.0 all KL = 0.277 +- 0.305 (in-sample avg dev_std = 0.261)
NEC for r=1.0 all L1 = 0.376 +- 0.241 (in-sample avg dev_std = 0.261)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.184055
Model XAI WIoU of binarized graphs for r=0.3 =  0.25674625
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.339
NEC for r=0.3 class 0 = 0.241 +- 0.138 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 1 = 0.204 +- 0.138 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 2 = 0.234 +- 0.138 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all KL = 0.112 +- 0.138 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all L1 = 0.226 +- 0.175 (in-sample avg dev_std = 0.179)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.47
Model XAI F1 of binarized graphs for r=0.6 =  0.14279624999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.25693875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.357
NEC for r=0.6 class 0 = 0.348 +- 0.276 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 1 = 0.334 +- 0.276 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 2 = 0.381 +- 0.276 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all KL = 0.291 +- 0.276 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all L1 = 0.354 +- 0.219 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.505
Model XAI F1 of binarized graphs for r=0.9 =  0.11866125
Model XAI WIoU of binarized graphs for r=0.9 =  0.25629125
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.39
NEC for r=0.9 class 0 = 0.365 +- 0.309 (in-sample avg dev_std = 0.265)
NEC for r=0.9 class 1 = 0.319 +- 0.309 (in-sample avg dev_std = 0.265)
NEC for r=0.9 class 2 = 0.369 +- 0.309 (in-sample avg dev_std = 0.265)
NEC for r=0.9 all KL = 0.31 +- 0.309 (in-sample avg dev_std = 0.265)
NEC for r=0.9 all L1 = 0.35 +- 0.251 (in-sample avg dev_std = 0.265)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.625
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.25578
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.387
NEC for r=1.0 class 0 = 0.462 +- 0.296 (in-sample avg dev_std = 0.274)
NEC for r=1.0 class 1 = 0.458 +- 0.296 (in-sample avg dev_std = 0.274)
NEC for r=1.0 class 2 = 0.448 +- 0.296 (in-sample avg dev_std = 0.274)
NEC for r=1.0 all KL = 0.373 +- 0.296 (in-sample avg dev_std = 0.274)
NEC for r=1.0 all L1 = 0.456 +- 0.251 (in-sample avg dev_std = 0.274)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 20:37:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:36 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:44 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:37:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.8608
Train Loss: 0.6424
ID Validation ACCURACY: 0.8730
ID Validation Loss: 0.6027
ID Test ACCURACY: 0.8603
ID Test Loss: 0.6261
OOD Validation ACCURACY: 0.7577
OOD Validation Loss: 2.8104
OOD Test ACCURACY: 0.3357
OOD Test Loss: 25.5783

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 69...
[0m[1;37mINFO[0m: [1mCheckpoint 69: 
-----------------------------------
Train ACCURACY: 0.8049
Train Loss: 1.0751
ID Validation ACCURACY: 0.8090
ID Validation Loss: 1.0838
ID Test ACCURACY: 0.8037
ID Test Loss: 1.0621
OOD Validation ACCURACY: 0.8020
OOD Validation Loss: 4.9580
OOD Test ACCURACY: 0.3227
OOD Test Loss: 24.0481

[0m[1;37mINFO[0m: [1mChartInfo 0.8603 0.3357 0.8037 0.3227 0.8090 0.8020[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.652
WIoU for r=0.3 = 0.554
F1 for r=0.6 = 0.646
WIoU for r=0.6 = 0.647
F1 for r=0.9 = 0.523
WIoU for r=0.9 = 0.616
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.611
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.454
WIoU for r=0.3 = 0.539
F1 for r=0.6 = 0.333
WIoU for r=0.6 = 0.515
F1 for r=0.9 = 0.257
WIoU for r=0.9 = 0.497
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.493
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.213
WIoU for r=0.3 = 0.165
F1 for r=0.6 = 0.151
WIoU for r=0.6 = 0.113
F1 for r=0.9 = 0.119
WIoU for r=0.9 = 0.095
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.092


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.495
Model XAI F1 of binarized graphs for r=0.3 =  0.6522199999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5535275
len(reference) = 788
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.404
SUFF++ for r=0.3 class 0 = 0.676 +- 0.254 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 1 = 0.8 +- 0.254 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 2 = 0.686 +- 0.254 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all KL = 0.774 +- 0.254 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all L1 = 0.72 +- 0.189 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  0.64599875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6469799999999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.613 +- 0.274 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 1 = 0.85 +- 0.274 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 2 = 0.681 +- 0.274 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all KL = 0.727 +- 0.274 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all L1 = 0.712 +- 0.215 (in-sample avg dev_std = 0.455)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  0.5233275
Model XAI WIoU of binarized graphs for r=0.9 =  0.6158625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.815
SUFF++ for r=0.9 class 0 = 0.823 +- 0.148 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 1 = 0.848 +- 0.148 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.148 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all KL = 0.914 +- 0.148 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all L1 = 0.848 +- 0.161 (in-sample avg dev_std = 0.210)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.45441249999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.53943875
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.571
SUFF++ for r=0.3 class 0 = 0.633 +- 0.168 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 1 = 0.716 +- 0.168 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 2 = 0.632 +- 0.168 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all KL = 0.78 +- 0.168 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.159 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  0.33286
Model XAI WIoU of binarized graphs for r=0.6 =  0.51536125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.65
SUFF++ for r=0.6 class 0 = 0.564 +- 0.201 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1 = 0.678 +- 0.201 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 2 = 0.597 +- 0.201 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.707 +- 0.201 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.613 +- 0.183 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.738
Model XAI F1 of binarized graphs for r=0.9 =  0.25704499999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.49657874999999996
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.704
SUFF++ for r=0.9 class 0 = 0.754 +- 0.140 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.82 +- 0.140 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.811 +- 0.140 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.888 +- 0.140 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.795 +- 0.188 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.21339875000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.16486
len(reference) = 798
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.425
SUFF++ for r=0.3 class 0 = 0.578 +- 0.255 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 1 = 0.594 +- 0.255 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 2 = 0.626 +- 0.255 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all KL = 0.684 +- 0.255 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.156 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.405
Model XAI F1 of binarized graphs for r=0.6 =  0.151155
Model XAI WIoU of binarized graphs for r=0.6 =  0.11327375
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.389
SUFF++ for r=0.6 class 0 = 0.628 +- 0.250 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 class 1 = 0.595 +- 0.250 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 class 2 = 0.664 +- 0.250 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all KL = 0.671 +- 0.250 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all L1 = 0.628 +- 0.142 (in-sample avg dev_std = 0.381)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.33
Model XAI F1 of binarized graphs for r=0.9 =  0.11932625
Model XAI WIoU of binarized graphs for r=0.9 =  0.09509375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.386
SUFF++ for r=0.9 class 0 = 0.821 +- 0.307 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.816 +- 0.307 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.857 +- 0.307 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.758 +- 0.307 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.144 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.488
Model XAI F1 of binarized graphs for r=0.3 =  0.6522199999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5535275
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.362 +- 0.308 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 1 = 0.232 +- 0.308 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 2 = 0.373 +- 0.308 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all KL = 0.266 +- 0.308 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all L1 = 0.324 +- 0.237 (in-sample avg dev_std = 0.267)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  0.64599875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6469799999999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.46
NEC for r=0.6 class 0 = 0.546 +- 0.310 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 1 = 0.342 +- 0.310 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 2 = 0.592 +- 0.310 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all KL = 0.521 +- 0.310 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all L1 = 0.496 +- 0.227 (in-sample avg dev_std = 0.521)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  0.5233275
Model XAI WIoU of binarized graphs for r=0.9 =  0.6158625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.534 +- 0.287 (in-sample avg dev_std = 0.510)
NEC for r=0.9 class 1 = 0.367 +- 0.287 (in-sample avg dev_std = 0.510)
NEC for r=0.9 class 2 = 0.516 +- 0.287 (in-sample avg dev_std = 0.510)
NEC for r=0.9 all KL = 0.454 +- 0.287 (in-sample avg dev_std = 0.510)
NEC for r=0.9 all L1 = 0.474 +- 0.204 (in-sample avg dev_std = 0.510)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.6113525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.535 +- 0.280 (in-sample avg dev_std = 0.491)
NEC for r=1.0 class 1 = 0.352 +- 0.280 (in-sample avg dev_std = 0.491)
NEC for r=1.0 class 2 = 0.534 +- 0.280 (in-sample avg dev_std = 0.491)
NEC for r=1.0 all KL = 0.427 +- 0.280 (in-sample avg dev_std = 0.491)
NEC for r=1.0 all L1 = 0.475 +- 0.197 (in-sample avg dev_std = 0.491)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.45441249999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.53943875
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.368
NEC for r=0.3 class 0 = 0.445 +- 0.246 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 1 = 0.344 +- 0.246 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 2 = 0.483 +- 0.246 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all KL = 0.316 +- 0.246 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all L1 = 0.423 +- 0.195 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  0.33286
Model XAI WIoU of binarized graphs for r=0.6 =  0.51536125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.47
NEC for r=0.6 class 0 = 0.41 +- 0.276 (in-sample avg dev_std = 0.448)
NEC for r=0.6 class 1 = 0.354 +- 0.276 (in-sample avg dev_std = 0.448)
NEC for r=0.6 class 2 = 0.475 +- 0.276 (in-sample avg dev_std = 0.448)
NEC for r=0.6 all KL = 0.348 +- 0.276 (in-sample avg dev_std = 0.448)
NEC for r=0.6 all L1 = 0.412 +- 0.193 (in-sample avg dev_std = 0.448)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.738
Model XAI F1 of binarized graphs for r=0.9 =  0.25704499999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.49657874999999996
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.502
NEC for r=0.9 class 0 = 0.344 +- 0.285 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 1 = 0.256 +- 0.285 (in-sample avg dev_std = 0.385)
NEC for r=0.9 class 2 = 0.344 +- 0.285 (in-sample avg dev_std = 0.385)
NEC for r=0.9 all KL = 0.247 +- 0.285 (in-sample avg dev_std = 0.385)
NEC for r=0.9 all L1 = 0.314 +- 0.233 (in-sample avg dev_std = 0.385)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.786
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.492705
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.514
NEC for r=1.0 class 0 = 0.37 +- 0.290 (in-sample avg dev_std = 0.383)
NEC for r=1.0 class 1 = 0.253 +- 0.290 (in-sample avg dev_std = 0.383)
NEC for r=1.0 class 2 = 0.366 +- 0.290 (in-sample avg dev_std = 0.383)
NEC for r=1.0 all KL = 0.259 +- 0.290 (in-sample avg dev_std = 0.383)
NEC for r=1.0 all L1 = 0.329 +- 0.242 (in-sample avg dev_std = 0.383)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.21339875000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.16486
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.436 +- 0.263 (in-sample avg dev_std = 0.273)
NEC for r=0.3 class 1 = 0.419 +- 0.263 (in-sample avg dev_std = 0.273)
NEC for r=0.3 class 2 = 0.42 +- 0.263 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all KL = 0.32 +- 0.263 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all L1 = 0.425 +- 0.199 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.406
Model XAI F1 of binarized graphs for r=0.6 =  0.151155
Model XAI WIoU of binarized graphs for r=0.6 =  0.11327375
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.377
NEC for r=0.6 class 0 = 0.452 +- 0.292 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 1 = 0.466 +- 0.292 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 2 = 0.438 +- 0.292 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all KL = 0.407 +- 0.292 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all L1 = 0.453 +- 0.196 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.33
Model XAI F1 of binarized graphs for r=0.9 =  0.11932625
Model XAI WIoU of binarized graphs for r=0.9 =  0.09509375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.396
NEC for r=0.9 class 0 = 0.345 +- 0.375 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 1 = 0.319 +- 0.375 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 2 = 0.288 +- 0.375 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all KL = 0.387 +- 0.375 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all L1 = 0.318 +- 0.239 (in-sample avg dev_std = 0.270)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.33
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.09164874999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.391
NEC for r=1.0 class 0 = 0.378 +- 0.387 (in-sample avg dev_std = 0.278)
NEC for r=1.0 class 1 = 0.36 +- 0.387 (in-sample avg dev_std = 0.278)
NEC for r=1.0 class 2 = 0.342 +- 0.387 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all KL = 0.473 +- 0.387 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all L1 = 0.361 +- 0.290 (in-sample avg dev_std = 0.278)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 20:43:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 08:43:50 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:09 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:44:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.8512
Train Loss: 0.8087
ID Validation ACCURACY: 0.8677
ID Validation Loss: 0.7474
ID Test ACCURACY: 0.8560
ID Test Loss: 0.7724
OOD Validation ACCURACY: 0.8517
OOD Validation Loss: 3.1122
OOD Test ACCURACY: 0.5443
OOD Test Loss: 10.9092

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.8512
Train Loss: 0.8087
ID Validation ACCURACY: 0.8677
ID Validation Loss: 0.7474
ID Test ACCURACY: 0.8560
ID Test Loss: 0.7724
OOD Validation ACCURACY: 0.8517
OOD Validation Loss: 3.1122
OOD Test ACCURACY: 0.5443
OOD Test Loss: 10.9092

[0m[1;37mINFO[0m: [1mChartInfo 0.8560 0.5443 0.8560 0.5443 0.8677 0.8517[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.592
WIoU for r=0.3 = 0.504
F1 for r=0.6 = 0.618
WIoU for r=0.6 = 0.610
F1 for r=0.9 = 0.522
WIoU for r=0.9 = 0.595
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.591
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.458
WIoU for r=0.3 = 0.530
F1 for r=0.6 = 0.322
WIoU for r=0.6 = 0.498
F1 for r=0.9 = 0.255
WIoU for r=0.9 = 0.494
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.492
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.250
WIoU for r=0.3 = 0.295
F1 for r=0.6 = 0.156
WIoU for r=0.6 = 0.245
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.237
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.235


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  0.59181
Model XAI WIoU of binarized graphs for r=0.3 =  0.50385875
len(reference) = 783
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.435
SUFF++ for r=0.3 class 0 = 0.563 +- 0.198 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 1 = 0.589 +- 0.198 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 2 = 0.572 +- 0.198 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all KL = 0.644 +- 0.198 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all L1 = 0.574 +- 0.138 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.6177375
Model XAI WIoU of binarized graphs for r=0.6 =  0.60975625
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.595 +- 0.293 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 1 = 0.72 +- 0.293 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 2 = 0.658 +- 0.293 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all KL = 0.638 +- 0.293 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all L1 = 0.657 +- 0.212 (in-sample avg dev_std = 0.518)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.837
Model XAI F1 of binarized graphs for r=0.9 =  0.5223774999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5954125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0 = 0.824 +- 0.179 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1 = 0.821 +- 0.179 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.179 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.9 +- 0.179 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.183 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.691
Model XAI F1 of binarized graphs for r=0.3 =  0.45824000000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.53027625
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.623
SUFF++ for r=0.3 class 0 = 0.558 +- 0.234 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.3 class 1 = 0.619 +- 0.234 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.3 class 2 = 0.605 +- 0.234 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.3 all KL = 0.626 +- 0.234 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.3 all L1 = 0.594 +- 0.187 (in-sample avg dev_std = 0.496)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  0.3223375
Model XAI WIoU of binarized graphs for r=0.6 =  0.49806625000000004
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0 = 0.565 +- 0.262 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 class 1 = 0.592 +- 0.262 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 class 2 = 0.654 +- 0.262 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 all KL = 0.621 +- 0.262 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 all L1 = 0.603 +- 0.202 (in-sample avg dev_std = 0.522)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.781
Model XAI F1 of binarized graphs for r=0.9 =  0.2549375
Model XAI WIoU of binarized graphs for r=0.9 =  0.49390625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.77
SUFF++ for r=0.9 class 0 = 0.802 +- 0.148 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.813 +- 0.148 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.84 +- 0.148 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.902 +- 0.148 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.160 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  0.2496725
Model XAI WIoU of binarized graphs for r=0.3 =  0.2949525
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.493
SUFF++ for r=0.3 class 0 = 0.566 +- 0.272 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 class 1 = 0.635 +- 0.272 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 class 2 = 0.704 +- 0.272 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 all KL = 0.562 +- 0.272 (in-sample avg dev_std = 0.581)
SUFF++ for r=0.3 all L1 = 0.633 +- 0.216 (in-sample avg dev_std = 0.581)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  0.1561525
Model XAI WIoU of binarized graphs for r=0.6 =  0.245015
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.479
SUFF++ for r=0.6 class 0 = 0.665 +- 0.292 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 1 = 0.688 +- 0.292 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 class 2 = 0.76 +- 0.292 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all KL = 0.702 +- 0.292 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.6 all L1 = 0.703 +- 0.261 (in-sample avg dev_std = 0.401)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.526
Model XAI F1 of binarized graphs for r=0.9 =  0.12054625
Model XAI WIoU of binarized graphs for r=0.9 =  0.23652625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.518
SUFF++ for r=0.9 class 0 = 0.755 +- 0.162 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 1 = 0.776 +- 0.162 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 2 = 0.814 +- 0.162 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all KL = 0.848 +- 0.162 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all L1 = 0.781 +- 0.189 (in-sample avg dev_std = 0.284)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  0.59181
Model XAI WIoU of binarized graphs for r=0.3 =  0.50385875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.32
NEC for r=0.3 class 0 = 0.496 +- 0.295 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 1 = 0.433 +- 0.295 (in-sample avg dev_std = 0.401)
NEC for r=0.3 class 2 = 0.503 +- 0.295 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all KL = 0.405 +- 0.295 (in-sample avg dev_std = 0.401)
NEC for r=0.3 all L1 = 0.478 +- 0.199 (in-sample avg dev_std = 0.401)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.6177375
Model XAI WIoU of binarized graphs for r=0.6 =  0.60975625
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.407
NEC for r=0.6 class 0 = 0.541 +- 0.295 (in-sample avg dev_std = 0.537)
NEC for r=0.6 class 1 = 0.463 +- 0.295 (in-sample avg dev_std = 0.537)
NEC for r=0.6 class 2 = 0.591 +- 0.295 (in-sample avg dev_std = 0.537)
NEC for r=0.6 all KL = 0.581 +- 0.295 (in-sample avg dev_std = 0.537)
NEC for r=0.6 all L1 = 0.533 +- 0.203 (in-sample avg dev_std = 0.537)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.837
Model XAI F1 of binarized graphs for r=0.9 =  0.5223774999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5954125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.498
NEC for r=0.9 class 0 = 0.535 +- 0.290 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 1 = 0.431 +- 0.290 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 2 = 0.545 +- 0.290 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all KL = 0.472 +- 0.290 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all L1 = 0.505 +- 0.187 (in-sample avg dev_std = 0.499)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.858
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.5909774999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.519
NEC for r=1.0 class 0 = 0.514 +- 0.275 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 1 = 0.413 +- 0.275 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 2 = 0.523 +- 0.275 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all KL = 0.437 +- 0.275 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all L1 = 0.484 +- 0.183 (in-sample avg dev_std = 0.484)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.69
Model XAI F1 of binarized graphs for r=0.3 =  0.45824000000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.53027625
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.372
NEC for r=0.3 class 0 = 0.528 +- 0.284 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1 = 0.476 +- 0.284 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 2 = 0.554 +- 0.284 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.469 +- 0.284 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.519 +- 0.230 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  0.3223375
Model XAI WIoU of binarized graphs for r=0.6 =  0.49806625000000004
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.487
NEC for r=0.6 class 0 = 0.481 +- 0.334 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 1 = 0.432 +- 0.334 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 2 = 0.493 +- 0.334 (in-sample avg dev_std = 0.346)
NEC for r=0.6 all KL = 0.411 +- 0.334 (in-sample avg dev_std = 0.346)
NEC for r=0.6 all L1 = 0.468 +- 0.229 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.781
Model XAI F1 of binarized graphs for r=0.9 =  0.2549375
Model XAI WIoU of binarized graphs for r=0.9 =  0.49390625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.546
NEC for r=0.9 class 0 = 0.408 +- 0.259 (in-sample avg dev_std = 0.343)
NEC for r=0.9 class 1 = 0.31 +- 0.259 (in-sample avg dev_std = 0.343)
NEC for r=0.9 class 2 = 0.413 +- 0.259 (in-sample avg dev_std = 0.343)
NEC for r=0.9 all KL = 0.275 +- 0.259 (in-sample avg dev_std = 0.343)
NEC for r=0.9 all L1 = 0.377 +- 0.198 (in-sample avg dev_std = 0.343)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.49248375000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.558
NEC for r=1.0 class 0 = 0.478 +- 0.284 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 1 = 0.33 +- 0.284 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 2 = 0.425 +- 0.284 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all KL = 0.298 +- 0.284 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all L1 = 0.411 +- 0.221 (in-sample avg dev_std = 0.337)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  0.2496725
Model XAI WIoU of binarized graphs for r=0.3 =  0.2949525
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.361 +- 0.329 (in-sample avg dev_std = 0.366)
NEC for r=0.3 class 1 = 0.313 +- 0.329 (in-sample avg dev_std = 0.366)
NEC for r=0.3 class 2 = 0.33 +- 0.329 (in-sample avg dev_std = 0.366)
NEC for r=0.3 all KL = 0.346 +- 0.329 (in-sample avg dev_std = 0.366)
NEC for r=0.3 all L1 = 0.335 +- 0.284 (in-sample avg dev_std = 0.366)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.545
Model XAI F1 of binarized graphs for r=0.6 =  0.1561525
Model XAI WIoU of binarized graphs for r=0.6 =  0.245015
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.422
NEC for r=0.6 class 0 = 0.368 +- 0.350 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 1 = 0.273 +- 0.350 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 2 = 0.327 +- 0.350 (in-sample avg dev_std = 0.371)
NEC for r=0.6 all KL = 0.366 +- 0.350 (in-sample avg dev_std = 0.371)
NEC for r=0.6 all L1 = 0.322 +- 0.259 (in-sample avg dev_std = 0.371)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.526
Model XAI F1 of binarized graphs for r=0.9 =  0.12054625
Model XAI WIoU of binarized graphs for r=0.9 =  0.23652625
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.462
NEC for r=0.9 class 0 = 0.329 +- 0.288 (in-sample avg dev_std = 0.271)
NEC for r=0.9 class 1 = 0.263 +- 0.288 (in-sample avg dev_std = 0.271)
NEC for r=0.9 class 2 = 0.267 +- 0.288 (in-sample avg dev_std = 0.271)
NEC for r=0.9 all KL = 0.239 +- 0.288 (in-sample avg dev_std = 0.271)
NEC for r=0.9 all L1 = 0.286 +- 0.257 (in-sample avg dev_std = 0.271)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.525
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.234915
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.463
NEC for r=1.0 class 0 = 0.398 +- 0.277 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 1 = 0.244 +- 0.277 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 2 = 0.287 +- 0.277 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all KL = 0.253 +- 0.277 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all L1 = 0.31 +- 0.247 (in-sample avg dev_std = 0.249)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 20:50:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:23 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:25 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:27 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:30 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:36 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:36 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:50:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 96...
[0m[1;37mINFO[0m: [1mCheckpoint 96: 
-----------------------------------
Train ACCURACY: 0.9269
Train Loss: 0.4147
ID Validation ACCURACY: 0.9340
ID Validation Loss: 0.4035
ID Test ACCURACY: 0.9293
ID Test Loss: 0.4161
OOD Validation ACCURACY: 0.9037
OOD Validation Loss: 0.6125
OOD Test ACCURACY: 0.6287
OOD Test Loss: 1.7378

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 76...
[0m[1;37mINFO[0m: [1mCheckpoint 76: 
-----------------------------------
Train ACCURACY: 0.9249
Train Loss: 0.4031
ID Validation ACCURACY: 0.9330
ID Validation Loss: 0.3920
ID Test ACCURACY: 0.9273
ID Test Loss: 0.4070
OOD Validation ACCURACY: 0.9103
OOD Validation Loss: 0.5791
OOD Test ACCURACY: 0.7027
OOD Test Loss: 0.8664

[0m[1;37mINFO[0m: [1mChartInfo 0.9293 0.6287 0.9273 0.7027 0.9330 0.9103[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.574
WIoU for r=0.3 = 0.506
F1 for r=0.6 = 0.608
WIoU for r=0.6 = 0.645
F1 for r=0.9 = 0.515
WIoU for r=0.9 = 0.635
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.636
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.417
WIoU for r=0.3 = 0.531
F1 for r=0.6 = 0.322
WIoU for r=0.6 = 0.535
F1 for r=0.9 = 0.256
WIoU for r=0.9 = 0.527
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.526
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.208
WIoU for r=0.3 = 0.389
F1 for r=0.6 = 0.156
WIoU for r=0.6 = 0.356
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.328
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.321


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.454
Model XAI F1 of binarized graphs for r=0.3 =  0.57435125
Model XAI WIoU of binarized graphs for r=0.3 =  0.50566375
len(reference) = 786
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.4
SUFF++ for r=0.3 class 0 = 0.613 +- 0.224 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 1 = 0.627 +- 0.224 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 2 = 0.599 +- 0.224 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all KL = 0.702 +- 0.224 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all L1 = 0.613 +- 0.170 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.60781625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6449575
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0 = 0.659 +- 0.247 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 1 = 0.773 +- 0.247 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 class 2 = 0.649 +- 0.247 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all KL = 0.749 +- 0.247 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.6 all L1 = 0.692 +- 0.200 (in-sample avg dev_std = 0.421)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  0.51542875
Model XAI WIoU of binarized graphs for r=0.9 =  0.63503
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.811
SUFF++ for r=0.9 class 0 = 0.843 +- 0.145 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 1 = 0.856 +- 0.145 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.145 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all KL = 0.924 +- 0.145 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all L1 = 0.856 +- 0.154 (in-sample avg dev_std = 0.231)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.417085
Model XAI WIoU of binarized graphs for r=0.3 =  0.53073
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.551
SUFF++ for r=0.3 class 0 = 0.662 +- 0.150 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 1 = 0.695 +- 0.150 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 2 = 0.673 +- 0.150 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all KL = 0.814 +- 0.150 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all L1 = 0.677 +- 0.135 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.716
Model XAI F1 of binarized graphs for r=0.6 =  0.3222150000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.534915
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.623
SUFF++ for r=0.6 class 0 = 0.705 +- 0.199 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 1 = 0.787 +- 0.199 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 class 2 = 0.711 +- 0.199 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all KL = 0.836 +- 0.199 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.6 all L1 = 0.734 +- 0.160 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  0.25568
Model XAI WIoU of binarized graphs for r=0.9 =  0.5267025000000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.797
SUFF++ for r=0.9 class 0 = 0.839 +- 0.102 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.102 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.102 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 all KL = 0.942 +- 0.102 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 all L1 = 0.858 +- 0.108 (in-sample avg dev_std = 0.209)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.20774125000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.38934874999999997
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.505
SUFF++ for r=0.3 class 0 = 0.686 +- 0.098 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.3 class 1 = 0.711 +- 0.098 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.3 class 2 = 0.683 +- 0.098 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.3 all KL = 0.835 +- 0.098 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.3 all L1 = 0.694 +- 0.095 (in-sample avg dev_std = 0.356)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.598
Model XAI F1 of binarized graphs for r=0.6 =  0.155895
Model XAI WIoU of binarized graphs for r=0.6 =  0.35561750000000003
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.508
SUFF++ for r=0.6 class 0 = 0.724 +- 0.144 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 class 1 = 0.756 +- 0.144 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 class 2 = 0.722 +- 0.144 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all KL = 0.854 +- 0.144 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all L1 = 0.734 +- 0.148 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.649
Model XAI F1 of binarized graphs for r=0.9 =  0.12115625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.32804375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.631
SUFF++ for r=0.9 class 0 = 0.795 +- 0.152 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 1 = 0.825 +- 0.152 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 2 = 0.778 +- 0.152 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all KL = 0.874 +- 0.152 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all L1 = 0.8 +- 0.149 (in-sample avg dev_std = 0.300)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.451
Model XAI F1 of binarized graphs for r=0.3 =  0.57435125
Model XAI WIoU of binarized graphs for r=0.3 =  0.50566375
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.438 +- 0.274 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 1 = 0.412 +- 0.274 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 2 = 0.455 +- 0.274 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all KL = 0.346 +- 0.274 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all L1 = 0.435 +- 0.215 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.60781625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6449575
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.408
NEC for r=0.6 class 0 = 0.464 +- 0.331 (in-sample avg dev_std = 0.425)
NEC for r=0.6 class 1 = 0.32 +- 0.331 (in-sample avg dev_std = 0.425)
NEC for r=0.6 class 2 = 0.488 +- 0.331 (in-sample avg dev_std = 0.425)
NEC for r=0.6 all KL = 0.397 +- 0.331 (in-sample avg dev_std = 0.425)
NEC for r=0.6 all L1 = 0.425 +- 0.251 (in-sample avg dev_std = 0.425)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  0.51542875
Model XAI WIoU of binarized graphs for r=0.9 =  0.63503
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.509
NEC for r=0.9 class 0 = 0.512 +- 0.288 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 1 = 0.366 +- 0.288 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 2 = 0.524 +- 0.288 (in-sample avg dev_std = 0.476)
NEC for r=0.9 all KL = 0.417 +- 0.288 (in-sample avg dev_std = 0.476)
NEC for r=0.9 all L1 = 0.469 +- 0.199 (in-sample avg dev_std = 0.476)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.6364425
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.548
NEC for r=1.0 class 0 = 0.523 +- 0.294 (in-sample avg dev_std = 0.503)
NEC for r=1.0 class 1 = 0.34 +- 0.294 (in-sample avg dev_std = 0.503)
NEC for r=1.0 class 2 = 0.524 +- 0.294 (in-sample avg dev_std = 0.503)
NEC for r=1.0 all KL = 0.432 +- 0.294 (in-sample avg dev_std = 0.503)
NEC for r=1.0 all L1 = 0.464 +- 0.201 (in-sample avg dev_std = 0.503)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.417085
Model XAI WIoU of binarized graphs for r=0.3 =  0.53073
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.353
NEC for r=0.3 class 0 = 0.442 +- 0.194 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 1 = 0.395 +- 0.194 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 2 = 0.46 +- 0.194 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all KL = 0.291 +- 0.194 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all L1 = 0.432 +- 0.178 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.716
Model XAI F1 of binarized graphs for r=0.6 =  0.3222150000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.534915
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.453
NEC for r=0.6 class 0 = 0.358 +- 0.266 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 1 = 0.267 +- 0.266 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 2 = 0.401 +- 0.266 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all KL = 0.219 +- 0.266 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all L1 = 0.341 +- 0.196 (in-sample avg dev_std = 0.270)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  0.25568
Model XAI WIoU of binarized graphs for r=0.9 =  0.5267025000000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.518
NEC for r=0.9 class 0 = 0.381 +- 0.278 (in-sample avg dev_std = 0.312)
NEC for r=0.9 class 1 = 0.266 +- 0.278 (in-sample avg dev_std = 0.312)
NEC for r=0.9 class 2 = 0.418 +- 0.278 (in-sample avg dev_std = 0.312)
NEC for r=0.9 all KL = 0.244 +- 0.278 (in-sample avg dev_std = 0.312)
NEC for r=0.9 all L1 = 0.354 +- 0.199 (in-sample avg dev_std = 0.312)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.5257799999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.559
NEC for r=1.0 class 0 = 0.46 +- 0.304 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 1 = 0.269 +- 0.304 (in-sample avg dev_std = 0.362)
NEC for r=1.0 class 2 = 0.453 +- 0.304 (in-sample avg dev_std = 0.362)
NEC for r=1.0 all KL = 0.312 +- 0.304 (in-sample avg dev_std = 0.362)
NEC for r=1.0 all L1 = 0.394 +- 0.225 (in-sample avg dev_std = 0.362)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.20774125000000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.38934874999999997
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.381
NEC for r=0.3 class 0 = 0.365 +- 0.173 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 1 = 0.277 +- 0.173 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 2 = 0.358 +- 0.173 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all KL = 0.17 +- 0.173 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all L1 = 0.333 +- 0.153 (in-sample avg dev_std = 0.242)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.598
Model XAI F1 of binarized graphs for r=0.6 =  0.155895
Model XAI WIoU of binarized graphs for r=0.6 =  0.35561750000000003
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.425
NEC for r=0.6 class 0 = 0.291 +- 0.196 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 1 = 0.221 +- 0.196 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 2 = 0.296 +- 0.196 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all KL = 0.147 +- 0.196 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all L1 = 0.269 +- 0.182 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.65
Model XAI F1 of binarized graphs for r=0.9 =  0.12115625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.32804375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.467
NEC for r=0.9 class 0 = 0.325 +- 0.229 (in-sample avg dev_std = 0.223)
NEC for r=0.9 class 1 = 0.249 +- 0.229 (in-sample avg dev_std = 0.223)
NEC for r=0.9 class 2 = 0.335 +- 0.229 (in-sample avg dev_std = 0.223)
NEC for r=0.9 all KL = 0.193 +- 0.229 (in-sample avg dev_std = 0.223)
NEC for r=0.9 all L1 = 0.302 +- 0.209 (in-sample avg dev_std = 0.223)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.613
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.32111874999999995
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.466
NEC for r=1.0 class 0 = 0.451 +- 0.374 (in-sample avg dev_std = 0.263)
NEC for r=1.0 class 1 = 0.344 +- 0.374 (in-sample avg dev_std = 0.263)
NEC for r=1.0 class 2 = 0.471 +- 0.374 (in-sample avg dev_std = 0.263)
NEC for r=1.0 all KL = 0.351 +- 0.374 (in-sample avg dev_std = 0.263)
NEC for r=1.0 all L1 = 0.421 +- 0.284 (in-sample avg dev_std = 0.263)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 20:56:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:30 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:41 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:43 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:45 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:48 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/07/2024 08:56:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ACCURACY: 0.8779
Train Loss: 0.4536
ID Validation ACCURACY: 0.8817
ID Validation Loss: 0.4380
ID Test ACCURACY: 0.8783
ID Test Loss: 0.4717
OOD Validation ACCURACY: 0.7770
OOD Validation Loss: 0.8594
OOD Test ACCURACY: 0.5180
OOD Test Loss: 9.7886

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ACCURACY: 0.8536
Train Loss: 0.9450
ID Validation ACCURACY: 0.8677
ID Validation Loss: 0.8652
ID Test ACCURACY: 0.8547
ID Test Loss: 0.9125
OOD Validation ACCURACY: 0.8193
OOD Validation Loss: 3.8423
OOD Test ACCURACY: 0.6583
OOD Test Loss: 12.0829

[0m[1;37mINFO[0m: [1mChartInfo 0.8783 0.5180 0.8547 0.6583 0.8677 0.8193[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.646
WIoU for r=0.3 = 0.520
F1 for r=0.6 = 0.634
WIoU for r=0.6 = 0.561
F1 for r=0.9 = 0.521
WIoU for r=0.9 = 0.531
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.526
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.497
WIoU for r=0.3 = 0.420
F1 for r=0.6 = 0.332
WIoU for r=0.6 = 0.295
F1 for r=0.9 = 0.255
WIoU for r=0.9 = 0.252
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.244
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.269
WIoU for r=0.3 = 0.307
F1 for r=0.6 = 0.162
WIoU for r=0.6 = 0.264
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.254
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.253


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  0.645805
Model XAI WIoU of binarized graphs for r=0.3 =  0.5201475000000001
len(reference) = 779
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.403
SUFF++ for r=0.3 class 0 = 0.634 +- 0.257 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 class 1 = 0.683 +- 0.257 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 class 2 = 0.589 +- 0.257 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 all KL = 0.701 +- 0.257 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.3 all L1 = 0.635 +- 0.170 (in-sample avg dev_std = 0.392)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  0.634105
Model XAI WIoU of binarized graphs for r=0.6 =  0.56108375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.586 +- 0.313 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 class 1 = 0.761 +- 0.313 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 class 2 = 0.696 +- 0.313 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 all KL = 0.65 +- 0.313 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 all L1 = 0.68 +- 0.235 (in-sample avg dev_std = 0.485)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  0.5209762499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.53053375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.762
SUFF++ for r=0.9 class 0 = 0.722 +- 0.263 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 class 1 = 0.8 +- 0.263 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 class 2 = 0.857 +- 0.263 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 all KL = 0.827 +- 0.263 (in-sample avg dev_std = 0.290)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.235 (in-sample avg dev_std = 0.290)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  0.496935
Model XAI WIoU of binarized graphs for r=0.3 =  0.42042124999999997
len(reference) = 799
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.545
SUFF++ for r=0.3 class 0 = 0.66 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 class 1 = 0.733 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 class 2 = 0.614 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 all KL = 0.716 +- 0.265 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 all L1 = 0.67 +- 0.207 (in-sample avg dev_std = 0.375)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.702
Model XAI F1 of binarized graphs for r=0.6 =  0.331505
Model XAI WIoU of binarized graphs for r=0.6 =  0.29499125000000004
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0 = 0.544 +- 0.317 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 1 = 0.634 +- 0.317 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 2 = 0.698 +- 0.317 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all KL = 0.617 +- 0.317 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all L1 = 0.624 +- 0.210 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  0.25453000000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.25223
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.609
SUFF++ for r=0.9 class 0 = 0.601 +- 0.324 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.9 class 1 = 0.703 +- 0.324 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.9 class 2 = 0.806 +- 0.324 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.9 all KL = 0.725 +- 0.324 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.9 all L1 = 0.702 +- 0.261 (in-sample avg dev_std = 0.360)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.2689125
Model XAI WIoU of binarized graphs for r=0.3 =  0.30749375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.465
SUFF++ for r=0.3 class 0 = 0.565 +- 0.268 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 class 1 = 0.576 +- 0.268 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.268 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 all KL = 0.606 +- 0.268 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 all L1 = 0.584 +- 0.154 (in-sample avg dev_std = 0.466)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.464
Model XAI F1 of binarized graphs for r=0.6 =  0.1623925
Model XAI WIoU of binarized graphs for r=0.6 =  0.2644925
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.446
SUFF++ for r=0.6 class 0 = 0.685 +- 0.213 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 1 = 0.719 +- 0.213 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 2 = 0.746 +- 0.213 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all KL = 0.721 +- 0.213 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all L1 = 0.716 +- 0.170 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.491
Model XAI F1 of binarized graphs for r=0.9 =  0.12121125
Model XAI WIoU of binarized graphs for r=0.9 =  0.2540575
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.453
SUFF++ for r=0.9 class 0 = 0.758 +- 0.254 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 1 = 0.794 +- 0.254 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 class 2 = 0.822 +- 0.254 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all KL = 0.826 +- 0.254 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.9 all L1 = 0.791 +- 0.238 (in-sample avg dev_std = 0.258)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  0.645805
Model XAI WIoU of binarized graphs for r=0.3 =  0.5201475000000001
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.41 +- 0.313 (in-sample avg dev_std = 0.327)
NEC for r=0.3 class 1 = 0.362 +- 0.313 (in-sample avg dev_std = 0.327)
NEC for r=0.3 class 2 = 0.491 +- 0.313 (in-sample avg dev_std = 0.327)
NEC for r=0.3 all KL = 0.358 +- 0.313 (in-sample avg dev_std = 0.327)
NEC for r=0.3 all L1 = 0.422 +- 0.216 (in-sample avg dev_std = 0.327)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  0.634105
Model XAI WIoU of binarized graphs for r=0.6 =  0.56108375
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.428
NEC for r=0.6 class 0 = 0.58 +- 0.305 (in-sample avg dev_std = 0.546)
NEC for r=0.6 class 1 = 0.424 +- 0.305 (in-sample avg dev_std = 0.546)
NEC for r=0.6 class 2 = 0.616 +- 0.305 (in-sample avg dev_std = 0.546)
NEC for r=0.6 all KL = 0.597 +- 0.305 (in-sample avg dev_std = 0.546)
NEC for r=0.6 all L1 = 0.542 +- 0.217 (in-sample avg dev_std = 0.546)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  0.5209762499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.53053375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.491
NEC for r=0.9 class 0 = 0.611 +- 0.259 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 1 = 0.448 +- 0.259 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 2 = 0.578 +- 0.259 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all KL = 0.562 +- 0.259 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all L1 = 0.547 +- 0.181 (in-sample avg dev_std = 0.567)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.871
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.526405
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.51
NEC for r=1.0 class 0 = 0.586 +- 0.264 (in-sample avg dev_std = 0.547)
NEC for r=1.0 class 1 = 0.433 +- 0.264 (in-sample avg dev_std = 0.547)
NEC for r=1.0 class 2 = 0.566 +- 0.264 (in-sample avg dev_std = 0.547)
NEC for r=1.0 all KL = 0.53 +- 0.264 (in-sample avg dev_std = 0.547)
NEC for r=1.0 all L1 = 0.53 +- 0.185 (in-sample avg dev_std = 0.547)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  0.496935
Model XAI WIoU of binarized graphs for r=0.3 =  0.42042124999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.367
NEC for r=0.3 class 0 = 0.446 +- 0.328 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 1 = 0.402 +- 0.328 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 2 = 0.637 +- 0.328 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all KL = 0.476 +- 0.328 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all L1 = 0.493 +- 0.234 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.701
Model XAI F1 of binarized graphs for r=0.6 =  0.331505
Model XAI WIoU of binarized graphs for r=0.6 =  0.29499125000000004
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.424
NEC for r=0.6 class 0 = 0.557 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.6 class 1 = 0.317 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.6 class 2 = 0.548 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.6 all KL = 0.464 +- 0.309 (in-sample avg dev_std = 0.397)
NEC for r=0.6 all L1 = 0.474 +- 0.223 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.702
Model XAI F1 of binarized graphs for r=0.9 =  0.25453000000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.25223
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.476
NEC for r=0.9 class 0 = 0.573 +- 0.280 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 1 = 0.344 +- 0.280 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 2 = 0.501 +- 0.280 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all KL = 0.445 +- 0.280 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all L1 = 0.473 +- 0.209 (in-sample avg dev_std = 0.475)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.798
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.24419625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.502
NEC for r=1.0 class 0 = 0.555 +- 0.258 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 1 = 0.363 +- 0.258 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 2 = 0.509 +- 0.258 (in-sample avg dev_std = 0.443)
NEC for r=1.0 all KL = 0.417 +- 0.258 (in-sample avg dev_std = 0.443)
NEC for r=1.0 all L1 = 0.475 +- 0.203 (in-sample avg dev_std = 0.443)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.2689125
Model XAI WIoU of binarized graphs for r=0.3 =  0.30749375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.333
NEC for r=0.3 class 0 = 0.352 +- 0.346 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1 = 0.34 +- 0.346 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 2 = 0.386 +- 0.346 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.292 +- 0.346 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.359 +- 0.249 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.463
Model XAI F1 of binarized graphs for r=0.6 =  0.1623925
Model XAI WIoU of binarized graphs for r=0.6 =  0.2644925
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.355
NEC for r=0.6 class 0 = 0.244 +- 0.224 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 1 = 0.199 +- 0.224 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 2 = 0.236 +- 0.224 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all KL = 0.216 +- 0.224 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all L1 = 0.226 +- 0.139 (in-sample avg dev_std = 0.211)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.493
Model XAI F1 of binarized graphs for r=0.9 =  0.12121125
Model XAI WIoU of binarized graphs for r=0.9 =  0.2540575
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.384
NEC for r=0.9 class 0 = 0.264 +- 0.276 (in-sample avg dev_std = 0.214)
NEC for r=0.9 class 1 = 0.198 +- 0.276 (in-sample avg dev_std = 0.214)
NEC for r=0.9 class 2 = 0.225 +- 0.276 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all KL = 0.224 +- 0.276 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all L1 = 0.229 +- 0.179 (in-sample avg dev_std = 0.214)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.511
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.252845
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.392
NEC for r=1.0 class 0 = 0.258 +- 0.315 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1 = 0.186 +- 0.315 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 2 = 0.21 +- 0.315 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.252 +- 0.315 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.218 +- 0.191 (in-sample avg dev_std = 0.238)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.743, 0.817, 0.882, 1.0], 'all_L1': [0.629, 0.729, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.774, 0.727, 0.914, 1.0], 'all_L1': [0.72, 0.712, 0.848, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.644, 0.638, 0.9, 1.0], 'all_L1': [0.574, 0.657, 0.831, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.702, 0.749, 0.924, 1.0], 'all_L1': [0.613, 0.692, 0.856, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.701, 0.65, 0.827, 1.0], 'all_L1': [0.635, 0.68, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.201, 0.219, 0.334, 0.454], 'all_L1': [0.314, 0.302, 0.389, 0.443]}), defaultdict(<class 'list'>, {'all_KL': [0.266, 0.521, 0.454, 0.427], 'all_L1': [0.324, 0.496, 0.474, 0.475]}), defaultdict(<class 'list'>, {'all_KL': [0.405, 0.581, 0.472, 0.437], 'all_L1': [0.478, 0.533, 0.505, 0.484]}), defaultdict(<class 'list'>, {'all_KL': [0.346, 0.397, 0.417, 0.432], 'all_L1': [0.435, 0.425, 0.469, 0.464]}), defaultdict(<class 'list'>, {'all_KL': [0.358, 0.597, 0.562, 0.53], 'all_L1': [0.422, 0.542, 0.547, 0.53]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.767, 0.807, 0.907, 1.0], 'all_L1': [0.621, 0.684, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.78, 0.707, 0.888, 1.0], 'all_L1': [0.661, 0.613, 0.795, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.626, 0.621, 0.902, 1.0], 'all_L1': [0.594, 0.603, 0.818, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.814, 0.836, 0.942, 1.0], 'all_L1': [0.677, 0.734, 0.858, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.617, 0.725, 1.0], 'all_L1': [0.67, 0.624, 0.702, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.224, 0.157, 0.178, 0.277], 'all_L1': [0.378, 0.298, 0.295, 0.376]}), defaultdict(<class 'list'>, {'all_KL': [0.316, 0.348, 0.247, 0.259], 'all_L1': [0.423, 0.412, 0.314, 0.329]}), defaultdict(<class 'list'>, {'all_KL': [0.469, 0.411, 0.275, 0.298], 'all_L1': [0.519, 0.468, 0.377, 0.411]}), defaultdict(<class 'list'>, {'all_KL': [0.291, 0.219, 0.244, 0.312], 'all_L1': [0.432, 0.341, 0.354, 0.394]}), defaultdict(<class 'list'>, {'all_KL': [0.476, 0.464, 0.445, 0.417], 'all_L1': [0.493, 0.474, 0.473, 0.475]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.578, 0.557, 0.764, 1.0], 'all_L1': [0.575, 0.552, 0.705, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.684, 0.671, 0.758, 1.0], 'all_L1': [0.599, 0.628, 0.831, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.562, 0.702, 0.848, 1.0], 'all_L1': [0.633, 0.703, 0.781, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.835, 0.854, 0.874, 1.0], 'all_L1': [0.694, 0.734, 0.8, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.606, 0.721, 0.826, 1.0], 'all_L1': [0.584, 0.716, 0.791, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.112, 0.291, 0.31, 0.373], 'all_L1': [0.226, 0.354, 0.35, 0.456]}), defaultdict(<class 'list'>, {'all_KL': [0.32, 0.407, 0.387, 0.473], 'all_L1': [0.425, 0.453, 0.318, 0.361]}), defaultdict(<class 'list'>, {'all_KL': [0.346, 0.366, 0.239, 0.253], 'all_L1': [0.335, 0.322, 0.286, 0.31]}), defaultdict(<class 'list'>, {'all_KL': [0.17, 0.147, 0.193, 0.351], 'all_L1': [0.333, 0.269, 0.302, 0.421]}), defaultdict(<class 'list'>, {'all_KL': [0.292, 0.216, 0.224, 0.252], 'all_L1': [0.359, 0.226, 0.229, 0.218]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.634 +- 0.048, 0.694 +- 0.025, 0.830 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.713 +- 0.044, 0.716 +- 0.066, 0.889 +- 0.034, 1.000 +- 0.000
suff++_acc_int  =  0.406 +- 0.016, 0.608 +- 0.073, 0.780 +- 0.047
nec class all_L1  =  0.395 +- 0.065, 0.460 +- 0.089, 0.477 +- 0.052, 0.479 +- 0.029
nec class all_KL  =  0.315 +- 0.073, 0.463 +- 0.141, 0.448 +- 0.074, 0.456 +- 0.038
nec_acc_int  =  0.337 +- 0.010, 0.419 +- 0.023, 0.501 +- 0.018, 0.533 +- 0.017

Eval split val
suff++ class all_L1  =  0.645 +- 0.032, 0.652 +- 0.050, 0.799 +- 0.052, 1.000 +- 0.000
suff++ class all_KL  =  0.741 +- 0.065, 0.718 +- 0.091, 0.873 +- 0.076, 1.000 +- 0.000
suff++_acc_int  =  0.570 +- 0.028, 0.615 +- 0.027, 0.710 +- 0.068
nec class all_L1  =  0.449 +- 0.051, 0.399 +- 0.069, 0.363 +- 0.062, 0.397 +- 0.048
nec class all_KL  =  0.355 +- 0.100, 0.320 +- 0.115, 0.278 +- 0.089, 0.313 +- 0.055
nec_acc_int  =  0.363 +- 0.008, 0.456 +- 0.022, 0.507 +- 0.023, 0.532 +- 0.023

Eval split test
suff++ class all_L1  =  0.617 +- 0.043, 0.667 +- 0.068, 0.782 +- 0.042, 1.000 +- 0.000
suff++ class all_KL  =  0.653 +- 0.100, 0.701 +- 0.095, 0.814 +- 0.046, 1.000 +- 0.000
suff++_acc_int  =  0.465 +- 0.031, 0.452 +- 0.040, 0.494 +- 0.081
nec class all_L1  =  0.336 +- 0.064, 0.325 +- 0.078, 0.297 +- 0.040, 0.353 +- 0.084
nec class all_KL  =  0.248 +- 0.091, 0.285 +- 0.095, 0.271 +- 0.070, 0.340 +- 0.083
nec_acc_int  =  0.346 +- 0.018, 0.387 +- 0.031, 0.420 +- 0.037, 0.420 +- 0.037


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.514 +- 0.022, 0.577 +- 0.036, 0.653 +- 0.024, 0.740 +- 0.014
Faith. Armon (L1)= 		  =  0.481 +- 0.040, 0.546 +- 0.065, 0.604 +- 0.041, 0.647 +- 0.026
Faith. GMean (L1)= 	  =  0.497 +- 0.030, 0.561 +- 0.051, 0.628 +- 0.032, 0.692 +- 0.021
Faith. Aritm (KL)= 		  =  0.514 +- 0.021, 0.590 +- 0.040, 0.669 +- 0.031, 0.728 +- 0.019
Faith. Armon (KL)= 		  =  0.429 +- 0.066, 0.540 +- 0.104, 0.591 +- 0.061, 0.625 +- 0.035
Faith. GMean (KL)= 	  =  0.469 +- 0.046, 0.563 +- 0.075, 0.628 +- 0.047, 0.675 +- 0.028

Eval split val
Faith. Aritm (L1)= 		  =  0.547 +- 0.027, 0.525 +- 0.021, 0.581 +- 0.021, 0.699 +- 0.024
Faith. Armon (L1)= 		  =  0.527 +- 0.034, 0.488 +- 0.045, 0.493 +- 0.047, 0.567 +- 0.049
Faith. GMean (L1)= 	  =  0.537 +- 0.030, 0.506 +- 0.032, 0.535 +- 0.033, 0.629 +- 0.038
Faith. Aritm (KL)= 		  =  0.548 +- 0.032, 0.519 +- 0.020, 0.575 +- 0.019, 0.656 +- 0.028
Faith. Armon (KL)= 		  =  0.467 +- 0.080, 0.420 +- 0.100, 0.409 +- 0.082, 0.474 +- 0.061
Faith. GMean (KL)= 	  =  0.505 +- 0.057, 0.464 +- 0.064, 0.483 +- 0.053, 0.557 +- 0.047

Eval split test
Faith. Aritm (L1)= 		  =  0.476 +- 0.041, 0.496 +- 0.031, 0.539 +- 0.022, 0.677 +- 0.042
Faith. Armon (L1)= 		  =  0.431 +- 0.057, 0.427 +- 0.060, 0.428 +- 0.040, 0.516 +- 0.095
Faith. GMean (L1)= 	  =  0.453 +- 0.049, 0.460 +- 0.044, 0.480 +- 0.030, 0.590 +- 0.074
Faith. Aritm (KL)= 		  =  0.451 +- 0.057, 0.493 +- 0.043, 0.542 +- 0.016, 0.670 +- 0.041
Faith. Armon (KL)= 		  =  0.346 +- 0.096, 0.391 +- 0.095, 0.399 +- 0.070, 0.502 +- 0.091
Faith. GMean (KL)= 	  =  0.392 +- 0.075, 0.436 +- 0.066, 0.464 +- 0.046, 0.579 +- 0.070
Computed for split load_split = id



Completed in  0:32:01.916475  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Apr  7 21:03:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/07/2024 09:03:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;31mERROR[0m: 04/07/2024 09:03:17 PM - utils.py - line 52 : [1mCheckpoint not found at /mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/storage/checkpoints/round1/GOODMotif2_basis_covariate/repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_virtualweightedavgedgeattnmean/0.001lr_0.0wd/LECI_0.0_10_0_20_20_0_True/best.ckpt
[0m
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 559, in goodtg
    main()
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 490, in main
    evaluate_metric(args)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 276, in evaluate_metric
    pipeline.load_task(load_param=True, load_split=load_split)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 1348, in load_task
    test_score, test_loss = self.config_model('test', load_param=load_param, load_split=load_split)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 1378, in config_model
    print(f'#E#Checkpoint not found at {os.path.abspath(self.config.test_ckpt)}')

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:18:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:18:19 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8783
ID Validation Loss: 0.4308
ID Test ACCURACY: 0.8740
ID Test Loss: 0.4820
OOD Validation ACCURACY: 0.8742
OOD Validation Loss: 0.6112
OOD Test ACCURACY: 0.8261
OOD Test Loss: 1.0737

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 70...
[0m[1;37mINFO[0m: [1mCheckpoint 70: 
-----------------------------------
Train ACCURACY: 0.9476
Train Loss: 0.0824
ID Validation ACCURACY: 0.8713
ID Validation Loss: 0.3665
ID Test ACCURACY: 0.8717
ID Test Loss: 0.4026
OOD Validation ACCURACY: 0.8773
OOD Validation Loss: 0.4708
OOD Test ACCURACY: 0.8326
OOD Test Loss: 0.7168

[0m[1;37mINFO[0m: [1mChartInfo 0.8740 0.8261 0.8717 0.8326 0.8713 0.8773[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/08/2024 10:18:21 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.856
SUFF++ for r=0.6 class 0.0 = 0.849 +- 0.286 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 1.0 = 0.926 +- 0.286 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all KL = 0.823 +- 0.286 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all L1 = 0.893 +- 0.164 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.162 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 1.0 = 0.937 +- 0.162 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all KL = 0.946 +- 0.162 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.142 (in-sample avg dev_std = 0.130)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.839
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 793
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.808
SUFF++ for r=0.3 class 0.0 = 0.851 +- 0.297 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 class 1.0 = 0.879 +- 0.297 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all KL = 0.772 +- 0.297 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.3 all L1 = 0.866 +- 0.173 (in-sample avg dev_std = 0.416)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.858
SUFF++ for r=0.6 class 0.0 = 0.915 +- 0.190 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 class 1.0 = 0.932 +- 0.190 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 all KL = 0.901 +- 0.190 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 all L1 = 0.924 +- 0.136 (in-sample avg dev_std = 0.249)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0.0 = 0.961 +- 0.090 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.090 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.97 +- 0.090 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.081 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.832
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.792
SUFF++ for r=0.3 class 0.0 = 0.839 +- 0.309 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 class 1.0 = 0.877 +- 0.309 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 all KL = 0.761 +- 0.309 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 all L1 = 0.859 +- 0.185 (in-sample avg dev_std = 0.413)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.817
SUFF++ for r=0.6 class 0.0 = 0.896 +- 0.221 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 class 1.0 = 0.931 +- 0.221 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 all KL = 0.88 +- 0.221 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 all L1 = 0.914 +- 0.152 (in-sample avg dev_std = 0.278)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.835
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.833
SUFF++ for r=0.9 class 0.0 = 0.949 +- 0.086 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 1.0 = 0.974 +- 0.086 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all KL = 0.975 +- 0.086 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.097 (in-sample avg dev_std = 0.125)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.859
NEC for r=0.6 class 0.0 = 0.057 +- 0.212 (in-sample avg dev_std = 0.142)
NEC for r=0.6 class 1.0 = 0.07 +- 0.212 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all KL = 0.077 +- 0.212 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all L1 = 0.065 +- 0.141 (in-sample avg dev_std = 0.142)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.876
NEC for r=0.9 class 0.0 = 0.049 +- 0.181 (in-sample avg dev_std = 0.130)
NEC for r=0.9 class 1.0 = 0.06 +- 0.181 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all KL = 0.056 +- 0.181 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all L1 = 0.056 +- 0.136 (in-sample avg dev_std = 0.130)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.88
NEC for r=1.0 class 0.0 = 0.045 +- 0.183 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 1.0 = 0.056 +- 0.183 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all KL = 0.054 +- 0.183 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all L1 = 0.051 +- 0.129 (in-sample avg dev_std = 0.131)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.837
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.837
NEC for r=0.3 class 0.0 = 0.096 +- 0.203 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 1.0 = 0.07 +- 0.203 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all KL = 0.083 +- 0.203 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all L1 = 0.082 +- 0.175 (in-sample avg dev_std = 0.170)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.056 +- 0.120 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.042 +- 0.120 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.038 +- 0.120 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.049 +- 0.122 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.878
NEC for r=0.9 class 0.0 = 0.046 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=0.9 class 1.0 = 0.031 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all KL = 0.024 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all L1 = 0.038 +- 0.102 (in-sample avg dev_std = 0.106)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.879
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.881
NEC for r=1.0 class 0.0 = 0.033 +- 0.076 (in-sample avg dev_std = 0.086)
NEC for r=1.0 class 1.0 = 0.028 +- 0.076 (in-sample avg dev_std = 0.086)
NEC for r=1.0 all KL = 0.018 +- 0.076 (in-sample avg dev_std = 0.086)
NEC for r=1.0 all L1 = 0.031 +- 0.087 (in-sample avg dev_std = 0.086)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.832
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.815
NEC for r=0.3 class 0.0 = 0.097 +- 0.218 (in-sample avg dev_std = 0.185)
NEC for r=0.3 class 1.0 = 0.074 +- 0.218 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all KL = 0.091 +- 0.218 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all L1 = 0.085 +- 0.179 (in-sample avg dev_std = 0.185)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.829
NEC for r=0.6 class 0.0 = 0.081 +- 0.185 (in-sample avg dev_std = 0.162)
NEC for r=0.6 class 1.0 = 0.06 +- 0.185 (in-sample avg dev_std = 0.162)
NEC for r=0.6 all KL = 0.068 +- 0.185 (in-sample avg dev_std = 0.162)
NEC for r=0.6 all L1 = 0.07 +- 0.161 (in-sample avg dev_std = 0.162)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.835
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.833
NEC for r=0.9 class 0.0 = 0.064 +- 0.115 (in-sample avg dev_std = 0.131)
NEC for r=0.9 class 1.0 = 0.045 +- 0.115 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all KL = 0.038 +- 0.115 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all L1 = 0.054 +- 0.126 (in-sample avg dev_std = 0.131)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.841
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.839
NEC for r=1.0 class 0.0 = 0.061 +- 0.108 (in-sample avg dev_std = 0.117)
NEC for r=1.0 class 1.0 = 0.042 +- 0.108 (in-sample avg dev_std = 0.117)
NEC for r=1.0 all KL = 0.036 +- 0.108 (in-sample avg dev_std = 0.117)
NEC for r=1.0 all L1 = 0.051 +- 0.120 (in-sample avg dev_std = 0.117)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:21:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:54 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 164...
[0m[1;37mINFO[0m: [1mCheckpoint 164: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8776
ID Validation Loss: 0.4435
ID Test ACCURACY: 0.8717
ID Test Loss: 0.4848
OOD Validation ACCURACY: 0.8721
OOD Validation Loss: 0.6219
OOD Test ACCURACY: 0.8164
OOD Test Loss: 0.9938

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0752
ID Validation ACCURACY: 0.8751
ID Validation Loss: 0.4381
ID Test ACCURACY: 0.8730
ID Test Loss: 0.4836
OOD Validation ACCURACY: 0.8763
OOD Validation Loss: 0.5902
OOD Test ACCURACY: 0.8262
OOD Test Loss: 0.9075

[0m[1;37mINFO[0m: [1mChartInfo 0.8717 0.8164 0.8730 0.8262 0.8751 0.8763[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/08/2024 10:21:55 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.862
SUFF++ for r=0.6 class 0.0 = 0.867 +- 0.297 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 1.0 = 0.927 +- 0.297 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all KL = 0.833 +- 0.297 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all L1 = 0.902 +- 0.168 (in-sample avg dev_std = 0.324)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.953 +- 0.160 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 class 1.0 = 0.938 +- 0.160 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 all KL = 0.948 +- 0.160 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.128 (in-sample avg dev_std = 0.135)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.839
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 795
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.808
SUFF++ for r=0.3 class 0.0 = 0.85 +- 0.278 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 class 1.0 = 0.896 +- 0.278 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all KL = 0.807 +- 0.278 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all L1 = 0.874 +- 0.173 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.852
SUFF++ for r=0.6 class 0.0 = 0.9 +- 0.206 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 class 1.0 = 0.943 +- 0.206 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all KL = 0.902 +- 0.206 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all L1 = 0.923 +- 0.145 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0.0 = 0.96 +- 0.083 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.083 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all KL = 0.972 +- 0.083 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.083 (in-sample avg dev_std = 0.148)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.775
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.763
SUFF++ for r=0.3 class 0.0 = 0.836 +- 0.236 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.3 class 1.0 = 0.929 +- 0.236 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.3 all KL = 0.852 +- 0.236 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.3 all L1 = 0.884 +- 0.164 (in-sample avg dev_std = 0.308)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.793
SUFF++ for r=0.6 class 0.0 = 0.868 +- 0.186 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 1.0 = 0.938 +- 0.186 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all KL = 0.901 +- 0.186 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all L1 = 0.904 +- 0.157 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.838
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.075 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.075 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.974 +- 0.075 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.096 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.871
NEC for r=0.6 class 0.0 = 0.065 +- 0.222 (in-sample avg dev_std = 0.179)
NEC for r=0.6 class 1.0 = 0.075 +- 0.222 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all KL = 0.087 +- 0.222 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all L1 = 0.071 +- 0.157 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.876
NEC for r=0.9 class 0.0 = 0.038 +- 0.192 (in-sample avg dev_std = 0.144)
NEC for r=0.9 class 1.0 = 0.066 +- 0.192 (in-sample avg dev_std = 0.144)
NEC for r=0.9 all KL = 0.062 +- 0.192 (in-sample avg dev_std = 0.144)
NEC for r=0.9 all L1 = 0.054 +- 0.134 (in-sample avg dev_std = 0.144)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.044 +- 0.198 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.057 +- 0.198 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.061 +- 0.198 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.052 +- 0.135 (in-sample avg dev_std = 0.145)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.84
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.832
NEC for r=0.3 class 0.0 = 0.107 +- 0.197 (in-sample avg dev_std = 0.176)
NEC for r=0.3 class 1.0 = 0.082 +- 0.197 (in-sample avg dev_std = 0.176)
NEC for r=0.3 all KL = 0.089 +- 0.197 (in-sample avg dev_std = 0.176)
NEC for r=0.3 all L1 = 0.094 +- 0.175 (in-sample avg dev_std = 0.176)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.86
NEC for r=0.6 class 0.0 = 0.068 +- 0.142 (in-sample avg dev_std = 0.151)
NEC for r=0.6 class 1.0 = 0.045 +- 0.142 (in-sample avg dev_std = 0.151)
NEC for r=0.6 all KL = 0.047 +- 0.142 (in-sample avg dev_std = 0.151)
NEC for r=0.6 all L1 = 0.056 +- 0.131 (in-sample avg dev_std = 0.151)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.885
NEC for r=0.9 class 0.0 = 0.057 +- 0.106 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 1.0 = 0.039 +- 0.106 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all KL = 0.034 +- 0.106 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all L1 = 0.048 +- 0.110 (in-sample avg dev_std = 0.121)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.882
NEC for r=1.0 class 0.0 = 0.05 +- 0.096 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.032 +- 0.096 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.027 +- 0.096 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.04 +- 0.099 (in-sample avg dev_std = 0.105)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.775
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.778
NEC for r=0.3 class 0.0 = 0.127 +- 0.193 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 1.0 = 0.07 +- 0.193 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all KL = 0.087 +- 0.193 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all L1 = 0.097 +- 0.177 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.808
NEC for r=0.6 class 0.0 = 0.1 +- 0.136 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 1.0 = 0.057 +- 0.136 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all KL = 0.057 +- 0.136 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all L1 = 0.078 +- 0.144 (in-sample avg dev_std = 0.146)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.841
NEC for r=0.9 class 0.0 = 0.074 +- 0.107 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.048 +- 0.107 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.042 +- 0.107 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.061 +- 0.123 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.848
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.848
NEC for r=1.0 class 0.0 = 0.057 +- 0.085 (in-sample avg dev_std = 0.103)
NEC for r=1.0 class 1.0 = 0.038 +- 0.085 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all KL = 0.03 +- 0.085 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all L1 = 0.047 +- 0.100 (in-sample avg dev_std = 0.103)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:25:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:25:27 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:25:28 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8783
ID Validation Loss: 0.5164
ID Test ACCURACY: 0.8776
ID Test Loss: 0.5680
OOD Validation ACCURACY: 0.8782
OOD Validation Loss: 0.7542
OOD Test ACCURACY: 0.8254
OOD Test Loss: 1.5904

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 151...
[0m[1;37mINFO[0m: [1mCheckpoint 151: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0756
ID Validation ACCURACY: 0.8740
ID Validation Loss: 0.4313
ID Test ACCURACY: 0.8749
ID Test Loss: 0.4697
OOD Validation ACCURACY: 0.8793
OOD Validation Loss: 0.6053
OOD Test ACCURACY: 0.8291
OOD Test Loss: 1.1932

[0m[1;37mINFO[0m: [1mChartInfo 0.8776 0.8254 0.8749 0.8291 0.8740 0.8793[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/08/2024 10:25:28 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.847
SUFF++ for r=0.6 class 0.0 = 0.927 +- 0.207 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 class 1.0 = 0.937 +- 0.207 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all KL = 0.911 +- 0.207 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all L1 = 0.933 +- 0.135 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.135 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1.0 = 0.948 +- 0.135 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.96 +- 0.135 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.946 +- 0.144 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.814
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.79
SUFF++ for r=0.3 class 0.0 = 0.892 +- 0.232 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 class 1.0 = 0.911 +- 0.232 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 all KL = 0.865 +- 0.232 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 all L1 = 0.902 +- 0.142 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.851
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.842
SUFF++ for r=0.6 class 0.0 = 0.93 +- 0.163 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 class 1.0 = 0.958 +- 0.163 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 all KL = 0.939 +- 0.163 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 all L1 = 0.944 +- 0.126 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.879
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.106 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.106 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all KL = 0.965 +- 0.106 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all L1 = 0.965 +- 0.089 (in-sample avg dev_std = 0.164)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.766
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.758
SUFF++ for r=0.3 class 0.0 = 0.9 +- 0.160 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.3 class 1.0 = 0.935 +- 0.160 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.3 all KL = 0.917 +- 0.160 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.3 all L1 = 0.918 +- 0.133 (in-sample avg dev_std = 0.224)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.803
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.796
SUFF++ for r=0.6 class 0.0 = 0.914 +- 0.164 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.6 class 1.0 = 0.944 +- 0.164 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.6 all KL = 0.926 +- 0.164 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.6 all L1 = 0.93 +- 0.141 (in-sample avg dev_std = 0.207)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.836
SUFF++ for r=0.9 class 0.0 = 0.961 +- 0.078 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.078 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all KL = 0.976 +- 0.078 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.087 (in-sample avg dev_std = 0.120)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.849
NEC for r=0.6 class 0.0 = 0.069 +- 0.132 (in-sample avg dev_std = 0.113)
NEC for r=0.6 class 1.0 = 0.039 +- 0.132 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all KL = 0.043 +- 0.132 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all L1 = 0.052 +- 0.121 (in-sample avg dev_std = 0.113)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.857
NEC for r=0.9 class 0.0 = 0.055 +- 0.131 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.038 +- 0.131 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.034 +- 0.131 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.045 +- 0.134 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.86
NEC for r=1.0 class 0.0 = 0.042 +- 0.119 (in-sample avg dev_std = 0.103)
NEC for r=1.0 class 1.0 = 0.03 +- 0.119 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all KL = 0.027 +- 0.119 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all L1 = 0.035 +- 0.119 (in-sample avg dev_std = 0.103)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.815
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.808
NEC for r=0.3 class 0.0 = 0.097 +- 0.157 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 1.0 = 0.054 +- 0.157 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all KL = 0.06 +- 0.157 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all L1 = 0.075 +- 0.144 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.851
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.848
NEC for r=0.6 class 0.0 = 0.05 +- 0.098 (in-sample avg dev_std = 0.113)
NEC for r=0.6 class 1.0 = 0.032 +- 0.098 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all KL = 0.028 +- 0.098 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all L1 = 0.04 +- 0.107 (in-sample avg dev_std = 0.113)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.882
NEC for r=0.9 class 0.0 = 0.036 +- 0.094 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1.0 = 0.037 +- 0.094 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.025 +- 0.094 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.036 +- 0.107 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.883
NEC for r=1.0 class 0.0 = 0.03 +- 0.082 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.029 +- 0.082 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.018 +- 0.082 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.03 +- 0.092 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.766
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.774
NEC for r=0.3 class 0.0 = 0.094 +- 0.127 (in-sample avg dev_std = 0.141)
NEC for r=0.3 class 1.0 = 0.053 +- 0.127 (in-sample avg dev_std = 0.141)
NEC for r=0.3 all KL = 0.048 +- 0.127 (in-sample avg dev_std = 0.141)
NEC for r=0.3 all L1 = 0.073 +- 0.146 (in-sample avg dev_std = 0.141)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.803
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.807
NEC for r=0.6 class 0.0 = 0.067 +- 0.116 (in-sample avg dev_std = 0.128)
NEC for r=0.6 class 1.0 = 0.044 +- 0.116 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all KL = 0.039 +- 0.116 (in-sample avg dev_std = 0.128)
NEC for r=0.6 all L1 = 0.055 +- 0.127 (in-sample avg dev_std = 0.128)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.832
NEC for r=0.9 class 0.0 = 0.058 +- 0.125 (in-sample avg dev_std = 0.137)
NEC for r=0.9 class 1.0 = 0.044 +- 0.125 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all KL = 0.04 +- 0.125 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all L1 = 0.051 +- 0.133 (in-sample avg dev_std = 0.137)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.844
NEC for r=1.0 class 0.0 = 0.047 +- 0.117 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 1.0 = 0.037 +- 0.117 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all KL = 0.035 +- 0.117 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all L1 = 0.042 +- 0.118 (in-sample avg dev_std = 0.122)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:29:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:29:02 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0754
ID Validation ACCURACY: 0.8738
ID Validation Loss: 0.4466
ID Test ACCURACY: 0.8695
ID Test Loss: 0.4845
OOD Validation ACCURACY: 0.8709
OOD Validation Loss: 0.6243
OOD Test ACCURACY: 0.8083
OOD Test Loss: 1.0867

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 123...
[0m[1;37mINFO[0m: [1mCheckpoint 123: 
-----------------------------------
Train ACCURACY: 0.9485
Train Loss: 0.0805
ID Validation ACCURACY: 0.8666
ID Validation Loss: 0.3627
ID Test ACCURACY: 0.8691
ID Test Loss: 0.3724
OOD Validation ACCURACY: 0.8774
OOD Validation Loss: 0.4706
OOD Test ACCURACY: 0.8316
OOD Test Loss: 0.7130

[0m[1;37mINFO[0m: [1mChartInfo 0.8695 0.8083 0.8691 0.8316 0.8666 0.8774[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/08/2024 10:29:03 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.877
SUFF++ for r=0.6 class 0.0 = 0.909 +- 0.259 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 class 1.0 = 0.914 +- 0.259 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all KL = 0.863 +- 0.259 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.6 all L1 = 0.912 +- 0.150 (in-sample avg dev_std = 0.273)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.883
SUFF++ for r=0.9 class 0.0 = 0.955 +- 0.168 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.168 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all KL = 0.948 +- 0.168 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all L1 = 0.942 +- 0.137 (in-sample avg dev_std = 0.122)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.817
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 794
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.798
SUFF++ for r=0.3 class 0.0 = 0.874 +- 0.245 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 1.0 = 0.902 +- 0.245 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all KL = 0.842 +- 0.245 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all L1 = 0.889 +- 0.155 (in-sample avg dev_std = 0.328)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.84
SUFF++ for r=0.6 class 0.0 = 0.916 +- 0.163 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.6 class 1.0 = 0.945 +- 0.163 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.6 all KL = 0.928 +- 0.163 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.6 all L1 = 0.932 +- 0.128 (in-sample avg dev_std = 0.196)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0.0 = 0.948 +- 0.098 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.098 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all KL = 0.967 +- 0.098 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.093 (in-sample avg dev_std = 0.161)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.777
SUFF++ for r=0.3 class 0.0 = 0.85 +- 0.236 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 class 1.0 = 0.921 +- 0.236 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 all KL = 0.847 +- 0.236 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 all L1 = 0.887 +- 0.154 (in-sample avg dev_std = 0.304)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.82
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.798
SUFF++ for r=0.6 class 0.0 = 0.866 +- 0.185 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 class 1.0 = 0.949 +- 0.185 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 all KL = 0.904 +- 0.185 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 all L1 = 0.909 +- 0.148 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.833
SUFF++ for r=0.9 class 0.0 = 0.951 +- 0.099 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.099 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all KL = 0.971 +- 0.099 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.090 (in-sample avg dev_std = 0.119)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.88
NEC for r=0.6 class 0.0 = 0.059 +- 0.250 (in-sample avg dev_std = 0.154)
NEC for r=0.6 class 1.0 = 0.083 +- 0.250 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all KL = 0.102 +- 0.250 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all L1 = 0.073 +- 0.147 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.882
NEC for r=0.9 class 0.0 = 0.046 +- 0.236 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.09 +- 0.236 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.088 +- 0.236 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.072 +- 0.157 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.884
NEC for r=1.0 class 0.0 = 0.049 +- 0.238 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.086 +- 0.238 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.088 +- 0.238 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.07 +- 0.156 (in-sample avg dev_std = 0.145)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.817
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.822
NEC for r=0.3 class 0.0 = 0.104 +- 0.186 (in-sample avg dev_std = 0.154)
NEC for r=0.3 class 1.0 = 0.073 +- 0.186 (in-sample avg dev_std = 0.154)
NEC for r=0.3 all KL = 0.081 +- 0.186 (in-sample avg dev_std = 0.154)
NEC for r=0.3 all L1 = 0.088 +- 0.160 (in-sample avg dev_std = 0.154)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.851
NEC for r=0.6 class 0.0 = 0.073 +- 0.123 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.046 +- 0.123 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.041 +- 0.123 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.059 +- 0.124 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.062 +- 0.121 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 1.0 = 0.039 +- 0.121 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all KL = 0.035 +- 0.121 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all L1 = 0.05 +- 0.116 (in-sample avg dev_std = 0.126)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.867
NEC for r=1.0 class 0.0 = 0.058 +- 0.117 (in-sample avg dev_std = 0.107)
NEC for r=1.0 class 1.0 = 0.035 +- 0.117 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all KL = 0.031 +- 0.117 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all L1 = 0.046 +- 0.112 (in-sample avg dev_std = 0.107)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.782
NEC for r=0.3 class 0.0 = 0.113 +- 0.183 (in-sample avg dev_std = 0.149)
NEC for r=0.3 class 1.0 = 0.065 +- 0.183 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all KL = 0.077 +- 0.183 (in-sample avg dev_std = 0.149)
NEC for r=0.3 all L1 = 0.088 +- 0.160 (in-sample avg dev_std = 0.149)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.82
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.806
NEC for r=0.6 class 0.0 = 0.093 +- 0.149 (in-sample avg dev_std = 0.135)
NEC for r=0.6 class 1.0 = 0.052 +- 0.149 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all KL = 0.053 +- 0.149 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all L1 = 0.072 +- 0.139 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
NEC for r=0.9 class 0.0 = 0.07 +- 0.118 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 1.0 = 0.038 +- 0.118 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all KL = 0.04 +- 0.118 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all L1 = 0.054 +- 0.110 (in-sample avg dev_std = 0.121)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.827
NEC for r=1.0 class 0.0 = 0.065 +- 0.117 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 1.0 = 0.033 +- 0.117 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all KL = 0.038 +- 0.117 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all L1 = 0.049 +- 0.105 (in-sample avg dev_std = 0.111)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:32:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 98...
[0m[1;37mINFO[0m: [1mCheckpoint 98: 
-----------------------------------
Train ACCURACY: 0.9483
Train Loss: 0.0811
ID Validation ACCURACY: 0.8772
ID Validation Loss: 0.3448
ID Test ACCURACY: 0.8736
ID Test Loss: 0.3787
OOD Validation ACCURACY: 0.8607
OOD Validation Loss: 0.4603
OOD Test ACCURACY: 0.7820
OOD Test Loss: 0.8553

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8751
ID Validation Loss: 0.4503
ID Test ACCURACY: 0.8761
ID Test Loss: 0.5026
OOD Validation ACCURACY: 0.8743
OOD Validation Loss: 0.5659
OOD Test ACCURACY: 0.7891
OOD Test Loss: 0.8707

[0m[1;37mINFO[0m: [1mChartInfo 0.8736 0.7820 0.8761 0.7891 0.8751 0.8743[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/08/2024 10:32:43 AM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.863
SUFF++ for r=0.6 class 0.0 = 0.846 +- 0.236 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 class 1.0 = 0.941 +- 0.236 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 all KL = 0.857 +- 0.236 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.6 all L1 = 0.901 +- 0.149 (in-sample avg dev_std = 0.314)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0.0 = 0.912 +- 0.136 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1.0 = 0.948 +- 0.136 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.954 +- 0.136 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.932 +- 0.143 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.828
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 798
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.793
SUFF++ for r=0.3 class 0.0 = 0.823 +- 0.254 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 class 1.0 = 0.903 +- 0.254 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all KL = 0.819 +- 0.254 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all L1 = 0.865 +- 0.163 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.839
SUFF++ for r=0.6 class 0.0 = 0.862 +- 0.164 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1.0 = 0.941 +- 0.164 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.91 +- 0.164 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.903 +- 0.145 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0.0 = 0.908 +- 0.105 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.105 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all KL = 0.952 +- 0.105 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all L1 = 0.937 +- 0.101 (in-sample avg dev_std = 0.191)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.756
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.74
SUFF++ for r=0.3 class 0.0 = 0.82 +- 0.196 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 1.0 = 0.926 +- 0.196 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all KL = 0.876 +- 0.196 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all L1 = 0.875 +- 0.157 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.757
SUFF++ for r=0.6 class 0.0 = 0.847 +- 0.129 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 class 1.0 = 0.947 +- 0.129 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all KL = 0.927 +- 0.129 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all L1 = 0.899 +- 0.141 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.804
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.793
SUFF++ for r=0.9 class 0.0 = 0.905 +- 0.068 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 1.0 = 0.975 +- 0.068 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all KL = 0.97 +- 0.068 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.100 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.883
NEC for r=0.6 class 0.0 = 0.095 +- 0.160 (in-sample avg dev_std = 0.119)
NEC for r=0.6 class 1.0 = 0.039 +- 0.160 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all KL = 0.058 +- 0.160 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all L1 = 0.062 +- 0.131 (in-sample avg dev_std = 0.119)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.883
NEC for r=0.9 class 0.0 = 0.071 +- 0.109 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 1.0 = 0.04 +- 0.109 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all KL = 0.034 +- 0.109 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all L1 = 0.053 +- 0.123 (in-sample avg dev_std = 0.113)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.892
NEC for r=1.0 class 0.0 = 0.063 +- 0.091 (in-sample avg dev_std = 0.100)
NEC for r=1.0 class 1.0 = 0.033 +- 0.091 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all KL = 0.025 +- 0.091 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all L1 = 0.045 +- 0.109 (in-sample avg dev_std = 0.100)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.827
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.815
NEC for r=0.3 class 0.0 = 0.133 +- 0.182 (in-sample avg dev_std = 0.155)
NEC for r=0.3 class 1.0 = 0.08 +- 0.182 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all KL = 0.088 +- 0.182 (in-sample avg dev_std = 0.155)
NEC for r=0.3 all L1 = 0.105 +- 0.170 (in-sample avg dev_std = 0.155)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.849
NEC for r=0.6 class 0.0 = 0.097 +- 0.112 (in-sample avg dev_std = 0.125)
NEC for r=0.6 class 1.0 = 0.044 +- 0.112 (in-sample avg dev_std = 0.125)
NEC for r=0.6 all KL = 0.042 +- 0.112 (in-sample avg dev_std = 0.125)
NEC for r=0.6 all L1 = 0.07 +- 0.126 (in-sample avg dev_std = 0.125)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.083 +- 0.078 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1.0 = 0.035 +- 0.078 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.027 +- 0.078 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.058 +- 0.111 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.072 +- 0.058 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 1.0 = 0.025 +- 0.058 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all KL = 0.018 +- 0.058 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all L1 = 0.047 +- 0.094 (in-sample avg dev_std = 0.088)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.756
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.753
NEC for r=0.3 class 0.0 = 0.157 +- 0.186 (in-sample avg dev_std = 0.139)
NEC for r=0.3 class 1.0 = 0.064 +- 0.186 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all KL = 0.08 +- 0.186 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all L1 = 0.109 +- 0.172 (in-sample avg dev_std = 0.139)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.77
NEC for r=0.6 class 0.0 = 0.132 +- 0.117 (in-sample avg dev_std = 0.120)
NEC for r=0.6 class 1.0 = 0.044 +- 0.117 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all KL = 0.047 +- 0.117 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all L1 = 0.086 +- 0.138 (in-sample avg dev_std = 0.120)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.804
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.799
NEC for r=0.9 class 0.0 = 0.111 +- 0.079 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 1.0 = 0.035 +- 0.079 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all KL = 0.031 +- 0.079 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all L1 = 0.072 +- 0.118 (in-sample avg dev_std = 0.099)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.8
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.797
NEC for r=1.0 class 0.0 = 0.085 +- 0.060 (in-sample avg dev_std = 0.080)
NEC for r=1.0 class 1.0 = 0.025 +- 0.060 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all KL = 0.02 +- 0.060 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all L1 = 0.054 +- 0.097 (in-sample avg dev_std = 0.080)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.823, 0.946, 1.0], 'all_L1': [0.893, 0.939, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.833, 0.948, 1.0], 'all_L1': [0.902, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.96, 1.0], 'all_L1': [0.933, 0.946, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.863, 0.948, 1.0], 'all_L1': [0.912, 0.942, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.857, 0.954, 1.0], 'all_L1': [0.901, 0.932, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.077, 0.056, 0.054], 'all_L1': [0.065, 0.056, 0.051]}), defaultdict(<class 'list'>, {'all_KL': [0.087, 0.062, 0.061], 'all_L1': [0.071, 0.054, 0.052]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.034, 0.027], 'all_L1': [0.052, 0.045, 0.035]}), defaultdict(<class 'list'>, {'all_KL': [0.102, 0.088, 0.088], 'all_L1': [0.073, 0.072, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.058, 0.034, 0.025], 'all_L1': [0.062, 0.053, 0.045]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.772, 0.901, 0.97, 1.0], 'all_L1': [0.866, 0.924, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.807, 0.902, 0.972, 1.0], 'all_L1': [0.874, 0.923, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.865, 0.939, 0.965, 1.0], 'all_L1': [0.902, 0.944, 0.965, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.842, 0.928, 0.967, 1.0], 'all_L1': [0.889, 0.932, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.819, 0.91, 0.952, 1.0], 'all_L1': [0.865, 0.903, 0.937, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.083, 0.038, 0.024, 0.018], 'all_L1': [0.082, 0.049, 0.038, 0.031]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.047, 0.034, 0.027], 'all_L1': [0.094, 0.056, 0.048, 0.04]}), defaultdict(<class 'list'>, {'all_KL': [0.06, 0.028, 0.025, 0.018], 'all_L1': [0.075, 0.04, 0.036, 0.03]}), defaultdict(<class 'list'>, {'all_KL': [0.081, 0.041, 0.035, 0.031], 'all_L1': [0.088, 0.059, 0.05, 0.046]}), defaultdict(<class 'list'>, {'all_KL': [0.088, 0.042, 0.027, 0.018], 'all_L1': [0.105, 0.07, 0.058, 0.047]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.761, 0.88, 0.975, 1.0], 'all_L1': [0.859, 0.914, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.852, 0.901, 0.974, 1.0], 'all_L1': [0.884, 0.904, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.917, 0.926, 0.976, 1.0], 'all_L1': [0.918, 0.93, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.847, 0.904, 0.971, 1.0], 'all_L1': [0.887, 0.909, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.876, 0.927, 0.97, 1.0], 'all_L1': [0.875, 0.899, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.091, 0.068, 0.038, 0.036], 'all_L1': [0.085, 0.07, 0.054, 0.051]}), defaultdict(<class 'list'>, {'all_KL': [0.087, 0.057, 0.042, 0.03], 'all_L1': [0.097, 0.078, 0.061, 0.047]}), defaultdict(<class 'list'>, {'all_KL': [0.048, 0.039, 0.04, 0.035], 'all_L1': [0.073, 0.055, 0.051, 0.042]}), defaultdict(<class 'list'>, {'all_KL': [0.077, 0.053, 0.04, 0.038], 'all_L1': [0.088, 0.072, 0.054, 0.049]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.047, 0.031, 0.02], 'all_L1': [0.109, 0.086, 0.072, 0.054]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.908 +- 0.014, 0.941 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.857 +- 0.031, 0.951 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.861 +- 0.010, 0.871 +- 0.008
nec class all_L1  =  0.065 +- 0.007, 0.056 +- 0.009, 0.051 +- 0.011
nec class all_KL  =  0.073 +- 0.021, 0.055 +- 0.020, 0.051 +- 0.023
nec_acc_int  =  0.868 +- 0.013, 0.875 +- 0.010, 0.879 +- 0.011

Eval split val
suff++ class all_L1  =  0.879 +- 0.014, 0.925 +- 0.013, 0.958 +- 0.011, 1.000 +- 0.000
suff++ class all_KL  =  0.821 +- 0.032, 0.916 +- 0.015, 0.965 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.800 +- 0.007, 0.846 +- 0.008, 0.873 +- 0.007
nec class all_L1  =  0.089 +- 0.010, 0.055 +- 0.010, 0.046 +- 0.008, 0.039 +- 0.007
nec class all_KL  =  0.080 +- 0.011, 0.039 +- 0.006, 0.029 +- 0.005, 0.022 +- 0.006
nec_acc_int  =  0.823 +- 0.011, 0.854 +- 0.006, 0.877 +- 0.006, 0.877 +- 0.007

Eval split test
suff++ class all_L1  =  0.885 +- 0.019, 0.911 +- 0.011, 0.958 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.851 +- 0.051, 0.908 +- 0.018, 0.973 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.766 +- 0.018, 0.792 +- 0.019, 0.827 +- 0.017
nec class all_L1  =  0.090 +- 0.012, 0.072 +- 0.010, 0.058 +- 0.008, 0.049 +- 0.004
nec class all_KL  =  0.077 +- 0.015, 0.053 +- 0.010, 0.038 +- 0.004, 0.032 +- 0.006
nec_acc_int  =  0.780 +- 0.020, 0.804 +- 0.019, 0.826 +- 0.014, 0.831 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.486 +- 0.006, 0.498 +- 0.005, 0.525 +- 0.006
Faith. Armon (L1)= 		  =  0.121 +- 0.013, 0.106 +- 0.016, 0.096 +- 0.021
Faith. GMean (L1)= 	  =  0.242 +- 0.013, 0.229 +- 0.018, 0.224 +- 0.025
Faith. Aritm (KL)= 		  =  0.465 +- 0.012, 0.503 +- 0.008, 0.525 +- 0.012
Faith. Armon (KL)= 		  =  0.134 +- 0.035, 0.103 +- 0.036, 0.096 +- 0.042
Faith. GMean (KL)= 	  =  0.248 +- 0.035, 0.224 +- 0.041, 0.220 +- 0.052

Eval split val
Faith. Aritm (L1)= 		  =  0.484 +- 0.005, 0.490 +- 0.003, 0.502 +- 0.003, 0.519 +- 0.004
Faith. Armon (L1)= 		  =  0.161 +- 0.017, 0.103 +- 0.018, 0.088 +- 0.015, 0.075 +- 0.013
Faith. GMean (L1)= 	  =  0.279 +- 0.015, 0.224 +- 0.019, 0.209 +- 0.017, 0.196 +- 0.018
Faith. Aritm (KL)= 		  =  0.451 +- 0.013, 0.478 +- 0.006, 0.497 +- 0.005, 0.511 +- 0.003
Faith. Armon (KL)= 		  =  0.146 +- 0.018, 0.075 +- 0.012, 0.056 +- 0.009, 0.044 +- 0.011
Faith. GMean (KL)= 	  =  0.256 +- 0.015, 0.189 +- 0.015, 0.167 +- 0.013, 0.149 +- 0.018

Eval split test
Faith. Aritm (L1)= 		  =  0.488 +- 0.008, 0.492 +- 0.001, 0.508 +- 0.001, 0.524 +- 0.002
Faith. Armon (L1)= 		  =  0.164 +- 0.020, 0.134 +- 0.018, 0.110 +- 0.013, 0.093 +- 0.007
Faith. GMean (L1)= 	  =  0.282 +- 0.017, 0.256 +- 0.017, 0.236 +- 0.014, 0.220 +- 0.009
Faith. Aritm (KL)= 		  =  0.464 +- 0.020, 0.480 +- 0.004, 0.506 +- 0.003, 0.516 +- 0.003
Faith. Armon (KL)= 		  =  0.140 +- 0.026, 0.100 +- 0.017, 0.073 +- 0.007, 0.062 +- 0.012
Faith. GMean (KL)= 	  =  0.253 +- 0.022, 0.218 +- 0.018, 0.193 +- 0.010, 0.177 +- 0.019
Computed for split load_split = id



Completed in  0:17:59.446105  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:36:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:37 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:40 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:40 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:41 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:44 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:36:45 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 80...
[0m[1;37mINFO[0m: [1mCheckpoint 80: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0004
ID Validation ACCURACY: 0.6895
ID Validation Loss: 2.4069
ID Test ACCURACY: 0.6643
ID Test Loss: 2.5890
OOD Validation ACCURACY: 0.6028
OOD Validation Loss: 3.2805
OOD Test ACCURACY: 0.5621
OOD Test Loss: 4.8450

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 12...
[0m[1;37mINFO[0m: [1mCheckpoint 12: 
-----------------------------------
Train ACCURACY: 0.8293
Train Loss: 0.4544
ID Validation ACCURACY: 0.6877
ID Validation Loss: 0.8142
ID Test ACCURACY: 0.6931
ID Test Loss: 0.8130
OOD Validation ACCURACY: 0.6291
OOD Validation Loss: 1.0284
OOD Test ACCURACY: 0.5848
OOD Test Loss: 1.3883

[0m[1;37mINFO[0m: [1mChartInfo 0.6643 0.5621 0.6931 0.5848 0.6877 0.6291[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.596
SUFF++ for r=0.3 class 0 = 0.68 +- 0.314 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 1 = 0.664 +- 0.314 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 2 = 0.637 +- 0.314 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all KL = 0.436 +- 0.314 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.214 (in-sample avg dev_std = 0.618)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.664
SUFF++ for r=0.6 class 0 = 0.802 +- 0.323 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 1 = 0.781 +- 0.323 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 2 = 0.769 +- 0.323 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all KL = 0.681 +- 0.323 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all L1 = 0.783 +- 0.226 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0 = 0.91 +- 0.155 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.155 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 2 = 0.879 +- 0.155 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all KL = 0.91 +- 0.155 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all L1 = 0.9 +- 0.155 (in-sample avg dev_std = 0.234)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.559
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.537
SUFF++ for r=0.3 class 0 = 0.706 +- 0.322 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.667 +- 0.322 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.631 +- 0.322 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.498 +- 0.322 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.67 +- 0.230 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.588
SUFF++ for r=0.6 class 0 = 0.817 +- 0.293 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 1 = 0.772 +- 0.293 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 2 = 0.724 +- 0.293 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all KL = 0.705 +- 0.293 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all L1 = 0.773 +- 0.224 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.594
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.599
SUFF++ for r=0.9 class 0 = 0.902 +- 0.156 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 class 1 = 0.891 +- 0.156 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.156 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all KL = 0.911 +- 0.156 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.171 (in-sample avg dev_std = 0.224)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0 = 0.716 +- 0.321 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 class 1 = 0.637 +- 0.321 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 class 2 = 0.597 +- 0.321 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 all KL = 0.455 +- 0.321 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 all L1 = 0.647 +- 0.226 (in-sample avg dev_std = 0.596)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.539
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.535
SUFF++ for r=0.6 class 0 = 0.811 +- 0.308 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 1 = 0.745 +- 0.308 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 2 = 0.729 +- 0.308 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all KL = 0.662 +- 0.308 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all L1 = 0.758 +- 0.230 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.559
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.554
SUFF++ for r=0.9 class 0 = 0.91 +- 0.163 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 1 = 0.868 +- 0.163 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.163 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all KL = 0.903 +- 0.163 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.170 (in-sample avg dev_std = 0.225)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.655
NEC for r=0.3 class 0 = 0.214 +- 0.301 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 1 = 0.221 +- 0.301 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 2 = 0.174 +- 0.301 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all KL = 0.234 +- 0.301 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all L1 = 0.206 +- 0.252 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.674
NEC for r=0.6 class 0 = 0.131 +- 0.236 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 1 = 0.151 +- 0.236 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 2 = 0.141 +- 0.236 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all KL = 0.142 +- 0.236 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all L1 = 0.144 +- 0.208 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.683
NEC for r=0.9 class 0 = 0.101 +- 0.162 (in-sample avg dev_std = 0.186)
NEC for r=0.9 class 1 = 0.091 +- 0.162 (in-sample avg dev_std = 0.186)
NEC for r=0.9 class 2 = 0.1 +- 0.162 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all KL = 0.078 +- 0.162 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all L1 = 0.096 +- 0.162 (in-sample avg dev_std = 0.186)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.686
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0 = 0.096 +- 0.155 (in-sample avg dev_std = 0.195)
NEC for r=1.0 class 1 = 0.085 +- 0.155 (in-sample avg dev_std = 0.195)
NEC for r=1.0 class 2 = 0.085 +- 0.155 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all KL = 0.07 +- 0.155 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all L1 = 0.088 +- 0.154 (in-sample avg dev_std = 0.195)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.559
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.57
NEC for r=0.3 class 0 = 0.243 +- 0.333 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1 = 0.27 +- 0.333 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 2 = 0.287 +- 0.333 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.321 +- 0.333 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.267 +- 0.270 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.586
NEC for r=0.6 class 0 = 0.159 +- 0.266 (in-sample avg dev_std = 0.290)
NEC for r=0.6 class 1 = 0.18 +- 0.266 (in-sample avg dev_std = 0.290)
NEC for r=0.6 class 2 = 0.214 +- 0.266 (in-sample avg dev_std = 0.290)
NEC for r=0.6 all KL = 0.188 +- 0.266 (in-sample avg dev_std = 0.290)
NEC for r=0.6 all L1 = 0.182 +- 0.227 (in-sample avg dev_std = 0.290)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.594
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.6
NEC for r=0.9 class 0 = 0.118 +- 0.203 (in-sample avg dev_std = 0.217)
NEC for r=0.9 class 1 = 0.123 +- 0.203 (in-sample avg dev_std = 0.217)
NEC for r=0.9 class 2 = 0.15 +- 0.203 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all KL = 0.106 +- 0.203 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all L1 = 0.127 +- 0.198 (in-sample avg dev_std = 0.217)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.606
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.608
NEC for r=1.0 class 0 = 0.118 +- 0.199 (in-sample avg dev_std = 0.220)
NEC for r=1.0 class 1 = 0.116 +- 0.199 (in-sample avg dev_std = 0.220)
NEC for r=1.0 class 2 = 0.148 +- 0.199 (in-sample avg dev_std = 0.220)
NEC for r=1.0 all KL = 0.104 +- 0.199 (in-sample avg dev_std = 0.220)
NEC for r=1.0 all L1 = 0.123 +- 0.194 (in-sample avg dev_std = 0.220)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.534
NEC for r=0.3 class 0 = 0.212 +- 0.335 (in-sample avg dev_std = 0.381)
NEC for r=0.3 class 1 = 0.271 +- 0.335 (in-sample avg dev_std = 0.381)
NEC for r=0.3 class 2 = 0.289 +- 0.335 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all KL = 0.312 +- 0.335 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all L1 = 0.26 +- 0.266 (in-sample avg dev_std = 0.381)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.539
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.553
NEC for r=0.6 class 0 = 0.143 +- 0.280 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1 = 0.201 +- 0.280 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 2 = 0.188 +- 0.280 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.192 +- 0.280 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.183 +- 0.238 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.559
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.561
NEC for r=0.9 class 0 = 0.096 +- 0.181 (in-sample avg dev_std = 0.214)
NEC for r=0.9 class 1 = 0.132 +- 0.181 (in-sample avg dev_std = 0.214)
NEC for r=0.9 class 2 = 0.131 +- 0.181 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all KL = 0.1 +- 0.181 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all L1 = 0.122 +- 0.183 (in-sample avg dev_std = 0.214)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.56
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.093 +- 0.182 (in-sample avg dev_std = 0.209)
NEC for r=1.0 class 1 = 0.125 +- 0.182 (in-sample avg dev_std = 0.209)
NEC for r=1.0 class 2 = 0.118 +- 0.182 (in-sample avg dev_std = 0.209)
NEC for r=1.0 all KL = 0.095 +- 0.182 (in-sample avg dev_std = 0.209)
NEC for r=1.0 all L1 = 0.115 +- 0.178 (in-sample avg dev_std = 0.209)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:42:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:29 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:31 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:32 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:32 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:34 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:42:36 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ACCURACY: 0.8614
Train Loss: 0.3803
ID Validation ACCURACY: 0.7076
ID Validation Loss: 0.8850
ID Test ACCURACY: 0.6931
ID Test Loss: 0.9033
OOD Validation ACCURACY: 0.6286
OOD Validation Loss: 1.1594
OOD Test ACCURACY: 0.5758
OOD Test Loss: 1.5271

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ACCURACY: 0.7409
Train Loss: 0.6213
ID Validation ACCURACY: 0.6661
ID Validation Loss: 0.7887
ID Test ACCURACY: 0.6733
ID Test Loss: 0.7724
OOD Validation ACCURACY: 0.6381
OOD Validation Loss: 0.8823
OOD Test ACCURACY: 0.5868
OOD Test Loss: 1.0592

[0m[1;37mINFO[0m: [1mChartInfo 0.6931 0.5758 0.6733 0.5868 0.6661 0.6381[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.612
SUFF++ for r=0.3 class 0 = 0.718 +- 0.110 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 class 1 = 0.74 +- 0.110 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 class 2 = 0.713 +- 0.110 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 all KL = 0.864 +- 0.110 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.3 all L1 = 0.727 +- 0.109 (in-sample avg dev_std = 0.289)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.677
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0 = 0.766 +- 0.121 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.121 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 class 2 = 0.772 +- 0.121 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all KL = 0.874 +- 0.121 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all L1 = 0.771 +- 0.128 (in-sample avg dev_std = 0.279)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.878 +- 0.055 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 1 = 0.874 +- 0.055 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 2 = 0.897 +- 0.055 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all KL = 0.964 +- 0.055 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.103 (in-sample avg dev_std = 0.133)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.595
SUFF++ for r=0.3 class 0 = 0.742 +- 0.102 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 class 1 = 0.744 +- 0.102 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 class 2 = 0.723 +- 0.102 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all KL = 0.884 +- 0.102 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all L1 = 0.739 +- 0.101 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.614
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0 = 0.794 +- 0.090 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.6 class 1 = 0.79 +- 0.090 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.6 class 2 = 0.782 +- 0.090 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.6 all KL = 0.907 +- 0.090 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.6 all L1 = 0.789 +- 0.112 (in-sample avg dev_std = 0.222)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.625
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.627
SUFF++ for r=0.9 class 0 = 0.869 +- 0.064 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 1 = 0.856 +- 0.064 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.064 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all KL = 0.956 +- 0.064 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.109 (in-sample avg dev_std = 0.129)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.525
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0 = 0.777 +- 0.085 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 1 = 0.768 +- 0.085 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 2 = 0.742 +- 0.085 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 all KL = 0.905 +- 0.085 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 all L1 = 0.764 +- 0.101 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.562
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.549
SUFF++ for r=0.6 class 0 = 0.823 +- 0.086 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 1 = 0.794 +- 0.086 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 class 2 = 0.786 +- 0.086 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all KL = 0.912 +- 0.086 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.6 all L1 = 0.8 +- 0.117 (in-sample avg dev_std = 0.218)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.575
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.566
SUFF++ for r=0.9 class 0 = 0.872 +- 0.060 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 1 = 0.852 +- 0.060 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.060 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all KL = 0.954 +- 0.060 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all L1 = 0.859 +- 0.114 (in-sample avg dev_std = 0.136)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.635
NEC for r=0.3 class 0 = 0.219 +- 0.099 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 1 = 0.198 +- 0.099 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 2 = 0.245 +- 0.099 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all KL = 0.08 +- 0.099 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all L1 = 0.216 +- 0.127 (in-sample avg dev_std = 0.170)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.677
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.665
NEC for r=0.6 class 0 = 0.157 +- 0.089 (in-sample avg dev_std = 0.168)
NEC for r=0.6 class 1 = 0.165 +- 0.089 (in-sample avg dev_std = 0.168)
NEC for r=0.6 class 2 = 0.177 +- 0.089 (in-sample avg dev_std = 0.168)
NEC for r=0.6 all KL = 0.062 +- 0.089 (in-sample avg dev_std = 0.168)
NEC for r=0.6 all L1 = 0.167 +- 0.119 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.684
NEC for r=0.9 class 0 = 0.116 +- 0.062 (in-sample avg dev_std = 0.125)
NEC for r=0.9 class 1 = 0.112 +- 0.062 (in-sample avg dev_std = 0.125)
NEC for r=0.9 class 2 = 0.118 +- 0.062 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all KL = 0.034 +- 0.062 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all L1 = 0.115 +- 0.097 (in-sample avg dev_std = 0.125)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0 = 0.102 +- 0.064 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 1 = 0.101 +- 0.064 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 2 = 0.1 +- 0.064 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all KL = 0.03 +- 0.064 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all L1 = 0.101 +- 0.094 (in-sample avg dev_std = 0.111)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.615
NEC for r=0.3 class 0 = 0.215 +- 0.082 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 1 = 0.218 +- 0.082 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 2 = 0.228 +- 0.082 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all KL = 0.075 +- 0.082 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all L1 = 0.219 +- 0.107 (in-sample avg dev_std = 0.165)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.614
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.623
NEC for r=0.6 class 0 = 0.175 +- 0.084 (in-sample avg dev_std = 0.148)
NEC for r=0.6 class 1 = 0.175 +- 0.084 (in-sample avg dev_std = 0.148)
NEC for r=0.6 class 2 = 0.174 +- 0.084 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all KL = 0.061 +- 0.084 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all L1 = 0.175 +- 0.116 (in-sample avg dev_std = 0.148)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.625
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.626
NEC for r=0.9 class 0 = 0.121 +- 0.053 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 1 = 0.124 +- 0.053 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 2 = 0.122 +- 0.053 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all KL = 0.036 +- 0.053 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all L1 = 0.123 +- 0.101 (in-sample avg dev_std = 0.116)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.639
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.631
NEC for r=1.0 class 0 = 0.111 +- 0.047 (in-sample avg dev_std = 0.101)
NEC for r=1.0 class 1 = 0.104 +- 0.047 (in-sample avg dev_std = 0.101)
NEC for r=1.0 class 2 = 0.107 +- 0.047 (in-sample avg dev_std = 0.101)
NEC for r=1.0 all KL = 0.029 +- 0.047 (in-sample avg dev_std = 0.101)
NEC for r=1.0 all L1 = 0.107 +- 0.089 (in-sample avg dev_std = 0.101)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.525
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.55
NEC for r=0.3 class 0 = 0.198 +- 0.076 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 1 = 0.201 +- 0.076 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 2 = 0.216 +- 0.076 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all KL = 0.067 +- 0.076 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all L1 = 0.204 +- 0.108 (in-sample avg dev_std = 0.158)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.562
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.569
NEC for r=0.6 class 0 = 0.146 +- 0.076 (in-sample avg dev_std = 0.144)
NEC for r=0.6 class 1 = 0.17 +- 0.076 (in-sample avg dev_std = 0.144)
NEC for r=0.6 class 2 = 0.17 +- 0.076 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all KL = 0.057 +- 0.076 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all L1 = 0.164 +- 0.119 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.575
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.577
NEC for r=0.9 class 0 = 0.104 +- 0.050 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 1 = 0.125 +- 0.050 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 2 = 0.121 +- 0.050 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all KL = 0.035 +- 0.050 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all L1 = 0.119 +- 0.102 (in-sample avg dev_std = 0.116)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.576
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.577
NEC for r=1.0 class 0 = 0.096 +- 0.051 (in-sample avg dev_std = 0.109)
NEC for r=1.0 class 1 = 0.114 +- 0.051 (in-sample avg dev_std = 0.109)
NEC for r=1.0 class 2 = 0.11 +- 0.051 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all KL = 0.031 +- 0.051 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all L1 = 0.108 +- 0.102 (in-sample avg dev_std = 0.109)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:48:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:13 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:15 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:16 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:16 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:18 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:48:20 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ACCURACY: 0.9174
Train Loss: 0.2354
ID Validation ACCURACY: 0.7094
ID Validation Loss: 0.8777
ID Test ACCURACY: 0.6643
ID Test Loss: 1.0338
OOD Validation ACCURACY: 0.6078
OOD Validation Loss: 1.3174
OOD Test ACCURACY: 0.5388
OOD Test Loss: 2.0252

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.8093
Train Loss: 0.4763
ID Validation ACCURACY: 0.7040
ID Validation Loss: 0.7643
ID Test ACCURACY: 0.6859
ID Test Loss: 0.8172
OOD Validation ACCURACY: 0.6426
OOD Validation Loss: 0.9870
OOD Test ACCURACY: 0.5916
OOD Test Loss: 1.2249

[0m[1;37mINFO[0m: [1mChartInfo 0.6643 0.5388 0.6859 0.5916 0.7040 0.6426[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.626
SUFF++ for r=0.3 class 0 = 0.68 +- 0.134 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 1 = 0.751 +- 0.134 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.134 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all KL = 0.833 +- 0.134 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all L1 = 0.718 +- 0.127 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.701
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0 = 0.736 +- 0.141 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 class 1 = 0.791 +- 0.141 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 class 2 = 0.733 +- 0.141 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 all KL = 0.85 +- 0.141 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.6 all L1 = 0.761 +- 0.152 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.7
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.694
SUFF++ for r=0.9 class 0 = 0.872 +- 0.069 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1 = 0.882 +- 0.069 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.069 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.954 +- 0.069 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.876 +- 0.113 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.614
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0 = 0.687 +- 0.142 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 1 = 0.725 +- 0.142 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 2 = 0.683 +- 0.142 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 all KL = 0.817 +- 0.142 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 all L1 = 0.706 +- 0.138 (in-sample avg dev_std = 0.310)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.624
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.603
SUFF++ for r=0.6 class 0 = 0.792 +- 0.117 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 1 = 0.783 +- 0.117 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.117 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 all KL = 0.876 +- 0.117 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 all L1 = 0.776 +- 0.143 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0 = 0.888 +- 0.069 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 1 = 0.864 +- 0.069 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 2 = 0.846 +- 0.069 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all KL = 0.952 +- 0.069 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all L1 = 0.866 +- 0.119 (in-sample avg dev_std = 0.148)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.529
SUFF++ for r=0.3 class 0 = 0.759 +- 0.108 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 1 = 0.738 +- 0.108 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 2 = 0.705 +- 0.108 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all KL = 0.864 +- 0.108 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all L1 = 0.736 +- 0.121 (in-sample avg dev_std = 0.272)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.523
SUFF++ for r=0.6 class 0 = 0.856 +- 0.095 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 1 = 0.801 +- 0.095 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 2 = 0.773 +- 0.095 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all KL = 0.91 +- 0.095 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all L1 = 0.808 +- 0.135 (in-sample avg dev_std = 0.216)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.524
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.515
SUFF++ for r=0.9 class 0 = 0.92 +- 0.053 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 1 = 0.872 +- 0.053 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.053 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all KL = 0.96 +- 0.053 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all L1 = 0.879 +- 0.105 (in-sample avg dev_std = 0.142)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.657
NEC for r=0.3 class 0 = 0.251 +- 0.125 (in-sample avg dev_std = 0.192)
NEC for r=0.3 class 1 = 0.194 +- 0.125 (in-sample avg dev_std = 0.192)
NEC for r=0.3 class 2 = 0.263 +- 0.125 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all KL = 0.102 +- 0.125 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all L1 = 0.227 +- 0.144 (in-sample avg dev_std = 0.192)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.701
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.684
NEC for r=0.6 class 0 = 0.184 +- 0.106 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 1 = 0.15 +- 0.106 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 2 = 0.184 +- 0.106 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all KL = 0.072 +- 0.106 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all L1 = 0.168 +- 0.136 (in-sample avg dev_std = 0.189)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.694
NEC for r=0.9 class 0 = 0.124 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 1 = 0.114 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 2 = 0.123 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all KL = 0.041 +- 0.071 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all L1 = 0.119 +- 0.106 (in-sample avg dev_std = 0.143)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.698
NEC for r=1.0 class 0 = 0.105 +- 0.059 (in-sample avg dev_std = 0.124)
NEC for r=1.0 class 1 = 0.095 +- 0.059 (in-sample avg dev_std = 0.124)
NEC for r=1.0 class 2 = 0.109 +- 0.059 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all KL = 0.033 +- 0.059 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all L1 = 0.102 +- 0.099 (in-sample avg dev_std = 0.124)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.614
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.619
NEC for r=0.3 class 0 = 0.279 +- 0.141 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 1 = 0.228 +- 0.141 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 2 = 0.261 +- 0.141 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all KL = 0.125 +- 0.141 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all L1 = 0.248 +- 0.153 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.624
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.618
NEC for r=0.6 class 0 = 0.187 +- 0.105 (in-sample avg dev_std = 0.183)
NEC for r=0.6 class 1 = 0.176 +- 0.105 (in-sample avg dev_std = 0.183)
NEC for r=0.6 class 2 = 0.211 +- 0.105 (in-sample avg dev_std = 0.183)
NEC for r=0.6 all KL = 0.082 +- 0.105 (in-sample avg dev_std = 0.183)
NEC for r=0.6 all L1 = 0.186 +- 0.142 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0 = 0.117 +- 0.072 (in-sample avg dev_std = 0.133)
NEC for r=0.9 class 1 = 0.127 +- 0.072 (in-sample avg dev_std = 0.133)
NEC for r=0.9 class 2 = 0.154 +- 0.072 (in-sample avg dev_std = 0.133)
NEC for r=0.9 all KL = 0.045 +- 0.072 (in-sample avg dev_std = 0.133)
NEC for r=0.9 all L1 = 0.13 +- 0.121 (in-sample avg dev_std = 0.133)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.604
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.608
NEC for r=1.0 class 0 = 0.097 +- 0.070 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1 = 0.118 +- 0.070 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 2 = 0.139 +- 0.070 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.04 +- 0.070 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.117 +- 0.115 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.544
NEC for r=0.3 class 0 = 0.22 +- 0.116 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1 = 0.231 +- 0.116 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 2 = 0.253 +- 0.116 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.102 +- 0.116 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.234 +- 0.140 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.533
NEC for r=0.6 class 0 = 0.128 +- 0.089 (in-sample avg dev_std = 0.163)
NEC for r=0.6 class 1 = 0.176 +- 0.089 (in-sample avg dev_std = 0.163)
NEC for r=0.6 class 2 = 0.178 +- 0.089 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all KL = 0.063 +- 0.089 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all L1 = 0.164 +- 0.130 (in-sample avg dev_std = 0.163)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.524
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.075 +- 0.057 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1 = 0.12 +- 0.057 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 2 = 0.138 +- 0.057 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.034 +- 0.057 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.113 +- 0.108 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.533
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.073 +- 0.064 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 1 = 0.113 +- 0.064 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 2 = 0.135 +- 0.064 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all KL = 0.036 +- 0.064 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all L1 = 0.108 +- 0.112 (in-sample avg dev_std = 0.116)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:54:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:03 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:05 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:06 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:06 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:08 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:54:10 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 68...
[0m[1;37mINFO[0m: [1mCheckpoint 68: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0049
ID Validation ACCURACY: 0.6949
ID Validation Loss: 2.4204
ID Test ACCURACY: 0.6715
ID Test Loss: 2.5571
OOD Validation ACCURACY: 0.6067
OOD Validation Loss: 3.0162
OOD Test ACCURACY: 0.5607
OOD Test Loss: 4.3468

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ACCURACY: 0.9197
Train Loss: 0.2315
ID Validation ACCURACY: 0.6859
ID Validation Loss: 0.9984
ID Test ACCURACY: 0.6895
ID Test Loss: 0.9864
OOD Validation ACCURACY: 0.6437
OOD Validation Loss: 1.1437
OOD Test ACCURACY: 0.5834
OOD Test Loss: 1.4921

[0m[1;37mINFO[0m: [1mChartInfo 0.6715 0.5607 0.6895 0.5834 0.6859 0.6437[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.578
SUFF++ for r=0.3 class 0 = 0.71 +- 0.353 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 class 1 = 0.701 +- 0.353 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 class 2 = 0.667 +- 0.353 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all KL = 0.477 +- 0.353 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all L1 = 0.694 +- 0.233 (in-sample avg dev_std = 0.602)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.646
SUFF++ for r=0.6 class 0 = 0.81 +- 0.295 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 1 = 0.83 +- 0.295 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 2 = 0.794 +- 0.295 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all KL = 0.744 +- 0.295 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all L1 = 0.815 +- 0.212 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
SUFF++ for r=0.9 class 0 = 0.887 +- 0.181 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 1 = 0.896 +- 0.181 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 2 = 0.891 +- 0.181 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all KL = 0.902 +- 0.181 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all L1 = 0.892 +- 0.167 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0 = 0.694 +- 0.323 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 class 1 = 0.596 +- 0.323 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.323 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 all KL = 0.385 +- 0.323 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 all L1 = 0.613 +- 0.234 (in-sample avg dev_std = 0.640)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.577
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.586
SUFF++ for r=0.6 class 0 = 0.807 +- 0.316 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 1 = 0.74 +- 0.316 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 2 = 0.708 +- 0.316 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all KL = 0.671 +- 0.316 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all L1 = 0.75 +- 0.240 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.606
SUFF++ for r=0.9 class 0 = 0.89 +- 0.200 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1 = 0.854 +- 0.200 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 2 = 0.822 +- 0.200 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.88 +- 0.200 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.195 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.52
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.486
SUFF++ for r=0.3 class 0 = 0.742 +- 0.350 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 class 1 = 0.622 +- 0.350 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 class 2 = 0.597 +- 0.350 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 all KL = 0.419 +- 0.350 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 all L1 = 0.647 +- 0.246 (in-sample avg dev_std = 0.629)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.534
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.523
SUFF++ for r=0.6 class 0 = 0.843 +- 0.321 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1 = 0.752 +- 0.321 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 2 = 0.715 +- 0.321 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.661 +- 0.321 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.230 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.541
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
SUFF++ for r=0.9 class 0 = 0.925 +- 0.152 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.152 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 2 = 0.864 +- 0.152 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all KL = 0.913 +- 0.152 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all L1 = 0.886 +- 0.164 (in-sample avg dev_std = 0.205)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.627
NEC for r=0.3 class 0 = 0.247 +- 0.366 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1 = 0.244 +- 0.366 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 2 = 0.251 +- 0.366 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.325 +- 0.366 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.247 +- 0.273 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0 = 0.173 +- 0.278 (in-sample avg dev_std = 0.323)
NEC for r=0.6 class 1 = 0.153 +- 0.278 (in-sample avg dev_std = 0.323)
NEC for r=0.6 class 2 = 0.177 +- 0.278 (in-sample avg dev_std = 0.323)
NEC for r=0.6 all KL = 0.191 +- 0.278 (in-sample avg dev_std = 0.323)
NEC for r=0.6 all L1 = 0.165 +- 0.222 (in-sample avg dev_std = 0.323)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0 = 0.128 +- 0.191 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 1 = 0.093 +- 0.191 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 2 = 0.109 +- 0.191 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all KL = 0.099 +- 0.191 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all L1 = 0.106 +- 0.169 (in-sample avg dev_std = 0.233)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0 = 0.103 +- 0.160 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 1 = 0.08 +- 0.160 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 2 = 0.093 +- 0.160 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all KL = 0.071 +- 0.160 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all L1 = 0.089 +- 0.154 (in-sample avg dev_std = 0.198)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.549
NEC for r=0.3 class 0 = 0.236 +- 0.370 (in-sample avg dev_std = 0.472)
NEC for r=0.3 class 1 = 0.336 +- 0.370 (in-sample avg dev_std = 0.472)
NEC for r=0.3 class 2 = 0.347 +- 0.370 (in-sample avg dev_std = 0.472)
NEC for r=0.3 all KL = 0.409 +- 0.370 (in-sample avg dev_std = 0.472)
NEC for r=0.3 all L1 = 0.313 +- 0.283 (in-sample avg dev_std = 0.472)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.577
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.591
NEC for r=0.6 class 0 = 0.166 +- 0.306 (in-sample avg dev_std = 0.368)
NEC for r=0.6 class 1 = 0.224 +- 0.306 (in-sample avg dev_std = 0.368)
NEC for r=0.6 class 2 = 0.245 +- 0.306 (in-sample avg dev_std = 0.368)
NEC for r=0.6 all KL = 0.249 +- 0.306 (in-sample avg dev_std = 0.368)
NEC for r=0.6 all L1 = 0.214 +- 0.236 (in-sample avg dev_std = 0.368)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.604
NEC for r=0.9 class 0 = 0.125 +- 0.211 (in-sample avg dev_std = 0.250)
NEC for r=0.9 class 1 = 0.151 +- 0.211 (in-sample avg dev_std = 0.250)
NEC for r=0.9 class 2 = 0.172 +- 0.211 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all KL = 0.13 +- 0.211 (in-sample avg dev_std = 0.250)
NEC for r=0.9 all L1 = 0.149 +- 0.201 (in-sample avg dev_std = 0.250)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.599
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.608
NEC for r=1.0 class 0 = 0.108 +- 0.185 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 1 = 0.128 +- 0.185 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 2 = 0.146 +- 0.185 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all KL = 0.098 +- 0.185 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all L1 = 0.127 +- 0.187 (in-sample avg dev_std = 0.214)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.52
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.51
NEC for r=0.3 class 0 = 0.18 +- 0.356 (in-sample avg dev_std = 0.421)
NEC for r=0.3 class 1 = 0.261 +- 0.356 (in-sample avg dev_std = 0.421)
NEC for r=0.3 class 2 = 0.286 +- 0.356 (in-sample avg dev_std = 0.421)
NEC for r=0.3 all KL = 0.323 +- 0.356 (in-sample avg dev_std = 0.421)
NEC for r=0.3 all L1 = 0.246 +- 0.267 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.534
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0 = 0.122 +- 0.288 (in-sample avg dev_std = 0.312)
NEC for r=0.6 class 1 = 0.195 +- 0.288 (in-sample avg dev_std = 0.312)
NEC for r=0.6 class 2 = 0.209 +- 0.288 (in-sample avg dev_std = 0.312)
NEC for r=0.6 all KL = 0.206 +- 0.288 (in-sample avg dev_std = 0.312)
NEC for r=0.6 all L1 = 0.179 +- 0.231 (in-sample avg dev_std = 0.312)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.541
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.097 +- 0.192 (in-sample avg dev_std = 0.214)
NEC for r=0.9 class 1 = 0.148 +- 0.192 (in-sample avg dev_std = 0.214)
NEC for r=0.9 class 2 = 0.147 +- 0.192 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all KL = 0.112 +- 0.192 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all L1 = 0.134 +- 0.191 (in-sample avg dev_std = 0.214)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.545
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.539
NEC for r=1.0 class 0 = 0.091 +- 0.163 (in-sample avg dev_std = 0.193)
NEC for r=1.0 class 1 = 0.119 +- 0.163 (in-sample avg dev_std = 0.193)
NEC for r=1.0 class 2 = 0.138 +- 0.163 (in-sample avg dev_std = 0.193)
NEC for r=1.0 all KL = 0.088 +- 0.163 (in-sample avg dev_std = 0.193)
NEC for r=1.0 all L1 = 0.116 +- 0.172 (in-sample avg dev_std = 0.193)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 10:59:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:51 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:53 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:54 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:54 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:56 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 10:59:58 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 83...
[0m[1;37mINFO[0m: [1mCheckpoint 83: 
-----------------------------------
Train ACCURACY: 0.9988
Train Loss: 0.0034
ID Validation ACCURACY: 0.7058
ID Validation Loss: 2.2920
ID Test ACCURACY: 0.6733
ID Test Loss: 2.5888
OOD Validation ACCURACY: 0.6252
OOD Validation Loss: 2.9282
OOD Test ACCURACY: 0.5559
OOD Test Loss: 3.9683

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.8857
Train Loss: 0.3079
ID Validation ACCURACY: 0.6715
ID Validation Loss: 0.8781
ID Test ACCURACY: 0.6787
ID Test Loss: 0.9051
OOD Validation ACCURACY: 0.6420
OOD Validation Loss: 1.0861
OOD Test ACCURACY: 0.5772
OOD Test Loss: 1.4643

[0m[1;37mINFO[0m: [1mChartInfo 0.6733 0.5559 0.6787 0.5772 0.6715 0.6420[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0 = 0.757 +- 0.312 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.312 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 class 2 = 0.634 +- 0.312 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 all KL = 0.509 +- 0.312 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.3 all L1 = 0.68 +- 0.219 (in-sample avg dev_std = 0.575)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.836 +- 0.290 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.290 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 class 2 = 0.726 +- 0.290 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 all KL = 0.71 +- 0.290 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 all L1 = 0.785 +- 0.217 (in-sample avg dev_std = 0.418)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0 = 0.912 +- 0.136 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.912 +- 0.136 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.136 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.923 +- 0.136 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.898 +- 0.148 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.551
SUFF++ for r=0.3 class 0 = 0.644 +- 0.299 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 class 1 = 0.633 +- 0.299 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 class 2 = 0.554 +- 0.299 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 all KL = 0.389 +- 0.299 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 all L1 = 0.619 +- 0.226 (in-sample avg dev_std = 0.629)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.626
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.601
SUFF++ for r=0.6 class 0 = 0.763 +- 0.308 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.762 +- 0.308 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.694 +- 0.308 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.661 +- 0.308 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.748 +- 0.232 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.627
SUFF++ for r=0.9 class 0 = 0.896 +- 0.171 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 class 1 = 0.885 +- 0.171 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 class 2 = 0.861 +- 0.171 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all KL = 0.906 +- 0.171 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all L1 = 0.883 +- 0.173 (in-sample avg dev_std = 0.201)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.495
SUFF++ for r=0.3 class 0 = 0.665 +- 0.298 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 1 = 0.631 +- 0.298 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 2 = 0.563 +- 0.298 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all KL = 0.396 +- 0.298 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all L1 = 0.623 +- 0.217 (in-sample avg dev_std = 0.620)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.528
SUFF++ for r=0.6 class 0 = 0.772 +- 0.304 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 1 = 0.74 +- 0.304 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 2 = 0.682 +- 0.304 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all KL = 0.624 +- 0.304 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all L1 = 0.734 +- 0.223 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.546
SUFF++ for r=0.9 class 0 = 0.893 +- 0.159 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 1 = 0.875 +- 0.159 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 2 = 0.847 +- 0.159 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all KL = 0.903 +- 0.159 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all L1 = 0.873 +- 0.173 (in-sample avg dev_std = 0.214)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.628
NEC for r=0.3 class 0 = 0.172 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 class 1 = 0.236 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 class 2 = 0.289 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all KL = 0.265 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all L1 = 0.235 +- 0.260 (in-sample avg dev_std = 0.351)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.652
NEC for r=0.6 class 0 = 0.108 +- 0.247 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 1 = 0.163 +- 0.247 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 2 = 0.182 +- 0.247 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all KL = 0.153 +- 0.247 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all L1 = 0.155 +- 0.216 (in-sample avg dev_std = 0.259)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.67
NEC for r=0.9 class 0 = 0.094 +- 0.164 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 1 = 0.099 +- 0.164 (in-sample avg dev_std = 0.192)
NEC for r=0.9 class 2 = 0.121 +- 0.164 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all KL = 0.076 +- 0.164 (in-sample avg dev_std = 0.192)
NEC for r=0.9 all L1 = 0.104 +- 0.162 (in-sample avg dev_std = 0.192)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.703
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.681
NEC for r=1.0 class 0 = 0.089 +- 0.151 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 1 = 0.084 +- 0.151 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 2 = 0.113 +- 0.151 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all KL = 0.066 +- 0.151 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all L1 = 0.093 +- 0.152 (in-sample avg dev_std = 0.186)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.593
NEC for r=0.3 class 0 = 0.229 +- 0.342 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 1 = 0.281 +- 0.342 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 2 = 0.319 +- 0.342 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all KL = 0.341 +- 0.342 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all L1 = 0.276 +- 0.267 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.626
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.617
NEC for r=0.6 class 0 = 0.143 +- 0.248 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 1 = 0.178 +- 0.248 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 2 = 0.206 +- 0.248 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all KL = 0.179 +- 0.248 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all L1 = 0.175 +- 0.220 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.626
NEC for r=0.9 class 0 = 0.098 +- 0.172 (in-sample avg dev_std = 0.197)
NEC for r=0.9 class 1 = 0.117 +- 0.172 (in-sample avg dev_std = 0.197)
NEC for r=0.9 class 2 = 0.137 +- 0.172 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all KL = 0.093 +- 0.172 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all L1 = 0.116 +- 0.177 (in-sample avg dev_std = 0.197)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.636
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.634
NEC for r=1.0 class 0 = 0.095 +- 0.155 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 1 = 0.101 +- 0.155 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 2 = 0.12 +- 0.155 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all KL = 0.077 +- 0.155 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all L1 = 0.103 +- 0.164 (in-sample avg dev_std = 0.186)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.534
NEC for r=0.3 class 0 = 0.246 +- 0.328 (in-sample avg dev_std = 0.392)
NEC for r=0.3 class 1 = 0.252 +- 0.328 (in-sample avg dev_std = 0.392)
NEC for r=0.3 class 2 = 0.302 +- 0.328 (in-sample avg dev_std = 0.392)
NEC for r=0.3 all KL = 0.323 +- 0.328 (in-sample avg dev_std = 0.392)
NEC for r=0.3 all L1 = 0.263 +- 0.260 (in-sample avg dev_std = 0.392)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.535
NEC for r=0.6 class 0 = 0.156 +- 0.251 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 1 = 0.178 +- 0.251 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 2 = 0.212 +- 0.251 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all KL = 0.18 +- 0.251 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all L1 = 0.181 +- 0.221 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.535
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.537
NEC for r=0.9 class 0 = 0.106 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1 = 0.122 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 2 = 0.156 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.098 +- 0.169 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.126 +- 0.176 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.54
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.094 +- 0.149 (in-sample avg dev_std = 0.189)
NEC for r=1.0 class 1 = 0.108 +- 0.149 (in-sample avg dev_std = 0.189)
NEC for r=1.0 class 2 = 0.128 +- 0.149 (in-sample avg dev_std = 0.189)
NEC for r=1.0 all KL = 0.078 +- 0.149 (in-sample avg dev_std = 0.189)
NEC for r=1.0 all L1 = 0.11 +- 0.162 (in-sample avg dev_std = 0.189)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.436, 0.681, 0.91, 1.0], 'all_L1': [0.661, 0.783, 0.9, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.864, 0.874, 0.964, 1.0], 'all_L1': [0.727, 0.771, 0.882, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.833, 0.85, 0.954, 1.0], 'all_L1': [0.718, 0.761, 0.876, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.477, 0.744, 0.902, 1.0], 'all_L1': [0.694, 0.815, 0.892, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.509, 0.71, 0.923, 1.0], 'all_L1': [0.68, 0.785, 0.898, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.234, 0.142, 0.078, 0.07], 'all_L1': [0.206, 0.144, 0.096, 0.088]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.062, 0.034, 0.03], 'all_L1': [0.216, 0.167, 0.115, 0.101]}), defaultdict(<class 'list'>, {'all_KL': [0.102, 0.072, 0.041, 0.033], 'all_L1': [0.227, 0.168, 0.119, 0.102]}), defaultdict(<class 'list'>, {'all_KL': [0.325, 0.191, 0.099, 0.071], 'all_L1': [0.247, 0.165, 0.106, 0.089]}), defaultdict(<class 'list'>, {'all_KL': [0.265, 0.153, 0.076, 0.066], 'all_L1': [0.235, 0.155, 0.104, 0.093]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.498, 0.705, 0.911, 1.0], 'all_L1': [0.67, 0.773, 0.885, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.884, 0.907, 0.956, 1.0], 'all_L1': [0.739, 0.789, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.817, 0.876, 0.952, 1.0], 'all_L1': [0.706, 0.776, 0.866, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.385, 0.671, 0.88, 1.0], 'all_L1': [0.613, 0.75, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.389, 0.661, 0.906, 1.0], 'all_L1': [0.619, 0.748, 0.883, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.321, 0.188, 0.106, 0.104], 'all_L1': [0.267, 0.182, 0.127, 0.123]}), defaultdict(<class 'list'>, {'all_KL': [0.075, 0.061, 0.036, 0.029], 'all_L1': [0.219, 0.175, 0.123, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.125, 0.082, 0.045, 0.04], 'all_L1': [0.248, 0.186, 0.13, 0.117]}), defaultdict(<class 'list'>, {'all_KL': [0.409, 0.249, 0.13, 0.098], 'all_L1': [0.313, 0.214, 0.149, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.341, 0.179, 0.093, 0.077], 'all_L1': [0.276, 0.175, 0.116, 0.103]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.455, 0.662, 0.903, 1.0], 'all_L1': [0.647, 0.758, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.905, 0.912, 0.954, 1.0], 'all_L1': [0.764, 0.8, 0.859, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.864, 0.91, 0.96, 1.0], 'all_L1': [0.736, 0.808, 0.879, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.419, 0.661, 0.913, 1.0], 'all_L1': [0.647, 0.766, 0.886, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.396, 0.624, 0.903, 1.0], 'all_L1': [0.623, 0.734, 0.873, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.312, 0.192, 0.1, 0.095], 'all_L1': [0.26, 0.183, 0.122, 0.115]}), defaultdict(<class 'list'>, {'all_KL': [0.067, 0.057, 0.035, 0.031], 'all_L1': [0.204, 0.164, 0.119, 0.108]}), defaultdict(<class 'list'>, {'all_KL': [0.102, 0.063, 0.034, 0.036], 'all_L1': [0.234, 0.164, 0.113, 0.108]}), defaultdict(<class 'list'>, {'all_KL': [0.323, 0.206, 0.112, 0.088], 'all_L1': [0.246, 0.179, 0.134, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.323, 0.18, 0.098, 0.078], 'all_L1': [0.263, 0.181, 0.126, 0.11]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.696 +- 0.024, 0.783 +- 0.018, 0.890 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.624 +- 0.185, 0.772 +- 0.077, 0.931 +- 0.024, 1.000 +- 0.000
suff++_acc_int  =  0.597 +- 0.020, 0.650 +- 0.010, 0.685 +- 0.006
nec class all_L1  =  0.226 +- 0.014, 0.160 +- 0.009, 0.108 +- 0.008, 0.095 +- 0.006
nec class all_KL  =  0.201 +- 0.095, 0.124 +- 0.049, 0.066 +- 0.024, 0.054 +- 0.018
nec_acc_int  =  0.641 +- 0.013, 0.668 +- 0.011, 0.683 +- 0.008, 0.687 +- 0.006

Eval split val
suff++ class all_L1  =  0.669 +- 0.049, 0.767 +- 0.016, 0.870 +- 0.012, 1.000 +- 0.000
suff++ class all_KL  =  0.595 +- 0.214, 0.764 +- 0.106, 0.921 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.559 +- 0.027, 0.599 +- 0.011, 0.612 +- 0.012
nec class all_L1  =  0.265 +- 0.031, 0.186 +- 0.014, 0.129 +- 0.011, 0.115 +- 0.009
nec class all_KL  =  0.254 +- 0.130, 0.152 +- 0.070, 0.082 +- 0.036, 0.070 +- 0.030
nec_acc_int  =  0.589 +- 0.027, 0.607 +- 0.015, 0.613 +- 0.011, 0.618 +- 0.012

Eval split test
suff++ class all_L1  =  0.683 +- 0.056, 0.773 +- 0.027, 0.876 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.608 +- 0.227, 0.754 +- 0.129, 0.927 +- 0.025, 1.000 +- 0.000
suff++_acc_int  =  0.507 +- 0.018, 0.532 +- 0.010, 0.543 +- 0.017
nec class all_L1  =  0.241 +- 0.021, 0.174 +- 0.008, 0.123 +- 0.007, 0.111 +- 0.003
nec class all_KL  =  0.225 +- 0.116, 0.140 +- 0.066, 0.076 +- 0.034, 0.066 +- 0.027
nec_acc_int  =  0.534 +- 0.014, 0.545 +- 0.014, 0.548 +- 0.018, 0.552 +- 0.017


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.461 +- 0.015, 0.471 +- 0.010, 0.499 +- 0.001, 0.547 +- 0.003
Faith. Armon (L1)= 		  =  0.341 +- 0.017, 0.265 +- 0.013, 0.192 +- 0.013, 0.173 +- 0.010
Faith. GMean (L1)= 	  =  0.397 +- 0.015, 0.354 +- 0.011, 0.310 +- 0.010, 0.307 +- 0.010
Faith. Aritm (KL)= 		  =  0.412 +- 0.052, 0.448 +- 0.023, 0.498 +- 0.002, 0.527 +- 0.009
Faith. Armon (KL)= 		  =  0.274 +- 0.094, 0.208 +- 0.072, 0.121 +- 0.043, 0.102 +- 0.033
Faith. GMean (KL)= 	  =  0.327 +- 0.048, 0.300 +- 0.053, 0.242 +- 0.045, 0.229 +- 0.042

Eval split val
Faith. Aritm (L1)= 		  =  0.467 +- 0.011, 0.477 +- 0.008, 0.500 +- 0.005, 0.558 +- 0.005
Faith. Armon (L1)= 		  =  0.377 +- 0.025, 0.300 +- 0.018, 0.224 +- 0.016, 0.207 +- 0.015
Faith. GMean (L1)= 	  =  0.419 +- 0.012, 0.378 +- 0.013, 0.335 +- 0.013, 0.339 +- 0.014
Faith. Aritm (KL)= 		  =  0.424 +- 0.044, 0.458 +- 0.023, 0.502 +- 0.005, 0.535 +- 0.015
Faith. Armon (KL)= 		  =  0.301 +- 0.104, 0.241 +- 0.094, 0.148 +- 0.061, 0.129 +- 0.053
Faith. GMean (KL)= 	  =  0.348 +- 0.054, 0.324 +- 0.064, 0.266 +- 0.060, 0.257 +- 0.061

Eval split test
Faith. Aritm (L1)= 		  =  0.462 +- 0.018, 0.474 +- 0.010, 0.499 +- 0.007, 0.556 +- 0.002
Faith. Armon (L1)= 		  =  0.355 +- 0.018, 0.284 +- 0.010, 0.215 +- 0.011, 0.200 +- 0.006
Faith. GMean (L1)= 	  =  0.405 +- 0.007, 0.367 +- 0.004, 0.328 +- 0.010, 0.334 +- 0.005
Faith. Aritm (KL)= 		  =  0.417 +- 0.056, 0.447 +- 0.033, 0.501 +- 0.006, 0.533 +- 0.013
Faith. Armon (KL)= 		  =  0.280 +- 0.105, 0.223 +- 0.091, 0.138 +- 0.059, 0.122 +- 0.048
Faith. GMean (KL)= 	  =  0.329 +- 0.050, 0.306 +- 0.060, 0.256 +- 0.061, 0.250 +- 0.056
Computed for split load_split = id



Completed in  0:29:01.924805  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:05:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/08/2024 11:05:59 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:03 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:07 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:10 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:06:14 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ROC-AUC: 0.9729
Train Loss: 0.0639
ID Validation ROC-AUC: 0.8522
ID Validation Loss: 0.1516
ID Test ROC-AUC: 0.8113
ID Test Loss: 0.1412
OOD Validation ROC-AUC: 0.7689
OOD Validation Loss: 0.1537
OOD Test ROC-AUC: 0.7319
OOD Test Loss: 0.1081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ROC-AUC: 0.9776
Train Loss: 0.0639
ID Validation ROC-AUC: 0.8381
ID Validation Loss: 0.1455
ID Test ROC-AUC: 0.7990
ID Test Loss: 0.1369
OOD Validation ROC-AUC: 0.7828
OOD Validation Loss: 0.1353
OOD Test ROC-AUC: 0.7122
OOD Test Loss: 0.1048

[0m[1;37mINFO[0m: [1mChartInfo 0.8113 0.7319 0.7990 0.7122 0.8381 0.7828[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/08/2024 11:06:15 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/08/2024 11:06:18 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/08/2024 11:06:19 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.616
SUFF++ for r=0.3 class 0.0 = 0.934 +- 0.167 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 1.0 = 0.886 +- 0.167 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all KL = 0.889 +- 0.167 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all L1 = 0.91 +- 0.120 (in-sample avg dev_std = 0.227)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0.0 = 0.952 +- 0.179 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.6 class 1.0 = 0.8 +- 0.179 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.6 all KL = 0.878 +- 0.179 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.6 all L1 = 0.876 +- 0.171 (in-sample avg dev_std = 0.239)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.82
SUFF++ for r=0.9 class 0.0 = 0.975 +- 0.140 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 class 1.0 = 0.857 +- 0.140 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all KL = 0.936 +- 0.140 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all L1 = 0.916 +- 0.143 (in-sample avg dev_std = 0.179)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.603
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
SUFF++ for r=0.3 class 0.0 = 0.97 +- 0.101 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.3 class 1.0 = 0.933 +- 0.101 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.3 all KL = 0.947 +- 0.101 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.3 all L1 = 0.952 +- 0.067 (in-sample avg dev_std = 0.140)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.721
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.711
SUFF++ for r=0.6 class 0.0 = 0.976 +- 0.098 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 class 1.0 = 0.89 +- 0.098 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all KL = 0.945 +- 0.098 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all L1 = 0.933 +- 0.109 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0.0 = 0.982 +- 0.068 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 class 1.0 = 0.918 +- 0.068 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 all KL = 0.971 +- 0.068 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.099 (in-sample avg dev_std = 0.114)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.623
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0.0 = 0.975 +- 0.069 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 class 1.0 = 0.951 +- 0.069 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 all KL = 0.966 +- 0.069 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.3 all L1 = 0.963 +- 0.054 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.661
SUFF++ for r=0.6 class 0.0 = 0.977 +- 0.153 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 1.0 = 0.893 +- 0.153 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all KL = 0.93 +- 0.153 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all L1 = 0.935 +- 0.128 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.774
SUFF++ for r=0.9 class 0.0 = 0.987 +- 0.072 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 class 1.0 = 0.935 +- 0.072 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all KL = 0.972 +- 0.072 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.085 (in-sample avg dev_std = 0.096)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
NEC for r=0.3 class 0.0 = 0.034 +- 0.111 (in-sample avg dev_std = 0.114)
NEC for r=0.3 class 1.0 = 0.102 +- 0.111 (in-sample avg dev_std = 0.114)
NEC for r=0.3 all KL = 0.054 +- 0.111 (in-sample avg dev_std = 0.114)
NEC for r=0.3 all L1 = 0.068 +- 0.121 (in-sample avg dev_std = 0.114)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.734
NEC for r=0.6 class 0.0 = 0.027 +- 0.134 (in-sample avg dev_std = 0.169)
NEC for r=0.6 class 1.0 = 0.165 +- 0.134 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all KL = 0.069 +- 0.134 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all L1 = 0.096 +- 0.158 (in-sample avg dev_std = 0.169)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.796
NEC for r=0.9 class 0.0 = 0.032 +- 0.205 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 1.0 = 0.222 +- 0.205 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all KL = 0.112 +- 0.205 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all L1 = 0.127 +- 0.193 (in-sample avg dev_std = 0.243)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.8
NEC for r=1.0 class 0.0 = 0.029 +- 0.211 (in-sample avg dev_std = 0.250)
NEC for r=1.0 class 1.0 = 0.22 +- 0.211 (in-sample avg dev_std = 0.250)
NEC for r=1.0 all KL = 0.114 +- 0.211 (in-sample avg dev_std = 0.250)
NEC for r=1.0 all L1 = 0.124 +- 0.203 (in-sample avg dev_std = 0.250)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.603
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.654
NEC for r=0.3 class 0.0 = 0.022 +- 0.098 (in-sample avg dev_std = 0.103)
NEC for r=0.3 class 1.0 = 0.07 +- 0.098 (in-sample avg dev_std = 0.103)
NEC for r=0.3 all KL = 0.044 +- 0.098 (in-sample avg dev_std = 0.103)
NEC for r=0.3 all L1 = 0.046 +- 0.074 (in-sample avg dev_std = 0.103)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.721
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.691
NEC for r=0.6 class 0.0 = 0.026 +- 0.117 (in-sample avg dev_std = 0.151)
NEC for r=0.6 class 1.0 = 0.118 +- 0.117 (in-sample avg dev_std = 0.151)
NEC for r=0.6 all KL = 0.055 +- 0.117 (in-sample avg dev_std = 0.151)
NEC for r=0.6 all L1 = 0.072 +- 0.130 (in-sample avg dev_std = 0.151)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.766
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
NEC for r=0.9 class 0.0 = 0.025 +- 0.133 (in-sample avg dev_std = 0.168)
NEC for r=0.9 class 1.0 = 0.128 +- 0.133 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all KL = 0.06 +- 0.133 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all L1 = 0.077 +- 0.136 (in-sample avg dev_std = 0.168)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.775
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.713
NEC for r=1.0 class 0.0 = 0.018 +- 0.116 (in-sample avg dev_std = 0.158)
NEC for r=1.0 class 1.0 = 0.125 +- 0.116 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all KL = 0.052 +- 0.116 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all L1 = 0.071 +- 0.130 (in-sample avg dev_std = 0.158)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.623
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.594
NEC for r=0.3 class 0.0 = 0.023 +- 0.110 (in-sample avg dev_std = 0.133)
NEC for r=0.3 class 1.0 = 0.063 +- 0.110 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all KL = 0.04 +- 0.110 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all L1 = 0.043 +- 0.084 (in-sample avg dev_std = 0.133)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.715
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.609
NEC for r=0.6 class 0.0 = 0.021 +- 0.143 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.079 +- 0.143 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.05 +- 0.143 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.05 +- 0.114 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.707
NEC for r=0.9 class 0.0 = 0.014 +- 0.174 (in-sample avg dev_std = 0.181)
NEC for r=0.9 class 1.0 = 0.106 +- 0.174 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all KL = 0.06 +- 0.174 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all L1 = 0.06 +- 0.139 (in-sample avg dev_std = 0.181)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.783
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.751
NEC for r=1.0 class 0.0 = 0.01 +- 0.146 (in-sample avg dev_std = 0.158)
NEC for r=1.0 class 1.0 = 0.099 +- 0.146 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all KL = 0.045 +- 0.146 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all L1 = 0.055 +- 0.125 (in-sample avg dev_std = 0.158)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:07:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/08/2024 11:07:51 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:07:55 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:07:59 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:02 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 170...
[0m[1;37mINFO[0m: [1mCheckpoint 170: 
-----------------------------------
Train ROC-AUC: 0.9892
Train Loss: 0.0470
ID Validation ROC-AUC: 0.8419
ID Validation Loss: 0.1603
ID Test ROC-AUC: 0.8082
ID Test Loss: 0.1430
OOD Validation ROC-AUC: 0.7492
OOD Validation Loss: 0.1646
OOD Test ROC-AUC: 0.7304
OOD Test Loss: 0.1121

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 98...
[0m[1;37mINFO[0m: [1mCheckpoint 98: 
-----------------------------------
Train ROC-AUC: 0.9422
Train Loss: 0.0833
ID Validation ROC-AUC: 0.8126
ID Validation Loss: 0.1422
ID Test ROC-AUC: 0.8015
ID Test Loss: 0.1249
OOD Validation ROC-AUC: 0.7780
OOD Validation Loss: 0.1259
OOD Test ROC-AUC: 0.6962
OOD Test Loss: 0.0973

[0m[1;37mINFO[0m: [1mChartInfo 0.8082 0.7304 0.8015 0.6962 0.8126 0.7780[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/08/2024 11:08:06 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/08/2024 11:08:08 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/08/2024 11:08:10 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.653
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.626
SUFF++ for r=0.3 class 0.0 = 0.94 +- 0.126 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.3 class 1.0 = 0.862 +- 0.126 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.3 all KL = 0.918 +- 0.126 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.3 all L1 = 0.901 +- 0.121 (in-sample avg dev_std = 0.192)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.803
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.711
SUFF++ for r=0.6 class 0.0 = 0.963 +- 0.171 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 class 1.0 = 0.802 +- 0.171 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all KL = 0.905 +- 0.171 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all L1 = 0.883 +- 0.184 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.981 +- 0.201 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1.0 = 0.852 +- 0.201 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.917 +- 0.201 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.917 +- 0.164 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
SUFF++ for r=0.3 class 0.0 = 0.965 +- 0.110 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.3 class 1.0 = 0.917 +- 0.110 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.3 all KL = 0.947 +- 0.110 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.3 all L1 = 0.941 +- 0.083 (in-sample avg dev_std = 0.134)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.642
SUFF++ for r=0.6 class 0.0 = 0.979 +- 0.131 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 1.0 = 0.863 +- 0.131 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all KL = 0.946 +- 0.131 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all L1 = 0.921 +- 0.156 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.728
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
SUFF++ for r=0.9 class 0.0 = 0.992 +- 0.127 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 1.0 = 0.905 +- 0.127 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all KL = 0.962 +- 0.127 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.124 (in-sample avg dev_std = 0.170)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.538
SUFF++ for r=0.3 class 0.0 = 0.962 +- 0.100 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.3 class 1.0 = 0.923 +- 0.100 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.3 all KL = 0.952 +- 0.100 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.3 all L1 = 0.942 +- 0.088 (in-sample avg dev_std = 0.130)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.72
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0.0 = 0.985 +- 0.145 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.6 class 1.0 = 0.879 +- 0.145 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.6 all KL = 0.936 +- 0.145 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.6 all L1 = 0.932 +- 0.129 (in-sample avg dev_std = 0.152)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.774
SUFF++ for r=0.9 class 0.0 = 0.998 +- 0.106 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 class 1.0 = 0.922 +- 0.106 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all KL = 0.968 +- 0.106 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.112 (in-sample avg dev_std = 0.131)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.653
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.676
NEC for r=0.3 class 0.0 = 0.044 +- 0.106 (in-sample avg dev_std = 0.106)
NEC for r=0.3 class 1.0 = 0.124 +- 0.106 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all KL = 0.056 +- 0.106 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all L1 = 0.084 +- 0.118 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.803
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.746
NEC for r=0.6 class 0.0 = 0.029 +- 0.159 (in-sample avg dev_std = 0.169)
NEC for r=0.6 class 1.0 = 0.185 +- 0.159 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all KL = 0.078 +- 0.159 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all L1 = 0.107 +- 0.180 (in-sample avg dev_std = 0.169)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.772
NEC for r=0.9 class 0.0 = 0.018 +- 0.281 (in-sample avg dev_std = 0.282)
NEC for r=0.9 class 1.0 = 0.253 +- 0.281 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all KL = 0.15 +- 0.281 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all L1 = 0.135 +- 0.232 (in-sample avg dev_std = 0.282)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.857
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.782
NEC for r=1.0 class 0.0 = 0.019 +- 0.295 (in-sample avg dev_std = 0.303)
NEC for r=1.0 class 1.0 = 0.265 +- 0.295 (in-sample avg dev_std = 0.303)
NEC for r=1.0 all KL = 0.164 +- 0.295 (in-sample avg dev_std = 0.303)
NEC for r=1.0 all L1 = 0.142 +- 0.239 (in-sample avg dev_std = 0.303)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.599
NEC for r=0.3 class 0.0 = 0.039 +- 0.119 (in-sample avg dev_std = 0.127)
NEC for r=0.3 class 1.0 = 0.1 +- 0.119 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all KL = 0.064 +- 0.119 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all L1 = 0.07 +- 0.094 (in-sample avg dev_std = 0.127)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.685
NEC for r=0.6 class 0.0 = 0.022 +- 0.114 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 1.0 = 0.122 +- 0.114 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all KL = 0.044 +- 0.114 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all L1 = 0.072 +- 0.137 (in-sample avg dev_std = 0.117)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.728
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0.0 = 0.016 +- 0.212 (in-sample avg dev_std = 0.200)
NEC for r=0.9 class 1.0 = 0.178 +- 0.212 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all KL = 0.094 +- 0.212 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all L1 = 0.097 +- 0.197 (in-sample avg dev_std = 0.200)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.709
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.686
NEC for r=1.0 class 0.0 = 0.013 +- 0.224 (in-sample avg dev_std = 0.212)
NEC for r=1.0 class 1.0 = 0.192 +- 0.224 (in-sample avg dev_std = 0.212)
NEC for r=1.0 all KL = 0.103 +- 0.224 (in-sample avg dev_std = 0.212)
NEC for r=1.0 all L1 = 0.102 +- 0.207 (in-sample avg dev_std = 0.212)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.601
NEC for r=0.3 class 0.0 = 0.036 +- 0.111 (in-sample avg dev_std = 0.120)
NEC for r=0.3 class 1.0 = 0.078 +- 0.111 (in-sample avg dev_std = 0.120)
NEC for r=0.3 all KL = 0.05 +- 0.111 (in-sample avg dev_std = 0.120)
NEC for r=0.3 all L1 = 0.057 +- 0.092 (in-sample avg dev_std = 0.120)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.72
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.682
NEC for r=0.6 class 0.0 = 0.012 +- 0.127 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.101 +- 0.127 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.045 +- 0.127 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.057 +- 0.130 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.718
NEC for r=0.9 class 0.0 = 0.005 +- 0.195 (in-sample avg dev_std = 0.150)
NEC for r=0.9 class 1.0 = 0.138 +- 0.195 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all KL = 0.069 +- 0.195 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all L1 = 0.071 +- 0.179 (in-sample avg dev_std = 0.150)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.793
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.739
NEC for r=1.0 class 0.0 = 0.003 +- 0.213 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1.0 = 0.136 +- 0.213 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.072 +- 0.213 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.069 +- 0.180 (in-sample avg dev_std = 0.191)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:09:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:43 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:47 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:51 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:54 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ROC-AUC: 0.9914
Train Loss: 0.0436
ID Validation ROC-AUC: 0.8439
ID Validation Loss: 0.1547
ID Test ROC-AUC: 0.8014
ID Test Loss: 0.1463
OOD Validation ROC-AUC: 0.7797
OOD Validation Loss: 0.1455
OOD Test ROC-AUC: 0.7537
OOD Test Loss: 0.1123

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ROC-AUC: 0.9708
Train Loss: 0.0685
ID Validation ROC-AUC: 0.8312
ID Validation Loss: 0.1580
ID Test ROC-AUC: 0.7951
ID Test Loss: 0.1480
OOD Validation ROC-AUC: 0.7848
OOD Validation Loss: 0.1435
OOD Test ROC-AUC: 0.7454
OOD Test Loss: 0.1005

[0m[1;37mINFO[0m: [1mChartInfo 0.8014 0.7537 0.7951 0.7454 0.8312 0.7848[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/08/2024 11:09:58 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/08/2024 11:10:00 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/08/2024 11:10:01 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.644
SUFF++ for r=0.3 class 0.0 = 0.925 +- 0.183 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 class 1.0 = 0.856 +- 0.183 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all KL = 0.871 +- 0.183 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all L1 = 0.89 +- 0.142 (in-sample avg dev_std = 0.265)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.79
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.722
SUFF++ for r=0.6 class 0.0 = 0.946 +- 0.171 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.6 class 1.0 = 0.809 +- 0.171 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.6 all KL = 0.89 +- 0.171 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.6 all L1 = 0.878 +- 0.166 (in-sample avg dev_std = 0.232)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0.0 = 0.968 +- 0.165 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 class 1.0 = 0.861 +- 0.165 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all KL = 0.917 +- 0.165 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.9 all L1 = 0.915 +- 0.148 (in-sample avg dev_std = 0.225)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
SUFF++ for r=0.3 class 0.0 = 0.939 +- 0.137 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.3 class 1.0 = 0.898 +- 0.137 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.3 all KL = 0.899 +- 0.137 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.3 all L1 = 0.919 +- 0.094 (in-sample avg dev_std = 0.206)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.734
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.7
SUFF++ for r=0.6 class 0.0 = 0.957 +- 0.140 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 class 1.0 = 0.835 +- 0.140 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all KL = 0.907 +- 0.140 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all L1 = 0.896 +- 0.142 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.792
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.781
SUFF++ for r=0.9 class 0.0 = 0.983 +- 0.101 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 1.0 = 0.914 +- 0.101 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all KL = 0.962 +- 0.101 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all L1 = 0.948 +- 0.105 (in-sample avg dev_std = 0.142)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.514
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0.0 = 0.963 +- 0.135 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 1.0 = 0.93 +- 0.135 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 all KL = 0.942 +- 0.135 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 all L1 = 0.947 +- 0.112 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.694
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
SUFF++ for r=0.6 class 0.0 = 0.98 +- 0.151 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 1.0 = 0.878 +- 0.151 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 all KL = 0.915 +- 0.151 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 all L1 = 0.929 +- 0.127 (in-sample avg dev_std = 0.191)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.784
SUFF++ for r=0.9 class 0.0 = 0.99 +- 0.086 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 1.0 = 0.926 +- 0.086 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all KL = 0.967 +- 0.086 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.096 (in-sample avg dev_std = 0.125)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.686
NEC for r=0.3 class 0.0 = 0.032 +- 0.147 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 1.0 = 0.138 +- 0.147 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all KL = 0.071 +- 0.147 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all L1 = 0.085 +- 0.147 (in-sample avg dev_std = 0.140)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.79
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.742
NEC for r=0.6 class 0.0 = 0.034 +- 0.142 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1.0 = 0.17 +- 0.142 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.072 +- 0.142 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.102 +- 0.163 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.786
NEC for r=0.9 class 0.0 = 0.03 +- 0.250 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 1.0 = 0.241 +- 0.250 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all KL = 0.139 +- 0.250 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all L1 = 0.135 +- 0.220 (in-sample avg dev_std = 0.257)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0.0 = 0.029 +- 0.278 (in-sample avg dev_std = 0.284)
NEC for r=1.0 class 1.0 = 0.261 +- 0.278 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all KL = 0.162 +- 0.278 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all L1 = 0.145 +- 0.233 (in-sample avg dev_std = 0.284)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.635
NEC for r=0.3 class 0.0 = 0.036 +- 0.143 (in-sample avg dev_std = 0.152)
NEC for r=0.3 class 1.0 = 0.11 +- 0.143 (in-sample avg dev_std = 0.152)
NEC for r=0.3 all KL = 0.074 +- 0.143 (in-sample avg dev_std = 0.152)
NEC for r=0.3 all L1 = 0.073 +- 0.118 (in-sample avg dev_std = 0.152)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.734
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.683
NEC for r=0.6 class 0.0 = 0.04 +- 0.147 (in-sample avg dev_std = 0.180)
NEC for r=0.6 class 1.0 = 0.148 +- 0.147 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all KL = 0.074 +- 0.147 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all L1 = 0.094 +- 0.149 (in-sample avg dev_std = 0.180)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.792
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.744
NEC for r=0.9 class 0.0 = 0.026 +- 0.180 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 1.0 = 0.155 +- 0.180 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all KL = 0.083 +- 0.180 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all L1 = 0.09 +- 0.170 (in-sample avg dev_std = 0.184)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.785
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.748
NEC for r=1.0 class 0.0 = 0.019 +- 0.204 (in-sample avg dev_std = 0.207)
NEC for r=1.0 class 1.0 = 0.172 +- 0.204 (in-sample avg dev_std = 0.207)
NEC for r=1.0 all KL = 0.092 +- 0.204 (in-sample avg dev_std = 0.207)
NEC for r=1.0 all L1 = 0.096 +- 0.186 (in-sample avg dev_std = 0.207)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.514
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.598
NEC for r=0.3 class 0.0 = 0.028 +- 0.159 (in-sample avg dev_std = 0.124)
NEC for r=0.3 class 1.0 = 0.081 +- 0.159 (in-sample avg dev_std = 0.124)
NEC for r=0.3 all KL = 0.053 +- 0.159 (in-sample avg dev_std = 0.124)
NEC for r=0.3 all L1 = 0.054 +- 0.132 (in-sample avg dev_std = 0.124)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.694
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.656
NEC for r=0.6 class 0.0 = 0.022 +- 0.160 (in-sample avg dev_std = 0.143)
NEC for r=0.6 class 1.0 = 0.095 +- 0.160 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all KL = 0.058 +- 0.160 (in-sample avg dev_std = 0.143)
NEC for r=0.6 all L1 = 0.059 +- 0.137 (in-sample avg dev_std = 0.143)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.733
NEC for r=0.9 class 0.0 = 0.009 +- 0.202 (in-sample avg dev_std = 0.207)
NEC for r=0.9 class 1.0 = 0.135 +- 0.202 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all KL = 0.072 +- 0.202 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all L1 = 0.072 +- 0.170 (in-sample avg dev_std = 0.207)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.816
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.736
NEC for r=1.0 class 0.0 = 0.009 +- 0.204 (in-sample avg dev_std = 0.214)
NEC for r=1.0 class 1.0 = 0.126 +- 0.204 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all KL = 0.074 +- 0.204 (in-sample avg dev_std = 0.214)
NEC for r=1.0 all L1 = 0.067 +- 0.155 (in-sample avg dev_std = 0.214)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:11:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:34 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:38 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:42 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:45 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ROC-AUC: 0.9728
Train Loss: 0.0679
ID Validation ROC-AUC: 0.8537
ID Validation Loss: 0.1457
ID Test ROC-AUC: 0.8140
ID Test Loss: 0.1315
OOD Validation ROC-AUC: 0.7482
OOD Validation Loss: 0.1428
OOD Test ROC-AUC: 0.7319
OOD Test Loss: 0.1080

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.9890
Train Loss: 0.0494
ID Validation ROC-AUC: 0.8399
ID Validation Loss: 0.1573
ID Test ROC-AUC: 0.8171
ID Test Loss: 0.1410
OOD Validation ROC-AUC: 0.7829
OOD Validation Loss: 0.1443
OOD Test ROC-AUC: 0.7345
OOD Test Loss: 0.1094

[0m[1;37mINFO[0m: [1mChartInfo 0.8140 0.7319 0.8171 0.7345 0.8399 0.7829[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/08/2024 11:11:49 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/08/2024 11:11:51 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/08/2024 11:11:53 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 351
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.643
SUFF++ for r=0.3 class 0.0 = 0.953 +- 0.134 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.3 class 1.0 = 0.9 +- 0.134 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.3 all KL = 0.918 +- 0.134 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.3 all L1 = 0.926 +- 0.096 (in-sample avg dev_std = 0.208)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.727
SUFF++ for r=0.6 class 0.0 = 0.962 +- 0.148 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 1.0 = 0.829 +- 0.148 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all KL = 0.916 +- 0.148 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all L1 = 0.895 +- 0.160 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.822
SUFF++ for r=0.9 class 0.0 = 0.981 +- 0.150 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 class 1.0 = 0.867 +- 0.150 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all KL = 0.941 +- 0.150 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.9 all L1 = 0.924 +- 0.141 (in-sample avg dev_std = 0.190)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.646
SUFF++ for r=0.3 class 0.0 = 0.972 +- 0.103 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.3 class 1.0 = 0.926 +- 0.103 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.3 all KL = 0.943 +- 0.103 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.3 all L1 = 0.949 +- 0.073 (in-sample avg dev_std = 0.157)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.743
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.741
SUFF++ for r=0.6 class 0.0 = 0.98 +- 0.125 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.6 class 1.0 = 0.857 +- 0.125 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.6 all KL = 0.937 +- 0.125 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.6 all L1 = 0.918 +- 0.141 (in-sample avg dev_std = 0.164)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.757
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.753
SUFF++ for r=0.9 class 0.0 = 0.99 +- 0.087 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 1.0 = 0.919 +- 0.087 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all KL = 0.973 +- 0.087 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all L1 = 0.955 +- 0.103 (in-sample avg dev_std = 0.129)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.569
SUFF++ for r=0.3 class 0.0 = 0.982 +- 0.077 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.3 class 1.0 = 0.953 +- 0.077 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.3 all KL = 0.97 +- 0.077 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.3 all L1 = 0.968 +- 0.067 (in-sample avg dev_std = 0.081)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.684
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0.0 = 0.986 +- 0.105 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.6 class 1.0 = 0.906 +- 0.105 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.6 all KL = 0.949 +- 0.105 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.6 all L1 = 0.946 +- 0.099 (in-sample avg dev_std = 0.153)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.764
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.763
SUFF++ for r=0.9 class 0.0 = 0.996 +- 0.066 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.066 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.979 +- 0.066 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.965 +- 0.090 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.682
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.693
NEC for r=0.3 class 0.0 = 0.016 +- 0.096 (in-sample avg dev_std = 0.090)
NEC for r=0.3 class 1.0 = 0.086 +- 0.096 (in-sample avg dev_std = 0.090)
NEC for r=0.3 all KL = 0.037 +- 0.096 (in-sample avg dev_std = 0.090)
NEC for r=0.3 all L1 = 0.051 +- 0.095 (in-sample avg dev_std = 0.090)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.76
NEC for r=0.6 class 0.0 = 0.024 +- 0.128 (in-sample avg dev_std = 0.150)
NEC for r=0.6 class 1.0 = 0.16 +- 0.128 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all KL = 0.06 +- 0.128 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all L1 = 0.092 +- 0.160 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.806
NEC for r=0.9 class 0.0 = 0.021 +- 0.199 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1.0 = 0.19 +- 0.199 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.094 +- 0.199 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.105 +- 0.184 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0.0 = 0.021 +- 0.231 (in-sample avg dev_std = 0.254)
NEC for r=1.0 class 1.0 = 0.213 +- 0.231 (in-sample avg dev_std = 0.254)
NEC for r=1.0 all KL = 0.112 +- 0.231 (in-sample avg dev_std = 0.254)
NEC for r=1.0 all L1 = 0.117 +- 0.203 (in-sample avg dev_std = 0.254)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.69
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.677
NEC for r=0.3 class 0.0 = 0.016 +- 0.131 (in-sample avg dev_std = 0.106)
NEC for r=0.3 class 1.0 = 0.092 +- 0.131 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all KL = 0.052 +- 0.131 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all L1 = 0.054 +- 0.108 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.743
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.716
NEC for r=0.6 class 0.0 = 0.015 +- 0.096 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1.0 = 0.112 +- 0.096 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.041 +- 0.096 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.064 +- 0.120 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.757
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.744
NEC for r=0.9 class 0.0 = 0.013 +- 0.140 (in-sample avg dev_std = 0.140)
NEC for r=0.9 class 1.0 = 0.124 +- 0.140 (in-sample avg dev_std = 0.140)
NEC for r=0.9 all KL = 0.052 +- 0.140 (in-sample avg dev_std = 0.140)
NEC for r=0.9 all L1 = 0.069 +- 0.151 (in-sample avg dev_std = 0.140)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.745
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.74
NEC for r=1.0 class 0.0 = 0.016 +- 0.152 (in-sample avg dev_std = 0.154)
NEC for r=1.0 class 1.0 = 0.14 +- 0.152 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all KL = 0.062 +- 0.152 (in-sample avg dev_std = 0.154)
NEC for r=1.0 all L1 = 0.078 +- 0.165 (in-sample avg dev_std = 0.154)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
NEC for r=0.3 class 0.0 = 0.012 +- 0.096 (in-sample avg dev_std = 0.069)
NEC for r=0.3 class 1.0 = 0.05 +- 0.096 (in-sample avg dev_std = 0.069)
NEC for r=0.3 all KL = 0.025 +- 0.096 (in-sample avg dev_std = 0.069)
NEC for r=0.3 all L1 = 0.031 +- 0.080 (in-sample avg dev_std = 0.069)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.684
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.674
NEC for r=0.6 class 0.0 = 0.007 +- 0.121 (in-sample avg dev_std = 0.079)
NEC for r=0.6 class 1.0 = 0.087 +- 0.121 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all KL = 0.036 +- 0.121 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all L1 = 0.047 +- 0.121 (in-sample avg dev_std = 0.079)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.764
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.725
NEC for r=0.9 class 0.0 = 0.005 +- 0.132 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1.0 = 0.089 +- 0.132 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.038 +- 0.132 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.047 +- 0.128 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.776
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.736
NEC for r=1.0 class 0.0 = 0.004 +- 0.131 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1.0 = 0.08 +- 0.131 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.037 +- 0.131 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.042 +- 0.109 (in-sample avg dev_std = 0.161)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:13:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:26 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:30 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:34 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:38 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ROC-AUC: 0.9356
Train Loss: 0.0853
ID Validation ROC-AUC: 0.8442
ID Validation Loss: 0.1322
ID Test ROC-AUC: 0.8133
ID Test Loss: 0.1163
OOD Validation ROC-AUC: 0.7351
OOD Validation Loss: 0.1310
OOD Test ROC-AUC: 0.7150
OOD Test Loss: 0.0919

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ROC-AUC: 0.9721
Train Loss: 0.0675
ID Validation ROC-AUC: 0.8337
ID Validation Loss: 0.1459
ID Test ROC-AUC: 0.8022
ID Test Loss: 0.1310
OOD Validation ROC-AUC: 0.7768
OOD Validation Loss: 0.1394
OOD Test ROC-AUC: 0.7463
OOD Test Loss: 0.0906

[0m[1;37mINFO[0m: [1mChartInfo 0.8133 0.7150 0.8022 0.7463 0.8337 0.7768[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/08/2024 11:13:41 AM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/08/2024 11:13:43 AM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/08/2024 11:13:45 AM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.641
SUFF++ for r=0.3 class 0.0 = 0.943 +- 0.116 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.3 class 1.0 = 0.881 +- 0.116 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.3 all KL = 0.922 +- 0.116 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.3 all L1 = 0.912 +- 0.115 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.701
SUFF++ for r=0.6 class 0.0 = 0.923 +- 0.158 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1.0 = 0.791 +- 0.158 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.874 +- 0.158 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.857 +- 0.157 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0.0 = 0.967 +- 0.142 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 1.0 = 0.843 +- 0.142 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all KL = 0.933 +- 0.142 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.151 (in-sample avg dev_std = 0.205)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.628
SUFF++ for r=0.3 class 0.0 = 0.959 +- 0.085 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 1.0 = 0.904 +- 0.085 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 all KL = 0.951 +- 0.085 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.098 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0.0 = 0.938 +- 0.125 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1.0 = 0.842 +- 0.125 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.906 +- 0.125 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.132 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.704
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.702
SUFF++ for r=0.9 class 0.0 = 0.968 +- 0.079 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1.0 = 0.915 +- 0.079 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.967 +- 0.079 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.103 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.551
SUFF++ for r=0.3 class 0.0 = 0.978 +- 0.057 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.3 class 1.0 = 0.963 +- 0.057 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.3 all KL = 0.978 +- 0.057 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.3 all L1 = 0.971 +- 0.050 (in-sample avg dev_std = 0.088)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.614
SUFF++ for r=0.6 class 0.0 = 0.972 +- 0.094 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.6 class 1.0 = 0.931 +- 0.094 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.6 all KL = 0.955 +- 0.094 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.6 all L1 = 0.952 +- 0.074 (in-sample avg dev_std = 0.134)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.674
SUFF++ for r=0.9 class 0.0 = 0.987 +- 0.109 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.9 class 1.0 = 0.916 +- 0.109 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.9 all KL = 0.967 +- 0.109 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.107 (in-sample avg dev_std = 0.149)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.705
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.697
NEC for r=0.3 class 0.0 = 0.024 +- 0.091 (in-sample avg dev_std = 0.109)
NEC for r=0.3 class 1.0 = 0.101 +- 0.091 (in-sample avg dev_std = 0.109)
NEC for r=0.3 all KL = 0.036 +- 0.091 (in-sample avg dev_std = 0.109)
NEC for r=0.3 all L1 = 0.063 +- 0.115 (in-sample avg dev_std = 0.109)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.77
NEC for r=0.6 class 0.0 = 0.035 +- 0.132 (in-sample avg dev_std = 0.176)
NEC for r=0.6 class 1.0 = 0.179 +- 0.132 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all KL = 0.069 +- 0.132 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all L1 = 0.107 +- 0.157 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.809
NEC for r=0.9 class 0.0 = 0.035 +- 0.196 (in-sample avg dev_std = 0.229)
NEC for r=0.9 class 1.0 = 0.226 +- 0.196 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all KL = 0.105 +- 0.196 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all L1 = 0.131 +- 0.199 (in-sample avg dev_std = 0.229)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.857
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.81
NEC for r=1.0 class 0.0 = 0.031 +- 0.196 (in-sample avg dev_std = 0.223)
NEC for r=1.0 class 1.0 = 0.203 +- 0.196 (in-sample avg dev_std = 0.223)
NEC for r=1.0 all KL = 0.098 +- 0.196 (in-sample avg dev_std = 0.223)
NEC for r=1.0 all L1 = 0.117 +- 0.188 (in-sample avg dev_std = 0.223)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
NEC for r=0.3 class 0.0 = 0.022 +- 0.087 (in-sample avg dev_std = 0.116)
NEC for r=0.3 class 1.0 = 0.103 +- 0.087 (in-sample avg dev_std = 0.116)
NEC for r=0.3 all KL = 0.035 +- 0.087 (in-sample avg dev_std = 0.116)
NEC for r=0.3 all L1 = 0.063 +- 0.113 (in-sample avg dev_std = 0.116)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.684
NEC for r=0.6 class 0.0 = 0.026 +- 0.086 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1.0 = 0.123 +- 0.086 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.037 +- 0.086 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.075 +- 0.128 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.704
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.699
NEC for r=0.9 class 0.0 = 0.033 +- 0.102 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 1.0 = 0.108 +- 0.102 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all KL = 0.045 +- 0.102 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all L1 = 0.07 +- 0.121 (in-sample avg dev_std = 0.113)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.72
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.699
NEC for r=1.0 class 0.0 = 0.028 +- 0.126 (in-sample avg dev_std = 0.128)
NEC for r=1.0 class 1.0 = 0.129 +- 0.126 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all KL = 0.053 +- 0.126 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all L1 = 0.078 +- 0.146 (in-sample avg dev_std = 0.128)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.546
NEC for r=0.3 class 0.0 = 0.012 +- 0.037 (in-sample avg dev_std = 0.027)
NEC for r=0.3 class 1.0 = 0.026 +- 0.037 (in-sample avg dev_std = 0.027)
NEC for r=0.3 all KL = 0.008 +- 0.037 (in-sample avg dev_std = 0.027)
NEC for r=0.3 all L1 = 0.019 +- 0.043 (in-sample avg dev_std = 0.027)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.649
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.648
NEC for r=0.6 class 0.0 = 0.015 +- 0.043 (in-sample avg dev_std = 0.059)
NEC for r=0.6 class 1.0 = 0.048 +- 0.043 (in-sample avg dev_std = 0.059)
NEC for r=0.6 all KL = 0.016 +- 0.043 (in-sample avg dev_std = 0.059)
NEC for r=0.6 all L1 = 0.032 +- 0.066 (in-sample avg dev_std = 0.059)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.697
NEC for r=0.9 class 0.0 = 0.009 +- 0.134 (in-sample avg dev_std = 0.138)
NEC for r=0.9 class 1.0 = 0.106 +- 0.134 (in-sample avg dev_std = 0.138)
NEC for r=0.9 all KL = 0.04 +- 0.134 (in-sample avg dev_std = 0.138)
NEC for r=0.9 all L1 = 0.057 +- 0.133 (in-sample avg dev_std = 0.138)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.726
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.69
NEC for r=1.0 class 0.0 = 0.007 +- 0.109 (in-sample avg dev_std = 0.131)
NEC for r=1.0 class 1.0 = 0.107 +- 0.109 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all KL = 0.037 +- 0.109 (in-sample avg dev_std = 0.131)
NEC for r=1.0 all L1 = 0.057 +- 0.126 (in-sample avg dev_std = 0.131)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.889, 0.878, 0.936, 1.0], 'all_L1': [0.91, 0.876, 0.916, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.918, 0.905, 0.917, 1.0], 'all_L1': [0.901, 0.883, 0.917, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.871, 0.89, 0.917, 1.0], 'all_L1': [0.89, 0.878, 0.915, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.918, 0.916, 0.941, 1.0], 'all_L1': [0.926, 0.895, 0.924, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.874, 0.933, 1.0], 'all_L1': [0.912, 0.857, 0.905, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.054, 0.069, 0.112, 0.114], 'all_L1': [0.068, 0.096, 0.127, 0.124]}), defaultdict(<class 'list'>, {'all_KL': [0.056, 0.078, 0.15, 0.164], 'all_L1': [0.084, 0.107, 0.135, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.071, 0.072, 0.139, 0.162], 'all_L1': [0.085, 0.102, 0.135, 0.145]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.06, 0.094, 0.112], 'all_L1': [0.051, 0.092, 0.105, 0.117]}), defaultdict(<class 'list'>, {'all_KL': [0.036, 0.069, 0.105, 0.098], 'all_L1': [0.063, 0.107, 0.131, 0.117]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.947, 0.945, 0.971, 1.0], 'all_L1': [0.952, 0.933, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.947, 0.946, 0.962, 1.0], 'all_L1': [0.941, 0.921, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.899, 0.907, 0.962, 1.0], 'all_L1': [0.919, 0.896, 0.948, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.943, 0.937, 0.973, 1.0], 'all_L1': [0.949, 0.918, 0.955, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.951, 0.906, 0.967, 1.0], 'all_L1': [0.931, 0.89, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.044, 0.055, 0.06, 0.052], 'all_L1': [0.046, 0.072, 0.077, 0.071]}), defaultdict(<class 'list'>, {'all_KL': [0.064, 0.044, 0.094, 0.103], 'all_L1': [0.07, 0.072, 0.097, 0.102]}), defaultdict(<class 'list'>, {'all_KL': [0.074, 0.074, 0.083, 0.092], 'all_L1': [0.073, 0.094, 0.09, 0.096]}), defaultdict(<class 'list'>, {'all_KL': [0.052, 0.041, 0.052, 0.062], 'all_L1': [0.054, 0.064, 0.069, 0.078]}), defaultdict(<class 'list'>, {'all_KL': [0.035, 0.037, 0.045, 0.053], 'all_L1': [0.063, 0.075, 0.07, 0.078]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.966, 0.93, 0.972, 1.0], 'all_L1': [0.963, 0.935, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.952, 0.936, 0.968, 1.0], 'all_L1': [0.942, 0.932, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.942, 0.915, 0.967, 1.0], 'all_L1': [0.947, 0.929, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.97, 0.949, 0.979, 1.0], 'all_L1': [0.968, 0.946, 0.965, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.978, 0.955, 0.967, 1.0], 'all_L1': [0.971, 0.952, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.04, 0.05, 0.06, 0.045], 'all_L1': [0.043, 0.05, 0.06, 0.055]}), defaultdict(<class 'list'>, {'all_KL': [0.05, 0.045, 0.069, 0.072], 'all_L1': [0.057, 0.057, 0.071, 0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.053, 0.058, 0.072, 0.074], 'all_L1': [0.054, 0.059, 0.072, 0.067]}), defaultdict(<class 'list'>, {'all_KL': [0.025, 0.036, 0.038, 0.037], 'all_L1': [0.031, 0.047, 0.047, 0.042]}), defaultdict(<class 'list'>, {'all_KL': [0.008, 0.016, 0.04, 0.037], 'all_L1': [0.019, 0.032, 0.057, 0.057]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.908 +- 0.012, 0.878 +- 0.012, 0.915 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.904 +- 0.020, 0.893 +- 0.016, 0.929 +- 0.010, 1.000 +- 0.000
suff++_acc_int  =  0.634 +- 0.011, 0.716 +- 0.009, 0.818 +- 0.005
nec class all_L1  =  0.070 +- 0.013, 0.101 +- 0.006, 0.127 +- 0.011, 0.129 +- 0.012
nec class all_KL  =  0.051 +- 0.013, 0.070 +- 0.006, 0.120 +- 0.021, 0.130 +- 0.028
nec_acc_int  =  0.678 +- 0.021, 0.750 +- 0.013, 0.794 +- 0.014, 0.800 +- 0.010

Eval split val
suff++ class all_L1  =  0.938 +- 0.012, 0.912 +- 0.016, 0.949 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.937 +- 0.019, 0.928 +- 0.018, 0.967 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.608 +- 0.026, 0.690 +- 0.036, 0.741 +- 0.029
nec class all_L1  =  0.061 +- 0.010, 0.075 +- 0.010, 0.081 +- 0.011, 0.085 +- 0.012
nec class all_KL  =  0.054 +- 0.014, 0.050 +- 0.013, 0.067 +- 0.019, 0.072 +- 0.021
nec_acc_int  =  0.645 +- 0.027, 0.692 +- 0.013, 0.718 +- 0.023, 0.717 +- 0.024

Eval split test
suff++ class all_L1  =  0.958 +- 0.012, 0.939 +- 0.009, 0.959 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.962 +- 0.013, 0.937 +- 0.014, 0.971 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.560 +- 0.013, 0.662 +- 0.027, 0.754 +- 0.040
nec class all_L1  =  0.041 +- 0.014, 0.049 +- 0.010, 0.061 +- 0.009, 0.058 +- 0.010
nec class all_KL  =  0.035 +- 0.017, 0.041 +- 0.014, 0.056 +- 0.014, 0.053 +- 0.017
nec_acc_int  =  0.592 +- 0.024, 0.654 +- 0.026, 0.716 +- 0.013, 0.730 +- 0.021


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.489 +- 0.002, 0.489 +- 0.005, 0.521 +- 0.004, 0.564 +- 0.006
Faith. Armon (L1)= 		  =  0.130 +- 0.022, 0.181 +- 0.009, 0.222 +- 0.017, 0.228 +- 0.019
Faith. GMean (L1)= 	  =  0.251 +- 0.022, 0.297 +- 0.008, 0.340 +- 0.015, 0.359 +- 0.017
Faith. Aritm (KL)= 		  =  0.477 +- 0.006, 0.481 +- 0.008, 0.524 +- 0.006, 0.565 +- 0.014
Faith. Armon (KL)= 		  =  0.096 +- 0.023, 0.129 +- 0.010, 0.212 +- 0.033, 0.229 +- 0.043
Faith. GMean (KL)= 	  =  0.212 +- 0.026, 0.249 +- 0.010, 0.332 +- 0.027, 0.359 +- 0.038

Eval split val
Faith. Aritm (L1)= 		  =  0.500 +- 0.003, 0.493 +- 0.007, 0.515 +- 0.006, 0.542 +- 0.006
Faith. Armon (L1)= 		  =  0.115 +- 0.018, 0.139 +- 0.017, 0.148 +- 0.019, 0.156 +- 0.020
Faith. GMean (L1)= 	  =  0.239 +- 0.019, 0.262 +- 0.016, 0.276 +- 0.019, 0.291 +- 0.020
Faith. Aritm (KL)= 		  =  0.496 +- 0.006, 0.489 +- 0.010, 0.517 +- 0.008, 0.536 +- 0.011
Faith. Armon (KL)= 		  =  0.101 +- 0.025, 0.095 +- 0.024, 0.124 +- 0.032, 0.134 +- 0.036
Faith. GMean (KL)= 	  =  0.222 +- 0.027, 0.214 +- 0.027, 0.252 +- 0.035, 0.266 +- 0.039

Eval split test
Faith. Aritm (L1)= 		  =  0.499 +- 0.003, 0.494 +- 0.002, 0.510 +- 0.005, 0.529 +- 0.005
Faith. Armon (L1)= 		  =  0.078 +- 0.026, 0.093 +- 0.017, 0.115 +- 0.016, 0.109 +- 0.017
Faith. GMean (L1)= 	  =  0.194 +- 0.036, 0.213 +- 0.021, 0.242 +- 0.019, 0.240 +- 0.021
Faith. Aritm (KL)= 		  =  0.498 +- 0.003, 0.489 +- 0.003, 0.513 +- 0.006, 0.526 +- 0.008
Faith. Armon (KL)= 		  =  0.067 +- 0.031, 0.078 +- 0.027, 0.105 +- 0.026, 0.100 +- 0.030
Faith. GMean (KL)= 	  =  0.176 +- 0.050, 0.192 +- 0.037, 0.231 +- 0.030, 0.227 +- 0.036
Computed for split load_split = id



Completed in  0:09:27.742504  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:15:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/08/2024 11:15:41 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 11:16:19 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:16:32 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:16:46 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:06 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:17:26 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 139...
[0m[1;37mINFO[0m: [1mCheckpoint 139: 
-----------------------------------
Train ROC-AUC: 0.9678
Train Loss: 0.1501
ID Validation ROC-AUC: 0.9223
ID Validation Loss: 0.2502
ID Test ROC-AUC: 0.9241
ID Test Loss: 0.2529
OOD Validation ROC-AUC: 0.6438
OOD Validation Loss: 0.4615
OOD Test ROC-AUC: 0.7106
OOD Test Loss: 0.6155

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ROC-AUC: 0.9255
Train Loss: 0.2418
ID Validation ROC-AUC: 0.9083
ID Validation Loss: 0.2671
ID Test ROC-AUC: 0.9111
ID Test Loss: 0.2691
OOD Validation ROC-AUC: 0.6953
OOD Validation Loss: 0.3258
OOD Test ROC-AUC: 0.7205
OOD Test Loss: 0.5206

[0m[1;37mINFO[0m: [1mChartInfo 0.9241 0.7106 0.9111 0.7205 0.9083 0.6953[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/08/2024 11:17:27 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/08/2024 11:17:33 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/08/2024 11:17:38 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.758
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.689
SUFF++ for r=0.3 class 0.0 = 0.703 +- 0.204 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 1.0 = 0.871 +- 0.204 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 all KL = 0.851 +- 0.204 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 all L1 = 0.851 +- 0.201 (in-sample avg dev_std = 0.258)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.74
SUFF++ for r=0.6 class 0.0 = 0.844 +- 0.117 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 class 1.0 = 0.958 +- 0.117 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 all KL = 0.956 +- 0.117 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 all L1 = 0.945 +- 0.132 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.874 +- 0.096 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.096 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.971 +- 0.096 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.102 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
SUFF++ for r=0.3 class 0.0 = 0.703 +- 0.224 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.3 class 1.0 = 0.809 +- 0.224 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.3 all KL = 0.794 +- 0.224 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.3 all L1 = 0.8 +- 0.208 (in-sample avg dev_std = 0.315)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0.0 = 0.803 +- 0.143 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 1.0 = 0.926 +- 0.143 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 all KL = 0.933 +- 0.143 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 all L1 = 0.916 +- 0.159 (in-sample avg dev_std = 0.169)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.606
SUFF++ for r=0.9 class 0.0 = 0.871 +- 0.106 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.106 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all KL = 0.96 +- 0.106 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all L1 = 0.938 +- 0.124 (in-sample avg dev_std = 0.129)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0.0 = 0.744 +- 0.222 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 1.0 = 0.809 +- 0.222 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 all KL = 0.798 +- 0.222 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 all L1 = 0.798 +- 0.212 (in-sample avg dev_std = 0.311)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.604
SUFF++ for r=0.6 class 0.0 = 0.847 +- 0.155 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 1.0 = 0.927 +- 0.155 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all KL = 0.928 +- 0.155 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all L1 = 0.914 +- 0.166 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.64
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.611
SUFF++ for r=0.9 class 0.0 = 0.905 +- 0.100 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.100 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all KL = 0.959 +- 0.100 (in-sample avg dev_std = 0.134)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.132 (in-sample avg dev_std = 0.134)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.758
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.713
NEC for r=0.3 class 0.0 = 0.325 +- 0.251 (in-sample avg dev_std = 0.259)
NEC for r=0.3 class 1.0 = 0.148 +- 0.251 (in-sample avg dev_std = 0.259)
NEC for r=0.3 all KL = 0.184 +- 0.251 (in-sample avg dev_std = 0.259)
NEC for r=0.3 all L1 = 0.169 +- 0.217 (in-sample avg dev_std = 0.259)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.747
NEC for r=0.6 class 0.0 = 0.189 +- 0.149 (in-sample avg dev_std = 0.167)
NEC for r=0.6 class 1.0 = 0.052 +- 0.149 (in-sample avg dev_std = 0.167)
NEC for r=0.6 all KL = 0.067 +- 0.149 (in-sample avg dev_std = 0.167)
NEC for r=0.6 all L1 = 0.068 +- 0.139 (in-sample avg dev_std = 0.167)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.8
NEC for r=0.9 class 0.0 = 0.163 +- 0.099 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.031 +- 0.099 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.036 +- 0.099 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.046 +- 0.112 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.854
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.811
NEC for r=1.0 class 0.0 = 0.198 +- 0.102 (in-sample avg dev_std = 0.130)
NEC for r=1.0 class 1.0 = 0.032 +- 0.102 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all KL = 0.038 +- 0.102 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all L1 = 0.052 +- 0.119 (in-sample avg dev_std = 0.130)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.63
NEC for r=0.3 class 0.0 = 0.324 +- 0.258 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1.0 = 0.203 +- 0.258 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.221 +- 0.258 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.213 +- 0.229 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.617
NEC for r=0.6 class 0.0 = 0.222 +- 0.181 (in-sample avg dev_std = 0.206)
NEC for r=0.6 class 1.0 = 0.086 +- 0.181 (in-sample avg dev_std = 0.206)
NEC for r=0.6 all KL = 0.093 +- 0.181 (in-sample avg dev_std = 0.206)
NEC for r=0.6 all L1 = 0.097 +- 0.168 (in-sample avg dev_std = 0.206)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0.0 = 0.158 +- 0.142 (in-sample avg dev_std = 0.167)
NEC for r=0.9 class 1.0 = 0.069 +- 0.142 (in-sample avg dev_std = 0.167)
NEC for r=0.9 all KL = 0.062 +- 0.142 (in-sample avg dev_std = 0.167)
NEC for r=0.9 all L1 = 0.076 +- 0.148 (in-sample avg dev_std = 0.167)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.637
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.623
NEC for r=1.0 class 0.0 = 0.157 +- 0.114 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1.0 = 0.069 +- 0.114 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.052 +- 0.114 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.077 +- 0.141 (in-sample avg dev_std = 0.161)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
NEC for r=0.3 class 0.0 = 0.263 +- 0.262 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 1.0 = 0.209 +- 0.262 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all KL = 0.224 +- 0.262 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all L1 = 0.218 +- 0.227 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.615
NEC for r=0.6 class 0.0 = 0.183 +- 0.197 (in-sample avg dev_std = 0.221)
NEC for r=0.6 class 1.0 = 0.091 +- 0.197 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all KL = 0.105 +- 0.197 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all L1 = 0.106 +- 0.179 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.64
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.633
NEC for r=0.9 class 0.0 = 0.134 +- 0.148 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.076 +- 0.148 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.069 +- 0.148 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.085 +- 0.158 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.672
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.646
NEC for r=1.0 class 0.0 = 0.142 +- 0.155 (in-sample avg dev_std = 0.181)
NEC for r=1.0 class 1.0 = 0.087 +- 0.155 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all KL = 0.076 +- 0.155 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all L1 = 0.096 +- 0.171 (in-sample avg dev_std = 0.181)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:22:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/08/2024 11:22:53 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 11:23:32 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:23:45 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:23:58 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:18 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9711
Train Loss: 0.1734
ID Validation ROC-AUC: 0.9197
ID Validation Loss: 0.3259
ID Test ROC-AUC: 0.9231
ID Test Loss: 0.3278
OOD Validation ROC-AUC: 0.6681
OOD Validation Loss: 0.5008
OOD Test ROC-AUC: 0.7148
OOD Test Loss: 0.7542

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ROC-AUC: 0.9487
Train Loss: 0.2395
ID Validation ROC-AUC: 0.9097
ID Validation Loss: 0.3393
ID Test ROC-AUC: 0.9137
ID Test Loss: 0.3404
OOD Validation ROC-AUC: 0.6879
OOD Validation Loss: 0.4535
OOD Test ROC-AUC: 0.7303
OOD Test Loss: 0.7173

[0m[1;37mINFO[0m: [1mChartInfo 0.9231 0.7148 0.9137 0.7303 0.9097 0.6879[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/08/2024 11:24:38 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/08/2024 11:24:43 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/08/2024 11:24:48 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.807
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.692
SUFF++ for r=0.3 class 0.0 = 0.614 +- 0.255 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 1.0 = 0.837 +- 0.255 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all KL = 0.77 +- 0.255 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all L1 = 0.811 +- 0.214 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.726
SUFF++ for r=0.6 class 0.0 = 0.709 +- 0.186 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 class 1.0 = 0.923 +- 0.186 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all KL = 0.89 +- 0.186 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all L1 = 0.898 +- 0.177 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.794
SUFF++ for r=0.9 class 0.0 = 0.805 +- 0.123 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 1.0 = 0.95 +- 0.123 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all KL = 0.945 +- 0.123 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.137 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0.0 = 0.699 +- 0.264 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 1.0 = 0.749 +- 0.264 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 all KL = 0.722 +- 0.264 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 all L1 = 0.745 +- 0.236 (in-sample avg dev_std = 0.376)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
SUFF++ for r=0.6 class 0.0 = 0.776 +- 0.207 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 class 1.0 = 0.875 +- 0.207 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all KL = 0.871 +- 0.207 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all L1 = 0.867 +- 0.201 (in-sample avg dev_std = 0.246)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.644
SUFF++ for r=0.9 class 0.0 = 0.852 +- 0.139 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 class 1.0 = 0.918 +- 0.139 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all KL = 0.934 +- 0.139 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all L1 = 0.912 +- 0.157 (in-sample avg dev_std = 0.171)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
SUFF++ for r=0.3 class 0.0 = 0.662 +- 0.270 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 class 1.0 = 0.746 +- 0.270 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all KL = 0.711 +- 0.270 (in-sample avg dev_std = 0.386)
SUFF++ for r=0.3 all L1 = 0.732 +- 0.241 (in-sample avg dev_std = 0.386)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.58
SUFF++ for r=0.6 class 0.0 = 0.762 +- 0.220 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 class 1.0 = 0.862 +- 0.220 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 all KL = 0.846 +- 0.220 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.6 all L1 = 0.845 +- 0.215 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.632
SUFF++ for r=0.9 class 0.0 = 0.865 +- 0.144 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1.0 = 0.915 +- 0.144 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.929 +- 0.144 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.906 +- 0.158 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.807
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.791
NEC for r=0.3 class 0.0 = 0.375 +- 0.247 (in-sample avg dev_std = 0.282)
NEC for r=0.3 class 1.0 = 0.142 +- 0.247 (in-sample avg dev_std = 0.282)
NEC for r=0.3 all KL = 0.172 +- 0.247 (in-sample avg dev_std = 0.282)
NEC for r=0.3 all L1 = 0.169 +- 0.218 (in-sample avg dev_std = 0.282)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.808
NEC for r=0.6 class 0.0 = 0.306 +- 0.205 (in-sample avg dev_std = 0.227)
NEC for r=0.6 class 1.0 = 0.082 +- 0.205 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all KL = 0.112 +- 0.205 (in-sample avg dev_std = 0.227)
NEC for r=0.6 all L1 = 0.108 +- 0.186 (in-sample avg dev_std = 0.227)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.813
NEC for r=0.9 class 0.0 = 0.259 +- 0.167 (in-sample avg dev_std = 0.199)
NEC for r=0.9 class 1.0 = 0.058 +- 0.167 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all KL = 0.079 +- 0.167 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all L1 = 0.081 +- 0.156 (in-sample avg dev_std = 0.199)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.885
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.82
NEC for r=1.0 class 0.0 = 0.274 +- 0.172 (in-sample avg dev_std = 0.200)
NEC for r=1.0 class 1.0 = 0.058 +- 0.172 (in-sample avg dev_std = 0.200)
NEC for r=1.0 all KL = 0.076 +- 0.172 (in-sample avg dev_std = 0.200)
NEC for r=1.0 all L1 = 0.083 +- 0.163 (in-sample avg dev_std = 0.200)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.641
NEC for r=0.3 class 0.0 = 0.311 +- 0.276 (in-sample avg dev_std = 0.335)
NEC for r=0.3 class 1.0 = 0.233 +- 0.276 (in-sample avg dev_std = 0.335)
NEC for r=0.3 all KL = 0.242 +- 0.276 (in-sample avg dev_std = 0.335)
NEC for r=0.3 all L1 = 0.24 +- 0.237 (in-sample avg dev_std = 0.335)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.637
NEC for r=0.6 class 0.0 = 0.225 +- 0.214 (in-sample avg dev_std = 0.242)
NEC for r=0.6 class 1.0 = 0.127 +- 0.214 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all KL = 0.132 +- 0.214 (in-sample avg dev_std = 0.242)
NEC for r=0.6 all L1 = 0.135 +- 0.199 (in-sample avg dev_std = 0.242)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0.0 = 0.213 +- 0.170 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1.0 = 0.089 +- 0.170 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.087 +- 0.170 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.099 +- 0.170 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.676
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.652
NEC for r=1.0 class 0.0 = 0.26 +- 0.180 (in-sample avg dev_std = 0.227)
NEC for r=1.0 class 1.0 = 0.101 +- 0.180 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all KL = 0.094 +- 0.180 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all L1 = 0.114 +- 0.181 (in-sample avg dev_std = 0.227)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.648
NEC for r=0.3 class 0.0 = 0.3 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=0.3 class 1.0 = 0.226 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=0.3 all KL = 0.22 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=0.3 all L1 = 0.239 +- 0.242 (in-sample avg dev_std = 0.317)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.643
NEC for r=0.6 class 0.0 = 0.246 +- 0.230 (in-sample avg dev_std = 0.272)
NEC for r=0.6 class 1.0 = 0.139 +- 0.230 (in-sample avg dev_std = 0.272)
NEC for r=0.6 all KL = 0.156 +- 0.230 (in-sample avg dev_std = 0.272)
NEC for r=0.6 all L1 = 0.157 +- 0.210 (in-sample avg dev_std = 0.272)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0.0 = 0.181 +- 0.198 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 1.0 = 0.108 +- 0.198 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all KL = 0.113 +- 0.198 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all L1 = 0.12 +- 0.185 (in-sample avg dev_std = 0.243)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.686
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.658
NEC for r=1.0 class 0.0 = 0.203 +- 0.200 (in-sample avg dev_std = 0.236)
NEC for r=1.0 class 1.0 = 0.117 +- 0.200 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all KL = 0.113 +- 0.200 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all L1 = 0.131 +- 0.197 (in-sample avg dev_std = 0.236)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:30:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/08/2024 11:30:01 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 11:30:40 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:30:52 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:06 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:26 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:31:45 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ROC-AUC: 0.9761
Train Loss: 0.1383
ID Validation ROC-AUC: 0.9230
ID Validation Loss: 0.2640
ID Test ROC-AUC: 0.9263
ID Test Loss: 0.2652
OOD Validation ROC-AUC: 0.6587
OOD Validation Loss: 0.4426
OOD Test ROC-AUC: 0.7116
OOD Test Loss: 0.6134

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ROC-AUC: 0.9136
Train Loss: 0.2491
ID Validation ROC-AUC: 0.9005
ID Validation Loss: 0.2661
ID Test ROC-AUC: 0.9034
ID Test Loss: 0.2678
OOD Validation ROC-AUC: 0.6991
OOD Validation Loss: 0.3043
OOD Test ROC-AUC: 0.7251
OOD Test Loss: 0.4883

[0m[1;37mINFO[0m: [1mChartInfo 0.9263 0.7116 0.9034 0.7251 0.9005 0.6991[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/08/2024 11:31:46 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/08/2024 11:31:51 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/08/2024 11:31:56 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.832
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.773
SUFF++ for r=0.3 class 0.0 = 0.647 +- 0.203 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.3 class 1.0 = 0.86 +- 0.203 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.3 all KL = 0.828 +- 0.203 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.3 all L1 = 0.835 +- 0.192 (in-sample avg dev_std = 0.267)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.861
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.789
SUFF++ for r=0.6 class 0.0 = 0.756 +- 0.172 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1.0 = 0.939 +- 0.172 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.927 +- 0.172 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.918 +- 0.173 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.838
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.781
SUFF++ for r=0.9 class 0.0 = 0.772 +- 0.115 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.943 +- 0.115 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.945 +- 0.115 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.923 +- 0.140 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.595
SUFF++ for r=0.3 class 0.0 = 0.726 +- 0.213 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 1.0 = 0.77 +- 0.213 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all KL = 0.777 +- 0.213 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all L1 = 0.766 +- 0.201 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0.0 = 0.792 +- 0.157 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 1.0 = 0.903 +- 0.157 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all KL = 0.917 +- 0.157 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all L1 = 0.894 +- 0.180 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.599
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.608
SUFF++ for r=0.9 class 0.0 = 0.829 +- 0.127 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 class 1.0 = 0.894 +- 0.127 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 all KL = 0.929 +- 0.127 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.9 all L1 = 0.888 +- 0.163 (in-sample avg dev_std = 0.175)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.614
SUFF++ for r=0.3 class 0.0 = 0.699 +- 0.201 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 class 1.0 = 0.786 +- 0.201 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 all KL = 0.793 +- 0.201 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 all L1 = 0.772 +- 0.196 (in-sample avg dev_std = 0.318)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.618
SUFF++ for r=0.6 class 0.0 = 0.814 +- 0.160 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 1.0 = 0.895 +- 0.160 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all KL = 0.906 +- 0.160 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all L1 = 0.882 +- 0.183 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.62
SUFF++ for r=0.9 class 0.0 = 0.846 +- 0.145 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 1.0 = 0.89 +- 0.145 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all KL = 0.919 +- 0.145 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.167 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.832
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.787
NEC for r=0.3 class 0.0 = 0.347 +- 0.230 (in-sample avg dev_std = 0.263)
NEC for r=0.3 class 1.0 = 0.156 +- 0.230 (in-sample avg dev_std = 0.263)
NEC for r=0.3 all KL = 0.189 +- 0.230 (in-sample avg dev_std = 0.263)
NEC for r=0.3 all L1 = 0.178 +- 0.198 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.861
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.822
NEC for r=0.6 class 0.0 = 0.246 +- 0.169 (in-sample avg dev_std = 0.188)
NEC for r=0.6 class 1.0 = 0.064 +- 0.169 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all KL = 0.08 +- 0.169 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all L1 = 0.085 +- 0.158 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.838
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.788
NEC for r=0.9 class 0.0 = 0.229 +- 0.130 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 1.0 = 0.056 +- 0.130 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all KL = 0.06 +- 0.130 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all L1 = 0.076 +- 0.142 (in-sample avg dev_std = 0.155)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.852
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.799
NEC for r=1.0 class 0.0 = 0.308 +- 0.152 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 1.0 = 0.076 +- 0.152 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all KL = 0.079 +- 0.152 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all L1 = 0.103 +- 0.171 (in-sample avg dev_std = 0.194)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.627
NEC for r=0.3 class 0.0 = 0.312 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.3 class 1.0 = 0.247 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all KL = 0.236 +- 0.242 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all L1 = 0.252 +- 0.213 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.64
NEC for r=0.6 class 0.0 = 0.229 +- 0.171 (in-sample avg dev_std = 0.203)
NEC for r=0.6 class 1.0 = 0.105 +- 0.171 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all KL = 0.099 +- 0.171 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all L1 = 0.115 +- 0.178 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.599
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.61
NEC for r=0.9 class 0.0 = 0.203 +- 0.144 (in-sample avg dev_std = 0.187)
NEC for r=0.9 class 1.0 = 0.112 +- 0.144 (in-sample avg dev_std = 0.187)
NEC for r=0.9 all KL = 0.084 +- 0.144 (in-sample avg dev_std = 0.187)
NEC for r=0.9 all L1 = 0.12 +- 0.176 (in-sample avg dev_std = 0.187)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.583
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.613
NEC for r=1.0 class 0.0 = 0.24 +- 0.156 (in-sample avg dev_std = 0.217)
NEC for r=1.0 class 1.0 = 0.143 +- 0.156 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all KL = 0.104 +- 0.156 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all L1 = 0.151 +- 0.191 (in-sample avg dev_std = 0.217)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.626
NEC for r=0.3 class 0.0 = 0.31 +- 0.229 (in-sample avg dev_std = 0.309)
NEC for r=0.3 class 1.0 = 0.236 +- 0.229 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all KL = 0.225 +- 0.229 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all L1 = 0.249 +- 0.208 (in-sample avg dev_std = 0.309)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.645
NEC for r=0.6 class 0.0 = 0.2 +- 0.183 (in-sample avg dev_std = 0.229)
NEC for r=0.6 class 1.0 = 0.119 +- 0.183 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all KL = 0.114 +- 0.183 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all L1 = 0.133 +- 0.185 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.633
NEC for r=0.9 class 0.0 = 0.18 +- 0.164 (in-sample avg dev_std = 0.199)
NEC for r=0.9 class 1.0 = 0.116 +- 0.164 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all KL = 0.095 +- 0.164 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all L1 = 0.127 +- 0.184 (in-sample avg dev_std = 0.199)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.674
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.651
NEC for r=1.0 class 0.0 = 0.225 +- 0.167 (in-sample avg dev_std = 0.226)
NEC for r=1.0 class 1.0 = 0.148 +- 0.167 (in-sample avg dev_std = 0.226)
NEC for r=1.0 all KL = 0.11 +- 0.167 (in-sample avg dev_std = 0.226)
NEC for r=1.0 all L1 = 0.161 +- 0.201 (in-sample avg dev_std = 0.226)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:37:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/08/2024 11:37:15 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 11:37:53 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:06 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:19 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:39 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ROC-AUC: 0.9668
Train Loss: 0.1507
ID Validation ROC-AUC: 0.9235
ID Validation Loss: 0.2539
ID Test ROC-AUC: 0.9241
ID Test Loss: 0.2579
OOD Validation ROC-AUC: 0.6656
OOD Validation Loss: 0.4541
OOD Test ROC-AUC: 0.7147
OOD Test Loss: 0.6219

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ROC-AUC: 0.9048
Train Loss: 0.2555
ID Validation ROC-AUC: 0.8976
ID Validation Loss: 0.2635
ID Test ROC-AUC: 0.8978
ID Test Loss: 0.2675
OOD Validation ROC-AUC: 0.7022
OOD Validation Loss: 0.2917
OOD Test ROC-AUC: 0.7352
OOD Test Loss: 0.4638

[0m[1;37mINFO[0m: [1mChartInfo 0.9241 0.7147 0.8978 0.7352 0.8976 0.7022[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/08/2024 11:38:58 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/08/2024 11:39:03 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/08/2024 11:39:08 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.852
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.739
SUFF++ for r=0.3 class 0.0 = 0.72 +- 0.156 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 class 1.0 = 0.893 +- 0.156 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all KL = 0.874 +- 0.156 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all L1 = 0.873 +- 0.151 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.848
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.772
SUFF++ for r=0.6 class 0.0 = 0.779 +- 0.116 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 1.0 = 0.96 +- 0.116 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 all KL = 0.954 +- 0.116 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.138 (in-sample avg dev_std = 0.137)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0.0 = 0.807 +- 0.092 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.092 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all KL = 0.961 +- 0.092 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.123 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.666
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
SUFF++ for r=0.3 class 0.0 = 0.74 +- 0.161 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 1.0 = 0.823 +- 0.161 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all KL = 0.844 +- 0.161 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all L1 = 0.816 +- 0.173 (in-sample avg dev_std = 0.272)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.662
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0.0 = 0.822 +- 0.133 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 class 1.0 = 0.91 +- 0.133 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 all KL = 0.929 +- 0.133 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 all L1 = 0.902 +- 0.165 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.613
SUFF++ for r=0.9 class 0.0 = 0.868 +- 0.113 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 1.0 = 0.909 +- 0.113 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all KL = 0.937 +- 0.113 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.143 (in-sample avg dev_std = 0.163)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.684
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.647
SUFF++ for r=0.3 class 0.0 = 0.747 +- 0.178 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 class 1.0 = 0.823 +- 0.178 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all KL = 0.838 +- 0.178 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.3 all L1 = 0.81 +- 0.180 (in-sample avg dev_std = 0.282)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0.0 = 0.82 +- 0.150 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 1.0 = 0.907 +- 0.150 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all KL = 0.917 +- 0.150 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all L1 = 0.892 +- 0.175 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.677
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.668
SUFF++ for r=0.9 class 0.0 = 0.843 +- 0.116 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 class 1.0 = 0.909 +- 0.116 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 all KL = 0.935 +- 0.116 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 all L1 = 0.898 +- 0.153 (in-sample avg dev_std = 0.177)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.852
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.772
NEC for r=0.3 class 0.0 = 0.296 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.3 class 1.0 = 0.136 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.3 all KL = 0.162 +- 0.204 (in-sample avg dev_std = 0.244)
NEC for r=0.3 all L1 = 0.155 +- 0.171 (in-sample avg dev_std = 0.244)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.848
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.823
NEC for r=0.6 class 0.0 = 0.216 +- 0.118 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 1.0 = 0.048 +- 0.118 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all KL = 0.054 +- 0.118 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all L1 = 0.067 +- 0.133 (in-sample avg dev_std = 0.146)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.838
NEC for r=0.9 class 0.0 = 0.198 +- 0.093 (in-sample avg dev_std = 0.137)
NEC for r=0.9 class 1.0 = 0.039 +- 0.093 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all KL = 0.038 +- 0.093 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all L1 = 0.058 +- 0.119 (in-sample avg dev_std = 0.137)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.835
NEC for r=1.0 class 0.0 = 0.194 +- 0.097 (in-sample avg dev_std = 0.144)
NEC for r=1.0 class 1.0 = 0.041 +- 0.097 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all KL = 0.039 +- 0.097 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all L1 = 0.059 +- 0.120 (in-sample avg dev_std = 0.144)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.666
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.628
NEC for r=0.3 class 0.0 = 0.256 +- 0.211 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 1.0 = 0.209 +- 0.211 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all KL = 0.19 +- 0.211 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all L1 = 0.213 +- 0.186 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.662
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.643
NEC for r=0.6 class 0.0 = 0.181 +- 0.138 (in-sample avg dev_std = 0.176)
NEC for r=0.6 class 1.0 = 0.095 +- 0.138 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all KL = 0.077 +- 0.138 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all L1 = 0.102 +- 0.159 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.623
NEC for r=0.9 class 0.0 = 0.143 +- 0.121 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 1.0 = 0.08 +- 0.121 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all KL = 0.058 +- 0.121 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all L1 = 0.085 +- 0.140 (in-sample avg dev_std = 0.172)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.65
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.622
NEC for r=1.0 class 0.0 = 0.147 +- 0.124 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 1.0 = 0.086 +- 0.124 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all KL = 0.059 +- 0.124 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all L1 = 0.092 +- 0.151 (in-sample avg dev_std = 0.176)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.684
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.638
NEC for r=0.3 class 0.0 = 0.289 +- 0.213 (in-sample avg dev_std = 0.278)
NEC for r=0.3 class 1.0 = 0.205 +- 0.213 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all KL = 0.194 +- 0.213 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all L1 = 0.219 +- 0.189 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.671
NEC for r=0.6 class 0.0 = 0.173 +- 0.151 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 1.0 = 0.1 +- 0.151 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all KL = 0.09 +- 0.151 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all L1 = 0.112 +- 0.164 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.677
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.677
NEC for r=0.9 class 0.0 = 0.145 +- 0.114 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 1.0 = 0.083 +- 0.114 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all KL = 0.059 +- 0.114 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all L1 = 0.093 +- 0.150 (in-sample avg dev_std = 0.169)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.677
NEC for r=1.0 class 0.0 = 0.156 +- 0.123 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 1.0 = 0.085 +- 0.123 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all KL = 0.06 +- 0.123 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all L1 = 0.097 +- 0.157 (in-sample avg dev_std = 0.174)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:44:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/08/2024 11:44:19 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/08/2024 11:44:57 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/08/2024 11:45:10 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/08/2024 11:45:24 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/08/2024 11:45:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:02 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ROC-AUC: 0.9618
Train Loss: 0.1777
ID Validation ROC-AUC: 0.9247
ID Validation Loss: 0.2482
ID Test ROC-AUC: 0.9280
ID Test Loss: 0.2464
OOD Validation ROC-AUC: 0.6735
OOD Validation Loss: 0.3762
OOD Test ROC-AUC: 0.7162
OOD Test Loss: 0.5599

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ROC-AUC: 0.9100
Train Loss: 0.2732
ID Validation ROC-AUC: 0.8964
ID Validation Loss: 0.2902
ID Test ROC-AUC: 0.9006
ID Test Loss: 0.2915
OOD Validation ROC-AUC: 0.6954
OOD Validation Loss: 0.3250
OOD Test ROC-AUC: 0.7317
OOD Test Loss: 0.5237

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.7162 0.9006 0.7317 0.8964 0.6954[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/08/2024 11:46:03 AM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/08/2024 11:46:08 AM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/08/2024 11:46:13 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.793
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.695
SUFF++ for r=0.3 class 0.0 = 0.744 +- 0.151 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 1.0 = 0.843 +- 0.151 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all KL = 0.858 +- 0.151 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all L1 = 0.832 +- 0.142 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.804
SUFF++ for r=0.6 class 0.0 = 0.77 +- 0.091 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 1.0 = 0.939 +- 0.091 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all KL = 0.949 +- 0.091 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all L1 = 0.919 +- 0.130 (in-sample avg dev_std = 0.136)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.907
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.849 +- 0.061 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.061 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all KL = 0.978 +- 0.061 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.087 (in-sample avg dev_std = 0.090)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
SUFF++ for r=0.3 class 0.0 = 0.75 +- 0.150 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 class 1.0 = 0.784 +- 0.150 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 all KL = 0.838 +- 0.150 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 all L1 = 0.781 +- 0.143 (in-sample avg dev_std = 0.284)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.619
SUFF++ for r=0.6 class 0.0 = 0.826 +- 0.091 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.6 class 1.0 = 0.89 +- 0.091 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.6 all KL = 0.936 +- 0.091 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.6 all L1 = 0.885 +- 0.134 (in-sample avg dev_std = 0.167)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.665
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.643
SUFF++ for r=0.9 class 0.0 = 0.881 +- 0.069 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.931 +- 0.069 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.969 +- 0.069 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.926 +- 0.107 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.584
SUFF++ for r=0.3 class 0.0 = 0.755 +- 0.144 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 1.0 = 0.784 +- 0.144 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all KL = 0.843 +- 0.144 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all L1 = 0.78 +- 0.146 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.611
SUFF++ for r=0.6 class 0.0 = 0.803 +- 0.113 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.6 class 1.0 = 0.87 +- 0.113 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.6 all KL = 0.916 +- 0.113 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.6 all L1 = 0.859 +- 0.159 (in-sample avg dev_std = 0.186)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.666
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.644
SUFF++ for r=0.9 class 0.0 = 0.888 +- 0.073 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 class 1.0 = 0.922 +- 0.073 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 all KL = 0.965 +- 0.073 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 all L1 = 0.916 +- 0.113 (in-sample avg dev_std = 0.115)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.793
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.752
NEC for r=0.3 class 0.0 = 0.253 +- 0.156 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 1.0 = 0.163 +- 0.156 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all KL = 0.137 +- 0.156 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all L1 = 0.173 +- 0.145 (in-sample avg dev_std = 0.208)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.825
NEC for r=0.6 class 0.0 = 0.229 +- 0.116 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 1.0 = 0.075 +- 0.116 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all KL = 0.069 +- 0.116 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all L1 = 0.093 +- 0.129 (in-sample avg dev_std = 0.153)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.907
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.861
NEC for r=0.9 class 0.0 = 0.208 +- 0.084 (in-sample avg dev_std = 0.122)
NEC for r=0.9 class 1.0 = 0.048 +- 0.084 (in-sample avg dev_std = 0.122)
NEC for r=0.9 all KL = 0.041 +- 0.084 (in-sample avg dev_std = 0.122)
NEC for r=0.9 all L1 = 0.066 +- 0.104 (in-sample avg dev_std = 0.122)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.867
NEC for r=1.0 class 0.0 = 0.218 +- 0.075 (in-sample avg dev_std = 0.119)
NEC for r=1.0 class 1.0 = 0.045 +- 0.075 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all KL = 0.037 +- 0.075 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all L1 = 0.065 +- 0.109 (in-sample avg dev_std = 0.119)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.597
NEC for r=0.3 class 0.0 = 0.251 +- 0.167 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 1.0 = 0.22 +- 0.167 (in-sample avg dev_std = 0.246)
NEC for r=0.3 all KL = 0.157 +- 0.167 (in-sample avg dev_std = 0.246)
NEC for r=0.3 all L1 = 0.222 +- 0.157 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.618
NEC for r=0.6 class 0.0 = 0.174 +- 0.109 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.129 +- 0.109 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.084 +- 0.109 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.133 +- 0.139 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.665
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0.0 = 0.161 +- 0.091 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1.0 = 0.094 +- 0.091 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.054 +- 0.091 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.1 +- 0.123 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.679
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.631
NEC for r=1.0 class 0.0 = 0.159 +- 0.083 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.089 +- 0.083 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.048 +- 0.083 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.095 +- 0.118 (in-sample avg dev_std = 0.145)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.607
NEC for r=0.3 class 0.0 = 0.248 +- 0.163 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 1.0 = 0.213 +- 0.163 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all KL = 0.149 +- 0.163 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all L1 = 0.218 +- 0.155 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.622
NEC for r=0.6 class 0.0 = 0.199 +- 0.127 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 1.0 = 0.143 +- 0.127 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all KL = 0.099 +- 0.127 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all L1 = 0.152 +- 0.153 (in-sample avg dev_std = 0.189)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.666
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.639
NEC for r=0.9 class 0.0 = 0.157 +- 0.107 (in-sample avg dev_std = 0.159)
NEC for r=0.9 class 1.0 = 0.107 +- 0.107 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all KL = 0.063 +- 0.107 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all L1 = 0.115 +- 0.138 (in-sample avg dev_std = 0.159)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.677
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.654
NEC for r=1.0 class 0.0 = 0.158 +- 0.106 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 1.0 = 0.102 +- 0.106 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all KL = 0.061 +- 0.106 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all L1 = 0.112 +- 0.138 (in-sample avg dev_std = 0.164)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.851, 0.956, 0.971, 1.0], 'all_L1': [0.851, 0.945, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.77, 0.89, 0.945, 1.0], 'all_L1': [0.811, 0.898, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.828, 0.927, 0.945, 1.0], 'all_L1': [0.835, 0.918, 0.923, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.874, 0.954, 0.961, 1.0], 'all_L1': [0.873, 0.939, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.858, 0.949, 0.978, 1.0], 'all_L1': [0.832, 0.919, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.184, 0.067, 0.036, 0.038], 'all_L1': [0.169, 0.068, 0.046, 0.052]}), defaultdict(<class 'list'>, {'all_KL': [0.172, 0.112, 0.079, 0.076], 'all_L1': [0.169, 0.108, 0.081, 0.083]}), defaultdict(<class 'list'>, {'all_KL': [0.189, 0.08, 0.06, 0.079], 'all_L1': [0.178, 0.085, 0.076, 0.103]}), defaultdict(<class 'list'>, {'all_KL': [0.162, 0.054, 0.038, 0.039], 'all_L1': [0.155, 0.067, 0.058, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.137, 0.069, 0.041, 0.037], 'all_L1': [0.173, 0.093, 0.066, 0.065]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.794, 0.933, 0.96, 1.0], 'all_L1': [0.8, 0.916, 0.938, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.722, 0.871, 0.934, 1.0], 'all_L1': [0.745, 0.867, 0.912, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.777, 0.917, 0.929, 1.0], 'all_L1': [0.766, 0.894, 0.888, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.844, 0.929, 0.937, 1.0], 'all_L1': [0.816, 0.902, 0.905, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.838, 0.936, 0.969, 1.0], 'all_L1': [0.781, 0.885, 0.926, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.221, 0.093, 0.062, 0.052], 'all_L1': [0.213, 0.097, 0.076, 0.077]}), defaultdict(<class 'list'>, {'all_KL': [0.242, 0.132, 0.087, 0.094], 'all_L1': [0.24, 0.135, 0.099, 0.114]}), defaultdict(<class 'list'>, {'all_KL': [0.236, 0.099, 0.084, 0.104], 'all_L1': [0.252, 0.115, 0.12, 0.151]}), defaultdict(<class 'list'>, {'all_KL': [0.19, 0.077, 0.058, 0.059], 'all_L1': [0.213, 0.102, 0.085, 0.092]}), defaultdict(<class 'list'>, {'all_KL': [0.157, 0.084, 0.054, 0.048], 'all_L1': [0.222, 0.133, 0.1, 0.095]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.798, 0.928, 0.959, 1.0], 'all_L1': [0.798, 0.914, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.711, 0.846, 0.929, 1.0], 'all_L1': [0.732, 0.845, 0.906, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.793, 0.906, 0.919, 1.0], 'all_L1': [0.772, 0.882, 0.882, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.838, 0.917, 0.935, 1.0], 'all_L1': [0.81, 0.892, 0.898, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.843, 0.916, 0.965, 1.0], 'all_L1': [0.78, 0.859, 0.916, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.224, 0.105, 0.069, 0.076], 'all_L1': [0.218, 0.106, 0.085, 0.096]}), defaultdict(<class 'list'>, {'all_KL': [0.22, 0.156, 0.113, 0.113], 'all_L1': [0.239, 0.157, 0.12, 0.131]}), defaultdict(<class 'list'>, {'all_KL': [0.225, 0.114, 0.095, 0.11], 'all_L1': [0.249, 0.133, 0.127, 0.161]}), defaultdict(<class 'list'>, {'all_KL': [0.194, 0.09, 0.059, 0.06], 'all_L1': [0.219, 0.112, 0.093, 0.097]}), defaultdict(<class 'list'>, {'all_KL': [0.149, 0.099, 0.063, 0.061], 'all_L1': [0.218, 0.152, 0.115, 0.112]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.840 +- 0.021, 0.924 +- 0.017, 0.942 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.836 +- 0.036, 0.935 +- 0.025, 0.960 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.718 +- 0.033, 0.766 +- 0.029, 0.816 +- 0.030
nec class all_L1  =  0.169 +- 0.008, 0.084 +- 0.016, 0.065 +- 0.013, 0.072 +- 0.018
nec class all_KL  =  0.169 +- 0.018, 0.076 +- 0.020, 0.051 +- 0.016, 0.054 +- 0.019
nec_acc_int  =  0.763 +- 0.028, 0.805 +- 0.029, 0.820 +- 0.026, 0.826 +- 0.024

Eval split val
suff++ class all_L1  =  0.782 +- 0.025, 0.893 +- 0.016, 0.914 +- 0.017, 1.000 +- 0.000
suff++ class all_KL  =  0.795 +- 0.045, 0.917 +- 0.024, 0.946 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.587 +- 0.016, 0.615 +- 0.008, 0.623 +- 0.017
nec class all_L1  =  0.228 +- 0.016, 0.116 +- 0.016, 0.096 +- 0.015, 0.106 +- 0.025
nec class all_KL  =  0.209 +- 0.032, 0.097 +- 0.019, 0.069 +- 0.014, 0.071 +- 0.023
nec_acc_int  =  0.625 +- 0.015, 0.631 +- 0.011, 0.629 +- 0.018, 0.628 +- 0.013

Eval split test
suff++ class all_L1  =  0.778 +- 0.027, 0.878 +- 0.024, 0.907 +- 0.018, 1.000 +- 0.000
suff++ class all_KL  =  0.797 +- 0.047, 0.903 +- 0.029, 0.941 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.599 +- 0.027, 0.614 +- 0.025, 0.635 +- 0.020
nec class all_L1  =  0.229 +- 0.013, 0.132 +- 0.021, 0.108 +- 0.016, 0.119 +- 0.024
nec class all_KL  =  0.202 +- 0.029, 0.113 +- 0.023, 0.080 +- 0.021, 0.084 +- 0.023
nec_acc_int  =  0.625 +- 0.016, 0.639 +- 0.020, 0.647 +- 0.017, 0.657 +- 0.011


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.505 +- 0.008, 0.504 +- 0.002, 0.504 +- 0.004, 0.536 +- 0.009
Faith. Armon (L1)= 		  =  0.281 +- 0.010, 0.154 +- 0.026, 0.122 +- 0.022, 0.134 +- 0.032
Faith. GMean (L1)= 	  =  0.376 +- 0.007, 0.277 +- 0.023, 0.247 +- 0.023, 0.267 +- 0.033
Faith. Aritm (KL)= 		  =  0.502 +- 0.017, 0.506 +- 0.004, 0.505 +- 0.005, 0.527 +- 0.010
Faith. Armon (KL)= 		  =  0.280 +- 0.025, 0.140 +- 0.033, 0.096 +- 0.029, 0.101 +- 0.035
Faith. GMean (KL)= 	  =  0.375 +- 0.020, 0.265 +- 0.029, 0.218 +- 0.033, 0.228 +- 0.041

Eval split val
Faith. Aritm (L1)= 		  =  0.505 +- 0.007, 0.505 +- 0.003, 0.505 +- 0.006, 0.553 +- 0.013
Faith. Armon (L1)= 		  =  0.352 +- 0.016, 0.205 +- 0.024, 0.173 +- 0.024, 0.190 +- 0.041
Faith. GMean (L1)= 	  =  0.422 +- 0.009, 0.321 +- 0.019, 0.295 +- 0.021, 0.323 +- 0.038
Faith. Aritm (KL)= 		  =  0.502 +- 0.012, 0.507 +- 0.004, 0.507 +- 0.005, 0.536 +- 0.012
Faith. Armon (KL)= 		  =  0.329 +- 0.037, 0.175 +- 0.030, 0.128 +- 0.024, 0.132 +- 0.040
Faith. GMean (KL)= 	  =  0.406 +- 0.023, 0.297 +- 0.024, 0.254 +- 0.024, 0.264 +- 0.042

Eval split test
Faith. Aritm (L1)= 		  =  0.503 +- 0.010, 0.505 +- 0.003, 0.508 +- 0.007, 0.560 +- 0.012
Faith. Armon (L1)= 		  =  0.353 +- 0.014, 0.229 +- 0.030, 0.193 +- 0.026, 0.212 +- 0.038
Faith. GMean (L1)= 	  =  0.421 +- 0.009, 0.339 +- 0.022, 0.312 +- 0.022, 0.344 +- 0.034
Faith. Aritm (KL)= 		  =  0.500 +- 0.018, 0.508 +- 0.005, 0.511 +- 0.008, 0.542 +- 0.012
Faith. Armon (KL)= 		  =  0.321 +- 0.036, 0.199 +- 0.034, 0.146 +- 0.035, 0.154 +- 0.039
Faith. GMean (KL)= 	  =  0.400 +- 0.025, 0.317 +- 0.026, 0.272 +- 0.033, 0.287 +- 0.040
Computed for split load_split = id



Completed in  0:35:46.089407  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 11:51:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:45 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:45 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:45 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 11:51:46 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 125...
[0m[1;37mINFO[0m: [1mCheckpoint 125: 
-----------------------------------
Train ACCURACY: 0.9855
Train Loss: 0.0481
ID Validation ACCURACY: 0.9006
ID Validation Loss: 0.3612
ID Test ACCURACY: 0.8956
ID Test Loss: 0.3577
OOD Validation ACCURACY: 0.8899
OOD Validation Loss: 0.3794
OOD Test ACCURACY: 0.7986
OOD Test Loss: 0.7413

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9952
Train Loss: 0.0209
ID Validation ACCURACY: 0.8953
ID Validation Loss: 0.4052
ID Test ACCURACY: 0.8983
ID Test Loss: 0.3891
OOD Validation ACCURACY: 0.8929
OOD Validation Loss: 0.4151
OOD Test ACCURACY: 0.7227
OOD Test Loss: 1.2543

[0m[1;37mINFO[0m: [1mChartInfo 0.8956 0.7986 0.8983 0.7227 0.8953 0.8929[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.642 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 1 = 0.602 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 2 = 0.599 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 3 = 0.587 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 4 = 0.563 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 5 = 0.59 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 6 = 0.57 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 7 = 0.593 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 8 = 0.596 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 9 = 0.544 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 all KL = 0.759 +- 0.120 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 all L1 = 0.589 +- 0.107 (in-sample avg dev_std = 0.276)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.188
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
SUFF++ for r=0.6 class 0 = 0.539 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 1 = 0.541 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 2 = 0.558 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 3 = 0.582 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 4 = 0.565 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 5 = 0.592 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 6 = 0.538 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 7 = 0.534 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 8 = 0.576 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 9 = 0.536 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all KL = 0.631 +- 0.260 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all L1 = 0.555 +- 0.208 (in-sample avg dev_std = 0.149)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.771
SUFF++ for r=0.9 class 0 = 0.936 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.827 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 3 = 0.794 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 4 = 0.817 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 5 = 0.698 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 6 = 0.821 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 7 = 0.81 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 8 = 0.843 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 9 = 0.77 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.854 +- 0.215 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.825 +- 0.198 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.62 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 1 = 0.602 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 3 = 0.605 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 4 = 0.586 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 5 = 0.606 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 6 = 0.594 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 7 = 0.584 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 8 = 0.569 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 9 = 0.577 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 all KL = 0.768 +- 0.113 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 all L1 = 0.595 +- 0.100 (in-sample avg dev_std = 0.271)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.145
SUFF++ for r=0.6 class 0 = 0.508 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 1 = 0.549 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 2 = 0.588 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 3 = 0.588 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 4 = 0.493 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 5 = 0.513 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 6 = 0.488 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 7 = 0.505 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 8 = 0.565 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 9 = 0.481 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all KL = 0.602 +- 0.258 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all L1 = 0.528 +- 0.200 (in-sample avg dev_std = 0.149)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.777
SUFF++ for r=0.9 class 0 = 0.897 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 1 = 0.929 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 2 = 0.766 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 3 = 0.82 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 4 = 0.79 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 5 = 0.755 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 6 = 0.794 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 7 = 0.868 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 8 = 0.831 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 9 = 0.781 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all KL = 0.851 +- 0.213 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all L1 = 0.825 +- 0.196 (in-sample avg dev_std = 0.231)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.657 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 1 = 0.659 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 2 = 0.626 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 3 = 0.611 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 4 = 0.6 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 5 = 0.652 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 6 = 0.614 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 7 = 0.619 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 8 = 0.609 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 class 9 = 0.604 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 all KL = 0.801 +- 0.110 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.3 all L1 = 0.625 +- 0.102 (in-sample avg dev_std = 0.244)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.161
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
SUFF++ for r=0.6 class 0 = 0.542 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 1 = 0.542 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 2 = 0.545 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 3 = 0.54 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 4 = 0.523 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 5 = 0.542 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 6 = 0.521 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 7 = 0.535 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 8 = 0.531 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 9 = 0.5 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 all KL = 0.62 +- 0.246 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 all L1 = 0.532 +- 0.184 (in-sample avg dev_std = 0.148)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.716
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.658
SUFF++ for r=0.9 class 0 = 0.809 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 1 = 0.865 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 2 = 0.811 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 3 = 0.731 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 4 = 0.766 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 5 = 0.755 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 6 = 0.763 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 7 = 0.856 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 8 = 0.738 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 9 = 0.733 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all KL = 0.836 +- 0.204 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all L1 = 0.784 +- 0.202 (in-sample avg dev_std = 0.255)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
NEC for r=0.3 class 0 = 0.345 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 1 = 0.382 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 2 = 0.385 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 3 = 0.383 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 4 = 0.407 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 5 = 0.389 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 6 = 0.419 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 7 = 0.381 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 8 = 0.384 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 9 = 0.422 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all KL = 0.215 +- 0.134 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all L1 = 0.389 +- 0.119 (in-sample avg dev_std = 0.206)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.188
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.168
NEC for r=0.6 class 0 = 0.509 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 1 = 0.449 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 2 = 0.437 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 3 = 0.431 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 4 = 0.459 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 5 = 0.433 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 6 = 0.428 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 7 = 0.473 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 8 = 0.459 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 class 9 = 0.5 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all KL = 0.392 +- 0.205 (in-sample avg dev_std = 0.320)
NEC for r=0.6 all L1 = 0.458 +- 0.155 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.639
NEC for r=0.9 class 0 = 0.345 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 1 = 0.218 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 2 = 0.384 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 3 = 0.461 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 4 = 0.343 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 5 = 0.589 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 6 = 0.413 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 7 = 0.419 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 8 = 0.32 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 9 = 0.489 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 all KL = 0.525 +- 0.307 (in-sample avg dev_std = 0.425)
NEC for r=0.9 all L1 = 0.393 +- 0.251 (in-sample avg dev_std = 0.425)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.952
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.844
NEC for r=1.0 class 0 = 0.109 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 1 = 0.044 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 2 = 0.232 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 3 = 0.286 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 4 = 0.191 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 5 = 0.414 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 6 = 0.313 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 7 = 0.176 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 8 = 0.186 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 9 = 0.309 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all KL = 0.346 +- 0.332 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all L1 = 0.22 +- 0.239 (in-sample avg dev_std = 0.374)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.089
NEC for r=0.3 class 0 = 0.358 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 1 = 0.388 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 2 = 0.396 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 3 = 0.362 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 4 = 0.387 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 5 = 0.362 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 6 = 0.41 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 7 = 0.385 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 8 = 0.384 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 9 = 0.421 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all KL = 0.21 +- 0.127 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all L1 = 0.386 +- 0.113 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
NEC for r=0.6 class 0 = 0.492 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 1 = 0.44 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 2 = 0.442 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 3 = 0.436 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 4 = 0.488 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 5 = 0.456 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 6 = 0.504 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 7 = 0.483 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 8 = 0.48 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 9 = 0.506 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all KL = 0.41 +- 0.197 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all L1 = 0.473 +- 0.149 (in-sample avg dev_std = 0.318)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.622
NEC for r=0.9 class 0 = 0.527 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 1 = 0.175 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 2 = 0.396 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 3 = 0.494 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 4 = 0.387 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 5 = 0.536 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 6 = 0.468 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 7 = 0.337 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 8 = 0.363 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 class 9 = 0.455 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 all KL = 0.54 +- 0.317 (in-sample avg dev_std = 0.436)
NEC for r=0.9 all L1 = 0.409 +- 0.256 (in-sample avg dev_std = 0.436)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.93
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.812
NEC for r=1.0 class 0 = 0.142 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 1 = 0.054 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 2 = 0.284 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 3 = 0.336 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 4 = 0.261 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 5 = 0.362 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 6 = 0.303 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 7 = 0.172 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 8 = 0.243 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 class 9 = 0.353 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 all KL = 0.367 +- 0.331 (in-sample avg dev_std = 0.382)
NEC for r=1.0 all L1 = 0.248 +- 0.247 (in-sample avg dev_std = 0.382)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
NEC for r=0.3 class 0 = 0.312 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 1 = 0.356 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 2 = 0.351 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 3 = 0.37 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 4 = 0.401 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 5 = 0.349 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 6 = 0.387 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 7 = 0.368 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 8 = 0.374 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 9 = 0.394 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all KL = 0.192 +- 0.137 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all L1 = 0.366 +- 0.118 (in-sample avg dev_std = 0.197)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.161
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.144
NEC for r=0.6 class 0 = 0.449 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 1 = 0.435 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 2 = 0.482 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 3 = 0.465 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 4 = 0.498 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 5 = 0.47 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 6 = 0.493 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 7 = 0.484 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 8 = 0.495 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 9 = 0.536 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all KL = 0.411 +- 0.200 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all L1 = 0.48 +- 0.142 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.716
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.484
NEC for r=0.9 class 0 = 0.6 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 1 = 0.345 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 2 = 0.332 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 3 = 0.556 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 4 = 0.401 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 5 = 0.546 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 6 = 0.521 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 7 = 0.365 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 8 = 0.511 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 9 = 0.517 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 all KL = 0.556 +- 0.308 (in-sample avg dev_std = 0.394)
NEC for r=0.9 all L1 = 0.466 +- 0.252 (in-sample avg dev_std = 0.394)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.822
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.686
NEC for r=1.0 class 0 = 0.484 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 1 = 0.119 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 2 = 0.247 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 3 = 0.466 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 4 = 0.368 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 5 = 0.416 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 6 = 0.409 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 7 = 0.193 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 8 = 0.423 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 class 9 = 0.424 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 all KL = 0.447 +- 0.333 (in-sample avg dev_std = 0.391)
NEC for r=1.0 all L1 = 0.351 +- 0.270 (in-sample avg dev_std = 0.391)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 12:16:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:54 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:54 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:54 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:16:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.9972
Train Loss: 0.0135
ID Validation ACCURACY: 0.9029
ID Validation Loss: 0.3993
ID Test ACCURACY: 0.8986
ID Test Loss: 0.3943
OOD Validation ACCURACY: 0.8639
OOD Validation Loss: 0.5682
OOD Test ACCURACY: 0.5783
OOD Test Loss: 2.9195

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ACCURACY: 0.9395
Train Loss: 0.1754
ID Validation ACCURACY: 0.8879
ID Validation Loss: 0.3481
ID Test ACCURACY: 0.8850
ID Test Loss: 0.3562
OOD Validation ACCURACY: 0.8849
OOD Validation Loss: 0.3644
OOD Test ACCURACY: 0.8000
OOD Test Loss: 0.6623

[0m[1;37mINFO[0m: [1mChartInfo 0.8986 0.5783 0.8850 0.8000 0.8879 0.8849[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.081
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.743 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 1 = 0.603 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 2 = 0.684 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 3 = 0.709 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 4 = 0.664 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 5 = 0.707 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 6 = 0.673 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 7 = 0.715 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 8 = 0.76 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 class 9 = 0.71 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 all KL = 0.802 +- 0.191 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.3 all L1 = 0.696 +- 0.211 (in-sample avg dev_std = 0.185)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
SUFF++ for r=0.6 class 0 = 0.53 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 1 = 0.495 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 2 = 0.541 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 3 = 0.6 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 4 = 0.598 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 5 = 0.532 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 6 = 0.593 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 7 = 0.514 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 8 = 0.683 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 9 = 0.593 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all KL = 0.618 +- 0.287 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all L1 = 0.567 +- 0.232 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.77
SUFF++ for r=0.9 class 0 = 0.937 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 1 = 0.966 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 2 = 0.794 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 3 = 0.801 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 4 = 0.794 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 5 = 0.679 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 6 = 0.766 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 7 = 0.814 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 8 = 0.826 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 class 9 = 0.79 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all KL = 0.83 +- 0.246 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.214 (in-sample avg dev_std = 0.255)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.08
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
SUFF++ for r=0.3 class 0 = 0.736 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 1 = 0.564 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 2 = 0.678 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 3 = 0.71 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 4 = 0.679 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 5 = 0.662 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 6 = 0.687 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 7 = 0.643 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 8 = 0.76 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 class 9 = 0.651 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 all KL = 0.786 +- 0.188 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.3 all L1 = 0.675 +- 0.200 (in-sample avg dev_std = 0.216)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.165
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.14
SUFF++ for r=0.6 class 0 = 0.528 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 1 = 0.533 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 2 = 0.578 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 3 = 0.551 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 4 = 0.573 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 5 = 0.474 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 6 = 0.553 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 7 = 0.464 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 8 = 0.645 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 9 = 0.527 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 all KL = 0.598 +- 0.278 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 all L1 = 0.542 +- 0.224 (in-sample avg dev_std = 0.169)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.739
SUFF++ for r=0.9 class 0 = 0.889 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 1 = 0.969 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 2 = 0.74 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 3 = 0.865 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 4 = 0.798 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 5 = 0.752 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 6 = 0.748 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 7 = 0.869 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 8 = 0.788 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 9 = 0.794 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all KL = 0.838 +- 0.239 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all L1 = 0.824 +- 0.208 (in-sample avg dev_std = 0.259)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.794 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 1 = 0.661 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 2 = 0.757 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 3 = 0.75 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 4 = 0.657 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 5 = 0.741 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 6 = 0.713 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 7 = 0.717 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 8 = 0.729 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 9 = 0.693 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all KL = 0.83 +- 0.174 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all L1 = 0.721 +- 0.198 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.167
SUFF++ for r=0.6 class 0 = 0.521 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 1 = 0.503 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 2 = 0.473 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 3 = 0.541 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 4 = 0.507 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 5 = 0.497 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 6 = 0.466 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 7 = 0.463 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 8 = 0.494 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 9 = 0.467 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all KL = 0.55 +- 0.271 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all L1 = 0.493 +- 0.203 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.55
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.509
SUFF++ for r=0.9 class 0 = 0.693 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 1 = 0.947 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 2 = 0.759 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 3 = 0.749 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 4 = 0.765 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 5 = 0.703 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 6 = 0.704 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 7 = 0.732 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 8 = 0.767 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 9 = 0.709 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all KL = 0.802 +- 0.227 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all L1 = 0.756 +- 0.208 (in-sample avg dev_std = 0.280)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.081
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
NEC for r=0.3 class 0 = 0.301 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 1 = 0.448 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 2 = 0.363 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 3 = 0.337 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 4 = 0.388 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 5 = 0.332 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 6 = 0.385 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 7 = 0.335 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 8 = 0.283 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 9 = 0.327 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all KL = 0.259 +- 0.253 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all L1 = 0.351 +- 0.244 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.149
NEC for r=0.6 class 0 = 0.477 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 1 = 0.484 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 2 = 0.464 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 3 = 0.397 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 4 = 0.42 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 5 = 0.415 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 6 = 0.402 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 7 = 0.457 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 8 = 0.341 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 9 = 0.408 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all KL = 0.388 +- 0.223 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all L1 = 0.428 +- 0.180 (in-sample avg dev_std = 0.328)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.637
NEC for r=0.9 class 0 = 0.282 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 1 = 0.154 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 2 = 0.42 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 3 = 0.424 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 4 = 0.404 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 5 = 0.588 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 6 = 0.497 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 7 = 0.39 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 8 = 0.333 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 9 = 0.461 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all KL = 0.559 +- 0.327 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all L1 = 0.389 +- 0.265 (in-sample avg dev_std = 0.456)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.954
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0 = 0.06 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.018 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.26 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.245 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.18 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.43 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.34 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.183 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.201 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.283 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.372 +- 0.363 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.213 +- 0.246 (in-sample avg dev_std = 0.397)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.08
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
NEC for r=0.3 class 0 = 0.296 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 1 = 0.52 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 2 = 0.387 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 3 = 0.336 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 4 = 0.355 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 5 = 0.391 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 6 = 0.366 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 7 = 0.406 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 8 = 0.284 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 9 = 0.412 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all KL = 0.29 +- 0.262 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all L1 = 0.378 +- 0.242 (in-sample avg dev_std = 0.222)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.165
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.143
NEC for r=0.6 class 0 = 0.494 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 1 = 0.485 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 2 = 0.443 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 3 = 0.45 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 4 = 0.455 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 5 = 0.487 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 6 = 0.491 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 7 = 0.499 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 8 = 0.356 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 9 = 0.48 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 all KL = 0.421 +- 0.230 (in-sample avg dev_std = 0.338)
NEC for r=0.6 all L1 = 0.465 +- 0.178 (in-sample avg dev_std = 0.338)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.589
NEC for r=0.9 class 0 = 0.429 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 1 = 0.078 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 2 = 0.48 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 3 = 0.392 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 4 = 0.45 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 5 = 0.601 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 6 = 0.549 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 7 = 0.378 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 8 = 0.395 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 9 = 0.524 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 all KL = 0.58 +- 0.335 (in-sample avg dev_std = 0.448)
NEC for r=0.9 all L1 = 0.421 +- 0.276 (in-sample avg dev_std = 0.448)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.808
NEC for r=1.0 class 0 = 0.196 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 1 = 0.018 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 2 = 0.354 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 3 = 0.249 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 4 = 0.276 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 5 = 0.359 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 6 = 0.354 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 7 = 0.179 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 8 = 0.269 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 9 = 0.344 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all KL = 0.4 +- 0.352 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all L1 = 0.255 +- 0.256 (in-sample avg dev_std = 0.407)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.223 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 1 = 0.405 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 2 = 0.291 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 3 = 0.296 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 4 = 0.407 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 5 = 0.284 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 6 = 0.342 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 7 = 0.335 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 8 = 0.321 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 9 = 0.37 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all KL = 0.232 +- 0.239 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all L1 = 0.328 +- 0.241 (in-sample avg dev_std = 0.196)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.161
NEC for r=0.6 class 0 = 0.503 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 1 = 0.484 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 2 = 0.547 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 3 = 0.511 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 4 = 0.52 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 5 = 0.581 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 6 = 0.543 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 7 = 0.537 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 8 = 0.508 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 9 = 0.523 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all KL = 0.501 +- 0.220 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all L1 = 0.525 +- 0.160 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.55
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.404
NEC for r=0.9 class 0 = 0.665 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 1 = 0.084 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 2 = 0.502 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 3 = 0.498 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 4 = 0.483 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 5 = 0.577 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 6 = 0.586 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 7 = 0.529 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 8 = 0.495 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 9 = 0.583 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all KL = 0.595 +- 0.305 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all L1 = 0.494 +- 0.255 (in-sample avg dev_std = 0.429)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.599
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.52
NEC for r=1.0 class 0 = 0.655 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 1 = 0.04 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 2 = 0.39 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 3 = 0.417 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 4 = 0.401 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 5 = 0.584 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 6 = 0.512 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 7 = 0.411 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 8 = 0.483 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 9 = 0.563 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 all KL = 0.57 +- 0.350 (in-sample avg dev_std = 0.429)
NEC for r=1.0 all L1 = 0.439 +- 0.286 (in-sample avg dev_std = 0.429)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 12:41:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:41:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 12:42:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9957
Train Loss: 0.0203
ID Validation ACCURACY: 0.9063
ID Validation Loss: 0.3567
ID Test ACCURACY: 0.9043
ID Test Loss: 0.3557
OOD Validation ACCURACY: 0.8889
OOD Validation Loss: 0.4423
OOD Test ACCURACY: 0.6141
OOD Test Loss: 8.5453

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.9674
Train Loss: 0.0974
ID Validation ACCURACY: 0.8981
ID Validation Loss: 0.3375
ID Test ACCURACY: 0.8983
ID Test Loss: 0.3318
OOD Validation ACCURACY: 0.8900
OOD Validation Loss: 0.3691
OOD Test ACCURACY: 0.7417
OOD Test Loss: 1.0086

[0m[1;37mINFO[0m: [1mChartInfo 0.9043 0.6141 0.8983 0.7417 0.8981 0.8900[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.121
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.121
SUFF++ for r=0.3 class 0 = 0.634 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 1 = 0.663 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 2 = 0.6 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 3 = 0.584 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 4 = 0.609 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 5 = 0.613 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 6 = 0.617 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 7 = 0.611 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 8 = 0.617 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 9 = 0.59 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all KL = 0.758 +- 0.147 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all L1 = 0.614 +- 0.125 (in-sample avg dev_std = 0.247)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
SUFF++ for r=0.6 class 0 = 0.468 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 1 = 0.513 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 2 = 0.493 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 3 = 0.489 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 4 = 0.52 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 5 = 0.473 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 6 = 0.466 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 7 = 0.472 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 8 = 0.505 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 9 = 0.476 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all KL = 0.538 +- 0.292 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all L1 = 0.488 +- 0.213 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.768
SUFF++ for r=0.9 class 0 = 0.962 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1 = 0.888 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 2 = 0.823 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 3 = 0.775 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 4 = 0.821 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 5 = 0.72 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 6 = 0.805 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 7 = 0.837 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 8 = 0.866 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 9 = 0.753 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.843 +- 0.230 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.828 +- 0.201 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
SUFF++ for r=0.3 class 0 = 0.643 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 1 = 0.635 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 2 = 0.62 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 3 = 0.631 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 4 = 0.609 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 5 = 0.653 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 6 = 0.619 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 7 = 0.614 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 8 = 0.573 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 9 = 0.609 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all KL = 0.765 +- 0.145 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all L1 = 0.621 +- 0.126 (in-sample avg dev_std = 0.250)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.127
SUFF++ for r=0.6 class 0 = 0.453 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1 = 0.562 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 2 = 0.542 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 3 = 0.53 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 4 = 0.479 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 5 = 0.449 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 6 = 0.468 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 7 = 0.498 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 8 = 0.548 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 9 = 0.452 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.541 +- 0.295 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.499 +- 0.228 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.753
SUFF++ for r=0.9 class 0 = 0.917 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 2 = 0.79 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 3 = 0.837 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 4 = 0.785 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 5 = 0.738 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 6 = 0.761 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 7 = 0.858 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 8 = 0.85 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 9 = 0.784 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all KL = 0.848 +- 0.224 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all L1 = 0.83 +- 0.202 (in-sample avg dev_std = 0.231)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
SUFF++ for r=0.3 class 0 = 0.66 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 1 = 0.664 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 2 = 0.62 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 3 = 0.583 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 4 = 0.583 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 5 = 0.617 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 6 = 0.589 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 7 = 0.613 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 8 = 0.608 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 9 = 0.61 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all KL = 0.752 +- 0.151 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all L1 = 0.616 +- 0.133 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.186
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
SUFF++ for r=0.6 class 0 = 0.576 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 1 = 0.624 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 2 = 0.563 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 3 = 0.543 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 4 = 0.528 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 5 = 0.518 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 6 = 0.467 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 7 = 0.598 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 8 = 0.525 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 9 = 0.489 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all KL = 0.614 +- 0.295 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all L1 = 0.545 +- 0.246 (in-sample avg dev_std = 0.158)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.614
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.586
SUFF++ for r=0.9 class 0 = 0.813 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 1 = 0.932 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 2 = 0.768 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 3 = 0.763 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 4 = 0.729 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 5 = 0.67 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 6 = 0.716 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 7 = 0.788 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 8 = 0.731 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 9 = 0.701 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all KL = 0.793 +- 0.251 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all L1 = 0.765 +- 0.222 (in-sample avg dev_std = 0.292)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.121
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.32 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 1 = 0.338 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 2 = 0.35 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 3 = 0.381 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 4 = 0.366 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 5 = 0.357 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 6 = 0.369 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 7 = 0.371 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 8 = 0.395 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 9 = 0.401 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 all KL = 0.23 +- 0.179 (in-sample avg dev_std = 0.250)
NEC for r=0.3 all L1 = 0.364 +- 0.149 (in-sample avg dev_std = 0.250)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
NEC for r=0.6 class 0 = 0.555 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 1 = 0.442 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 2 = 0.518 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 3 = 0.542 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 4 = 0.502 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 5 = 0.534 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 6 = 0.552 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 7 = 0.527 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 8 = 0.551 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 class 9 = 0.537 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all KL = 0.501 +- 0.247 (in-sample avg dev_std = 0.331)
NEC for r=0.6 all L1 = 0.525 +- 0.172 (in-sample avg dev_std = 0.331)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.648
NEC for r=0.9 class 0 = 0.18 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 1 = 0.217 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 2 = 0.36 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 3 = 0.49 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 4 = 0.362 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 5 = 0.552 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 6 = 0.473 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 7 = 0.402 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 8 = 0.334 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 9 = 0.476 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 all KL = 0.526 +- 0.325 (in-sample avg dev_std = 0.427)
NEC for r=0.9 all L1 = 0.38 +- 0.262 (in-sample avg dev_std = 0.427)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.959
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.853
NEC for r=1.0 class 0 = 0.077 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 1 = 0.04 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 2 = 0.234 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 3 = 0.276 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 4 = 0.197 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 5 = 0.416 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 6 = 0.294 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 7 = 0.227 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 8 = 0.159 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 9 = 0.328 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all KL = 0.374 +- 0.351 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all L1 = 0.219 +- 0.244 (in-sample avg dev_std = 0.388)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.345 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 1 = 0.358 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 2 = 0.357 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 3 = 0.343 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 4 = 0.356 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 5 = 0.312 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 6 = 0.381 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 7 = 0.355 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 8 = 0.399 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 class 9 = 0.395 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 all KL = 0.228 +- 0.181 (in-sample avg dev_std = 0.252)
NEC for r=0.3 all L1 = 0.361 +- 0.153 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.13
NEC for r=0.6 class 0 = 0.551 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 1 = 0.404 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 2 = 0.466 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 3 = 0.526 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 4 = 0.524 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 5 = 0.541 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 6 = 0.54 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 7 = 0.471 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 8 = 0.481 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 9 = 0.541 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all KL = 0.482 +- 0.254 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all L1 = 0.503 +- 0.187 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.295 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 1 = 0.122 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 2 = 0.376 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 3 = 0.492 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 4 = 0.392 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 5 = 0.555 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 6 = 0.538 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 7 = 0.351 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 8 = 0.338 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 9 = 0.516 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all KL = 0.546 +- 0.332 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all L1 = 0.393 +- 0.270 (in-sample avg dev_std = 0.433)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.817
NEC for r=1.0 class 0 = 0.134 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 1 = 0.033 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 2 = 0.292 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 3 = 0.304 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 4 = 0.273 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 5 = 0.341 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 6 = 0.35 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 7 = 0.162 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 8 = 0.244 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 class 9 = 0.346 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 all KL = 0.375 +- 0.355 (in-sample avg dev_std = 0.396)
NEC for r=1.0 all L1 = 0.245 +- 0.260 (in-sample avg dev_std = 0.396)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
NEC for r=0.3 class 0 = 0.324 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 1 = 0.338 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 2 = 0.357 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 3 = 0.408 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 4 = 0.415 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 5 = 0.348 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 6 = 0.4 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 7 = 0.378 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 8 = 0.384 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 class 9 = 0.379 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 all KL = 0.244 +- 0.193 (in-sample avg dev_std = 0.256)
NEC for r=0.3 all L1 = 0.373 +- 0.163 (in-sample avg dev_std = 0.256)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.186
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
NEC for r=0.6 class 0 = 0.413 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 1 = 0.35 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 2 = 0.452 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 3 = 0.455 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 4 = 0.508 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 5 = 0.482 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 6 = 0.539 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 7 = 0.404 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 8 = 0.498 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 9 = 0.512 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all KL = 0.404 +- 0.261 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all L1 = 0.459 +- 0.213 (in-sample avg dev_std = 0.304)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.614
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.47
NEC for r=0.9 class 0 = 0.61 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 1 = 0.135 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 2 = 0.427 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 3 = 0.566 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 4 = 0.433 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 5 = 0.546 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 6 = 0.592 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 7 = 0.459 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 8 = 0.503 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 9 = 0.611 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 all KL = 0.605 +- 0.335 (in-sample avg dev_std = 0.434)
NEC for r=0.9 all L1 = 0.483 +- 0.271 (in-sample avg dev_std = 0.434)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.615
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.624
NEC for r=1.0 class 0 = 0.327 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 1 = 0.213 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 2 = 0.392 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 3 = 0.36 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 4 = 0.482 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 5 = 0.481 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 6 = 0.563 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 7 = 0.334 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 8 = 0.497 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 class 9 = 0.536 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 all KL = 0.564 +- 0.372 (in-sample avg dev_std = 0.426)
NEC for r=1.0 all L1 = 0.414 +- 0.298 (in-sample avg dev_std = 0.426)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 13:07:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:07:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 0.9959
Train Loss: 0.0198
ID Validation ACCURACY: 0.9006
ID Validation Loss: 0.3858
ID Test ACCURACY: 0.8987
ID Test Loss: 0.3853
OOD Validation ACCURACY: 0.8801
OOD Validation Loss: 0.4607
OOD Test ACCURACY: 0.6320
OOD Test Loss: 2.5556

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ACCURACY: 0.9966
Train Loss: 0.0176
ID Validation ACCURACY: 0.8933
ID Validation Loss: 0.3904
ID Test ACCURACY: 0.8970
ID Test Loss: 0.3980
OOD Validation ACCURACY: 0.8859
OOD Validation Loss: 0.4307
OOD Test ACCURACY: 0.7093
OOD Test Loss: 1.4702

[0m[1;37mINFO[0m: [1mChartInfo 0.8987 0.6320 0.8970 0.7093 0.8933 0.8859[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.649 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 1 = 0.642 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 2 = 0.624 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 3 = 0.616 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 4 = 0.606 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 5 = 0.621 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 6 = 0.61 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 7 = 0.643 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 8 = 0.661 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 9 = 0.616 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all KL = 0.8 +- 0.129 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all L1 = 0.629 +- 0.116 (in-sample avg dev_std = 0.226)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.226
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.194
SUFF++ for r=0.6 class 0 = 0.437 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1 = 0.503 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 2 = 0.506 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 3 = 0.47 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 4 = 0.566 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 5 = 0.48 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 6 = 0.535 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 7 = 0.504 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 8 = 0.56 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 9 = 0.503 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.554 +- 0.286 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.506 +- 0.211 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.764
SUFF++ for r=0.9 class 0 = 0.958 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.934 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.795 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 3 = 0.732 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 4 = 0.839 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 5 = 0.701 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 6 = 0.825 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 7 = 0.786 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 8 = 0.846 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 9 = 0.771 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.835 +- 0.236 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.206 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.082
SUFF++ for r=0.3 class 0 = 0.64 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 1 = 0.627 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 2 = 0.622 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 3 = 0.637 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 4 = 0.635 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 5 = 0.632 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 6 = 0.63 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 7 = 0.616 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 8 = 0.612 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 9 = 0.626 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 all KL = 0.806 +- 0.110 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 all L1 = 0.628 +- 0.104 (in-sample avg dev_std = 0.237)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.164
SUFF++ for r=0.6 class 0 = 0.514 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 1 = 0.489 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 2 = 0.538 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 3 = 0.521 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 4 = 0.543 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 5 = 0.471 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 6 = 0.496 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 7 = 0.469 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 8 = 0.544 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 9 = 0.478 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 all KL = 0.545 +- 0.285 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 all L1 = 0.506 +- 0.211 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.798
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.754
SUFF++ for r=0.9 class 0 = 0.922 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 1 = 0.943 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 2 = 0.74 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 3 = 0.794 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 4 = 0.811 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 5 = 0.735 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 6 = 0.806 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 7 = 0.795 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 8 = 0.789 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 9 = 0.782 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all KL = 0.835 +- 0.229 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all L1 = 0.814 +- 0.210 (in-sample avg dev_std = 0.252)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
SUFF++ for r=0.3 class 0 = 0.658 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 1 = 0.663 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 2 = 0.624 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 3 = 0.624 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 4 = 0.627 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 5 = 0.639 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 6 = 0.646 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 7 = 0.636 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 8 = 0.633 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 9 = 0.648 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all KL = 0.822 +- 0.102 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all L1 = 0.64 +- 0.100 (in-sample avg dev_std = 0.227)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.18
SUFF++ for r=0.6 class 0 = 0.515 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 1 = 0.589 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 2 = 0.514 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 3 = 0.5 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 4 = 0.502 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 5 = 0.488 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 6 = 0.447 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 7 = 0.515 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 8 = 0.481 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 9 = 0.48 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all KL = 0.547 +- 0.291 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all L1 = 0.504 +- 0.209 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.548
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.513
SUFF++ for r=0.9 class 0 = 0.68 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.971 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.705 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 3 = 0.692 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 4 = 0.79 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 5 = 0.676 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 6 = 0.762 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 7 = 0.745 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 8 = 0.754 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 9 = 0.697 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.802 +- 0.228 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.75 +- 0.212 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
NEC for r=0.3 class 0 = 0.358 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 1 = 0.357 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 2 = 0.375 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 3 = 0.4 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 4 = 0.407 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 5 = 0.374 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 6 = 0.403 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 7 = 0.383 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 8 = 0.371 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 9 = 0.406 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 all KL = 0.221 +- 0.160 (in-sample avg dev_std = 0.239)
NEC for r=0.3 all L1 = 0.383 +- 0.127 (in-sample avg dev_std = 0.239)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.226
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.19
NEC for r=0.6 class 0 = 0.583 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 1 = 0.48 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 2 = 0.528 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 3 = 0.557 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 4 = 0.469 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 5 = 0.513 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 6 = 0.478 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 7 = 0.519 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 8 = 0.484 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 9 = 0.496 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all KL = 0.484 +- 0.226 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all L1 = 0.511 +- 0.157 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.61
NEC for r=0.9 class 0 = 0.22 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 1 = 0.212 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 2 = 0.447 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 3 = 0.589 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 4 = 0.316 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 5 = 0.629 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 6 = 0.382 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 7 = 0.469 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 8 = 0.368 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 9 = 0.478 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 all KL = 0.561 +- 0.327 (in-sample avg dev_std = 0.448)
NEC for r=0.9 all L1 = 0.407 +- 0.264 (in-sample avg dev_std = 0.448)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.961
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.835
NEC for r=1.0 class 0 = 0.056 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 1 = 0.025 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 2 = 0.247 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 3 = 0.374 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 4 = 0.156 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 5 = 0.424 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 6 = 0.249 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 7 = 0.252 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 8 = 0.207 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 9 = 0.375 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all KL = 0.384 +- 0.351 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all L1 = 0.232 +- 0.248 (in-sample avg dev_std = 0.414)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.083
NEC for r=0.3 class 0 = 0.354 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 1 = 0.379 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 2 = 0.379 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 3 = 0.354 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 4 = 0.358 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 5 = 0.345 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 6 = 0.385 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 7 = 0.374 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 8 = 0.381 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 9 = 0.38 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all KL = 0.204 +- 0.153 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all L1 = 0.369 +- 0.124 (in-sample avg dev_std = 0.224)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.167
NEC for r=0.6 class 0 = 0.546 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 1 = 0.484 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 2 = 0.519 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 3 = 0.537 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 4 = 0.503 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 5 = 0.532 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 6 = 0.516 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 7 = 0.525 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 8 = 0.499 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 9 = 0.496 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all KL = 0.502 +- 0.207 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all L1 = 0.515 +- 0.145 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.798
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0 = 0.295 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 1 = 0.149 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 2 = 0.454 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 3 = 0.596 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 4 = 0.335 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 5 = 0.573 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 6 = 0.41 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 7 = 0.433 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 8 = 0.422 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 9 = 0.489 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all KL = 0.568 +- 0.323 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all L1 = 0.411 +- 0.265 (in-sample avg dev_std = 0.445)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.804
NEC for r=1.0 class 0 = 0.096 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 1 = 0.034 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 2 = 0.276 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 3 = 0.446 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 4 = 0.203 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 5 = 0.37 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 6 = 0.267 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 7 = 0.23 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 8 = 0.289 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 9 = 0.364 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all KL = 0.393 +- 0.357 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all L1 = 0.254 +- 0.261 (in-sample avg dev_std = 0.407)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
NEC for r=0.3 class 0 = 0.345 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1 = 0.342 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 2 = 0.381 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 3 = 0.369 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 4 = 0.381 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 5 = 0.354 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 6 = 0.396 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 7 = 0.356 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 8 = 0.36 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 9 = 0.387 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.192 +- 0.138 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.367 +- 0.118 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.175
NEC for r=0.6 class 0 = 0.505 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 1 = 0.447 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 2 = 0.515 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 3 = 0.519 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 4 = 0.507 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 5 = 0.528 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 6 = 0.525 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 7 = 0.513 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 8 = 0.545 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 9 = 0.517 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all KL = 0.495 +- 0.219 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all L1 = 0.511 +- 0.151 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.548
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.399
NEC for r=0.9 class 0 = 0.635 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 1 = 0.065 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 2 = 0.521 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 3 = 0.583 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 4 = 0.34 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 5 = 0.55 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 6 = 0.496 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 7 = 0.508 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 8 = 0.547 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 class 9 = 0.526 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 all KL = 0.553 +- 0.318 (in-sample avg dev_std = 0.410)
NEC for r=0.9 all L1 = 0.473 +- 0.265 (in-sample avg dev_std = 0.410)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.658
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.549
NEC for r=1.0 class 0 = 0.488 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 1 = 0.022 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 2 = 0.404 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 3 = 0.598 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 4 = 0.302 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 5 = 0.54 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 6 = 0.388 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 7 = 0.356 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 8 = 0.516 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 class 9 = 0.479 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 all KL = 0.522 +- 0.350 (in-sample avg dev_std = 0.434)
NEC for r=1.0 all L1 = 0.404 +- 0.279 (in-sample avg dev_std = 0.434)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Mon Apr  8 13:32:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/08/2024 01:32:39 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 164...
[0m[1;37mINFO[0m: [1mCheckpoint 164: 
-----------------------------------
Train ACCURACY: 0.9971
Train Loss: 0.0164
ID Validation ACCURACY: 0.9043
ID Validation Loss: 0.3738
ID Test ACCURACY: 0.9040
ID Test Loss: 0.3712
OOD Validation ACCURACY: 0.8893
OOD Validation Loss: 0.4367
OOD Test ACCURACY: 0.6837
OOD Test Loss: 1.6646

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ACCURACY: 0.9851
Train Loss: 0.0519
ID Validation ACCURACY: 0.8954
ID Validation Loss: 0.3700
ID Test ACCURACY: 0.8970
ID Test Loss: 0.3527
OOD Validation ACCURACY: 0.8943
OOD Validation Loss: 0.3780
OOD Test ACCURACY: 0.7649
OOD Test Loss: 0.9929

[0m[1;37mINFO[0m: [1mChartInfo 0.9040 0.6837 0.8970 0.7649 0.8954 0.8943[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.089
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
SUFF++ for r=0.3 class 0 = 0.625 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 1 = 0.595 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 2 = 0.6 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 3 = 0.6 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 4 = 0.588 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 5 = 0.628 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 6 = 0.588 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 7 = 0.599 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 8 = 0.602 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 9 = 0.571 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all KL = 0.747 +- 0.133 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all L1 = 0.599 +- 0.119 (in-sample avg dev_std = 0.255)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.218
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.161
SUFF++ for r=0.6 class 0 = 0.409 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 1 = 0.498 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 2 = 0.45 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 3 = 0.442 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 4 = 0.482 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 5 = 0.433 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 6 = 0.463 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 7 = 0.432 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 8 = 0.462 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 9 = 0.459 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all KL = 0.49 +- 0.280 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all L1 = 0.453 +- 0.190 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.753
SUFF++ for r=0.9 class 0 = 0.954 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 1 = 0.915 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 2 = 0.8 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 3 = 0.79 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 4 = 0.801 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 5 = 0.746 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 6 = 0.808 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 7 = 0.79 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 8 = 0.849 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 9 = 0.754 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all KL = 0.838 +- 0.238 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.208 (in-sample avg dev_std = 0.257)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.08
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
SUFF++ for r=0.3 class 0 = 0.627 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 1 = 0.605 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 2 = 0.604 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 3 = 0.629 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 4 = 0.575 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 5 = 0.616 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 6 = 0.606 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 7 = 0.598 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 8 = 0.565 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 9 = 0.593 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 all KL = 0.746 +- 0.138 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 all L1 = 0.602 +- 0.125 (in-sample avg dev_std = 0.253)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.195
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.144
SUFF++ for r=0.6 class 0 = 0.432 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 1 = 0.463 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 2 = 0.466 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 3 = 0.492 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 4 = 0.473 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 5 = 0.383 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 6 = 0.444 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 7 = 0.471 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 8 = 0.467 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 9 = 0.423 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all KL = 0.488 +- 0.265 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all L1 = 0.453 +- 0.176 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.77
SUFF++ for r=0.9 class 0 = 0.918 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.944 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.766 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 3 = 0.805 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 4 = 0.787 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 5 = 0.761 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 6 = 0.792 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 7 = 0.812 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 8 = 0.831 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 9 = 0.733 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.827 +- 0.241 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.213 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.122
SUFF++ for r=0.3 class 0 = 0.686 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 1 = 0.631 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 2 = 0.656 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 3 = 0.618 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 4 = 0.604 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 5 = 0.638 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 6 = 0.616 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 7 = 0.654 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 8 = 0.637 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 9 = 0.595 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all KL = 0.765 +- 0.143 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all L1 = 0.634 +- 0.141 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.161
SUFF++ for r=0.6 class 0 = 0.541 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 1 = 0.509 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 2 = 0.58 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 3 = 0.514 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 4 = 0.529 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 5 = 0.564 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 6 = 0.525 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 7 = 0.532 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 8 = 0.524 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 class 9 = 0.451 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all KL = 0.608 +- 0.259 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.6 all L1 = 0.527 +- 0.194 (in-sample avg dev_std = 0.145)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.582
SUFF++ for r=0.9 class 0 = 0.818 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.965 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.761 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 3 = 0.734 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 4 = 0.719 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 5 = 0.687 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 6 = 0.692 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 7 = 0.754 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 8 = 0.758 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 9 = 0.633 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.79 +- 0.249 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.756 +- 0.223 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.089
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.384 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 1 = 0.432 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 2 = 0.427 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 3 = 0.413 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 4 = 0.421 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 5 = 0.379 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 6 = 0.429 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 7 = 0.427 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 8 = 0.401 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 9 = 0.456 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 all KL = 0.281 +- 0.181 (in-sample avg dev_std = 0.260)
NEC for r=0.3 all L1 = 0.417 +- 0.142 (in-sample avg dev_std = 0.260)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.218
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
NEC for r=0.6 class 0 = 0.617 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 1 = 0.503 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 2 = 0.567 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 3 = 0.595 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 4 = 0.557 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 5 = 0.541 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 6 = 0.558 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 7 = 0.547 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 8 = 0.594 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 9 = 0.574 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all KL = 0.556 +- 0.231 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all L1 = 0.565 +- 0.145 (in-sample avg dev_std = 0.334)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.611
NEC for r=0.9 class 0 = 0.229 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.221 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.38 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 3 = 0.509 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 4 = 0.381 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 5 = 0.489 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 6 = 0.468 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 7 = 0.496 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 8 = 0.381 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 9 = 0.527 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.561 +- 0.319 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.405 +- 0.259 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.845
NEC for r=1.0 class 0 = 0.043 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 1 = 0.024 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 2 = 0.24 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 3 = 0.299 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 4 = 0.163 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 5 = 0.317 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 6 = 0.253 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 7 = 0.289 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 8 = 0.215 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 9 = 0.354 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 all KL = 0.368 +- 0.354 (in-sample avg dev_std = 0.389)
NEC for r=1.0 all L1 = 0.216 +- 0.246 (in-sample avg dev_std = 0.389)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.08
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
NEC for r=0.3 class 0 = 0.379 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 1 = 0.442 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 2 = 0.426 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 3 = 0.374 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 4 = 0.398 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 5 = 0.415 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 6 = 0.417 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 7 = 0.42 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 8 = 0.396 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 9 = 0.451 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all KL = 0.277 +- 0.189 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all L1 = 0.413 +- 0.152 (in-sample avg dev_std = 0.245)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.195
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.612 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 1 = 0.52 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 2 = 0.553 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 3 = 0.528 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 4 = 0.537 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 5 = 0.565 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 6 = 0.584 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 7 = 0.538 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 8 = 0.574 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 9 = 0.574 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 all KL = 0.541 +- 0.221 (in-sample avg dev_std = 0.346)
NEC for r=0.6 all L1 = 0.557 +- 0.137 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.607
NEC for r=0.9 class 0 = 0.314 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 1 = 0.145 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 2 = 0.354 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 3 = 0.542 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 4 = 0.383 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 5 = 0.51 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 6 = 0.469 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 7 = 0.465 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 8 = 0.442 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 9 = 0.546 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all KL = 0.577 +- 0.322 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all L1 = 0.414 +- 0.258 (in-sample avg dev_std = 0.458)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.946
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.822
NEC for r=1.0 class 0 = 0.102 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 1 = 0.024 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 2 = 0.301 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 3 = 0.345 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 4 = 0.257 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 5 = 0.292 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 6 = 0.28 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 7 = 0.213 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 8 = 0.225 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 9 = 0.408 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all KL = 0.386 +- 0.356 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all L1 = 0.242 +- 0.253 (in-sample avg dev_std = 0.402)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.326 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 1 = 0.384 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 2 = 0.336 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 3 = 0.381 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 4 = 0.44 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 5 = 0.373 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 6 = 0.399 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 7 = 0.387 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 8 = 0.392 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 9 = 0.413 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all KL = 0.257 +- 0.209 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all L1 = 0.382 +- 0.186 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.199
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.475 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1 = 0.468 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 2 = 0.44 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 3 = 0.487 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 4 = 0.469 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 5 = 0.454 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 6 = 0.486 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 7 = 0.444 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 8 = 0.533 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 9 = 0.523 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.399 +- 0.232 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.478 +- 0.164 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.634
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.443
NEC for r=0.9 class 0 = 0.53 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.072 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.415 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 3 = 0.593 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 4 = 0.48 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 5 = 0.605 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 6 = 0.605 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 7 = 0.517 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 8 = 0.517 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 9 = 0.619 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.608 +- 0.330 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.488 +- 0.272 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.63
NEC for r=1.0 class 0 = 0.236 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 1 = 0.034 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 2 = 0.407 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 3 = 0.463 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 4 = 0.468 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 5 = 0.478 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 6 = 0.538 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 7 = 0.374 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 8 = 0.391 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 class 9 = 0.517 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 all KL = 0.52 +- 0.352 (in-sample avg dev_std = 0.438)
NEC for r=1.0 all L1 = 0.384 +- 0.279 (in-sample avg dev_std = 0.438)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.759, 0.631, 0.854, 1.0], 'all_L1': [0.589, 0.555, 0.825, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.802, 0.618, 0.83, 1.0], 'all_L1': [0.696, 0.567, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.758, 0.538, 0.843, 1.0], 'all_L1': [0.614, 0.488, 0.828, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.8, 0.554, 0.835, 1.0], 'all_L1': [0.629, 0.506, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.747, 0.49, 0.838, 1.0], 'all_L1': [0.599, 0.453, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.215, 0.392, 0.525, 0.346], 'all_L1': [0.389, 0.458, 0.393, 0.22]}), defaultdict(<class 'list'>, {'all_KL': [0.259, 0.388, 0.559, 0.372], 'all_L1': [0.351, 0.428, 0.389, 0.213]}), defaultdict(<class 'list'>, {'all_KL': [0.23, 0.501, 0.526, 0.374], 'all_L1': [0.364, 0.525, 0.38, 0.219]}), defaultdict(<class 'list'>, {'all_KL': [0.221, 0.484, 0.561, 0.384], 'all_L1': [0.383, 0.511, 0.407, 0.232]}), defaultdict(<class 'list'>, {'all_KL': [0.281, 0.556, 0.561, 0.368], 'all_L1': [0.417, 0.565, 0.405, 0.216]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.768, 0.602, 0.851, 1.0], 'all_L1': [0.595, 0.528, 0.825, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.786, 0.598, 0.838, 1.0], 'all_L1': [0.675, 0.542, 0.824, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.765, 0.541, 0.848, 1.0], 'all_L1': [0.621, 0.499, 0.83, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.806, 0.545, 0.835, 1.0], 'all_L1': [0.628, 0.506, 0.814, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.746, 0.488, 0.827, 1.0], 'all_L1': [0.602, 0.453, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.21, 0.41, 0.54, 0.367], 'all_L1': [0.386, 0.473, 0.409, 0.248]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.421, 0.58, 0.4], 'all_L1': [0.378, 0.465, 0.421, 0.255]}), defaultdict(<class 'list'>, {'all_KL': [0.228, 0.482, 0.546, 0.375], 'all_L1': [0.361, 0.503, 0.393, 0.245]}), defaultdict(<class 'list'>, {'all_KL': [0.204, 0.502, 0.568, 0.393], 'all_L1': [0.369, 0.515, 0.411, 0.254]}), defaultdict(<class 'list'>, {'all_KL': [0.277, 0.541, 0.577, 0.386], 'all_L1': [0.413, 0.557, 0.414, 0.242]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.801, 0.62, 0.836, 1.0], 'all_L1': [0.625, 0.532, 0.784, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.83, 0.55, 0.802, 1.0], 'all_L1': [0.721, 0.493, 0.756, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.752, 0.614, 0.793, 1.0], 'all_L1': [0.616, 0.545, 0.765, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.822, 0.547, 0.802, 1.0], 'all_L1': [0.64, 0.504, 0.75, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.765, 0.608, 0.79, 1.0], 'all_L1': [0.634, 0.527, 0.756, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.192, 0.411, 0.556, 0.447], 'all_L1': [0.366, 0.48, 0.466, 0.351]}), defaultdict(<class 'list'>, {'all_KL': [0.232, 0.501, 0.595, 0.57], 'all_L1': [0.328, 0.525, 0.494, 0.439]}), defaultdict(<class 'list'>, {'all_KL': [0.244, 0.404, 0.605, 0.564], 'all_L1': [0.373, 0.459, 0.483, 0.414]}), defaultdict(<class 'list'>, {'all_KL': [0.192, 0.495, 0.553, 0.522], 'all_L1': [0.367, 0.511, 0.473, 0.404]}), defaultdict(<class 'list'>, {'all_KL': [0.257, 0.399, 0.608, 0.52], 'all_L1': [0.382, 0.478, 0.488, 0.384]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.625 +- 0.038, 0.514 +- 0.042, 0.824 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.773 +- 0.023, 0.566 +- 0.052, 0.840 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.102 +- 0.011, 0.164 +- 0.016, 0.765 +- 0.006
nec class all_L1  =  0.381 +- 0.023, 0.497 +- 0.049, 0.395 +- 0.010, 0.220 +- 0.006
nec class all_KL  =  0.241 +- 0.025, 0.464 +- 0.065, 0.546 +- 0.017, 0.369 +- 0.013
nec_acc_int  =  0.099 +- 0.008, 0.165 +- 0.014, 0.629 +- 0.015, 0.845 +- 0.006

Eval split val
suff++ class all_L1  =  0.624 +- 0.028, 0.506 +- 0.030, 0.822 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.774 +- 0.020, 0.555 +- 0.042, 0.840 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.097 +- 0.009, 0.144 +- 0.012, 0.759 +- 0.014
nec class all_L1  =  0.381 +- 0.018, 0.503 +- 0.033, 0.410 +- 0.009, 0.249 +- 0.005
nec class all_KL  =  0.242 +- 0.035, 0.471 +- 0.049, 0.562 +- 0.016, 0.384 +- 0.012
nec_acc_int  =  0.091 +- 0.006, 0.150 +- 0.013, 0.608 +- 0.012, 0.812 +- 0.006

Eval split test
suff++ class all_L1  =  0.647 +- 0.038, 0.520 +- 0.019, 0.762 +- 0.012, 1.000 +- 0.000
suff++ class all_KL  =  0.794 +- 0.031, 0.588 +- 0.032, 0.805 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.111 +- 0.008, 0.161 +- 0.013, 0.570 +- 0.055
nec class all_L1  =  0.363 +- 0.018, 0.491 +- 0.024, 0.481 +- 0.010, 0.398 +- 0.030
nec class all_KL  =  0.223 +- 0.027, 0.442 +- 0.046, 0.583 +- 0.024, 0.525 +- 0.044
nec_acc_int  =  0.105 +- 0.008, 0.158 +- 0.010, 0.440 +- 0.034, 0.602 +- 0.060


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.503 +- 0.013, 0.506 +- 0.004, 0.609 +- 0.004, 0.610 +- 0.003
Faith. Armon (L1)= 		  =  0.472 +- 0.012, 0.501 +- 0.007, 0.534 +- 0.009, 0.361 +- 0.009
Faith. GMean (L1)= 	  =  0.487 +- 0.010, 0.503 +- 0.006, 0.570 +- 0.007, 0.469 +- 0.007
Faith. Aritm (KL)= 		  =  0.507 +- 0.015, 0.515 +- 0.007, 0.693 +- 0.006, 0.684 +- 0.006
Faith. Armon (KL)= 		  =  0.367 +- 0.028, 0.503 +- 0.019, 0.662 +- 0.011, 0.539 +- 0.014
Faith. GMean (KL)= 	  =  0.431 +- 0.022, 0.509 +- 0.013, 0.677 +- 0.008, 0.607 +- 0.010

Eval split val
Faith. Aritm (L1)= 		  =  0.503 +- 0.013, 0.504 +- 0.004, 0.616 +- 0.004, 0.624 +- 0.003
Faith. Armon (L1)= 		  =  0.473 +- 0.012, 0.502 +- 0.004, 0.547 +- 0.008, 0.398 +- 0.006
Faith. GMean (L1)= 	  =  0.488 +- 0.012, 0.503 +- 0.004, 0.580 +- 0.006, 0.499 +- 0.005
Faith. Aritm (KL)= 		  =  0.508 +- 0.017, 0.513 +- 0.006, 0.701 +- 0.005, 0.692 +- 0.006
Faith. Armon (KL)= 		  =  0.367 +- 0.040, 0.505 +- 0.013, 0.673 +- 0.009, 0.555 +- 0.012
Faith. GMean (KL)= 	  =  0.431 +- 0.030, 0.509 +- 0.009, 0.687 +- 0.007, 0.620 +- 0.010

Eval split test
Faith. Aritm (L1)= 		  =  0.505 +- 0.011, 0.505 +- 0.003, 0.622 +- 0.005, 0.699 +- 0.015
Faith. Armon (L1)= 		  =  0.464 +- 0.008, 0.504 +- 0.004, 0.589 +- 0.006, 0.569 +- 0.030
Faith. GMean (L1)= 	  =  0.484 +- 0.005, 0.505 +- 0.003, 0.605 +- 0.005, 0.631 +- 0.024
Faith. Aritm (KL)= 		  =  0.509 +- 0.012, 0.515 +- 0.008, 0.694 +- 0.008, 0.762 +- 0.022
Faith. Armon (KL)= 		  =  0.347 +- 0.031, 0.502 +- 0.017, 0.676 +- 0.013, 0.687 +- 0.039
Faith. GMean (KL)= 	  =  0.420 +- 0.021, 0.508 +- 0.013, 0.685 +- 0.010, 0.724 +- 0.031
Computed for split load_split = id



Completed in  2:06:13.009166  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color
DONE all :)
