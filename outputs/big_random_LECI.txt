nohup: ignoring input
Time to compute metrics for random explanations!
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:49:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:49:58 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.8846
Train Loss: 0.4663
ID Validation ACCURACY: 0.8883
ID Validation Loss: 0.4567
ID Test ACCURACY: 0.8753
ID Test Loss: 0.4923
OOD Validation ACCURACY: 0.8767
OOD Validation Loss: 0.5561
OOD Test ACCURACY: 0.8990
OOD Test Loss: 0.4482

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.8700
Train Loss: 0.4809
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.4691
ID Test ACCURACY: 0.8660
ID Test Loss: 0.5000
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4306
OOD Test ACCURACY: 0.6947
OOD Test Loss: 0.8828

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8990 0.8660 0.6947 0.8710 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.200
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.270
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.306
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.308
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.183
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.239
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.248
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.248


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.20006625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.414
SUFF++ for r=0.3 class 0 = 0.47 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 class 1 = 0.507 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 class 2 = 0.411 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 all KL = 0.412 +- 0.299 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.3 all L1 = 0.463 +- 0.177 (in-sample avg dev_std = 0.525)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.27043125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.487
SUFF++ for r=0.6 class 0 = 0.395 +- 0.311 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.575 +- 0.311 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.357 +- 0.311 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.427 +- 0.311 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.443 +- 0.170 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30637000000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.706
SUFF++ for r=0.9 class 0 = 0.629 +- 0.294 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 class 1 = 0.71 +- 0.294 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 class 2 = 0.647 +- 0.294 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 all KL = 0.71 +- 0.294 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.9 all L1 = 0.662 +- 0.225 (in-sample avg dev_std = 0.325)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18305750000000004
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.459
SUFF++ for r=0.3 class 0 = 0.38 +- 0.310 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 1 = 0.611 +- 0.310 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 2 = 0.439 +- 0.310 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all KL = 0.386 +- 0.310 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all L1 = 0.479 +- 0.165 (in-sample avg dev_std = 0.608)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23856249999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.548
SUFF++ for r=0.6 class 0 = 0.439 +- 0.340 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 1 = 0.661 +- 0.340 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 class 2 = 0.414 +- 0.340 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 all KL = 0.469 +- 0.340 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.6 all L1 = 0.507 +- 0.189 (in-sample avg dev_std = 0.526)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24831375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.739
SUFF++ for r=0.9 class 0 = 0.673 +- 0.303 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 class 1 = 0.786 +- 0.303 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 class 2 = 0.643 +- 0.303 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 all KL = 0.725 +- 0.303 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.9 all L1 = 0.702 +- 0.232 (in-sample avg dev_std = 0.335)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.20006625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.488
NEC for r=0.3 class 0 = 0.46 +- 0.321 (in-sample avg dev_std = 0.494)
NEC for r=0.3 class 1 = 0.463 +- 0.321 (in-sample avg dev_std = 0.494)
NEC for r=0.3 class 2 = 0.5 +- 0.321 (in-sample avg dev_std = 0.494)
NEC for r=0.3 all KL = 0.517 +- 0.321 (in-sample avg dev_std = 0.494)
NEC for r=0.3 all L1 = 0.474 +- 0.220 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.27043125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.587
NEC for r=0.6 class 0 = 0.529 +- 0.311 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 1 = 0.404 +- 0.311 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 2 = 0.525 +- 0.311 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all KL = 0.512 +- 0.311 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all L1 = 0.486 +- 0.177 (in-sample avg dev_std = 0.542)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30637000000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.599
NEC for r=0.9 class 0 = 0.501 +- 0.306 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 1 = 0.399 +- 0.306 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 2 = 0.51 +- 0.306 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all KL = 0.461 +- 0.306 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all L1 = 0.47 +- 0.174 (in-sample avg dev_std = 0.509)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30779625000000005
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.51 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 1 = 0.396 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 class 2 = 0.512 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all KL = 0.463 +- 0.296 (in-sample avg dev_std = 0.516)
NEC for r=1.0 all L1 = 0.472 +- 0.161 (in-sample avg dev_std = 0.516)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18305750000000004
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.569
NEC for r=0.3 class 0 = 0.427 +- 0.321 (in-sample avg dev_std = 0.517)
NEC for r=0.3 class 1 = 0.326 +- 0.321 (in-sample avg dev_std = 0.517)
NEC for r=0.3 class 2 = 0.362 +- 0.321 (in-sample avg dev_std = 0.517)
NEC for r=0.3 all KL = 0.43 +- 0.321 (in-sample avg dev_std = 0.517)
NEC for r=0.3 all L1 = 0.371 +- 0.222 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23856249999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.679
NEC for r=0.6 class 0 = 0.402 +- 0.339 (in-sample avg dev_std = 0.526)
NEC for r=0.6 class 1 = 0.287 +- 0.339 (in-sample avg dev_std = 0.526)
NEC for r=0.6 class 2 = 0.43 +- 0.339 (in-sample avg dev_std = 0.526)
NEC for r=0.6 all KL = 0.421 +- 0.339 (in-sample avg dev_std = 0.526)
NEC for r=0.6 all L1 = 0.372 +- 0.195 (in-sample avg dev_std = 0.526)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24831375
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.687
NEC for r=0.9 class 0 = 0.39 +- 0.305 (in-sample avg dev_std = 0.523)
NEC for r=0.9 class 1 = 0.276 +- 0.305 (in-sample avg dev_std = 0.523)
NEC for r=0.9 class 2 = 0.406 +- 0.305 (in-sample avg dev_std = 0.523)
NEC for r=0.9 all KL = 0.379 +- 0.305 (in-sample avg dev_std = 0.523)
NEC for r=0.9 all L1 = 0.356 +- 0.183 (in-sample avg dev_std = 0.523)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.24840625000000002
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.678
NEC for r=1.0 class 0 = 0.395 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 class 1 = 0.284 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 class 2 = 0.432 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 all KL = 0.393 +- 0.316 (in-sample avg dev_std = 0.527)
NEC for r=1.0 all L1 = 0.369 +- 0.190 (in-sample avg dev_std = 0.527)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:52:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:52:38 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.8872
Train Loss: 0.4454
ID Validation ACCURACY: 0.8927
ID Validation Loss: 0.4356
ID Test ACCURACY: 0.8933
ID Test Loss: 0.4534
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.4829
OOD Test ACCURACY: 0.8907
OOD Test Loss: 0.4426

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8367
Train Loss: 0.5254
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.5010
ID Test ACCURACY: 0.8350
ID Test Loss: 0.5355
OOD Validation ACCURACY: 0.9210
OOD Validation Loss: 0.5277
OOD Test ACCURACY: 0.8627
OOD Test Loss: 0.5303

[0m[1;37mINFO[0m: [1mChartInfo 0.8933 0.8907 0.8350 0.8627 0.8440 0.9210[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.215
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.283
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.306
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.307
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.196
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.238
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.253
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.256


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21512124999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.387
SUFF++ for r=0.3 class 0 = 0.43 +- 0.283 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.569 +- 0.283 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.406 +- 0.283 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.407 +- 0.283 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.469 +- 0.159 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28295000000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.459
SUFF++ for r=0.6 class 0 = 0.399 +- 0.280 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 class 1 = 0.498 +- 0.280 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 class 2 = 0.373 +- 0.280 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 all KL = 0.365 +- 0.280 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.6 all L1 = 0.424 +- 0.150 (in-sample avg dev_std = 0.529)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30634
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.694
SUFF++ for r=0.9 class 0 = 0.644 +- 0.291 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 1 = 0.682 +- 0.291 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 2 = 0.598 +- 0.291 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all KL = 0.681 +- 0.291 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all L1 = 0.641 +- 0.225 (in-sample avg dev_std = 0.348)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.551
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19611374999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.436
SUFF++ for r=0.3 class 0 = 0.475 +- 0.244 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 class 1 = 0.571 +- 0.244 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 class 2 = 0.473 +- 0.244 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 all KL = 0.527 +- 0.244 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 all L1 = 0.507 +- 0.146 (in-sample avg dev_std = 0.540)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.238235
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.405
SUFF++ for r=0.6 class 0 = 0.415 +- 0.291 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 1 = 0.487 +- 0.291 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 2 = 0.361 +- 0.291 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all KL = 0.415 +- 0.291 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all L1 = 0.421 +- 0.142 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25273125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.445
SUFF++ for r=0.9 class 0 = 0.52 +- 0.281 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 1 = 0.501 +- 0.281 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 2 = 0.473 +- 0.281 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all KL = 0.523 +- 0.281 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all L1 = 0.498 +- 0.199 (in-sample avg dev_std = 0.411)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21512124999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.464
NEC for r=0.3 class 0 = 0.507 +- 0.281 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 1 = 0.425 +- 0.281 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 2 = 0.499 +- 0.281 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all KL = 0.536 +- 0.281 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all L1 = 0.477 +- 0.170 (in-sample avg dev_std = 0.483)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28295000000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.528
NEC for r=0.6 class 0 = 0.508 +- 0.301 (in-sample avg dev_std = 0.533)
NEC for r=0.6 class 1 = 0.493 +- 0.301 (in-sample avg dev_std = 0.533)
NEC for r=0.6 class 2 = 0.538 +- 0.301 (in-sample avg dev_std = 0.533)
NEC for r=0.6 all KL = 0.571 +- 0.301 (in-sample avg dev_std = 0.533)
NEC for r=0.6 all L1 = 0.513 +- 0.159 (in-sample avg dev_std = 0.533)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30634
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.543
NEC for r=0.9 class 0 = 0.491 +- 0.288 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 1 = 0.472 +- 0.288 (in-sample avg dev_std = 0.499)
NEC for r=0.9 class 2 = 0.552 +- 0.288 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all KL = 0.509 +- 0.288 (in-sample avg dev_std = 0.499)
NEC for r=0.9 all L1 = 0.505 +- 0.168 (in-sample avg dev_std = 0.499)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30690125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.525
NEC for r=1.0 class 0 = 0.51 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 1 = 0.482 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 2 = 0.543 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all KL = 0.515 +- 0.279 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all L1 = 0.511 +- 0.158 (in-sample avg dev_std = 0.499)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19611374999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.536
NEC for r=0.3 class 0 = 0.418 +- 0.239 (in-sample avg dev_std = 0.474)
NEC for r=0.3 class 1 = 0.408 +- 0.239 (in-sample avg dev_std = 0.474)
NEC for r=0.3 class 2 = 0.414 +- 0.239 (in-sample avg dev_std = 0.474)
NEC for r=0.3 all KL = 0.371 +- 0.239 (in-sample avg dev_std = 0.474)
NEC for r=0.3 all L1 = 0.413 +- 0.177 (in-sample avg dev_std = 0.474)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.238235
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.602
NEC for r=0.6 class 0 = 0.385 +- 0.373 (in-sample avg dev_std = 0.525)
NEC for r=0.6 class 1 = 0.416 +- 0.373 (in-sample avg dev_std = 0.525)
NEC for r=0.6 class 2 = 0.443 +- 0.373 (in-sample avg dev_std = 0.525)
NEC for r=0.6 all KL = 0.432 +- 0.373 (in-sample avg dev_std = 0.525)
NEC for r=0.6 all L1 = 0.415 +- 0.240 (in-sample avg dev_std = 0.525)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25273125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.633
NEC for r=0.9 class 0 = 0.38 +- 0.350 (in-sample avg dev_std = 0.564)
NEC for r=0.9 class 1 = 0.415 +- 0.350 (in-sample avg dev_std = 0.564)
NEC for r=0.9 class 2 = 0.4 +- 0.350 (in-sample avg dev_std = 0.564)
NEC for r=0.9 all KL = 0.418 +- 0.350 (in-sample avg dev_std = 0.564)
NEC for r=0.9 all L1 = 0.399 +- 0.219 (in-sample avg dev_std = 0.564)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25641624999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.419 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 1 = 0.435 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 2 = 0.44 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all KL = 0.444 +- 0.324 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all L1 = 0.431 +- 0.186 (in-sample avg dev_std = 0.576)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:55:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:55:19 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9123
Train Loss: 0.4007
ID Validation ACCURACY: 0.9150
ID Validation Loss: 0.3813
ID Test ACCURACY: 0.9053
ID Test Loss: 0.4430
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.3879
OOD Test ACCURACY: 0.7097
OOD Test Loss: 0.7779

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8903
Train Loss: 0.4322
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4222
ID Test ACCURACY: 0.8893
ID Test Loss: 0.4666
OOD Validation ACCURACY: 0.9303
OOD Validation Loss: 0.3953
OOD Test ACCURACY: 0.8417
OOD Test Loss: 0.6994

[0m[1;37mINFO[0m: [1mChartInfo 0.9053 0.7097 0.8893 0.8417 0.8910 0.9303[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.198
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.280
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.315
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.316
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.181
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.230
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.247
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1979325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.35
SUFF++ for r=0.3 class 0 = 0.435 +- 0.261 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 class 1 = 0.467 +- 0.261 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 class 2 = 0.397 +- 0.261 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 all KL = 0.389 +- 0.261 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 all L1 = 0.434 +- 0.136 (in-sample avg dev_std = 0.505)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28003875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.46
SUFF++ for r=0.6 class 0 = 0.429 +- 0.265 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 1 = 0.484 +- 0.265 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 2 = 0.341 +- 0.265 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 all KL = 0.337 +- 0.265 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 all L1 = 0.418 +- 0.155 (in-sample avg dev_std = 0.582)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.31453
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.675
SUFF++ for r=0.9 class 0 = 0.586 +- 0.319 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 1 = 0.673 +- 0.319 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 class 2 = 0.582 +- 0.319 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 all KL = 0.62 +- 0.319 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.9 all L1 = 0.614 +- 0.244 (in-sample avg dev_std = 0.381)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18093125000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.441
SUFF++ for r=0.3 class 0 = 0.484 +- 0.275 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 1 = 0.55 +- 0.275 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 2 = 0.393 +- 0.275 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all KL = 0.418 +- 0.275 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all L1 = 0.476 +- 0.120 (in-sample avg dev_std = 0.580)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.2303775
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.439
SUFF++ for r=0.6 class 0 = 0.428 +- 0.271 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 1 = 0.437 +- 0.271 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 class 2 = 0.289 +- 0.271 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all KL = 0.331 +- 0.271 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.6 all L1 = 0.385 +- 0.149 (in-sample avg dev_std = 0.580)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2473075
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.471
SUFF++ for r=0.9 class 0 = 0.442 +- 0.270 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.9 class 1 = 0.456 +- 0.270 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.9 class 2 = 0.481 +- 0.270 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.9 all KL = 0.454 +- 0.270 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.9 all L1 = 0.46 +- 0.209 (in-sample avg dev_std = 0.393)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1979325
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.41
NEC for r=0.3 class 0 = 0.499 +- 0.290 (in-sample avg dev_std = 0.514)
NEC for r=0.3 class 1 = 0.461 +- 0.290 (in-sample avg dev_std = 0.514)
NEC for r=0.3 class 2 = 0.521 +- 0.290 (in-sample avg dev_std = 0.514)
NEC for r=0.3 all KL = 0.536 +- 0.290 (in-sample avg dev_std = 0.514)
NEC for r=0.3 all L1 = 0.493 +- 0.190 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28003875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.544
NEC for r=0.6 class 0 = 0.526 +- 0.289 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 1 = 0.474 +- 0.289 (in-sample avg dev_std = 0.599)
NEC for r=0.6 class 2 = 0.533 +- 0.289 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all KL = 0.587 +- 0.289 (in-sample avg dev_std = 0.599)
NEC for r=0.6 all L1 = 0.511 +- 0.171 (in-sample avg dev_std = 0.599)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.31453
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.548
NEC for r=0.9 class 0 = 0.523 +- 0.294 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 1 = 0.469 +- 0.294 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 2 = 0.555 +- 0.294 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all KL = 0.559 +- 0.294 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all L1 = 0.515 +- 0.168 (in-sample avg dev_std = 0.583)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.926
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31582375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.552
NEC for r=1.0 class 0 = 0.527 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 1 = 0.469 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 2 = 0.553 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all KL = 0.555 +- 0.285 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all L1 = 0.516 +- 0.163 (in-sample avg dev_std = 0.577)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18093125000000002
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.558
NEC for r=0.3 class 0 = 0.391 +- 0.311 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 1 = 0.363 +- 0.311 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 2 = 0.447 +- 0.311 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all KL = 0.436 +- 0.311 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all L1 = 0.4 +- 0.198 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.2303775
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.628
NEC for r=0.6 class 0 = 0.372 +- 0.403 (in-sample avg dev_std = 0.567)
NEC for r=0.6 class 1 = 0.384 +- 0.403 (in-sample avg dev_std = 0.567)
NEC for r=0.6 class 2 = 0.455 +- 0.403 (in-sample avg dev_std = 0.567)
NEC for r=0.6 all KL = 0.459 +- 0.403 (in-sample avg dev_std = 0.567)
NEC for r=0.6 all L1 = 0.404 +- 0.279 (in-sample avg dev_std = 0.567)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.665
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2473075
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.671
NEC for r=0.9 class 0 = 0.383 +- 0.326 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 1 = 0.378 +- 0.326 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 2 = 0.271 +- 0.326 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all KL = 0.394 +- 0.326 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all L1 = 0.344 +- 0.222 (in-sample avg dev_std = 0.496)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.71
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25113
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0 = 0.403 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 1 = 0.427 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 class 2 = 0.326 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all KL = 0.441 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=1.0 all L1 = 0.386 +- 0.199 (in-sample avg dev_std = 0.536)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 11:57:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:50 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:50 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:50 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:57:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:57:51 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.5315
ID Validation ACCURACY: 0.8940
ID Validation Loss: 0.5268
ID Test ACCURACY: 0.8807
ID Test Loss: 0.5595
OOD Validation ACCURACY: 0.8480
OOD Validation Loss: 0.5785
OOD Test ACCURACY: 0.9053
OOD Test Loss: 0.4997

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 116...
[0m[1;37mINFO[0m: [1mCheckpoint 116: 
-----------------------------------
Train ACCURACY: 0.8415
Train Loss: 0.5162
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.4990
ID Test ACCURACY: 0.8423
ID Test Loss: 0.5364
OOD Validation ACCURACY: 0.9043
OOD Validation Loss: 0.5293
OOD Test ACCURACY: 0.7010
OOD Test Loss: 0.9220

[0m[1;37mINFO[0m: [1mChartInfo 0.8807 0.9053 0.8423 0.7010 0.8440 0.9043[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.228
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.292
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.307
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.308
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.211
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.245
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.254
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.254


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.668
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22796375000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.387
SUFF++ for r=0.3 class 0 = 0.493 +- 0.310 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 class 1 = 0.562 +- 0.310 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 class 2 = 0.414 +- 0.310 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 all KL = 0.498 +- 0.310 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.3 all L1 = 0.49 +- 0.139 (in-sample avg dev_std = 0.468)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.29162625000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.44
SUFF++ for r=0.6 class 0 = 0.551 +- 0.301 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 1 = 0.57 +- 0.301 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 2 = 0.371 +- 0.301 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all KL = 0.547 +- 0.301 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all L1 = 0.498 +- 0.164 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3072025
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.599
SUFF++ for r=0.9 class 0 = 0.687 +- 0.296 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 1 = 0.691 +- 0.296 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 2 = 0.544 +- 0.296 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all KL = 0.727 +- 0.296 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all L1 = 0.641 +- 0.224 (in-sample avg dev_std = 0.286)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21107374999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.426
SUFF++ for r=0.3 class 0 = 0.486 +- 0.310 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 1 = 0.592 +- 0.310 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 class 2 = 0.431 +- 0.310 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 all KL = 0.498 +- 0.310 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.3 all L1 = 0.504 +- 0.139 (in-sample avg dev_std = 0.481)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24522875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.486
SUFF++ for r=0.6 class 0 = 0.567 +- 0.314 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 1 = 0.604 +- 0.314 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 2 = 0.409 +- 0.314 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all KL = 0.565 +- 0.314 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all L1 = 0.527 +- 0.175 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25422625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.502
SUFF++ for r=0.9 class 0 = 0.665 +- 0.298 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 1 = 0.629 +- 0.298 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 2 = 0.505 +- 0.298 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 all KL = 0.678 +- 0.298 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 all L1 = 0.599 +- 0.231 (in-sample avg dev_std = 0.291)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.669
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22796375000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.465
NEC for r=0.3 class 0 = 0.443 +- 0.322 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 1 = 0.357 +- 0.322 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 2 = 0.463 +- 0.322 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all KL = 0.408 +- 0.322 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all L1 = 0.421 +- 0.189 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.29162625000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.565
NEC for r=0.6 class 0 = 0.386 +- 0.298 (in-sample avg dev_std = 0.471)
NEC for r=0.6 class 1 = 0.382 +- 0.298 (in-sample avg dev_std = 0.471)
NEC for r=0.6 class 2 = 0.483 +- 0.298 (in-sample avg dev_std = 0.471)
NEC for r=0.6 all KL = 0.379 +- 0.298 (in-sample avg dev_std = 0.471)
NEC for r=0.6 all L1 = 0.417 +- 0.169 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.3072025
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.567
NEC for r=0.9 class 0 = 0.362 +- 0.291 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 1 = 0.37 +- 0.291 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 2 = 0.501 +- 0.291 (in-sample avg dev_std = 0.460)
NEC for r=0.9 all KL = 0.341 +- 0.291 (in-sample avg dev_std = 0.460)
NEC for r=0.9 all L1 = 0.41 +- 0.171 (in-sample avg dev_std = 0.460)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.307525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.556
NEC for r=1.0 class 0 = 0.372 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 1 = 0.371 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 class 2 = 0.511 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all KL = 0.347 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=1.0 all L1 = 0.417 +- 0.171 (in-sample avg dev_std = 0.462)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.744
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21107374999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.525
NEC for r=0.3 class 0 = 0.43 +- 0.309 (in-sample avg dev_std = 0.431)
NEC for r=0.3 class 1 = 0.355 +- 0.309 (in-sample avg dev_std = 0.431)
NEC for r=0.3 class 2 = 0.374 +- 0.309 (in-sample avg dev_std = 0.431)
NEC for r=0.3 all KL = 0.38 +- 0.309 (in-sample avg dev_std = 0.431)
NEC for r=0.3 all L1 = 0.386 +- 0.188 (in-sample avg dev_std = 0.431)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24522875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.613
NEC for r=0.6 class 0 = 0.355 +- 0.319 (in-sample avg dev_std = 0.506)
NEC for r=0.6 class 1 = 0.325 +- 0.319 (in-sample avg dev_std = 0.506)
NEC for r=0.6 class 2 = 0.458 +- 0.319 (in-sample avg dev_std = 0.506)
NEC for r=0.6 all KL = 0.362 +- 0.319 (in-sample avg dev_std = 0.506)
NEC for r=0.6 all L1 = 0.379 +- 0.189 (in-sample avg dev_std = 0.506)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25422625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.626
NEC for r=0.9 class 0 = 0.358 +- 0.311 (in-sample avg dev_std = 0.490)
NEC for r=0.9 class 1 = 0.332 +- 0.311 (in-sample avg dev_std = 0.490)
NEC for r=0.9 class 2 = 0.414 +- 0.311 (in-sample avg dev_std = 0.490)
NEC for r=0.9 all KL = 0.343 +- 0.311 (in-sample avg dev_std = 0.490)
NEC for r=0.9 all L1 = 0.368 +- 0.196 (in-sample avg dev_std = 0.490)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25437750000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.369 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 1 = 0.355 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 2 = 0.458 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all KL = 0.366 +- 0.305 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all L1 = 0.394 +- 0.182 (in-sample avg dev_std = 0.511)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:00:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:00:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8887
Train Loss: 0.4987
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4744
ID Test ACCURACY: 0.8860
ID Test Loss: 0.5215
OOD Validation ACCURACY: 0.8970
OOD Validation Loss: 0.5042
OOD Test ACCURACY: 0.8647
OOD Test Loss: 0.5045

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.7957
Train Loss: 0.6628
ID Validation ACCURACY: 0.7933
ID Validation Loss: 0.6550
ID Test ACCURACY: 0.7830
ID Test Loss: 0.7186
OOD Validation ACCURACY: 0.9107
OOD Validation Loss: 0.5086
OOD Test ACCURACY: 0.8793
OOD Test Loss: 0.5214

[0m[1;37mINFO[0m: [1mChartInfo 0.8860 0.8647 0.7830 0.8793 0.7933 0.9107[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.226
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.286
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.309
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.311
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.211
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.244
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.253
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.254


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22591625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.423
SUFF++ for r=0.3 class 0 = 0.398 +- 0.264 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 class 1 = 0.455 +- 0.264 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 class 2 = 0.372 +- 0.264 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all KL = 0.273 +- 0.264 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all L1 = 0.409 +- 0.133 (in-sample avg dev_std = 0.624)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28643500000000005
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.492
SUFF++ for r=0.6 class 0 = 0.439 +- 0.314 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 1 = 0.557 +- 0.314 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 2 = 0.334 +- 0.314 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all KL = 0.354 +- 0.314 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all L1 = 0.444 +- 0.180 (in-sample avg dev_std = 0.554)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30940125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.684
SUFF++ for r=0.9 class 0 = 0.617 +- 0.351 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 class 1 = 0.697 +- 0.351 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 class 2 = 0.602 +- 0.351 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 all KL = 0.634 +- 0.351 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.9 all L1 = 0.639 +- 0.251 (in-sample avg dev_std = 0.378)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.863
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21108625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.455
SUFF++ for r=0.3 class 0 = 0.417 +- 0.284 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 class 1 = 0.498 +- 0.284 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 class 2 = 0.349 +- 0.284 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all KL = 0.361 +- 0.284 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all L1 = 0.422 +- 0.140 (in-sample avg dev_std = 0.582)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24385
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.515
SUFF++ for r=0.6 class 0 = 0.534 +- 0.327 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 class 1 = 0.572 +- 0.327 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 class 2 = 0.374 +- 0.327 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 all KL = 0.477 +- 0.327 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 all L1 = 0.494 +- 0.166 (in-sample avg dev_std = 0.538)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.252675
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.53
SUFF++ for r=0.9 class 0 = 0.605 +- 0.344 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 1 = 0.595 +- 0.344 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 2 = 0.445 +- 0.344 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all KL = 0.567 +- 0.344 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all L1 = 0.548 +- 0.239 (in-sample avg dev_std = 0.352)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.22591625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.51
NEC for r=0.3 class 0 = 0.552 +- 0.331 (in-sample avg dev_std = 0.560)
NEC for r=0.3 class 1 = 0.48 +- 0.331 (in-sample avg dev_std = 0.560)
NEC for r=0.3 class 2 = 0.503 +- 0.331 (in-sample avg dev_std = 0.560)
NEC for r=0.3 all KL = 0.625 +- 0.331 (in-sample avg dev_std = 0.560)
NEC for r=0.3 all L1 = 0.512 +- 0.219 (in-sample avg dev_std = 0.560)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.28643500000000005
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.598
NEC for r=0.6 class 0 = 0.472 +- 0.318 (in-sample avg dev_std = 0.601)
NEC for r=0.6 class 1 = 0.423 +- 0.318 (in-sample avg dev_std = 0.601)
NEC for r=0.6 class 2 = 0.533 +- 0.318 (in-sample avg dev_std = 0.601)
NEC for r=0.6 all KL = 0.578 +- 0.318 (in-sample avg dev_std = 0.601)
NEC for r=0.6 all L1 = 0.476 +- 0.179 (in-sample avg dev_std = 0.601)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30940125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.593
NEC for r=0.9 class 0 = 0.454 +- 0.308 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 1 = 0.425 +- 0.308 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 2 = 0.53 +- 0.308 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all KL = 0.524 +- 0.308 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all L1 = 0.469 +- 0.168 (in-sample avg dev_std = 0.572)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3106275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.581
NEC for r=1.0 class 0 = 0.459 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 1 = 0.422 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 2 = 0.545 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all KL = 0.528 +- 0.308 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all L1 = 0.475 +- 0.169 (in-sample avg dev_std = 0.568)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.863
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.21108625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.577
NEC for r=0.3 class 0 = 0.508 +- 0.334 (in-sample avg dev_std = 0.508)
NEC for r=0.3 class 1 = 0.406 +- 0.334 (in-sample avg dev_std = 0.508)
NEC for r=0.3 class 2 = 0.502 +- 0.334 (in-sample avg dev_std = 0.508)
NEC for r=0.3 all KL = 0.518 +- 0.334 (in-sample avg dev_std = 0.508)
NEC for r=0.3 all L1 = 0.471 +- 0.230 (in-sample avg dev_std = 0.508)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24385
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.667
NEC for r=0.6 class 0 = 0.384 +- 0.326 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 1 = 0.329 +- 0.326 (in-sample avg dev_std = 0.538)
NEC for r=0.6 class 2 = 0.446 +- 0.326 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all KL = 0.421 +- 0.326 (in-sample avg dev_std = 0.538)
NEC for r=0.6 all L1 = 0.386 +- 0.196 (in-sample avg dev_std = 0.538)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.252675
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0 = 0.371 +- 0.331 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 1 = 0.336 +- 0.331 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 2 = 0.422 +- 0.331 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all KL = 0.425 +- 0.331 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all L1 = 0.376 +- 0.196 (in-sample avg dev_std = 0.556)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25397125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.648
NEC for r=1.0 class 0 = 0.388 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 class 1 = 0.349 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 class 2 = 0.457 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 all KL = 0.449 +- 0.319 (in-sample avg dev_std = 0.583)
NEC for r=1.0 all L1 = 0.397 +- 0.174 (in-sample avg dev_std = 0.583)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.412, 0.427, 0.71, 1.0], 'all_L1': [0.463, 0.443, 0.662, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.407, 0.365, 0.681, 1.0], 'all_L1': [0.469, 0.424, 0.641, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.389, 0.337, 0.62, 1.0], 'all_L1': [0.434, 0.418, 0.614, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.498, 0.547, 0.727, 1.0], 'all_L1': [0.49, 0.498, 0.641, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.273, 0.354, 0.634, 1.0], 'all_L1': [0.409, 0.444, 0.639, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.517, 0.512, 0.461, 0.463], 'all_L1': [0.474, 0.486, 0.47, 0.472]}), defaultdict(<class 'list'>, {'all_KL': [0.536, 0.571, 0.509, 0.515], 'all_L1': [0.477, 0.513, 0.505, 0.511]}), defaultdict(<class 'list'>, {'all_KL': [0.536, 0.587, 0.559, 0.555], 'all_L1': [0.493, 0.511, 0.515, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.408, 0.379, 0.341, 0.347], 'all_L1': [0.421, 0.417, 0.41, 0.417]}), defaultdict(<class 'list'>, {'all_KL': [0.625, 0.578, 0.524, 0.528], 'all_L1': [0.512, 0.476, 0.469, 0.475]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.386, 0.469, 0.725, 1.0], 'all_L1': [0.479, 0.507, 0.702, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.527, 0.415, 0.523, 1.0], 'all_L1': [0.507, 0.421, 0.498, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.418, 0.331, 0.454, 1.0], 'all_L1': [0.476, 0.385, 0.46, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.498, 0.565, 0.678, 1.0], 'all_L1': [0.504, 0.527, 0.599, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.361, 0.477, 0.567, 1.0], 'all_L1': [0.422, 0.494, 0.548, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.43, 0.421, 0.379, 0.393], 'all_L1': [0.371, 0.372, 0.356, 0.369]}), defaultdict(<class 'list'>, {'all_KL': [0.371, 0.432, 0.418, 0.444], 'all_L1': [0.413, 0.415, 0.399, 0.431]}), defaultdict(<class 'list'>, {'all_KL': [0.436, 0.459, 0.394, 0.441], 'all_L1': [0.4, 0.404, 0.344, 0.386]}), defaultdict(<class 'list'>, {'all_KL': [0.38, 0.362, 0.343, 0.366], 'all_L1': [0.386, 0.379, 0.368, 0.394]}), defaultdict(<class 'list'>, {'all_KL': [0.518, 0.421, 0.425, 0.449], 'all_L1': [0.471, 0.386, 0.376, 0.397]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.453 +- 0.028, 0.445 +- 0.028, 0.639 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.396 +- 0.072, 0.406 +- 0.077, 0.674 +- 0.042, 1.000 +- 0.000
suff++_acc_int  =  0.392 +- 0.026, 0.468 +- 0.019, 0.672 +- 0.038
nec class all_L1  =  0.475 +- 0.030, 0.481 +- 0.035, 0.474 +- 0.037, 0.478 +- 0.035
nec class all_KL  =  0.524 +- 0.069, 0.525 +- 0.078, 0.479 +- 0.076, 0.482 +- 0.074
nec_acc_int  =  0.467 +- 0.033, 0.564 +- 0.026, 0.570 +- 0.023, 0.563 +- 0.027

Eval split test
suff++ class all_L1  =  0.478 +- 0.031, 0.467 +- 0.054, 0.561 +- 0.084, 1.000 +- 0.000
suff++ class all_KL  =  0.438 +- 0.064, 0.451 +- 0.077, 0.589 +- 0.099, 1.000 +- 0.000
suff++_acc_int  =  0.444 +- 0.012, 0.479 +- 0.052, 0.537 +- 0.105
nec class all_L1  =  0.408 +- 0.034, 0.391 +- 0.016, 0.369 +- 0.019, 0.395 +- 0.020
nec class all_KL  =  0.427 +- 0.052, 0.419 +- 0.032, 0.392 +- 0.029, 0.419 +- 0.033
nec_acc_int  =  0.553 +- 0.020, 0.638 +- 0.030, 0.657 +- 0.023, 0.633 +- 0.030


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.464 +- 0.006, 0.463 +- 0.004, 0.557 +- 0.017, 0.739 +- 0.018
Faith. Armon (L1)= 		  =  0.462 +- 0.008, 0.460 +- 0.004, 0.543 +- 0.023, 0.646 +- 0.033
Faith. GMean (L1)= 	  =  0.463 +- 0.007, 0.462 +- 0.004, 0.550 +- 0.020, 0.691 +- 0.026
Faith. Aritm (KL)= 		  =  0.460 +- 0.008, 0.466 +- 0.003, 0.577 +- 0.022, 0.741 +- 0.037
Faith. Armon (KL)= 		  =  0.440 +- 0.030, 0.445 +- 0.012, 0.554 +- 0.046, 0.647 +- 0.071
Faith. GMean (KL)= 	  =  0.450 +- 0.019, 0.455 +- 0.007, 0.565 +- 0.034, 0.692 +- 0.055

Eval split test
Faith. Aritm (L1)= 		  =  0.443 +- 0.011, 0.429 +- 0.021, 0.465 +- 0.042, 0.698 +- 0.010
Faith. Armon (L1)= 		  =  0.438 +- 0.012, 0.423 +- 0.016, 0.442 +- 0.026, 0.566 +- 0.021
Faith. GMean (L1)= 	  =  0.440 +- 0.012, 0.426 +- 0.018, 0.453 +- 0.033, 0.629 +- 0.016
Faith. Aritm (KL)= 		  =  0.432 +- 0.014, 0.435 +- 0.024, 0.491 +- 0.043, 0.709 +- 0.017
Faith. Armon (KL)= 		  =  0.425 +- 0.010, 0.428 +- 0.023, 0.465 +- 0.026, 0.589 +- 0.033
Faith. GMean (KL)= 	  =  0.429 +- 0.012, 0.432 +- 0.023, 0.478 +- 0.033, 0.646 +- 0.026
Computed for split load_split = id



Completed in  0:13:17.065465  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:03:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:30 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:03:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4334
ID Test ACCURACY: 0.9151
ID Test Loss: 0.4930
OOD Validation ACCURACY: 0.8823
OOD Validation Loss: 0.6328
OOD Test ACCURACY: 0.8311
OOD Test Loss: 1.1309

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0004
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.4056
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4650
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.6111
OOD Test ACCURACY: 0.8308
OOD Test Loss: 1.1121

[0m[1;37mINFO[0m: [1mChartInfo 0.9151 0.8311 0.9130 0.8308 0.9172 0.8837[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:03:32 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.834
SUFF++ for r=0.6 class 0.0 = 0.794 +- 0.353 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 1.0 = 0.842 +- 0.353 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all KL = 0.649 +- 0.353 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all L1 = 0.822 +- 0.201 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.988 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.98 +- 0.114 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.099 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.8
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.731
SUFF++ for r=0.3 class 0.0 = 0.673 +- 0.361 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 1.0 = 0.756 +- 0.361 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all KL = 0.456 +- 0.361 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all L1 = 0.716 +- 0.225 (in-sample avg dev_std = 0.636)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.791
SUFF++ for r=0.6 class 0.0 = 0.798 +- 0.350 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 1.0 = 0.849 +- 0.350 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all KL = 0.659 +- 0.350 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.203 (in-sample avg dev_std = 0.480)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.842
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.184 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 1.0 = 0.947 +- 0.184 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all KL = 0.915 +- 0.184 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all L1 = 0.937 +- 0.136 (in-sample avg dev_std = 0.249)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.106 +- 0.242 (in-sample avg dev_std = 0.201)
NEC for r=0.6 class 1.0 = 0.059 +- 0.242 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all KL = 0.099 +- 0.242 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all L1 = 0.078 +- 0.181 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.877
NEC for r=0.9 class 0.0 = 0.037 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=0.9 class 1.0 = 0.016 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all KL = 0.021 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all L1 = 0.025 +- 0.100 (in-sample avg dev_std = 0.096)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.877
NEC for r=1.0 class 0.0 = 0.037 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.016 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.021 +- 0.110 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.025 +- 0.100 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.8
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.79
NEC for r=0.3 class 0.0 = 0.171 +- 0.308 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 1.0 = 0.108 +- 0.308 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all KL = 0.182 +- 0.308 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all L1 = 0.138 +- 0.232 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.829
NEC for r=0.6 class 0.0 = 0.096 +- 0.216 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1.0 = 0.062 +- 0.216 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.091 +- 0.216 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.079 +- 0.176 (in-sample avg dev_std = 0.237)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.848
NEC for r=0.9 class 0.0 = 0.042 +- 0.108 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 1.0 = 0.022 +- 0.108 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all KL = 0.025 +- 0.108 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all L1 = 0.032 +- 0.106 (in-sample avg dev_std = 0.123)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.856
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.85
NEC for r=1.0 class 0.0 = 0.027 +- 0.084 (in-sample avg dev_std = 0.103)
NEC for r=1.0 class 1.0 = 0.019 +- 0.084 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all KL = 0.017 +- 0.084 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all L1 = 0.023 +- 0.082 (in-sample avg dev_std = 0.103)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:05:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:05:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0004
ID Validation ACCURACY: 0.9219
ID Validation Loss: 0.4149
ID Test ACCURACY: 0.9153
ID Test Loss: 0.4712
OOD Validation ACCURACY: 0.8844
OOD Validation Loss: 0.6335
OOD Test ACCURACY: 0.8226
OOD Test Loss: 1.5522

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9206
ID Validation Loss: 0.4566
ID Test ACCURACY: 0.9164
ID Test Loss: 0.5199
OOD Validation ACCURACY: 0.8857
OOD Validation Loss: 0.7013
OOD Test ACCURACY: 0.8256
OOD Test Loss: 1.5657

[0m[1;37mINFO[0m: [1mChartInfo 0.9153 0.8226 0.9164 0.8256 0.9206 0.8857[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:05:56 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.819
SUFF++ for r=0.6 class 0.0 = 0.776 +- 0.346 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 1.0 = 0.853 +- 0.346 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all KL = 0.64 +- 0.346 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.193 (in-sample avg dev_std = 0.490)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.878
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.121 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.121 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.978 +- 0.121 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.106 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.703
SUFF++ for r=0.3 class 0.0 = 0.63 +- 0.355 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.3 class 1.0 = 0.769 +- 0.355 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.3 all KL = 0.458 +- 0.355 (in-sample avg dev_std = 0.638)
SUFF++ for r=0.3 all L1 = 0.702 +- 0.223 (in-sample avg dev_std = 0.638)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.822
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.759
SUFF++ for r=0.6 class 0.0 = 0.736 +- 0.369 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.6 class 1.0 = 0.843 +- 0.369 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.6 all KL = 0.583 +- 0.369 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.211 (in-sample avg dev_std = 0.546)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.829
SUFF++ for r=0.9 class 0.0 = 0.922 +- 0.177 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.177 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all KL = 0.922 +- 0.177 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all L1 = 0.942 +- 0.129 (in-sample avg dev_std = 0.249)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.855
NEC for r=0.6 class 0.0 = 0.106 +- 0.229 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1.0 = 0.044 +- 0.229 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.084 +- 0.229 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.07 +- 0.168 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.041 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 1.0 = 0.019 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all KL = 0.027 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all L1 = 0.028 +- 0.115 (in-sample avg dev_std = 0.099)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.041 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=1.0 class 1.0 = 0.019 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=1.0 all KL = 0.027 +- 0.137 (in-sample avg dev_std = 0.099)
NEC for r=1.0 all L1 = 0.028 +- 0.115 (in-sample avg dev_std = 0.099)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.763
NEC for r=0.3 class 0.0 = 0.192 +- 0.291 (in-sample avg dev_std = 0.335)
NEC for r=0.3 class 1.0 = 0.1 +- 0.291 (in-sample avg dev_std = 0.335)
NEC for r=0.3 all KL = 0.18 +- 0.291 (in-sample avg dev_std = 0.335)
NEC for r=0.3 all L1 = 0.144 +- 0.226 (in-sample avg dev_std = 0.335)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.824
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.817
NEC for r=0.6 class 0.0 = 0.114 +- 0.214 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 1.0 = 0.053 +- 0.214 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all KL = 0.097 +- 0.214 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all L1 = 0.083 +- 0.171 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.837
NEC for r=0.9 class 0.0 = 0.037 +- 0.102 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1.0 = 0.023 +- 0.102 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.022 +- 0.102 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.03 +- 0.103 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.84
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.84
NEC for r=1.0 class 0.0 = 0.033 +- 0.095 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 1.0 = 0.023 +- 0.095 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all KL = 0.021 +- 0.095 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all L1 = 0.027 +- 0.094 (in-sample avg dev_std = 0.111)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:08:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9217
ID Validation Loss: 0.4089
ID Test ACCURACY: 0.9170
ID Test Loss: 0.4793
OOD Validation ACCURACY: 0.8800
OOD Validation Loss: 0.6717
OOD Test ACCURACY: 0.8278
OOD Test Loss: 1.4934

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0032
ID Validation ACCURACY: 0.9189
ID Validation Loss: 0.3261
ID Test ACCURACY: 0.9128
ID Test Loss: 0.3801
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.5452
OOD Test ACCURACY: 0.8331
OOD Test Loss: 1.2119

[0m[1;37mINFO[0m: [1mChartInfo 0.9170 0.8278 0.9128 0.8331 0.9189 0.8837[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:08:22 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.832
SUFF++ for r=0.6 class 0.0 = 0.783 +- 0.339 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 1.0 = 0.871 +- 0.339 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all KL = 0.648 +- 0.339 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all L1 = 0.835 +- 0.190 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all KL = 0.977 +- 0.119 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.099 (in-sample avg dev_std = 0.095)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.78
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.709
SUFF++ for r=0.3 class 0.0 = 0.654 +- 0.342 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 class 1.0 = 0.734 +- 0.342 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 all KL = 0.449 +- 0.342 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.3 all L1 = 0.695 +- 0.217 (in-sample avg dev_std = 0.640)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.76
SUFF++ for r=0.6 class 0.0 = 0.739 +- 0.376 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 1.0 = 0.815 +- 0.376 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all KL = 0.539 +- 0.376 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all L1 = 0.779 +- 0.203 (in-sample avg dev_std = 0.576)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0.0 = 0.92 +- 0.189 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1.0 = 0.958 +- 0.189 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.91 +- 0.189 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.129 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.881
NEC for r=0.6 class 0.0 = 0.09 +- 0.189 (in-sample avg dev_std = 0.156)
NEC for r=0.6 class 1.0 = 0.036 +- 0.189 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all KL = 0.062 +- 0.189 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all L1 = 0.059 +- 0.158 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.048 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=0.9 class 1.0 = 0.017 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all KL = 0.029 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all L1 = 0.03 +- 0.117 (in-sample avg dev_std = 0.115)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.871
NEC for r=1.0 class 0.0 = 0.048 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.017 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.029 +- 0.141 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.03 +- 0.117 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.78
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.773
NEC for r=0.3 class 0.0 = 0.195 +- 0.295 (in-sample avg dev_std = 0.348)
NEC for r=0.3 class 1.0 = 0.12 +- 0.295 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all KL = 0.195 +- 0.295 (in-sample avg dev_std = 0.348)
NEC for r=0.3 all L1 = 0.156 +- 0.229 (in-sample avg dev_std = 0.348)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.821
NEC for r=0.6 class 0.0 = 0.093 +- 0.201 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 1.0 = 0.054 +- 0.201 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all KL = 0.085 +- 0.201 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all L1 = 0.073 +- 0.163 (in-sample avg dev_std = 0.235)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.835
NEC for r=0.9 class 0.0 = 0.024 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 class 1.0 = 0.018 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all KL = 0.018 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all L1 = 0.021 +- 0.088 (in-sample avg dev_std = 0.106)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.84
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.834
NEC for r=1.0 class 0.0 = 0.026 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 class 1.0 = 0.017 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all KL = 0.017 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all L1 = 0.021 +- 0.090 (in-sample avg dev_std = 0.107)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:10:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:10:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 180...
[0m[1;37mINFO[0m: [1mCheckpoint 180: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9225
ID Validation Loss: 0.4107
ID Test ACCURACY: 0.9176
ID Test Loss: 0.4755
OOD Validation ACCURACY: 0.8817
OOD Validation Loss: 0.6167
OOD Test ACCURACY: 0.8206
OOD Test Loss: 1.3282

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9204
ID Validation Loss: 0.4402
ID Test ACCURACY: 0.9183
ID Test Loss: 0.5109
OOD Validation ACCURACY: 0.8846
OOD Validation Loss: 0.6529
OOD Test ACCURACY: 0.8255
OOD Test Loss: 1.3708

[0m[1;37mINFO[0m: [1mChartInfo 0.9176 0.8206 0.9183 0.8255 0.9204 0.8846[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:10:49 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.811
SUFF++ for r=0.6 class 0.0 = 0.736 +- 0.354 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 1.0 = 0.841 +- 0.354 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all KL = 0.619 +- 0.354 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all L1 = 0.797 +- 0.216 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.891
SUFF++ for r=0.9 class 0.0 = 0.946 +- 0.144 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.144 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all KL = 0.967 +- 0.144 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.121 (in-sample avg dev_std = 0.133)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.693
SUFF++ for r=0.3 class 0.0 = 0.595 +- 0.319 (in-sample avg dev_std = 0.680)
SUFF++ for r=0.3 class 1.0 = 0.699 +- 0.319 (in-sample avg dev_std = 0.680)
SUFF++ for r=0.3 all KL = 0.386 +- 0.319 (in-sample avg dev_std = 0.680)
SUFF++ for r=0.3 all L1 = 0.649 +- 0.211 (in-sample avg dev_std = 0.680)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.82
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.76
SUFF++ for r=0.6 class 0.0 = 0.739 +- 0.356 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 1.0 = 0.83 +- 0.356 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all KL = 0.588 +- 0.356 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.208 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.822
SUFF++ for r=0.9 class 0.0 = 0.924 +- 0.166 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.166 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all KL = 0.924 +- 0.166 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.122 (in-sample avg dev_std = 0.237)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.874
NEC for r=0.6 class 0.0 = 0.121 +- 0.257 (in-sample avg dev_std = 0.213)
NEC for r=0.6 class 1.0 = 0.065 +- 0.257 (in-sample avg dev_std = 0.213)
NEC for r=0.6 all KL = 0.103 +- 0.257 (in-sample avg dev_std = 0.213)
NEC for r=0.6 all L1 = 0.088 +- 0.201 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.88
NEC for r=0.9 class 0.0 = 0.057 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=0.9 class 1.0 = 0.024 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all KL = 0.036 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all L1 = 0.038 +- 0.137 (in-sample avg dev_std = 0.107)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.88
NEC for r=1.0 class 0.0 = 0.057 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=1.0 class 1.0 = 0.024 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all KL = 0.036 +- 0.161 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all L1 = 0.038 +- 0.137 (in-sample avg dev_std = 0.107)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.785
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.763
NEC for r=0.3 class 0.0 = 0.231 +- 0.313 (in-sample avg dev_std = 0.368)
NEC for r=0.3 class 1.0 = 0.144 +- 0.313 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all KL = 0.231 +- 0.313 (in-sample avg dev_std = 0.368)
NEC for r=0.3 all L1 = 0.186 +- 0.246 (in-sample avg dev_std = 0.368)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.82
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.812
NEC for r=0.6 class 0.0 = 0.112 +- 0.208 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1.0 = 0.067 +- 0.208 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.098 +- 0.208 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.089 +- 0.176 (in-sample avg dev_std = 0.237)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
NEC for r=0.9 class 0.0 = 0.034 +- 0.085 (in-sample avg dev_std = 0.110)
NEC for r=0.9 class 1.0 = 0.021 +- 0.085 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all KL = 0.019 +- 0.085 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all L1 = 0.027 +- 0.089 (in-sample avg dev_std = 0.110)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.825
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.825
NEC for r=1.0 class 0.0 = 0.024 +- 0.067 (in-sample avg dev_std = 0.083)
NEC for r=1.0 class 1.0 = 0.019 +- 0.067 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all KL = 0.013 +- 0.067 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all L1 = 0.021 +- 0.077 (in-sample avg dev_std = 0.083)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:13:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:13:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9208
ID Validation Loss: 0.4313
ID Test ACCURACY: 0.9178
ID Test Loss: 0.4948
OOD Validation ACCURACY: 0.8829
OOD Validation Loss: 0.6848
OOD Test ACCURACY: 0.8338
OOD Test Loss: 1.5415

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9178
ID Validation Loss: 0.4301
ID Test ACCURACY: 0.9166
ID Test Loss: 0.4923
OOD Validation ACCURACY: 0.8847
OOD Validation Loss: 0.6580
OOD Test ACCURACY: 0.8312
OOD Test Loss: 1.4830

[0m[1;37mINFO[0m: [1mChartInfo 0.9178 0.8338 0.9166 0.8312 0.9178 0.8847[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 12:13:12 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.814
SUFF++ for r=0.6 class 0.0 = 0.812 +- 0.362 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 1.0 = 0.814 +- 0.362 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all KL = 0.615 +- 0.362 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all L1 = 0.813 +- 0.199 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0.0 = 0.952 +- 0.141 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.141 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all KL = 0.97 +- 0.141 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.120 (in-sample avg dev_std = 0.119)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.714
SUFF++ for r=0.3 class 0.0 = 0.637 +- 0.332 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.3 class 1.0 = 0.667 +- 0.332 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.3 all KL = 0.375 +- 0.332 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.3 all L1 = 0.653 +- 0.221 (in-sample avg dev_std = 0.667)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.777
SUFF++ for r=0.6 class 0.0 = 0.769 +- 0.370 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.6 class 1.0 = 0.783 +- 0.370 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.6 all KL = 0.536 +- 0.370 (in-sample avg dev_std = 0.547)
SUFF++ for r=0.6 all L1 = 0.776 +- 0.211 (in-sample avg dev_std = 0.547)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.846
SUFF++ for r=0.9 class 0.0 = 0.933 +- 0.167 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.167 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all KL = 0.921 +- 0.167 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.119 (in-sample avg dev_std = 0.227)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.863
NEC for r=0.6 class 0.0 = 0.089 +- 0.235 (in-sample avg dev_std = 0.201)
NEC for r=0.6 class 1.0 = 0.053 +- 0.235 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all KL = 0.087 +- 0.235 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all L1 = 0.068 +- 0.174 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.044 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1.0 = 0.03 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.032 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.036 +- 0.128 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.044 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.03 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.032 +- 0.147 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.036 +- 0.128 (in-sample avg dev_std = 0.105)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.778
NEC for r=0.3 class 0.0 = 0.206 +- 0.317 (in-sample avg dev_std = 0.349)
NEC for r=0.3 class 1.0 = 0.148 +- 0.317 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all KL = 0.217 +- 0.317 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all L1 = 0.176 +- 0.247 (in-sample avg dev_std = 0.349)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.829
NEC for r=0.6 class 0.0 = 0.116 +- 0.237 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 1.0 = 0.079 +- 0.237 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all KL = 0.12 +- 0.237 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all L1 = 0.097 +- 0.184 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.849
NEC for r=0.9 class 0.0 = 0.033 +- 0.084 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 1.0 = 0.024 +- 0.084 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all KL = 0.022 +- 0.084 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all L1 = 0.028 +- 0.087 (in-sample avg dev_std = 0.113)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0.0 = 0.022 +- 0.059 (in-sample avg dev_std = 0.079)
NEC for r=1.0 class 1.0 = 0.015 +- 0.059 (in-sample avg dev_std = 0.079)
NEC for r=1.0 all KL = 0.011 +- 0.059 (in-sample avg dev_std = 0.079)
NEC for r=1.0 all L1 = 0.018 +- 0.067 (in-sample avg dev_std = 0.079)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.649, 0.98, 1.0], 'all_L1': [0.822, 0.977, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.64, 0.978, 1.0], 'all_L1': [0.821, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.648, 0.977, 1.0], 'all_L1': [0.835, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.619, 0.967, 1.0], 'all_L1': [0.797, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.615, 0.97, 1.0], 'all_L1': [0.813, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.099, 0.021, 0.021], 'all_L1': [0.078, 0.025, 0.025]}), defaultdict(<class 'list'>, {'all_KL': [0.084, 0.027, 0.027], 'all_L1': [0.07, 0.028, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.062, 0.029, 0.029], 'all_L1': [0.059, 0.03, 0.03]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.036, 0.036], 'all_L1': [0.088, 0.038, 0.038]}), defaultdict(<class 'list'>, {'all_KL': [0.087, 0.032, 0.032], 'all_L1': [0.068, 0.036, 0.036]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.456, 0.659, 0.915, 1.0], 'all_L1': [0.716, 0.824, 0.937, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.458, 0.583, 0.922, 1.0], 'all_L1': [0.702, 0.791, 0.942, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.449, 0.539, 0.91, 1.0], 'all_L1': [0.695, 0.779, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.386, 0.588, 0.924, 1.0], 'all_L1': [0.649, 0.786, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.375, 0.536, 0.921, 1.0], 'all_L1': [0.653, 0.776, 0.944, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.182, 0.091, 0.025, 0.017], 'all_L1': [0.138, 0.079, 0.032, 0.023]}), defaultdict(<class 'list'>, {'all_KL': [0.18, 0.097, 0.022, 0.021], 'all_L1': [0.144, 0.083, 0.03, 0.027]}), defaultdict(<class 'list'>, {'all_KL': [0.195, 0.085, 0.018, 0.017], 'all_L1': [0.156, 0.073, 0.021, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.231, 0.098, 0.019, 0.013], 'all_L1': [0.186, 0.089, 0.027, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.217, 0.12, 0.022, 0.011], 'all_L1': [0.176, 0.097, 0.028, 0.018]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.818 +- 0.012, 0.971 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.634 +- 0.014, 0.974 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.822 +- 0.009, 0.874 +- 0.011
nec class all_L1  =  0.073 +- 0.010, 0.031 +- 0.005, 0.031 +- 0.005
nec class all_KL  =  0.087 +- 0.014, 0.029 +- 0.005, 0.029 +- 0.005
nec_acc_int  =  0.867 +- 0.009, 0.872 +- 0.006, 0.872 +- 0.006

Eval split test
suff++ class all_L1  =  0.683 +- 0.027, 0.791 +- 0.017, 0.941 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.425 +- 0.036, 0.581 +- 0.045, 0.918 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.710 +- 0.012, 0.769 +- 0.013, 0.834 +- 0.009
nec class all_L1  =  0.160 +- 0.018, 0.084 +- 0.008, 0.028 +- 0.004, 0.022 +- 0.003
nec class all_KL  =  0.201 +- 0.020, 0.098 +- 0.012, 0.021 +- 0.002, 0.016 +- 0.003
nec_acc_int  =  0.773 +- 0.010, 0.822 +- 0.007, 0.839 +- 0.009, 0.839 +- 0.009


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.445 +- 0.003, 0.501 +- 0.001, 0.516 +- 0.002
Faith. Armon (L1)= 		  =  0.133 +- 0.016, 0.061 +- 0.009, 0.061 +- 0.009
Faith. GMean (L1)= 	  =  0.243 +- 0.015, 0.174 +- 0.013, 0.177 +- 0.014
Faith. Aritm (KL)= 		  =  0.361 +- 0.008, 0.502 +- 0.001, 0.515 +- 0.003
Faith. Armon (KL)= 		  =  0.153 +- 0.022, 0.056 +- 0.009, 0.056 +- 0.009
Faith. GMean (KL)= 	  =  0.234 +- 0.019, 0.167 +- 0.014, 0.170 +- 0.015

Eval split test
Faith. Aritm (L1)= 		  =  0.422 +- 0.005, 0.438 +- 0.008, 0.484 +- 0.002, 0.511 +- 0.001
Faith. Armon (L1)= 		  =  0.258 +- 0.022, 0.152 +- 0.013, 0.054 +- 0.007, 0.043 +- 0.006
Faith. GMean (L1)= 	  =  0.330 +- 0.012, 0.258 +- 0.012, 0.161 +- 0.011, 0.148 +- 0.010
Faith. Aritm (KL)= 		  =  0.313 +- 0.010, 0.340 +- 0.021, 0.470 +- 0.003, 0.508 +- 0.002
Faith. Armon (KL)= 		  =  0.271 +- 0.011, 0.167 +- 0.016, 0.041 +- 0.005, 0.031 +- 0.007
Faith. GMean (KL)= 	  =  0.291 +- 0.005, 0.238 +- 0.013, 0.139 +- 0.008, 0.125 +- 0.014
Computed for split load_split = id



Completed in  0:12:08.297701  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:15:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:15:52 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:16:25 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:16:36 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:16:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:17:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 174...
[0m[1;37mINFO[0m: [1mCheckpoint 174: 
-----------------------------------
Train ROC-AUC: 0.9747
Train Loss: 0.1592
ID Validation ROC-AUC: 0.9216
ID Validation Loss: 0.3096
ID Test ROC-AUC: 0.9242
ID Test Loss: 0.3130
OOD Validation ROC-AUC: 0.6625
OOD Validation Loss: 0.4639
OOD Test ROC-AUC: 0.7200
OOD Test Loss: 0.6879

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ROC-AUC: 0.9117
Train Loss: 0.2596
ID Validation ROC-AUC: 0.8990
ID Validation Loss: 0.2737
ID Test ROC-AUC: 0.9017
ID Test Loss: 0.2762
OOD Validation ROC-AUC: 0.6935
OOD Validation Loss: 0.2996
OOD Test ROC-AUC: 0.7346
OOD Test Loss: 0.4781

[0m[1;37mINFO[0m: [1mChartInfo 0.9242 0.7200 0.9017 0.7346 0.8990 0.6935[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:17:20 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:17:25 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.636
SUFF++ for r=0.3 class 0.0 = 0.621 +- 0.176 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 class 1.0 = 0.609 +- 0.176 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 all KL = 0.729 +- 0.176 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.3 all L1 = 0.611 +- 0.150 (in-sample avg dev_std = 0.412)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.817
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.766
SUFF++ for r=0.6 class 0.0 = 0.62 +- 0.200 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 1.0 = 0.794 +- 0.200 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all KL = 0.806 +- 0.200 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.211 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.854
SUFF++ for r=0.9 class 0.0 = 0.736 +- 0.164 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1.0 = 0.906 +- 0.164 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.912 +- 0.164 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.887 +- 0.177 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.592
SUFF++ for r=0.3 class 0.0 = 0.61 +- 0.177 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 1.0 = 0.598 +- 0.177 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all KL = 0.73 +- 0.177 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all L1 = 0.6 +- 0.136 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.656
SUFF++ for r=0.6 class 0.0 = 0.618 +- 0.215 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 1.0 = 0.697 +- 0.215 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all KL = 0.739 +- 0.215 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all L1 = 0.684 +- 0.209 (in-sample avg dev_std = 0.410)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.72
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.705
SUFF++ for r=0.9 class 0.0 = 0.721 +- 0.202 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 class 1.0 = 0.828 +- 0.202 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all KL = 0.853 +- 0.202 (in-sample avg dev_std = 0.292)
SUFF++ for r=0.9 all L1 = 0.81 +- 0.210 (in-sample avg dev_std = 0.292)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0.0 = 0.286 +- 0.169 (in-sample avg dev_std = 0.302)
NEC for r=0.3 class 1.0 = 0.315 +- 0.169 (in-sample avg dev_std = 0.302)
NEC for r=0.3 all KL = 0.179 +- 0.169 (in-sample avg dev_std = 0.302)
NEC for r=0.3 all L1 = 0.312 +- 0.154 (in-sample avg dev_std = 0.302)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.817
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.785
NEC for r=0.6 class 0.0 = 0.278 +- 0.170 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 1.0 = 0.173 +- 0.170 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all KL = 0.138 +- 0.170 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all L1 = 0.185 +- 0.182 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.839
NEC for r=0.9 class 0.0 = 0.289 +- 0.180 (in-sample avg dev_std = 0.257)
NEC for r=0.9 class 1.0 = 0.1 +- 0.180 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all KL = 0.105 +- 0.180 (in-sample avg dev_std = 0.257)
NEC for r=0.9 all L1 = 0.122 +- 0.178 (in-sample avg dev_std = 0.257)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0.0 = 0.308 +- 0.200 (in-sample avg dev_std = 0.278)
NEC for r=1.0 class 1.0 = 0.096 +- 0.200 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all KL = 0.111 +- 0.200 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all L1 = 0.12 +- 0.180 (in-sample avg dev_std = 0.278)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.629
NEC for r=0.3 class 0.0 = 0.273 +- 0.167 (in-sample avg dev_std = 0.300)
NEC for r=0.3 class 1.0 = 0.323 +- 0.167 (in-sample avg dev_std = 0.300)
NEC for r=0.3 all KL = 0.173 +- 0.167 (in-sample avg dev_std = 0.300)
NEC for r=0.3 all L1 = 0.315 +- 0.151 (in-sample avg dev_std = 0.300)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.712
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.698
NEC for r=0.6 class 0.0 = 0.268 +- 0.184 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 1.0 = 0.25 +- 0.184 (in-sample avg dev_std = 0.325)
NEC for r=0.6 all KL = 0.179 +- 0.184 (in-sample avg dev_std = 0.325)
NEC for r=0.6 all L1 = 0.253 +- 0.186 (in-sample avg dev_std = 0.325)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.72
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.703
NEC for r=0.9 class 0.0 = 0.271 +- 0.211 (in-sample avg dev_std = 0.321)
NEC for r=0.9 class 1.0 = 0.186 +- 0.211 (in-sample avg dev_std = 0.321)
NEC for r=0.9 all KL = 0.166 +- 0.211 (in-sample avg dev_std = 0.321)
NEC for r=0.9 all L1 = 0.2 +- 0.204 (in-sample avg dev_std = 0.321)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.72
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.71
NEC for r=1.0 class 0.0 = 0.263 +- 0.225 (in-sample avg dev_std = 0.339)
NEC for r=1.0 class 1.0 = 0.189 +- 0.225 (in-sample avg dev_std = 0.339)
NEC for r=1.0 all KL = 0.177 +- 0.225 (in-sample avg dev_std = 0.339)
NEC for r=1.0 all L1 = 0.201 +- 0.209 (in-sample avg dev_std = 0.339)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:21:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:21:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:21:33 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:21:43 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:21:54 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:11 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:22:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9783
Train Loss: 0.1269
ID Validation ROC-AUC: 0.9244
ID Validation Loss: 0.2658
ID Test ROC-AUC: 0.9267
ID Test Loss: 0.2679
OOD Validation ROC-AUC: 0.6593
OOD Validation Loss: 0.4783
OOD Test ROC-AUC: 0.7128
OOD Test Loss: 0.6262

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9086
Train Loss: 0.2436
ID Validation ROC-AUC: 0.8959
ID Validation Loss: 0.2566
ID Test ROC-AUC: 0.8988
ID Test Loss: 0.2585
OOD Validation ROC-AUC: 0.6869
OOD Validation Loss: 0.2916
OOD Test ROC-AUC: 0.7309
OOD Test Loss: 0.4531

[0m[1;37mINFO[0m: [1mChartInfo 0.9267 0.7128 0.8988 0.7309 0.8959 0.6869[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:22:28 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:22:32 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.632
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0.0 = 0.776 +- 0.112 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 class 1.0 = 0.768 +- 0.112 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all KL = 0.897 +- 0.112 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all L1 = 0.769 +- 0.099 (in-sample avg dev_std = 0.259)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.838
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0.0 = 0.793 +- 0.147 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.6 class 1.0 = 0.812 +- 0.147 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.6 all KL = 0.882 +- 0.147 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.6 all L1 = 0.81 +- 0.144 (in-sample avg dev_std = 0.236)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.895
SUFF++ for r=0.9 class 0.0 = 0.904 +- 0.047 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.047 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.9 all KL = 0.983 +- 0.047 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.075 (in-sample avg dev_std = 0.117)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0.0 = 0.77 +- 0.106 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 class 1.0 = 0.764 +- 0.106 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all KL = 0.904 +- 0.106 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all L1 = 0.765 +- 0.102 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.621
SUFF++ for r=0.6 class 0.0 = 0.791 +- 0.123 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1.0 = 0.786 +- 0.123 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.897 +- 0.123 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.132 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.704
SUFF++ for r=0.9 class 0.0 = 0.896 +- 0.058 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 1.0 = 0.919 +- 0.058 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all KL = 0.969 +- 0.058 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all L1 = 0.915 +- 0.094 (in-sample avg dev_std = 0.160)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.616
NEC for r=0.3 class 0.0 = 0.193 +- 0.092 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 1.0 = 0.207 +- 0.092 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all KL = 0.078 +- 0.092 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all L1 = 0.206 +- 0.113 (in-sample avg dev_std = 0.210)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.838
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.802
NEC for r=0.6 class 0.0 = 0.197 +- 0.111 (in-sample avg dev_std = 0.230)
NEC for r=0.6 class 1.0 = 0.158 +- 0.111 (in-sample avg dev_std = 0.230)
NEC for r=0.6 all KL = 0.086 +- 0.111 (in-sample avg dev_std = 0.230)
NEC for r=0.6 all L1 = 0.163 +- 0.133 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.863
NEC for r=0.9 class 0.0 = 0.253 +- 0.137 (in-sample avg dev_std = 0.227)
NEC for r=0.9 class 1.0 = 0.117 +- 0.137 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all KL = 0.087 +- 0.137 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all L1 = 0.133 +- 0.156 (in-sample avg dev_std = 0.227)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.863
NEC for r=1.0 class 0.0 = 0.295 +- 0.159 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 1.0 = 0.105 +- 0.159 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all KL = 0.093 +- 0.159 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all L1 = 0.127 +- 0.164 (in-sample avg dev_std = 0.239)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.573
NEC for r=0.3 class 0.0 = 0.195 +- 0.090 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 1.0 = 0.212 +- 0.090 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all KL = 0.074 +- 0.090 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all L1 = 0.209 +- 0.112 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.619
NEC for r=0.6 class 0.0 = 0.209 +- 0.118 (in-sample avg dev_std = 0.251)
NEC for r=0.6 class 1.0 = 0.202 +- 0.118 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all KL = 0.095 +- 0.118 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all L1 = 0.203 +- 0.133 (in-sample avg dev_std = 0.251)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.689
NEC for r=0.9 class 0.0 = 0.278 +- 0.166 (in-sample avg dev_std = 0.305)
NEC for r=0.9 class 1.0 = 0.204 +- 0.166 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all KL = 0.136 +- 0.166 (in-sample avg dev_std = 0.305)
NEC for r=0.9 all L1 = 0.216 +- 0.172 (in-sample avg dev_std = 0.305)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.72
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.693
NEC for r=1.0 class 0.0 = 0.278 +- 0.181 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 1.0 = 0.205 +- 0.181 (in-sample avg dev_std = 0.317)
NEC for r=1.0 all KL = 0.148 +- 0.181 (in-sample avg dev_std = 0.317)
NEC for r=1.0 all L1 = 0.217 +- 0.186 (in-sample avg dev_std = 0.317)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:25:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:25:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:26:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:26:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:26:36 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:26:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ROC-AUC: 0.9586
Train Loss: 0.1793
ID Validation ROC-AUC: 0.9217
ID Validation Loss: 0.2533
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2525
OOD Validation ROC-AUC: 0.6759
OOD Validation Loss: 0.3745
OOD Test ROC-AUC: 0.7109
OOD Test Loss: 0.5685

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ROC-AUC: 0.9479
Train Loss: 0.1985
ID Validation ROC-AUC: 0.9155
ID Validation Loss: 0.2618
ID Test ROC-AUC: 0.9197
ID Test Loss: 0.2606
OOD Validation ROC-AUC: 0.6885
OOD Validation Loss: 0.3598
OOD Test ROC-AUC: 0.7250
OOD Test Loss: 0.5469

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7109 0.9197 0.7250 0.9155 0.6885[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:27:10 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:27:15 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.723
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
SUFF++ for r=0.3 class 0.0 = 0.668 +- 0.101 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 class 1.0 = 0.684 +- 0.101 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all KL = 0.847 +- 0.101 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all L1 = 0.683 +- 0.119 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0.0 = 0.672 +- 0.099 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 1.0 = 0.83 +- 0.099 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all KL = 0.899 +- 0.099 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all L1 = 0.811 +- 0.154 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.853
SUFF++ for r=0.9 class 0.0 = 0.759 +- 0.089 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 class 1.0 = 0.91 +- 0.089 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all KL = 0.949 +- 0.089 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all L1 = 0.893 +- 0.135 (in-sample avg dev_std = 0.164)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.674 +- 0.106 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.3 class 1.0 = 0.681 +- 0.106 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.3 all KL = 0.852 +- 0.106 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.3 all L1 = 0.68 +- 0.112 (in-sample avg dev_std = 0.302)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.659
SUFF++ for r=0.6 class 0.0 = 0.701 +- 0.103 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 class 1.0 = 0.769 +- 0.103 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all KL = 0.877 +- 0.103 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all L1 = 0.757 +- 0.149 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.682
SUFF++ for r=0.9 class 0.0 = 0.772 +- 0.095 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 1.0 = 0.857 +- 0.095 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all KL = 0.93 +- 0.095 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all L1 = 0.843 +- 0.144 (in-sample avg dev_std = 0.193)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.723
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.729
NEC for r=0.3 class 0.0 = 0.201 +- 0.091 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1.0 = 0.247 +- 0.091 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.088 +- 0.091 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.241 +- 0.121 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.817
NEC for r=0.6 class 0.0 = 0.23 +- 0.089 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.143 +- 0.089 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.069 +- 0.089 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.153 +- 0.132 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.849
NEC for r=0.9 class 0.0 = 0.229 +- 0.094 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 1.0 = 0.095 +- 0.094 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all KL = 0.058 +- 0.094 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all L1 = 0.111 +- 0.128 (in-sample avg dev_std = 0.169)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.909
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.868
NEC for r=1.0 class 0.0 = 0.253 +- 0.107 (in-sample avg dev_std = 0.184)
NEC for r=1.0 class 1.0 = 0.093 +- 0.107 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all KL = 0.061 +- 0.107 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all L1 = 0.112 +- 0.136 (in-sample avg dev_std = 0.184)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.65
NEC for r=0.3 class 0.0 = 0.218 +- 0.088 (in-sample avg dev_std = 0.191)
NEC for r=0.3 class 1.0 = 0.241 +- 0.088 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all KL = 0.08 +- 0.088 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all L1 = 0.237 +- 0.121 (in-sample avg dev_std = 0.191)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.693
NEC for r=0.6 class 0.0 = 0.211 +- 0.093 (in-sample avg dev_std = 0.205)
NEC for r=0.6 class 1.0 = 0.193 +- 0.093 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all KL = 0.082 +- 0.093 (in-sample avg dev_std = 0.205)
NEC for r=0.6 all L1 = 0.196 +- 0.127 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.694
NEC for r=0.9 class 0.0 = 0.204 +- 0.104 (in-sample avg dev_std = 0.198)
NEC for r=0.9 class 1.0 = 0.153 +- 0.104 (in-sample avg dev_std = 0.198)
NEC for r=0.9 all KL = 0.076 +- 0.104 (in-sample avg dev_std = 0.198)
NEC for r=0.9 all L1 = 0.161 +- 0.138 (in-sample avg dev_std = 0.198)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0.0 = 0.221 +- 0.099 (in-sample avg dev_std = 0.217)
NEC for r=1.0 class 1.0 = 0.154 +- 0.099 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all KL = 0.077 +- 0.099 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all L1 = 0.165 +- 0.141 (in-sample avg dev_std = 0.217)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:30:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:30:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:31:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:31:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:31:33 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:31:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:32:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ROC-AUC: 0.9561
Train Loss: 0.1699
ID Validation ROC-AUC: 0.9223
ID Validation Loss: 0.2340
ID Test ROC-AUC: 0.9235
ID Test Loss: 0.2358
OOD Validation ROC-AUC: 0.6576
OOD Validation Loss: 0.3970
OOD Test ROC-AUC: 0.7067
OOD Test Loss: 0.5494

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ROC-AUC: 0.9016
Train Loss: 0.2482
ID Validation ROC-AUC: 0.8949
ID Validation Loss: 0.2557
ID Test ROC-AUC: 0.8953
ID Test Loss: 0.2587
OOD Validation ROC-AUC: 0.6908
OOD Validation Loss: 0.2916
OOD Test ROC-AUC: 0.7285
OOD Test Loss: 0.4503

[0m[1;37mINFO[0m: [1mChartInfo 0.9235 0.7067 0.8953 0.7285 0.8949 0.6908[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:32:06 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:32:14 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.625
SUFF++ for r=0.3 class 0.0 = 0.747 +- 0.079 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 1.0 = 0.728 +- 0.079 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all KL = 0.903 +- 0.079 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all L1 = 0.73 +- 0.097 (in-sample avg dev_std = 0.255)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.762
SUFF++ for r=0.6 class 0.0 = 0.702 +- 0.101 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1.0 = 0.754 +- 0.101 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.876 +- 0.101 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.748 +- 0.132 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0.0 = 0.786 +- 0.087 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 class 1.0 = 0.885 +- 0.087 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all KL = 0.942 +- 0.087 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all L1 = 0.873 +- 0.128 (in-sample avg dev_std = 0.165)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.537
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.571
SUFF++ for r=0.3 class 0.0 = 0.768 +- 0.070 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 1.0 = 0.735 +- 0.070 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all KL = 0.913 +- 0.070 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all L1 = 0.741 +- 0.091 (in-sample avg dev_std = 0.249)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.606
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0.0 = 0.705 +- 0.104 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 1.0 = 0.714 +- 0.104 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all KL = 0.865 +- 0.104 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all L1 = 0.713 +- 0.121 (in-sample avg dev_std = 0.285)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.693
SUFF++ for r=0.9 class 0.0 = 0.78 +- 0.099 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 class 1.0 = 0.826 +- 0.099 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all KL = 0.922 +- 0.099 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.140 (in-sample avg dev_std = 0.201)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.611
NEC for r=0.3 class 0.0 = 0.196 +- 0.065 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 1.0 = 0.207 +- 0.065 (in-sample avg dev_std = 0.173)
NEC for r=0.3 all KL = 0.055 +- 0.065 (in-sample avg dev_std = 0.173)
NEC for r=0.3 all L1 = 0.205 +- 0.101 (in-sample avg dev_std = 0.173)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.753
NEC for r=0.6 class 0.0 = 0.203 +- 0.097 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 1.0 = 0.211 +- 0.097 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all KL = 0.088 +- 0.097 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all L1 = 0.21 +- 0.120 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.855
NEC for r=0.9 class 0.0 = 0.226 +- 0.098 (in-sample avg dev_std = 0.194)
NEC for r=0.9 class 1.0 = 0.128 +- 0.098 (in-sample avg dev_std = 0.194)
NEC for r=0.9 all KL = 0.073 +- 0.098 (in-sample avg dev_std = 0.194)
NEC for r=0.9 all L1 = 0.139 +- 0.127 (in-sample avg dev_std = 0.194)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.917
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.863
NEC for r=1.0 class 0.0 = 0.211 +- 0.107 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1.0 = 0.105 +- 0.107 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.065 +- 0.107 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.117 +- 0.123 (in-sample avg dev_std = 0.191)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.537
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.552
NEC for r=0.3 class 0.0 = 0.176 +- 0.059 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 1.0 = 0.202 +- 0.059 (in-sample avg dev_std = 0.167)
NEC for r=0.3 all KL = 0.051 +- 0.059 (in-sample avg dev_std = 0.167)
NEC for r=0.3 all L1 = 0.197 +- 0.100 (in-sample avg dev_std = 0.167)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.606
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.617
NEC for r=0.6 class 0.0 = 0.239 +- 0.099 (in-sample avg dev_std = 0.214)
NEC for r=0.6 class 1.0 = 0.236 +- 0.099 (in-sample avg dev_std = 0.214)
NEC for r=0.6 all KL = 0.093 +- 0.099 (in-sample avg dev_std = 0.214)
NEC for r=0.6 all L1 = 0.236 +- 0.122 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.682
NEC for r=0.9 class 0.0 = 0.212 +- 0.106 (in-sample avg dev_std = 0.227)
NEC for r=0.9 class 1.0 = 0.189 +- 0.106 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all KL = 0.091 +- 0.106 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all L1 = 0.193 +- 0.135 (in-sample avg dev_std = 0.227)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.691
NEC for r=1.0 class 0.0 = 0.208 +- 0.112 (in-sample avg dev_std = 0.229)
NEC for r=1.0 class 1.0 = 0.167 +- 0.112 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all KL = 0.083 +- 0.112 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all L1 = 0.174 +- 0.133 (in-sample avg dev_std = 0.229)
model_dirname= repr_LECIvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:35:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 12:35:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 12:36:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 12:36:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 12:36:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 12:36:57 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ROC-AUC: 0.9604
Train Loss: 0.1577
ID Validation ROC-AUC: 0.9213
ID Validation Loss: 0.2276
ID Test ROC-AUC: 0.9231
ID Test Loss: 0.2288
OOD Validation ROC-AUC: 0.6638
OOD Validation Loss: 0.4052
OOD Test ROC-AUC: 0.7105
OOD Test Loss: 0.5421

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ROC-AUC: 0.8989
Train Loss: 0.2529
ID Validation ROC-AUC: 0.8912
ID Validation Loss: 0.2608
ID Test ROC-AUC: 0.8911
ID Test Loss: 0.2654
OOD Validation ROC-AUC: 0.6866
OOD Validation Loss: 0.2898
OOD Test ROC-AUC: 0.7229
OOD Test Loss: 0.4564

[0m[1;37mINFO[0m: [1mChartInfo 0.9231 0.7105 0.8911 0.7229 0.8912 0.6866[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 12:37:13 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 12:37:18 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.66
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.631
SUFF++ for r=0.3 class 0.0 = 0.727 +- 0.080 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 1.0 = 0.714 +- 0.080 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all KL = 0.893 +- 0.080 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all L1 = 0.716 +- 0.095 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.718
SUFF++ for r=0.6 class 0.0 = 0.698 +- 0.143 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 class 1.0 = 0.695 +- 0.143 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 all KL = 0.822 +- 0.143 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 all L1 = 0.695 +- 0.111 (in-sample avg dev_std = 0.309)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0.0 = 0.792 +- 0.126 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 class 1.0 = 0.845 +- 0.126 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all KL = 0.909 +- 0.126 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.141 (in-sample avg dev_std = 0.211)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.533
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.555
SUFF++ for r=0.3 class 0.0 = 0.73 +- 0.077 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 1.0 = 0.722 +- 0.077 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all KL = 0.899 +- 0.077 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all L1 = 0.723 +- 0.093 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.581
SUFF++ for r=0.6 class 0.0 = 0.66 +- 0.127 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 class 1.0 = 0.688 +- 0.127 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 all KL = 0.838 +- 0.127 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.6 all L1 = 0.684 +- 0.112 (in-sample avg dev_std = 0.303)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.648
SUFF++ for r=0.9 class 0.0 = 0.782 +- 0.132 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1.0 = 0.782 +- 0.132 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.892 +- 0.132 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.782 +- 0.147 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.66
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.663
NEC for r=0.3 class 0.0 = 0.198 +- 0.079 (in-sample avg dev_std = 0.204)
NEC for r=0.3 class 1.0 = 0.232 +- 0.079 (in-sample avg dev_std = 0.204)
NEC for r=0.3 all KL = 0.072 +- 0.079 (in-sample avg dev_std = 0.204)
NEC for r=0.3 all L1 = 0.228 +- 0.112 (in-sample avg dev_std = 0.204)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.761
NEC for r=0.6 class 0.0 = 0.254 +- 0.129 (in-sample avg dev_std = 0.261)
NEC for r=0.6 class 1.0 = 0.259 +- 0.129 (in-sample avg dev_std = 0.261)
NEC for r=0.6 all KL = 0.133 +- 0.129 (in-sample avg dev_std = 0.261)
NEC for r=0.6 all L1 = 0.258 +- 0.124 (in-sample avg dev_std = 0.261)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.856
NEC for r=0.9 class 0.0 = 0.244 +- 0.150 (in-sample avg dev_std = 0.260)
NEC for r=0.9 class 1.0 = 0.185 +- 0.150 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all KL = 0.127 +- 0.150 (in-sample avg dev_std = 0.260)
NEC for r=0.9 all L1 = 0.192 +- 0.141 (in-sample avg dev_std = 0.260)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.863
NEC for r=1.0 class 0.0 = 0.226 +- 0.154 (in-sample avg dev_std = 0.248)
NEC for r=1.0 class 1.0 = 0.153 +- 0.154 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all KL = 0.11 +- 0.154 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all L1 = 0.162 +- 0.140 (in-sample avg dev_std = 0.248)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.533
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.543
NEC for r=0.3 class 0.0 = 0.214 +- 0.067 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 1.0 = 0.224 +- 0.067 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all KL = 0.065 +- 0.067 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all L1 = 0.222 +- 0.106 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.531
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.591
NEC for r=0.6 class 0.0 = 0.291 +- 0.127 (in-sample avg dev_std = 0.253)
NEC for r=0.6 class 1.0 = 0.283 +- 0.127 (in-sample avg dev_std = 0.253)
NEC for r=0.6 all KL = 0.134 +- 0.127 (in-sample avg dev_std = 0.253)
NEC for r=0.6 all L1 = 0.284 +- 0.129 (in-sample avg dev_std = 0.253)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0.0 = 0.223 +- 0.141 (in-sample avg dev_std = 0.266)
NEC for r=0.9 class 1.0 = 0.238 +- 0.141 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all KL = 0.125 +- 0.141 (in-sample avg dev_std = 0.266)
NEC for r=0.9 all L1 = 0.235 +- 0.138 (in-sample avg dev_std = 0.266)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.662
NEC for r=1.0 class 0.0 = 0.215 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=1.0 class 1.0 = 0.216 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all KL = 0.118 +- 0.146 (in-sample avg dev_std = 0.262)
NEC for r=1.0 all L1 = 0.216 +- 0.146 (in-sample avg dev_std = 0.262)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.729, 0.806, 0.912, 1.0], 'all_L1': [0.611, 0.774, 0.887, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.897, 0.882, 0.983, 1.0], 'all_L1': [0.769, 0.81, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.847, 0.899, 0.949, 1.0], 'all_L1': [0.683, 0.811, 0.893, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.903, 0.876, 0.942, 1.0], 'all_L1': [0.73, 0.748, 0.873, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.893, 0.822, 0.909, 1.0], 'all_L1': [0.716, 0.695, 0.839, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.179, 0.138, 0.105, 0.111], 'all_L1': [0.312, 0.185, 0.122, 0.12]}), defaultdict(<class 'list'>, {'all_KL': [0.078, 0.086, 0.087, 0.093], 'all_L1': [0.206, 0.163, 0.133, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.088, 0.069, 0.058, 0.061], 'all_L1': [0.241, 0.153, 0.111, 0.112]}), defaultdict(<class 'list'>, {'all_KL': [0.055, 0.088, 0.073, 0.065], 'all_L1': [0.205, 0.21, 0.139, 0.117]}), defaultdict(<class 'list'>, {'all_KL': [0.072, 0.133, 0.127, 0.11], 'all_L1': [0.228, 0.258, 0.192, 0.162]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.73, 0.739, 0.853, 1.0], 'all_L1': [0.6, 0.684, 0.81, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.904, 0.897, 0.969, 1.0], 'all_L1': [0.765, 0.787, 0.915, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.852, 0.877, 0.93, 1.0], 'all_L1': [0.68, 0.757, 0.843, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.913, 0.865, 0.922, 1.0], 'all_L1': [0.741, 0.713, 0.818, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.899, 0.838, 0.892, 1.0], 'all_L1': [0.723, 0.684, 0.782, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.173, 0.179, 0.166, 0.177], 'all_L1': [0.315, 0.253, 0.2, 0.201]}), defaultdict(<class 'list'>, {'all_KL': [0.074, 0.095, 0.136, 0.148], 'all_L1': [0.209, 0.203, 0.216, 0.217]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.082, 0.076, 0.077], 'all_L1': [0.237, 0.196, 0.161, 0.165]}), defaultdict(<class 'list'>, {'all_KL': [0.051, 0.093, 0.091, 0.083], 'all_L1': [0.197, 0.236, 0.193, 0.174]}), defaultdict(<class 'list'>, {'all_KL': [0.065, 0.134, 0.125, 0.118], 'all_L1': [0.222, 0.284, 0.235, 0.216]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.702 +- 0.053, 0.768 +- 0.043, 0.889 +- 0.037, 1.000 +- 0.000
suff++ class all_KL  =  0.854 +- 0.065, 0.857 +- 0.036, 0.939 +- 0.027, 1.000 +- 0.000
suff++_acc_int  =  0.621 +- 0.036, 0.757 +- 0.019, 0.866 +- 0.015
nec class all_L1  =  0.238 +- 0.039, 0.194 +- 0.038, 0.139 +- 0.028, 0.128 +- 0.018
nec class all_KL  =  0.094 +- 0.044, 0.103 +- 0.028, 0.090 +- 0.024, 0.088 +- 0.021
nec_acc_int  =  0.651 +- 0.043, 0.783 +- 0.024, 0.853 +- 0.008, 0.863 +- 0.003

Eval split test
suff++ class all_L1  =  0.702 +- 0.058, 0.725 +- 0.041, 0.834 +- 0.045, 1.000 +- 0.000
suff++ class all_KL  =  0.860 +- 0.068, 0.843 +- 0.055, 0.913 +- 0.039, 1.000 +- 0.000
suff++_acc_int  =  0.577 +- 0.018, 0.631 +- 0.029, 0.687 +- 0.021
nec class all_L1  =  0.236 +- 0.042, 0.234 +- 0.032, 0.201 +- 0.025, 0.195 +- 0.021
nec class all_KL  =  0.089 +- 0.043, 0.117 +- 0.036, 0.119 +- 0.032, 0.121 +- 0.038
nec_acc_int  =  0.589 +- 0.043, 0.643 +- 0.044, 0.684 +- 0.018, 0.689 +- 0.015


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.470 +- 0.010, 0.481 +- 0.003, 0.514 +- 0.015, 0.564 +- 0.009
Faith. Armon (L1)= 		  =  0.352 +- 0.033, 0.306 +- 0.043, 0.240 +- 0.039, 0.226 +- 0.028
Faith. GMean (L1)= 	  =  0.406 +- 0.017, 0.383 +- 0.025, 0.350 +- 0.030, 0.356 +- 0.024
Faith. Aritm (KL)= 		  =  0.474 +- 0.012, 0.480 +- 0.005, 0.514 +- 0.011, 0.544 +- 0.011
Faith. Armon (KL)= 		  =  0.165 +- 0.064, 0.182 +- 0.043, 0.163 +- 0.040, 0.161 +- 0.036
Faith. GMean (KL)= 	  =  0.275 +- 0.046, 0.293 +- 0.033, 0.288 +- 0.037, 0.294 +- 0.037

Eval split test
Faith. Aritm (L1)= 		  =  0.469 +- 0.011, 0.480 +- 0.009, 0.517 +- 0.024, 0.597 +- 0.011
Faith. Armon (L1)= 		  =  0.349 +- 0.035, 0.352 +- 0.032, 0.323 +- 0.032, 0.325 +- 0.030
Faith. GMean (L1)= 	  =  0.404 +- 0.017, 0.410 +- 0.018, 0.408 +- 0.026, 0.440 +- 0.025
Faith. Aritm (KL)= 		  =  0.474 +- 0.014, 0.480 +- 0.012, 0.516 +- 0.018, 0.560 +- 0.019
Faith. Armon (KL)= 		  =  0.156 +- 0.064, 0.202 +- 0.051, 0.208 +- 0.050, 0.213 +- 0.060
Faith. GMean (KL)= 	  =  0.267 +- 0.047, 0.309 +- 0.035, 0.326 +- 0.042, 0.343 +- 0.055
Computed for split load_split = id



Completed in  0:25:03.000859  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:41:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:41:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9879
Train Loss: 0.0408
ID Validation ACCURACY: 0.8967
ID Validation Loss: 0.3836
ID Test ACCURACY: 0.8910
ID Test Loss: 0.3737
OOD Validation ACCURACY: 0.8210
OOD Validation Loss: 0.7581
OOD Test ACCURACY: 0.3357
OOD Test Loss: 4.8493

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ACCURACY: 0.9669
Train Loss: 0.1038
ID Validation ACCURACY: 0.8889
ID Validation Loss: 0.3636
ID Test ACCURACY: 0.8920
ID Test Loss: 0.3454
OOD Validation ACCURACY: 0.8796
OOD Validation Loss: 0.3944
OOD Test ACCURACY: 0.5937
OOD Test Loss: 1.5026

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.3357 0.8920 0.5937 0.8889 0.8796[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.622 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 1 = 0.56 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 2 = 0.595 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 3 = 0.588 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 4 = 0.591 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 5 = 0.585 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 6 = 0.605 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 7 = 0.587 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 8 = 0.593 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 9 = 0.582 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all KL = 0.727 +- 0.137 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all L1 = 0.59 +- 0.106 (in-sample avg dev_std = 0.247)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.264
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.17
SUFF++ for r=0.6 class 0 = 0.385 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 1 = 0.389 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 2 = 0.371 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 3 = 0.406 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 4 = 0.391 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 5 = 0.393 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 6 = 0.411 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 7 = 0.394 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 8 = 0.393 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 9 = 0.394 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all KL = 0.346 +- 0.218 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all L1 = 0.393 +- 0.129 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.772
SUFF++ for r=0.9 class 0 = 0.947 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.947 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.808 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 3 = 0.77 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 4 = 0.81 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 5 = 0.71 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 6 = 0.823 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 7 = 0.828 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 8 = 0.879 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 9 = 0.782 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.846 +- 0.230 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.834 +- 0.198 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.612 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 1 = 0.585 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 2 = 0.609 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 3 = 0.602 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 4 = 0.605 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 5 = 0.603 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 6 = 0.594 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 7 = 0.579 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 8 = 0.592 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 9 = 0.565 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 all KL = 0.693 +- 0.168 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 all L1 = 0.595 +- 0.126 (in-sample avg dev_std = 0.277)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.21
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
SUFF++ for r=0.6 class 0 = 0.457 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 1 = 0.479 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 2 = 0.524 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 3 = 0.517 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 4 = 0.496 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 5 = 0.474 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 6 = 0.517 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 7 = 0.546 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 8 = 0.481 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 class 9 = 0.453 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 all KL = 0.506 +- 0.255 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.6 all L1 = 0.495 +- 0.180 (in-sample avg dev_std = 0.374)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.366
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.358
SUFF++ for r=0.9 class 0 = 0.678 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 1 = 0.798 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 2 = 0.784 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 3 = 0.673 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 4 = 0.737 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 5 = 0.684 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 6 = 0.687 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 7 = 0.739 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 8 = 0.691 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 9 = 0.692 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 all KL = 0.775 +- 0.219 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 all L1 = 0.718 +- 0.189 (in-sample avg dev_std = 0.322)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.394 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 1 = 0.43 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 2 = 0.409 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 3 = 0.415 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 4 = 0.406 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 5 = 0.413 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 6 = 0.419 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 7 = 0.391 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 8 = 0.426 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 class 9 = 0.413 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all KL = 0.249 +- 0.154 (in-sample avg dev_std = 0.223)
NEC for r=0.3 all L1 = 0.412 +- 0.116 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.264
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.222
NEC for r=0.6 class 0 = 0.498 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 1 = 0.441 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 2 = 0.487 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 3 = 0.481 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 4 = 0.511 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 5 = 0.465 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 6 = 0.506 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 7 = 0.503 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 8 = 0.498 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 9 = 0.529 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all KL = 0.444 +- 0.198 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all L1 = 0.491 +- 0.139 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.651
NEC for r=0.9 class 0 = 0.319 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 1 = 0.184 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 2 = 0.334 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 3 = 0.457 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 4 = 0.38 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 5 = 0.536 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 6 = 0.403 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 7 = 0.416 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 8 = 0.3 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 9 = 0.44 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all KL = 0.514 +- 0.307 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all L1 = 0.373 +- 0.250 (in-sample avg dev_std = 0.437)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.946
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.836
NEC for r=1.0 class 0 = 0.09 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 1 = 0.029 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 2 = 0.262 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 3 = 0.322 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 4 = 0.202 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 5 = 0.397 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 6 = 0.265 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 7 = 0.213 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 8 = 0.171 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 9 = 0.321 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all KL = 0.345 +- 0.328 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all L1 = 0.222 +- 0.240 (in-sample avg dev_std = 0.374)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.352 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 1 = 0.353 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 2 = 0.372 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 3 = 0.369 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 4 = 0.357 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 5 = 0.363 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 6 = 0.387 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 7 = 0.367 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 8 = 0.385 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 class 9 = 0.36 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all KL = 0.203 +- 0.139 (in-sample avg dev_std = 0.200)
NEC for r=0.3 all L1 = 0.366 +- 0.117 (in-sample avg dev_std = 0.200)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.21
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.194
NEC for r=0.6 class 0 = 0.376 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 1 = 0.292 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 2 = 0.427 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 3 = 0.428 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 4 = 0.482 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 5 = 0.424 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 6 = 0.425 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 7 = 0.424 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 8 = 0.464 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 9 = 0.489 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all KL = 0.35 +- 0.213 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all L1 = 0.421 +- 0.181 (in-sample avg dev_std = 0.299)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.366
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.305
NEC for r=0.9 class 0 = 0.542 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 1 = 0.385 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 2 = 0.455 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 3 = 0.551 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 4 = 0.428 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 5 = 0.493 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 6 = 0.528 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 7 = 0.395 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 8 = 0.534 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 class 9 = 0.5 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 all KL = 0.52 +- 0.274 (in-sample avg dev_std = 0.378)
NEC for r=0.9 all L1 = 0.48 +- 0.216 (in-sample avg dev_std = 0.378)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.33
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.366
NEC for r=1.0 class 0 = 0.562 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 1 = 0.122 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 2 = 0.335 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 3 = 0.507 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 4 = 0.587 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 5 = 0.52 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 6 = 0.584 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 7 = 0.49 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 8 = 0.588 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 class 9 = 0.525 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all KL = 0.56 +- 0.320 (in-sample avg dev_std = 0.348)
NEC for r=1.0 all L1 = 0.476 +- 0.266 (in-sample avg dev_std = 0.348)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 12:54:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 12:54:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9954
Train Loss: 0.0235
ID Validation ACCURACY: 0.9044
ID Validation Loss: 0.3485
ID Test ACCURACY: 0.8980
ID Test Loss: 0.3777
OOD Validation ACCURACY: 0.8489
OOD Validation Loss: 0.5902
OOD Test ACCURACY: 0.4007
OOD Test Loss: 3.1852

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 79...
[0m[1;37mINFO[0m: [1mCheckpoint 79: 
-----------------------------------
Train ACCURACY: 0.9265
Train Loss: 0.2243
ID Validation ACCURACY: 0.8853
ID Validation Loss: 0.3617
ID Test ACCURACY: 0.8787
ID Test Loss: 0.3669
OOD Validation ACCURACY: 0.8706
OOD Validation Loss: 0.3979
OOD Test ACCURACY: 0.4916
OOD Test Loss: 2.4039

[0m[1;37mINFO[0m: [1mChartInfo 0.8980 0.4007 0.8787 0.4916 0.8853 0.8706[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
SUFF++ for r=0.3 class 0 = 0.575 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 1 = 0.533 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 2 = 0.568 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 3 = 0.555 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 4 = 0.578 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 5 = 0.568 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 6 = 0.545 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 7 = 0.544 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 8 = 0.585 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 9 = 0.547 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all KL = 0.667 +- 0.137 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all L1 = 0.559 +- 0.084 (in-sample avg dev_std = 0.327)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.287
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.225
SUFF++ for r=0.6 class 0 = 0.476 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 1 = 0.526 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 2 = 0.451 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 3 = 0.425 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 4 = 0.461 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 5 = 0.455 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 6 = 0.448 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 7 = 0.446 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 8 = 0.431 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 9 = 0.411 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 all KL = 0.47 +- 0.223 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 all L1 = 0.454 +- 0.147 (in-sample avg dev_std = 0.282)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.767
SUFF++ for r=0.9 class 0 = 0.911 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 1 = 0.976 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 2 = 0.762 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 3 = 0.696 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 4 = 0.809 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 5 = 0.741 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 6 = 0.802 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 7 = 0.778 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 8 = 0.742 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 9 = 0.762 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all KL = 0.75 +- 0.308 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all L1 = 0.8 +- 0.216 (in-sample avg dev_std = 0.334)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.562 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 1 = 0.545 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 2 = 0.555 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 3 = 0.565 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 4 = 0.543 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 5 = 0.557 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 6 = 0.541 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 7 = 0.533 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 8 = 0.554 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 class 9 = 0.564 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all KL = 0.667 +- 0.119 (in-sample avg dev_std = 0.326)
SUFF++ for r=0.3 all L1 = 0.552 +- 0.078 (in-sample avg dev_std = 0.326)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.231
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.2
SUFF++ for r=0.6 class 0 = 0.506 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 1 = 0.51 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 2 = 0.519 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 3 = 0.512 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 4 = 0.464 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 5 = 0.487 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 6 = 0.486 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 7 = 0.49 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 8 = 0.478 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 9 = 0.416 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all KL = 0.532 +- 0.231 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all L1 = 0.487 +- 0.160 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.434
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.423
SUFF++ for r=0.9 class 0 = 0.653 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 1 = 0.852 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 2 = 0.678 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 3 = 0.706 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 4 = 0.753 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 5 = 0.751 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 6 = 0.737 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 7 = 0.674 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 8 = 0.665 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 9 = 0.665 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all KL = 0.782 +- 0.211 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all L1 = 0.714 +- 0.189 (in-sample avg dev_std = 0.316)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.357 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 1 = 0.363 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 2 = 0.334 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 3 = 0.358 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 4 = 0.333 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 5 = 0.348 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 6 = 0.354 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 7 = 0.366 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 8 = 0.351 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 9 = 0.352 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 all KL = 0.178 +- 0.122 (in-sample avg dev_std = 0.187)
NEC for r=0.3 all L1 = 0.352 +- 0.107 (in-sample avg dev_std = 0.187)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.287
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.246
NEC for r=0.6 class 0 = 0.426 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 1 = 0.396 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 2 = 0.468 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 3 = 0.502 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 4 = 0.482 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 5 = 0.478 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 6 = 0.493 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 7 = 0.487 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 8 = 0.523 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 9 = 0.518 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 all KL = 0.403 +- 0.202 (in-sample avg dev_std = 0.291)
NEC for r=0.6 all L1 = 0.476 +- 0.137 (in-sample avg dev_std = 0.291)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0 = 0.27 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 1 = 0.064 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 2 = 0.362 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 3 = 0.533 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 4 = 0.344 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 5 = 0.466 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 6 = 0.389 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 7 = 0.395 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 8 = 0.487 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 class 9 = 0.492 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 all KL = 0.54 +- 0.317 (in-sample avg dev_std = 0.425)
NEC for r=0.9 all L1 = 0.375 +- 0.250 (in-sample avg dev_std = 0.425)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.954
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0 = 0.085 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 1 = 0.008 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 2 = 0.233 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 3 = 0.294 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 4 = 0.181 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 5 = 0.327 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 6 = 0.258 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 7 = 0.207 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 8 = 0.252 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 9 = 0.32 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 all KL = 0.345 +- 0.335 (in-sample avg dev_std = 0.370)
NEC for r=1.0 all L1 = 0.212 +- 0.234 (in-sample avg dev_std = 0.370)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.343 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1 = 0.352 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 2 = 0.345 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 3 = 0.337 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 4 = 0.368 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 5 = 0.338 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 6 = 0.388 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 7 = 0.359 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 8 = 0.361 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 9 = 0.351 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.177 +- 0.118 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.354 +- 0.104 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.231
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.215
NEC for r=0.6 class 0 = 0.404 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 1 = 0.377 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 2 = 0.426 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 3 = 0.424 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 4 = 0.473 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 5 = 0.433 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 6 = 0.468 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 7 = 0.466 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 8 = 0.483 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 9 = 0.532 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all KL = 0.358 +- 0.208 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all L1 = 0.448 +- 0.151 (in-sample avg dev_std = 0.259)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.434
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.375
NEC for r=0.9 class 0 = 0.548 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 1 = 0.228 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 2 = 0.478 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 3 = 0.514 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 4 = 0.38 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 5 = 0.457 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 6 = 0.479 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 7 = 0.467 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 8 = 0.525 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 9 = 0.504 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 all KL = 0.458 +- 0.261 (in-sample avg dev_std = 0.345)
NEC for r=0.9 all L1 = 0.456 +- 0.217 (in-sample avg dev_std = 0.345)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.399
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.403
NEC for r=1.0 class 0 = 0.544 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 1 = 0.179 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 2 = 0.47 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 3 = 0.537 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 4 = 0.431 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 5 = 0.382 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 6 = 0.482 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 7 = 0.436 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 8 = 0.525 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 class 9 = 0.52 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 all KL = 0.471 +- 0.277 (in-sample avg dev_std = 0.356)
NEC for r=1.0 all L1 = 0.449 +- 0.230 (in-sample avg dev_std = 0.356)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 13:07:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:26 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:07:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9962
Train Loss: 0.0184
ID Validation ACCURACY: 0.8971
ID Validation Loss: 0.4034
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3939
OOD Validation ACCURACY: 0.7454
OOD Validation Loss: 1.2265
OOD Test ACCURACY: 0.2080
OOD Test Loss: 15.1594

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.9543
Train Loss: 0.1370
ID Validation ACCURACY: 0.8837
ID Validation Loss: 0.3612
ID Test ACCURACY: 0.8867
ID Test Loss: 0.3557
OOD Validation ACCURACY: 0.8760
OOD Validation Loss: 0.3949
OOD Test ACCURACY: 0.6457
OOD Test Loss: 1.3561

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.2080 0.8867 0.6457 0.8837 0.8760[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.149
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
SUFF++ for r=0.3 class 0 = 0.422 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 1 = 0.328 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 2 = 0.427 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 3 = 0.429 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 4 = 0.431 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 5 = 0.445 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 6 = 0.427 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 7 = 0.42 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 8 = 0.435 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 9 = 0.43 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all KL = 0.444 +- 0.186 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all L1 = 0.418 +- 0.090 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.276
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
SUFF++ for r=0.6 class 0 = 0.271 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 1 = 0.324 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 2 = 0.306 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 3 = 0.301 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 4 = 0.329 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 5 = 0.302 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 6 = 0.312 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 7 = 0.33 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 8 = 0.3 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 9 = 0.308 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all KL = 0.165 +- 0.156 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all L1 = 0.309 +- 0.086 (in-sample avg dev_std = 0.422)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.735
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.425
SUFF++ for r=0.9 class 0 = 0.357 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 1 = 0.91 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 2 = 0.322 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 3 = 0.289 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 4 = 0.341 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 5 = 0.291 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 6 = 0.347 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 7 = 0.369 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 8 = 0.323 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 class 9 = 0.266 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 all KL = 0.153 +- 0.261 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.9 all L1 = 0.39 +- 0.219 (in-sample avg dev_std = 0.549)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.147
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.123
SUFF++ for r=0.3 class 0 = 0.422 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 1 = 0.237 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 2 = 0.411 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 3 = 0.37 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 4 = 0.325 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 5 = 0.372 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 6 = 0.37 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 7 = 0.377 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 8 = 0.352 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 class 9 = 0.307 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all KL = 0.32 +- 0.222 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.3 all L1 = 0.354 +- 0.123 (in-sample avg dev_std = 0.433)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
SUFF++ for r=0.6 class 0 = 0.257 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 1 = 0.24 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 2 = 0.267 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 3 = 0.284 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 4 = 0.258 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 5 = 0.289 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 6 = 0.284 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 7 = 0.295 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 8 = 0.268 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 9 = 0.249 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 all KL = 0.106 +- 0.130 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 all L1 = 0.268 +- 0.091 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.171
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.138
SUFF++ for r=0.9 class 0 = 0.332 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 1 = 0.312 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 2 = 0.327 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 3 = 0.314 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 4 = 0.271 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 5 = 0.297 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 6 = 0.292 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 7 = 0.291 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 8 = 0.27 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 class 9 = 0.271 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 all KL = 0.023 +- 0.089 (in-sample avg dev_std = 0.729)
SUFF++ for r=0.9 all L1 = 0.298 +- 0.107 (in-sample avg dev_std = 0.729)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.149
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.52 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 1 = 0.605 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 2 = 0.503 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 3 = 0.518 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 4 = 0.499 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 5 = 0.488 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 6 = 0.52 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 7 = 0.51 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 8 = 0.506 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 9 = 0.516 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all KL = 0.412 +- 0.211 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all L1 = 0.52 +- 0.122 (in-sample avg dev_std = 0.210)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.276
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.182
NEC for r=0.6 class 0 = 0.707 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 1 = 0.444 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 2 = 0.67 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 3 = 0.641 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 4 = 0.635 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 5 = 0.665 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 6 = 0.624 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 7 = 0.632 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 8 = 0.652 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 9 = 0.637 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all KL = 0.733 +- 0.239 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all L1 = 0.628 +- 0.161 (in-sample avg dev_std = 0.354)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.735
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.568
NEC for r=0.9 class 0 = 0.535 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 1 = 0.058 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 2 = 0.375 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 3 = 0.524 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 4 = 0.583 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 5 = 0.544 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 6 = 0.598 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 7 = 0.521 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 8 = 0.394 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 class 9 = 0.687 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all KL = 0.614 +- 0.319 (in-sample avg dev_std = 0.431)
NEC for r=0.9 all L1 = 0.474 +- 0.257 (in-sample avg dev_std = 0.431)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0 = 0.107 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 1 = 0.007 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 2 = 0.235 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 3 = 0.264 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 4 = 0.162 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 5 = 0.337 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 6 = 0.312 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 7 = 0.266 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 8 = 0.172 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 9 = 0.333 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all KL = 0.371 +- 0.354 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all L1 = 0.215 +- 0.239 (in-sample avg dev_std = 0.399)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.147
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.14
NEC for r=0.3 class 0 = 0.478 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 1 = 0.723 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 2 = 0.496 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 3 = 0.544 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 4 = 0.63 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 5 = 0.538 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 6 = 0.569 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 7 = 0.522 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 8 = 0.574 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 9 = 0.642 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all KL = 0.53 +- 0.306 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all L1 = 0.573 +- 0.176 (in-sample avg dev_std = 0.190)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.106
NEC for r=0.6 class 0 = 0.696 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 1 = 0.645 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 2 = 0.664 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 3 = 0.629 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 4 = 0.698 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 5 = 0.65 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 6 = 0.625 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 7 = 0.633 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 8 = 0.663 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 9 = 0.7 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all KL = 0.787 +- 0.263 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all L1 = 0.66 +- 0.202 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.171
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.155
NEC for r=0.9 class 0 = 0.312 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 1 = 0.621 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 2 = 0.27 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 3 = 0.403 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 4 = 0.522 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 5 = 0.47 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 6 = 0.514 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 7 = 0.478 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 8 = 0.535 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 9 = 0.525 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 all KL = 0.533 +- 0.354 (in-sample avg dev_std = 0.350)
NEC for r=0.9 all L1 = 0.464 +- 0.283 (in-sample avg dev_std = 0.350)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.214
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.19
NEC for r=1.0 class 0 = 0.37 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 1 = 0.382 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 2 = 0.304 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 3 = 0.407 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 4 = 0.428 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 5 = 0.438 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 6 = 0.486 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 7 = 0.421 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 8 = 0.455 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 class 9 = 0.468 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all KL = 0.473 +- 0.347 (in-sample avg dev_std = 0.341)
NEC for r=1.0 all L1 = 0.414 +- 0.284 (in-sample avg dev_std = 0.341)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 13:22:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:22:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.9953
Train Loss: 0.0210
ID Validation ACCURACY: 0.8947
ID Validation Loss: 0.4144
ID Test ACCURACY: 0.8940
ID Test Loss: 0.4075
OOD Validation ACCURACY: 0.8159
OOD Validation Loss: 0.9172
OOD Test ACCURACY: 0.1800
OOD Test Loss: 30.3619

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9521
Train Loss: 0.1419
ID Validation ACCURACY: 0.8747
ID Validation Loss: 0.3859
ID Test ACCURACY: 0.8801
ID Test Loss: 0.3806
OOD Validation ACCURACY: 0.8700
OOD Validation Loss: 0.4310
OOD Test ACCURACY: 0.7046
OOD Test Loss: 1.0001

[0m[1;37mINFO[0m: [1mChartInfo 0.8940 0.1800 0.8801 0.7046 0.8747 0.8700[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.556 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 1 = 0.514 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 2 = 0.546 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 3 = 0.541 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 4 = 0.529 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 5 = 0.53 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 6 = 0.532 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 7 = 0.534 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 8 = 0.548 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 class 9 = 0.531 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all KL = 0.628 +- 0.157 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.3 all L1 = 0.536 +- 0.103 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.244
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.178
SUFF++ for r=0.6 class 0 = 0.381 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 1 = 0.384 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 2 = 0.431 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 3 = 0.381 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 4 = 0.399 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 5 = 0.389 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 6 = 0.39 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 7 = 0.408 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 8 = 0.392 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 class 9 = 0.4 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all KL = 0.336 +- 0.220 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.6 all L1 = 0.396 +- 0.136 (in-sample avg dev_std = 0.406)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.782
SUFF++ for r=0.9 class 0 = 0.933 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 1 = 0.982 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 2 = 0.779 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 3 = 0.768 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 4 = 0.86 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 5 = 0.689 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 6 = 0.843 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 7 = 0.815 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 8 = 0.85 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 9 = 0.763 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all KL = 0.832 +- 0.247 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all L1 = 0.832 +- 0.211 (in-sample avg dev_std = 0.270)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
SUFF++ for r=0.3 class 0 = 0.566 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 1 = 0.581 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 2 = 0.572 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 3 = 0.56 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 4 = 0.556 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 5 = 0.573 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 6 = 0.559 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 7 = 0.547 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 8 = 0.551 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 9 = 0.568 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 all KL = 0.669 +- 0.159 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.104 (in-sample avg dev_std = 0.384)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.161
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.122
SUFF++ for r=0.6 class 0 = 0.542 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 1 = 0.386 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 2 = 0.524 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 3 = 0.537 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 4 = 0.507 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 5 = 0.515 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 6 = 0.566 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 7 = 0.511 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 8 = 0.544 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 9 = 0.499 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all KL = 0.359 +- 0.210 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all L1 = 0.512 +- 0.152 (in-sample avg dev_std = 0.519)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.243
SUFF++ for r=0.9 class 0 = 0.711 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 1 = 0.971 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 2 = 0.722 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 3 = 0.737 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 4 = 0.716 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 5 = 0.726 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 6 = 0.742 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 7 = 0.775 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 8 = 0.743 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 9 = 0.749 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all KL = 0.763 +- 0.283 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all L1 = 0.762 +- 0.236 (in-sample avg dev_std = 0.341)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.381 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 1 = 0.383 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 2 = 0.392 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 3 = 0.387 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 4 = 0.389 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 5 = 0.386 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 6 = 0.403 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 7 = 0.379 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 8 = 0.411 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 9 = 0.374 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all KL = 0.227 +- 0.147 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all L1 = 0.388 +- 0.121 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.244
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.218
NEC for r=0.6 class 0 = 0.495 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 1 = 0.389 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 2 = 0.463 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 3 = 0.491 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 4 = 0.487 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 5 = 0.514 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 6 = 0.522 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 7 = 0.529 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 8 = 0.501 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 class 9 = 0.498 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 all KL = 0.454 +- 0.235 (in-sample avg dev_std = 0.316)
NEC for r=0.6 all L1 = 0.487 +- 0.177 (in-sample avg dev_std = 0.316)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0 = 0.314 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.045 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.428 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 3 = 0.451 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 4 = 0.284 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 5 = 0.534 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 6 = 0.437 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 7 = 0.378 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 8 = 0.319 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 9 = 0.483 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.521 +- 0.334 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.361 +- 0.266 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.961
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0 = 0.102 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 1 = 0.015 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 2 = 0.301 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 3 = 0.247 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 4 = 0.167 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 5 = 0.343 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 6 = 0.24 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 7 = 0.198 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 8 = 0.191 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 9 = 0.321 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all KL = 0.358 +- 0.342 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all L1 = 0.208 +- 0.232 (in-sample avg dev_std = 0.380)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
NEC for r=0.3 class 0 = 0.349 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 1 = 0.314 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 2 = 0.338 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 3 = 0.341 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 4 = 0.32 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 5 = 0.318 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 6 = 0.342 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 7 = 0.329 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 8 = 0.323 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 9 = 0.321 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all KL = 0.191 +- 0.144 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all L1 = 0.33 +- 0.134 (in-sample avg dev_std = 0.242)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.161
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
NEC for r=0.6 class 0 = 0.123 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 1 = 0.409 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 2 = 0.157 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 3 = 0.184 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 4 = 0.203 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 5 = 0.201 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 6 = 0.166 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 7 = 0.274 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 8 = 0.25 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 9 = 0.255 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all KL = 0.174 +- 0.204 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all L1 = 0.224 +- 0.209 (in-sample avg dev_std = 0.191)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.239
NEC for r=0.9 class 0 = 0.539 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 1 = 0.062 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 2 = 0.513 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 3 = 0.518 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 4 = 0.544 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 5 = 0.486 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 6 = 0.499 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 7 = 0.41 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 8 = 0.544 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 class 9 = 0.437 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 all KL = 0.545 +- 0.378 (in-sample avg dev_std = 0.303)
NEC for r=0.9 all L1 = 0.451 +- 0.321 (in-sample avg dev_std = 0.303)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.183
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.226
NEC for r=1.0 class 0 = 0.5 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 1 = 0.065 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 2 = 0.463 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 3 = 0.449 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 4 = 0.322 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 5 = 0.46 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 6 = 0.355 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 7 = 0.276 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 8 = 0.494 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 class 9 = 0.323 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 all KL = 0.506 +- 0.437 (in-sample avg dev_std = 0.312)
NEC for r=1.0 all L1 = 0.368 +- 0.350 (in-sample avg dev_std = 0.312)
model_dirname= repr_LECIvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 13:35:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 01:35:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 177...
[0m[1;37mINFO[0m: [1mCheckpoint 177: 
-----------------------------------
Train ACCURACY: 0.9977
Train Loss: 0.0148
ID Validation ACCURACY: 0.8996
ID Validation Loss: 0.3885
ID Test ACCURACY: 0.8940
ID Test Loss: 0.3976
OOD Validation ACCURACY: 0.6997
OOD Validation Loss: 1.7319
OOD Test ACCURACY: 0.1520
OOD Test Loss: 75.5642

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.9054
Train Loss: 0.2814
ID Validation ACCURACY: 0.8654
ID Validation Loss: 0.4107
ID Test ACCURACY: 0.8644
ID Test Loss: 0.4072
OOD Validation ACCURACY: 0.8570
OOD Validation Loss: 0.4363
OOD Test ACCURACY: 0.7327
OOD Test Loss: 0.9882

[0m[1;37mINFO[0m: [1mChartInfo 0.8940 0.1520 0.8644 0.7327 0.8654 0.8570[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.483 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 1 = 0.462 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 2 = 0.461 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 3 = 0.469 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 4 = 0.445 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 5 = 0.482 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 6 = 0.451 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 7 = 0.49 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 8 = 0.465 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 class 9 = 0.437 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all KL = 0.458 +- 0.238 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.3 all L1 = 0.465 +- 0.146 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
SUFF++ for r=0.6 class 0 = 0.374 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1 = 0.411 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 2 = 0.436 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 3 = 0.487 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 4 = 0.497 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 5 = 0.419 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 6 = 0.485 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 7 = 0.375 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 8 = 0.616 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 9 = 0.479 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.31 +- 0.298 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.457 +- 0.240 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.756
SUFF++ for r=0.9 class 0 = 0.948 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.738 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 3 = 0.67 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 4 = 0.841 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 5 = 0.716 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 6 = 0.756 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 7 = 0.81 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 8 = 0.886 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 9 = 0.739 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.799 +- 0.270 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.225 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.427 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 1 = 0.433 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 2 = 0.44 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 3 = 0.493 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 4 = 0.523 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 5 = 0.493 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 6 = 0.515 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 7 = 0.474 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 8 = 0.509 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 9 = 0.538 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 all KL = 0.402 +- 0.281 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 all L1 = 0.483 +- 0.179 (in-sample avg dev_std = 0.593)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.185
SUFF++ for r=0.6 class 0 = 0.627 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 1 = 0.746 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 2 = 0.727 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 3 = 0.701 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 4 = 0.631 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 5 = 0.686 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 6 = 0.586 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 7 = 0.59 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 8 = 0.679 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 9 = 0.544 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all KL = 0.586 +- 0.362 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all L1 = 0.653 +- 0.289 (in-sample avg dev_std = 0.379)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.181
SUFF++ for r=0.9 class 0 = 0.849 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 1 = 0.992 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 3 = 0.866 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 4 = 0.851 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 5 = 0.849 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 6 = 0.883 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 7 = 0.889 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 8 = 0.843 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 9 = 0.891 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all KL = 0.889 +- 0.207 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all L1 = 0.879 +- 0.188 (in-sample avg dev_std = 0.226)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
NEC for r=0.3 class 0 = 0.427 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1 = 0.497 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 2 = 0.505 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 3 = 0.447 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 4 = 0.476 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 5 = 0.442 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 6 = 0.498 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 7 = 0.437 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 8 = 0.479 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 9 = 0.508 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.389 +- 0.233 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.472 +- 0.159 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.137
NEC for r=0.6 class 0 = 0.487 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 1 = 0.538 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 2 = 0.461 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 3 = 0.361 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 4 = 0.387 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 5 = 0.397 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 6 = 0.422 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 7 = 0.522 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 8 = 0.322 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 9 = 0.442 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all KL = 0.472 +- 0.301 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all L1 = 0.437 +- 0.252 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0 = 0.274 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 1 = 0.174 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 2 = 0.507 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 3 = 0.64 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 4 = 0.33 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 5 = 0.551 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 6 = 0.45 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 7 = 0.378 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 8 = 0.302 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 9 = 0.477 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all KL = 0.586 +- 0.336 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all L1 = 0.405 +- 0.270 (in-sample avg dev_std = 0.468)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.952
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.833
NEC for r=1.0 class 0 = 0.095 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 1 = 0.016 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 2 = 0.287 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 3 = 0.386 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 4 = 0.159 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 5 = 0.373 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 6 = 0.285 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 7 = 0.18 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 8 = 0.191 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 9 = 0.358 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all KL = 0.384 +- 0.360 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all L1 = 0.228 +- 0.251 (in-sample avg dev_std = 0.402)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.362 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 1 = 0.347 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 2 = 0.367 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 3 = 0.373 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 4 = 0.362 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 5 = 0.376 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 6 = 0.394 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 7 = 0.411 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 8 = 0.413 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 9 = 0.38 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all KL = 0.326 +- 0.258 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all L1 = 0.378 +- 0.193 (in-sample avg dev_std = 0.333)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.189
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.188
NEC for r=0.6 class 0 = 0.311 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 1 = 0.124 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 2 = 0.292 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 3 = 0.283 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 4 = 0.28 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 5 = 0.287 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 6 = 0.286 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 7 = 0.344 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 8 = 0.298 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 9 = 0.382 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all KL = 0.318 +- 0.292 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all L1 = 0.287 +- 0.250 (in-sample avg dev_std = 0.352)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.182
NEC for r=0.9 class 0 = 0.253 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 1 = 0.013 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 2 = 0.202 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 3 = 0.23 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 4 = 0.265 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 5 = 0.25 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 6 = 0.175 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 7 = 0.205 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 8 = 0.259 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 9 = 0.168 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all KL = 0.238 +- 0.315 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all L1 = 0.199 +- 0.260 (in-sample avg dev_std = 0.259)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.147
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.164
NEC for r=1.0 class 0 = 0.289 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 1 = 0.009 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 2 = 0.295 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 3 = 0.257 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 4 = 0.185 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 5 = 0.303 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 6 = 0.137 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 7 = 0.119 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 8 = 0.219 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 9 = 0.127 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all KL = 0.271 +- 0.363 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all L1 = 0.192 +- 0.272 (in-sample avg dev_std = 0.257)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.727, 0.346, 0.846, 1.0], 'all_L1': [0.59, 0.393, 0.834, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.667, 0.47, 0.75, 1.0], 'all_L1': [0.559, 0.454, 0.8, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.444, 0.165, 0.153, 1.0], 'all_L1': [0.418, 0.309, 0.39, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.628, 0.336, 0.832, 1.0], 'all_L1': [0.536, 0.396, 0.832, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.458, 0.31, 0.799, 1.0], 'all_L1': [0.465, 0.457, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.249, 0.444, 0.514, 0.345], 'all_L1': [0.412, 0.491, 0.373, 0.222]}), defaultdict(<class 'list'>, {'all_KL': [0.178, 0.403, 0.54, 0.345], 'all_L1': [0.352, 0.476, 0.375, 0.212]}), defaultdict(<class 'list'>, {'all_KL': [0.412, 0.733, 0.614, 0.371], 'all_L1': [0.52, 0.628, 0.474, 0.215]}), defaultdict(<class 'list'>, {'all_KL': [0.227, 0.454, 0.521, 0.358], 'all_L1': [0.388, 0.487, 0.361, 0.208]}), defaultdict(<class 'list'>, {'all_KL': [0.389, 0.472, 0.586, 0.384], 'all_L1': [0.472, 0.437, 0.405, 0.228]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.693, 0.506, 0.775, 1.0], 'all_L1': [0.595, 0.495, 0.718, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.667, 0.532, 0.782, 1.0], 'all_L1': [0.552, 0.487, 0.714, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.32, 0.106, 0.023, 1.0], 'all_L1': [0.354, 0.268, 0.298, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.669, 0.359, 0.763, 1.0], 'all_L1': [0.563, 0.512, 0.762, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.402, 0.586, 0.889, 1.0], 'all_L1': [0.483, 0.653, 0.879, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.203, 0.35, 0.52, 0.56], 'all_L1': [0.366, 0.421, 0.48, 0.476]}), defaultdict(<class 'list'>, {'all_KL': [0.177, 0.358, 0.458, 0.471], 'all_L1': [0.354, 0.448, 0.456, 0.449]}), defaultdict(<class 'list'>, {'all_KL': [0.53, 0.787, 0.533, 0.473], 'all_L1': [0.573, 0.66, 0.464, 0.414]}), defaultdict(<class 'list'>, {'all_KL': [0.191, 0.174, 0.545, 0.506], 'all_L1': [0.33, 0.224, 0.451, 0.368]}), defaultdict(<class 'list'>, {'all_KL': [0.326, 0.318, 0.238, 0.271], 'all_L1': [0.378, 0.287, 0.199, 0.192]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.514 +- 0.063, 0.402 +- 0.054, 0.733 +- 0.172, 1.000 +- 0.000
suff++ class all_KL  =  0.585 +- 0.114, 0.325 +- 0.097, 0.676 +- 0.264, 1.000 +- 0.000
suff++_acc_int  =  0.104 +- 0.005, 0.176 +- 0.026, 0.700 +- 0.138
nec class all_L1  =  0.429 +- 0.060, 0.504 +- 0.065, 0.398 +- 0.041, 0.217 +- 0.007
nec class all_KL  =  0.291 +- 0.093, 0.501 +- 0.118, 0.555 +- 0.039, 0.361 +- 0.015
nec_acc_int  =  0.109 +- 0.005, 0.201 +- 0.038, 0.632 +- 0.040, 0.846 +- 0.010

Eval split test
suff++ class all_L1  =  0.509 +- 0.086, 0.483 +- 0.123, 0.674 +- 0.197, 1.000 +- 0.000
suff++ class all_KL  =  0.550 +- 0.157, 0.418 +- 0.173, 0.646 +- 0.315, 1.000 +- 0.000
suff++_acc_int  =  0.109 +- 0.007, 0.155 +- 0.034, 0.269 +- 0.107
nec class all_L1  =  0.400 +- 0.088, 0.408 +- 0.151, 0.410 +- 0.106, 0.380 +- 0.101
nec class all_KL  =  0.285 +- 0.133, 0.397 +- 0.206, 0.459 +- 0.114, 0.456 +- 0.098
nec_acc_int  =  0.112 +- 0.016, 0.167 +- 0.041, 0.251 +- 0.081, 0.270 +- 0.097


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.471 +- 0.016, 0.453 +- 0.012, 0.565 +- 0.067, 0.609 +- 0.004
Faith. Armon (L1)= 		  =  0.460 +- 0.018, 0.440 +- 0.016, 0.499 +- 0.038, 0.357 +- 0.010
Faith. GMean (L1)= 	  =  0.465 +- 0.016, 0.446 +- 0.010, 0.531 +- 0.051, 0.466 +- 0.008
Faith. Aritm (KL)= 		  =  0.438 +- 0.025, 0.413 +- 0.024, 0.615 +- 0.117, 0.680 +- 0.008
Faith. Armon (KL)= 		  =  0.367 +- 0.055, 0.371 +- 0.054, 0.566 +- 0.161, 0.530 +- 0.016
Faith. GMean (KL)= 	  =  0.399 +- 0.033, 0.390 +- 0.028, 0.589 +- 0.142, 0.600 +- 0.013

Eval split test
Faith. Aritm (L1)= 		  =  0.455 +- 0.017, 0.445 +- 0.039, 0.542 +- 0.084, 0.690 +- 0.050
Faith. Armon (L1)= 		  =  0.432 +- 0.013, 0.403 +- 0.056, 0.477 +- 0.110, 0.542 +- 0.116
Faith. GMean (L1)= 	  =  0.443 +- 0.014, 0.423 +- 0.045, 0.507 +- 0.093, 0.610 +- 0.090
Faith. Aritm (KL)= 		  =  0.418 +- 0.028, 0.408 +- 0.071, 0.553 +- 0.141, 0.728 +- 0.049
Faith. Armon (KL)= 		  =  0.330 +- 0.044, 0.335 +- 0.103, 0.451 +- 0.224, 0.620 +- 0.101
Faith. GMean (KL)= 	  =  0.370 +- 0.023, 0.366 +- 0.080, 0.490 +- 0.201, 0.671 +- 0.078
Computed for split load_split = id



Completed in  1:06:49.768407  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color
big_random.sh: line 31: syntax error near unexpected token `)'
