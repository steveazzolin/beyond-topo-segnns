nohup: ignoring input

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 17:37:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:15 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:28 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:30 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:34 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:37:36 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.9222
Train Loss: 0.4118
ID Validation ACCURACY: 0.9240
ID Validation Loss: 0.4256
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4312
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3641
OOD Test ACCURACY: 0.7457
OOD Test Loss: 0.8785

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.9222
Train Loss: 0.4118
ID Validation ACCURACY: 0.9240
ID Validation Loss: 0.4256
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4312
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3641
OOD Test ACCURACY: 0.7457
OOD Test Loss: 0.8785

[0m[1;37mINFO[0m: [1mChartInfo 0.9193 0.7457 0.9193 0.7457 0.9240 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.701
WIoU for r=0.3 = 0.654
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.711
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.709
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.709
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.848
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.476
WIoU for r=0.3 = 0.375
F1 for r=0.6 = 0.642
WIoU for r=0.6 = 0.537
F1 for r=0.9 = 0.593
WIoU for r=0.9 = 0.556
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.556


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  0.7010925
Model XAI WIoU of binarized graphs for r=0.3 =  0.65357625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.474
SUFF++ for r=0.3 class 0 = 0.519 +- 0.312 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 class 1 = 0.757 +- 0.312 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 class 2 = 0.561 +- 0.312 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 all KL = 0.441 +- 0.312 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 all L1 = 0.613 +- 0.228 (in-sample avg dev_std = 0.578)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.859
Model XAI F1 of binarized graphs for r=0.6 =  0.6162225
Model XAI WIoU of binarized graphs for r=0.6 =  0.71121625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.733
SUFF++ for r=0.6 class 0 = 0.556 +- 0.301 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 1 = 0.779 +- 0.301 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 2 = 0.612 +- 0.301 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all KL = 0.562 +- 0.301 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all L1 = 0.65 +- 0.208 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7094749999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0 = 0.759 +- 0.217 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.823 +- 0.217 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.846 +- 0.217 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.845 +- 0.217 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.81 +- 0.194 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.8476275
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.544
SUFF++ for r=0.3 class 0 = 0.495 +- 0.353 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 1 = 0.829 +- 0.353 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 2 = 0.5 +- 0.353 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all KL = 0.449 +- 0.353 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all L1 = 0.607 +- 0.262 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.935
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.879
SUFF++ for r=0.6 class 0 = 0.958 +- 0.298 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 class 1 = 0.787 +- 0.298 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 class 2 = 0.792 +- 0.298 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all KL = 0.767 +- 0.298 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all L1 = 0.846 +- 0.160 (in-sample avg dev_std = 0.380)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.935
SUFF++ for r=0.9 class 0 = 0.978 +- 0.020 (in-sample avg dev_std = 0.085)
SUFF++ for r=0.9 class 1 = 0.948 +- 0.020 (in-sample avg dev_std = 0.085)
SUFF++ for r=0.9 class 2 = 0.932 +- 0.020 (in-sample avg dev_std = 0.085)
SUFF++ for r=0.9 all KL = 0.989 +- 0.020 (in-sample avg dev_std = 0.085)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.062 (in-sample avg dev_std = 0.085)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.233
Model XAI F1 of binarized graphs for r=0.3 =  0.47595250000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.37469625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.337
SUFF++ for r=0.3 class 0 = 0.69 +- 0.295 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.57 +- 0.295 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.747 +- 0.295 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.59 +- 0.295 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.671 +- 0.227 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.468
Model XAI F1 of binarized graphs for r=0.6 =  0.6422137499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.53693125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.53
SUFF++ for r=0.6 class 0 = 0.565 +- 0.314 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 1 = 0.697 +- 0.314 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 2 = 0.589 +- 0.314 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all KL = 0.504 +- 0.314 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all L1 = 0.615 +- 0.244 (in-sample avg dev_std = 0.532)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.736
Model XAI F1 of binarized graphs for r=0.9 =  0.59344
Model XAI WIoU of binarized graphs for r=0.9 =  0.5555737500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.67
SUFF++ for r=0.9 class 0 = 0.701 +- 0.259 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 1 = 0.957 +- 0.259 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 2 = 0.745 +- 0.259 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all KL = 0.791 +- 0.259 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all L1 = 0.798 +- 0.213 (in-sample avg dev_std = 0.388)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  0.7010925
Model XAI WIoU of binarized graphs for r=0.3 =  0.65357625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.537 +- 0.292 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 1 = 0.475 +- 0.292 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 2 = 0.537 +- 0.292 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all KL = 0.687 +- 0.292 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all L1 = 0.516 +- 0.228 (in-sample avg dev_std = 0.489)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  0.6162225
Model XAI WIoU of binarized graphs for r=0.6 =  0.71121625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.447
NEC for r=0.6 class 0 = 0.609 +- 0.275 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 1 = 0.504 +- 0.275 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 2 = 0.615 +- 0.275 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all KL = 0.682 +- 0.275 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all L1 = 0.576 +- 0.173 (in-sample avg dev_std = 0.539)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7094749999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.518
NEC for r=0.9 class 0 = 0.533 +- 0.299 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.477 +- 0.299 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.585 +- 0.299 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.609 +- 0.299 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.532 +- 0.170 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.70917
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.542
NEC for r=1.0 class 0 = 0.527 +- 0.305 (in-sample avg dev_std = 0.579)
NEC for r=1.0 class 1 = 0.486 +- 0.305 (in-sample avg dev_std = 0.579)
NEC for r=1.0 class 2 = 0.556 +- 0.305 (in-sample avg dev_std = 0.579)
NEC for r=1.0 all KL = 0.592 +- 0.305 (in-sample avg dev_std = 0.579)
NEC for r=1.0 all L1 = 0.523 +- 0.169 (in-sample avg dev_std = 0.579)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.8476275
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.316
NEC for r=0.3 class 0 = 0.574 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 1 = 0.621 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.3 class 2 = 0.549 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.3 all KL = 0.739 +- 0.314 (in-sample avg dev_std = 0.393)
NEC for r=0.3 all L1 = 0.581 +- 0.238 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.935
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.6
NEC for r=0.6 class 0 = 0.529 +- 0.275 (in-sample avg dev_std = 0.666)
NEC for r=0.6 class 1 = 0.462 +- 0.275 (in-sample avg dev_std = 0.666)
NEC for r=0.6 class 2 = 0.525 +- 0.275 (in-sample avg dev_std = 0.666)
NEC for r=0.6 all KL = 0.713 +- 0.275 (in-sample avg dev_std = 0.666)
NEC for r=0.6 all L1 = 0.505 +- 0.146 (in-sample avg dev_std = 0.666)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0 = 0.398 +- 0.255 (in-sample avg dev_std = 0.593)
NEC for r=0.9 class 1 = 0.37 +- 0.255 (in-sample avg dev_std = 0.593)
NEC for r=0.9 class 2 = 0.392 +- 0.255 (in-sample avg dev_std = 0.593)
NEC for r=0.9 all KL = 0.434 +- 0.255 (in-sample avg dev_std = 0.593)
NEC for r=0.9 all L1 = 0.387 +- 0.138 (in-sample avg dev_std = 0.593)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.688
NEC for r=1.0 class 0 = 0.376 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=1.0 class 1 = 0.364 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=1.0 class 2 = 0.4 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=1.0 all KL = 0.399 +- 0.239 (in-sample avg dev_std = 0.567)
NEC for r=1.0 all L1 = 0.38 +- 0.138 (in-sample avg dev_std = 0.567)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.233
Model XAI F1 of binarized graphs for r=0.3 =  0.47595250000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.37469625
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.362
NEC for r=0.3 class 0 = 0.359 +- 0.327 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.401 +- 0.327 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.34 +- 0.327 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.424 +- 0.327 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.366 +- 0.253 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.471
Model XAI F1 of binarized graphs for r=0.6 =  0.6422137499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.53693125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.541
NEC for r=0.6 class 0 = 0.565 +- 0.316 (in-sample avg dev_std = 0.563)
NEC for r=0.6 class 1 = 0.346 +- 0.316 (in-sample avg dev_std = 0.563)
NEC for r=0.6 class 2 = 0.633 +- 0.316 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all KL = 0.643 +- 0.316 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all L1 = 0.518 +- 0.234 (in-sample avg dev_std = 0.563)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.735
Model XAI F1 of binarized graphs for r=0.9 =  0.59344
Model XAI WIoU of binarized graphs for r=0.9 =  0.5555737500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.631
NEC for r=0.9 class 0 = 0.519 +- 0.283 (in-sample avg dev_std = 0.585)
NEC for r=0.9 class 1 = 0.215 +- 0.283 (in-sample avg dev_std = 0.585)
NEC for r=0.9 class 2 = 0.55 +- 0.283 (in-sample avg dev_std = 0.585)
NEC for r=0.9 all KL = 0.538 +- 0.283 (in-sample avg dev_std = 0.585)
NEC for r=0.9 all L1 = 0.432 +- 0.208 (in-sample avg dev_std = 0.585)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.766
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.55582875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.652
NEC for r=1.0 class 0 = 0.5 +- 0.264 (in-sample avg dev_std = 0.564)
NEC for r=1.0 class 1 = 0.224 +- 0.264 (in-sample avg dev_std = 0.564)
NEC for r=1.0 class 2 = 0.515 +- 0.264 (in-sample avg dev_std = 0.564)
NEC for r=1.0 all KL = 0.497 +- 0.264 (in-sample avg dev_std = 0.564)
NEC for r=1.0 all L1 = 0.416 +- 0.196 (in-sample avg dev_std = 0.564)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 17:40:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 05:40:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:41:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 108...
[0m[1;37mINFO[0m: [1mCheckpoint 108: 
-----------------------------------
Train ACCURACY: 0.9043
Train Loss: 0.4735
ID Validation ACCURACY: 0.9057
ID Validation Loss: 0.4820
ID Test ACCURACY: 0.8980
ID Test Loss: 0.4858
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3931
OOD Test ACCURACY: 0.8780
OOD Test Loss: 0.4974

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.8769
Train Loss: 0.4574
ID Validation ACCURACY: 0.8750
ID Validation Loss: 0.4700
ID Test ACCURACY: 0.8720
ID Test Loss: 0.4685
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3684
OOD Test ACCURACY: 0.8137
OOD Test Loss: 0.5853

[0m[1;37mINFO[0m: [1mChartInfo 0.8980 0.8780 0.8720 0.8137 0.8750 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.676
F1 for r=0.6 = 0.621
WIoU for r=0.6 = 0.796
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.800
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.800
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.786
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.551
WIoU for r=0.3 = 0.403
F1 for r=0.6 = 0.709
WIoU for r=0.6 = 0.592
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.587
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.587


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.7257112499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6763425
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.449
SUFF++ for r=0.3 class 0 = 0.5 +- 0.346 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 1 = 0.708 +- 0.346 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 2 = 0.504 +- 0.346 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all KL = 0.555 +- 0.346 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all L1 = 0.571 +- 0.223 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.6206050000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7957325000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.733
SUFF++ for r=0.6 class 0 = 0.64 +- 0.273 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 1 = 0.657 +- 0.273 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 2 = 0.644 +- 0.273 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all KL = 0.636 +- 0.273 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all L1 = 0.647 +- 0.192 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.79988125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.829
SUFF++ for r=0.9 class 0 = 0.843 +- 0.164 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1 = 0.737 +- 0.164 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.164 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.883 +- 0.164 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.81 +- 0.185 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.446
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78618875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.432
SUFF++ for r=0.3 class 0 = 0.645 +- 0.262 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 1 = 0.654 +- 0.262 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 2 = 0.598 +- 0.262 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all KL = 0.625 +- 0.262 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all L1 = 0.632 +- 0.181 (in-sample avg dev_std = 0.533)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.919
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.873
SUFF++ for r=0.6 class 0 = 0.849 +- 0.251 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 1 = 0.788 +- 0.251 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 class 2 = 0.888 +- 0.251 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all KL = 0.824 +- 0.251 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.6 all L1 = 0.842 +- 0.163 (in-sample avg dev_std = 0.369)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.906
SUFF++ for r=0.9 class 0 = 0.977 +- 0.077 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 1 = 0.856 +- 0.077 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 2 = 0.962 +- 0.077 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all KL = 0.972 +- 0.077 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all L1 = 0.932 +- 0.119 (in-sample avg dev_std = 0.125)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.335
Model XAI F1 of binarized graphs for r=0.3 =  0.55066125
Model XAI WIoU of binarized graphs for r=0.3 =  0.4034312499999999
len(reference) = 786
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.35
SUFF++ for r=0.3 class 0 = 0.717 +- 0.190 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 1 = 0.76 +- 0.190 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 class 2 = 0.671 +- 0.190 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all KL = 0.763 +- 0.190 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.3 all L1 = 0.715 +- 0.136 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  0.7092725
Model XAI WIoU of binarized graphs for r=0.6 =  0.5918424999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.682
SUFF++ for r=0.6 class 0 = 0.619 +- 0.305 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 1 = 0.802 +- 0.305 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 2 = 0.601 +- 0.305 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all KL = 0.663 +- 0.305 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all L1 = 0.672 +- 0.223 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.59387375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5871850000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.835
SUFF++ for r=0.9 class 0 = 0.801 +- 0.210 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 class 1 = 0.878 +- 0.210 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 class 2 = 0.77 +- 0.210 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all KL = 0.844 +- 0.210 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.169 (in-sample avg dev_std = 0.339)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.7257112499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6763425
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.63 +- 0.311 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 1 = 0.524 +- 0.311 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 2 = 0.604 +- 0.311 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all KL = 0.592 +- 0.311 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all L1 = 0.585 +- 0.182 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.6206050000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7957325000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.612 +- 0.283 (in-sample avg dev_std = 0.451)
NEC for r=0.6 class 1 = 0.55 +- 0.283 (in-sample avg dev_std = 0.451)
NEC for r=0.6 class 2 = 0.638 +- 0.283 (in-sample avg dev_std = 0.451)
NEC for r=0.6 all KL = 0.638 +- 0.283 (in-sample avg dev_std = 0.451)
NEC for r=0.6 all L1 = 0.6 +- 0.138 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.79988125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.516 +- 0.285 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 1 = 0.492 +- 0.285 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 2 = 0.54 +- 0.285 (in-sample avg dev_std = 0.486)
NEC for r=0.9 all KL = 0.513 +- 0.285 (in-sample avg dev_std = 0.486)
NEC for r=0.9 all L1 = 0.516 +- 0.134 (in-sample avg dev_std = 0.486)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.906
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.79986875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.493 +- 0.283 (in-sample avg dev_std = 0.481)
NEC for r=1.0 class 1 = 0.478 +- 0.283 (in-sample avg dev_std = 0.481)
NEC for r=1.0 class 2 = 0.521 +- 0.283 (in-sample avg dev_std = 0.481)
NEC for r=1.0 all KL = 0.487 +- 0.283 (in-sample avg dev_std = 0.481)
NEC for r=1.0 all L1 = 0.498 +- 0.138 (in-sample avg dev_std = 0.481)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.446
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.78618875
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.469
NEC for r=0.3 class 0 = 0.517 +- 0.268 (in-sample avg dev_std = 0.527)
NEC for r=0.3 class 1 = 0.56 +- 0.268 (in-sample avg dev_std = 0.527)
NEC for r=0.3 class 2 = 0.544 +- 0.268 (in-sample avg dev_std = 0.527)
NEC for r=0.3 all KL = 0.545 +- 0.268 (in-sample avg dev_std = 0.527)
NEC for r=0.3 all L1 = 0.54 +- 0.151 (in-sample avg dev_std = 0.527)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.919
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.705
NEC for r=0.6 class 0 = 0.427 +- 0.283 (in-sample avg dev_std = 0.560)
NEC for r=0.6 class 1 = 0.421 +- 0.283 (in-sample avg dev_std = 0.560)
NEC for r=0.6 class 2 = 0.384 +- 0.283 (in-sample avg dev_std = 0.560)
NEC for r=0.6 all KL = 0.503 +- 0.283 (in-sample avg dev_std = 0.560)
NEC for r=0.6 all L1 = 0.41 +- 0.160 (in-sample avg dev_std = 0.560)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.773
NEC for r=0.9 class 0 = 0.308 +- 0.215 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 1 = 0.31 +- 0.215 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 2 = 0.309 +- 0.215 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all KL = 0.281 +- 0.215 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all L1 = 0.309 +- 0.141 (in-sample avg dev_std = 0.462)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.772
NEC for r=1.0 class 0 = 0.31 +- 0.194 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 1 = 0.31 +- 0.194 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 2 = 0.286 +- 0.194 (in-sample avg dev_std = 0.450)
NEC for r=1.0 all KL = 0.257 +- 0.194 (in-sample avg dev_std = 0.450)
NEC for r=1.0 all L1 = 0.302 +- 0.133 (in-sample avg dev_std = 0.450)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.335
Model XAI F1 of binarized graphs for r=0.3 =  0.55066125
Model XAI WIoU of binarized graphs for r=0.3 =  0.4034312499999999
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.25 +- 0.258 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 1 = 0.329 +- 0.258 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 2 = 0.32 +- 0.258 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all KL = 0.255 +- 0.258 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all L1 = 0.299 +- 0.193 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  0.7092725
Model XAI WIoU of binarized graphs for r=0.6 =  0.5918424999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.513
NEC for r=0.6 class 0 = 0.589 +- 0.296 (in-sample avg dev_std = 0.603)
NEC for r=0.6 class 1 = 0.399 +- 0.296 (in-sample avg dev_std = 0.603)
NEC for r=0.6 class 2 = 0.588 +- 0.296 (in-sample avg dev_std = 0.603)
NEC for r=0.6 all KL = 0.576 +- 0.296 (in-sample avg dev_std = 0.603)
NEC for r=0.6 all L1 = 0.528 +- 0.182 (in-sample avg dev_std = 0.603)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  0.59387375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5871850000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.656
NEC for r=0.9 class 0 = 0.462 +- 0.252 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 1 = 0.407 +- 0.252 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 2 = 0.49 +- 0.252 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all KL = 0.487 +- 0.252 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all L1 = 0.454 +- 0.134 (in-sample avg dev_std = 0.557)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.901
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.58725875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0 = 0.422 +- 0.239 (in-sample avg dev_std = 0.526)
NEC for r=1.0 class 1 = 0.39 +- 0.239 (in-sample avg dev_std = 0.526)
NEC for r=1.0 class 2 = 0.464 +- 0.239 (in-sample avg dev_std = 0.526)
NEC for r=1.0 all KL = 0.43 +- 0.239 (in-sample avg dev_std = 0.526)
NEC for r=1.0 all L1 = 0.426 +- 0.126 (in-sample avg dev_std = 0.526)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 17:44:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:29 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:42 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:45 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:44:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9210
Train Loss: 0.4112
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4190
ID Test ACCURACY: 0.9170
ID Test Loss: 0.4245
OOD Validation ACCURACY: 0.9057
OOD Validation Loss: 0.4172
OOD Test ACCURACY: 0.7763
OOD Test Loss: 0.6641

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.9148
Train Loss: 0.4212
ID Validation ACCURACY: 0.9120
ID Validation Loss: 0.4446
ID Test ACCURACY: 0.9110
ID Test Loss: 0.4271
OOD Validation ACCURACY: 0.9197
OOD Validation Loss: 0.4141
OOD Test ACCURACY: 0.5997
OOD Test Loss: 1.1375

[0m[1;37mINFO[0m: [1mChartInfo 0.9170 0.7763 0.9110 0.5997 0.9120 0.9197[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.728
WIoU for r=0.3 = 0.694
F1 for r=0.6 = 0.620
WIoU for r=0.6 = 0.794
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.790
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.790
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.868
WIoU for r=0.3 = 0.859
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.516
WIoU for r=0.3 = 0.383
F1 for r=0.6 = 0.645
WIoU for r=0.6 = 0.511
F1 for r=0.9 = 0.593
WIoU for r=0.9 = 0.490
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.489


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  0.72810125
Model XAI WIoU of binarized graphs for r=0.3 =  0.6941999999999999
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.49
SUFF++ for r=0.3 class 0 = 0.551 +- 0.346 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 class 1 = 0.816 +- 0.346 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 class 2 = 0.56 +- 0.346 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 all KL = 0.589 +- 0.346 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 all L1 = 0.643 +- 0.237 (in-sample avg dev_std = 0.520)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.61979125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7940625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.733
SUFF++ for r=0.6 class 0 = 0.551 +- 0.284 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 1 = 0.743 +- 0.284 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 2 = 0.645 +- 0.284 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all KL = 0.614 +- 0.284 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all L1 = 0.648 +- 0.200 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.78982625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0 = 0.803 +- 0.155 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.761 +- 0.155 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.155 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.872 +- 0.155 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.804 +- 0.162 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.8684999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8586275000000001
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.514
SUFF++ for r=0.3 class 0 = 0.656 +- 0.344 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 1 = 0.875 +- 0.344 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 2 = 0.653 +- 0.344 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all KL = 0.644 +- 0.344 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all L1 = 0.728 +- 0.223 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.849
SUFF++ for r=0.6 class 0 = 0.765 +- 0.298 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 1 = 0.797 +- 0.298 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 2 = 0.826 +- 0.298 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all KL = 0.766 +- 0.298 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all L1 = 0.796 +- 0.205 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.921
SUFF++ for r=0.9 class 0 = 0.933 +- 0.078 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 1 = 0.924 +- 0.078 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 2 = 0.953 +- 0.078 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all KL = 0.974 +- 0.078 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all L1 = 0.937 +- 0.103 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.336
Model XAI F1 of binarized graphs for r=0.3 =  0.5162549999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.38262
len(reference) = 786
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.338
SUFF++ for r=0.3 class 0 = 0.882 +- 0.170 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 class 1 = 0.887 +- 0.170 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 class 2 = 0.834 +- 0.170 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all KL = 0.892 +- 0.170 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all L1 = 0.867 +- 0.128 (in-sample avg dev_std = 0.265)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  0.6449637500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.511145
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.589
SUFF++ for r=0.6 class 0 = 0.517 +- 0.321 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.321 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 2 = 0.595 +- 0.321 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all KL = 0.576 +- 0.321 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all L1 = 0.623 +- 0.246 (in-sample avg dev_std = 0.567)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  0.5933737499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.48987499999999995
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.729
SUFF++ for r=0.9 class 0 = 0.72 +- 0.190 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.871 +- 0.190 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.721 +- 0.190 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.846 +- 0.190 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.769 +- 0.175 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  0.72810125
Model XAI WIoU of binarized graphs for r=0.3 =  0.6941999999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.369
NEC for r=0.3 class 0 = 0.51 +- 0.335 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 1 = 0.406 +- 0.335 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 2 = 0.541 +- 0.335 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all KL = 0.536 +- 0.335 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all L1 = 0.486 +- 0.231 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  0.61979125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7940625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.505
NEC for r=0.6 class 0 = 0.57 +- 0.312 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 1 = 0.45 +- 0.312 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 2 = 0.594 +- 0.312 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all KL = 0.591 +- 0.312 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all L1 = 0.538 +- 0.191 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.78982625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.571
NEC for r=0.9 class 0 = 0.515 +- 0.307 (in-sample avg dev_std = 0.559)
NEC for r=0.9 class 1 = 0.464 +- 0.307 (in-sample avg dev_std = 0.559)
NEC for r=0.9 class 2 = 0.536 +- 0.307 (in-sample avg dev_std = 0.559)
NEC for r=0.9 all KL = 0.526 +- 0.307 (in-sample avg dev_std = 0.559)
NEC for r=0.9 all L1 = 0.505 +- 0.163 (in-sample avg dev_std = 0.559)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.78982625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.494 +- 0.302 (in-sample avg dev_std = 0.554)
NEC for r=1.0 class 1 = 0.46 +- 0.302 (in-sample avg dev_std = 0.554)
NEC for r=1.0 class 2 = 0.521 +- 0.302 (in-sample avg dev_std = 0.554)
NEC for r=1.0 all KL = 0.503 +- 0.302 (in-sample avg dev_std = 0.554)
NEC for r=1.0 all L1 = 0.492 +- 0.159 (in-sample avg dev_std = 0.554)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.8684999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8586275000000001
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.403
NEC for r=0.3 class 0 = 0.461 +- 0.351 (in-sample avg dev_std = 0.365)
NEC for r=0.3 class 1 = 0.517 +- 0.351 (in-sample avg dev_std = 0.365)
NEC for r=0.3 class 2 = 0.546 +- 0.351 (in-sample avg dev_std = 0.365)
NEC for r=0.3 all KL = 0.586 +- 0.351 (in-sample avg dev_std = 0.365)
NEC for r=0.3 all L1 = 0.508 +- 0.263 (in-sample avg dev_std = 0.365)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.611
NEC for r=0.6 class 0 = 0.518 +- 0.299 (in-sample avg dev_std = 0.623)
NEC for r=0.6 class 1 = 0.374 +- 0.299 (in-sample avg dev_std = 0.623)
NEC for r=0.6 class 2 = 0.383 +- 0.299 (in-sample avg dev_std = 0.623)
NEC for r=0.6 all KL = 0.542 +- 0.299 (in-sample avg dev_std = 0.623)
NEC for r=0.6 all L1 = 0.425 +- 0.180 (in-sample avg dev_std = 0.623)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.693
NEC for r=0.9 class 0 = 0.383 +- 0.214 (in-sample avg dev_std = 0.522)
NEC for r=0.9 class 1 = 0.267 +- 0.214 (in-sample avg dev_std = 0.522)
NEC for r=0.9 class 2 = 0.294 +- 0.214 (in-sample avg dev_std = 0.522)
NEC for r=0.9 all KL = 0.307 +- 0.214 (in-sample avg dev_std = 0.522)
NEC for r=0.9 all L1 = 0.315 +- 0.145 (in-sample avg dev_std = 0.522)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.91
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0 = 0.391 +- 0.208 (in-sample avg dev_std = 0.506)
NEC for r=1.0 class 1 = 0.252 +- 0.208 (in-sample avg dev_std = 0.506)
NEC for r=1.0 class 2 = 0.292 +- 0.208 (in-sample avg dev_std = 0.506)
NEC for r=1.0 all KL = 0.284 +- 0.208 (in-sample avg dev_std = 0.506)
NEC for r=1.0 all L1 = 0.312 +- 0.149 (in-sample avg dev_std = 0.506)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.334
Model XAI F1 of binarized graphs for r=0.3 =  0.5162549999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.38262
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.339
NEC for r=0.3 class 0 = 0.117 +- 0.176 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 1 = 0.1 +- 0.176 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 2 = 0.169 +- 0.176 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all KL = 0.099 +- 0.176 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all L1 = 0.129 +- 0.140 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.654
Model XAI F1 of binarized graphs for r=0.6 =  0.6449637500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.511145
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.567
NEC for r=0.6 class 0 = 0.56 +- 0.329 (in-sample avg dev_std = 0.626)
NEC for r=0.6 class 1 = 0.252 +- 0.329 (in-sample avg dev_std = 0.626)
NEC for r=0.6 class 2 = 0.575 +- 0.329 (in-sample avg dev_std = 0.626)
NEC for r=0.6 all KL = 0.547 +- 0.329 (in-sample avg dev_std = 0.626)
NEC for r=0.6 all L1 = 0.466 +- 0.240 (in-sample avg dev_std = 0.626)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.743
Model XAI F1 of binarized graphs for r=0.9 =  0.5933737499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.48987499999999995
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.708
NEC for r=0.9 class 0 = 0.473 +- 0.246 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 1 = 0.235 +- 0.246 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 2 = 0.456 +- 0.246 (in-sample avg dev_std = 0.455)
NEC for r=0.9 all KL = 0.369 +- 0.246 (in-sample avg dev_std = 0.455)
NEC for r=0.9 all L1 = 0.391 +- 0.178 (in-sample avg dev_std = 0.455)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.786
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.48930499999999993
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.727
NEC for r=1.0 class 0 = 0.43 +- 0.206 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.233 +- 0.206 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.419 +- 0.206 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.306 +- 0.206 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.363 +- 0.153 (in-sample avg dev_std = 0.425)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 17:48:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:26 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:31 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:48:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9109
Train Loss: 0.4453
ID Validation ACCURACY: 0.9133
ID Validation Loss: 0.4608
ID Test ACCURACY: 0.9067
ID Test Loss: 0.4550
OOD Validation ACCURACY: 0.8670
OOD Validation Loss: 0.5066
OOD Test ACCURACY: 0.8083
OOD Test Loss: 0.6156

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8497
Train Loss: 0.5092
ID Validation ACCURACY: 0.8490
ID Validation Loss: 0.5287
ID Test ACCURACY: 0.8573
ID Test Loss: 0.5036
OOD Validation ACCURACY: 0.9263
OOD Validation Loss: 0.4377
OOD Test ACCURACY: 0.7577
OOD Test Loss: 0.8451

[0m[1;37mINFO[0m: [1mChartInfo 0.9067 0.8083 0.8573 0.7577 0.8490 0.9263[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.680
WIoU for r=0.3 = 0.618
F1 for r=0.6 = 0.617
WIoU for r=0.6 = 0.749
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.754
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.855
WIoU for r=0.3 = 0.886
F1 for r=0.6 = 0.792
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.616
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.548
WIoU for r=0.3 = 0.408
F1 for r=0.6 = 0.710
WIoU for r=0.6 = 0.610
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.627
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.627


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  0.679555
Model XAI WIoU of binarized graphs for r=0.3 =  0.61797
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.44
SUFF++ for r=0.3 class 0 = 0.584 +- 0.305 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 1 = 0.743 +- 0.305 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 2 = 0.569 +- 0.305 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all KL = 0.616 +- 0.305 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all L1 = 0.633 +- 0.218 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.842
Model XAI F1 of binarized graphs for r=0.6 =  0.61741625
Model XAI WIoU of binarized graphs for r=0.6 =  0.74943875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.702
SUFF++ for r=0.6 class 0 = 0.592 +- 0.265 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 1 = 0.665 +- 0.265 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 2 = 0.574 +- 0.265 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all KL = 0.582 +- 0.265 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all L1 = 0.61 +- 0.178 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7542975
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.811
SUFF++ for r=0.9 class 0 = 0.822 +- 0.207 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1 = 0.73 +- 0.207 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 2 = 0.793 +- 0.207 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.838 +- 0.207 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.781 +- 0.184 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.609
Model XAI F1 of binarized graphs for r=0.3 =  0.8549925
Model XAI WIoU of binarized graphs for r=0.3 =  0.88620125
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.521
SUFF++ for r=0.3 class 0 = 0.657 +- 0.317 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.3 class 1 = 0.789 +- 0.317 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.3 class 2 = 0.565 +- 0.317 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.3 all KL = 0.586 +- 0.317 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.3 all L1 = 0.67 +- 0.218 (in-sample avg dev_std = 0.548)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.79161
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.833
SUFF++ for r=0.6 class 0 = 0.834 +- 0.313 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 class 1 = 0.773 +- 0.313 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 class 2 = 0.732 +- 0.313 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all KL = 0.719 +- 0.313 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.6 all L1 = 0.78 +- 0.181 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.6162512499999999
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.886
SUFF++ for r=0.9 class 0 = 0.96 +- 0.096 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 class 1 = 0.956 +- 0.096 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 class 2 = 0.927 +- 0.096 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all KL = 0.967 +- 0.096 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.9 all L1 = 0.948 +- 0.103 (in-sample avg dev_std = 0.156)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.54840125
Model XAI WIoU of binarized graphs for r=0.3 =  0.40831625000000005
len(reference) = 782
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.337
SUFF++ for r=0.3 class 0 = 0.703 +- 0.212 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 1 = 0.754 +- 0.212 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 class 2 = 0.7 +- 0.212 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all KL = 0.72 +- 0.212 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.3 all L1 = 0.718 +- 0.160 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.575
Model XAI F1 of binarized graphs for r=0.6 =  0.710375
Model XAI WIoU of binarized graphs for r=0.6 =  0.6100275
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.609 +- 0.309 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 1 = 0.746 +- 0.309 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 class 2 = 0.562 +- 0.309 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all KL = 0.604 +- 0.309 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.6 all L1 = 0.637 +- 0.221 (in-sample avg dev_std = 0.501)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  0.59401375
Model XAI WIoU of binarized graphs for r=0.9 =  0.6273775
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.772
SUFF++ for r=0.9 class 0 = 0.776 +- 0.194 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 1 = 0.834 +- 0.194 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 2 = 0.687 +- 0.194 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all KL = 0.825 +- 0.194 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all L1 = 0.765 +- 0.176 (in-sample avg dev_std = 0.334)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  0.679555
Model XAI WIoU of binarized graphs for r=0.3 =  0.61797
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.328
NEC for r=0.3 class 0 = 0.547 +- 0.298 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 1 = 0.525 +- 0.298 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 2 = 0.549 +- 0.298 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all KL = 0.574 +- 0.298 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all L1 = 0.541 +- 0.205 (in-sample avg dev_std = 0.458)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.842
Model XAI F1 of binarized graphs for r=0.6 =  0.61741625
Model XAI WIoU of binarized graphs for r=0.6 =  0.74943875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.433
NEC for r=0.6 class 0 = 0.575 +- 0.307 (in-sample avg dev_std = 0.457)
NEC for r=0.6 class 1 = 0.491 +- 0.307 (in-sample avg dev_std = 0.457)
NEC for r=0.6 class 2 = 0.606 +- 0.307 (in-sample avg dev_std = 0.457)
NEC for r=0.6 all KL = 0.585 +- 0.307 (in-sample avg dev_std = 0.457)
NEC for r=0.6 all L1 = 0.558 +- 0.181 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7542975
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.514
NEC for r=0.9 class 0 = 0.496 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 1 = 0.457 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 2 = 0.544 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all KL = 0.495 +- 0.301 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all L1 = 0.5 +- 0.166 (in-sample avg dev_std = 0.491)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.911
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.754285
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.509
NEC for r=1.0 class 0 = 0.488 +- 0.294 (in-sample avg dev_std = 0.476)
NEC for r=1.0 class 1 = 0.455 +- 0.294 (in-sample avg dev_std = 0.476)
NEC for r=1.0 class 2 = 0.543 +- 0.294 (in-sample avg dev_std = 0.476)
NEC for r=1.0 all KL = 0.478 +- 0.294 (in-sample avg dev_std = 0.476)
NEC for r=1.0 all L1 = 0.496 +- 0.165 (in-sample avg dev_std = 0.476)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.609
Model XAI F1 of binarized graphs for r=0.3 =  0.8549925
Model XAI WIoU of binarized graphs for r=0.3 =  0.88620125
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.24
NEC for r=0.3 class 0 = 0.578 +- 0.272 (in-sample avg dev_std = 0.420)
NEC for r=0.3 class 1 = 0.68 +- 0.272 (in-sample avg dev_std = 0.420)
NEC for r=0.3 class 2 = 0.635 +- 0.272 (in-sample avg dev_std = 0.420)
NEC for r=0.3 all KL = 0.706 +- 0.272 (in-sample avg dev_std = 0.420)
NEC for r=0.3 all L1 = 0.631 +- 0.160 (in-sample avg dev_std = 0.420)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.79161
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.533
NEC for r=0.6 class 0 = 0.487 +- 0.337 (in-sample avg dev_std = 0.580)
NEC for r=0.6 class 1 = 0.367 +- 0.337 (in-sample avg dev_std = 0.580)
NEC for r=0.6 class 2 = 0.452 +- 0.337 (in-sample avg dev_std = 0.580)
NEC for r=0.6 all KL = 0.545 +- 0.337 (in-sample avg dev_std = 0.580)
NEC for r=0.6 all L1 = 0.436 +- 0.172 (in-sample avg dev_std = 0.580)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.6162512499999999
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.599
NEC for r=0.9 class 0 = 0.362 +- 0.258 (in-sample avg dev_std = 0.501)
NEC for r=0.9 class 1 = 0.26 +- 0.258 (in-sample avg dev_std = 0.501)
NEC for r=0.9 class 2 = 0.35 +- 0.258 (in-sample avg dev_std = 0.501)
NEC for r=0.9 all KL = 0.325 +- 0.258 (in-sample avg dev_std = 0.501)
NEC for r=0.9 all L1 = 0.324 +- 0.151 (in-sample avg dev_std = 0.501)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0 = 0.358 +- 0.246 (in-sample avg dev_std = 0.492)
NEC for r=1.0 class 1 = 0.247 +- 0.246 (in-sample avg dev_std = 0.492)
NEC for r=1.0 class 2 = 0.359 +- 0.246 (in-sample avg dev_std = 0.492)
NEC for r=1.0 all KL = 0.31 +- 0.246 (in-sample avg dev_std = 0.492)
NEC for r=1.0 all L1 = 0.322 +- 0.153 (in-sample avg dev_std = 0.492)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.347
Model XAI F1 of binarized graphs for r=0.3 =  0.54840125
Model XAI WIoU of binarized graphs for r=0.3 =  0.40831625000000005
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.313
NEC for r=0.3 class 0 = 0.231 +- 0.259 (in-sample avg dev_std = 0.349)
NEC for r=0.3 class 1 = 0.263 +- 0.259 (in-sample avg dev_std = 0.349)
NEC for r=0.3 class 2 = 0.268 +- 0.259 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all KL = 0.232 +- 0.259 (in-sample avg dev_std = 0.349)
NEC for r=0.3 all L1 = 0.254 +- 0.212 (in-sample avg dev_std = 0.349)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.575
Model XAI F1 of binarized graphs for r=0.6 =  0.710375
Model XAI WIoU of binarized graphs for r=0.6 =  0.6100275
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.484
NEC for r=0.6 class 0 = 0.562 +- 0.279 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 1 = 0.427 +- 0.279 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 2 = 0.586 +- 0.279 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all KL = 0.59 +- 0.279 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all L1 = 0.527 +- 0.175 (in-sample avg dev_std = 0.593)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  0.59401375
Model XAI WIoU of binarized graphs for r=0.9 =  0.6273775
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.489 +- 0.242 (in-sample avg dev_std = 0.503)
NEC for r=0.9 class 1 = 0.396 +- 0.242 (in-sample avg dev_std = 0.503)
NEC for r=0.9 class 2 = 0.503 +- 0.242 (in-sample avg dev_std = 0.503)
NEC for r=0.9 all KL = 0.449 +- 0.242 (in-sample avg dev_std = 0.503)
NEC for r=0.9 all L1 = 0.464 +- 0.129 (in-sample avg dev_std = 0.503)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.832
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.6273337499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.627
NEC for r=1.0 class 0 = 0.472 +- 0.230 (in-sample avg dev_std = 0.480)
NEC for r=1.0 class 1 = 0.384 +- 0.230 (in-sample avg dev_std = 0.480)
NEC for r=1.0 class 2 = 0.489 +- 0.230 (in-sample avg dev_std = 0.480)
NEC for r=1.0 all KL = 0.41 +- 0.230 (in-sample avg dev_std = 0.480)
NEC for r=1.0 all L1 = 0.45 +- 0.122 (in-sample avg dev_std = 0.480)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 17:51:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 05:51:51 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:07 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:09 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:11 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:52:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 0.9204
Train Loss: 0.4007
ID Validation ACCURACY: 0.9157
ID Validation Loss: 0.4156
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4182
OOD Validation ACCURACY: 0.8913
OOD Validation Loss: 0.4308
OOD Test ACCURACY: 0.8130
OOD Test Loss: 0.6450

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.9017
Train Loss: 0.4520
ID Validation ACCURACY: 0.9030
ID Validation Loss: 0.4688
ID Test ACCURACY: 0.9007
ID Test Loss: 0.4646
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.4280
OOD Test ACCURACY: 0.8577
OOD Test Loss: 0.4768

[0m[1;37mINFO[0m: [1mChartInfo 0.9130 0.8130 0.9007 0.8577 0.9030 0.9310[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.733
WIoU for r=0.3 = 0.680
F1 for r=0.6 = 0.620
WIoU for r=0.6 = 0.778
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.782
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.782
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.869
WIoU for r=0.3 = 0.877
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.518
WIoU for r=0.3 = 0.386
F1 for r=0.6 = 0.704
WIoU for r=0.6 = 0.581
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.585
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.585


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.616
Model XAI F1 of binarized graphs for r=0.3 =  0.73346
Model XAI WIoU of binarized graphs for r=0.3 =  0.6799250000000001
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.467
SUFF++ for r=0.3 class 0 = 0.575 +- 0.338 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 1 = 0.834 +- 0.338 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 2 = 0.569 +- 0.338 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all KL = 0.602 +- 0.338 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all L1 = 0.66 +- 0.252 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.858
Model XAI F1 of binarized graphs for r=0.6 =  0.62024375
Model XAI WIoU of binarized graphs for r=0.6 =  0.7779599999999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.707
SUFF++ for r=0.6 class 0 = 0.574 +- 0.293 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 1 = 0.786 +- 0.293 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 2 = 0.597 +- 0.293 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all KL = 0.599 +- 0.293 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all L1 = 0.653 +- 0.212 (in-sample avg dev_std = 0.481)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.78227125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0 = 0.797 +- 0.188 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.806 +- 0.188 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.833 +- 0.188 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.865 +- 0.188 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.181 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.876845
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.445
SUFF++ for r=0.3 class 0 = 0.651 +- 0.343 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 class 1 = 0.86 +- 0.343 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 class 2 = 0.649 +- 0.343 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 all KL = 0.637 +- 0.343 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 all L1 = 0.72 +- 0.237 (in-sample avg dev_std = 0.489)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.869
SUFF++ for r=0.6 class 0 = 0.812 +- 0.291 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1 = 0.818 +- 0.291 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 2 = 0.905 +- 0.291 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.815 +- 0.291 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.845 +- 0.192 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.89
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.894
SUFF++ for r=0.9 class 0 = 0.972 +- 0.051 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 class 1 = 0.952 +- 0.051 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 class 2 = 0.964 +- 0.051 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all KL = 0.988 +- 0.051 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all L1 = 0.963 +- 0.066 (in-sample avg dev_std = 0.104)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.365
Model XAI F1 of binarized graphs for r=0.3 =  0.5184424999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.38606124999999997
len(reference) = 789
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.332
SUFF++ for r=0.3 class 0 = 0.858 +- 0.262 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 1 = 0.847 +- 0.262 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 2 = 0.717 +- 0.262 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all KL = 0.767 +- 0.262 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all L1 = 0.807 +- 0.191 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  0.70418625
Model XAI WIoU of binarized graphs for r=0.6 =  0.58078125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.679
SUFF++ for r=0.6 class 0 = 0.632 +- 0.333 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 1 = 0.854 +- 0.333 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 2 = 0.562 +- 0.333 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all KL = 0.612 +- 0.333 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all L1 = 0.68 +- 0.251 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  0.593825
Model XAI WIoU of binarized graphs for r=0.9 =  0.58510875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.744
SUFF++ for r=0.9 class 0 = 0.727 +- 0.251 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 class 1 = 0.922 +- 0.251 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 class 2 = 0.694 +- 0.251 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 all KL = 0.806 +- 0.251 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 all L1 = 0.779 +- 0.211 (in-sample avg dev_std = 0.379)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.73346
Model XAI WIoU of binarized graphs for r=0.3 =  0.6799250000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.315
NEC for r=0.3 class 0 = 0.553 +- 0.313 (in-sample avg dev_std = 0.508)
NEC for r=0.3 class 1 = 0.515 +- 0.313 (in-sample avg dev_std = 0.508)
NEC for r=0.3 class 2 = 0.54 +- 0.313 (in-sample avg dev_std = 0.508)
NEC for r=0.3 all KL = 0.623 +- 0.313 (in-sample avg dev_std = 0.508)
NEC for r=0.3 all L1 = 0.536 +- 0.230 (in-sample avg dev_std = 0.508)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.859
Model XAI F1 of binarized graphs for r=0.6 =  0.62024375
Model XAI WIoU of binarized graphs for r=0.6 =  0.7779599999999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.624 +- 0.304 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 1 = 0.521 +- 0.304 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 2 = 0.622 +- 0.304 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all KL = 0.659 +- 0.304 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all L1 = 0.589 +- 0.179 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.78227125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.535 +- 0.308 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 1 = 0.495 +- 0.308 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 2 = 0.531 +- 0.308 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all KL = 0.544 +- 0.308 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all L1 = 0.52 +- 0.169 (in-sample avg dev_std = 0.560)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.78227125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.514 +- 0.302 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 1 = 0.484 +- 0.302 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 2 = 0.523 +- 0.302 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all KL = 0.514 +- 0.302 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all L1 = 0.507 +- 0.168 (in-sample avg dev_std = 0.545)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  0.86858875
Model XAI WIoU of binarized graphs for r=0.3 =  0.876845
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.229
NEC for r=0.3 class 0 = 0.465 +- 0.360 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 1 = 0.688 +- 0.360 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 2 = 0.529 +- 0.360 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all KL = 0.66 +- 0.360 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all L1 = 0.56 +- 0.264 (in-sample avg dev_std = 0.406)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.522
NEC for r=0.6 class 0 = 0.557 +- 0.311 (in-sample avg dev_std = 0.711)
NEC for r=0.6 class 1 = 0.462 +- 0.311 (in-sample avg dev_std = 0.711)
NEC for r=0.6 class 2 = 0.526 +- 0.311 (in-sample avg dev_std = 0.711)
NEC for r=0.6 all KL = 0.659 +- 0.311 (in-sample avg dev_std = 0.711)
NEC for r=0.6 all L1 = 0.515 +- 0.186 (in-sample avg dev_std = 0.711)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.89
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.61
NEC for r=0.9 class 0 = 0.406 +- 0.273 (in-sample avg dev_std = 0.596)
NEC for r=0.9 class 1 = 0.331 +- 0.273 (in-sample avg dev_std = 0.596)
NEC for r=0.9 class 2 = 0.375 +- 0.273 (in-sample avg dev_std = 0.596)
NEC for r=0.9 all KL = 0.396 +- 0.273 (in-sample avg dev_std = 0.596)
NEC for r=0.9 all L1 = 0.371 +- 0.162 (in-sample avg dev_std = 0.596)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.889
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0 = 0.395 +- 0.251 (in-sample avg dev_std = 0.581)
NEC for r=1.0 class 1 = 0.31 +- 0.251 (in-sample avg dev_std = 0.581)
NEC for r=1.0 class 2 = 0.38 +- 0.251 (in-sample avg dev_std = 0.581)
NEC for r=1.0 all KL = 0.368 +- 0.251 (in-sample avg dev_std = 0.581)
NEC for r=1.0 all L1 = 0.362 +- 0.153 (in-sample avg dev_std = 0.581)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.366
Model XAI F1 of binarized graphs for r=0.3 =  0.5184424999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.38606124999999997
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.355
NEC for r=0.3 class 0 = 0.152 +- 0.317 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1 = 0.172 +- 0.317 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 2 = 0.361 +- 0.317 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.268 +- 0.317 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.229 +- 0.236 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  0.70418625
Model XAI WIoU of binarized graphs for r=0.6 =  0.58078125
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.522
NEC for r=0.6 class 0 = 0.621 +- 0.315 (in-sample avg dev_std = 0.635)
NEC for r=0.6 class 1 = 0.327 +- 0.315 (in-sample avg dev_std = 0.635)
NEC for r=0.6 class 2 = 0.63 +- 0.315 (in-sample avg dev_std = 0.635)
NEC for r=0.6 all KL = 0.655 +- 0.315 (in-sample avg dev_std = 0.635)
NEC for r=0.6 all L1 = 0.529 +- 0.234 (in-sample avg dev_std = 0.635)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  0.593825
Model XAI WIoU of binarized graphs for r=0.9 =  0.58510875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.665
NEC for r=0.9 class 0 = 0.497 +- 0.227 (in-sample avg dev_std = 0.544)
NEC for r=0.9 class 1 = 0.342 +- 0.227 (in-sample avg dev_std = 0.544)
NEC for r=0.9 class 2 = 0.455 +- 0.227 (in-sample avg dev_std = 0.544)
NEC for r=0.9 all KL = 0.47 +- 0.227 (in-sample avg dev_std = 0.544)
NEC for r=0.9 all L1 = 0.433 +- 0.159 (in-sample avg dev_std = 0.544)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.835
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5852474999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0 = 0.477 +- 0.209 (in-sample avg dev_std = 0.530)
NEC for r=1.0 class 1 = 0.339 +- 0.209 (in-sample avg dev_std = 0.530)
NEC for r=1.0 class 2 = 0.435 +- 0.209 (in-sample avg dev_std = 0.530)
NEC for r=1.0 all KL = 0.431 +- 0.209 (in-sample avg dev_std = 0.530)
NEC for r=1.0 all L1 = 0.418 +- 0.145 (in-sample avg dev_std = 0.530)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.441, 0.562, 0.845, 1.0], 'all_L1': [0.613, 0.65, 0.81, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.555, 0.636, 0.883, 1.0], 'all_L1': [0.571, 0.647, 0.81, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.589, 0.614, 0.872, 1.0], 'all_L1': [0.643, 0.648, 0.804, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.616, 0.582, 0.838, 1.0], 'all_L1': [0.633, 0.61, 0.781, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.602, 0.599, 0.865, 1.0], 'all_L1': [0.66, 0.653, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.687, 0.682, 0.609, 0.592], 'all_L1': [0.516, 0.576, 0.532, 0.523]}), defaultdict(<class 'list'>, {'all_KL': [0.592, 0.638, 0.513, 0.487], 'all_L1': [0.585, 0.6, 0.516, 0.498]}), defaultdict(<class 'list'>, {'all_KL': [0.536, 0.591, 0.526, 0.503], 'all_L1': [0.486, 0.538, 0.505, 0.492]}), defaultdict(<class 'list'>, {'all_KL': [0.574, 0.585, 0.495, 0.478], 'all_L1': [0.541, 0.558, 0.5, 0.496]}), defaultdict(<class 'list'>, {'all_KL': [0.623, 0.659, 0.544, 0.514], 'all_L1': [0.536, 0.589, 0.52, 0.507]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.449, 0.767, 0.989, 1.0], 'all_L1': [0.607, 0.846, 0.953, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.625, 0.824, 0.972, 1.0], 'all_L1': [0.632, 0.842, 0.932, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.644, 0.766, 0.974, 1.0], 'all_L1': [0.728, 0.796, 0.937, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.586, 0.719, 0.967, 1.0], 'all_L1': [0.67, 0.78, 0.948, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.637, 0.815, 0.988, 1.0], 'all_L1': [0.72, 0.845, 0.963, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.739, 0.713, 0.434, 0.399], 'all_L1': [0.581, 0.505, 0.387, 0.38]}), defaultdict(<class 'list'>, {'all_KL': [0.545, 0.503, 0.281, 0.257], 'all_L1': [0.54, 0.41, 0.309, 0.302]}), defaultdict(<class 'list'>, {'all_KL': [0.586, 0.542, 0.307, 0.284], 'all_L1': [0.508, 0.425, 0.315, 0.312]}), defaultdict(<class 'list'>, {'all_KL': [0.706, 0.545, 0.325, 0.31], 'all_L1': [0.631, 0.436, 0.324, 0.322]}), defaultdict(<class 'list'>, {'all_KL': [0.66, 0.659, 0.396, 0.368], 'all_L1': [0.56, 0.515, 0.371, 0.362]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.59, 0.504, 0.791, 1.0], 'all_L1': [0.671, 0.615, 0.798, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.763, 0.663, 0.844, 1.0], 'all_L1': [0.715, 0.672, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.892, 0.576, 0.846, 1.0], 'all_L1': [0.867, 0.623, 0.769, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.72, 0.604, 0.825, 1.0], 'all_L1': [0.718, 0.637, 0.765, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.767, 0.612, 0.806, 1.0], 'all_L1': [0.807, 0.68, 0.779, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.424, 0.643, 0.538, 0.497], 'all_L1': [0.366, 0.518, 0.432, 0.416]}), defaultdict(<class 'list'>, {'all_KL': [0.255, 0.576, 0.487, 0.43], 'all_L1': [0.299, 0.528, 0.454, 0.426]}), defaultdict(<class 'list'>, {'all_KL': [0.099, 0.547, 0.369, 0.306], 'all_L1': [0.129, 0.466, 0.391, 0.363]}), defaultdict(<class 'list'>, {'all_KL': [0.232, 0.59, 0.449, 0.41], 'all_L1': [0.254, 0.527, 0.464, 0.45]}), defaultdict(<class 'list'>, {'all_KL': [0.268, 0.655, 0.47, 0.431], 'all_L1': [0.229, 0.529, 0.433, 0.418]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.624 +- 0.031, 0.642 +- 0.016, 0.803 +- 0.012, 1.000 +- 0.000
suff++ class all_KL  =  0.561 +- 0.063, 0.599 +- 0.025, 0.861 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.464 +- 0.018, 0.722 +- 0.014, 0.836 +- 0.014
nec class all_L1  =  0.533 +- 0.032, 0.572 +- 0.022, 0.515 +- 0.011, 0.503 +- 0.011
nec class all_KL  =  0.602 +- 0.051, 0.631 +- 0.038, 0.537 +- 0.039, 0.515 +- 0.041
nec_acc_int  =  0.337 +- 0.018, 0.455 +- 0.025, 0.534 +- 0.020, 0.545 +- 0.024

Eval split val
suff++ class all_L1  =  0.671 +- 0.047, 0.822 +- 0.028, 0.947 +- 0.011, 1.000 +- 0.000
suff++ class all_KL  =  0.588 +- 0.072, 0.778 +- 0.038, 0.978 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.491 +- 0.044, 0.861 +- 0.017, 0.908 +- 0.018
nec class all_L1  =  0.564 +- 0.041, 0.458 +- 0.043, 0.341 +- 0.032, 0.336 +- 0.030
nec class all_KL  =  0.647 +- 0.072, 0.592 +- 0.080, 0.349 +- 0.057, 0.324 +- 0.053
nec_acc_int  =  0.331 +- 0.093, 0.594 +- 0.066, 0.671 +- 0.063, 0.673 +- 0.061

Eval split test
suff++ class all_L1  =  0.756 +- 0.071, 0.645 +- 0.026, 0.785 +- 0.019, 1.000 +- 0.000
suff++ class all_KL  =  0.746 +- 0.097, 0.592 +- 0.052, 0.822 +- 0.021, 1.000 +- 0.000
suff++_acc_int  =  0.339 +- 0.006, 0.621 +- 0.058, 0.750 +- 0.054
nec class all_L1  =  0.255 +- 0.078, 0.514 +- 0.024, 0.435 +- 0.025, 0.415 +- 0.028
nec class all_KL  =  0.256 +- 0.104, 0.602 +- 0.041, 0.463 +- 0.055, 0.415 +- 0.062
nec_acc_int  =  0.340 +- 0.017, 0.526 +- 0.028, 0.656 +- 0.031, 0.672 +- 0.033


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.578 +- 0.013, 0.607 +- 0.016, 0.659 +- 0.011, 0.752 +- 0.006
Faith. Armon (L1)= 		  =  0.573 +- 0.014, 0.605 +- 0.016, 0.627 +- 0.011, 0.669 +- 0.010
Faith. GMean (L1)= 	  =  0.576 +- 0.014, 0.606 +- 0.016, 0.643 +- 0.011, 0.709 +- 0.008
Faith. Aritm (KL)= 		  =  0.581 +- 0.019, 0.615 +- 0.019, 0.699 +- 0.019, 0.757 +- 0.020
Faith. Armon (KL)= 		  =  0.576 +- 0.026, 0.613 +- 0.019, 0.661 +- 0.028, 0.679 +- 0.034
Faith. GMean (KL)= 	  =  0.579 +- 0.022, 0.614 +- 0.019, 0.680 +- 0.024, 0.717 +- 0.028

Eval split val
Faith. Aritm (L1)= 		  =  0.618 +- 0.025, 0.640 +- 0.031, 0.644 +- 0.021, 0.668 +- 0.015
Faith. Armon (L1)= 		  =  0.611 +- 0.025, 0.587 +- 0.040, 0.501 +- 0.035, 0.502 +- 0.034
Faith. GMean (L1)= 	  =  0.614 +- 0.025, 0.613 +- 0.036, 0.568 +- 0.029, 0.579 +- 0.026
Faith. Aritm (KL)= 		  =  0.618 +- 0.026, 0.685 +- 0.045, 0.663 +- 0.033, 0.662 +- 0.026
Faith. Armon (KL)= 		  =  0.609 +- 0.034, 0.669 +- 0.053, 0.512 +- 0.063, 0.487 +- 0.060
Faith. GMean (KL)= 	  =  0.613 +- 0.030, 0.677 +- 0.049, 0.582 +- 0.050, 0.567 +- 0.046

Eval split test
Faith. Aritm (L1)= 		  =  0.506 +- 0.012, 0.580 +- 0.022, 0.610 +- 0.018, 0.707 +- 0.014
Faith. Armon (L1)= 		  =  0.370 +- 0.083, 0.572 +- 0.022, 0.559 +- 0.023, 0.586 +- 0.029
Faith. GMean (L1)= 	  =  0.430 +- 0.054, 0.576 +- 0.022, 0.584 +- 0.020, 0.644 +- 0.022
Faith. Aritm (KL)= 		  =  0.501 +- 0.014, 0.597 +- 0.027, 0.643 +- 0.021, 0.707 +- 0.031
Faith. Armon (KL)= 		  =  0.360 +- 0.103, 0.594 +- 0.028, 0.589 +- 0.043, 0.584 +- 0.064
Faith. GMean (KL)= 	  =  0.420 +- 0.068, 0.596 +- 0.027, 0.615 +- 0.033, 0.642 +- 0.050
Computed for split load_split = id



Completed in  0:18:31.230075  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis topk

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 17:56:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:34 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:36 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:38 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 05:56:39 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9156
Train Loss: 0.3913
ID Validation ACCURACY: 0.9120
ID Validation Loss: 0.4126
ID Test ACCURACY: 0.9150
ID Test Loss: 0.3906
OOD Validation ACCURACY: 0.9000
OOD Validation Loss: 0.4068
OOD Test ACCURACY: 0.4780
OOD Test Loss: 2.2425

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.8658
Train Loss: 0.4650
ID Validation ACCURACY: 0.8613
ID Validation Loss: 0.4710
ID Test ACCURACY: 0.8720
ID Test Loss: 0.4530
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3266
OOD Test ACCURACY: 0.4253
OOD Test Loss: 2.2652

[0m[1;37mINFO[0m: [1mChartInfo 0.9150 0.4780 0.8720 0.4253 0.8613 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.533
WIoU for r=0.3 = 0.488
F1 for r=0.6 = 0.495
WIoU for r=0.6 = 0.544
F1 for r=0.9 = 0.458
WIoU for r=0.9 = 0.578
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.584
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.828
WIoU for r=0.3 = 0.851
F1 for r=0.6 = 0.764
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.609
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.335
WIoU for r=0.3 = 0.214
F1 for r=0.6 = 0.467
WIoU for r=0.6 = 0.317
F1 for r=0.9 = 0.544
WIoU for r=0.9 = 0.382
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.393


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.516
Model XAI F1 of binarized graphs for r=0.3 =  0.5326925
Model XAI WIoU of binarized graphs for r=0.3 =  0.48780375
len(reference) = 742
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.448
SUFF++ for r=0.3 class 0 = 0.55 +- 0.282 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 1 = 0.597 +- 0.282 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 2 = 0.574 +- 0.282 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all KL = 0.6 +- 0.282 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all L1 = 0.574 +- 0.168 (in-sample avg dev_std = 0.498)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.49515249999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.5441750000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.51
SUFF++ for r=0.6 class 0 = 0.582 +- 0.265 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 1 = 0.647 +- 0.265 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 class 2 = 0.584 +- 0.265 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 all KL = 0.654 +- 0.265 (in-sample avg dev_std = 0.458)
SUFF++ for r=0.6 all L1 = 0.604 +- 0.187 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  0.4576225000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.57830125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.767
SUFF++ for r=0.9 class 0 = 0.827 +- 0.177 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 class 1 = 0.867 +- 0.177 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 class 2 = 0.856 +- 0.177 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all KL = 0.886 +- 0.177 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all L1 = 0.85 +- 0.161 (in-sample avg dev_std = 0.302)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  0.8282425000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.85102375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.497
SUFF++ for r=0.3 class 0 = 0.588 +- 0.325 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 1 = 0.784 +- 0.325 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.325 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all KL = 0.535 +- 0.325 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all L1 = 0.659 +- 0.214 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.7643924999999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.815
SUFF++ for r=0.6 class 0 = 0.749 +- 0.300 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 class 1 = 0.861 +- 0.300 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.300 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 all KL = 0.71 +- 0.300 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.6 all L1 = 0.784 +- 0.185 (in-sample avg dev_std = 0.485)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.6094275
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.912
SUFF++ for r=0.9 class 0 = 0.937 +- 0.088 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 1 = 0.961 +- 0.088 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 2 = 0.961 +- 0.088 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all KL = 0.977 +- 0.088 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.092 (in-sample avg dev_std = 0.136)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.333
Model XAI F1 of binarized graphs for r=0.3 =  0.3354925
Model XAI WIoU of binarized graphs for r=0.3 =  0.21449000000000001
len(reference) = 697
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.316
SUFF++ for r=0.3 class 0 = 0.736 +- 0.114 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 1 = 0.716 +- 0.114 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 class 2 = 0.721 +- 0.114 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 all KL = 0.849 +- 0.114 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.3 all L1 = 0.724 +- 0.115 (in-sample avg dev_std = 0.384)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  0.46713375
Model XAI WIoU of binarized graphs for r=0.6 =  0.31665124999999994
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.313
SUFF++ for r=0.6 class 0 = 0.682 +- 0.141 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 1 = 0.679 +- 0.141 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 2 = 0.693 +- 0.141 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all KL = 0.83 +- 0.141 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.133 (in-sample avg dev_std = 0.324)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.527
Model XAI F1 of binarized graphs for r=0.9 =  0.5442775
Model XAI WIoU of binarized graphs for r=0.9 =  0.38197499999999995
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.507
SUFF++ for r=0.9 class 0 = 0.868 +- 0.152 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 1 = 0.957 +- 0.152 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 2 = 0.855 +- 0.152 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all KL = 0.911 +- 0.152 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all L1 = 0.892 +- 0.141 (in-sample avg dev_std = 0.284)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  0.5326925
Model XAI WIoU of binarized graphs for r=0.3 =  0.48780375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.364
NEC for r=0.3 class 0 = 0.444 +- 0.338 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 1 = 0.418 +- 0.338 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 2 = 0.454 +- 0.338 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all KL = 0.396 +- 0.338 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all L1 = 0.439 +- 0.208 (in-sample avg dev_std = 0.403)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.49515249999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.5441750000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.47 +- 0.269 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 1 = 0.413 +- 0.269 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 2 = 0.478 +- 0.269 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all KL = 0.411 +- 0.269 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all L1 = 0.454 +- 0.163 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  0.4576225000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.57830125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.539
NEC for r=0.9 class 0 = 0.479 +- 0.277 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 1 = 0.42 +- 0.277 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 2 = 0.509 +- 0.277 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all KL = 0.483 +- 0.277 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all L1 = 0.47 +- 0.170 (in-sample avg dev_std = 0.543)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.91
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.5841074999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0 = 0.476 +- 0.296 (in-sample avg dev_std = 0.612)
NEC for r=1.0 class 1 = 0.433 +- 0.296 (in-sample avg dev_std = 0.612)
NEC for r=1.0 class 2 = 0.548 +- 0.296 (in-sample avg dev_std = 0.612)
NEC for r=1.0 all KL = 0.547 +- 0.296 (in-sample avg dev_std = 0.612)
NEC for r=1.0 all L1 = 0.486 +- 0.178 (in-sample avg dev_std = 0.612)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  0.8282425000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.85102375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.313
NEC for r=0.3 class 0 = 0.491 +- 0.330 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1 = 0.535 +- 0.330 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 2 = 0.442 +- 0.330 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.635 +- 0.330 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.489 +- 0.204 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.7643924999999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.62
NEC for r=0.6 class 0 = 0.426 +- 0.282 (in-sample avg dev_std = 0.638)
NEC for r=0.6 class 1 = 0.386 +- 0.282 (in-sample avg dev_std = 0.638)
NEC for r=0.6 class 2 = 0.477 +- 0.282 (in-sample avg dev_std = 0.638)
NEC for r=0.6 all KL = 0.555 +- 0.282 (in-sample avg dev_std = 0.638)
NEC for r=0.6 all L1 = 0.43 +- 0.169 (in-sample avg dev_std = 0.638)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.6094275
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.702
NEC for r=0.9 class 0 = 0.314 +- 0.260 (in-sample avg dev_std = 0.581)
NEC for r=0.9 class 1 = 0.328 +- 0.260 (in-sample avg dev_std = 0.581)
NEC for r=0.9 class 2 = 0.394 +- 0.260 (in-sample avg dev_std = 0.581)
NEC for r=0.9 all KL = 0.391 +- 0.260 (in-sample avg dev_std = 0.581)
NEC for r=0.9 all L1 = 0.345 +- 0.160 (in-sample avg dev_std = 0.581)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.701
NEC for r=1.0 class 0 = 0.297 +- 0.262 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 1 = 0.319 +- 0.262 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 2 = 0.404 +- 0.262 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all KL = 0.377 +- 0.262 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all L1 = 0.34 +- 0.161 (in-sample avg dev_std = 0.568)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.329
Model XAI F1 of binarized graphs for r=0.3 =  0.3354925
Model XAI WIoU of binarized graphs for r=0.3 =  0.21449000000000001
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.335
NEC for r=0.3 class 0 = 0.144 +- 0.086 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 1 = 0.143 +- 0.086 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 2 = 0.159 +- 0.086 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all KL = 0.054 +- 0.086 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all L1 = 0.149 +- 0.126 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  0.46713375
Model XAI WIoU of binarized graphs for r=0.6 =  0.31665124999999994
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.312
NEC for r=0.6 class 0 = 0.218 +- 0.124 (in-sample avg dev_std = 0.258)
NEC for r=0.6 class 1 = 0.211 +- 0.124 (in-sample avg dev_std = 0.258)
NEC for r=0.6 class 2 = 0.206 +- 0.124 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all KL = 0.096 +- 0.124 (in-sample avg dev_std = 0.258)
NEC for r=0.6 all L1 = 0.212 +- 0.129 (in-sample avg dev_std = 0.258)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.527
Model XAI F1 of binarized graphs for r=0.9 =  0.5442775
Model XAI WIoU of binarized graphs for r=0.9 =  0.38197499999999995
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.472
NEC for r=0.9 class 0 = 0.293 +- 0.248 (in-sample avg dev_std = 0.424)
NEC for r=0.9 class 1 = 0.184 +- 0.248 (in-sample avg dev_std = 0.424)
NEC for r=0.9 class 2 = 0.358 +- 0.248 (in-sample avg dev_std = 0.424)
NEC for r=0.9 all KL = 0.287 +- 0.248 (in-sample avg dev_std = 0.424)
NEC for r=0.9 all L1 = 0.28 +- 0.206 (in-sample avg dev_std = 0.424)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.474
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39313625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.486
NEC for r=1.0 class 0 = 0.301 +- 0.294 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 1 = 0.074 +- 0.294 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 2 = 0.467 +- 0.294 (in-sample avg dev_std = 0.464)
NEC for r=1.0 all KL = 0.32 +- 0.294 (in-sample avg dev_std = 0.464)
NEC for r=1.0 all L1 = 0.285 +- 0.242 (in-sample avg dev_std = 0.464)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 17:59:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 05:59:42 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 05:59:54 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 05:59:56 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 05:59:58 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:00 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:00:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8863
Train Loss: 0.4187
ID Validation ACCURACY: 0.8863
ID Validation Loss: 0.4339
ID Test ACCURACY: 0.8927
ID Test Loss: 0.4034
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.3908
OOD Test ACCURACY: 0.5523
OOD Test Loss: 1.4832

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.8378
Train Loss: 0.5286
ID Validation ACCURACY: 0.8383
ID Validation Loss: 0.5354
ID Test ACCURACY: 0.8503
ID Test Loss: 0.5064
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3667
OOD Test ACCURACY: 0.8500
OOD Test Loss: 0.5069

[0m[1;37mINFO[0m: [1mChartInfo 0.8927 0.5523 0.8503 0.8500 0.8383 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.546
WIoU for r=0.3 = 0.476
F1 for r=0.6 = 0.509
WIoU for r=0.6 = 0.528
F1 for r=0.9 = 0.460
WIoU for r=0.9 = 0.554
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.558
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.624
WIoU for r=0.3 = 0.535
F1 for r=0.6 = 0.600
WIoU for r=0.6 = 0.588
F1 for r=0.9 = 0.578
WIoU for r=0.9 = 0.594
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.605
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.334
WIoU for r=0.3 = 0.215
F1 for r=0.6 = 0.463
WIoU for r=0.6 = 0.313
F1 for r=0.9 = 0.539
WIoU for r=0.9 = 0.376
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.393


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.569
Model XAI F1 of binarized graphs for r=0.3 =  0.54582875
Model XAI WIoU of binarized graphs for r=0.3 =  0.47587125
len(reference) = 736
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.431
SUFF++ for r=0.3 class 0 = 0.548 +- 0.301 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 class 1 = 0.542 +- 0.301 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 class 2 = 0.568 +- 0.301 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 all KL = 0.567 +- 0.301 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.3 all L1 = 0.553 +- 0.171 (in-sample avg dev_std = 0.493)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  0.5088374999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.527765
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0 = 0.599 +- 0.242 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 1 = 0.631 +- 0.242 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 2 = 0.642 +- 0.242 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all KL = 0.685 +- 0.242 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all L1 = 0.624 +- 0.170 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.772
Model XAI F1 of binarized graphs for r=0.9 =  0.4604475
Model XAI WIoU of binarized graphs for r=0.9 =  0.55405625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.758
SUFF++ for r=0.9 class 0 = 0.831 +- 0.166 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 1 = 0.817 +- 0.166 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.166 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all KL = 0.886 +- 0.166 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all L1 = 0.836 +- 0.154 (in-sample avg dev_std = 0.289)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.461
Model XAI F1 of binarized graphs for r=0.3 =  0.62436875
Model XAI WIoU of binarized graphs for r=0.3 =  0.53456625
len(reference) = 694
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.366
SUFF++ for r=0.3 class 0 = 0.61 +- 0.316 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 1 = 0.56 +- 0.316 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 2 = 0.563 +- 0.316 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all KL = 0.574 +- 0.316 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all L1 = 0.578 +- 0.185 (in-sample avg dev_std = 0.508)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  0.5998500000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.58751875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.458
SUFF++ for r=0.6 class 0 = 0.673 +- 0.283 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 1 = 0.589 +- 0.283 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 2 = 0.636 +- 0.283 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all KL = 0.668 +- 0.283 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all L1 = 0.633 +- 0.181 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  0.5779875
Model XAI WIoU of binarized graphs for r=0.9 =  0.5941624999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.71
SUFF++ for r=0.9 class 0 = 0.813 +- 0.150 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 1 = 0.831 +- 0.150 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 2 = 0.835 +- 0.150 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 all KL = 0.881 +- 0.150 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.128 (in-sample avg dev_std = 0.311)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.353
Model XAI F1 of binarized graphs for r=0.3 =  0.33440125000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.21465249999999997
len(reference) = 696
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.338
SUFF++ for r=0.3 class 0 = 0.738 +- 0.098 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 1 = 0.75 +- 0.098 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 2 = 0.748 +- 0.098 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 all KL = 0.872 +- 0.098 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 all L1 = 0.746 +- 0.100 (in-sample avg dev_std = 0.354)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.312
Model XAI F1 of binarized graphs for r=0.6 =  0.46316375
Model XAI WIoU of binarized graphs for r=0.6 =  0.3125225
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.332
SUFF++ for r=0.6 class 0 = 0.702 +- 0.144 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 class 1 = 0.711 +- 0.144 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 class 2 = 0.721 +- 0.144 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 all KL = 0.861 +- 0.144 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.6 all L1 = 0.711 +- 0.137 (in-sample avg dev_std = 0.283)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.559
Model XAI F1 of binarized graphs for r=0.9 =  0.5386974999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.37644750000000005
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.544
SUFF++ for r=0.9 class 0 = 0.821 +- 0.159 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.9 class 1 = 0.905 +- 0.159 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.9 class 2 = 0.824 +- 0.159 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.9 all KL = 0.883 +- 0.159 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.9 all L1 = 0.849 +- 0.142 (in-sample avg dev_std = 0.333)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  0.54582875
Model XAI WIoU of binarized graphs for r=0.3 =  0.47587125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.398
NEC for r=0.3 class 0 = 0.439 +- 0.330 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 1 = 0.43 +- 0.330 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 2 = 0.428 +- 0.330 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all KL = 0.405 +- 0.330 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all L1 = 0.432 +- 0.210 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.678
Model XAI F1 of binarized graphs for r=0.6 =  0.5088374999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.527765
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.477
NEC for r=0.6 class 0 = 0.439 +- 0.277 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 1 = 0.418 +- 0.277 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 2 = 0.441 +- 0.277 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all KL = 0.381 +- 0.277 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all L1 = 0.433 +- 0.175 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.772
Model XAI F1 of binarized graphs for r=0.9 =  0.4604475
Model XAI WIoU of binarized graphs for r=0.9 =  0.55405625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.528
NEC for r=0.9 class 0 = 0.472 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.9 class 1 = 0.48 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.9 class 2 = 0.483 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.9 all KL = 0.465 +- 0.282 (in-sample avg dev_std = 0.514)
NEC for r=0.9 all L1 = 0.479 +- 0.162 (in-sample avg dev_std = 0.514)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.5576175
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.584
NEC for r=1.0 class 0 = 0.468 +- 0.294 (in-sample avg dev_std = 0.582)
NEC for r=1.0 class 1 = 0.496 +- 0.294 (in-sample avg dev_std = 0.582)
NEC for r=1.0 class 2 = 0.504 +- 0.294 (in-sample avg dev_std = 0.582)
NEC for r=1.0 all KL = 0.52 +- 0.294 (in-sample avg dev_std = 0.582)
NEC for r=1.0 all L1 = 0.49 +- 0.170 (in-sample avg dev_std = 0.582)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.62436875
Model XAI WIoU of binarized graphs for r=0.3 =  0.53456625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.308
NEC for r=0.3 class 0 = 0.286 +- 0.383 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 1 = 0.365 +- 0.383 (in-sample avg dev_std = 0.359)
NEC for r=0.3 class 2 = 0.346 +- 0.383 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all KL = 0.326 +- 0.383 (in-sample avg dev_std = 0.359)
NEC for r=0.3 all L1 = 0.332 +- 0.279 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  0.5998500000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.58751875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.444
NEC for r=0.6 class 0 = 0.26 +- 0.273 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 1 = 0.306 +- 0.273 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 2 = 0.264 +- 0.273 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all KL = 0.239 +- 0.273 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all L1 = 0.277 +- 0.216 (in-sample avg dev_std = 0.357)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  0.5779875
Model XAI WIoU of binarized graphs for r=0.9 =  0.5941624999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.532
NEC for r=0.9 class 0 = 0.359 +- 0.256 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 1 = 0.337 +- 0.256 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 2 = 0.39 +- 0.256 (in-sample avg dev_std = 0.473)
NEC for r=0.9 all KL = 0.316 +- 0.256 (in-sample avg dev_std = 0.473)
NEC for r=0.9 all L1 = 0.362 +- 0.167 (in-sample avg dev_std = 0.473)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.60511375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0 = 0.408 +- 0.238 (in-sample avg dev_std = 0.559)
NEC for r=1.0 class 1 = 0.316 +- 0.238 (in-sample avg dev_std = 0.559)
NEC for r=1.0 class 2 = 0.414 +- 0.238 (in-sample avg dev_std = 0.559)
NEC for r=1.0 all KL = 0.392 +- 0.238 (in-sample avg dev_std = 0.559)
NEC for r=1.0 all L1 = 0.38 +- 0.165 (in-sample avg dev_std = 0.559)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.344
Model XAI F1 of binarized graphs for r=0.3 =  0.33440125000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.21465249999999997
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.125 +- 0.068 (in-sample avg dev_std = 0.168)
NEC for r=0.3 class 1 = 0.127 +- 0.068 (in-sample avg dev_std = 0.168)
NEC for r=0.3 class 2 = 0.126 +- 0.068 (in-sample avg dev_std = 0.168)
NEC for r=0.3 all KL = 0.04 +- 0.068 (in-sample avg dev_std = 0.168)
NEC for r=0.3 all L1 = 0.126 +- 0.111 (in-sample avg dev_std = 0.168)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.312
Model XAI F1 of binarized graphs for r=0.6 =  0.46316375
Model XAI WIoU of binarized graphs for r=0.6 =  0.3125225
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.32
NEC for r=0.6 class 0 = 0.192 +- 0.128 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 1 = 0.174 +- 0.128 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 2 = 0.187 +- 0.128 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all KL = 0.082 +- 0.128 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all L1 = 0.184 +- 0.125 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.559
Model XAI F1 of binarized graphs for r=0.9 =  0.5386974999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.37644750000000005
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.459
NEC for r=0.9 class 0 = 0.365 +- 0.219 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 1 = 0.343 +- 0.219 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 2 = 0.412 +- 0.219 (in-sample avg dev_std = 0.459)
NEC for r=0.9 all KL = 0.343 +- 0.219 (in-sample avg dev_std = 0.459)
NEC for r=0.9 all L1 = 0.374 +- 0.170 (in-sample avg dev_std = 0.459)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.553
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39307249999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0 = 0.421 +- 0.245 (in-sample avg dev_std = 0.481)
NEC for r=1.0 class 1 = 0.162 +- 0.245 (in-sample avg dev_std = 0.481)
NEC for r=1.0 class 2 = 0.494 +- 0.245 (in-sample avg dev_std = 0.481)
NEC for r=1.0 all KL = 0.37 +- 0.245 (in-sample avg dev_std = 0.481)
NEC for r=1.0 all L1 = 0.363 +- 0.217 (in-sample avg dev_std = 0.481)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:03:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:15 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:17 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:19 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:21 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:03:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8939
Train Loss: 0.4164
ID Validation ACCURACY: 0.8883
ID Validation Loss: 0.4389
ID Test ACCURACY: 0.8993
ID Test Loss: 0.4048
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3256
OOD Test ACCURACY: 0.5150
OOD Test Loss: 1.5261

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 122...
[0m[1;37mINFO[0m: [1mCheckpoint 122: 
-----------------------------------
Train ACCURACY: 0.8592
Train Loss: 0.4774
ID Validation ACCURACY: 0.8513
ID Validation Loss: 0.5092
ID Test ACCURACY: 0.8580
ID Test Loss: 0.4831
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3226
OOD Test ACCURACY: 0.4660
OOD Test Loss: 2.4640

[0m[1;37mINFO[0m: [1mChartInfo 0.8993 0.5150 0.8580 0.4660 0.8513 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.554
WIoU for r=0.3 = 0.477
F1 for r=0.6 = 0.519
WIoU for r=0.6 = 0.535
F1 for r=0.9 = 0.461
WIoU for r=0.9 = 0.546
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.548
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.868
WIoU for r=0.3 = 0.783
F1 for r=0.6 = 0.798
WIoU for r=0.6 = 0.988
F1 for r=0.9 = 0.618
WIoU for r=0.9 = 0.955
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.948
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.335
WIoU for r=0.3 = 0.216
F1 for r=0.6 = 0.461
WIoU for r=0.6 = 0.313
F1 for r=0.9 = 0.542
WIoU for r=0.9 = 0.379
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.391


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.507
Model XAI F1 of binarized graphs for r=0.3 =  0.55350625
Model XAI WIoU of binarized graphs for r=0.3 =  0.4768025
len(reference) = 742
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.411
SUFF++ for r=0.3 class 0 = 0.619 +- 0.310 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 class 1 = 0.604 +- 0.310 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 class 2 = 0.588 +- 0.310 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 all KL = 0.606 +- 0.310 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.3 all L1 = 0.603 +- 0.193 (in-sample avg dev_std = 0.465)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  0.51899625
Model XAI WIoU of binarized graphs for r=0.6 =  0.5348625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.55
SUFF++ for r=0.6 class 0 = 0.597 +- 0.256 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 1 = 0.627 +- 0.256 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 class 2 = 0.569 +- 0.256 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 all KL = 0.635 +- 0.256 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.6 all L1 = 0.598 +- 0.175 (in-sample avg dev_std = 0.472)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.785
Model XAI F1 of binarized graphs for r=0.9 =  0.46104750000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.5464825000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.75
SUFF++ for r=0.9 class 0 = 0.803 +- 0.188 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 1 = 0.822 +- 0.188 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 2 = 0.817 +- 0.188 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all KL = 0.859 +- 0.188 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all L1 = 0.814 +- 0.172 (in-sample avg dev_std = 0.315)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.445
Model XAI F1 of binarized graphs for r=0.3 =  0.8684999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7829925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.384
SUFF++ for r=0.3 class 0 = 0.596 +- 0.308 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 1 = 0.647 +- 0.308 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 2 = 0.61 +- 0.308 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all KL = 0.59 +- 0.308 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all L1 = 0.617 +- 0.202 (in-sample avg dev_std = 0.508)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.935
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9877250000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.86
SUFF++ for r=0.6 class 0 = 0.84 +- 0.284 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 1 = 0.892 +- 0.284 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 2 = 0.819 +- 0.284 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all KL = 0.76 +- 0.284 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all L1 = 0.85 +- 0.147 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9551900000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.934
SUFF++ for r=0.9 class 0 = 0.977 +- 0.047 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 class 1 = 0.954 +- 0.047 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 class 2 = 0.955 +- 0.047 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all KL = 0.978 +- 0.047 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.048 (in-sample avg dev_std = 0.081)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.351
Model XAI F1 of binarized graphs for r=0.3 =  0.33474999999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.21617874999999998
len(reference) = 709
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.345
SUFF++ for r=0.3 class 0 = 0.832 +- 0.115 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 1 = 0.833 +- 0.115 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 2 = 0.829 +- 0.115 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all KL = 0.881 +- 0.115 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all L1 = 0.831 +- 0.089 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.317
Model XAI F1 of binarized graphs for r=0.6 =  0.46082
Model XAI WIoU of binarized graphs for r=0.6 =  0.31264875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.343
SUFF++ for r=0.6 class 0 = 0.677 +- 0.147 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 1 = 0.674 +- 0.147 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 2 = 0.666 +- 0.147 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all KL = 0.8 +- 0.147 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all L1 = 0.672 +- 0.121 (in-sample avg dev_std = 0.379)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.551
Model XAI F1 of binarized graphs for r=0.9 =  0.542085
Model XAI WIoU of binarized graphs for r=0.9 =  0.37918625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.547
SUFF++ for r=0.9 class 0 = 0.849 +- 0.145 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 1 = 0.919 +- 0.145 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.145 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all KL = 0.904 +- 0.145 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.134 (in-sample avg dev_std = 0.299)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.494
Model XAI F1 of binarized graphs for r=0.3 =  0.55350625
Model XAI WIoU of binarized graphs for r=0.3 =  0.4768025
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.403 +- 0.350 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1 = 0.395 +- 0.350 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 2 = 0.438 +- 0.350 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.386 +- 0.350 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.412 +- 0.230 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  0.51899625
Model XAI WIoU of binarized graphs for r=0.6 =  0.5348625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.455
NEC for r=0.6 class 0 = 0.465 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.6 class 1 = 0.467 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.6 class 2 = 0.54 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.6 all KL = 0.463 +- 0.262 (in-sample avg dev_std = 0.507)
NEC for r=0.6 all L1 = 0.492 +- 0.155 (in-sample avg dev_std = 0.507)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.785
Model XAI F1 of binarized graphs for r=0.9 =  0.46104750000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.5464825000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.485 +- 0.271 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 1 = 0.492 +- 0.271 (in-sample avg dev_std = 0.556)
NEC for r=0.9 class 2 = 0.561 +- 0.271 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all KL = 0.523 +- 0.271 (in-sample avg dev_std = 0.556)
NEC for r=0.9 all L1 = 0.514 +- 0.159 (in-sample avg dev_std = 0.556)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.5484637499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.554
NEC for r=1.0 class 0 = 0.485 +- 0.281 (in-sample avg dev_std = 0.600)
NEC for r=1.0 class 1 = 0.493 +- 0.281 (in-sample avg dev_std = 0.600)
NEC for r=1.0 class 2 = 0.575 +- 0.281 (in-sample avg dev_std = 0.600)
NEC for r=1.0 all KL = 0.561 +- 0.281 (in-sample avg dev_std = 0.600)
NEC for r=1.0 all L1 = 0.519 +- 0.160 (in-sample avg dev_std = 0.600)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.445
Model XAI F1 of binarized graphs for r=0.3 =  0.8684999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7829925
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.383
NEC for r=0.3 class 0 = 0.481 +- 0.336 (in-sample avg dev_std = 0.528)
NEC for r=0.3 class 1 = 0.526 +- 0.336 (in-sample avg dev_std = 0.528)
NEC for r=0.3 class 2 = 0.469 +- 0.336 (in-sample avg dev_std = 0.528)
NEC for r=0.3 all KL = 0.523 +- 0.336 (in-sample avg dev_std = 0.528)
NEC for r=0.3 all L1 = 0.492 +- 0.218 (in-sample avg dev_std = 0.528)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.935
Model XAI F1 of binarized graphs for r=0.6 =  0.7975175
Model XAI WIoU of binarized graphs for r=0.6 =  0.9877250000000001
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0 = 0.411 +- 0.272 (in-sample avg dev_std = 0.712)
NEC for r=0.6 class 1 = 0.448 +- 0.272 (in-sample avg dev_std = 0.712)
NEC for r=0.6 class 2 = 0.533 +- 0.272 (in-sample avg dev_std = 0.712)
NEC for r=0.6 all KL = 0.648 +- 0.272 (in-sample avg dev_std = 0.712)
NEC for r=0.6 all L1 = 0.464 +- 0.169 (in-sample avg dev_std = 0.712)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.61811125
Model XAI WIoU of binarized graphs for r=0.9 =  0.9551900000000001
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.703
NEC for r=0.9 class 0 = 0.308 +- 0.256 (in-sample avg dev_std = 0.654)
NEC for r=0.9 class 1 = 0.358 +- 0.256 (in-sample avg dev_std = 0.654)
NEC for r=0.9 class 2 = 0.456 +- 0.256 (in-sample avg dev_std = 0.654)
NEC for r=0.9 all KL = 0.463 +- 0.256 (in-sample avg dev_std = 0.654)
NEC for r=0.9 all L1 = 0.374 +- 0.167 (in-sample avg dev_std = 0.654)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9483112499999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.717
NEC for r=1.0 class 0 = 0.307 +- 0.253 (in-sample avg dev_std = 0.658)
NEC for r=1.0 class 1 = 0.356 +- 0.253 (in-sample avg dev_std = 0.658)
NEC for r=1.0 class 2 = 0.436 +- 0.253 (in-sample avg dev_std = 0.658)
NEC for r=1.0 all KL = 0.452 +- 0.253 (in-sample avg dev_std = 0.658)
NEC for r=1.0 all L1 = 0.366 +- 0.162 (in-sample avg dev_std = 0.658)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.352
Model XAI F1 of binarized graphs for r=0.3 =  0.33474999999999994
Model XAI WIoU of binarized graphs for r=0.3 =  0.21617874999999998
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.349
NEC for r=0.3 class 0 = 0.089 +- 0.068 (in-sample avg dev_std = 0.106)
NEC for r=0.3 class 1 = 0.087 +- 0.068 (in-sample avg dev_std = 0.106)
NEC for r=0.3 class 2 = 0.088 +- 0.068 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all KL = 0.026 +- 0.068 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all L1 = 0.088 +- 0.083 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.317
Model XAI F1 of binarized graphs for r=0.6 =  0.46082
Model XAI WIoU of binarized graphs for r=0.6 =  0.31264875
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.318
NEC for r=0.6 class 0 = 0.211 +- 0.127 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 1 = 0.187 +- 0.127 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 2 = 0.206 +- 0.127 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all KL = 0.099 +- 0.127 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all L1 = 0.202 +- 0.131 (in-sample avg dev_std = 0.270)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.551
Model XAI F1 of binarized graphs for r=0.9 =  0.542085
Model XAI WIoU of binarized graphs for r=0.9 =  0.37918625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.487
NEC for r=0.9 class 0 = 0.386 +- 0.246 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 1 = 0.233 +- 0.246 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 2 = 0.404 +- 0.246 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all KL = 0.329 +- 0.246 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all L1 = 0.343 +- 0.194 (in-sample avg dev_std = 0.475)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.511
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39134125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.524
NEC for r=1.0 class 0 = 0.39 +- 0.250 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 1 = 0.108 +- 0.250 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 2 = 0.485 +- 0.250 (in-sample avg dev_std = 0.450)
NEC for r=1.0 all KL = 0.32 +- 0.250 (in-sample avg dev_std = 0.450)
NEC for r=1.0 all L1 = 0.332 +- 0.229 (in-sample avg dev_std = 0.450)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:06:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:42 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:43 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:06:45 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 0.9053
Train Loss: 0.4094
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.4157
ID Test ACCURACY: 0.9050
ID Test Loss: 0.4015
OOD Validation ACCURACY: 0.7847
OOD Validation Loss: 0.6164
OOD Test ACCURACY: 0.5540
OOD Test Loss: 1.3180

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.8841
Train Loss: 0.4563
ID Validation ACCURACY: 0.8853
ID Validation Loss: 0.4721
ID Test ACCURACY: 0.8843
ID Test Loss: 0.4499
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3433
OOD Test ACCURACY: 0.5810
OOD Test Loss: 1.4825

[0m[1;37mINFO[0m: [1mChartInfo 0.9050 0.5540 0.8843 0.5810 0.8853 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.511
WIoU for r=0.3 = 0.454
F1 for r=0.6 = 0.505
WIoU for r=0.6 = 0.526
F1 for r=0.9 = 0.462
WIoU for r=0.9 = 0.538
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.536
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.844
WIoU for r=0.3 = 0.758
F1 for r=0.6 = 0.785
WIoU for r=0.6 = 0.782
F1 for r=0.9 = 0.616
WIoU for r=0.9 = 0.611
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.578
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.242
WIoU for r=0.3 = 0.166
F1 for r=0.6 = 0.345
WIoU for r=0.6 = 0.239
F1 for r=0.9 = 0.508
WIoU for r=0.9 = 0.311
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.325


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.486
Model XAI F1 of binarized graphs for r=0.3 =  0.51115125
Model XAI WIoU of binarized graphs for r=0.3 =  0.45424125000000004
len(reference) = 769
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.36
SUFF++ for r=0.3 class 0 = 0.779 +- 0.352 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.3 class 1 = 0.72 +- 0.352 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.3 class 2 = 0.698 +- 0.352 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.3 all KL = 0.736 +- 0.352 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.3 all L1 = 0.732 +- 0.268 (in-sample avg dev_std = 0.404)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.709
Model XAI F1 of binarized graphs for r=0.6 =  0.50456375
Model XAI WIoU of binarized graphs for r=0.6 =  0.5261087500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.521
SUFF++ for r=0.6 class 0 = 0.59 +- 0.279 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 class 1 = 0.561 +- 0.279 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 class 2 = 0.562 +- 0.279 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 all KL = 0.584 +- 0.279 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 all L1 = 0.571 +- 0.194 (in-sample avg dev_std = 0.522)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  0.46181000000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.53770125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0 = 0.759 +- 0.164 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 1 = 0.832 +- 0.164 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 2 = 0.839 +- 0.164 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all KL = 0.877 +- 0.164 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.168 (in-sample avg dev_std = 0.286)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.4
Model XAI F1 of binarized graphs for r=0.3 =  0.8443074999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.75812625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.348
SUFF++ for r=0.3 class 0 = 0.71 +- 0.346 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 1 = 0.727 +- 0.346 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 2 = 0.685 +- 0.346 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all KL = 0.679 +- 0.346 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all L1 = 0.707 +- 0.238 (in-sample avg dev_std = 0.463)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.7852937499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7823499999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.824
SUFF++ for r=0.6 class 0 = 0.876 +- 0.273 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.661 +- 0.273 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.851 +- 0.273 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.743 +- 0.273 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.797 +- 0.183 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  0.6159
Model XAI WIoU of binarized graphs for r=0.9 =  0.611375
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0 = 0.945 +- 0.156 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 1 = 0.808 +- 0.156 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 2 = 0.869 +- 0.156 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all KL = 0.919 +- 0.156 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all L1 = 0.874 +- 0.164 (in-sample avg dev_std = 0.203)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.346
Model XAI F1 of binarized graphs for r=0.3 =  0.24198124999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.16555375000000003
len(reference) = 739
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.344
SUFF++ for r=0.3 class 0 = 0.952 +- 0.064 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.3 class 1 = 0.967 +- 0.064 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.3 class 2 = 0.954 +- 0.064 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.3 all KL = 0.982 +- 0.064 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.3 all L1 = 0.957 +- 0.045 (in-sample avg dev_std = 0.096)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.298
Model XAI F1 of binarized graphs for r=0.6 =  0.34527125
Model XAI WIoU of binarized graphs for r=0.6 =  0.2389425
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.335
SUFF++ for r=0.6 class 0 = 0.737 +- 0.185 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 1 = 0.864 +- 0.185 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 2 = 0.8 +- 0.185 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all KL = 0.857 +- 0.185 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all L1 = 0.799 +- 0.176 (in-sample avg dev_std = 0.291)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.562
Model XAI F1 of binarized graphs for r=0.9 =  0.5081700000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.31074749999999995
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.569
SUFF++ for r=0.9 class 0 = 0.773 +- 0.216 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.9 class 1 = 0.814 +- 0.216 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.9 class 2 = 0.769 +- 0.216 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.9 all KL = 0.826 +- 0.216 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.9 all L1 = 0.785 +- 0.170 (in-sample avg dev_std = 0.372)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.475
Model XAI F1 of binarized graphs for r=0.3 =  0.51115125
Model XAI WIoU of binarized graphs for r=0.3 =  0.45424125000000004
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.323
NEC for r=0.3 class 0 = 0.208 +- 0.360 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 1 = 0.272 +- 0.360 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 2 = 0.323 +- 0.360 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all KL = 0.252 +- 0.360 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all L1 = 0.269 +- 0.288 (in-sample avg dev_std = 0.303)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.709
Model XAI F1 of binarized graphs for r=0.6 =  0.50456375
Model XAI WIoU of binarized graphs for r=0.6 =  0.5261087500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.43
NEC for r=0.6 class 0 = 0.411 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 1 = 0.488 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 2 = 0.563 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all KL = 0.482 +- 0.308 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all L1 = 0.489 +- 0.217 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  0.46181000000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.53770125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.516
NEC for r=0.9 class 0 = 0.445 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 1 = 0.524 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 2 = 0.58 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all KL = 0.514 +- 0.284 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all L1 = 0.518 +- 0.169 (in-sample avg dev_std = 0.537)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.5358625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.428 +- 0.283 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 1 = 0.528 +- 0.283 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 2 = 0.572 +- 0.283 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all KL = 0.519 +- 0.283 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all L1 = 0.511 +- 0.173 (in-sample avg dev_std = 0.569)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.4
Model XAI F1 of binarized graphs for r=0.3 =  0.8443074999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.75812625
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.364 +- 0.377 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 1 = 0.352 +- 0.377 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 2 = 0.413 +- 0.377 (in-sample avg dev_std = 0.452)
NEC for r=0.3 all KL = 0.394 +- 0.377 (in-sample avg dev_std = 0.452)
NEC for r=0.3 all L1 = 0.376 +- 0.285 (in-sample avg dev_std = 0.452)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.7852937499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7823499999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.6
NEC for r=0.6 class 0 = 0.256 +- 0.333 (in-sample avg dev_std = 0.710)
NEC for r=0.6 class 1 = 0.475 +- 0.333 (in-sample avg dev_std = 0.710)
NEC for r=0.6 class 2 = 0.565 +- 0.333 (in-sample avg dev_std = 0.710)
NEC for r=0.6 all KL = 0.569 +- 0.333 (in-sample avg dev_std = 0.710)
NEC for r=0.6 all L1 = 0.431 +- 0.228 (in-sample avg dev_std = 0.710)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  0.6159
Model XAI WIoU of binarized graphs for r=0.9 =  0.611375
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.648
NEC for r=0.9 class 0 = 0.185 +- 0.264 (in-sample avg dev_std = 0.568)
NEC for r=0.9 class 1 = 0.392 +- 0.264 (in-sample avg dev_std = 0.568)
NEC for r=0.9 class 2 = 0.417 +- 0.264 (in-sample avg dev_std = 0.568)
NEC for r=0.9 all KL = 0.35 +- 0.264 (in-sample avg dev_std = 0.568)
NEC for r=0.9 all L1 = 0.331 +- 0.197 (in-sample avg dev_std = 0.568)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.789
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.5782400000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0 = 0.164 +- 0.261 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 1 = 0.415 +- 0.261 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 2 = 0.388 +- 0.261 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all KL = 0.328 +- 0.261 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all L1 = 0.322 +- 0.205 (in-sample avg dev_std = 0.531)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.339
Model XAI F1 of binarized graphs for r=0.3 =  0.24198124999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.16555375000000003
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.338
NEC for r=0.3 class 0 = 0.031 +- 0.044 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 1 = 0.021 +- 0.044 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 2 = 0.031 +- 0.044 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all KL = 0.008 +- 0.044 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all L1 = 0.028 +- 0.033 (in-sample avg dev_std = 0.057)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.298
Model XAI F1 of binarized graphs for r=0.6 =  0.34527125
Model XAI WIoU of binarized graphs for r=0.6 =  0.2389425
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.322
NEC for r=0.6 class 0 = 0.242 +- 0.185 (in-sample avg dev_std = 0.236)
NEC for r=0.6 class 1 = 0.076 +- 0.185 (in-sample avg dev_std = 0.236)
NEC for r=0.6 class 2 = 0.146 +- 0.185 (in-sample avg dev_std = 0.236)
NEC for r=0.6 all KL = 0.099 +- 0.185 (in-sample avg dev_std = 0.236)
NEC for r=0.6 all L1 = 0.156 +- 0.187 (in-sample avg dev_std = 0.236)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.562
Model XAI F1 of binarized graphs for r=0.9 =  0.5081700000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.31074749999999995
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.499
NEC for r=0.9 class 0 = 0.462 +- 0.243 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 1 = 0.386 +- 0.243 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 2 = 0.496 +- 0.243 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all KL = 0.436 +- 0.243 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all L1 = 0.449 +- 0.158 (in-sample avg dev_std = 0.557)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.562
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.325105
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.564
NEC for r=1.0 class 0 = 0.426 +- 0.223 (in-sample avg dev_std = 0.504)
NEC for r=1.0 class 1 = 0.246 +- 0.223 (in-sample avg dev_std = 0.504)
NEC for r=1.0 class 2 = 0.503 +- 0.223 (in-sample avg dev_std = 0.504)
NEC for r=1.0 all KL = 0.381 +- 0.223 (in-sample avg dev_std = 0.504)
NEC for r=1.0 all L1 = 0.394 +- 0.181 (in-sample avg dev_std = 0.504)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:09:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:09:48 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:10:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.8957
Train Loss: 0.4266
ID Validation ACCURACY: 0.8947
ID Validation Loss: 0.4346
ID Test ACCURACY: 0.9027
ID Test Loss: 0.4111
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3303
OOD Test ACCURACY: 0.4547
OOD Test Loss: 1.8491

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ACCURACY: 0.8101
Train Loss: 0.5547
ID Validation ACCURACY: 0.8103
ID Validation Loss: 0.5686
ID Test ACCURACY: 0.8203
ID Test Loss: 0.5302
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3421
OOD Test ACCURACY: 0.5927
OOD Test Loss: 1.2143

[0m[1;37mINFO[0m: [1mChartInfo 0.9027 0.4547 0.8203 0.5927 0.8103 0.9317[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.568
WIoU for r=0.3 = 0.507
F1 for r=0.6 = 0.504
WIoU for r=0.6 = 0.567
F1 for r=0.9 = 0.458
WIoU for r=0.9 = 0.598
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.604
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.769
WIoU for r=0.3 = 0.686
F1 for r=0.6 = 0.700
WIoU for r=0.6 = 0.833
F1 for r=0.9 = 0.601
WIoU for r=0.9 = 0.855
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.861
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.338
WIoU for r=0.3 = 0.216
F1 for r=0.6 = 0.472
WIoU for r=0.6 = 0.320
F1 for r=0.9 = 0.545
WIoU for r=0.9 = 0.383
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.393


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.564
Model XAI F1 of binarized graphs for r=0.3 =  0.5682875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5066025
len(reference) = 730
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.449
SUFF++ for r=0.3 class 0 = 0.584 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 1 = 0.593 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 2 = 0.545 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all KL = 0.626 +- 0.275 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all L1 = 0.574 +- 0.163 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  0.5035075
Model XAI WIoU of binarized graphs for r=0.6 =  0.56690625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.579
SUFF++ for r=0.6 class 0 = 0.667 +- 0.220 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 1 = 0.67 +- 0.220 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 2 = 0.637 +- 0.220 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all KL = 0.748 +- 0.220 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all L1 = 0.657 +- 0.165 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  0.45758249999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.5982474999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.778
SUFF++ for r=0.9 class 0 = 0.872 +- 0.153 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 1 = 0.862 +- 0.153 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.153 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all KL = 0.908 +- 0.153 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.141 (in-sample avg dev_std = 0.284)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.445
Model XAI F1 of binarized graphs for r=0.3 =  0.76901125
Model XAI WIoU of binarized graphs for r=0.3 =  0.6864175
len(reference) = 757
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.386
SUFF++ for r=0.3 class 0 = 0.579 +- 0.301 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 1 = 0.635 +- 0.301 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 2 = 0.587 +- 0.301 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all KL = 0.583 +- 0.301 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all L1 = 0.6 +- 0.192 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.7001762500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.83271875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.597
SUFF++ for r=0.6 class 0 = 0.677 +- 0.291 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 1 = 0.679 +- 0.291 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 2 = 0.627 +- 0.291 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all KL = 0.623 +- 0.291 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all L1 = 0.661 +- 0.180 (in-sample avg dev_std = 0.568)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.60139875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8547637499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0 = 0.907 +- 0.108 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 1 = 0.904 +- 0.108 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 2 = 0.916 +- 0.108 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all KL = 0.948 +- 0.108 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all L1 = 0.909 +- 0.108 (in-sample avg dev_std = 0.210)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.333
Model XAI F1 of binarized graphs for r=0.3 =  0.33819375
Model XAI WIoU of binarized graphs for r=0.3 =  0.21610374999999998
len(reference) = 693
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.33
SUFF++ for r=0.3 class 0 = 0.758 +- 0.080 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 class 1 = 0.752 +- 0.080 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 class 2 = 0.747 +- 0.080 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 all KL = 0.891 +- 0.080 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.3 all L1 = 0.753 +- 0.100 (in-sample avg dev_std = 0.318)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.312
Model XAI F1 of binarized graphs for r=0.6 =  0.47233
Model XAI WIoU of binarized graphs for r=0.6 =  0.3199925
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.326
SUFF++ for r=0.6 class 0 = 0.713 +- 0.129 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 class 1 = 0.726 +- 0.129 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 class 2 = 0.719 +- 0.129 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all KL = 0.864 +- 0.129 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all L1 = 0.719 +- 0.130 (in-sample avg dev_std = 0.279)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.517
Model XAI F1 of binarized graphs for r=0.9 =  0.54528125
Model XAI WIoU of binarized graphs for r=0.9 =  0.38280625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.503
SUFF++ for r=0.9 class 0 = 0.844 +- 0.151 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 1 = 0.952 +- 0.151 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 2 = 0.841 +- 0.151 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 all KL = 0.906 +- 0.151 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.133 (in-sample avg dev_std = 0.294)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  0.5682875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5066025
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.37
NEC for r=0.3 class 0 = 0.439 +- 0.324 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 1 = 0.416 +- 0.324 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 2 = 0.481 +- 0.324 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all KL = 0.392 +- 0.324 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all L1 = 0.446 +- 0.208 (in-sample avg dev_std = 0.403)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  0.5035075
Model XAI WIoU of binarized graphs for r=0.6 =  0.56690625
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.398 +- 0.253 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 1 = 0.406 +- 0.253 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 2 = 0.446 +- 0.253 (in-sample avg dev_std = 0.426)
NEC for r=0.6 all KL = 0.333 +- 0.253 (in-sample avg dev_std = 0.426)
NEC for r=0.6 all L1 = 0.417 +- 0.162 (in-sample avg dev_std = 0.426)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  0.45758249999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.5982474999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.545
NEC for r=0.9 class 0 = 0.421 +- 0.272 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 1 = 0.449 +- 0.272 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 2 = 0.493 +- 0.272 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all KL = 0.418 +- 0.272 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all L1 = 0.455 +- 0.165 (in-sample avg dev_std = 0.504)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.6037575
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.578
NEC for r=1.0 class 0 = 0.434 +- 0.292 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 1 = 0.461 +- 0.292 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 2 = 0.533 +- 0.292 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all KL = 0.481 +- 0.292 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all L1 = 0.477 +- 0.173 (in-sample avg dev_std = 0.562)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.76901125
Model XAI WIoU of binarized graphs for r=0.3 =  0.6864175
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.407 +- 0.355 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 1 = 0.425 +- 0.355 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 2 = 0.431 +- 0.355 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all KL = 0.435 +- 0.355 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all L1 = 0.421 +- 0.228 (in-sample avg dev_std = 0.493)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.7001762500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.83271875
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.539
NEC for r=0.6 class 0 = 0.331 +- 0.296 (in-sample avg dev_std = 0.558)
NEC for r=0.6 class 1 = 0.346 +- 0.296 (in-sample avg dev_std = 0.558)
NEC for r=0.6 class 2 = 0.425 +- 0.296 (in-sample avg dev_std = 0.558)
NEC for r=0.6 all KL = 0.403 +- 0.296 (in-sample avg dev_std = 0.558)
NEC for r=0.6 all L1 = 0.367 +- 0.193 (in-sample avg dev_std = 0.558)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.60139875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8547637499999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.652
NEC for r=0.9 class 0 = 0.32 +- 0.230 (in-sample avg dev_std = 0.527)
NEC for r=0.9 class 1 = 0.333 +- 0.230 (in-sample avg dev_std = 0.527)
NEC for r=0.9 class 2 = 0.383 +- 0.230 (in-sample avg dev_std = 0.527)
NEC for r=0.9 all KL = 0.328 +- 0.230 (in-sample avg dev_std = 0.527)
NEC for r=0.9 all L1 = 0.345 +- 0.161 (in-sample avg dev_std = 0.527)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.86105875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.706
NEC for r=1.0 class 0 = 0.337 +- 0.215 (in-sample avg dev_std = 0.595)
NEC for r=1.0 class 1 = 0.345 +- 0.215 (in-sample avg dev_std = 0.595)
NEC for r=1.0 class 2 = 0.377 +- 0.215 (in-sample avg dev_std = 0.595)
NEC for r=1.0 all KL = 0.371 +- 0.215 (in-sample avg dev_std = 0.595)
NEC for r=1.0 all L1 = 0.353 +- 0.146 (in-sample avg dev_std = 0.595)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.335
Model XAI F1 of binarized graphs for r=0.3 =  0.33819375
Model XAI WIoU of binarized graphs for r=0.3 =  0.21610374999999998
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.337
NEC for r=0.3 class 0 = 0.141 +- 0.062 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 1 = 0.145 +- 0.062 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 2 = 0.128 +- 0.062 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all KL = 0.043 +- 0.062 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all L1 = 0.138 +- 0.112 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.312
Model XAI F1 of binarized graphs for r=0.6 =  0.47233
Model XAI WIoU of binarized graphs for r=0.6 =  0.3199925
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.322
NEC for r=0.6 class 0 = 0.185 +- 0.103 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 1 = 0.181 +- 0.103 (in-sample avg dev_std = 0.228)
NEC for r=0.6 class 2 = 0.188 +- 0.103 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all KL = 0.074 +- 0.103 (in-sample avg dev_std = 0.228)
NEC for r=0.6 all L1 = 0.185 +- 0.115 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.517
Model XAI F1 of binarized graphs for r=0.9 =  0.54528125
Model XAI WIoU of binarized graphs for r=0.9 =  0.38280625
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.471
NEC for r=0.9 class 0 = 0.349 +- 0.213 (in-sample avg dev_std = 0.414)
NEC for r=0.9 class 1 = 0.214 +- 0.213 (in-sample avg dev_std = 0.414)
NEC for r=0.9 class 2 = 0.337 +- 0.213 (in-sample avg dev_std = 0.414)
NEC for r=0.9 all KL = 0.268 +- 0.213 (in-sample avg dev_std = 0.414)
NEC for r=0.9 all L1 = 0.301 +- 0.186 (in-sample avg dev_std = 0.414)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.463
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.39304625000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.465
NEC for r=1.0 class 0 = 0.373 +- 0.249 (in-sample avg dev_std = 0.420)
NEC for r=1.0 class 1 = 0.092 +- 0.249 (in-sample avg dev_std = 0.420)
NEC for r=1.0 class 2 = 0.397 +- 0.249 (in-sample avg dev_std = 0.420)
NEC for r=1.0 all KL = 0.285 +- 0.249 (in-sample avg dev_std = 0.420)
NEC for r=1.0 all L1 = 0.291 +- 0.225 (in-sample avg dev_std = 0.420)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.6, 0.654, 0.886, 1.0], 'all_L1': [0.574, 0.604, 0.85, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.567, 0.685, 0.886, 1.0], 'all_L1': [0.553, 0.624, 0.836, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.606, 0.635, 0.859, 1.0], 'all_L1': [0.603, 0.598, 0.814, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.736, 0.584, 0.877, 1.0], 'all_L1': [0.732, 0.571, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.626, 0.748, 0.908, 1.0], 'all_L1': [0.574, 0.657, 0.863, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.396, 0.411, 0.483, 0.547], 'all_L1': [0.439, 0.454, 0.47, 0.486]}), defaultdict(<class 'list'>, {'all_KL': [0.405, 0.381, 0.465, 0.52], 'all_L1': [0.432, 0.433, 0.479, 0.49]}), defaultdict(<class 'list'>, {'all_KL': [0.386, 0.463, 0.523, 0.561], 'all_L1': [0.412, 0.492, 0.514, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.252, 0.482, 0.514, 0.519], 'all_L1': [0.269, 0.489, 0.518, 0.511]}), defaultdict(<class 'list'>, {'all_KL': [0.392, 0.333, 0.418, 0.481], 'all_L1': [0.446, 0.417, 0.455, 0.477]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.535, 0.71, 0.977, 1.0], 'all_L1': [0.659, 0.784, 0.953, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.574, 0.668, 0.881, 1.0], 'all_L1': [0.578, 0.633, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.59, 0.76, 0.978, 1.0], 'all_L1': [0.617, 0.85, 0.962, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.679, 0.743, 0.919, 1.0], 'all_L1': [0.707, 0.797, 0.874, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.583, 0.623, 0.948, 1.0], 'all_L1': [0.6, 0.661, 0.909, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.635, 0.555, 0.391, 0.377], 'all_L1': [0.489, 0.43, 0.345, 0.34]}), defaultdict(<class 'list'>, {'all_KL': [0.326, 0.239, 0.316, 0.392], 'all_L1': [0.332, 0.277, 0.362, 0.38]}), defaultdict(<class 'list'>, {'all_KL': [0.523, 0.648, 0.463, 0.452], 'all_L1': [0.492, 0.464, 0.374, 0.366]}), defaultdict(<class 'list'>, {'all_KL': [0.394, 0.569, 0.35, 0.328], 'all_L1': [0.376, 0.431, 0.331, 0.322]}), defaultdict(<class 'list'>, {'all_KL': [0.435, 0.403, 0.328, 0.371], 'all_L1': [0.421, 0.367, 0.345, 0.353]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.849, 0.83, 0.911, 1.0], 'all_L1': [0.724, 0.685, 0.892, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.872, 0.861, 0.883, 1.0], 'all_L1': [0.746, 0.711, 0.849, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.881, 0.8, 0.904, 1.0], 'all_L1': [0.831, 0.672, 0.872, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.982, 0.857, 0.826, 1.0], 'all_L1': [0.957, 0.799, 0.785, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.891, 0.864, 0.906, 1.0], 'all_L1': [0.753, 0.719, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.054, 0.096, 0.287, 0.32], 'all_L1': [0.149, 0.212, 0.28, 0.285]}), defaultdict(<class 'list'>, {'all_KL': [0.04, 0.082, 0.343, 0.37], 'all_L1': [0.126, 0.184, 0.374, 0.363]}), defaultdict(<class 'list'>, {'all_KL': [0.026, 0.099, 0.329, 0.32], 'all_L1': [0.088, 0.202, 0.343, 0.332]}), defaultdict(<class 'list'>, {'all_KL': [0.008, 0.099, 0.436, 0.381], 'all_L1': [0.028, 0.156, 0.449, 0.394]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.074, 0.268, 0.285], 'all_L1': [0.138, 0.185, 0.301, 0.291]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.607 +- 0.064, 0.611 +- 0.029, 0.835 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.627 +- 0.058, 0.661 +- 0.054, 0.883 +- 0.016, 1.000 +- 0.000
suff++_acc_int  =  0.420 +- 0.033, 0.542 +- 0.024, 0.773 +- 0.022
nec class all_L1  =  0.400 +- 0.066, 0.457 +- 0.030, 0.487 +- 0.025, 0.497 +- 0.016
nec class all_KL  =  0.366 +- 0.057, 0.414 +- 0.054, 0.481 +- 0.038, 0.526 +- 0.027
nec_acc_int  =  0.360 +- 0.025, 0.456 +- 0.015, 0.530 +- 0.010, 0.564 +- 0.019

Eval split val
suff++ class all_L1  =  0.632 +- 0.046, 0.745 +- 0.083, 0.905 +- 0.051, 1.000 +- 0.000
suff++ class all_KL  =  0.592 +- 0.047, 0.701 +- 0.050, 0.941 +- 0.037, 1.000 +- 0.000
suff++_acc_int  =  0.396 +- 0.052, 0.711 +- 0.157, 0.842 +- 0.080
nec class all_L1  =  0.422 +- 0.063, 0.394 +- 0.066, 0.351 +- 0.015, 0.352 +- 0.020
nec class all_KL  =  0.463 +- 0.107, 0.483 +- 0.145, 0.370 +- 0.053, 0.384 +- 0.040
nec_acc_int  =  0.339 +- 0.027, 0.566 +- 0.068, 0.647 +- 0.062, 0.682 +- 0.038

Eval split test
suff++ class all_L1  =  0.802 +- 0.085, 0.717 +- 0.044, 0.855 +- 0.038, 1.000 +- 0.000
suff++ class all_KL  =  0.895 +- 0.046, 0.842 +- 0.024, 0.886 +- 0.031, 1.000 +- 0.000
suff++_acc_int  =  0.335 +- 0.011, 0.330 +- 0.010, 0.534 +- 0.025
nec class all_L1  =  0.106 +- 0.044, 0.188 +- 0.019, 0.349 +- 0.060, 0.333 +- 0.042
nec class all_KL  =  0.034 +- 0.016, 0.090 +- 0.010, 0.333 +- 0.058, 0.335 +- 0.035
nec_acc_int  =  0.340 +- 0.005, 0.319 +- 0.004, 0.478 +- 0.014, 0.515 +- 0.035


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.503 +- 0.006, 0.534 +- 0.006, 0.661 +- 0.003, 0.748 +- 0.008
Faith. Armon (L1)= 		  =  0.473 +- 0.040, 0.521 +- 0.011, 0.615 +- 0.014, 0.663 +- 0.014
Faith. GMean (L1)= 	  =  0.488 +- 0.023, 0.528 +- 0.008, 0.637 +- 0.009, 0.705 +- 0.011
Faith. Aritm (KL)= 		  =  0.497 +- 0.007, 0.538 +- 0.006, 0.682 +- 0.012, 0.763 +- 0.014
Faith. Armon (KL)= 		  =  0.456 +- 0.040, 0.504 +- 0.027, 0.621 +- 0.029, 0.689 +- 0.024
Faith. GMean (KL)= 	  =  0.475 +- 0.023, 0.520 +- 0.015, 0.651 +- 0.020, 0.725 +- 0.019

Eval split val
Faith. Aritm (L1)= 		  =  0.527 +- 0.042, 0.569 +- 0.074, 0.628 +- 0.028, 0.676 +- 0.010
Faith. Armon (L1)= 		  =  0.503 +- 0.049, 0.514 +- 0.077, 0.506 +- 0.019, 0.521 +- 0.022
Faith. GMean (L1)= 	  =  0.515 +- 0.045, 0.541 +- 0.075, 0.564 +- 0.022, 0.593 +- 0.017
Faith. Aritm (KL)= 		  =  0.527 +- 0.046, 0.592 +- 0.093, 0.655 +- 0.043, 0.692 +- 0.020
Faith. Armon (KL)= 		  =  0.510 +- 0.057, 0.562 +- 0.126, 0.529 +- 0.058, 0.554 +- 0.041
Faith. GMean (KL)= 	  =  0.518 +- 0.051, 0.576 +- 0.110, 0.589 +- 0.051, 0.619 +- 0.032

Eval split test
Faith. Aritm (L1)= 		  =  0.454 +- 0.021, 0.453 +- 0.013, 0.602 +- 0.012, 0.666 +- 0.021
Faith. Armon (L1)= 		  =  0.182 +- 0.070, 0.296 +- 0.021, 0.491 +- 0.051, 0.498 +- 0.047
Faith. GMean (L1)= 	  =  0.278 +- 0.061, 0.366 +- 0.009, 0.544 +- 0.034, 0.576 +- 0.036
Faith. Aritm (KL)= 		  =  0.465 +- 0.016, 0.466 +- 0.010, 0.609 +- 0.015, 0.668 +- 0.018
Faith. Armon (KL)= 		  =  0.065 +- 0.030, 0.162 +- 0.016, 0.479 +- 0.054, 0.501 +- 0.040
Faith. GMean (KL)= 	  =  0.167 +- 0.044, 0.275 +- 0.014, 0.540 +- 0.037, 0.578 +- 0.031
Computed for split load_split = id



Completed in  0:16:53.715049  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis hard

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:13:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:48 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:13:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9162
Train Loss: 0.3884
ID Validation ACCURACY: 0.9193
ID Validation Loss: 0.4023
ID Test ACCURACY: 0.9150
ID Test Loss: 0.3977
OOD Validation ACCURACY: 0.8940
OOD Validation Loss: 0.4100
OOD Test ACCURACY: 0.8167
OOD Test Loss: 0.5613

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ACCURACY: 0.9152
Train Loss: 0.4068
ID Validation ACCURACY: 0.9160
ID Validation Loss: 0.4280
ID Test ACCURACY: 0.9147
ID Test Loss: 0.4153
OOD Validation ACCURACY: 0.9130
OOD Validation Loss: 0.3856
OOD Test ACCURACY: 0.8570
OOD Test Loss: 0.5491

[0m[1;37mINFO[0m: [1mChartInfo 0.9150 0.8167 0.9147 0.8570 0.9160 0.9130[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.689
WIoU for r=0.3 = 0.582
F1 for r=0.6 = 0.618
WIoU for r=0.6 = 0.671
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.675
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.675
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.853
WIoU for r=0.3 = 0.875
F1 for r=0.6 = 0.783
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.615
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.508
WIoU for r=0.3 = 0.359
F1 for r=0.6 = 0.690
WIoU for r=0.6 = 0.555
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.551
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.551


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  0.6885149999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5821312500000001
len(reference) = 794
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.414
SUFF++ for r=0.3 class 0 = 0.41 +- 0.289 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 1 = 0.454 +- 0.289 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 2 = 0.616 +- 0.289 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all KL = 0.39 +- 0.289 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all L1 = 0.495 +- 0.216 (in-sample avg dev_std = 0.577)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.6183974999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6705150000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.659
SUFF++ for r=0.6 class 0 = 0.442 +- 0.303 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 1 = 0.589 +- 0.303 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 2 = 0.733 +- 0.303 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all KL = 0.53 +- 0.303 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all L1 = 0.592 +- 0.209 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.67523625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.888
SUFF++ for r=0.9 class 0 = 0.864 +- 0.139 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1 = 0.859 +- 0.139 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 2 = 0.888 +- 0.139 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.919 +- 0.139 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.871 +- 0.138 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.8526400000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8753637499999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.479
SUFF++ for r=0.3 class 0 = 0.547 +- 0.307 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.3 class 1 = 0.677 +- 0.307 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.3 class 2 = 0.629 +- 0.307 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.3 all KL = 0.421 +- 0.307 (in-sample avg dev_std = 0.631)
SUFF++ for r=0.3 all L1 = 0.617 +- 0.202 (in-sample avg dev_std = 0.631)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.78312125
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.882
SUFF++ for r=0.6 class 0 = 0.821 +- 0.233 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 1 = 0.841 +- 0.233 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 class 2 = 0.931 +- 0.233 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all KL = 0.857 +- 0.233 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.6 all L1 = 0.865 +- 0.166 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.6149225
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.888
SUFF++ for r=0.9 class 0 = 0.891 +- 0.188 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 1 = 0.942 +- 0.188 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 class 2 = 0.963 +- 0.188 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all KL = 0.946 +- 0.188 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.9 all L1 = 0.932 +- 0.141 (in-sample avg dev_std = 0.226)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.346
Model XAI F1 of binarized graphs for r=0.3 =  0.50832625
Model XAI WIoU of binarized graphs for r=0.3 =  0.35949000000000003
len(reference) = 783
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.351
SUFF++ for r=0.3 class 0 = 0.593 +- 0.237 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 1 = 0.594 +- 0.237 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 2 = 0.617 +- 0.237 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all KL = 0.496 +- 0.237 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all L1 = 0.601 +- 0.150 (in-sample avg dev_std = 0.576)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  0.69007125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5547249999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.7
SUFF++ for r=0.6 class 0 = 0.557 +- 0.298 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 1 = 0.651 +- 0.298 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 2 = 0.673 +- 0.298 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all KL = 0.58 +- 0.298 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all L1 = 0.627 +- 0.243 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  0.59362125
Model XAI WIoU of binarized graphs for r=0.9 =  0.5510649999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.779
SUFF++ for r=0.9 class 0 = 0.773 +- 0.190 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 1 = 0.962 +- 0.190 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 2 = 0.818 +- 0.190 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all KL = 0.885 +- 0.190 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all L1 = 0.849 +- 0.174 (in-sample avg dev_std = 0.319)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  0.6885149999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5821312500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.655 +- 0.246 (in-sample avg dev_std = 0.550)
NEC for r=0.3 class 1 = 0.592 +- 0.246 (in-sample avg dev_std = 0.550)
NEC for r=0.3 class 2 = 0.571 +- 0.246 (in-sample avg dev_std = 0.550)
NEC for r=0.3 all KL = 0.725 +- 0.246 (in-sample avg dev_std = 0.550)
NEC for r=0.3 all L1 = 0.605 +- 0.165 (in-sample avg dev_std = 0.550)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.6183974999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.6705150000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.434
NEC for r=0.6 class 0 = 0.638 +- 0.282 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 1 = 0.584 +- 0.282 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 2 = 0.579 +- 0.282 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all KL = 0.679 +- 0.282 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all L1 = 0.599 +- 0.159 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.67523625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.531
NEC for r=0.9 class 0 = 0.557 +- 0.301 (in-sample avg dev_std = 0.568)
NEC for r=0.9 class 1 = 0.497 +- 0.301 (in-sample avg dev_std = 0.568)
NEC for r=0.9 class 2 = 0.551 +- 0.301 (in-sample avg dev_std = 0.568)
NEC for r=0.9 all KL = 0.579 +- 0.301 (in-sample avg dev_std = 0.568)
NEC for r=0.9 all L1 = 0.535 +- 0.172 (in-sample avg dev_std = 0.568)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.919
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.67523625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.531
NEC for r=1.0 class 0 = 0.543 +- 0.304 (in-sample avg dev_std = 0.564)
NEC for r=1.0 class 1 = 0.511 +- 0.304 (in-sample avg dev_std = 0.564)
NEC for r=1.0 class 2 = 0.545 +- 0.304 (in-sample avg dev_std = 0.564)
NEC for r=1.0 all KL = 0.57 +- 0.304 (in-sample avg dev_std = 0.564)
NEC for r=1.0 all L1 = 0.533 +- 0.171 (in-sample avg dev_std = 0.564)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.8526400000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8753637499999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.227
NEC for r=0.3 class 0 = 0.67 +- 0.235 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 1 = 0.658 +- 0.235 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 2 = 0.626 +- 0.235 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all KL = 0.813 +- 0.235 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all L1 = 0.651 +- 0.180 (in-sample avg dev_std = 0.489)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.78312125
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.511
NEC for r=0.6 class 0 = 0.564 +- 0.286 (in-sample avg dev_std = 0.681)
NEC for r=0.6 class 1 = 0.447 +- 0.286 (in-sample avg dev_std = 0.681)
NEC for r=0.6 class 2 = 0.502 +- 0.286 (in-sample avg dev_std = 0.681)
NEC for r=0.6 all KL = 0.637 +- 0.286 (in-sample avg dev_std = 0.681)
NEC for r=0.6 all L1 = 0.504 +- 0.168 (in-sample avg dev_std = 0.681)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.6149225
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.468 +- 0.263 (in-sample avg dev_std = 0.621)
NEC for r=0.9 class 1 = 0.344 +- 0.263 (in-sample avg dev_std = 0.621)
NEC for r=0.9 class 2 = 0.391 +- 0.263 (in-sample avg dev_std = 0.621)
NEC for r=0.9 all KL = 0.454 +- 0.263 (in-sample avg dev_std = 0.621)
NEC for r=0.9 all L1 = 0.401 +- 0.159 (in-sample avg dev_std = 0.621)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.892
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.604
NEC for r=1.0 class 0 = 0.453 +- 0.265 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 1 = 0.341 +- 0.265 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 2 = 0.409 +- 0.265 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all KL = 0.45 +- 0.265 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all L1 = 0.402 +- 0.163 (in-sample avg dev_std = 0.619)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.349
Model XAI F1 of binarized graphs for r=0.3 =  0.50832625
Model XAI WIoU of binarized graphs for r=0.3 =  0.35949000000000003
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.368
NEC for r=0.3 class 0 = 0.407 +- 0.295 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 1 = 0.403 +- 0.295 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 2 = 0.305 +- 0.295 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all KL = 0.444 +- 0.295 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all L1 = 0.371 +- 0.218 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  0.69007125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5547249999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.536
NEC for r=0.6 class 0 = 0.678 +- 0.261 (in-sample avg dev_std = 0.553)
NEC for r=0.6 class 1 = 0.524 +- 0.261 (in-sample avg dev_std = 0.553)
NEC for r=0.6 class 2 = 0.557 +- 0.261 (in-sample avg dev_std = 0.553)
NEC for r=0.6 all KL = 0.716 +- 0.261 (in-sample avg dev_std = 0.553)
NEC for r=0.6 all L1 = 0.587 +- 0.187 (in-sample avg dev_std = 0.553)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  0.59362125
Model XAI WIoU of binarized graphs for r=0.9 =  0.5510649999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.614
NEC for r=0.9 class 0 = 0.549 +- 0.241 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 1 = 0.343 +- 0.241 (in-sample avg dev_std = 0.570)
NEC for r=0.9 class 2 = 0.526 +- 0.241 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all KL = 0.534 +- 0.241 (in-sample avg dev_std = 0.570)
NEC for r=0.9 all L1 = 0.475 +- 0.170 (in-sample avg dev_std = 0.570)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.831
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.55100375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0 = 0.547 +- 0.237 (in-sample avg dev_std = 0.586)
NEC for r=1.0 class 1 = 0.335 +- 0.237 (in-sample avg dev_std = 0.586)
NEC for r=1.0 class 2 = 0.487 +- 0.237 (in-sample avg dev_std = 0.586)
NEC for r=1.0 all KL = 0.513 +- 0.237 (in-sample avg dev_std = 0.586)
NEC for r=1.0 all L1 = 0.458 +- 0.163 (in-sample avg dev_std = 0.586)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:17:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:15 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:17 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:19 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:21 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:17:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9101
Train Loss: 0.4106
ID Validation ACCURACY: 0.9077
ID Validation Loss: 0.4319
ID Test ACCURACY: 0.9090
ID Test Loss: 0.4145
OOD Validation ACCURACY: 0.8880
OOD Validation Loss: 0.4412
OOD Test ACCURACY: 0.7063
OOD Test Loss: 0.8280

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ACCURACY: 0.8303
Train Loss: 0.5438
ID Validation ACCURACY: 0.8223
ID Validation Loss: 0.5785
ID Test ACCURACY: 0.8280
ID Test Loss: 0.5468
OOD Validation ACCURACY: 0.8977
OOD Validation Loss: 0.4674
OOD Test ACCURACY: 0.7963
OOD Test Loss: 0.5781

[0m[1;37mINFO[0m: [1mChartInfo 0.9090 0.7063 0.8280 0.7963 0.8223 0.8977[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.677
WIoU for r=0.3 = 0.628
F1 for r=0.6 = 0.615
WIoU for r=0.6 = 0.723
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.728
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.728
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.828
WIoU for r=0.3 = 0.854
F1 for r=0.6 = 0.761
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.607
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.508
WIoU for r=0.3 = 0.373
F1 for r=0.6 = 0.682
WIoU for r=0.6 = 0.556
F1 for r=0.9 = 0.593
WIoU for r=0.9 = 0.582
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.582


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.6773424999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.627835
len(reference) = 797
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.446
SUFF++ for r=0.3 class 0 = 0.483 +- 0.276 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 1 = 0.548 +- 0.276 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 2 = 0.519 +- 0.276 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all KL = 0.403 +- 0.276 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all L1 = 0.517 +- 0.181 (in-sample avg dev_std = 0.618)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.864
Model XAI F1 of binarized graphs for r=0.6 =  0.61547375
Model XAI WIoU of binarized graphs for r=0.6 =  0.7225812500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.496 +- 0.267 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 1 = 0.669 +- 0.267 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 2 = 0.631 +- 0.267 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all KL = 0.538 +- 0.267 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all L1 = 0.601 +- 0.199 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7284674999999998
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.848
SUFF++ for r=0.9 class 0 = 0.817 +- 0.212 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 1 = 0.821 +- 0.212 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 2 = 0.856 +- 0.212 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all KL = 0.855 +- 0.212 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all L1 = 0.832 +- 0.172 (in-sample avg dev_std = 0.295)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.8277087500000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8539074999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.527
SUFF++ for r=0.3 class 0 = 0.583 +- 0.357 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 class 1 = 0.811 +- 0.357 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 class 2 = 0.644 +- 0.357 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 all KL = 0.51 +- 0.357 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 all L1 = 0.678 +- 0.233 (in-sample avg dev_std = 0.592)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.7606149999999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.869
SUFF++ for r=0.6 class 0 = 0.823 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 class 1 = 0.799 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 class 2 = 0.878 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all KL = 0.81 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all L1 = 0.833 +- 0.149 (in-sample avg dev_std = 0.380)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.6073825
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.898
SUFF++ for r=0.9 class 0 = 0.952 +- 0.087 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 class 1 = 0.901 +- 0.087 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 class 2 = 0.964 +- 0.087 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 all KL = 0.967 +- 0.087 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.093 (in-sample avg dev_std = 0.157)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.324
Model XAI F1 of binarized graphs for r=0.3 =  0.508055
Model XAI WIoU of binarized graphs for r=0.3 =  0.37309
len(reference) = 783
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.34
SUFF++ for r=0.3 class 0 = 0.487 +- 0.264 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 1 = 0.474 +- 0.264 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 2 = 0.477 +- 0.264 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all KL = 0.458 +- 0.264 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all L1 = 0.479 +- 0.174 (in-sample avg dev_std = 0.594)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.579
Model XAI F1 of binarized graphs for r=0.6 =  0.681995
Model XAI WIoU of binarized graphs for r=0.6 =  0.55573375
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0 = 0.569 +- 0.332 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 1 = 0.817 +- 0.332 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 2 = 0.576 +- 0.332 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all KL = 0.516 +- 0.332 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all L1 = 0.651 +- 0.239 (in-sample avg dev_std = 0.567)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  0.59348
Model XAI WIoU of binarized graphs for r=0.9 =  0.5815662500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.669
SUFF++ for r=0.9 class 0 = 0.725 +- 0.212 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 1 = 0.951 +- 0.212 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 2 = 0.733 +- 0.212 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all KL = 0.828 +- 0.212 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all L1 = 0.801 +- 0.186 (in-sample avg dev_std = 0.340)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.6773424999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.627835
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.353
NEC for r=0.3 class 0 = 0.555 +- 0.273 (in-sample avg dev_std = 0.530)
NEC for r=0.3 class 1 = 0.55 +- 0.273 (in-sample avg dev_std = 0.530)
NEC for r=0.3 class 2 = 0.598 +- 0.273 (in-sample avg dev_std = 0.530)
NEC for r=0.3 all KL = 0.654 +- 0.273 (in-sample avg dev_std = 0.530)
NEC for r=0.3 all L1 = 0.568 +- 0.173 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.864
Model XAI F1 of binarized graphs for r=0.6 =  0.61547375
Model XAI WIoU of binarized graphs for r=0.6 =  0.7225812500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.449
NEC for r=0.6 class 0 = 0.59 +- 0.293 (in-sample avg dev_std = 0.498)
NEC for r=0.6 class 1 = 0.543 +- 0.293 (in-sample avg dev_std = 0.498)
NEC for r=0.6 class 2 = 0.614 +- 0.293 (in-sample avg dev_std = 0.498)
NEC for r=0.6 all KL = 0.634 +- 0.293 (in-sample avg dev_std = 0.498)
NEC for r=0.6 all L1 = 0.583 +- 0.169 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7284674999999998
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.527
NEC for r=0.9 class 0 = 0.527 +- 0.282 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 1 = 0.522 +- 0.282 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 2 = 0.55 +- 0.282 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all KL = 0.558 +- 0.282 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all L1 = 0.533 +- 0.161 (in-sample avg dev_std = 0.543)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7284674999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.534
NEC for r=1.0 class 0 = 0.505 +- 0.282 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 1 = 0.516 +- 0.282 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 2 = 0.545 +- 0.282 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all KL = 0.544 +- 0.282 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all L1 = 0.522 +- 0.160 (in-sample avg dev_std = 0.546)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.8277087500000002
Model XAI WIoU of binarized graphs for r=0.3 =  0.8539074999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.199
NEC for r=0.3 class 0 = 0.589 +- 0.308 (in-sample avg dev_std = 0.553)
NEC for r=0.3 class 1 = 0.698 +- 0.308 (in-sample avg dev_std = 0.553)
NEC for r=0.3 class 2 = 0.504 +- 0.308 (in-sample avg dev_std = 0.553)
NEC for r=0.3 all KL = 0.753 +- 0.308 (in-sample avg dev_std = 0.553)
NEC for r=0.3 all L1 = 0.596 +- 0.224 (in-sample avg dev_std = 0.553)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.7606149999999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.585
NEC for r=0.6 class 0 = 0.481 +- 0.306 (in-sample avg dev_std = 0.639)
NEC for r=0.6 class 1 = 0.427 +- 0.306 (in-sample avg dev_std = 0.639)
NEC for r=0.6 class 2 = 0.432 +- 0.306 (in-sample avg dev_std = 0.639)
NEC for r=0.6 all KL = 0.56 +- 0.306 (in-sample avg dev_std = 0.639)
NEC for r=0.6 all L1 = 0.447 +- 0.175 (in-sample avg dev_std = 0.639)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.6073825
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.635
NEC for r=0.9 class 0 = 0.402 +- 0.255 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 1 = 0.362 +- 0.255 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 2 = 0.349 +- 0.255 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all KL = 0.409 +- 0.255 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all L1 = 0.371 +- 0.152 (in-sample avg dev_std = 0.574)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.892
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.635
NEC for r=1.0 class 0 = 0.394 +- 0.260 (in-sample avg dev_std = 0.563)
NEC for r=1.0 class 1 = 0.364 +- 0.260 (in-sample avg dev_std = 0.563)
NEC for r=1.0 class 2 = 0.336 +- 0.260 (in-sample avg dev_std = 0.563)
NEC for r=1.0 all KL = 0.397 +- 0.260 (in-sample avg dev_std = 0.563)
NEC for r=1.0 all L1 = 0.365 +- 0.160 (in-sample avg dev_std = 0.563)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.325
Model XAI F1 of binarized graphs for r=0.3 =  0.508055
Model XAI WIoU of binarized graphs for r=0.3 =  0.37309
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.487 +- 0.299 (in-sample avg dev_std = 0.512)
NEC for r=0.3 class 1 = 0.547 +- 0.299 (in-sample avg dev_std = 0.512)
NEC for r=0.3 class 2 = 0.506 +- 0.299 (in-sample avg dev_std = 0.512)
NEC for r=0.3 all KL = 0.523 +- 0.299 (in-sample avg dev_std = 0.512)
NEC for r=0.3 all L1 = 0.513 +- 0.218 (in-sample avg dev_std = 0.512)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.579
Model XAI F1 of binarized graphs for r=0.6 =  0.681995
Model XAI WIoU of binarized graphs for r=0.6 =  0.55573375
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.505
NEC for r=0.6 class 0 = 0.578 +- 0.290 (in-sample avg dev_std = 0.617)
NEC for r=0.6 class 1 = 0.36 +- 0.290 (in-sample avg dev_std = 0.617)
NEC for r=0.6 class 2 = 0.574 +- 0.290 (in-sample avg dev_std = 0.617)
NEC for r=0.6 all KL = 0.682 +- 0.290 (in-sample avg dev_std = 0.617)
NEC for r=0.6 all L1 = 0.507 +- 0.228 (in-sample avg dev_std = 0.617)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  0.59348
Model XAI WIoU of binarized graphs for r=0.9 =  0.5815662500000001
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.584
NEC for r=0.9 class 0 = 0.534 +- 0.226 (in-sample avg dev_std = 0.521)
NEC for r=0.9 class 1 = 0.305 +- 0.226 (in-sample avg dev_std = 0.521)
NEC for r=0.9 class 2 = 0.529 +- 0.226 (in-sample avg dev_std = 0.521)
NEC for r=0.9 all KL = 0.511 +- 0.226 (in-sample avg dev_std = 0.521)
NEC for r=0.9 all L1 = 0.459 +- 0.180 (in-sample avg dev_std = 0.521)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.711
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.58164
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.586
NEC for r=1.0 class 0 = 0.537 +- 0.234 (in-sample avg dev_std = 0.526)
NEC for r=1.0 class 1 = 0.306 +- 0.234 (in-sample avg dev_std = 0.526)
NEC for r=1.0 class 2 = 0.525 +- 0.234 (in-sample avg dev_std = 0.526)
NEC for r=1.0 all KL = 0.499 +- 0.234 (in-sample avg dev_std = 0.526)
NEC for r=1.0 all L1 = 0.459 +- 0.178 (in-sample avg dev_std = 0.526)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:20:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:24 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:36 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:39 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:42 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:20:44 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 152...
[0m[1;37mINFO[0m: [1mCheckpoint 152: 
-----------------------------------
Train ACCURACY: 0.9233
Train Loss: 0.3887
ID Validation ACCURACY: 0.9187
ID Validation Loss: 0.4022
ID Test ACCURACY: 0.9207
ID Test Loss: 0.4112
OOD Validation ACCURACY: 0.8813
OOD Validation Loss: 0.4260
OOD Test ACCURACY: 0.8423
OOD Test Loss: 0.5444

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 104...
[0m[1;37mINFO[0m: [1mCheckpoint 104: 
-----------------------------------
Train ACCURACY: 0.9108
Train Loss: 0.3975
ID Validation ACCURACY: 0.9077
ID Validation Loss: 0.4223
ID Test ACCURACY: 0.9117
ID Test Loss: 0.4159
OOD Validation ACCURACY: 0.9143
OOD Validation Loss: 0.3736
OOD Test ACCURACY: 0.8490
OOD Test Loss: 0.4678

[0m[1;37mINFO[0m: [1mChartInfo 0.9207 0.8423 0.9117 0.8490 0.9077 0.9143[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.691
WIoU for r=0.3 = 0.589
F1 for r=0.6 = 0.613
WIoU for r=0.6 = 0.640
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.633
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.633
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.859
WIoU for r=0.3 = 0.830
F1 for r=0.6 = 0.792
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.615
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.501
WIoU for r=0.3 = 0.406
F1 for r=0.6 = 0.687
WIoU for r=0.6 = 0.581
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.580
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.580


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.587
Model XAI F1 of binarized graphs for r=0.3 =  0.69093125
Model XAI WIoU of binarized graphs for r=0.3 =  0.58869125
len(reference) = 799
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.46
SUFF++ for r=0.3 class 0 = 0.383 +- 0.251 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 class 1 = 0.437 +- 0.251 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 class 2 = 0.509 +- 0.251 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 all KL = 0.276 +- 0.251 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.3 all L1 = 0.445 +- 0.183 (in-sample avg dev_std = 0.644)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.859
Model XAI F1 of binarized graphs for r=0.6 =  0.6126425000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6402387500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0 = 0.476 +- 0.303 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 1 = 0.554 +- 0.303 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 2 = 0.724 +- 0.303 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all KL = 0.485 +- 0.303 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all L1 = 0.588 +- 0.219 (in-sample avg dev_std = 0.558)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6326787500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.864
SUFF++ for r=0.9 class 0 = 0.775 +- 0.214 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.827 +- 0.214 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.841 +- 0.214 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.835 +- 0.214 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.168 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.556
Model XAI F1 of binarized graphs for r=0.3 =  0.8593175000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8295862500000001
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.486
SUFF++ for r=0.3 class 0 = 0.509 +- 0.305 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 class 1 = 0.625 +- 0.305 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.305 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 all KL = 0.393 +- 0.305 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.3 all L1 = 0.609 +- 0.214 (in-sample avg dev_std = 0.629)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.7921087499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.902
SUFF++ for r=0.6 class 0 = 0.901 +- 0.160 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 class 1 = 0.911 +- 0.160 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 class 2 = 0.933 +- 0.160 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 all KL = 0.928 +- 0.160 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 all L1 = 0.915 +- 0.148 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.88
Model XAI F1 of binarized graphs for r=0.9 =  0.6146375000000001
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.906
SUFF++ for r=0.9 class 0 = 0.916 +- 0.126 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1 = 0.948 +- 0.126 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 2 = 0.932 +- 0.126 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.96 +- 0.126 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.932 +- 0.135 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.404
Model XAI F1 of binarized graphs for r=0.3 =  0.501385
Model XAI WIoU of binarized graphs for r=0.3 =  0.40632375
len(reference) = 795
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.375
SUFF++ for r=0.3 class 0 = 0.414 +- 0.263 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 1 = 0.55 +- 0.263 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 2 = 0.582 +- 0.263 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all KL = 0.37 +- 0.263 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all L1 = 0.514 +- 0.202 (in-sample avg dev_std = 0.610)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.724
Model XAI F1 of binarized graphs for r=0.6 =  0.68652125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5805724999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.679
SUFF++ for r=0.6 class 0 = 0.471 +- 0.302 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 1 = 0.627 +- 0.302 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 2 = 0.711 +- 0.302 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 all KL = 0.465 +- 0.302 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 all L1 = 0.603 +- 0.232 (in-sample avg dev_std = 0.575)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  0.5937225
Model XAI WIoU of binarized graphs for r=0.9 =  0.57969875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.822
SUFF++ for r=0.9 class 0 = 0.658 +- 0.164 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 1 = 0.962 +- 0.164 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 2 = 0.824 +- 0.164 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all KL = 0.871 +- 0.164 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.196 (in-sample avg dev_std = 0.251)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  0.69093125
Model XAI WIoU of binarized graphs for r=0.3 =  0.58869125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.373
NEC for r=0.3 class 0 = 0.659 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 class 1 = 0.653 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 class 2 = 0.617 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 all KL = 0.794 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 all L1 = 0.642 +- 0.161 (in-sample avg dev_std = 0.562)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.858
Model XAI F1 of binarized graphs for r=0.6 =  0.6126425000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6402387500000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.451
NEC for r=0.6 class 0 = 0.613 +- 0.264 (in-sample avg dev_std = 0.575)
NEC for r=0.6 class 1 = 0.585 +- 0.264 (in-sample avg dev_std = 0.575)
NEC for r=0.6 class 2 = 0.578 +- 0.264 (in-sample avg dev_std = 0.575)
NEC for r=0.6 all KL = 0.708 +- 0.264 (in-sample avg dev_std = 0.575)
NEC for r=0.6 all L1 = 0.592 +- 0.156 (in-sample avg dev_std = 0.575)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.6326787500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.556
NEC for r=0.9 class 0 = 0.522 +- 0.293 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.529 +- 0.293 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.528 +- 0.293 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.598 +- 0.293 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.527 +- 0.159 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.63266875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.552
NEC for r=1.0 class 0 = 0.518 +- 0.283 (in-sample avg dev_std = 0.582)
NEC for r=1.0 class 1 = 0.531 +- 0.283 (in-sample avg dev_std = 0.582)
NEC for r=1.0 class 2 = 0.531 +- 0.283 (in-sample avg dev_std = 0.582)
NEC for r=1.0 all KL = 0.594 +- 0.283 (in-sample avg dev_std = 0.582)
NEC for r=1.0 all L1 = 0.527 +- 0.153 (in-sample avg dev_std = 0.582)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.556
Model XAI F1 of binarized graphs for r=0.3 =  0.8593175000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8295862500000001
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.314
NEC for r=0.3 class 0 = 0.688 +- 0.212 (in-sample avg dev_std = 0.539)
NEC for r=0.3 class 1 = 0.692 +- 0.212 (in-sample avg dev_std = 0.539)
NEC for r=0.3 class 2 = 0.541 +- 0.212 (in-sample avg dev_std = 0.539)
NEC for r=0.3 all KL = 0.847 +- 0.212 (in-sample avg dev_std = 0.539)
NEC for r=0.3 all L1 = 0.64 +- 0.166 (in-sample avg dev_std = 0.539)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.7921087499999999
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.534
NEC for r=0.6 class 0 = 0.564 +- 0.265 (in-sample avg dev_std = 0.641)
NEC for r=0.6 class 1 = 0.525 +- 0.265 (in-sample avg dev_std = 0.641)
NEC for r=0.6 class 2 = 0.457 +- 0.265 (in-sample avg dev_std = 0.641)
NEC for r=0.6 all KL = 0.696 +- 0.265 (in-sample avg dev_std = 0.641)
NEC for r=0.6 all L1 = 0.516 +- 0.164 (in-sample avg dev_std = 0.641)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.88
Model XAI F1 of binarized graphs for r=0.9 =  0.6146375000000001
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.631
NEC for r=0.9 class 0 = 0.428 +- 0.231 (in-sample avg dev_std = 0.603)
NEC for r=0.9 class 1 = 0.408 +- 0.231 (in-sample avg dev_std = 0.603)
NEC for r=0.9 class 2 = 0.353 +- 0.231 (in-sample avg dev_std = 0.603)
NEC for r=0.9 all KL = 0.455 +- 0.231 (in-sample avg dev_std = 0.603)
NEC for r=0.9 all L1 = 0.396 +- 0.149 (in-sample avg dev_std = 0.603)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0 = 0.428 +- 0.237 (in-sample avg dev_std = 0.601)
NEC for r=1.0 class 1 = 0.411 +- 0.237 (in-sample avg dev_std = 0.601)
NEC for r=1.0 class 2 = 0.365 +- 0.237 (in-sample avg dev_std = 0.601)
NEC for r=1.0 all KL = 0.456 +- 0.237 (in-sample avg dev_std = 0.601)
NEC for r=1.0 all L1 = 0.402 +- 0.149 (in-sample avg dev_std = 0.601)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.401
Model XAI F1 of binarized graphs for r=0.3 =  0.501385
Model XAI WIoU of binarized graphs for r=0.3 =  0.40632375
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.611 +- 0.292 (in-sample avg dev_std = 0.566)
NEC for r=0.3 class 1 = 0.495 +- 0.292 (in-sample avg dev_std = 0.566)
NEC for r=0.3 class 2 = 0.492 +- 0.292 (in-sample avg dev_std = 0.566)
NEC for r=0.3 all KL = 0.669 +- 0.292 (in-sample avg dev_std = 0.566)
NEC for r=0.3 all L1 = 0.533 +- 0.227 (in-sample avg dev_std = 0.566)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.724
Model XAI F1 of binarized graphs for r=0.6 =  0.68652125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5805724999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.56
NEC for r=0.6 class 0 = 0.633 +- 0.266 (in-sample avg dev_std = 0.629)
NEC for r=0.6 class 1 = 0.581 +- 0.266 (in-sample avg dev_std = 0.629)
NEC for r=0.6 class 2 = 0.467 +- 0.266 (in-sample avg dev_std = 0.629)
NEC for r=0.6 all KL = 0.722 +- 0.266 (in-sample avg dev_std = 0.629)
NEC for r=0.6 all L1 = 0.56 +- 0.191 (in-sample avg dev_std = 0.629)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  0.5937225
Model XAI WIoU of binarized graphs for r=0.9 =  0.57969875
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.644
NEC for r=0.9 class 0 = 0.523 +- 0.240 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 1 = 0.383 +- 0.240 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 2 = 0.48 +- 0.240 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all KL = 0.533 +- 0.240 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all L1 = 0.463 +- 0.165 (in-sample avg dev_std = 0.560)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.856
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5798375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0 = 0.484 +- 0.232 (in-sample avg dev_std = 0.556)
NEC for r=1.0 class 1 = 0.367 +- 0.232 (in-sample avg dev_std = 0.556)
NEC for r=1.0 class 2 = 0.463 +- 0.232 (in-sample avg dev_std = 0.556)
NEC for r=1.0 all KL = 0.484 +- 0.232 (in-sample avg dev_std = 0.556)
NEC for r=1.0 all L1 = 0.439 +- 0.155 (in-sample avg dev_std = 0.556)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:23:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:23:50 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:04 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:06 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:24:10 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9147
Train Loss: 0.3933
ID Validation ACCURACY: 0.9163
ID Validation Loss: 0.4034
ID Test ACCURACY: 0.9110
ID Test Loss: 0.4044
OOD Validation ACCURACY: 0.8683
OOD Validation Loss: 0.4646
OOD Test ACCURACY: 0.7923
OOD Test Loss: 0.6123

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ACCURACY: 0.9109
Train Loss: 0.4061
ID Validation ACCURACY: 0.9070
ID Validation Loss: 0.4215
ID Test ACCURACY: 0.9087
ID Test Loss: 0.4129
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3937
OOD Test ACCURACY: 0.7877
OOD Test Loss: 0.5793

[0m[1;37mINFO[0m: [1mChartInfo 0.9110 0.7923 0.9087 0.7877 0.9070 0.9313[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.691
WIoU for r=0.3 = 0.641
F1 for r=0.6 = 0.614
WIoU for r=0.6 = 0.740
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.745
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.745
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.824
WIoU for r=0.3 = 0.888
F1 for r=0.6 = 0.720
WIoU for r=0.6 = 0.994
F1 for r=0.9 = 0.597
WIoU for r=0.9 = 0.994
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 0.994
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.486
WIoU for r=0.3 = 0.338
F1 for r=0.6 = 0.678
WIoU for r=0.6 = 0.546
F1 for r=0.9 = 0.592
WIoU for r=0.9 = 0.582
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.582


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  0.6905625
Model XAI WIoU of binarized graphs for r=0.3 =  0.64146625
len(reference) = 790
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.492
SUFF++ for r=0.3 class 0 = 0.482 +- 0.283 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 class 1 = 0.617 +- 0.283 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 class 2 = 0.53 +- 0.283 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 all KL = 0.425 +- 0.283 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 all L1 = 0.544 +- 0.196 (in-sample avg dev_std = 0.606)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.854
Model XAI F1 of binarized graphs for r=0.6 =  0.6135437499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7400312499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.728
SUFF++ for r=0.6 class 0 = 0.606 +- 0.276 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 class 1 = 0.741 +- 0.276 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 class 2 = 0.645 +- 0.276 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 all KL = 0.618 +- 0.276 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 all L1 = 0.665 +- 0.196 (in-sample avg dev_std = 0.493)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4754975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7445099999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.879
SUFF++ for r=0.9 class 0 = 0.893 +- 0.150 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 1 = 0.879 +- 0.150 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 2 = 0.873 +- 0.150 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all KL = 0.915 +- 0.150 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.143 (in-sample avg dev_std = 0.221)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  0.8235837500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8881399999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0 = 0.672 +- 0.348 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 1 = 0.857 +- 0.348 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 2 = 0.599 +- 0.348 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all KL = 0.55 +- 0.348 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all L1 = 0.709 +- 0.229 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  0.7200774999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9941549999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.84
SUFF++ for r=0.6 class 0 = 0.813 +- 0.247 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.6 class 1 = 0.846 +- 0.247 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.6 class 2 = 0.84 +- 0.247 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.6 all KL = 0.793 +- 0.247 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.6 all L1 = 0.833 +- 0.151 (in-sample avg dev_std = 0.427)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.5966337500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.9941549999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.878
SUFF++ for r=0.9 class 0 = 0.968 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1 = 0.946 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 2 = 0.962 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.985 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.959 +- 0.066 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.341
Model XAI F1 of binarized graphs for r=0.3 =  0.48630625
Model XAI WIoU of binarized graphs for r=0.3 =  0.33787124999999996
len(reference) = 780
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.355
SUFF++ for r=0.3 class 0 = 0.532 +- 0.255 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 class 1 = 0.507 +- 0.255 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 class 2 = 0.504 +- 0.255 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all KL = 0.511 +- 0.255 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.3 all L1 = 0.514 +- 0.186 (in-sample avg dev_std = 0.568)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.631
Model XAI F1 of binarized graphs for r=0.6 =  0.6777612500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.5456599999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.658
SUFF++ for r=0.6 class 0 = 0.609 +- 0.310 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 1 = 0.875 +- 0.310 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 2 = 0.586 +- 0.310 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all KL = 0.628 +- 0.310 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all L1 = 0.687 +- 0.246 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  0.5923925
Model XAI WIoU of binarized graphs for r=0.9 =  0.5819225
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.72
SUFF++ for r=0.9 class 0 = 0.742 +- 0.226 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 1 = 0.957 +- 0.226 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 2 = 0.767 +- 0.226 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all KL = 0.84 +- 0.226 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all L1 = 0.82 +- 0.197 (in-sample avg dev_std = 0.366)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  0.6905625
Model XAI WIoU of binarized graphs for r=0.3 =  0.64146625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.577 +- 0.284 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 1 = 0.485 +- 0.284 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 2 = 0.583 +- 0.284 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all KL = 0.64 +- 0.284 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all L1 = 0.548 +- 0.204 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.854
Model XAI F1 of binarized graphs for r=0.6 =  0.6135437499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7400312499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.47
NEC for r=0.6 class 0 = 0.574 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 1 = 0.498 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 2 = 0.571 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all KL = 0.607 +- 0.306 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all L1 = 0.547 +- 0.183 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4754975
Model XAI WIoU of binarized graphs for r=0.9 =  0.7445099999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.507 +- 0.298 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 1 = 0.481 +- 0.298 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 2 = 0.543 +- 0.298 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all KL = 0.545 +- 0.298 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all L1 = 0.51 +- 0.182 (in-sample avg dev_std = 0.557)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.914
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7445099999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.543
NEC for r=1.0 class 0 = 0.503 +- 0.292 (in-sample avg dev_std = 0.552)
NEC for r=1.0 class 1 = 0.483 +- 0.292 (in-sample avg dev_std = 0.552)
NEC for r=1.0 class 2 = 0.548 +- 0.292 (in-sample avg dev_std = 0.552)
NEC for r=1.0 all KL = 0.54 +- 0.292 (in-sample avg dev_std = 0.552)
NEC for r=1.0 all L1 = 0.512 +- 0.175 (in-sample avg dev_std = 0.552)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  0.8235837500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8881399999999999
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.296
NEC for r=0.3 class 0 = 0.578 +- 0.324 (in-sample avg dev_std = 0.504)
NEC for r=0.3 class 1 = 0.597 +- 0.324 (in-sample avg dev_std = 0.504)
NEC for r=0.3 class 2 = 0.543 +- 0.324 (in-sample avg dev_std = 0.504)
NEC for r=0.3 all KL = 0.745 +- 0.324 (in-sample avg dev_std = 0.504)
NEC for r=0.3 all L1 = 0.572 +- 0.247 (in-sample avg dev_std = 0.504)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  0.7200774999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.9941549999999999
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.537
NEC for r=0.6 class 0 = 0.498 +- 0.297 (in-sample avg dev_std = 0.666)
NEC for r=0.6 class 1 = 0.425 +- 0.297 (in-sample avg dev_std = 0.666)
NEC for r=0.6 class 2 = 0.432 +- 0.297 (in-sample avg dev_std = 0.666)
NEC for r=0.6 all KL = 0.558 +- 0.297 (in-sample avg dev_std = 0.666)
NEC for r=0.6 all L1 = 0.452 +- 0.173 (in-sample avg dev_std = 0.666)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.5966337500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.9941549999999999
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.373 +- 0.243 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 1 = 0.356 +- 0.243 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 2 = 0.346 +- 0.243 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all KL = 0.384 +- 0.243 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all L1 = 0.358 +- 0.150 (in-sample avg dev_std = 0.588)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  0.9941549999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.625
NEC for r=1.0 class 0 = 0.361 +- 0.242 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 1 = 0.341 +- 0.242 (in-sample avg dev_std = 0.576)
NEC for r=1.0 class 2 = 0.353 +- 0.242 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all KL = 0.37 +- 0.242 (in-sample avg dev_std = 0.576)
NEC for r=1.0 all L1 = 0.352 +- 0.153 (in-sample avg dev_std = 0.576)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.341
Model XAI F1 of binarized graphs for r=0.3 =  0.48630625
Model XAI WIoU of binarized graphs for r=0.3 =  0.33787124999999996
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.413
NEC for r=0.3 class 0 = 0.5 +- 0.284 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 1 = 0.513 +- 0.284 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 2 = 0.453 +- 0.284 (in-sample avg dev_std = 0.498)
NEC for r=0.3 all KL = 0.478 +- 0.284 (in-sample avg dev_std = 0.498)
NEC for r=0.3 all L1 = 0.488 +- 0.212 (in-sample avg dev_std = 0.498)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  0.6777612500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.5456599999999999
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.565
NEC for r=0.6 class 0 = 0.609 +- 0.320 (in-sample avg dev_std = 0.597)
NEC for r=0.6 class 1 = 0.252 +- 0.320 (in-sample avg dev_std = 0.597)
NEC for r=0.6 class 2 = 0.615 +- 0.320 (in-sample avg dev_std = 0.597)
NEC for r=0.6 all KL = 0.611 +- 0.320 (in-sample avg dev_std = 0.597)
NEC for r=0.6 all L1 = 0.496 +- 0.251 (in-sample avg dev_std = 0.597)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  0.5923925
Model XAI WIoU of binarized graphs for r=0.9 =  0.5819225
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0 = 0.508 +- 0.231 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 1 = 0.278 +- 0.231 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 2 = 0.527 +- 0.231 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all KL = 0.478 +- 0.231 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all L1 = 0.441 +- 0.176 (in-sample avg dev_std = 0.574)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.58187875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.654
NEC for r=1.0 class 0 = 0.514 +- 0.230 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 1 = 0.277 +- 0.230 (in-sample avg dev_std = 0.577)
NEC for r=1.0 class 2 = 0.53 +- 0.230 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all KL = 0.475 +- 0.230 (in-sample avg dev_std = 0.577)
NEC for r=1.0 all L1 = 0.443 +- 0.175 (in-sample avg dev_std = 0.577)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:27:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:15 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:28 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:30 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:34 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:27:36 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.8970
Train Loss: 0.4589
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4799
ID Test ACCURACY: 0.8947
ID Test Loss: 0.4678
OOD Validation ACCURACY: 0.8997
OOD Validation Loss: 0.4210
OOD Test ACCURACY: 0.7737
OOD Test Loss: 0.5659

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.8970
Train Loss: 0.4589
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4799
ID Test ACCURACY: 0.8947
ID Test Loss: 0.4678
OOD Validation ACCURACY: 0.8997
OOD Validation Loss: 0.4210
OOD Test ACCURACY: 0.7737
OOD Test Loss: 0.5659

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.7737 0.8947 0.7737 0.8910 0.8997[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([ 959, 1004, 1037]))

Gold ratio (id_val) =  tensor(0.3071) +- tensor(0.1673)
F1 for r=0.3 = 0.704
WIoU for r=0.3 = 0.665
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.773
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.781
F1 for r=1.0 = 0.447
WIoU for r=1.0 = 0.781
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 34], x=[17, 1], node_gt=[17], edge_gt=[34], y=[1], env_id=[1], ori_edge_index=[2, 34], node_perm=[17], num_nodes=17)
Label distribution from val: (tensor([0, 1, 2]), tensor([1007,  991, 1002]))

Gold ratio (val) =  tensor(0.4137) +- tensor(0.0836)
F1 for r=0.3 = 0.845
WIoU for r=0.3 = 0.809
F1 for r=0.6 = 0.770
WIoU for r=0.6 = 1.000
F1 for r=0.9 = 0.600
WIoU for r=0.9 = 1.000
F1 for r=1.0 = 0.580
WIoU for r=1.0 = 1.000
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from test: (tensor([0, 1, 2]), tensor([1017,  962, 1021]))

Gold ratio (test) =  tensor(0.3931) +- tensor(0.0982)
F1 for r=0.3 = 0.488
WIoU for r=0.3 = 0.342
F1 for r=0.6 = 0.669
WIoU for r=0.6 = 0.525
F1 for r=0.9 = 0.594
WIoU for r=0.9 = 0.506
F1 for r=1.0 = 0.558
WIoU for r=1.0 = 0.506


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  0.7041624999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6645012499999998
len(reference) = 793
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.466
SUFF++ for r=0.3 class 0 = 0.445 +- 0.273 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 1 = 0.505 +- 0.273 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 2 = 0.511 +- 0.273 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all KL = 0.431 +- 0.273 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all L1 = 0.487 +- 0.162 (in-sample avg dev_std = 0.537)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.61006
Model XAI WIoU of binarized graphs for r=0.6 =  0.7733275000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.688
SUFF++ for r=0.6 class 0 = 0.538 +- 0.245 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1 = 0.629 +- 0.245 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.245 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.622 +- 0.245 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.615 +- 0.181 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7811475
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.839
SUFF++ for r=0.9 class 0 = 0.783 +- 0.182 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 1 = 0.751 +- 0.182 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 2 = 0.839 +- 0.182 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all KL = 0.857 +- 0.182 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.178 (in-sample avg dev_std = 0.252)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.8454875
Model XAI WIoU of binarized graphs for r=0.3 =  0.80894375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.525
SUFF++ for r=0.3 class 0 = 0.578 +- 0.297 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 class 1 = 0.608 +- 0.297 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 class 2 = 0.59 +- 0.297 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 all KL = 0.488 +- 0.297 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 all L1 = 0.592 +- 0.201 (in-sample avg dev_std = 0.601)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.77032125
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.886
SUFF++ for r=0.6 class 0 = 0.908 +- 0.138 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 1 = 0.783 +- 0.138 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 2 = 0.918 +- 0.138 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all KL = 0.906 +- 0.138 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all L1 = 0.87 +- 0.144 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.6004312500000001
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0 = 0.934 +- 0.093 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 1 = 0.841 +- 0.093 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 class 2 = 0.947 +- 0.093 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all KL = 0.958 +- 0.093 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.9 all L1 = 0.907 +- 0.142 (in-sample avg dev_std = 0.111)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.38
Model XAI F1 of binarized graphs for r=0.3 =  0.48758875
Model XAI WIoU of binarized graphs for r=0.3 =  0.342255
len(reference) = 772
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.35
SUFF++ for r=0.3 class 0 = 0.482 +- 0.197 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.3 class 1 = 0.512 +- 0.197 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.3 class 2 = 0.485 +- 0.197 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.3 all KL = 0.562 +- 0.197 (in-sample avg dev_std = 0.526)
SUFF++ for r=0.3 all L1 = 0.492 +- 0.122 (in-sample avg dev_std = 0.526)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  0.66871375
Model XAI WIoU of binarized graphs for r=0.6 =  0.52522375
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.589 +- 0.280 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.280 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 2 = 0.564 +- 0.280 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all KL = 0.613 +- 0.280 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all L1 = 0.646 +- 0.223 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.784
Model XAI F1 of binarized graphs for r=0.9 =  0.59382375
Model XAI WIoU of binarized graphs for r=0.9 =  0.505865
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.765
SUFF++ for r=0.9 class 0 = 0.757 +- 0.103 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 class 1 = 0.945 +- 0.103 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 class 2 = 0.836 +- 0.103 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all KL = 0.927 +- 0.103 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all L1 = 0.844 +- 0.144 (in-sample avg dev_std = 0.196)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.7041624999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6645012499999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.378
NEC for r=0.3 class 0 = 0.617 +- 0.276 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 1 = 0.541 +- 0.276 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 2 = 0.607 +- 0.276 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all KL = 0.634 +- 0.276 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all L1 = 0.588 +- 0.149 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.61006
Model XAI WIoU of binarized graphs for r=0.6 =  0.7733275000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.469
NEC for r=0.6 class 0 = 0.577 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.6 class 1 = 0.5 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.6 class 2 = 0.572 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.6 all KL = 0.567 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.6 all L1 = 0.549 +- 0.166 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  0.47577375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7811475
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.557
NEC for r=0.9 class 0 = 0.487 +- 0.290 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 1 = 0.459 +- 0.290 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 2 = 0.507 +- 0.290 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all KL = 0.476 +- 0.290 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all L1 = 0.484 +- 0.156 (in-sample avg dev_std = 0.492)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.4465199999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.7811262500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.558
NEC for r=1.0 class 0 = 0.485 +- 0.290 (in-sample avg dev_std = 0.498)
NEC for r=1.0 class 1 = 0.445 +- 0.290 (in-sample avg dev_std = 0.498)
NEC for r=1.0 class 2 = 0.5 +- 0.290 (in-sample avg dev_std = 0.498)
NEC for r=1.0 all KL = 0.464 +- 0.290 (in-sample avg dev_std = 0.498)
NEC for r=1.0 all L1 = 0.477 +- 0.155 (in-sample avg dev_std = 0.498)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.585
Model XAI F1 of binarized graphs for r=0.3 =  0.8454875
Model XAI WIoU of binarized graphs for r=0.3 =  0.80894375
len(reference) = 800
Effective ratio: 0.314 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.438
NEC for r=0.3 class 0 = 0.609 +- 0.253 (in-sample avg dev_std = 0.580)
NEC for r=0.3 class 1 = 0.613 +- 0.253 (in-sample avg dev_std = 0.580)
NEC for r=0.3 class 2 = 0.566 +- 0.253 (in-sample avg dev_std = 0.580)
NEC for r=0.3 all KL = 0.713 +- 0.253 (in-sample avg dev_std = 0.580)
NEC for r=0.3 all L1 = 0.596 +- 0.154 (in-sample avg dev_std = 0.580)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.77032125
Model XAI WIoU of binarized graphs for r=0.6 =  1.0
len(reference) = 800
Effective ratio: 0.614 +- 0.009
Model Accuracy over intervened graphs for r=0.6 =  0.681
NEC for r=0.6 class 0 = 0.419 +- 0.261 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 1 = 0.399 +- 0.261 (in-sample avg dev_std = 0.542)
NEC for r=0.6 class 2 = 0.35 +- 0.261 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all KL = 0.477 +- 0.261 (in-sample avg dev_std = 0.542)
NEC for r=0.6 all L1 = 0.389 +- 0.160 (in-sample avg dev_std = 0.542)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.899
Model XAI F1 of binarized graphs for r=0.9 =  0.6004312500000001
Model XAI WIoU of binarized graphs for r=0.9 =  1.0
len(reference) = 800
Effective ratio: 0.913 +- 0.009
Model Accuracy over intervened graphs for r=0.9 =  0.734
NEC for r=0.9 class 0 = 0.311 +- 0.178 (in-sample avg dev_std = 0.454)
NEC for r=0.9 class 1 = 0.302 +- 0.178 (in-sample avg dev_std = 0.454)
NEC for r=0.9 class 2 = 0.272 +- 0.178 (in-sample avg dev_std = 0.454)
NEC for r=0.9 all KL = 0.262 +- 0.178 (in-sample avg dev_std = 0.454)
NEC for r=0.9 all L1 = 0.295 +- 0.141 (in-sample avg dev_std = 0.454)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.5803825
Model XAI WIoU of binarized graphs for r=1.0 =  1.0
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.724
NEC for r=1.0 class 0 = 0.302 +- 0.171 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 1 = 0.308 +- 0.171 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 2 = 0.294 +- 0.171 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all KL = 0.266 +- 0.171 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all L1 = 0.301 +- 0.132 (in-sample avg dev_std = 0.455)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.386
Model XAI F1 of binarized graphs for r=0.3 =  0.48758875
Model XAI WIoU of binarized graphs for r=0.3 =  0.342255
len(reference) = 800
Effective ratio: 0.315 +- 0.009
Model Accuracy over intervened graphs for r=0.3 =  0.405
NEC for r=0.3 class 0 = 0.516 +- 0.239 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 1 = 0.542 +- 0.239 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 2 = 0.496 +- 0.239 (in-sample avg dev_std = 0.457)
NEC for r=0.3 all KL = 0.448 +- 0.239 (in-sample avg dev_std = 0.457)
NEC for r=0.3 all L1 = 0.517 +- 0.163 (in-sample avg dev_std = 0.457)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  0.66871375
Model XAI WIoU of binarized graphs for r=0.6 =  0.52522375
len(reference) = 800
Effective ratio: 0.616 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.602
NEC for r=0.6 class 0 = 0.581 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=0.6 class 1 = 0.333 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=0.6 class 2 = 0.58 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=0.6 all KL = 0.591 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=0.6 all L1 = 0.501 +- 0.204 (in-sample avg dev_std = 0.578)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.784
Model XAI F1 of binarized graphs for r=0.9 =  0.59382375
Model XAI WIoU of binarized graphs for r=0.9 =  0.505865
len(reference) = 800
Effective ratio: 0.913 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.654
NEC for r=0.9 class 0 = 0.473 +- 0.211 (in-sample avg dev_std = 0.477)
NEC for r=0.9 class 1 = 0.306 +- 0.211 (in-sample avg dev_std = 0.477)
NEC for r=0.9 class 2 = 0.469 +- 0.211 (in-sample avg dev_std = 0.477)
NEC for r=0.9 all KL = 0.412 +- 0.211 (in-sample avg dev_std = 0.477)
NEC for r=0.9 all L1 = 0.418 +- 0.154 (in-sample avg dev_std = 0.477)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.786
Model XAI F1 of binarized graphs for r=1.0 =  0.55751125
Model XAI WIoU of binarized graphs for r=1.0 =  0.5057675
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.67
NEC for r=1.0 class 0 = 0.45 +- 0.203 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 1 = 0.314 +- 0.203 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 2 = 0.44 +- 0.203 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all KL = 0.376 +- 0.203 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all L1 = 0.403 +- 0.141 (in-sample avg dev_std = 0.471)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.39, 0.53, 0.919, 1.0], 'all_L1': [0.495, 0.592, 0.871, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.403, 0.538, 0.855, 1.0], 'all_L1': [0.517, 0.601, 0.832, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.276, 0.485, 0.835, 1.0], 'all_L1': [0.445, 0.588, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.425, 0.618, 0.915, 1.0], 'all_L1': [0.544, 0.665, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.431, 0.622, 0.857, 1.0], 'all_L1': [0.487, 0.615, 0.792, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.725, 0.679, 0.579, 0.57], 'all_L1': [0.605, 0.599, 0.535, 0.533]}), defaultdict(<class 'list'>, {'all_KL': [0.654, 0.634, 0.558, 0.544], 'all_L1': [0.568, 0.583, 0.533, 0.522]}), defaultdict(<class 'list'>, {'all_KL': [0.794, 0.708, 0.598, 0.594], 'all_L1': [0.642, 0.592, 0.527, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.64, 0.607, 0.545, 0.54], 'all_L1': [0.548, 0.547, 0.51, 0.512]}), defaultdict(<class 'list'>, {'all_KL': [0.634, 0.567, 0.476, 0.464], 'all_L1': [0.588, 0.549, 0.484, 0.477]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.421, 0.857, 0.946, 1.0], 'all_L1': [0.617, 0.865, 0.932, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.51, 0.81, 0.967, 1.0], 'all_L1': [0.678, 0.833, 0.939, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.393, 0.928, 0.96, 1.0], 'all_L1': [0.609, 0.915, 0.932, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.55, 0.793, 0.985, 1.0], 'all_L1': [0.709, 0.833, 0.959, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.488, 0.906, 0.958, 1.0], 'all_L1': [0.592, 0.87, 0.907, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.813, 0.637, 0.454, 0.45], 'all_L1': [0.651, 0.504, 0.401, 0.402]}), defaultdict(<class 'list'>, {'all_KL': [0.753, 0.56, 0.409, 0.397], 'all_L1': [0.596, 0.447, 0.371, 0.365]}), defaultdict(<class 'list'>, {'all_KL': [0.847, 0.696, 0.455, 0.456], 'all_L1': [0.64, 0.516, 0.396, 0.402]}), defaultdict(<class 'list'>, {'all_KL': [0.745, 0.558, 0.384, 0.37], 'all_L1': [0.572, 0.452, 0.358, 0.352]}), defaultdict(<class 'list'>, {'all_KL': [0.713, 0.477, 0.262, 0.266], 'all_L1': [0.596, 0.389, 0.295, 0.301]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.496, 0.58, 0.885, 1.0], 'all_L1': [0.601, 0.627, 0.849, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.458, 0.516, 0.828, 1.0], 'all_L1': [0.479, 0.651, 0.801, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.37, 0.465, 0.871, 1.0], 'all_L1': [0.514, 0.603, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.511, 0.628, 0.84, 1.0], 'all_L1': [0.514, 0.687, 0.82, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.562, 0.613, 0.927, 1.0], 'all_L1': [0.492, 0.646, 0.844, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.444, 0.716, 0.534, 0.513], 'all_L1': [0.371, 0.587, 0.475, 0.458]}), defaultdict(<class 'list'>, {'all_KL': [0.523, 0.682, 0.511, 0.499], 'all_L1': [0.513, 0.507, 0.459, 0.459]}), defaultdict(<class 'list'>, {'all_KL': [0.669, 0.722, 0.533, 0.484], 'all_L1': [0.533, 0.56, 0.463, 0.439]}), defaultdict(<class 'list'>, {'all_KL': [0.478, 0.611, 0.478, 0.475], 'all_L1': [0.488, 0.496, 0.441, 0.443]}), defaultdict(<class 'list'>, {'all_KL': [0.448, 0.591, 0.412, 0.376], 'all_L1': [0.517, 0.501, 0.418, 0.403]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.498 +- 0.033, 0.612 +- 0.028, 0.838 +- 0.034, 1.000 +- 0.000
suff++ class all_KL  =  0.385 +- 0.056, 0.559 +- 0.053, 0.876 +- 0.034, 1.000 +- 0.000
suff++_acc_int  =  0.456 +- 0.025, 0.684 +- 0.024, 0.863 +- 0.018
nec class all_L1  =  0.590 +- 0.032, 0.574 +- 0.022, 0.518 +- 0.019, 0.514 +- 0.020
nec class all_KL  =  0.689 +- 0.062, 0.639 +- 0.050, 0.551 +- 0.042, 0.542 +- 0.044
nec_acc_int  =  0.366 +- 0.009, 0.454 +- 0.013, 0.542 +- 0.012, 0.543 +- 0.010

Eval split val
suff++ class all_L1  =  0.641 +- 0.045, 0.863 +- 0.030, 0.934 +- 0.017, 1.000 +- 0.000
suff++ class all_KL  =  0.472 +- 0.058, 0.859 +- 0.052, 0.963 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.517 +- 0.032, 0.876 +- 0.021, 0.886 +- 0.016
nec class all_L1  =  0.611 +- 0.030, 0.462 +- 0.045, 0.364 +- 0.038, 0.364 +- 0.037
nec class all_KL  =  0.774 +- 0.049, 0.586 +- 0.075, 0.393 +- 0.071, 0.388 +- 0.069
nec_acc_int  =  0.295 +- 0.083, 0.570 +- 0.061, 0.645 +- 0.045, 0.645 +- 0.041

Eval split test
suff++ class all_L1  =  0.520 +- 0.043, 0.643 +- 0.028, 0.825 +- 0.018, 1.000 +- 0.000
suff++ class all_KL  =  0.479 +- 0.064, 0.560 +- 0.061, 0.870 +- 0.035, 1.000 +- 0.000
suff++_acc_int  =  0.354 +- 0.012, 0.657 +- 0.031, 0.751 +- 0.052
nec class all_L1  =  0.484 +- 0.059, 0.530 +- 0.037, 0.451 +- 0.020, 0.440 +- 0.020
nec class all_KL  =  0.512 +- 0.083, 0.664 +- 0.054, 0.494 +- 0.046, 0.469 +- 0.048
nec_acc_int  =  0.381 +- 0.023, 0.554 +- 0.032, 0.629 +- 0.027, 0.642 +- 0.030


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.544 +- 0.004, 0.593 +- 0.008, 0.678 +- 0.023, 0.757 +- 0.010
Faith. Armon (L1)= 		  =  0.538 +- 0.008, 0.592 +- 0.007, 0.640 +- 0.021, 0.679 +- 0.018
Faith. GMean (L1)= 	  =  0.541 +- 0.005, 0.592 +- 0.007, 0.659 +- 0.022, 0.717 +- 0.014
Faith. Aritm (KL)= 		  =  0.537 +- 0.010, 0.599 +- 0.009, 0.714 +- 0.028, 0.771 +- 0.022
Faith. Armon (KL)= 		  =  0.488 +- 0.039, 0.592 +- 0.013, 0.676 +- 0.034, 0.702 +- 0.038
Faith. GMean (KL)= 	  =  0.512 +- 0.022, 0.595 +- 0.010, 0.694 +- 0.030, 0.736 +- 0.030

Eval split val
Faith. Aritm (L1)= 		  =  0.626 +- 0.017, 0.662 +- 0.033, 0.649 +- 0.024, 0.682 +- 0.019
Faith. Armon (L1)= 		  =  0.624 +- 0.015, 0.600 +- 0.043, 0.523 +- 0.042, 0.533 +- 0.041
Faith. GMean (L1)= 	  =  0.625 +- 0.016, 0.631 +- 0.038, 0.582 +- 0.034, 0.603 +- 0.032
Faith. Aritm (KL)= 		  =  0.623 +- 0.016, 0.722 +- 0.051, 0.678 +- 0.035, 0.694 +- 0.034
Faith. Armon (KL)= 		  =  0.582 +- 0.035, 0.694 +- 0.062, 0.554 +- 0.075, 0.555 +- 0.075
Faith. GMean (KL)= 	  =  0.602 +- 0.024, 0.708 +- 0.056, 0.612 +- 0.058, 0.620 +- 0.058

Eval split test
Faith. Aritm (L1)= 		  =  0.502 +- 0.012, 0.586 +- 0.012, 0.638 +- 0.012, 0.720 +- 0.010
Faith. Armon (L1)= 		  =  0.496 +- 0.021, 0.580 +- 0.015, 0.583 +- 0.017, 0.611 +- 0.020
Faith. GMean (L1)= 	  =  0.499 +- 0.016, 0.583 +- 0.013, 0.610 +- 0.014, 0.663 +- 0.015
Faith. Aritm (KL)= 		  =  0.496 +- 0.016, 0.612 +- 0.020, 0.682 +- 0.020, 0.735 +- 0.024
Faith. Armon (KL)= 		  =  0.485 +- 0.011, 0.603 +- 0.026, 0.628 +- 0.035, 0.637 +- 0.047
Faith. GMean (KL)= 	  =  0.490 +- 0.011, 0.608 +- 0.022, 0.654 +- 0.027, 0.684 +- 0.037
Computed for split load_split = id



Completed in  0:17:14.653904  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis anneal

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:31:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:31:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.8901
Train Loss: 0.4934
ID Validation ACCURACY: 0.8897
ID Validation Loss: 0.4995
ID Test ACCURACY: 0.8760
ID Test Loss: 0.5300
OOD Validation ACCURACY: 0.9067
OOD Validation Loss: 0.5424
OOD Test ACCURACY: 0.7153
OOD Test Loss: 0.9121

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.8639
Train Loss: 0.5056
ID Validation ACCURACY: 0.8597
ID Validation Loss: 0.5045
ID Test ACCURACY: 0.8623
ID Test Loss: 0.5278
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.5019
OOD Test ACCURACY: 0.7467
OOD Test Loss: 0.7172

[0m[1;37mINFO[0m: [1mChartInfo 0.8760 0.7153 0.8623 0.7467 0.8597 0.9307[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.692
WIoU for r=0.3 = 0.669
F1 for r=0.6 = 0.621
WIoU for r=0.6 = 0.736
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.737
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.737
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.997
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.997
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.997
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.997
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.583
WIoU for r=0.3 = 0.492
F1 for r=0.6 = 0.464
WIoU for r=0.6 = 0.398
F1 for r=0.9 = 0.422
WIoU for r=0.9 = 0.387
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.387


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  0.6917525000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.66936625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.474
SUFF++ for r=0.3 class 0 = 0.41 +- 0.299 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.667 +- 0.299 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.477 +- 0.299 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.445 +- 0.299 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.519 +- 0.195 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  0.6207474999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7363325000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.666
SUFF++ for r=0.6 class 0 = 0.505 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 1 = 0.654 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 2 = 0.531 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all KL = 0.573 +- 0.267 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all L1 = 0.564 +- 0.174 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.48086124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7370887500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0 = 0.791 +- 0.221 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 1 = 0.767 +- 0.221 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 2 = 0.803 +- 0.221 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all KL = 0.846 +- 0.221 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all L1 = 0.787 +- 0.186 (in-sample avg dev_std = 0.270)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.904
Model XAI F1 of binarized graphs for r=0.3 =  0.6680525
Model XAI WIoU of binarized graphs for r=0.3 =  0.9969125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.524
SUFF++ for r=0.3 class 0 = 0.308 +- 0.334 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 class 1 = 0.599 +- 0.334 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 class 2 = 0.373 +- 0.334 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all KL = 0.329 +- 0.334 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all L1 = 0.425 +- 0.180 (in-sample avg dev_std = 0.604)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.904
Model XAI F1 of binarized graphs for r=0.6 =  0.40885750000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.9969125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.485 +- 0.250 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 class 1 = 0.609 +- 0.250 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 class 2 = 0.513 +- 0.250 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all KL = 0.573 +- 0.250 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all L1 = 0.535 +- 0.129 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.2951275
Model XAI WIoU of binarized graphs for r=0.9 =  0.9969125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.704
SUFF++ for r=0.9 class 0 = 0.629 +- 0.260 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 class 1 = 0.817 +- 0.260 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 class 2 = 0.515 +- 0.260 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all KL = 0.738 +- 0.260 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all L1 = 0.652 +- 0.207 (in-sample avg dev_std = 0.338)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.43
Model XAI F1 of binarized graphs for r=0.3 =  0.5834999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.49242874999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.432
SUFF++ for r=0.3 class 0 = 0.541 +- 0.266 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 1 = 0.584 +- 0.266 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 2 = 0.529 +- 0.266 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all KL = 0.548 +- 0.266 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all L1 = 0.552 +- 0.211 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  0.46399
Model XAI WIoU of binarized graphs for r=0.6 =  0.3984825
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.555
SUFF++ for r=0.6 class 0 = 0.475 +- 0.221 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 1 = 0.468 +- 0.221 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 class 2 = 0.499 +- 0.221 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all KL = 0.466 +- 0.221 (in-sample avg dev_std = 0.519)
SUFF++ for r=0.6 all L1 = 0.481 +- 0.150 (in-sample avg dev_std = 0.519)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  0.42193624999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.38656875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.684
SUFF++ for r=0.9 class 0 = 0.6 +- 0.254 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 class 1 = 0.524 +- 0.254 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 class 2 = 0.698 +- 0.254 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 all KL = 0.675 +- 0.254 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.9 all L1 = 0.607 +- 0.223 (in-sample avg dev_std = 0.354)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  0.6917525000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.66936625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.316
NEC for r=0.3 class 0 = 0.591 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.3 class 1 = 0.56 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.3 class 2 = 0.567 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.3 all KL = 0.631 +- 0.299 (in-sample avg dev_std = 0.440)
NEC for r=0.3 all L1 = 0.573 +- 0.184 (in-sample avg dev_std = 0.440)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  0.6207474999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7363325000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.415
NEC for r=0.6 class 0 = 0.57 +- 0.287 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 1 = 0.537 +- 0.287 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 2 = 0.58 +- 0.287 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all KL = 0.574 +- 0.287 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all L1 = 0.562 +- 0.155 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.48086124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7370887500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.476
NEC for r=0.9 class 0 = 0.514 +- 0.282 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 1 = 0.508 +- 0.282 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 2 = 0.528 +- 0.282 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all KL = 0.479 +- 0.282 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all L1 = 0.516 +- 0.154 (in-sample avg dev_std = 0.471)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7370399999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.491
NEC for r=1.0 class 0 = 0.504 +- 0.275 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 1 = 0.496 +- 0.275 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 2 = 0.51 +- 0.275 (in-sample avg dev_std = 0.447)
NEC for r=1.0 all KL = 0.45 +- 0.275 (in-sample avg dev_std = 0.447)
NEC for r=1.0 all L1 = 0.503 +- 0.158 (in-sample avg dev_std = 0.447)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.904
Model XAI F1 of binarized graphs for r=0.3 =  0.6680525
Model XAI WIoU of binarized graphs for r=0.3 =  0.9969125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.75 +- 0.290 (in-sample avg dev_std = 0.491)
NEC for r=0.3 class 1 = 0.523 +- 0.290 (in-sample avg dev_std = 0.491)
NEC for r=0.3 class 2 = 0.724 +- 0.290 (in-sample avg dev_std = 0.491)
NEC for r=0.3 all KL = 0.746 +- 0.290 (in-sample avg dev_std = 0.491)
NEC for r=0.3 all L1 = 0.667 +- 0.154 (in-sample avg dev_std = 0.491)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.904
Model XAI F1 of binarized graphs for r=0.6 =  0.40885750000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.9969125
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.466
NEC for r=0.6 class 0 = 0.628 +- 0.257 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 1 = 0.48 +- 0.257 (in-sample avg dev_std = 0.522)
NEC for r=0.6 class 2 = 0.565 +- 0.257 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all KL = 0.544 +- 0.257 (in-sample avg dev_std = 0.522)
NEC for r=0.6 all L1 = 0.559 +- 0.132 (in-sample avg dev_std = 0.522)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.2951275
Model XAI WIoU of binarized graphs for r=0.9 =  0.9969125
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.516 +- 0.227 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 1 = 0.408 +- 0.227 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 2 = 0.49 +- 0.227 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all KL = 0.385 +- 0.227 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all L1 = 0.472 +- 0.127 (in-sample avg dev_std = 0.471)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.906
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9969125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.491 +- 0.224 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 1 = 0.387 +- 0.224 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 2 = 0.496 +- 0.224 (in-sample avg dev_std = 0.461)
NEC for r=1.0 all KL = 0.364 +- 0.224 (in-sample avg dev_std = 0.461)
NEC for r=1.0 all L1 = 0.459 +- 0.129 (in-sample avg dev_std = 0.461)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.43
Model XAI F1 of binarized graphs for r=0.3 =  0.5834999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.49242874999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.444
NEC for r=0.3 class 0 = 0.493 +- 0.290 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 1 = 0.401 +- 0.290 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 2 = 0.525 +- 0.290 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all KL = 0.456 +- 0.290 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all L1 = 0.472 +- 0.226 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.635
Model XAI F1 of binarized graphs for r=0.6 =  0.46399
Model XAI WIoU of binarized graphs for r=0.6 =  0.3984825
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.462
NEC for r=0.6 class 0 = 0.569 +- 0.256 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 1 = 0.532 +- 0.256 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 2 = 0.597 +- 0.256 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all KL = 0.563 +- 0.256 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all L1 = 0.565 +- 0.154 (in-sample avg dev_std = 0.529)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  0.42193624999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.38656875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.542
NEC for r=0.9 class 0 = 0.468 +- 0.260 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 1 = 0.508 +- 0.260 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 2 = 0.524 +- 0.260 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all KL = 0.473 +- 0.260 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all L1 = 0.501 +- 0.155 (in-sample avg dev_std = 0.504)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.77
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.38656875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.554
NEC for r=1.0 class 0 = 0.453 +- 0.274 (in-sample avg dev_std = 0.505)
NEC for r=1.0 class 1 = 0.518 +- 0.274 (in-sample avg dev_std = 0.505)
NEC for r=1.0 class 2 = 0.505 +- 0.274 (in-sample avg dev_std = 0.505)
NEC for r=1.0 all KL = 0.469 +- 0.274 (in-sample avg dev_std = 0.505)
NEC for r=1.0 all L1 = 0.493 +- 0.158 (in-sample avg dev_std = 0.505)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:35:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:35:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 152...
[0m[1;37mINFO[0m: [1mCheckpoint 152: 
-----------------------------------
Train ACCURACY: 0.9000
Train Loss: 0.4476
ID Validation ACCURACY: 0.9097
ID Validation Loss: 0.4245
ID Test ACCURACY: 0.8963
ID Test Loss: 0.4636
OOD Validation ACCURACY: 0.8920
OOD Validation Loss: 0.5712
OOD Test ACCURACY: 0.9130
OOD Test Loss: 0.4368

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.8113
Train Loss: 0.5429
ID Validation ACCURACY: 0.8193
ID Validation Loss: 0.5271
ID Test ACCURACY: 0.8157
ID Test Loss: 0.5510
OOD Validation ACCURACY: 0.9283
OOD Validation Loss: 0.5315
OOD Test ACCURACY: 0.8203
OOD Test Loss: 0.5604

[0m[1;37mINFO[0m: [1mChartInfo 0.8963 0.9130 0.8157 0.8203 0.8193 0.9283[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.670
WIoU for r=0.3 = 0.625
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.773
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.778
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.778
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.995
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.995
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.995
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.995
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.783
WIoU for r=0.3 = 0.900
F1 for r=0.6 = 0.565
WIoU for r=0.6 = 0.843
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.838
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.838


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.6702000000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.62483
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.417
SUFF++ for r=0.3 class 0 = 0.565 +- 0.300 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 1 = 0.675 +- 0.300 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 2 = 0.501 +- 0.300 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all KL = 0.594 +- 0.300 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all L1 = 0.581 +- 0.189 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  0.62475875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7730825
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0 = 0.582 +- 0.286 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.286 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 class 2 = 0.521 +- 0.286 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all KL = 0.552 +- 0.286 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.6 all L1 = 0.589 +- 0.190 (in-sample avg dev_std = 0.550)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7775749999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.84
SUFF++ for r=0.9 class 0 = 0.803 +- 0.198 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 1 = 0.791 +- 0.198 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 2 = 0.822 +- 0.198 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all KL = 0.863 +- 0.198 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all L1 = 0.805 +- 0.206 (in-sample avg dev_std = 0.214)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.865
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9949512500000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.53
SUFF++ for r=0.3 class 0 = 0.37 +- 0.317 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 1 = 0.577 +- 0.317 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 2 = 0.368 +- 0.317 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all KL = 0.374 +- 0.317 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all L1 = 0.437 +- 0.155 (in-sample avg dev_std = 0.617)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9949512500000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.691
SUFF++ for r=0.6 class 0 = 0.565 +- 0.197 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 1 = 0.57 +- 0.197 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 class 2 = 0.671 +- 0.197 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all KL = 0.705 +- 0.197 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.6 all L1 = 0.602 +- 0.138 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.29499375
Model XAI WIoU of binarized graphs for r=0.9 =  0.9949512500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.839
SUFF++ for r=0.9 class 0 = 0.805 +- 0.080 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 class 1 = 0.822 +- 0.080 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 class 2 = 0.884 +- 0.080 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 all KL = 0.939 +- 0.080 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.9 all L1 = 0.837 +- 0.124 (in-sample avg dev_std = 0.188)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.7825075000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9001425000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.563 +- 0.277 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 1 = 0.678 +- 0.277 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 class 2 = 0.465 +- 0.277 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all KL = 0.488 +- 0.277 (in-sample avg dev_std = 0.620)
SUFF++ for r=0.3 all L1 = 0.57 +- 0.156 (in-sample avg dev_std = 0.620)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.92
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8427875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.667
SUFF++ for r=0.6 class 0 = 0.57 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 class 1 = 0.668 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 class 2 = 0.466 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 all KL = 0.529 +- 0.324 (in-sample avg dev_std = 0.605)
SUFF++ for r=0.6 all L1 = 0.569 +- 0.192 (in-sample avg dev_std = 0.605)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.8379575
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.807
SUFF++ for r=0.9 class 0 = 0.859 +- 0.310 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 1 = 0.765 +- 0.310 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 class 2 = 0.748 +- 0.310 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 all KL = 0.801 +- 0.310 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.9 all L1 = 0.79 +- 0.226 (in-sample avg dev_std = 0.322)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.6702000000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.62483
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.348
NEC for r=0.3 class 0 = 0.5 +- 0.303 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 1 = 0.514 +- 0.303 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 2 = 0.533 +- 0.303 (in-sample avg dev_std = 0.409)
NEC for r=0.3 all KL = 0.505 +- 0.303 (in-sample avg dev_std = 0.409)
NEC for r=0.3 all L1 = 0.516 +- 0.194 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  0.62475875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7730825
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.475
NEC for r=0.6 class 0 = 0.572 +- 0.304 (in-sample avg dev_std = 0.467)
NEC for r=0.6 class 1 = 0.513 +- 0.304 (in-sample avg dev_std = 0.467)
NEC for r=0.6 class 2 = 0.586 +- 0.304 (in-sample avg dev_std = 0.467)
NEC for r=0.6 all KL = 0.582 +- 0.304 (in-sample avg dev_std = 0.467)
NEC for r=0.6 all L1 = 0.556 +- 0.173 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7775749999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.518
NEC for r=0.9 class 0 = 0.505 +- 0.292 (in-sample avg dev_std = 0.500)
NEC for r=0.9 class 1 = 0.478 +- 0.292 (in-sample avg dev_std = 0.500)
NEC for r=0.9 class 2 = 0.533 +- 0.292 (in-sample avg dev_std = 0.500)
NEC for r=0.9 all KL = 0.502 +- 0.292 (in-sample avg dev_std = 0.500)
NEC for r=0.9 all L1 = 0.505 +- 0.164 (in-sample avg dev_std = 0.500)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7775637500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.526
NEC for r=1.0 class 0 = 0.503 +- 0.283 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 1 = 0.479 +- 0.283 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 2 = 0.508 +- 0.283 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all KL = 0.484 +- 0.283 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all L1 = 0.497 +- 0.154 (in-sample avg dev_std = 0.490)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.865
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9949512500000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.351
NEC for r=0.3 class 0 = 0.664 +- 0.293 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 1 = 0.538 +- 0.293 (in-sample avg dev_std = 0.470)
NEC for r=0.3 class 2 = 0.74 +- 0.293 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all KL = 0.691 +- 0.293 (in-sample avg dev_std = 0.470)
NEC for r=0.3 all L1 = 0.649 +- 0.136 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9949512500000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.488
NEC for r=0.6 class 0 = 0.54 +- 0.232 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 1 = 0.482 +- 0.232 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 2 = 0.576 +- 0.232 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all KL = 0.45 +- 0.232 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all L1 = 0.533 +- 0.119 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  0.29499375
Model XAI WIoU of binarized graphs for r=0.9 =  0.9949512500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.547
NEC for r=0.9 class 0 = 0.452 +- 0.187 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 1 = 0.434 +- 0.187 (in-sample avg dev_std = 0.434)
NEC for r=0.9 class 2 = 0.457 +- 0.187 (in-sample avg dev_std = 0.434)
NEC for r=0.9 all KL = 0.324 +- 0.187 (in-sample avg dev_std = 0.434)
NEC for r=0.9 all L1 = 0.448 +- 0.111 (in-sample avg dev_std = 0.434)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.895
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9949512500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.442 +- 0.182 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 1 = 0.422 +- 0.182 (in-sample avg dev_std = 0.425)
NEC for r=1.0 class 2 = 0.455 +- 0.182 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all KL = 0.314 +- 0.182 (in-sample avg dev_std = 0.425)
NEC for r=1.0 all L1 = 0.44 +- 0.113 (in-sample avg dev_std = 0.425)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.699
Model XAI F1 of binarized graphs for r=0.3 =  0.7825075000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.9001425000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.414
NEC for r=0.3 class 0 = 0.553 +- 0.290 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 1 = 0.356 +- 0.290 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 2 = 0.555 +- 0.290 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all KL = 0.522 +- 0.290 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all L1 = 0.486 +- 0.182 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.92
Model XAI F1 of binarized graphs for r=0.6 =  0.5651437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.8427875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.581
NEC for r=0.6 class 0 = 0.468 +- 0.340 (in-sample avg dev_std = 0.545)
NEC for r=0.6 class 1 = 0.405 +- 0.340 (in-sample avg dev_std = 0.545)
NEC for r=0.6 class 2 = 0.538 +- 0.340 (in-sample avg dev_std = 0.545)
NEC for r=0.6 all KL = 0.496 +- 0.340 (in-sample avg dev_std = 0.545)
NEC for r=0.6 all L1 = 0.47 +- 0.189 (in-sample avg dev_std = 0.545)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.8379575
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.62
NEC for r=0.9 class 0 = 0.41 +- 0.312 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 1 = 0.416 +- 0.312 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 2 = 0.465 +- 0.312 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all KL = 0.442 +- 0.312 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all L1 = 0.43 +- 0.173 (in-sample avg dev_std = 0.555)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.8379575
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.627
NEC for r=1.0 class 0 = 0.414 +- 0.308 (in-sample avg dev_std = 0.556)
NEC for r=1.0 class 1 = 0.411 +- 0.308 (in-sample avg dev_std = 0.556)
NEC for r=1.0 class 2 = 0.438 +- 0.308 (in-sample avg dev_std = 0.556)
NEC for r=1.0 all KL = 0.438 +- 0.308 (in-sample avg dev_std = 0.556)
NEC for r=1.0 all L1 = 0.421 +- 0.171 (in-sample avg dev_std = 0.556)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:39:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:39:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ACCURACY: 0.9112
Train Loss: 0.4164
ID Validation ACCURACY: 0.9200
ID Validation Loss: 0.3891
ID Test ACCURACY: 0.9083
ID Test Loss: 0.4443
OOD Validation ACCURACY: 0.9280
OOD Validation Loss: 0.4648
OOD Test ACCURACY: 0.8933
OOD Test Loss: 0.4238

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8866
Train Loss: 0.4728
ID Validation ACCURACY: 0.8907
ID Validation Loss: 0.4594
ID Test ACCURACY: 0.8870
ID Test Loss: 0.5130
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.4993
OOD Test ACCURACY: 0.8790
OOD Test Loss: 0.5129

[0m[1;37mINFO[0m: [1mChartInfo 0.9083 0.8933 0.8870 0.8790 0.8907 0.9307[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.719
WIoU for r=0.3 = 0.690
F1 for r=0.6 = 0.624
WIoU for r=0.6 = 0.797
F1 for r=0.9 = 0.480
WIoU for r=0.9 = 0.801
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.801
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.669
WIoU for r=0.3 = 0.986
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.986
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.986
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.986
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.765
WIoU for r=0.3 = 0.745
F1 for r=0.6 = 0.563
WIoU for r=0.6 = 0.692
F1 for r=0.9 = 0.422
WIoU for r=0.9 = 0.684
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.684


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.7185000000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.690385
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.465
SUFF++ for r=0.3 class 0 = 0.624 +- 0.350 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 1 = 0.831 +- 0.350 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 class 2 = 0.586 +- 0.350 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all KL = 0.59 +- 0.350 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.3 all L1 = 0.681 +- 0.244 (in-sample avg dev_std = 0.527)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  0.624475
Model XAI WIoU of binarized graphs for r=0.6 =  0.79714375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.713
SUFF++ for r=0.6 class 0 = 0.522 +- 0.317 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 1 = 0.734 +- 0.317 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 2 = 0.563 +- 0.317 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all KL = 0.554 +- 0.317 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all L1 = 0.607 +- 0.228 (in-sample avg dev_std = 0.490)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.48027625
Model XAI WIoU of binarized graphs for r=0.9 =  0.8009899999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0 = 0.766 +- 0.189 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 1 = 0.818 +- 0.189 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 class 2 = 0.817 +- 0.189 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all KL = 0.847 +- 0.189 (in-sample avg dev_std = 0.298)
SUFF++ for r=0.9 all L1 = 0.8 +- 0.160 (in-sample avg dev_std = 0.298)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6691775000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.98602
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.564
SUFF++ for r=0.3 class 0 = 0.298 +- 0.358 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 1 = 0.707 +- 0.358 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 2 = 0.389 +- 0.358 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all KL = 0.333 +- 0.358 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all L1 = 0.462 +- 0.227 (in-sample avg dev_std = 0.623)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.9857724999999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.657
SUFF++ for r=0.6 class 0 = 0.437 +- 0.249 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 1 = 0.614 +- 0.249 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 2 = 0.561 +- 0.249 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all KL = 0.56 +- 0.249 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all L1 = 0.537 +- 0.137 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9857512500000002
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.807
SUFF++ for r=0.9 class 0 = 0.569 +- 0.171 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 1 = 0.808 +- 0.171 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 class 2 = 0.773 +- 0.171 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all KL = 0.811 +- 0.171 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.9 all L1 = 0.716 +- 0.157 (in-sample avg dev_std = 0.340)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  0.7653725
Model XAI WIoU of binarized graphs for r=0.3 =  0.7446050000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0 = 0.587 +- 0.291 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 class 1 = 0.898 +- 0.291 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 class 2 = 0.58 +- 0.291 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 all KL = 0.62 +- 0.291 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 all L1 = 0.691 +- 0.223 (in-sample avg dev_std = 0.569)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.56301625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6915625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.766
SUFF++ for r=0.6 class 0 = 0.568 +- 0.292 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 1 = 0.788 +- 0.292 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 2 = 0.711 +- 0.292 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all KL = 0.677 +- 0.292 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all L1 = 0.691 +- 0.174 (in-sample avg dev_std = 0.482)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4221725
Model XAI WIoU of binarized graphs for r=0.9 =  0.68436625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0 = 0.813 +- 0.169 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 1 = 0.806 +- 0.169 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 2 = 0.818 +- 0.169 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all KL = 0.86 +- 0.169 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.123 (in-sample avg dev_std = 0.259)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  0.7185000000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.690385
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.307
NEC for r=0.3 class 0 = 0.571 +- 0.300 (in-sample avg dev_std = 0.491)
NEC for r=0.3 class 1 = 0.57 +- 0.300 (in-sample avg dev_std = 0.491)
NEC for r=0.3 class 2 = 0.56 +- 0.300 (in-sample avg dev_std = 0.491)
NEC for r=0.3 all KL = 0.676 +- 0.300 (in-sample avg dev_std = 0.491)
NEC for r=0.3 all L1 = 0.567 +- 0.220 (in-sample avg dev_std = 0.491)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  0.624475
Model XAI WIoU of binarized graphs for r=0.6 =  0.79714375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.435
NEC for r=0.6 class 0 = 0.624 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 1 = 0.513 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 2 = 0.583 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all KL = 0.625 +- 0.304 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all L1 = 0.573 +- 0.162 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.48027625
Model XAI WIoU of binarized graphs for r=0.9 =  0.8009899999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.52
NEC for r=0.9 class 0 = 0.556 +- 0.291 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 1 = 0.483 +- 0.291 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 2 = 0.545 +- 0.291 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all KL = 0.54 +- 0.291 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all L1 = 0.528 +- 0.160 (in-sample avg dev_std = 0.541)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.80097125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.532
NEC for r=1.0 class 0 = 0.548 +- 0.293 (in-sample avg dev_std = 0.530)
NEC for r=1.0 class 1 = 0.486 +- 0.293 (in-sample avg dev_std = 0.530)
NEC for r=1.0 class 2 = 0.515 +- 0.293 (in-sample avg dev_std = 0.530)
NEC for r=1.0 all KL = 0.525 +- 0.293 (in-sample avg dev_std = 0.530)
NEC for r=1.0 all L1 = 0.516 +- 0.164 (in-sample avg dev_std = 0.530)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6691775000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.98602
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.37
NEC for r=0.3 class 0 = 0.746 +- 0.244 (in-sample avg dev_std = 0.488)
NEC for r=0.3 class 1 = 0.574 +- 0.244 (in-sample avg dev_std = 0.488)
NEC for r=0.3 class 2 = 0.703 +- 0.244 (in-sample avg dev_std = 0.488)
NEC for r=0.3 all KL = 0.787 +- 0.244 (in-sample avg dev_std = 0.488)
NEC for r=0.3 all L1 = 0.675 +- 0.126 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.9857724999999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.492
NEC for r=0.6 class 0 = 0.615 +- 0.270 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.464 +- 0.270 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.581 +- 0.270 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.535 +- 0.270 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.554 +- 0.141 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.9857512500000002
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.555
NEC for r=0.9 class 0 = 0.513 +- 0.224 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 1 = 0.425 +- 0.224 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 2 = 0.49 +- 0.224 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all KL = 0.398 +- 0.224 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all L1 = 0.477 +- 0.124 (in-sample avg dev_std = 0.482)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9857475
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.502 +- 0.216 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 1 = 0.419 +- 0.216 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 2 = 0.456 +- 0.216 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all KL = 0.374 +- 0.216 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all L1 = 0.459 +- 0.124 (in-sample avg dev_std = 0.473)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  0.7653725
Model XAI WIoU of binarized graphs for r=0.3 =  0.7446050000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.379
NEC for r=0.3 class 0 = 0.461 +- 0.324 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 1 = 0.363 +- 0.324 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 2 = 0.506 +- 0.324 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all KL = 0.496 +- 0.324 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all L1 = 0.443 +- 0.237 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.56301625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6915625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.528
NEC for r=0.6 class 0 = 0.586 +- 0.308 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 1 = 0.412 +- 0.308 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 2 = 0.594 +- 0.308 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all KL = 0.561 +- 0.308 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all L1 = 0.529 +- 0.182 (in-sample avg dev_std = 0.562)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.4221725
Model XAI WIoU of binarized graphs for r=0.9 =  0.68436625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.495 +- 0.303 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 1 = 0.378 +- 0.303 (in-sample avg dev_std = 0.572)
NEC for r=0.9 class 2 = 0.478 +- 0.303 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all KL = 0.458 +- 0.303 (in-sample avg dev_std = 0.572)
NEC for r=0.9 all L1 = 0.449 +- 0.169 (in-sample avg dev_std = 0.572)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.906
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.68436625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.633
NEC for r=1.0 class 0 = 0.483 +- 0.295 (in-sample avg dev_std = 0.572)
NEC for r=1.0 class 1 = 0.387 +- 0.295 (in-sample avg dev_std = 0.572)
NEC for r=1.0 class 2 = 0.46 +- 0.295 (in-sample avg dev_std = 0.572)
NEC for r=1.0 all KL = 0.454 +- 0.295 (in-sample avg dev_std = 0.572)
NEC for r=1.0 all L1 = 0.442 +- 0.161 (in-sample avg dev_std = 0.572)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:43:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:43:10 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 0.8811
Train Loss: 0.4941
ID Validation ACCURACY: 0.8810
ID Validation Loss: 0.4846
ID Test ACCURACY: 0.8770
ID Test Loss: 0.5137
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4928
OOD Test ACCURACY: 0.8760
OOD Test Loss: 0.5085

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.8485
Train Loss: 0.5228
ID Validation ACCURACY: 0.8473
ID Validation Loss: 0.5171
ID Test ACCURACY: 0.8530
ID Test Loss: 0.5301
OOD Validation ACCURACY: 0.9303
OOD Validation Loss: 0.5290
OOD Test ACCURACY: 0.7783
OOD Test Loss: 0.8339

[0m[1;37mINFO[0m: [1mChartInfo 0.8770 0.8760 0.8530 0.7783 0.8473 0.9303[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.723
WIoU for r=0.3 = 0.710
F1 for r=0.6 = 0.619
WIoU for r=0.6 = 0.800
F1 for r=0.9 = 0.479
WIoU for r=0.9 = 0.804
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.804
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.667
WIoU for r=0.3 = 0.946
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.946
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.946
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.946
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.675
WIoU for r=0.3 = 0.823
F1 for r=0.6 = 0.522
WIoU for r=0.6 = 0.818
F1 for r=0.9 = 0.421
WIoU for r=0.9 = 0.781
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.779


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.7226849999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7100699999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.456
SUFF++ for r=0.3 class 0 = 0.557 +- 0.297 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 1 = 0.727 +- 0.297 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 2 = 0.527 +- 0.297 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all KL = 0.595 +- 0.297 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all L1 = 0.604 +- 0.188 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  0.6189175
Model XAI WIoU of binarized graphs for r=0.6 =  0.8001875000000002
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.682
SUFF++ for r=0.6 class 0 = 0.513 +- 0.303 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.758 +- 0.303 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.599 +- 0.303 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.58 +- 0.303 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.624 +- 0.209 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.47899249999999993
Model XAI WIoU of binarized graphs for r=0.9 =  0.80402125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.796
SUFF++ for r=0.9 class 0 = 0.777 +- 0.253 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 class 1 = 0.808 +- 0.253 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 class 2 = 0.782 +- 0.253 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 all KL = 0.83 +- 0.253 (in-sample avg dev_std = 0.306)
SUFF++ for r=0.9 all L1 = 0.789 +- 0.217 (in-sample avg dev_std = 0.306)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.929
Model XAI F1 of binarized graphs for r=0.3 =  0.66746
Model XAI WIoU of binarized graphs for r=0.3 =  0.94558625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.547
SUFF++ for r=0.3 class 0 = 0.328 +- 0.319 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 class 1 = 0.649 +- 0.319 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 class 2 = 0.414 +- 0.319 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 all KL = 0.362 +- 0.319 (in-sample avg dev_std = 0.606)
SUFF++ for r=0.3 all L1 = 0.462 +- 0.195 (in-sample avg dev_std = 0.606)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.94558625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.631
SUFF++ for r=0.6 class 0 = 0.461 +- 0.230 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1 = 0.581 +- 0.230 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 2 = 0.584 +- 0.230 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.614 +- 0.230 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.541 +- 0.150 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29499375
Model XAI WIoU of binarized graphs for r=0.9 =  0.94558625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.848
SUFF++ for r=0.9 class 0 = 0.833 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 1 = 0.766 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all KL = 0.916 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all L1 = 0.817 +- 0.158 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  0.67487125
Model XAI WIoU of binarized graphs for r=0.3 =  0.82283375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.538
SUFF++ for r=0.3 class 0 = 0.619 +- 0.289 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 1 = 0.66 +- 0.289 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 2 = 0.613 +- 0.289 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all KL = 0.618 +- 0.289 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all L1 = 0.631 +- 0.194 (in-sample avg dev_std = 0.498)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  0.5218812500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.81814125
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.741
SUFF++ for r=0.6 class 0 = 0.572 +- 0.289 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 1 = 0.69 +- 0.289 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.289 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all KL = 0.673 +- 0.289 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.6 all L1 = 0.648 +- 0.208 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  0.42076499999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.7811224999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0 = 0.742 +- 0.115 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 1 = 0.909 +- 0.115 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 2 = 0.855 +- 0.115 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all KL = 0.902 +- 0.115 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all L1 = 0.837 +- 0.138 (in-sample avg dev_std = 0.193)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.7226849999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7100699999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.519 +- 0.296 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1 = 0.561 +- 0.296 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 2 = 0.535 +- 0.296 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.553 +- 0.296 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.538 +- 0.173 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  0.6189175
Model XAI WIoU of binarized graphs for r=0.6 =  0.8001875000000002
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.449
NEC for r=0.6 class 0 = 0.569 +- 0.314 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 1 = 0.535 +- 0.314 (in-sample avg dev_std = 0.465)
NEC for r=0.6 class 2 = 0.616 +- 0.314 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all KL = 0.62 +- 0.314 (in-sample avg dev_std = 0.465)
NEC for r=0.6 all L1 = 0.573 +- 0.169 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.876
Model XAI F1 of binarized graphs for r=0.9 =  0.47899249999999993
Model XAI WIoU of binarized graphs for r=0.9 =  0.80402125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.521
NEC for r=0.9 class 0 = 0.507 +- 0.312 (in-sample avg dev_std = 0.518)
NEC for r=0.9 class 1 = 0.474 +- 0.312 (in-sample avg dev_std = 0.518)
NEC for r=0.9 class 2 = 0.536 +- 0.312 (in-sample avg dev_std = 0.518)
NEC for r=0.9 all KL = 0.514 +- 0.312 (in-sample avg dev_std = 0.518)
NEC for r=0.9 all L1 = 0.505 +- 0.171 (in-sample avg dev_std = 0.518)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.80431
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.524
NEC for r=1.0 class 0 = 0.513 +- 0.308 (in-sample avg dev_std = 0.505)
NEC for r=1.0 class 1 = 0.474 +- 0.308 (in-sample avg dev_std = 0.505)
NEC for r=1.0 class 2 = 0.521 +- 0.308 (in-sample avg dev_std = 0.505)
NEC for r=1.0 all KL = 0.499 +- 0.308 (in-sample avg dev_std = 0.505)
NEC for r=1.0 all L1 = 0.503 +- 0.171 (in-sample avg dev_std = 0.505)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.929
Model XAI F1 of binarized graphs for r=0.3 =  0.66746
Model XAI WIoU of binarized graphs for r=0.3 =  0.94558625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.369
NEC for r=0.3 class 0 = 0.662 +- 0.263 (in-sample avg dev_std = 0.450)
NEC for r=0.3 class 1 = 0.584 +- 0.263 (in-sample avg dev_std = 0.450)
NEC for r=0.3 class 2 = 0.714 +- 0.263 (in-sample avg dev_std = 0.450)
NEC for r=0.3 all KL = 0.735 +- 0.263 (in-sample avg dev_std = 0.450)
NEC for r=0.3 all L1 = 0.654 +- 0.122 (in-sample avg dev_std = 0.450)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.929
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.94558625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.539 +- 0.244 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 1 = 0.447 +- 0.244 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 2 = 0.56 +- 0.244 (in-sample avg dev_std = 0.480)
NEC for r=0.6 all KL = 0.445 +- 0.244 (in-sample avg dev_std = 0.480)
NEC for r=0.6 all L1 = 0.516 +- 0.127 (in-sample avg dev_std = 0.480)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.29499375
Model XAI WIoU of binarized graphs for r=0.9 =  0.94558625
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.553
NEC for r=0.9 class 0 = 0.46 +- 0.209 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 1 = 0.395 +- 0.209 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 2 = 0.49 +- 0.209 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all KL = 0.328 +- 0.209 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all L1 = 0.449 +- 0.127 (in-sample avg dev_std = 0.429)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.94558625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.443 +- 0.201 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 1 = 0.389 +- 0.201 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 2 = 0.479 +- 0.201 (in-sample avg dev_std = 0.423)
NEC for r=1.0 all KL = 0.312 +- 0.201 (in-sample avg dev_std = 0.423)
NEC for r=1.0 all L1 = 0.438 +- 0.123 (in-sample avg dev_std = 0.423)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  0.67487125
Model XAI WIoU of binarized graphs for r=0.3 =  0.82283375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.379
NEC for r=0.3 class 0 = 0.493 +- 0.286 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 1 = 0.586 +- 0.286 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 2 = 0.551 +- 0.286 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all KL = 0.549 +- 0.286 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all L1 = 0.544 +- 0.171 (in-sample avg dev_std = 0.453)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.723
Model XAI F1 of binarized graphs for r=0.6 =  0.5218812500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.81814125
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.484
NEC for r=0.6 class 0 = 0.446 +- 0.332 (in-sample avg dev_std = 0.502)
NEC for r=0.6 class 1 = 0.429 +- 0.332 (in-sample avg dev_std = 0.502)
NEC for r=0.6 class 2 = 0.551 +- 0.332 (in-sample avg dev_std = 0.502)
NEC for r=0.6 all KL = 0.473 +- 0.332 (in-sample avg dev_std = 0.502)
NEC for r=0.6 all L1 = 0.475 +- 0.216 (in-sample avg dev_std = 0.502)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  0.42076499999999994
Model XAI WIoU of binarized graphs for r=0.9 =  0.7811224999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0 = 0.402 +- 0.300 (in-sample avg dev_std = 0.505)
NEC for r=0.9 class 1 = 0.366 +- 0.300 (in-sample avg dev_std = 0.505)
NEC for r=0.9 class 2 = 0.461 +- 0.300 (in-sample avg dev_std = 0.505)
NEC for r=0.9 all KL = 0.383 +- 0.300 (in-sample avg dev_std = 0.505)
NEC for r=0.9 all L1 = 0.409 +- 0.205 (in-sample avg dev_std = 0.505)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.77948375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.586
NEC for r=1.0 class 0 = 0.384 +- 0.298 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 1 = 0.366 +- 0.298 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 2 = 0.435 +- 0.298 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all KL = 0.375 +- 0.298 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all L1 = 0.395 +- 0.199 (in-sample avg dev_std = 0.511)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:46:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:46:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9193
Train Loss: 0.3937
ID Validation ACCURACY: 0.9260
ID Validation Loss: 0.3685
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4133
OOD Validation ACCURACY: 0.9267
OOD Validation Loss: 0.3917
OOD Test ACCURACY: 0.8700
OOD Test Loss: 0.4601

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 113...
[0m[1;37mINFO[0m: [1mCheckpoint 113: 
-----------------------------------
Train ACCURACY: 0.9197
Train Loss: 0.4116
ID Validation ACCURACY: 0.9253
ID Validation Loss: 0.3892
ID Test ACCURACY: 0.9170
ID Test Loss: 0.4274
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3425
OOD Test ACCURACY: 0.8747
OOD Test Loss: 0.5056

[0m[1;37mINFO[0m: [1mChartInfo 0.9130 0.8700 0.9170 0.8747 0.9253 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.714
WIoU for r=0.3 = 0.665
F1 for r=0.6 = 0.626
WIoU for r=0.6 = 0.731
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.732
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.732
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.666
WIoU for r=0.3 = 0.842
F1 for r=0.6 = 0.410
WIoU for r=0.6 = 0.835
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.835
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.835
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.826
F1 for r=0.6 = 0.546
WIoU for r=0.6 = 0.794
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.758
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.756


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  0.7135499999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6646837500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.512
SUFF++ for r=0.3 class 0 = 0.435 +- 0.262 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.3 class 1 = 0.576 +- 0.262 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.3 class 2 = 0.472 +- 0.262 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.3 all KL = 0.424 +- 0.262 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.3 all L1 = 0.494 +- 0.162 (in-sample avg dev_std = 0.536)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.897
Model XAI F1 of binarized graphs for r=0.6 =  0.62586875
Model XAI WIoU of binarized graphs for r=0.6 =  0.73128625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.782
SUFF++ for r=0.6 class 0 = 0.594 +- 0.279 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 1 = 0.768 +- 0.279 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.279 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all KL = 0.649 +- 0.279 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all L1 = 0.69 +- 0.199 (in-sample avg dev_std = 0.443)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.938
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7322775
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.896
SUFF++ for r=0.9 class 0 = 0.823 +- 0.169 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 1 = 0.865 +- 0.169 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 class 2 = 0.846 +- 0.169 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all KL = 0.89 +- 0.169 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.9 all L1 = 0.845 +- 0.156 (in-sample avg dev_std = 0.210)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.916
Model XAI F1 of binarized graphs for r=0.3 =  0.665545
Model XAI WIoU of binarized graphs for r=0.3 =  0.84192375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.594
SUFF++ for r=0.3 class 0 = 0.327 +- 0.327 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 1 = 0.734 +- 0.327 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 2 = 0.452 +- 0.327 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all KL = 0.343 +- 0.327 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all L1 = 0.502 +- 0.224 (in-sample avg dev_std = 0.628)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.925
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.8352099999999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.816
SUFF++ for r=0.6 class 0 = 0.572 +- 0.220 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 1 = 0.765 +- 0.220 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 class 2 = 0.746 +- 0.220 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all KL = 0.731 +- 0.220 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.6 all L1 = 0.694 +- 0.150 (in-sample avg dev_std = 0.397)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8351100000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.879
SUFF++ for r=0.9 class 0 = 0.779 +- 0.148 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1 = 0.816 +- 0.148 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 2 = 0.829 +- 0.148 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.898 +- 0.148 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.123 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  0.72565875
Model XAI WIoU of binarized graphs for r=0.3 =  0.82625125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.589
SUFF++ for r=0.3 class 0 = 0.522 +- 0.305 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.3 class 1 = 0.672 +- 0.305 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.3 class 2 = 0.65 +- 0.305 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.3 all KL = 0.534 +- 0.305 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.3 all L1 = 0.616 +- 0.186 (in-sample avg dev_std = 0.539)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  0.5462375
Model XAI WIoU of binarized graphs for r=0.6 =  0.79419875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.804
SUFF++ for r=0.6 class 0 = 0.615 +- 0.301 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 1 = 0.778 +- 0.301 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 class 2 = 0.726 +- 0.301 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all KL = 0.671 +- 0.301 (in-sample avg dev_std = 0.464)
SUFF++ for r=0.6 all L1 = 0.708 +- 0.199 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7578825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.879
SUFF++ for r=0.9 class 0 = 0.932 +- 0.072 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 class 1 = 0.804 +- 0.072 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 class 2 = 0.929 +- 0.072 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all KL = 0.95 +- 0.072 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all L1 = 0.887 +- 0.114 (in-sample avg dev_std = 0.131)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.58
Model XAI F1 of binarized graphs for r=0.3 =  0.7135499999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6646837500000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.299
NEC for r=0.3 class 0 = 0.601 +- 0.272 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 1 = 0.577 +- 0.272 (in-sample avg dev_std = 0.427)
NEC for r=0.3 class 2 = 0.578 +- 0.272 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all KL = 0.649 +- 0.272 (in-sample avg dev_std = 0.427)
NEC for r=0.3 all L1 = 0.585 +- 0.150 (in-sample avg dev_std = 0.427)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.62586875
Model XAI WIoU of binarized graphs for r=0.6 =  0.73128625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.435
NEC for r=0.6 class 0 = 0.591 +- 0.279 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 1 = 0.565 +- 0.279 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 2 = 0.623 +- 0.279 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all KL = 0.683 +- 0.279 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all L1 = 0.593 +- 0.152 (in-sample avg dev_std = 0.539)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.938
Model XAI F1 of binarized graphs for r=0.9 =  0.4814387499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.7322775
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.537
NEC for r=0.9 class 0 = 0.521 +- 0.298 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 1 = 0.503 +- 0.298 (in-sample avg dev_std = 0.583)
NEC for r=0.9 class 2 = 0.552 +- 0.298 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all KL = 0.593 +- 0.298 (in-sample avg dev_std = 0.583)
NEC for r=0.9 all L1 = 0.525 +- 0.164 (in-sample avg dev_std = 0.583)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.938
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7322675
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.503 +- 0.301 (in-sample avg dev_std = 0.575)
NEC for r=1.0 class 1 = 0.503 +- 0.301 (in-sample avg dev_std = 0.575)
NEC for r=1.0 class 2 = 0.543 +- 0.301 (in-sample avg dev_std = 0.575)
NEC for r=1.0 all KL = 0.572 +- 0.301 (in-sample avg dev_std = 0.575)
NEC for r=1.0 all L1 = 0.516 +- 0.171 (in-sample avg dev_std = 0.575)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.916
Model XAI F1 of binarized graphs for r=0.3 =  0.665545
Model XAI WIoU of binarized graphs for r=0.3 =  0.84192375
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.375
NEC for r=0.3 class 0 = 0.688 +- 0.162 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 1 = 0.643 +- 0.162 (in-sample avg dev_std = 0.495)
NEC for r=0.3 class 2 = 0.73 +- 0.162 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all KL = 0.842 +- 0.162 (in-sample avg dev_std = 0.495)
NEC for r=0.3 all L1 = 0.687 +- 0.092 (in-sample avg dev_std = 0.495)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.925
Model XAI F1 of binarized graphs for r=0.6 =  0.40952875000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.8352099999999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.488
NEC for r=0.6 class 0 = 0.581 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.6 class 1 = 0.51 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.6 class 2 = 0.613 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.6 all KL = 0.591 +- 0.235 (in-sample avg dev_std = 0.566)
NEC for r=0.6 all L1 = 0.569 +- 0.130 (in-sample avg dev_std = 0.566)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.29536875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8351100000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0 = 0.473 +- 0.217 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 1 = 0.44 +- 0.217 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 2 = 0.515 +- 0.217 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all KL = 0.413 +- 0.217 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all L1 = 0.477 +- 0.127 (in-sample avg dev_std = 0.519)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.928
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.8351100000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.589
NEC for r=1.0 class 0 = 0.43 +- 0.210 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 1 = 0.448 +- 0.210 (in-sample avg dev_std = 0.499)
NEC for r=1.0 class 2 = 0.499 +- 0.210 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all KL = 0.379 +- 0.210 (in-sample avg dev_std = 0.499)
NEC for r=1.0 all L1 = 0.459 +- 0.127 (in-sample avg dev_std = 0.499)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  0.72565875
Model XAI WIoU of binarized graphs for r=0.3 =  0.82625125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.458 +- 0.291 (in-sample avg dev_std = 0.481)
NEC for r=0.3 class 1 = 0.566 +- 0.291 (in-sample avg dev_std = 0.481)
NEC for r=0.3 class 2 = 0.621 +- 0.291 (in-sample avg dev_std = 0.481)
NEC for r=0.3 all KL = 0.621 +- 0.291 (in-sample avg dev_std = 0.481)
NEC for r=0.3 all L1 = 0.549 +- 0.195 (in-sample avg dev_std = 0.481)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  0.5462375
Model XAI WIoU of binarized graphs for r=0.6 =  0.79419875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.474
NEC for r=0.6 class 0 = 0.52 +- 0.313 (in-sample avg dev_std = 0.644)
NEC for r=0.6 class 1 = 0.552 +- 0.313 (in-sample avg dev_std = 0.644)
NEC for r=0.6 class 2 = 0.603 +- 0.313 (in-sample avg dev_std = 0.644)
NEC for r=0.6 all KL = 0.625 +- 0.313 (in-sample avg dev_std = 0.644)
NEC for r=0.6 all L1 = 0.558 +- 0.172 (in-sample avg dev_std = 0.644)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7578825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.59
NEC for r=0.9 class 0 = 0.373 +- 0.292 (in-sample avg dev_std = 0.596)
NEC for r=0.9 class 1 = 0.43 +- 0.292 (in-sample avg dev_std = 0.596)
NEC for r=0.9 class 2 = 0.492 +- 0.292 (in-sample avg dev_std = 0.596)
NEC for r=0.9 all KL = 0.483 +- 0.292 (in-sample avg dev_std = 0.596)
NEC for r=0.9 all L1 = 0.432 +- 0.176 (in-sample avg dev_std = 0.596)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.846
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7558812500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0 = 0.351 +- 0.282 (in-sample avg dev_std = 0.600)
NEC for r=1.0 class 1 = 0.426 +- 0.282 (in-sample avg dev_std = 0.600)
NEC for r=1.0 class 2 = 0.475 +- 0.282 (in-sample avg dev_std = 0.600)
NEC for r=1.0 all KL = 0.459 +- 0.282 (in-sample avg dev_std = 0.600)
NEC for r=1.0 all L1 = 0.418 +- 0.167 (in-sample avg dev_std = 0.600)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.445, 0.573, 0.846, 1.0], 'all_L1': [0.519, 0.564, 0.787, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.594, 0.552, 0.863, 1.0], 'all_L1': [0.581, 0.589, 0.805, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.59, 0.554, 0.847, 1.0], 'all_L1': [0.681, 0.607, 0.8, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.595, 0.58, 0.83, 1.0], 'all_L1': [0.604, 0.624, 0.789, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.424, 0.649, 0.89, 1.0], 'all_L1': [0.494, 0.69, 0.845, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.631, 0.574, 0.479, 0.45], 'all_L1': [0.573, 0.562, 0.516, 0.503]}), defaultdict(<class 'list'>, {'all_KL': [0.505, 0.582, 0.502, 0.484], 'all_L1': [0.516, 0.556, 0.505, 0.497]}), defaultdict(<class 'list'>, {'all_KL': [0.676, 0.625, 0.54, 0.525], 'all_L1': [0.567, 0.573, 0.528, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.553, 0.62, 0.514, 0.499], 'all_L1': [0.538, 0.573, 0.505, 0.503]}), defaultdict(<class 'list'>, {'all_KL': [0.649, 0.683, 0.593, 0.572], 'all_L1': [0.585, 0.593, 0.525, 0.516]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.329, 0.573, 0.738, 1.0], 'all_L1': [0.425, 0.535, 0.652, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.374, 0.705, 0.939, 1.0], 'all_L1': [0.437, 0.602, 0.837, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.333, 0.56, 0.811, 1.0], 'all_L1': [0.462, 0.537, 0.716, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.362, 0.614, 0.916, 1.0], 'all_L1': [0.462, 0.541, 0.817, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.343, 0.731, 0.898, 1.0], 'all_L1': [0.502, 0.694, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.746, 0.544, 0.385, 0.364], 'all_L1': [0.667, 0.559, 0.472, 0.459]}), defaultdict(<class 'list'>, {'all_KL': [0.691, 0.45, 0.324, 0.314], 'all_L1': [0.649, 0.533, 0.448, 0.44]}), defaultdict(<class 'list'>, {'all_KL': [0.787, 0.535, 0.398, 0.374], 'all_L1': [0.675, 0.554, 0.477, 0.459]}), defaultdict(<class 'list'>, {'all_KL': [0.735, 0.445, 0.328, 0.312], 'all_L1': [0.654, 0.516, 0.449, 0.438]}), defaultdict(<class 'list'>, {'all_KL': [0.842, 0.591, 0.413, 0.379], 'all_L1': [0.687, 0.569, 0.477, 0.459]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.548, 0.466, 0.675, 1.0], 'all_L1': [0.552, 0.481, 0.607, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.488, 0.529, 0.801, 1.0], 'all_L1': [0.57, 0.569, 0.79, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.677, 0.86, 1.0], 'all_L1': [0.691, 0.691, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.618, 0.673, 0.902, 1.0], 'all_L1': [0.631, 0.648, 0.837, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.534, 0.671, 0.95, 1.0], 'all_L1': [0.616, 0.708, 0.887, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.456, 0.563, 0.473, 0.469], 'all_L1': [0.472, 0.565, 0.501, 0.493]}), defaultdict(<class 'list'>, {'all_KL': [0.522, 0.496, 0.442, 0.438], 'all_L1': [0.486, 0.47, 0.43, 0.421]}), defaultdict(<class 'list'>, {'all_KL': [0.496, 0.561, 0.458, 0.454], 'all_L1': [0.443, 0.529, 0.449, 0.442]}), defaultdict(<class 'list'>, {'all_KL': [0.549, 0.473, 0.383, 0.375], 'all_L1': [0.544, 0.475, 0.409, 0.395]}), defaultdict(<class 'list'>, {'all_KL': [0.621, 0.625, 0.483, 0.459], 'all_L1': [0.549, 0.558, 0.432, 0.418]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.576 +- 0.066, 0.615 +- 0.043, 0.805 +- 0.021, 1.000 +- 0.000
suff++ class all_KL  =  0.530 +- 0.078, 0.582 +- 0.035, 0.855 +- 0.020, 1.000 +- 0.000
suff++_acc_int  =  0.465 +- 0.031, 0.707 +- 0.041, 0.852 +- 0.033
nec class all_L1  =  0.556 +- 0.025, 0.571 +- 0.013, 0.516 +- 0.010, 0.507 +- 0.008
nec class all_KL  =  0.603 +- 0.064, 0.617 +- 0.039, 0.526 +- 0.039, 0.506 +- 0.041
nec_acc_int  =  0.326 +- 0.024, 0.442 +- 0.020, 0.514 +- 0.020, 0.523 +- 0.018

Eval split val
suff++ class all_L1  =  0.458 +- 0.026, 0.582 +- 0.061, 0.766 +- 0.071, 1.000 +- 0.000
suff++ class all_KL  =  0.348 +- 0.017, 0.637 +- 0.069, 0.860 +- 0.075, 1.000 +- 0.000
suff++_acc_int  =  0.552 +- 0.025, 0.687 +- 0.068, 0.815 +- 0.060
nec class all_L1  =  0.666 +- 0.014, 0.546 +- 0.019, 0.465 +- 0.013, 0.451 +- 0.010
nec class all_KL  =  0.760 +- 0.051, 0.513 +- 0.057, 0.370 +- 0.037, 0.349 +- 0.029
nec_acc_int  =  0.361 +- 0.013, 0.487 +- 0.012, 0.554 +- 0.015, 0.556 +- 0.020

Eval split test
suff++ class all_L1  =  0.612 +- 0.049, 0.619 +- 0.084, 0.787 +- 0.095, 1.000 +- 0.000
suff++ class all_KL  =  0.562 +- 0.051, 0.603 +- 0.089, 0.838 +- 0.095, 1.000 +- 0.000
suff++_acc_int  =  0.539 +- 0.056, 0.707 +- 0.088, 0.818 +- 0.071
nec class all_L1  =  0.499 +- 0.041, 0.519 +- 0.040, 0.444 +- 0.031, 0.434 +- 0.033
nec class all_KL  =  0.529 +- 0.055, 0.544 +- 0.054, 0.448 +- 0.035, 0.439 +- 0.034
nec_acc_int  =  0.392 +- 0.034, 0.506 +- 0.044, 0.592 +- 0.030, 0.603 +- 0.029


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.566 +- 0.031, 0.593 +- 0.027, 0.660 +- 0.013, 0.753 +- 0.004
Faith. Armon (L1)= 		  =  0.563 +- 0.030, 0.592 +- 0.026, 0.629 +- 0.012, 0.673 +- 0.007
Faith. GMean (L1)= 	  =  0.564 +- 0.030, 0.593 +- 0.027, 0.644 +- 0.012, 0.712 +- 0.005
Faith. Aritm (KL)= 		  =  0.566 +- 0.036, 0.599 +- 0.035, 0.690 +- 0.028, 0.753 +- 0.020
Faith. Armon (KL)= 		  =  0.557 +- 0.042, 0.598 +- 0.035, 0.651 +- 0.034, 0.671 +- 0.036
Faith. GMean (KL)= 	  =  0.561 +- 0.039, 0.599 +- 0.035, 0.670 +- 0.031, 0.711 +- 0.029

Eval split val
Faith. Aritm (L1)= 		  =  0.562 +- 0.019, 0.564 +- 0.036, 0.615 +- 0.032, 0.726 +- 0.005
Faith. Armon (L1)= 		  =  0.542 +- 0.022, 0.562 +- 0.034, 0.577 +- 0.017, 0.622 +- 0.009
Faith. GMean (L1)= 	  =  0.552 +- 0.020, 0.563 +- 0.035, 0.596 +- 0.024, 0.672 +- 0.007
Faith. Aritm (KL)= 		  =  0.554 +- 0.021, 0.575 +- 0.046, 0.615 +- 0.031, 0.674 +- 0.015
Faith. Armon (KL)= 		  =  0.476 +- 0.012, 0.565 +- 0.047, 0.514 +- 0.032, 0.516 +- 0.033
Faith. GMean (KL)= 	  =  0.514 +- 0.014, 0.570 +- 0.046, 0.562 +- 0.026, 0.590 +- 0.025

Eval split test
Faith. Aritm (L1)= 		  =  0.555 +- 0.030, 0.569 +- 0.046, 0.615 +- 0.035, 0.717 +- 0.017
Faith. Armon (L1)= 		  =  0.548 +- 0.030, 0.561 +- 0.043, 0.563 +- 0.014, 0.604 +- 0.032
Faith. GMean (L1)= 	  =  0.551 +- 0.030, 0.565 +- 0.045, 0.588 +- 0.023, 0.658 +- 0.025
Faith. Aritm (KL)= 		  =  0.545 +- 0.035, 0.573 +- 0.054, 0.643 +- 0.047, 0.720 +- 0.017
Faith. Armon (KL)= 		  =  0.542 +- 0.035, 0.568 +- 0.055, 0.580 +- 0.036, 0.609 +- 0.033
Faith. GMean (KL)= 	  =  0.543 +- 0.035, 0.571 +- 0.055, 0.611 +- 0.039, 0.662 +- 0.026
Computed for split load_split = id



Completed in  0:19:38.759216  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis topk

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:51:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:51:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 0.8390
Train Loss: 0.5994
ID Validation ACCURACY: 0.8367
ID Validation Loss: 0.6099
ID Test ACCURACY: 0.8283
ID Test Loss: 0.6303
OOD Validation ACCURACY: 0.7063
OOD Validation Loss: 0.7746
OOD Test ACCURACY: 0.8737
OOD Test Loss: 0.5127

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.7172
Train Loss: 0.6782
ID Validation ACCURACY: 0.7113
ID Validation Loss: 0.6858
ID Test ACCURACY: 0.7210
ID Test Loss: 0.7018
OOD Validation ACCURACY: 0.8563
OOD Validation Loss: 0.5707
OOD Test ACCURACY: 0.8887
OOD Test Loss: 0.4610

[0m[1;37mINFO[0m: [1mChartInfo 0.8283 0.8737 0.7210 0.8887 0.7113 0.8563[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.520
WIoU for r=0.3 = 0.470
F1 for r=0.6 = 0.525
WIoU for r=0.6 = 0.564
F1 for r=0.9 = 0.455
WIoU for r=0.9 = 0.593
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.593
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.565
WIoU for r=0.3 = 0.786
F1 for r=0.6 = 0.350
WIoU for r=0.6 = 0.789
F1 for r=0.9 = 0.258
WIoU for r=0.9 = 0.789
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.789
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.476
WIoU for r=0.3 = 0.617
F1 for r=0.6 = 0.520
WIoU for r=0.6 = 0.777
F1 for r=0.9 = 0.394
WIoU for r=0.9 = 0.777
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.777


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.516
Model XAI F1 of binarized graphs for r=0.3 =  0.51966125
Model XAI WIoU of binarized graphs for r=0.3 =  0.47011250000000004
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.415
SUFF++ for r=0.3 class 0 = 0.497 +- 0.240 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 class 1 = 0.573 +- 0.240 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 class 2 = 0.486 +- 0.240 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 all KL = 0.55 +- 0.240 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.3 all L1 = 0.519 +- 0.142 (in-sample avg dev_std = 0.479)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  0.5246175000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.56363125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.594
SUFF++ for r=0.6 class 0 = 0.496 +- 0.268 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 1 = 0.622 +- 0.268 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 2 = 0.528 +- 0.268 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all KL = 0.557 +- 0.268 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all L1 = 0.549 +- 0.162 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  0.4554525
Model XAI WIoU of binarized graphs for r=0.9 =  0.59340125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.721
SUFF++ for r=0.9 class 0 = 0.728 +- 0.189 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 1 = 0.764 +- 0.189 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 2 = 0.759 +- 0.189 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all KL = 0.834 +- 0.189 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all L1 = 0.75 +- 0.179 (in-sample avg dev_std = 0.280)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.684
Model XAI F1 of binarized graphs for r=0.3 =  0.5649712499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.78605625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.457
SUFF++ for r=0.3 class 0 = 0.389 +- 0.249 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 1 = 0.47 +- 0.249 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 class 2 = 0.426 +- 0.249 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all KL = 0.438 +- 0.249 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.3 all L1 = 0.428 +- 0.123 (in-sample avg dev_std = 0.508)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  0.34991874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.7892137499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.575
SUFF++ for r=0.6 class 0 = 0.546 +- 0.191 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 class 1 = 0.515 +- 0.191 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 class 2 = 0.583 +- 0.191 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 all KL = 0.674 +- 0.191 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.6 all L1 = 0.548 +- 0.124 (in-sample avg dev_std = 0.389)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  0.258065
Model XAI WIoU of binarized graphs for r=0.9 =  0.7892137499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.65
SUFF++ for r=0.9 class 0 = 0.734 +- 0.148 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1 = 0.688 +- 0.148 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 2 = 0.72 +- 0.148 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.858 +- 0.148 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.714 +- 0.142 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.69
Model XAI F1 of binarized graphs for r=0.3 =  0.47629750000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.6165325
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.543
SUFF++ for r=0.3 class 0 = 0.592 +- 0.209 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 class 1 = 0.617 +- 0.209 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 class 2 = 0.529 +- 0.209 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 all KL = 0.628 +- 0.209 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.3 all L1 = 0.58 +- 0.121 (in-sample avg dev_std = 0.505)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.5196525000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7771062499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.657
SUFF++ for r=0.6 class 0 = 0.673 +- 0.289 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 class 1 = 0.61 +- 0.289 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 class 2 = 0.556 +- 0.289 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 all KL = 0.595 +- 0.289 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.6 all L1 = 0.613 +- 0.148 (in-sample avg dev_std = 0.530)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  0.39425125
Model XAI WIoU of binarized graphs for r=0.9 =  0.7771062499999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.779
SUFF++ for r=0.9 class 0 = 0.806 +- 0.180 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 class 1 = 0.783 +- 0.180 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 class 2 = 0.836 +- 0.180 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 all KL = 0.846 +- 0.180 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.146 (in-sample avg dev_std = 0.307)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.516
Model XAI F1 of binarized graphs for r=0.3 =  0.51966125
Model XAI WIoU of binarized graphs for r=0.3 =  0.47011250000000004
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.483 +- 0.277 (in-sample avg dev_std = 0.426)
NEC for r=0.3 class 1 = 0.456 +- 0.277 (in-sample avg dev_std = 0.426)
NEC for r=0.3 class 2 = 0.518 +- 0.277 (in-sample avg dev_std = 0.426)
NEC for r=0.3 all KL = 0.457 +- 0.277 (in-sample avg dev_std = 0.426)
NEC for r=0.3 all L1 = 0.486 +- 0.181 (in-sample avg dev_std = 0.426)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  0.5246175000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.56363125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.475
NEC for r=0.6 class 0 = 0.603 +- 0.291 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 1 = 0.446 +- 0.291 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 2 = 0.576 +- 0.291 (in-sample avg dev_std = 0.446)
NEC for r=0.6 all KL = 0.521 +- 0.291 (in-sample avg dev_std = 0.446)
NEC for r=0.6 all L1 = 0.541 +- 0.165 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  0.4554525
Model XAI WIoU of binarized graphs for r=0.9 =  0.59340125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.531
NEC for r=0.9 class 0 = 0.535 +- 0.292 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 1 = 0.395 +- 0.292 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 2 = 0.499 +- 0.292 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all KL = 0.423 +- 0.292 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all L1 = 0.476 +- 0.149 (in-sample avg dev_std = 0.472)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.851
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.59340125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.507 +- 0.295 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 1 = 0.377 +- 0.295 (in-sample avg dev_std = 0.449)
NEC for r=1.0 class 2 = 0.493 +- 0.295 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all KL = 0.391 +- 0.295 (in-sample avg dev_std = 0.449)
NEC for r=1.0 all L1 = 0.459 +- 0.149 (in-sample avg dev_std = 0.449)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.684
Model XAI F1 of binarized graphs for r=0.3 =  0.5649712499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.78605625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.349
NEC for r=0.3 class 0 = 0.639 +- 0.266 (in-sample avg dev_std = 0.420)
NEC for r=0.3 class 1 = 0.551 +- 0.266 (in-sample avg dev_std = 0.420)
NEC for r=0.3 class 2 = 0.671 +- 0.266 (in-sample avg dev_std = 0.420)
NEC for r=0.3 all KL = 0.599 +- 0.266 (in-sample avg dev_std = 0.420)
NEC for r=0.3 all L1 = 0.621 +- 0.127 (in-sample avg dev_std = 0.420)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  0.34991874999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.7892137499999999
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.456
NEC for r=0.6 class 0 = 0.534 +- 0.210 (in-sample avg dev_std = 0.415)
NEC for r=0.6 class 1 = 0.506 +- 0.210 (in-sample avg dev_std = 0.415)
NEC for r=0.6 class 2 = 0.531 +- 0.210 (in-sample avg dev_std = 0.415)
NEC for r=0.6 all KL = 0.41 +- 0.210 (in-sample avg dev_std = 0.415)
NEC for r=0.6 all L1 = 0.524 +- 0.109 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.697
Model XAI F1 of binarized graphs for r=0.9 =  0.258065
Model XAI WIoU of binarized graphs for r=0.9 =  0.7892137499999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.51
NEC for r=0.9 class 0 = 0.484 +- 0.190 (in-sample avg dev_std = 0.408)
NEC for r=0.9 class 1 = 0.466 +- 0.190 (in-sample avg dev_std = 0.408)
NEC for r=0.9 class 2 = 0.479 +- 0.190 (in-sample avg dev_std = 0.408)
NEC for r=0.9 all KL = 0.346 +- 0.190 (in-sample avg dev_std = 0.408)
NEC for r=0.9 all L1 = 0.476 +- 0.103 (in-sample avg dev_std = 0.408)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.728
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.7892137499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.508
NEC for r=1.0 class 0 = 0.455 +- 0.186 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 1 = 0.445 +- 0.186 (in-sample avg dev_std = 0.388)
NEC for r=1.0 class 2 = 0.46 +- 0.186 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all KL = 0.308 +- 0.186 (in-sample avg dev_std = 0.388)
NEC for r=1.0 all L1 = 0.453 +- 0.109 (in-sample avg dev_std = 0.388)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.69
Model XAI F1 of binarized graphs for r=0.3 =  0.47629750000000004
Model XAI WIoU of binarized graphs for r=0.3 =  0.6165325
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.433
NEC for r=0.3 class 0 = 0.504 +- 0.255 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 1 = 0.408 +- 0.255 (in-sample avg dev_std = 0.467)
NEC for r=0.3 class 2 = 0.533 +- 0.255 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all KL = 0.438 +- 0.255 (in-sample avg dev_std = 0.467)
NEC for r=0.3 all L1 = 0.481 +- 0.148 (in-sample avg dev_std = 0.467)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.5196525000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7771062499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.528
NEC for r=0.6 class 0 = 0.506 +- 0.368 (in-sample avg dev_std = 0.481)
NEC for r=0.6 class 1 = 0.315 +- 0.368 (in-sample avg dev_std = 0.481)
NEC for r=0.6 class 2 = 0.545 +- 0.368 (in-sample avg dev_std = 0.481)
NEC for r=0.6 all KL = 0.47 +- 0.368 (in-sample avg dev_std = 0.481)
NEC for r=0.6 all L1 = 0.453 +- 0.223 (in-sample avg dev_std = 0.481)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  0.39425125
Model XAI WIoU of binarized graphs for r=0.9 =  0.7771062499999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.606
NEC for r=0.9 class 0 = 0.437 +- 0.335 (in-sample avg dev_std = 0.524)
NEC for r=0.9 class 1 = 0.287 +- 0.335 (in-sample avg dev_std = 0.524)
NEC for r=0.9 class 2 = 0.494 +- 0.335 (in-sample avg dev_std = 0.524)
NEC for r=0.9 all KL = 0.423 +- 0.335 (in-sample avg dev_std = 0.524)
NEC for r=0.9 all L1 = 0.405 +- 0.193 (in-sample avg dev_std = 0.524)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7771062499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.591
NEC for r=1.0 class 0 = 0.428 +- 0.341 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 1 = 0.277 +- 0.341 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 2 = 0.496 +- 0.341 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all KL = 0.406 +- 0.341 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all L1 = 0.399 +- 0.204 (in-sample avg dev_std = 0.512)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:55:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:55:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 170...
[0m[1;37mINFO[0m: [1mCheckpoint 170: 
-----------------------------------
Train ACCURACY: 0.8457
Train Loss: 0.5356
ID Validation ACCURACY: 0.8503
ID Validation Loss: 0.5297
ID Test ACCURACY: 0.8380
ID Test Loss: 0.5597
OOD Validation ACCURACY: 0.7670
OOD Validation Loss: 0.6554
OOD Test ACCURACY: 0.8223
OOD Test Loss: 0.5829

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.6974
Train Loss: 0.6608
ID Validation ACCURACY: 0.6903
ID Validation Loss: 0.6695
ID Test ACCURACY: 0.7020
ID Test Loss: 0.6763
OOD Validation ACCURACY: 0.8513
OOD Validation Loss: 0.5399
OOD Test ACCURACY: 0.6037
OOD Test Loss: 1.0070

[0m[1;37mINFO[0m: [1mChartInfo 0.8380 0.8223 0.7020 0.6037 0.6903 0.8513[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.244
WIoU for r=0.3 = 0.233
F1 for r=0.6 = 0.445
WIoU for r=0.6 = 0.431
F1 for r=0.9 = 0.415
WIoU for r=0.9 = 0.437
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.437
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.500
WIoU for r=0.3 = 0.438
F1 for r=0.6 = 0.345
WIoU for r=0.6 = 0.315
F1 for r=0.9 = 0.264
WIoU for r=0.9 = 0.273
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.273
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.557
WIoU for r=0.3 = 0.767
F1 for r=0.6 = 0.437
WIoU for r=0.6 = 0.783
F1 for r=0.9 = 0.354
WIoU for r=0.9 = 0.753
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.753


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.4
Model XAI F1 of binarized graphs for r=0.3 =  0.2437225
Model XAI WIoU of binarized graphs for r=0.3 =  0.23340125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.361
SUFF++ for r=0.3 class 0 = 0.477 +- 0.204 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 1 = 0.514 +- 0.204 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.204 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all KL = 0.543 +- 0.204 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all L1 = 0.488 +- 0.135 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.685
Model XAI F1 of binarized graphs for r=0.6 =  0.44517625000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.43093875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.479
SUFF++ for r=0.6 class 0 = 0.499 +- 0.238 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 1 = 0.527 +- 0.238 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 2 = 0.521 +- 0.238 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all KL = 0.552 +- 0.238 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all L1 = 0.516 +- 0.143 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  0.4154837500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.43651749999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.668
SUFF++ for r=0.9 class 0 = 0.616 +- 0.222 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 class 1 = 0.601 +- 0.222 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 class 2 = 0.754 +- 0.222 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 all KL = 0.71 +- 0.222 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.9 all L1 = 0.656 +- 0.170 (in-sample avg dev_std = 0.420)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.49954499999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.43818000000000007
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.419
SUFF++ for r=0.3 class 0 = 0.468 +- 0.265 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 1 = 0.583 +- 0.265 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 2 = 0.409 +- 0.265 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all KL = 0.524 +- 0.265 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all L1 = 0.486 +- 0.157 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  0.34528875
Model XAI WIoU of binarized graphs for r=0.6 =  0.31475625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.551
SUFF++ for r=0.6 class 0 = 0.488 +- 0.210 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.569 +- 0.210 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.526 +- 0.210 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.619 +- 0.210 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.527 +- 0.128 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.774
Model XAI F1 of binarized graphs for r=0.9 =  0.2640825
Model XAI WIoU of binarized graphs for r=0.9 =  0.27343625000000005
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.611
SUFF++ for r=0.9 class 0 = 0.584 +- 0.190 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 1 = 0.576 +- 0.190 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 class 2 = 0.686 +- 0.190 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all KL = 0.746 +- 0.190 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.9 all L1 = 0.616 +- 0.150 (in-sample avg dev_std = 0.341)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.55696625
Model XAI WIoU of binarized graphs for r=0.3 =  0.7665000000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.468
SUFF++ for r=0.3 class 0 = 0.473 +- 0.195 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 class 1 = 0.521 +- 0.195 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 class 2 = 0.531 +- 0.195 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all KL = 0.568 +- 0.195 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.3 all L1 = 0.509 +- 0.134 (in-sample avg dev_std = 0.524)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.743
Model XAI F1 of binarized graphs for r=0.6 =  0.43693124999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.78260875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.517
SUFF++ for r=0.6 class 0 = 0.5 +- 0.316 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 1 = 0.596 +- 0.316 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 class 2 = 0.505 +- 0.316 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 all KL = 0.552 +- 0.316 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.6 all L1 = 0.534 +- 0.183 (in-sample avg dev_std = 0.555)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  0.3542375
Model XAI WIoU of binarized graphs for r=0.9 =  0.75287
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.573
SUFF++ for r=0.9 class 0 = 0.669 +- 0.323 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 class 1 = 0.509 +- 0.323 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.323 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 all KL = 0.718 +- 0.323 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.9 all L1 = 0.675 +- 0.237 (in-sample avg dev_std = 0.367)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.4
Model XAI F1 of binarized graphs for r=0.3 =  0.2437225
Model XAI WIoU of binarized graphs for r=0.3 =  0.23340125
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.5 +- 0.238 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 1 = 0.476 +- 0.238 (in-sample avg dev_std = 0.453)
NEC for r=0.3 class 2 = 0.559 +- 0.238 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all KL = 0.458 +- 0.238 (in-sample avg dev_std = 0.453)
NEC for r=0.3 all L1 = 0.512 +- 0.168 (in-sample avg dev_std = 0.453)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.685
Model XAI F1 of binarized graphs for r=0.6 =  0.44517625000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.43093875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.436
NEC for r=0.6 class 0 = 0.516 +- 0.242 (in-sample avg dev_std = 0.461)
NEC for r=0.6 class 1 = 0.453 +- 0.242 (in-sample avg dev_std = 0.461)
NEC for r=0.6 class 2 = 0.575 +- 0.242 (in-sample avg dev_std = 0.461)
NEC for r=0.6 all KL = 0.478 +- 0.242 (in-sample avg dev_std = 0.461)
NEC for r=0.6 all L1 = 0.514 +- 0.151 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  0.4154837500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.43651749999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.498
NEC for r=0.9 class 0 = 0.523 +- 0.268 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 1 = 0.455 +- 0.268 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 2 = 0.528 +- 0.268 (in-sample avg dev_std = 0.481)
NEC for r=0.9 all KL = 0.468 +- 0.268 (in-sample avg dev_std = 0.481)
NEC for r=0.9 all L1 = 0.502 +- 0.149 (in-sample avg dev_std = 0.481)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.866
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.4369149999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.508
NEC for r=1.0 class 0 = 0.503 +- 0.265 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 1 = 0.467 +- 0.265 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 2 = 0.51 +- 0.265 (in-sample avg dev_std = 0.477)
NEC for r=1.0 all KL = 0.454 +- 0.265 (in-sample avg dev_std = 0.477)
NEC for r=1.0 all L1 = 0.493 +- 0.144 (in-sample avg dev_std = 0.477)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  0.49954499999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.43818000000000007
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.576 +- 0.277 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 1 = 0.461 +- 0.277 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 2 = 0.64 +- 0.277 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all KL = 0.529 +- 0.277 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all L1 = 0.56 +- 0.170 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  0.34528875
Model XAI WIoU of binarized graphs for r=0.6 =  0.31475625
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.476
NEC for r=0.6 class 0 = 0.511 +- 0.240 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 1 = 0.434 +- 0.240 (in-sample avg dev_std = 0.440)
NEC for r=0.6 class 2 = 0.569 +- 0.240 (in-sample avg dev_std = 0.440)
NEC for r=0.6 all KL = 0.414 +- 0.240 (in-sample avg dev_std = 0.440)
NEC for r=0.6 all L1 = 0.505 +- 0.139 (in-sample avg dev_std = 0.440)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.774
Model XAI F1 of binarized graphs for r=0.9 =  0.2640825
Model XAI WIoU of binarized graphs for r=0.9 =  0.27343625000000005
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.545
NEC for r=0.9 class 0 = 0.483 +- 0.206 (in-sample avg dev_std = 0.423)
NEC for r=0.9 class 1 = 0.44 +- 0.206 (in-sample avg dev_std = 0.423)
NEC for r=0.9 class 2 = 0.486 +- 0.206 (in-sample avg dev_std = 0.423)
NEC for r=0.9 all KL = 0.361 +- 0.206 (in-sample avg dev_std = 0.423)
NEC for r=0.9 all L1 = 0.47 +- 0.113 (in-sample avg dev_std = 0.423)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.769
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.27252375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.478 +- 0.206 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 1 = 0.449 +- 0.206 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 2 = 0.467 +- 0.206 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all KL = 0.356 +- 0.206 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all L1 = 0.465 +- 0.115 (in-sample avg dev_std = 0.415)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.55696625
Model XAI WIoU of binarized graphs for r=0.3 =  0.7665000000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.429
NEC for r=0.3 class 0 = 0.492 +- 0.252 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 1 = 0.483 +- 0.252 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 2 = 0.556 +- 0.252 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all KL = 0.424 +- 0.252 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all L1 = 0.51 +- 0.156 (in-sample avg dev_std = 0.403)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.743
Model XAI F1 of binarized graphs for r=0.6 =  0.43693124999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.78260875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.505
NEC for r=0.6 class 0 = 0.426 +- 0.349 (in-sample avg dev_std = 0.470)
NEC for r=0.6 class 1 = 0.381 +- 0.349 (in-sample avg dev_std = 0.470)
NEC for r=0.6 class 2 = 0.554 +- 0.349 (in-sample avg dev_std = 0.470)
NEC for r=0.6 all KL = 0.435 +- 0.349 (in-sample avg dev_std = 0.470)
NEC for r=0.6 all L1 = 0.453 +- 0.218 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  0.3542375
Model XAI WIoU of binarized graphs for r=0.9 =  0.75287
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.413 +- 0.330 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 1 = 0.4 +- 0.330 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 2 = 0.461 +- 0.330 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all KL = 0.439 +- 0.330 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all L1 = 0.425 +- 0.193 (in-sample avg dev_std = 0.534)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.819
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.75287
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.407 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 1 = 0.417 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 2 = 0.417 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all KL = 0.419 +- 0.321 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all L1 = 0.414 +- 0.193 (in-sample avg dev_std = 0.522)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 18:58:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 06:58:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.8734
Train Loss: 0.4465
ID Validation ACCURACY: 0.8767
ID Validation Loss: 0.4224
ID Test ACCURACY: 0.8703
ID Test Loss: 0.4571
OOD Validation ACCURACY: 0.8427
OOD Validation Loss: 0.5959
OOD Test ACCURACY: 0.8777
OOD Test Loss: 0.4582

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.8734
Train Loss: 0.4465
ID Validation ACCURACY: 0.8767
ID Validation Loss: 0.4224
ID Test ACCURACY: 0.8703
ID Test Loss: 0.4571
OOD Validation ACCURACY: 0.8427
OOD Validation Loss: 0.5959
OOD Test ACCURACY: 0.8777
OOD Test Loss: 0.4582

[0m[1;37mINFO[0m: [1mChartInfo 0.8703 0.8777 0.8703 0.8777 0.8767 0.8427[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.445
WIoU for r=0.3 = 0.428
F1 for r=0.6 = 0.561
WIoU for r=0.6 = 0.627
F1 for r=0.9 = 0.474
WIoU for r=0.9 = 0.614
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.604
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.655
WIoU for r=0.3 = 0.696
F1 for r=0.6 = 0.408
WIoU for r=0.6 = 0.657
F1 for r=0.9 = 0.294
WIoU for r=0.9 = 0.657
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.657
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.626
WIoU for r=0.3 = 0.735
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.860
F1 for r=0.9 = 0.416
WIoU for r=0.9 = 0.862
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.862


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.501
Model XAI F1 of binarized graphs for r=0.3 =  0.44455500000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.42836874999999996
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.432
SUFF++ for r=0.3 class 0 = 0.574 +- 0.260 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 1 = 0.626 +- 0.260 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 2 = 0.537 +- 0.260 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all KL = 0.516 +- 0.260 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all L1 = 0.579 +- 0.167 (in-sample avg dev_std = 0.552)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  0.56122625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6272825000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.543
SUFF++ for r=0.6 class 0 = 0.508 +- 0.297 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.6 class 1 = 0.707 +- 0.297 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.6 class 2 = 0.485 +- 0.297 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.6 all KL = 0.549 +- 0.297 (in-sample avg dev_std = 0.527)
SUFF++ for r=0.6 all L1 = 0.567 +- 0.218 (in-sample avg dev_std = 0.527)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.47415125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6135237499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0 = 0.774 +- 0.187 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 1 = 0.824 +- 0.187 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 class 2 = 0.819 +- 0.187 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all KL = 0.858 +- 0.187 (in-sample avg dev_std = 0.318)
SUFF++ for r=0.9 all L1 = 0.805 +- 0.176 (in-sample avg dev_std = 0.318)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.829
Model XAI F1 of binarized graphs for r=0.3 =  0.6553825000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.69605625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.472
SUFF++ for r=0.3 class 0 = 0.401 +- 0.236 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 1 = 0.567 +- 0.236 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 2 = 0.37 +- 0.236 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all KL = 0.438 +- 0.236 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all L1 = 0.445 +- 0.155 (in-sample avg dev_std = 0.586)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  0.40769000000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.6569325
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.543
SUFF++ for r=0.6 class 0 = 0.438 +- 0.168 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 1 = 0.524 +- 0.168 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 2 = 0.547 +- 0.168 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all KL = 0.598 +- 0.168 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all L1 = 0.503 +- 0.116 (in-sample avg dev_std = 0.490)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  0.29429125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6565224999999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.776
SUFF++ for r=0.9 class 0 = 0.779 +- 0.089 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1 = 0.818 +- 0.089 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 2 = 0.852 +- 0.089 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.941 +- 0.089 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.116 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  0.6262325
Model XAI WIoU of binarized graphs for r=0.3 =  0.7346475000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.558
SUFF++ for r=0.3 class 0 = 0.599 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.3 class 1 = 0.68 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.3 class 2 = 0.59 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.3 all KL = 0.594 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.3 all L1 = 0.624 +- 0.159 (in-sample avg dev_std = 0.531)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.5444325
Model XAI WIoU of binarized graphs for r=0.6 =  0.85957625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.593 +- 0.270 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 class 1 = 0.605 +- 0.270 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 class 2 = 0.651 +- 0.270 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 all KL = 0.636 +- 0.270 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.6 all L1 = 0.617 +- 0.170 (in-sample avg dev_std = 0.538)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.41645375
Model XAI WIoU of binarized graphs for r=0.9 =  0.86162125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0 = 0.863 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all KL = 0.904 +- 0.176 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all L1 = 0.876 +- 0.150 (in-sample avg dev_std = 0.264)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.501
Model XAI F1 of binarized graphs for r=0.3 =  0.44455500000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.42836874999999996
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.393
NEC for r=0.3 class 0 = 0.464 +- 0.302 (in-sample avg dev_std = 0.502)
NEC for r=0.3 class 1 = 0.492 +- 0.302 (in-sample avg dev_std = 0.502)
NEC for r=0.3 class 2 = 0.463 +- 0.302 (in-sample avg dev_std = 0.502)
NEC for r=0.3 all KL = 0.525 +- 0.302 (in-sample avg dev_std = 0.502)
NEC for r=0.3 all L1 = 0.473 +- 0.198 (in-sample avg dev_std = 0.502)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  0.56122625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6272825000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.498
NEC for r=0.6 class 0 = 0.554 +- 0.288 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 1 = 0.476 +- 0.288 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 2 = 0.58 +- 0.288 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all KL = 0.578 +- 0.288 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all L1 = 0.536 +- 0.187 (in-sample avg dev_std = 0.529)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.47415125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6135237499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.584
NEC for r=0.9 class 0 = 0.499 +- 0.266 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 1 = 0.42 +- 0.266 (in-sample avg dev_std = 0.519)
NEC for r=0.9 class 2 = 0.516 +- 0.266 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all KL = 0.47 +- 0.266 (in-sample avg dev_std = 0.519)
NEC for r=0.9 all L1 = 0.478 +- 0.177 (in-sample avg dev_std = 0.519)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.9
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.60447875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0 = 0.492 +- 0.262 (in-sample avg dev_std = 0.501)
NEC for r=1.0 class 1 = 0.38 +- 0.262 (in-sample avg dev_std = 0.501)
NEC for r=1.0 class 2 = 0.491 +- 0.262 (in-sample avg dev_std = 0.501)
NEC for r=1.0 all KL = 0.441 +- 0.262 (in-sample avg dev_std = 0.501)
NEC for r=1.0 all L1 = 0.454 +- 0.169 (in-sample avg dev_std = 0.501)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.829
Model XAI F1 of binarized graphs for r=0.3 =  0.6553825000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.69605625
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.325
NEC for r=0.3 class 0 = 0.639 +- 0.222 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1 = 0.588 +- 0.222 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 2 = 0.712 +- 0.222 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.664 +- 0.222 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.647 +- 0.119 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  0.40769000000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.6569325
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.411
NEC for r=0.6 class 0 = 0.584 +- 0.191 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 1 = 0.547 +- 0.191 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 2 = 0.541 +- 0.191 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all KL = 0.459 +- 0.191 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all L1 = 0.558 +- 0.109 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  0.29429125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6565224999999999
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.495
NEC for r=0.9 class 0 = 0.519 +- 0.187 (in-sample avg dev_std = 0.389)
NEC for r=0.9 class 1 = 0.477 +- 0.187 (in-sample avg dev_std = 0.389)
NEC for r=0.9 class 2 = 0.399 +- 0.187 (in-sample avg dev_std = 0.389)
NEC for r=0.9 all KL = 0.323 +- 0.187 (in-sample avg dev_std = 0.389)
NEC for r=0.9 all L1 = 0.465 +- 0.133 (in-sample avg dev_std = 0.389)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.839
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.6565224999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.502 +- 0.155 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 1 = 0.428 +- 0.155 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 2 = 0.366 +- 0.155 (in-sample avg dev_std = 0.373)
NEC for r=1.0 all KL = 0.277 +- 0.155 (in-sample avg dev_std = 0.373)
NEC for r=1.0 all L1 = 0.432 +- 0.118 (in-sample avg dev_std = 0.373)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.6
Model XAI F1 of binarized graphs for r=0.3 =  0.6262325
Model XAI WIoU of binarized graphs for r=0.3 =  0.7346475000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.492
NEC for r=0.3 class 0 = 0.451 +- 0.276 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 1 = 0.366 +- 0.276 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 2 = 0.468 +- 0.276 (in-sample avg dev_std = 0.498)
NEC for r=0.3 all KL = 0.44 +- 0.276 (in-sample avg dev_std = 0.498)
NEC for r=0.3 all L1 = 0.428 +- 0.159 (in-sample avg dev_std = 0.498)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  0.5444325
Model XAI WIoU of binarized graphs for r=0.6 =  0.85957625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.577
NEC for r=0.6 class 0 = 0.471 +- 0.348 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 1 = 0.426 +- 0.348 (in-sample avg dev_std = 0.496)
NEC for r=0.6 class 2 = 0.435 +- 0.348 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all KL = 0.446 +- 0.348 (in-sample avg dev_std = 0.496)
NEC for r=0.6 all L1 = 0.444 +- 0.234 (in-sample avg dev_std = 0.496)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.871
Model XAI F1 of binarized graphs for r=0.9 =  0.41645375
Model XAI WIoU of binarized graphs for r=0.9 =  0.86162125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.641
NEC for r=0.9 class 0 = 0.437 +- 0.334 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 1 = 0.354 +- 0.334 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 2 = 0.374 +- 0.334 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all KL = 0.402 +- 0.334 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all L1 = 0.388 +- 0.216 (in-sample avg dev_std = 0.509)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.871
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.86162125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0 = 0.444 +- 0.314 (in-sample avg dev_std = 0.508)
NEC for r=1.0 class 1 = 0.345 +- 0.314 (in-sample avg dev_std = 0.508)
NEC for r=1.0 class 2 = 0.338 +- 0.314 (in-sample avg dev_std = 0.508)
NEC for r=1.0 all KL = 0.379 +- 0.314 (in-sample avg dev_std = 0.508)
NEC for r=1.0 all L1 = 0.375 +- 0.197 (in-sample avg dev_std = 0.508)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:02:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:02:39 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.8512
Train Loss: 0.5473
ID Validation ACCURACY: 0.8540
ID Validation Loss: 0.5424
ID Test ACCURACY: 0.8473
ID Test Loss: 0.5602
OOD Validation ACCURACY: 0.8573
OOD Validation Loss: 0.6130
OOD Test ACCURACY: 0.8597
OOD Test Loss: 0.5323

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.8512
Train Loss: 0.5473
ID Validation ACCURACY: 0.8540
ID Validation Loss: 0.5424
ID Test ACCURACY: 0.8473
ID Test Loss: 0.5602
OOD Validation ACCURACY: 0.8573
OOD Validation Loss: 0.6130
OOD Test ACCURACY: 0.8597
OOD Test Loss: 0.5323

[0m[1;37mINFO[0m: [1mChartInfo 0.8473 0.8597 0.8473 0.8597 0.8540 0.8573[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.653
WIoU for r=0.3 = 0.658
F1 for r=0.6 = 0.562
WIoU for r=0.6 = 0.774
F1 for r=0.9 = 0.457
WIoU for r=0.9 = 0.778
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.778
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.595
WIoU for r=0.3 = 0.976
F1 for r=0.6 = 0.364
WIoU for r=0.6 = 0.976
F1 for r=0.9 = 0.270
WIoU for r=0.9 = 0.976
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.976
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.647
WIoU for r=0.3 = 0.778
F1 for r=0.6 = 0.503
WIoU for r=0.6 = 0.799
F1 for r=0.9 = 0.390
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.754


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.555
Model XAI F1 of binarized graphs for r=0.3 =  0.6525875000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6578887499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.442
SUFF++ for r=0.3 class 0 = 0.582 +- 0.242 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 1 = 0.628 +- 0.242 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 2 = 0.512 +- 0.242 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all KL = 0.634 +- 0.242 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all L1 = 0.574 +- 0.136 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  0.5623762499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.77390625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.65
SUFF++ for r=0.6 class 0 = 0.619 +- 0.235 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1 = 0.643 +- 0.235 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 2 = 0.689 +- 0.235 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.688 +- 0.235 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.65 +- 0.154 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  0.45661
Model XAI WIoU of binarized graphs for r=0.9 =  0.7777062499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.81
SUFF++ for r=0.9 class 0 = 0.794 +- 0.141 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1 = 0.82 +- 0.141 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 2 = 0.869 +- 0.141 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.891 +- 0.141 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.827 +- 0.140 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.84
Model XAI F1 of binarized graphs for r=0.3 =  0.59537875
Model XAI WIoU of binarized graphs for r=0.3 =  0.9764937499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.606
SUFF++ for r=0.3 class 0 = 0.504 +- 0.258 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 class 1 = 0.628 +- 0.258 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 class 2 = 0.536 +- 0.258 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 all KL = 0.589 +- 0.258 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.3 all L1 = 0.555 +- 0.134 (in-sample avg dev_std = 0.540)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.36367875
Model XAI WIoU of binarized graphs for r=0.6 =  0.976395
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.697
SUFF++ for r=0.6 class 0 = 0.682 +- 0.148 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 1 = 0.649 +- 0.148 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 class 2 = 0.719 +- 0.148 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all KL = 0.827 +- 0.148 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.6 all L1 = 0.684 +- 0.120 (in-sample avg dev_std = 0.319)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.846
Model XAI F1 of binarized graphs for r=0.9 =  0.26964125000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.976395
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.78
SUFF++ for r=0.9 class 0 = 0.84 +- 0.063 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 class 1 = 0.815 +- 0.063 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 class 2 = 0.859 +- 0.063 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 all KL = 0.946 +- 0.063 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 all L1 = 0.838 +- 0.100 (in-sample avg dev_std = 0.187)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.6474575000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.77787
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.528
SUFF++ for r=0.3 class 0 = 0.588 +- 0.179 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 class 1 = 0.688 +- 0.179 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.179 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 all KL = 0.703 +- 0.179 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.3 all L1 = 0.628 +- 0.149 (in-sample avg dev_std = 0.466)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.726
Model XAI F1 of binarized graphs for r=0.6 =  0.5027025
Model XAI WIoU of binarized graphs for r=0.6 =  0.7991224999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.659
SUFF++ for r=0.6 class 0 = 0.581 +- 0.304 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 class 1 = 0.605 +- 0.304 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 class 2 = 0.678 +- 0.304 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 all KL = 0.637 +- 0.304 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.6 all L1 = 0.621 +- 0.193 (in-sample avg dev_std = 0.499)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  0.39032625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7541500000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.809
SUFF++ for r=0.9 class 0 = 0.771 +- 0.230 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 class 1 = 0.764 +- 0.230 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 class 2 = 0.869 +- 0.230 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 all KL = 0.847 +- 0.230 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.9 all L1 = 0.801 +- 0.174 (in-sample avg dev_std = 0.328)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.555
Model XAI F1 of binarized graphs for r=0.3 =  0.6525875000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6578887499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.367
NEC for r=0.3 class 0 = 0.529 +- 0.259 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 1 = 0.543 +- 0.259 (in-sample avg dev_std = 0.357)
NEC for r=0.3 class 2 = 0.578 +- 0.259 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all KL = 0.493 +- 0.259 (in-sample avg dev_std = 0.357)
NEC for r=0.3 all L1 = 0.55 +- 0.148 (in-sample avg dev_std = 0.357)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  0.5623762499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.77390625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.442
NEC for r=0.6 class 0 = 0.515 +- 0.304 (in-sample avg dev_std = 0.418)
NEC for r=0.6 class 1 = 0.488 +- 0.304 (in-sample avg dev_std = 0.418)
NEC for r=0.6 class 2 = 0.568 +- 0.304 (in-sample avg dev_std = 0.418)
NEC for r=0.6 all KL = 0.502 +- 0.304 (in-sample avg dev_std = 0.418)
NEC for r=0.6 all L1 = 0.523 +- 0.166 (in-sample avg dev_std = 0.418)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.845
Model XAI F1 of binarized graphs for r=0.9 =  0.45661
Model XAI WIoU of binarized graphs for r=0.9 =  0.7777062499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.504
NEC for r=0.9 class 0 = 0.467 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 1 = 0.446 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 2 = 0.497 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all KL = 0.433 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all L1 = 0.47 +- 0.174 (in-sample avg dev_std = 0.443)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7776975
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.518
NEC for r=1.0 class 0 = 0.469 +- 0.297 (in-sample avg dev_std = 0.442)
NEC for r=1.0 class 1 = 0.437 +- 0.297 (in-sample avg dev_std = 0.442)
NEC for r=1.0 class 2 = 0.482 +- 0.297 (in-sample avg dev_std = 0.442)
NEC for r=1.0 all KL = 0.422 +- 0.297 (in-sample avg dev_std = 0.442)
NEC for r=1.0 all L1 = 0.462 +- 0.172 (in-sample avg dev_std = 0.442)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.84
Model XAI F1 of binarized graphs for r=0.3 =  0.59537875
Model XAI WIoU of binarized graphs for r=0.3 =  0.9764937499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.371
NEC for r=0.3 class 0 = 0.588 +- 0.288 (in-sample avg dev_std = 0.380)
NEC for r=0.3 class 1 = 0.479 +- 0.288 (in-sample avg dev_std = 0.380)
NEC for r=0.3 class 2 = 0.64 +- 0.288 (in-sample avg dev_std = 0.380)
NEC for r=0.3 all KL = 0.532 +- 0.288 (in-sample avg dev_std = 0.380)
NEC for r=0.3 all L1 = 0.57 +- 0.156 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  0.36367875
Model XAI WIoU of binarized graphs for r=0.6 =  0.976395
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.499
NEC for r=0.6 class 0 = 0.448 +- 0.212 (in-sample avg dev_std = 0.390)
NEC for r=0.6 class 1 = 0.395 +- 0.212 (in-sample avg dev_std = 0.390)
NEC for r=0.6 class 2 = 0.473 +- 0.212 (in-sample avg dev_std = 0.390)
NEC for r=0.6 all KL = 0.299 +- 0.212 (in-sample avg dev_std = 0.390)
NEC for r=0.6 all L1 = 0.439 +- 0.139 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.846
Model XAI F1 of binarized graphs for r=0.9 =  0.26964125000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.976395
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.569
NEC for r=0.9 class 0 = 0.392 +- 0.176 (in-sample avg dev_std = 0.388)
NEC for r=0.9 class 1 = 0.362 +- 0.176 (in-sample avg dev_std = 0.388)
NEC for r=0.9 class 2 = 0.42 +- 0.176 (in-sample avg dev_std = 0.388)
NEC for r=0.9 all KL = 0.246 +- 0.176 (in-sample avg dev_std = 0.388)
NEC for r=0.9 all L1 = 0.392 +- 0.122 (in-sample avg dev_std = 0.388)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.848
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.976395
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.568
NEC for r=1.0 class 0 = 0.379 +- 0.172 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 1 = 0.352 +- 0.172 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 2 = 0.392 +- 0.172 (in-sample avg dev_std = 0.369)
NEC for r=1.0 all KL = 0.223 +- 0.172 (in-sample avg dev_std = 0.369)
NEC for r=1.0 all L1 = 0.375 +- 0.125 (in-sample avg dev_std = 0.369)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  0.6474575000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.77787
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.396
NEC for r=0.3 class 0 = 0.389 +- 0.228 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1 = 0.491 +- 0.228 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 2 = 0.505 +- 0.228 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.37 +- 0.228 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.463 +- 0.141 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.726
Model XAI F1 of binarized graphs for r=0.6 =  0.5027025
Model XAI WIoU of binarized graphs for r=0.6 =  0.7991224999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.518
NEC for r=0.6 class 0 = 0.357 +- 0.339 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 1 = 0.394 +- 0.339 (in-sample avg dev_std = 0.454)
NEC for r=0.6 class 2 = 0.515 +- 0.339 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all KL = 0.413 +- 0.339 (in-sample avg dev_std = 0.454)
NEC for r=0.6 all L1 = 0.423 +- 0.219 (in-sample avg dev_std = 0.454)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  0.39032625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7541500000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.567
NEC for r=0.9 class 0 = 0.355 +- 0.310 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 1 = 0.382 +- 0.310 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 2 = 0.435 +- 0.310 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all KL = 0.385 +- 0.310 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all L1 = 0.391 +- 0.197 (in-sample avg dev_std = 0.506)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7541500000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.618
NEC for r=1.0 class 0 = 0.348 +- 0.316 (in-sample avg dev_std = 0.503)
NEC for r=1.0 class 1 = 0.394 +- 0.316 (in-sample avg dev_std = 0.503)
NEC for r=1.0 class 2 = 0.42 +- 0.316 (in-sample avg dev_std = 0.503)
NEC for r=1.0 all KL = 0.38 +- 0.316 (in-sample avg dev_std = 0.503)
NEC for r=1.0 all L1 = 0.388 +- 0.198 (in-sample avg dev_std = 0.503)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:06:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:06:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.8154
Train Loss: 0.5648
ID Validation ACCURACY: 0.8137
ID Validation Loss: 0.5670
ID Test ACCURACY: 0.8167
ID Test Loss: 0.5772
OOD Validation ACCURACY: 0.8610
OOD Validation Loss: 0.6695
OOD Test ACCURACY: 0.8717
OOD Test Loss: 0.4828

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8046
Train Loss: 0.5987
ID Validation ACCURACY: 0.8087
ID Validation Loss: 0.6015
ID Test ACCURACY: 0.8027
ID Test Loss: 0.5965
OOD Validation ACCURACY: 0.8700
OOD Validation Loss: 0.6088
OOD Test ACCURACY: 0.8830
OOD Test Loss: 0.4452

[0m[1;37mINFO[0m: [1mChartInfo 0.8167 0.8717 0.8027 0.8830 0.8087 0.8700[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.470
WIoU for r=0.3 = 0.397
F1 for r=0.6 = 0.570
WIoU for r=0.6 = 0.584
F1 for r=0.9 = 0.467
WIoU for r=0.9 = 0.593
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.593
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.647
WIoU for r=0.3 = 0.976
F1 for r=0.6 = 0.397
WIoU for r=0.6 = 0.977
F1 for r=0.9 = 0.287
WIoU for r=0.9 = 0.977
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.977
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.730
WIoU for r=0.3 = 0.671
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.605
F1 for r=0.9 = 0.419
WIoU for r=0.9 = 0.558
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.558


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.433
Model XAI F1 of binarized graphs for r=0.3 =  0.4703637500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.39661874999999996
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.368
SUFF++ for r=0.3 class 0 = 0.615 +- 0.224 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.3 class 1 = 0.65 +- 0.224 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.3 class 2 = 0.571 +- 0.224 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.3 all KL = 0.699 +- 0.224 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.3 all L1 = 0.612 +- 0.155 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.5700125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5841337499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.631
SUFF++ for r=0.6 class 0 = 0.602 +- 0.258 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 1 = 0.652 +- 0.258 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 2 = 0.601 +- 0.258 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all KL = 0.665 +- 0.258 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all L1 = 0.619 +- 0.150 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  0.4674175
Model XAI WIoU of binarized graphs for r=0.9 =  0.5926675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.79
SUFF++ for r=0.9 class 0 = 0.798 +- 0.140 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 1 = 0.791 +- 0.140 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.140 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all KL = 0.888 +- 0.140 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.148 (in-sample avg dev_std = 0.269)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.859
Model XAI F1 of binarized graphs for r=0.3 =  0.6471325
Model XAI WIoU of binarized graphs for r=0.3 =  0.9763925
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0 = 0.41 +- 0.248 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 1 = 0.506 +- 0.248 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 class 2 = 0.441 +- 0.248 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all KL = 0.473 +- 0.248 (in-sample avg dev_std = 0.580)
SUFF++ for r=0.3 all L1 = 0.451 +- 0.104 (in-sample avg dev_std = 0.580)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.3969075
Model XAI WIoU of binarized graphs for r=0.6 =  0.9771912500000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.681
SUFF++ for r=0.6 class 0 = 0.627 +- 0.142 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 class 1 = 0.582 +- 0.142 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 class 2 = 0.665 +- 0.142 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all KL = 0.775 +- 0.142 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.117 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  0.286815
Model XAI WIoU of binarized graphs for r=0.9 =  0.9771912500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0 = 0.814 +- 0.058 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1 = 0.774 +- 0.058 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 2 = 0.894 +- 0.058 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.947 +- 0.058 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.828 +- 0.105 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  0.7299437499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6705462500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0 = 0.547 +- 0.217 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 class 1 = 0.668 +- 0.217 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 class 2 = 0.629 +- 0.217 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 all KL = 0.649 +- 0.217 (in-sample avg dev_std = 0.449)
SUFF++ for r=0.3 all L1 = 0.616 +- 0.140 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.808
Model XAI F1 of binarized graphs for r=0.6 =  0.54370875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6051375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.683
SUFF++ for r=0.6 class 0 = 0.594 +- 0.251 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 1 = 0.632 +- 0.251 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.251 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 all KL = 0.697 +- 0.251 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.172 (in-sample avg dev_std = 0.434)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.41949125000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.5578474999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.758
SUFF++ for r=0.9 class 0 = 0.808 +- 0.271 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 1 = 0.657 +- 0.271 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 class 2 = 0.892 +- 0.271 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all KL = 0.822 +- 0.271 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.9 all L1 = 0.784 +- 0.214 (in-sample avg dev_std = 0.321)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.433
Model XAI F1 of binarized graphs for r=0.3 =  0.4703637500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.39661874999999996
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.384
NEC for r=0.3 class 0 = 0.407 +- 0.235 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 1 = 0.396 +- 0.235 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 2 = 0.448 +- 0.235 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all KL = 0.336 +- 0.235 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all L1 = 0.417 +- 0.167 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.5700125
Model XAI WIoU of binarized graphs for r=0.6 =  0.5841337499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.507
NEC for r=0.6 class 0 = 0.494 +- 0.301 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 1 = 0.407 +- 0.301 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 2 = 0.594 +- 0.301 (in-sample avg dev_std = 0.434)
NEC for r=0.6 all KL = 0.449 +- 0.301 (in-sample avg dev_std = 0.434)
NEC for r=0.6 all L1 = 0.498 +- 0.171 (in-sample avg dev_std = 0.434)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  0.4674175
Model XAI WIoU of binarized graphs for r=0.9 =  0.5926675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.582
NEC for r=0.9 class 0 = 0.438 +- 0.285 (in-sample avg dev_std = 0.464)
NEC for r=0.9 class 1 = 0.389 +- 0.285 (in-sample avg dev_std = 0.464)
NEC for r=0.9 class 2 = 0.507 +- 0.285 (in-sample avg dev_std = 0.464)
NEC for r=0.9 all KL = 0.381 +- 0.285 (in-sample avg dev_std = 0.464)
NEC for r=0.9 all L1 = 0.444 +- 0.159 (in-sample avg dev_std = 0.464)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.822
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.5926325
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.586
NEC for r=1.0 class 0 = 0.419 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=1.0 class 1 = 0.389 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=1.0 class 2 = 0.499 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=1.0 all KL = 0.373 +- 0.285 (in-sample avg dev_std = 0.446)
NEC for r=1.0 all L1 = 0.436 +- 0.166 (in-sample avg dev_std = 0.446)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.859
Model XAI F1 of binarized graphs for r=0.3 =  0.6471325
Model XAI WIoU of binarized graphs for r=0.3 =  0.9763925
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.358
NEC for r=0.3 class 0 = 0.648 +- 0.305 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 1 = 0.457 +- 0.305 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 2 = 0.73 +- 0.305 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all KL = 0.578 +- 0.305 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all L1 = 0.614 +- 0.158 (in-sample avg dev_std = 0.403)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.3969075
Model XAI WIoU of binarized graphs for r=0.6 =  0.9771912500000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.491
NEC for r=0.6 class 0 = 0.491 +- 0.204 (in-sample avg dev_std = 0.424)
NEC for r=0.6 class 1 = 0.447 +- 0.204 (in-sample avg dev_std = 0.424)
NEC for r=0.6 class 2 = 0.559 +- 0.204 (in-sample avg dev_std = 0.424)
NEC for r=0.6 all KL = 0.367 +- 0.204 (in-sample avg dev_std = 0.424)
NEC for r=0.6 all L1 = 0.5 +- 0.121 (in-sample avg dev_std = 0.424)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  0.286815
Model XAI WIoU of binarized graphs for r=0.9 =  0.9771912500000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.55
NEC for r=0.9 class 0 = 0.423 +- 0.179 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 1 = 0.403 +- 0.179 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 2 = 0.484 +- 0.179 (in-sample avg dev_std = 0.402)
NEC for r=0.9 all KL = 0.29 +- 0.179 (in-sample avg dev_std = 0.402)
NEC for r=0.9 all L1 = 0.437 +- 0.113 (in-sample avg dev_std = 0.402)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9771912500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.556
NEC for r=1.0 class 0 = 0.411 +- 0.159 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 1 = 0.398 +- 0.159 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 2 = 0.46 +- 0.159 (in-sample avg dev_std = 0.389)
NEC for r=1.0 all KL = 0.267 +- 0.159 (in-sample avg dev_std = 0.389)
NEC for r=1.0 all L1 = 0.423 +- 0.104 (in-sample avg dev_std = 0.389)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  0.7299437499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6705462500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.473
NEC for r=0.3 class 0 = 0.543 +- 0.307 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1 = 0.515 +- 0.307 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 2 = 0.498 +- 0.307 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.488 +- 0.307 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.518 +- 0.157 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.808
Model XAI F1 of binarized graphs for r=0.6 =  0.54370875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6051375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.638
NEC for r=0.6 class 0 = 0.45 +- 0.297 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.378 +- 0.297 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.522 +- 0.297 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.395 +- 0.297 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.449 +- 0.175 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.41949125000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.5578474999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.651
NEC for r=0.9 class 0 = 0.401 +- 0.295 (in-sample avg dev_std = 0.489)
NEC for r=0.9 class 1 = 0.36 +- 0.295 (in-sample avg dev_std = 0.489)
NEC for r=0.9 class 2 = 0.473 +- 0.295 (in-sample avg dev_std = 0.489)
NEC for r=0.9 all KL = 0.375 +- 0.295 (in-sample avg dev_std = 0.489)
NEC for r=0.9 all L1 = 0.411 +- 0.174 (in-sample avg dev_std = 0.489)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.5580875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.681
NEC for r=1.0 class 0 = 0.395 +- 0.289 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 1 = 0.367 +- 0.289 (in-sample avg dev_std = 0.490)
NEC for r=1.0 class 2 = 0.437 +- 0.289 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all KL = 0.37 +- 0.289 (in-sample avg dev_std = 0.490)
NEC for r=1.0 all L1 = 0.4 +- 0.168 (in-sample avg dev_std = 0.490)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.55, 0.557, 0.834, 1.0], 'all_L1': [0.519, 0.549, 0.75, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.543, 0.552, 0.71, 1.0], 'all_L1': [0.488, 0.516, 0.656, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.516, 0.549, 0.858, 1.0], 'all_L1': [0.579, 0.567, 0.805, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.634, 0.688, 0.891, 1.0], 'all_L1': [0.574, 0.65, 0.827, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.699, 0.665, 0.888, 1.0], 'all_L1': [0.612, 0.619, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.457, 0.521, 0.423, 0.391], 'all_L1': [0.486, 0.541, 0.476, 0.459]}), defaultdict(<class 'list'>, {'all_KL': [0.458, 0.478, 0.468, 0.454], 'all_L1': [0.512, 0.514, 0.502, 0.493]}), defaultdict(<class 'list'>, {'all_KL': [0.525, 0.578, 0.47, 0.441], 'all_L1': [0.473, 0.536, 0.478, 0.454]}), defaultdict(<class 'list'>, {'all_KL': [0.493, 0.502, 0.433, 0.422], 'all_L1': [0.55, 0.523, 0.47, 0.462]}), defaultdict(<class 'list'>, {'all_KL': [0.336, 0.449, 0.381, 0.373], 'all_L1': [0.417, 0.498, 0.444, 0.436]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.438, 0.674, 0.858, 1.0], 'all_L1': [0.428, 0.548, 0.714, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.524, 0.619, 0.746, 1.0], 'all_L1': [0.486, 0.527, 0.616, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.438, 0.598, 0.941, 1.0], 'all_L1': [0.445, 0.503, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.589, 0.827, 0.946, 1.0], 'all_L1': [0.555, 0.684, 0.838, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.473, 0.775, 0.947, 1.0], 'all_L1': [0.451, 0.625, 0.828, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.599, 0.41, 0.346, 0.308], 'all_L1': [0.621, 0.524, 0.476, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.529, 0.414, 0.361, 0.356], 'all_L1': [0.56, 0.505, 0.47, 0.465]}), defaultdict(<class 'list'>, {'all_KL': [0.664, 0.459, 0.323, 0.277], 'all_L1': [0.647, 0.558, 0.465, 0.432]}), defaultdict(<class 'list'>, {'all_KL': [0.532, 0.299, 0.246, 0.223], 'all_L1': [0.57, 0.439, 0.392, 0.375]}), defaultdict(<class 'list'>, {'all_KL': [0.578, 0.367, 0.29, 0.267], 'all_L1': [0.614, 0.5, 0.437, 0.423]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.628, 0.595, 0.846, 1.0], 'all_L1': [0.58, 0.613, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.568, 0.552, 0.718, 1.0], 'all_L1': [0.509, 0.534, 0.675, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.594, 0.636, 0.904, 1.0], 'all_L1': [0.624, 0.617, 0.876, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.703, 0.637, 0.847, 1.0], 'all_L1': [0.628, 0.621, 0.801, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.649, 0.697, 0.822, 1.0], 'all_L1': [0.616, 0.644, 0.784, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.438, 0.47, 0.423, 0.406], 'all_L1': [0.481, 0.453, 0.405, 0.399]}), defaultdict(<class 'list'>, {'all_KL': [0.424, 0.435, 0.439, 0.419], 'all_L1': [0.51, 0.453, 0.425, 0.414]}), defaultdict(<class 'list'>, {'all_KL': [0.44, 0.446, 0.402, 0.379], 'all_L1': [0.428, 0.444, 0.388, 0.375]}), defaultdict(<class 'list'>, {'all_KL': [0.37, 0.413, 0.385, 0.38], 'all_L1': [0.463, 0.423, 0.391, 0.388]}), defaultdict(<class 'list'>, {'all_KL': [0.488, 0.395, 0.375, 0.37], 'all_L1': [0.518, 0.449, 0.411, 0.4]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.554 +- 0.045, 0.580 +- 0.048, 0.770 +- 0.063, 1.000 +- 0.000
suff++ class all_KL  =  0.588 +- 0.068, 0.602 +- 0.061, 0.836 +- 0.066, 1.000 +- 0.000
suff++_acc_int  =  0.404 +- 0.033, 0.579 +- 0.062, 0.760 +- 0.057
nec class all_L1  =  0.488 +- 0.044, 0.522 +- 0.015, 0.474 +- 0.019, 0.461 +- 0.018
nec class all_KL  =  0.454 +- 0.064, 0.506 +- 0.043, 0.435 +- 0.033, 0.416 +- 0.030
nec_acc_int  =  0.378 +- 0.011, 0.472 +- 0.029, 0.540 +- 0.037, 0.552 +- 0.041

Eval split val
suff++ class all_L1  =  0.473 +- 0.045, 0.577 +- 0.067, 0.762 +- 0.086, 1.000 +- 0.000
suff++ class all_KL  =  0.492 +- 0.058, 0.699 +- 0.089, 0.888 +- 0.078, 1.000 +- 0.000
suff++_acc_int  =  0.501 +- 0.068, 0.609 +- 0.066, 0.727 +- 0.082
nec class all_L1  =  0.602 +- 0.033, 0.505 +- 0.039, 0.448 +- 0.031, 0.430 +- 0.031
nec class all_KL  =  0.580 +- 0.050, 0.390 +- 0.054, 0.313 +- 0.041, 0.286 +- 0.044
nec_acc_int  =  0.349 +- 0.015, 0.467 +- 0.032, 0.534 +- 0.027, 0.543 +- 0.020

Eval split test
suff++ class all_L1  =  0.591 +- 0.045, 0.606 +- 0.037, 0.789 +- 0.065, 1.000 +- 0.000
suff++ class all_KL  =  0.628 +- 0.047, 0.623 +- 0.048, 0.827 +- 0.061, 1.000 +- 0.000
suff++_acc_int  =  0.529 +- 0.032, 0.638 +- 0.061, 0.748 +- 0.090
nec class all_L1  =  0.480 +- 0.033, 0.444 +- 0.011, 0.404 +- 0.014, 0.395 +- 0.013
nec class all_KL  =  0.432 +- 0.038, 0.432 +- 0.026, 0.405 +- 0.024, 0.391 +- 0.019
nec_acc_int  =  0.445 +- 0.034, 0.553 +- 0.049, 0.601 +- 0.042, 0.618 +- 0.050


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.521 +- 0.023, 0.551 +- 0.023, 0.622 +- 0.025, 0.730 +- 0.009
Faith. Armon (L1)= 		  =  0.516 +- 0.024, 0.549 +- 0.021, 0.585 +- 0.013, 0.631 +- 0.017
Faith. GMean (L1)= 	  =  0.518 +- 0.023, 0.550 +- 0.022, 0.603 +- 0.018, 0.679 +- 0.014
Faith. Aritm (KL)= 		  =  0.521 +- 0.023, 0.554 +- 0.027, 0.636 +- 0.027, 0.708 +- 0.015
Faith. Armon (KL)= 		  =  0.505 +- 0.033, 0.546 +- 0.024, 0.570 +- 0.025, 0.587 +- 0.030
Faith. GMean (KL)= 	  =  0.513 +- 0.026, 0.550 +- 0.025, 0.602 +- 0.023, 0.645 +- 0.024

Eval split val
Faith. Aritm (L1)= 		  =  0.538 +- 0.015, 0.541 +- 0.018, 0.605 +- 0.035, 0.715 +- 0.016
Faith. Armon (L1)= 		  =  0.527 +- 0.019, 0.534 +- 0.013, 0.561 +- 0.023, 0.600 +- 0.031
Faith. GMean (L1)= 	  =  0.532 +- 0.016, 0.538 +- 0.015, 0.582 +- 0.027, 0.655 +- 0.024
Faith. Aritm (KL)= 		  =  0.536 +- 0.016, 0.544 +- 0.020, 0.600 +- 0.027, 0.643 +- 0.022
Faith. Armon (KL)= 		  =  0.528 +- 0.017, 0.493 +- 0.028, 0.459 +- 0.038, 0.443 +- 0.053
Faith. GMean (KL)= 	  =  0.532 +- 0.016, 0.517 +- 0.013, 0.524 +- 0.024, 0.533 +- 0.041

Eval split test
Faith. Aritm (L1)= 		  =  0.536 +- 0.019, 0.525 +- 0.018, 0.596 +- 0.027, 0.698 +- 0.007
Faith. Armon (L1)= 		  =  0.528 +- 0.020, 0.512 +- 0.014, 0.533 +- 0.008, 0.566 +- 0.013
Faith. GMean (L1)= 	  =  0.532 +- 0.019, 0.518 +- 0.016, 0.564 +- 0.016, 0.629 +- 0.010
Faith. Aritm (KL)= 		  =  0.530 +- 0.024, 0.528 +- 0.019, 0.616 +- 0.026, 0.695 +- 0.009
Faith. Armon (KL)= 		  =  0.510 +- 0.026, 0.508 +- 0.015, 0.542 +- 0.018, 0.562 +- 0.019
Faith. GMean (KL)= 	  =  0.520 +- 0.024, 0.518 +- 0.015, 0.578 +- 0.019, 0.625 +- 0.015
Computed for split load_split = id



Completed in  0:18:58.844083  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis hard

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:10:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:10:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 159...
[0m[1;37mINFO[0m: [1mCheckpoint 159: 
-----------------------------------
Train ACCURACY: 0.8984
Train Loss: 0.4476
ID Validation ACCURACY: 0.9000
ID Validation Loss: 0.4287
ID Test ACCURACY: 0.8880
ID Test Loss: 0.4880
OOD Validation ACCURACY: 0.9187
OOD Validation Loss: 0.4932
OOD Test ACCURACY: 0.7040
OOD Test Loss: 0.8510

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.8621
Train Loss: 0.4692
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.4523
ID Test ACCURACY: 0.8580
ID Test Loss: 0.4853
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.4609
OOD Test ACCURACY: 0.8020
OOD Test Loss: 0.6932

[0m[1;37mINFO[0m: [1mChartInfo 0.8880 0.7040 0.8580 0.8020 0.8710 0.9297[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.607
WIoU for r=0.3 = 0.501
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.655
F1 for r=0.9 = 0.475
WIoU for r=0.9 = 0.657
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.657
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.663
WIoU for r=0.3 = 0.936
F1 for r=0.6 = 0.407
WIoU for r=0.6 = 0.936
F1 for r=0.9 = 0.294
WIoU for r=0.9 = 0.936
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.936
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.354
WIoU for r=0.3 = 0.404
F1 for r=0.6 = 0.363
WIoU for r=0.6 = 0.502
F1 for r=0.9 = 0.393
WIoU for r=0.9 = 0.584
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.585


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.6065424999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.50118375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.377
SUFF++ for r=0.3 class 0 = 0.443 +- 0.243 (in-sample avg dev_std = 0.572)
SUFF++ for r=0.3 class 1 = 0.52 +- 0.243 (in-sample avg dev_std = 0.572)
SUFF++ for r=0.3 class 2 = 0.444 +- 0.243 (in-sample avg dev_std = 0.572)
SUFF++ for r=0.3 all KL = 0.426 +- 0.243 (in-sample avg dev_std = 0.572)
SUFF++ for r=0.3 all L1 = 0.469 +- 0.131 (in-sample avg dev_std = 0.572)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6095437499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.655185
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.704
SUFF++ for r=0.6 class 0 = 0.535 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 1 = 0.632 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 2 = 0.677 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all KL = 0.55 +- 0.288 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all L1 = 0.615 +- 0.205 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.47453875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6567125000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF++ for r=0.9 class 0 = 0.743 +- 0.198 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 1 = 0.776 +- 0.198 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.198 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all KL = 0.83 +- 0.198 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.168 (in-sample avg dev_std = 0.315)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.913
Model XAI F1 of binarized graphs for r=0.3 =  0.6630199999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.9355662499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.558
SUFF++ for r=0.3 class 0 = 0.304 +- 0.280 (in-sample avg dev_std = 0.661)
SUFF++ for r=0.3 class 1 = 0.554 +- 0.280 (in-sample avg dev_std = 0.661)
SUFF++ for r=0.3 class 2 = 0.487 +- 0.280 (in-sample avg dev_std = 0.661)
SUFF++ for r=0.3 all KL = 0.326 +- 0.280 (in-sample avg dev_std = 0.661)
SUFF++ for r=0.3 all L1 = 0.447 +- 0.156 (in-sample avg dev_std = 0.661)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.924
Model XAI F1 of binarized graphs for r=0.6 =  0.40679625
Model XAI WIoU of binarized graphs for r=0.6 =  0.93561875
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.664
SUFF++ for r=0.6 class 0 = 0.474 +- 0.214 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 1 = 0.539 +- 0.214 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.214 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all KL = 0.61 +- 0.214 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all L1 = 0.563 +- 0.145 (in-sample avg dev_std = 0.476)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.29355125
Model XAI WIoU of binarized graphs for r=0.9 =  0.93561875
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.856
SUFF++ for r=0.9 class 0 = 0.797 +- 0.096 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1 = 0.756 +- 0.096 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 2 = 0.842 +- 0.096 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.9 +- 0.096 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.111 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.515
Model XAI F1 of binarized graphs for r=0.3 =  0.35395
Model XAI WIoU of binarized graphs for r=0.3 =  0.40401125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.475
SUFF++ for r=0.3 class 0 = 0.45 +- 0.279 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 1 = 0.567 +- 0.279 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 2 = 0.501 +- 0.279 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all KL = 0.47 +- 0.279 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all L1 = 0.507 +- 0.173 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.524
Model XAI F1 of binarized graphs for r=0.6 =  0.36275875
Model XAI WIoU of binarized graphs for r=0.6 =  0.5019
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.548
SUFF++ for r=0.6 class 0 = 0.461 +- 0.243 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 1 = 0.604 +- 0.243 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 class 2 = 0.529 +- 0.243 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 all KL = 0.552 +- 0.243 (in-sample avg dev_std = 0.524)
SUFF++ for r=0.6 all L1 = 0.533 +- 0.191 (in-sample avg dev_std = 0.524)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.623
Model XAI F1 of binarized graphs for r=0.9 =  0.3934375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5842474999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.6
SUFF++ for r=0.9 class 0 = 0.611 +- 0.282 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.9 class 1 = 0.693 +- 0.282 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.9 class 2 = 0.762 +- 0.282 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.9 all KL = 0.667 +- 0.282 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.9 all L1 = 0.69 +- 0.177 (in-sample avg dev_std = 0.415)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.539
Model XAI F1 of binarized graphs for r=0.3 =  0.6065424999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.50118375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.374
NEC for r=0.3 class 0 = 0.576 +- 0.290 (in-sample avg dev_std = 0.525)
NEC for r=0.3 class 1 = 0.529 +- 0.290 (in-sample avg dev_std = 0.525)
NEC for r=0.3 class 2 = 0.537 +- 0.290 (in-sample avg dev_std = 0.525)
NEC for r=0.3 all KL = 0.592 +- 0.290 (in-sample avg dev_std = 0.525)
NEC for r=0.3 all L1 = 0.547 +- 0.166 (in-sample avg dev_std = 0.525)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6095437499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.655185
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.452
NEC for r=0.6 class 0 = 0.594 +- 0.270 (in-sample avg dev_std = 0.534)
NEC for r=0.6 class 1 = 0.61 +- 0.270 (in-sample avg dev_std = 0.534)
NEC for r=0.6 class 2 = 0.593 +- 0.270 (in-sample avg dev_std = 0.534)
NEC for r=0.6 all KL = 0.687 +- 0.270 (in-sample avg dev_std = 0.534)
NEC for r=0.6 all L1 = 0.599 +- 0.146 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.47453875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6567125000000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.542
NEC for r=0.9 class 0 = 0.503 +- 0.280 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 1 = 0.548 +- 0.280 (in-sample avg dev_std = 0.582)
NEC for r=0.9 class 2 = 0.518 +- 0.280 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all KL = 0.585 +- 0.280 (in-sample avg dev_std = 0.582)
NEC for r=0.9 all L1 = 0.523 +- 0.153 (in-sample avg dev_std = 0.582)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.909
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.6567125000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.473 +- 0.282 (in-sample avg dev_std = 0.564)
NEC for r=1.0 class 1 = 0.538 +- 0.282 (in-sample avg dev_std = 0.564)
NEC for r=1.0 class 2 = 0.52 +- 0.282 (in-sample avg dev_std = 0.564)
NEC for r=1.0 all KL = 0.556 +- 0.282 (in-sample avg dev_std = 0.564)
NEC for r=1.0 all L1 = 0.51 +- 0.150 (in-sample avg dev_std = 0.564)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.913
Model XAI F1 of binarized graphs for r=0.3 =  0.6630199999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.9355662499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.753 +- 0.227 (in-sample avg dev_std = 0.561)
NEC for r=0.3 class 1 = 0.589 +- 0.227 (in-sample avg dev_std = 0.561)
NEC for r=0.3 class 2 = 0.672 +- 0.227 (in-sample avg dev_std = 0.561)
NEC for r=0.3 all KL = 0.776 +- 0.227 (in-sample avg dev_std = 0.561)
NEC for r=0.3 all L1 = 0.672 +- 0.126 (in-sample avg dev_std = 0.561)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.924
Model XAI F1 of binarized graphs for r=0.6 =  0.40679625
Model XAI WIoU of binarized graphs for r=0.6 =  0.93561875
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.492
NEC for r=0.6 class 0 = 0.598 +- 0.235 (in-sample avg dev_std = 0.537)
NEC for r=0.6 class 1 = 0.529 +- 0.235 (in-sample avg dev_std = 0.537)
NEC for r=0.6 class 2 = 0.504 +- 0.235 (in-sample avg dev_std = 0.537)
NEC for r=0.6 all KL = 0.519 +- 0.235 (in-sample avg dev_std = 0.537)
NEC for r=0.6 all L1 = 0.544 +- 0.124 (in-sample avg dev_std = 0.537)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.29355125
Model XAI WIoU of binarized graphs for r=0.9 =  0.93561875
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.583
NEC for r=0.9 class 0 = 0.467 +- 0.214 (in-sample avg dev_std = 0.495)
NEC for r=0.9 class 1 = 0.455 +- 0.214 (in-sample avg dev_std = 0.495)
NEC for r=0.9 class 2 = 0.465 +- 0.214 (in-sample avg dev_std = 0.495)
NEC for r=0.9 all KL = 0.399 +- 0.214 (in-sample avg dev_std = 0.495)
NEC for r=0.9 all L1 = 0.462 +- 0.115 (in-sample avg dev_std = 0.495)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.93561875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.606
NEC for r=1.0 class 0 = 0.452 +- 0.203 (in-sample avg dev_std = 0.465)
NEC for r=1.0 class 1 = 0.44 +- 0.203 (in-sample avg dev_std = 0.465)
NEC for r=1.0 class 2 = 0.453 +- 0.203 (in-sample avg dev_std = 0.465)
NEC for r=1.0 all KL = 0.363 +- 0.203 (in-sample avg dev_std = 0.465)
NEC for r=1.0 all L1 = 0.448 +- 0.113 (in-sample avg dev_std = 0.465)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.515
Model XAI F1 of binarized graphs for r=0.3 =  0.35395
Model XAI WIoU of binarized graphs for r=0.3 =  0.40401125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.384
NEC for r=0.3 class 0 = 0.594 +- 0.269 (in-sample avg dev_std = 0.557)
NEC for r=0.3 class 1 = 0.523 +- 0.269 (in-sample avg dev_std = 0.557)
NEC for r=0.3 class 2 = 0.635 +- 0.269 (in-sample avg dev_std = 0.557)
NEC for r=0.3 all KL = 0.617 +- 0.269 (in-sample avg dev_std = 0.557)
NEC for r=0.3 all L1 = 0.583 +- 0.145 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.524
Model XAI F1 of binarized graphs for r=0.6 =  0.36275875
Model XAI WIoU of binarized graphs for r=0.6 =  0.5019
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.513
NEC for r=0.6 class 0 = 0.502 +- 0.301 (in-sample avg dev_std = 0.518)
NEC for r=0.6 class 1 = 0.526 +- 0.301 (in-sample avg dev_std = 0.518)
NEC for r=0.6 class 2 = 0.549 +- 0.301 (in-sample avg dev_std = 0.518)
NEC for r=0.6 all KL = 0.497 +- 0.301 (in-sample avg dev_std = 0.518)
NEC for r=0.6 all L1 = 0.526 +- 0.197 (in-sample avg dev_std = 0.518)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.623
Model XAI F1 of binarized graphs for r=0.9 =  0.3934375
Model XAI WIoU of binarized graphs for r=0.9 =  0.5842474999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.565
NEC for r=0.9 class 0 = 0.454 +- 0.312 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 1 = 0.454 +- 0.312 (in-sample avg dev_std = 0.545)
NEC for r=0.9 class 2 = 0.414 +- 0.312 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all KL = 0.469 +- 0.312 (in-sample avg dev_std = 0.545)
NEC for r=0.9 all L1 = 0.441 +- 0.169 (in-sample avg dev_std = 0.545)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.584505
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.565
NEC for r=1.0 class 0 = 0.443 +- 0.291 (in-sample avg dev_std = 0.524)
NEC for r=1.0 class 1 = 0.435 +- 0.291 (in-sample avg dev_std = 0.524)
NEC for r=1.0 class 2 = 0.382 +- 0.291 (in-sample avg dev_std = 0.524)
NEC for r=1.0 all KL = 0.424 +- 0.291 (in-sample avg dev_std = 0.524)
NEC for r=1.0 all L1 = 0.42 +- 0.167 (in-sample avg dev_std = 0.524)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:15:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:15:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 176...
[0m[1;37mINFO[0m: [1mCheckpoint 176: 
-----------------------------------
Train ACCURACY: 0.9083
Train Loss: 0.4136
ID Validation ACCURACY: 0.9167
ID Validation Loss: 0.3859
ID Test ACCURACY: 0.9050
ID Test Loss: 0.4328
OOD Validation ACCURACY: 0.9213
OOD Validation Loss: 0.4327
OOD Test ACCURACY: 0.8697
OOD Test Loss: 0.4412

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9081
Train Loss: 0.4246
ID Validation ACCURACY: 0.9113
ID Validation Loss: 0.3996
ID Test ACCURACY: 0.9017
ID Test Loss: 0.4499
OOD Validation ACCURACY: 0.9303
OOD Validation Loss: 0.4022
OOD Test ACCURACY: 0.8897
OOD Test Loss: 0.5095

[0m[1;37mINFO[0m: [1mChartInfo 0.9050 0.8697 0.9017 0.8897 0.9113 0.9303[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.689
WIoU for r=0.3 = 0.620
F1 for r=0.6 = 0.617
WIoU for r=0.6 = 0.688
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.686
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.686
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.874
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.867
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.867
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.867
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.749
WIoU for r=0.3 = 0.731
F1 for r=0.6 = 0.555
WIoU for r=0.6 = 0.674
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.638
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.638


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.57
Model XAI F1 of binarized graphs for r=0.3 =  0.6891787500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6202075
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.414
SUFF++ for r=0.3 class 0 = 0.413 +- 0.273 (in-sample avg dev_std = 0.672)
SUFF++ for r=0.3 class 1 = 0.443 +- 0.273 (in-sample avg dev_std = 0.672)
SUFF++ for r=0.3 class 2 = 0.595 +- 0.273 (in-sample avg dev_std = 0.672)
SUFF++ for r=0.3 all KL = 0.29 +- 0.273 (in-sample avg dev_std = 0.672)
SUFF++ for r=0.3 all L1 = 0.483 +- 0.214 (in-sample avg dev_std = 0.672)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  0.6171387500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6875787499999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.657
SUFF++ for r=0.6 class 0 = 0.463 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 1 = 0.51 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 2 = 0.725 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all KL = 0.468 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all L1 = 0.565 +- 0.224 (in-sample avg dev_std = 0.576)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.48113500000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.68621875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.893
SUFF++ for r=0.9 class 0 = 0.81 +- 0.163 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 1 = 0.826 +- 0.163 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 2 = 0.88 +- 0.163 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all KL = 0.887 +- 0.163 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.160 (in-sample avg dev_std = 0.219)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.913
Model XAI F1 of binarized graphs for r=0.3 =  0.6684200000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8744187499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.443
SUFF++ for r=0.3 class 0 = 0.244 +- 0.312 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 class 1 = 0.316 +- 0.312 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 class 2 = 0.722 +- 0.312 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all KL = 0.282 +- 0.312 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all L1 = 0.429 +- 0.264 (in-sample avg dev_std = 0.625)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.915
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.86655375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.6
SUFF++ for r=0.6 class 0 = 0.366 +- 0.257 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.519 +- 0.257 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.715 +- 0.257 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.556 +- 0.257 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.534 +- 0.192 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.295315
Model XAI WIoU of binarized graphs for r=0.9 =  0.86655375
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.878
SUFF++ for r=0.9 class 0 = 0.766 +- 0.104 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.785 +- 0.104 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.829 +- 0.104 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.898 +- 0.104 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.111 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.74873625
Model XAI WIoU of binarized graphs for r=0.3 =  0.7305600000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.337 +- 0.313 (in-sample avg dev_std = 0.680)
SUFF++ for r=0.3 class 1 = 0.471 +- 0.313 (in-sample avg dev_std = 0.680)
SUFF++ for r=0.3 class 2 = 0.524 +- 0.313 (in-sample avg dev_std = 0.680)
SUFF++ for r=0.3 all KL = 0.287 +- 0.313 (in-sample avg dev_std = 0.680)
SUFF++ for r=0.3 all L1 = 0.445 +- 0.239 (in-sample avg dev_std = 0.680)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.733
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6736937500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.6
SUFF++ for r=0.6 class 0 = 0.417 +- 0.320 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 1 = 0.46 +- 0.320 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 2 = 0.567 +- 0.320 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all KL = 0.453 +- 0.320 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all L1 = 0.482 +- 0.221 (in-sample avg dev_std = 0.567)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.63787625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0 = 0.722 +- 0.230 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 class 1 = 0.836 +- 0.230 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 class 2 = 0.885 +- 0.230 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 all KL = 0.813 +- 0.230 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.151 (in-sample avg dev_std = 0.323)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  0.6891787500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6202075
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.346
NEC for r=0.3 class 0 = 0.705 +- 0.214 (in-sample avg dev_std = 0.571)
NEC for r=0.3 class 1 = 0.645 +- 0.214 (in-sample avg dev_std = 0.571)
NEC for r=0.3 class 2 = 0.576 +- 0.214 (in-sample avg dev_std = 0.571)
NEC for r=0.3 all KL = 0.823 +- 0.214 (in-sample avg dev_std = 0.571)
NEC for r=0.3 all L1 = 0.643 +- 0.171 (in-sample avg dev_std = 0.571)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  0.6171387500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6875787499999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.438
NEC for r=0.6 class 0 = 0.63 +- 0.272 (in-sample avg dev_std = 0.530)
NEC for r=0.6 class 1 = 0.618 +- 0.272 (in-sample avg dev_std = 0.530)
NEC for r=0.6 class 2 = 0.573 +- 0.272 (in-sample avg dev_std = 0.530)
NEC for r=0.6 all KL = 0.722 +- 0.272 (in-sample avg dev_std = 0.530)
NEC for r=0.6 all L1 = 0.607 +- 0.153 (in-sample avg dev_std = 0.530)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.48113500000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.68621875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.518
NEC for r=0.9 class 0 = 0.552 +- 0.283 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.545 +- 0.283 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.54 +- 0.283 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.61 +- 0.283 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.546 +- 0.153 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.924
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.68621875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.534
NEC for r=1.0 class 0 = 0.542 +- 0.283 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 1 = 0.533 +- 0.283 (in-sample avg dev_std = 0.566)
NEC for r=1.0 class 2 = 0.529 +- 0.283 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all KL = 0.585 +- 0.283 (in-sample avg dev_std = 0.566)
NEC for r=1.0 all L1 = 0.535 +- 0.155 (in-sample avg dev_std = 0.566)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.913
Model XAI F1 of binarized graphs for r=0.3 =  0.6684200000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8744187499999999
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.362
NEC for r=0.3 class 0 = 0.763 +- 0.177 (in-sample avg dev_std = 0.574)
NEC for r=0.3 class 1 = 0.678 +- 0.177 (in-sample avg dev_std = 0.574)
NEC for r=0.3 class 2 = 0.591 +- 0.177 (in-sample avg dev_std = 0.574)
NEC for r=0.3 all KL = 0.821 +- 0.177 (in-sample avg dev_std = 0.574)
NEC for r=0.3 all L1 = 0.677 +- 0.133 (in-sample avg dev_std = 0.574)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.915
Model XAI F1 of binarized graphs for r=0.6 =  0.40945499999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.86655375
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.477
NEC for r=0.6 class 0 = 0.662 +- 0.237 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 1 = 0.548 +- 0.237 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 2 = 0.467 +- 0.237 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all KL = 0.546 +- 0.237 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all L1 = 0.559 +- 0.146 (in-sample avg dev_std = 0.529)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.295315
Model XAI WIoU of binarized graphs for r=0.9 =  0.86655375
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.576
NEC for r=0.9 class 0 = 0.516 +- 0.216 (in-sample avg dev_std = 0.493)
NEC for r=0.9 class 1 = 0.461 +- 0.216 (in-sample avg dev_std = 0.493)
NEC for r=0.9 class 2 = 0.463 +- 0.216 (in-sample avg dev_std = 0.493)
NEC for r=0.9 all KL = 0.408 +- 0.216 (in-sample avg dev_std = 0.493)
NEC for r=0.9 all L1 = 0.48 +- 0.121 (in-sample avg dev_std = 0.493)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.86655375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.588
NEC for r=1.0 class 0 = 0.485 +- 0.203 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 1 = 0.434 +- 0.203 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 2 = 0.464 +- 0.203 (in-sample avg dev_std = 0.472)
NEC for r=1.0 all KL = 0.368 +- 0.203 (in-sample avg dev_std = 0.472)
NEC for r=1.0 all L1 = 0.462 +- 0.115 (in-sample avg dev_std = 0.472)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.565
Model XAI F1 of binarized graphs for r=0.3 =  0.74873625
Model XAI WIoU of binarized graphs for r=0.3 =  0.7305600000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.674 +- 0.231 (in-sample avg dev_std = 0.543)
NEC for r=0.3 class 1 = 0.582 +- 0.231 (in-sample avg dev_std = 0.543)
NEC for r=0.3 class 2 = 0.661 +- 0.231 (in-sample avg dev_std = 0.543)
NEC for r=0.3 all KL = 0.791 +- 0.231 (in-sample avg dev_std = 0.543)
NEC for r=0.3 all L1 = 0.638 +- 0.154 (in-sample avg dev_std = 0.543)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.733
Model XAI F1 of binarized graphs for r=0.6 =  0.5545187500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6736937500000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.525 +- 0.284 (in-sample avg dev_std = 0.544)
NEC for r=0.6 class 1 = 0.473 +- 0.284 (in-sample avg dev_std = 0.544)
NEC for r=0.6 class 2 = 0.541 +- 0.284 (in-sample avg dev_std = 0.544)
NEC for r=0.6 all KL = 0.516 +- 0.284 (in-sample avg dev_std = 0.544)
NEC for r=0.6 all L1 = 0.513 +- 0.168 (in-sample avg dev_std = 0.544)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.63787625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.584
NEC for r=0.9 class 0 = 0.459 +- 0.312 (in-sample avg dev_std = 0.598)
NEC for r=0.9 class 1 = 0.485 +- 0.312 (in-sample avg dev_std = 0.598)
NEC for r=0.9 class 2 = 0.492 +- 0.312 (in-sample avg dev_std = 0.598)
NEC for r=0.9 all KL = 0.523 +- 0.312 (in-sample avg dev_std = 0.598)
NEC for r=0.9 all L1 = 0.479 +- 0.165 (in-sample avg dev_std = 0.598)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.861
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.63787625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.601
NEC for r=1.0 class 0 = 0.441 +- 0.320 (in-sample avg dev_std = 0.604)
NEC for r=1.0 class 1 = 0.452 +- 0.320 (in-sample avg dev_std = 0.604)
NEC for r=1.0 class 2 = 0.477 +- 0.320 (in-sample avg dev_std = 0.604)
NEC for r=1.0 all KL = 0.503 +- 0.320 (in-sample avg dev_std = 0.604)
NEC for r=1.0 all L1 = 0.457 +- 0.167 (in-sample avg dev_std = 0.604)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:19:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:19:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 0.8937
Train Loss: 0.4436
ID Validation ACCURACY: 0.8993
ID Validation Loss: 0.4243
ID Test ACCURACY: 0.8943
ID Test Loss: 0.4472
OOD Validation ACCURACY: 0.9077
OOD Validation Loss: 0.5001
OOD Test ACCURACY: 0.8273
OOD Test Loss: 0.5768

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.8292
Train Loss: 0.5253
ID Validation ACCURACY: 0.8280
ID Validation Loss: 0.5214
ID Test ACCURACY: 0.8273
ID Test Loss: 0.5420
OOD Validation ACCURACY: 0.9277
OOD Validation Loss: 0.4723
OOD Test ACCURACY: 0.7537
OOD Test Loss: 1.0063

[0m[1;37mINFO[0m: [1mChartInfo 0.8943 0.8273 0.8273 0.7537 0.8280 0.9277[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.501
WIoU for r=0.3 = 0.445
F1 for r=0.6 = 0.608
WIoU for r=0.6 = 0.665
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.674
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.674
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.952
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.952
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.952
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.952
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.474
WIoU for r=0.3 = 0.377
F1 for r=0.6 = 0.514
WIoU for r=0.6 = 0.503
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.497
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.495


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.515
Model XAI F1 of binarized graphs for r=0.3 =  0.50093875
Model XAI WIoU of binarized graphs for r=0.3 =  0.4447149999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.398
SUFF++ for r=0.3 class 0 = 0.497 +- 0.250 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 1 = 0.518 +- 0.250 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.250 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all KL = 0.522 +- 0.250 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all L1 = 0.495 +- 0.132 (in-sample avg dev_std = 0.490)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.6076725000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.66543875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.671
SUFF++ for r=0.6 class 0 = 0.555 +- 0.261 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 1 = 0.621 +- 0.261 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 2 = 0.623 +- 0.261 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all KL = 0.548 +- 0.261 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all L1 = 0.6 +- 0.180 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.48117875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6740662499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.842
SUFF++ for r=0.9 class 0 = 0.825 +- 0.204 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.785 +- 0.204 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.204 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.876 +- 0.204 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.824 +- 0.194 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.929
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.95208125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.498
SUFF++ for r=0.3 class 0 = 0.355 +- 0.237 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 class 1 = 0.487 +- 0.237 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 class 2 = 0.413 +- 0.237 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 all KL = 0.308 +- 0.237 (in-sample avg dev_std = 0.601)
SUFF++ for r=0.3 all L1 = 0.417 +- 0.124 (in-sample avg dev_std = 0.601)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.916
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9518300000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.459 +- 0.208 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 1 = 0.539 +- 0.208 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 class 2 = 0.637 +- 0.208 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all KL = 0.618 +- 0.208 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.6 all L1 = 0.545 +- 0.141 (in-sample avg dev_std = 0.448)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.29496625000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.9518300000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.841
SUFF++ for r=0.9 class 0 = 0.783 +- 0.139 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 class 1 = 0.741 +- 0.139 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 class 2 = 0.866 +- 0.139 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 all KL = 0.91 +- 0.139 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 all L1 = 0.798 +- 0.144 (in-sample avg dev_std = 0.209)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  0.47407250000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.3772262500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.467
SUFF++ for r=0.3 class 0 = 0.467 +- 0.234 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 1 = 0.489 +- 0.234 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 class 2 = 0.408 +- 0.234 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all KL = 0.392 +- 0.234 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.3 all L1 = 0.455 +- 0.127 (in-sample avg dev_std = 0.618)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.749
Model XAI F1 of binarized graphs for r=0.6 =  0.5141837499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.502715
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.571 +- 0.256 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 class 1 = 0.566 +- 0.256 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 class 2 = 0.635 +- 0.256 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all KL = 0.617 +- 0.256 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all L1 = 0.591 +- 0.166 (in-sample avg dev_std = 0.502)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.815
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.49736
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.802
SUFF++ for r=0.9 class 0 = 0.692 +- 0.225 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 1 = 0.722 +- 0.225 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 class 2 = 0.932 +- 0.225 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all KL = 0.835 +- 0.225 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.9 all L1 = 0.782 +- 0.225 (in-sample avg dev_std = 0.301)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.515
Model XAI F1 of binarized graphs for r=0.3 =  0.50093875
Model XAI WIoU of binarized graphs for r=0.3 =  0.4447149999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.4
NEC for r=0.3 class 0 = 0.555 +- 0.245 (in-sample avg dev_std = 0.456)
NEC for r=0.3 class 1 = 0.535 +- 0.245 (in-sample avg dev_std = 0.456)
NEC for r=0.3 class 2 = 0.569 +- 0.245 (in-sample avg dev_std = 0.456)
NEC for r=0.3 all KL = 0.53 +- 0.245 (in-sample avg dev_std = 0.456)
NEC for r=0.3 all L1 = 0.553 +- 0.127 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  0.6076725000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.66543875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.502
NEC for r=0.6 class 0 = 0.53 +- 0.306 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 1 = 0.516 +- 0.306 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 2 = 0.592 +- 0.306 (in-sample avg dev_std = 0.524)
NEC for r=0.6 all KL = 0.598 +- 0.306 (in-sample avg dev_std = 0.524)
NEC for r=0.6 all L1 = 0.546 +- 0.163 (in-sample avg dev_std = 0.524)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.48117875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6740662499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.591
NEC for r=0.9 class 0 = 0.478 +- 0.276 (in-sample avg dev_std = 0.562)
NEC for r=0.9 class 1 = 0.499 +- 0.276 (in-sample avg dev_std = 0.562)
NEC for r=0.9 class 2 = 0.517 +- 0.276 (in-sample avg dev_std = 0.562)
NEC for r=0.9 all KL = 0.532 +- 0.276 (in-sample avg dev_std = 0.562)
NEC for r=0.9 all L1 = 0.498 +- 0.148 (in-sample avg dev_std = 0.562)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.673955
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.59
NEC for r=1.0 class 0 = 0.465 +- 0.281 (in-sample avg dev_std = 0.557)
NEC for r=1.0 class 1 = 0.515 +- 0.281 (in-sample avg dev_std = 0.557)
NEC for r=1.0 class 2 = 0.511 +- 0.281 (in-sample avg dev_std = 0.557)
NEC for r=1.0 all KL = 0.531 +- 0.281 (in-sample avg dev_std = 0.557)
NEC for r=1.0 all L1 = 0.497 +- 0.153 (in-sample avg dev_std = 0.557)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.929
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.95208125
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.369
NEC for r=0.3 class 0 = 0.657 +- 0.238 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1 = 0.585 +- 0.238 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 2 = 0.74 +- 0.238 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.75 +- 0.238 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.661 +- 0.119 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.916
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9518300000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.495
NEC for r=0.6 class 0 = 0.575 +- 0.230 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 1 = 0.489 +- 0.230 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 2 = 0.582 +- 0.230 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all KL = 0.496 +- 0.230 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all L1 = 0.549 +- 0.119 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.29496625000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.9518300000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.549
NEC for r=0.9 class 0 = 0.494 +- 0.188 (in-sample avg dev_std = 0.464)
NEC for r=0.9 class 1 = 0.451 +- 0.188 (in-sample avg dev_std = 0.464)
NEC for r=0.9 class 2 = 0.464 +- 0.188 (in-sample avg dev_std = 0.464)
NEC for r=0.9 all KL = 0.368 +- 0.188 (in-sample avg dev_std = 0.464)
NEC for r=0.9 all L1 = 0.47 +- 0.109 (in-sample avg dev_std = 0.464)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9518300000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.564
NEC for r=1.0 class 0 = 0.492 +- 0.185 (in-sample avg dev_std = 0.453)
NEC for r=1.0 class 1 = 0.452 +- 0.185 (in-sample avg dev_std = 0.453)
NEC for r=1.0 class 2 = 0.441 +- 0.185 (in-sample avg dev_std = 0.453)
NEC for r=1.0 all KL = 0.357 +- 0.185 (in-sample avg dev_std = 0.453)
NEC for r=1.0 all L1 = 0.462 +- 0.112 (in-sample avg dev_std = 0.453)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  0.47407250000000006
Model XAI WIoU of binarized graphs for r=0.3 =  0.3772262500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.474
NEC for r=0.3 class 0 = 0.634 +- 0.252 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 1 = 0.538 +- 0.252 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 2 = 0.664 +- 0.252 (in-sample avg dev_std = 0.536)
NEC for r=0.3 all KL = 0.683 +- 0.252 (in-sample avg dev_std = 0.536)
NEC for r=0.3 all L1 = 0.611 +- 0.135 (in-sample avg dev_std = 0.536)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.749
Model XAI F1 of binarized graphs for r=0.6 =  0.5141837499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.502715
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.501
NEC for r=0.6 class 0 = 0.529 +- 0.266 (in-sample avg dev_std = 0.503)
NEC for r=0.6 class 1 = 0.508 +- 0.266 (in-sample avg dev_std = 0.503)
NEC for r=0.6 class 2 = 0.534 +- 0.266 (in-sample avg dev_std = 0.503)
NEC for r=0.6 all KL = 0.499 +- 0.266 (in-sample avg dev_std = 0.503)
NEC for r=0.6 all L1 = 0.523 +- 0.159 (in-sample avg dev_std = 0.503)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.815
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.49736
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.626
NEC for r=0.9 class 0 = 0.433 +- 0.298 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 1 = 0.445 +- 0.298 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 2 = 0.356 +- 0.298 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all KL = 0.429 +- 0.298 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all L1 = 0.412 +- 0.182 (in-sample avg dev_std = 0.485)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.821
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.49493750000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.632
NEC for r=1.0 class 0 = 0.422 +- 0.291 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 1 = 0.447 +- 0.291 (in-sample avg dev_std = 0.484)
NEC for r=1.0 class 2 = 0.356 +- 0.291 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all KL = 0.431 +- 0.291 (in-sample avg dev_std = 0.484)
NEC for r=1.0 all L1 = 0.408 +- 0.172 (in-sample avg dev_std = 0.484)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:23:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:23:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 170...
[0m[1;37mINFO[0m: [1mCheckpoint 170: 
-----------------------------------
Train ACCURACY: 0.9200
Train Loss: 0.3876
ID Validation ACCURACY: 0.9280
ID Validation Loss: 0.3591
ID Test ACCURACY: 0.9133
ID Test Loss: 0.4112
OOD Validation ACCURACY: 0.9247
OOD Validation Loss: 0.4171
OOD Test ACCURACY: 0.7950
OOD Test Loss: 0.5897

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.8788
Train Loss: 0.4682
ID Validation ACCURACY: 0.8860
ID Validation Loss: 0.4337
ID Test ACCURACY: 0.8770
ID Test Loss: 0.4892
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.3991
OOD Test ACCURACY: 0.9177
OOD Test Loss: 0.4265

[0m[1;37mINFO[0m: [1mChartInfo 0.9133 0.7950 0.8770 0.9177 0.8860 0.9307[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.633
WIoU for r=0.3 = 0.528
F1 for r=0.6 = 0.618
WIoU for r=0.6 = 0.629
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.623
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.623
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.898
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.891
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.891
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.891
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.722
WIoU for r=0.3 = 0.645
F1 for r=0.6 = 0.544
WIoU for r=0.6 = 0.570
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.538
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.536


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.6327225
Model XAI WIoU of binarized graphs for r=0.3 =  0.52800625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.375
SUFF++ for r=0.3 class 0 = 0.409 +- 0.254 (in-sample avg dev_std = 0.615)
SUFF++ for r=0.3 class 1 = 0.459 +- 0.254 (in-sample avg dev_std = 0.615)
SUFF++ for r=0.3 class 2 = 0.52 +- 0.254 (in-sample avg dev_std = 0.615)
SUFF++ for r=0.3 all KL = 0.361 +- 0.254 (in-sample avg dev_std = 0.615)
SUFF++ for r=0.3 all L1 = 0.462 +- 0.171 (in-sample avg dev_std = 0.615)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.6175225000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6286125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.668
SUFF++ for r=0.6 class 0 = 0.433 +- 0.280 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 1 = 0.548 +- 0.280 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 2 = 0.728 +- 0.280 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all KL = 0.495 +- 0.280 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all L1 = 0.569 +- 0.211 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  0.48113875
Model XAI WIoU of binarized graphs for r=0.9 =  0.62345
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.898
SUFF++ for r=0.9 class 0 = 0.768 +- 0.187 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.828 +- 0.187 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.85 +- 0.187 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.855 +- 0.187 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.161 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.924
Model XAI F1 of binarized graphs for r=0.3 =  0.6682887500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8980250000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.475
SUFF++ for r=0.3 class 0 = 0.237 +- 0.301 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 1 = 0.374 +- 0.301 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 2 = 0.746 +- 0.301 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all KL = 0.317 +- 0.301 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all L1 = 0.454 +- 0.263 (in-sample avg dev_std = 0.589)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.925
Model XAI F1 of binarized graphs for r=0.6 =  0.40915625000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.8906575
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.629
SUFF++ for r=0.6 class 0 = 0.374 +- 0.243 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 class 1 = 0.558 +- 0.243 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.243 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 all KL = 0.598 +- 0.243 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 all L1 = 0.557 +- 0.191 (in-sample avg dev_std = 0.462)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.2951275
Model XAI WIoU of binarized graphs for r=0.9 =  0.8906575
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.878
SUFF++ for r=0.9 class 0 = 0.789 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1 = 0.806 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.92 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.824 +- 0.103 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.45
Model XAI F1 of binarized graphs for r=0.3 =  0.7222375
Model XAI WIoU of binarized graphs for r=0.3 =  0.644745
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.484
SUFF++ for r=0.3 class 0 = 0.368 +- 0.293 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 1 = 0.461 +- 0.293 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 2 = 0.52 +- 0.293 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all KL = 0.313 +- 0.293 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all L1 = 0.451 +- 0.219 (in-sample avg dev_std = 0.623)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.679
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.56999875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.678
SUFF++ for r=0.6 class 0 = 0.435 +- 0.291 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 class 1 = 0.531 +- 0.291 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 class 2 = 0.745 +- 0.291 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 all KL = 0.476 +- 0.291 (in-sample avg dev_std = 0.540)
SUFF++ for r=0.6 all L1 = 0.571 +- 0.217 (in-sample avg dev_std = 0.540)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.53791875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.792
SUFF++ for r=0.9 class 0 = 0.605 +- 0.238 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 class 1 = 0.731 +- 0.238 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 class 2 = 0.902 +- 0.238 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 all KL = 0.78 +- 0.238 (in-sample avg dev_std = 0.313)
SUFF++ for r=0.9 all L1 = 0.747 +- 0.230 (in-sample avg dev_std = 0.313)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.6327225
Model XAI WIoU of binarized graphs for r=0.3 =  0.52800625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.632 +- 0.214 (in-sample avg dev_std = 0.581)
NEC for r=0.3 class 1 = 0.626 +- 0.214 (in-sample avg dev_std = 0.581)
NEC for r=0.3 class 2 = 0.591 +- 0.214 (in-sample avg dev_std = 0.581)
NEC for r=0.3 all KL = 0.749 +- 0.214 (in-sample avg dev_std = 0.581)
NEC for r=0.3 all L1 = 0.616 +- 0.143 (in-sample avg dev_std = 0.581)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.6175225000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6286125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.441
NEC for r=0.6 class 0 = 0.637 +- 0.269 (in-sample avg dev_std = 0.525)
NEC for r=0.6 class 1 = 0.603 +- 0.269 (in-sample avg dev_std = 0.525)
NEC for r=0.6 class 2 = 0.559 +- 0.269 (in-sample avg dev_std = 0.525)
NEC for r=0.6 all KL = 0.697 +- 0.269 (in-sample avg dev_std = 0.525)
NEC for r=0.6 all L1 = 0.6 +- 0.156 (in-sample avg dev_std = 0.525)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  0.48113875
Model XAI WIoU of binarized graphs for r=0.9 =  0.62345
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.57
NEC for r=0.9 class 0 = 0.522 +- 0.270 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 1 = 0.519 +- 0.270 (in-sample avg dev_std = 0.566)
NEC for r=0.9 class 2 = 0.516 +- 0.270 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all KL = 0.558 +- 0.270 (in-sample avg dev_std = 0.566)
NEC for r=0.9 all L1 = 0.519 +- 0.152 (in-sample avg dev_std = 0.566)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.938
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.623285
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.566
NEC for r=1.0 class 0 = 0.515 +- 0.268 (in-sample avg dev_std = 0.554)
NEC for r=1.0 class 1 = 0.516 +- 0.268 (in-sample avg dev_std = 0.554)
NEC for r=1.0 class 2 = 0.512 +- 0.268 (in-sample avg dev_std = 0.554)
NEC for r=1.0 all KL = 0.545 +- 0.268 (in-sample avg dev_std = 0.554)
NEC for r=1.0 all L1 = 0.514 +- 0.150 (in-sample avg dev_std = 0.554)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.924
Model XAI F1 of binarized graphs for r=0.3 =  0.6682887500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.8980250000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.385
NEC for r=0.3 class 0 = 0.759 +- 0.172 (in-sample avg dev_std = 0.557)
NEC for r=0.3 class 1 = 0.67 +- 0.172 (in-sample avg dev_std = 0.557)
NEC for r=0.3 class 2 = 0.571 +- 0.172 (in-sample avg dev_std = 0.557)
NEC for r=0.3 all KL = 0.814 +- 0.172 (in-sample avg dev_std = 0.557)
NEC for r=0.3 all L1 = 0.666 +- 0.133 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.925
Model XAI F1 of binarized graphs for r=0.6 =  0.40915625000000005
Model XAI WIoU of binarized graphs for r=0.6 =  0.8906575
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.48
NEC for r=0.6 class 0 = 0.656 +- 0.230 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 1 = 0.544 +- 0.230 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 2 = 0.473 +- 0.230 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all KL = 0.541 +- 0.230 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all L1 = 0.558 +- 0.140 (in-sample avg dev_std = 0.521)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.2951275
Model XAI WIoU of binarized graphs for r=0.9 =  0.8906575
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.582
NEC for r=0.9 class 0 = 0.504 +- 0.207 (in-sample avg dev_std = 0.498)
NEC for r=0.9 class 1 = 0.463 +- 0.207 (in-sample avg dev_std = 0.498)
NEC for r=0.9 class 2 = 0.464 +- 0.207 (in-sample avg dev_std = 0.498)
NEC for r=0.9 all KL = 0.406 +- 0.207 (in-sample avg dev_std = 0.498)
NEC for r=0.9 all L1 = 0.477 +- 0.116 (in-sample avg dev_std = 0.498)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.8906575
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.598
NEC for r=1.0 class 0 = 0.468 +- 0.204 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 1 = 0.438 +- 0.204 (in-sample avg dev_std = 0.473)
NEC for r=1.0 class 2 = 0.461 +- 0.204 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all KL = 0.37 +- 0.204 (in-sample avg dev_std = 0.473)
NEC for r=1.0 all L1 = 0.456 +- 0.116 (in-sample avg dev_std = 0.473)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.45
Model XAI F1 of binarized graphs for r=0.3 =  0.7222375
Model XAI WIoU of binarized graphs for r=0.3 =  0.644745
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.464
NEC for r=0.3 class 0 = 0.675 +- 0.237 (in-sample avg dev_std = 0.590)
NEC for r=0.3 class 1 = 0.578 +- 0.237 (in-sample avg dev_std = 0.590)
NEC for r=0.3 class 2 = 0.633 +- 0.237 (in-sample avg dev_std = 0.590)
NEC for r=0.3 all KL = 0.782 +- 0.237 (in-sample avg dev_std = 0.590)
NEC for r=0.3 all L1 = 0.628 +- 0.153 (in-sample avg dev_std = 0.590)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.5438937500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.56999875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.493
NEC for r=0.6 class 0 = 0.593 +- 0.280 (in-sample avg dev_std = 0.581)
NEC for r=0.6 class 1 = 0.609 +- 0.280 (in-sample avg dev_std = 0.581)
NEC for r=0.6 class 2 = 0.461 +- 0.280 (in-sample avg dev_std = 0.581)
NEC for r=0.6 all KL = 0.643 +- 0.280 (in-sample avg dev_std = 0.581)
NEC for r=0.6 all L1 = 0.554 +- 0.189 (in-sample avg dev_std = 0.581)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.53791875
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.599
NEC for r=0.9 class 0 = 0.557 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 1 = 0.57 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 2 = 0.437 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all KL = 0.586 +- 0.260 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all L1 = 0.521 +- 0.170 (in-sample avg dev_std = 0.541)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.776
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.53592375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.618
NEC for r=1.0 class 0 = 0.497 +- 0.301 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 1 = 0.505 +- 0.301 (in-sample avg dev_std = 0.546)
NEC for r=1.0 class 2 = 0.423 +- 0.301 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all KL = 0.506 +- 0.301 (in-sample avg dev_std = 0.546)
NEC for r=1.0 all L1 = 0.475 +- 0.179 (in-sample avg dev_std = 0.546)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:26:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:26:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9071
Train Loss: 0.4263
ID Validation ACCURACY: 0.9083
ID Validation Loss: 0.4039
ID Test ACCURACY: 0.9023
ID Test Loss: 0.4419
OOD Validation ACCURACY: 0.8720
OOD Validation Loss: 0.5162
OOD Test ACCURACY: 0.8617
OOD Test Loss: 0.5498

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8972
Train Loss: 0.4383
ID Validation ACCURACY: 0.8987
ID Validation Loss: 0.4159
ID Test ACCURACY: 0.8907
ID Test Loss: 0.4581
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4581
OOD Test ACCURACY: 0.8073
OOD Test Loss: 0.7455

[0m[1;37mINFO[0m: [1mChartInfo 0.9023 0.8617 0.8907 0.8073 0.8987 0.9313[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))

Gold ratio (id_val) =  tensor(0.3098) +- tensor(0.1593)
F1 for r=0.3 = 0.582
WIoU for r=0.3 = 0.536
F1 for r=0.6 = 0.614
WIoU for r=0.6 = 0.716
F1 for r=0.9 = 0.481
WIoU for r=0.9 = 0.724
F1 for r=1.0 = 0.452
WIoU for r=1.0 = 0.724
GOODMotif2(3000)
Data example from val: Data(edge_index=[2, 84], x=[27, 1], node_gt=[27], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=27)
Label distribution from val: (tensor([0, 1, 2]), tensor([1009,  978, 1013]))

Gold ratio (val) =  tensor(0.1589) +- tensor(0.0458)
F1 for r=0.3 = 0.668
WIoU for r=0.3 = 0.943
F1 for r=0.6 = 0.409
WIoU for r=0.6 = 0.942
F1 for r=0.9 = 0.295
WIoU for r=0.9 = 0.942
F1 for r=1.0 = 0.272
WIoU for r=1.0 = 0.942
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.601
WIoU for r=0.3 = 0.686
F1 for r=0.6 = 0.545
WIoU for r=0.6 = 0.778
F1 for r=0.9 = 0.424
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.751


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.5824124999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5356375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.448
SUFF++ for r=0.3 class 0 = 0.593 +- 0.302 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 1 = 0.681 +- 0.302 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 2 = 0.549 +- 0.302 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all KL = 0.554 +- 0.302 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all L1 = 0.608 +- 0.209 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.904
Model XAI F1 of binarized graphs for r=0.6 =  0.614415
Model XAI WIoU of binarized graphs for r=0.6 =  0.7164
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.691
SUFF++ for r=0.6 class 0 = 0.537 +- 0.296 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 1 = 0.703 +- 0.296 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 class 2 = 0.575 +- 0.296 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all KL = 0.526 +- 0.296 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.6 all L1 = 0.605 +- 0.213 (in-sample avg dev_std = 0.554)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.48109625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7236162500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0 = 0.829 +- 0.192 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.824 +- 0.192 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.192 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.864 +- 0.192 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.835 +- 0.166 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9431225000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.531
SUFF++ for r=0.3 class 0 = 0.279 +- 0.317 (in-sample avg dev_std = 0.645)
SUFF++ for r=0.3 class 1 = 0.6 +- 0.317 (in-sample avg dev_std = 0.645)
SUFF++ for r=0.3 class 2 = 0.363 +- 0.317 (in-sample avg dev_std = 0.645)
SUFF++ for r=0.3 all KL = 0.281 +- 0.317 (in-sample avg dev_std = 0.645)
SUFF++ for r=0.3 all L1 = 0.412 +- 0.181 (in-sample avg dev_std = 0.645)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.914
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9424800000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.671
SUFF++ for r=0.6 class 0 = 0.461 +- 0.219 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.493 +- 0.219 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.548 +- 0.219 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.521 +- 0.219 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.501 +- 0.122 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.29494
Model XAI WIoU of binarized graphs for r=0.9 =  0.9424800000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0 = 0.85 +- 0.083 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 1 = 0.739 +- 0.083 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.083 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all KL = 0.923 +- 0.083 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.116 (in-sample avg dev_std = 0.206)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.625
Model XAI F1 of binarized graphs for r=0.3 =  0.60086375
Model XAI WIoU of binarized graphs for r=0.3 =  0.68616625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.561
SUFF++ for r=0.3 class 0 = 0.555 +- 0.262 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 class 1 = 0.604 +- 0.262 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 class 2 = 0.595 +- 0.262 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all KL = 0.448 +- 0.262 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all L1 = 0.585 +- 0.150 (in-sample avg dev_std = 0.602)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  0.5448375
Model XAI WIoU of binarized graphs for r=0.6 =  0.77765375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0 = 0.532 +- 0.283 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 class 1 = 0.526 +- 0.283 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 class 2 = 0.565 +- 0.283 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 all KL = 0.488 +- 0.283 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 all L1 = 0.541 +- 0.134 (in-sample avg dev_std = 0.597)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7538987500000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0 = 0.784 +- 0.229 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 1 = 0.739 +- 0.229 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 2 = 0.875 +- 0.229 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all KL = 0.835 +- 0.229 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.207 (in-sample avg dev_std = 0.262)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.5824124999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.5356375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.48 +- 0.319 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1 = 0.427 +- 0.319 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 2 = 0.474 +- 0.319 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.499 +- 0.319 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.46 +- 0.230 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.904
Model XAI F1 of binarized graphs for r=0.6 =  0.614415
Model XAI WIoU of binarized graphs for r=0.6 =  0.7164
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.61 +- 0.298 (in-sample avg dev_std = 0.516)
NEC for r=0.6 class 1 = 0.502 +- 0.298 (in-sample avg dev_std = 0.516)
NEC for r=0.6 class 2 = 0.625 +- 0.298 (in-sample avg dev_std = 0.516)
NEC for r=0.6 all KL = 0.653 +- 0.298 (in-sample avg dev_std = 0.516)
NEC for r=0.6 all L1 = 0.579 +- 0.178 (in-sample avg dev_std = 0.516)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  0.48109625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7236162500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.554
NEC for r=0.9 class 0 = 0.528 +- 0.304 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 1 = 0.481 +- 0.304 (in-sample avg dev_std = 0.555)
NEC for r=0.9 class 2 = 0.554 +- 0.304 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all KL = 0.574 +- 0.304 (in-sample avg dev_std = 0.555)
NEC for r=0.9 all L1 = 0.521 +- 0.173 (in-sample avg dev_std = 0.555)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.45171999999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7235300000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.511 +- 0.298 (in-sample avg dev_std = 0.540)
NEC for r=1.0 class 1 = 0.492 +- 0.298 (in-sample avg dev_std = 0.540)
NEC for r=1.0 class 2 = 0.538 +- 0.298 (in-sample avg dev_std = 0.540)
NEC for r=1.0 all KL = 0.551 +- 0.298 (in-sample avg dev_std = 0.540)
NEC for r=1.0 all L1 = 0.514 +- 0.171 (in-sample avg dev_std = 0.540)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.6683025
Model XAI WIoU of binarized graphs for r=0.3 =  0.9431225000000001
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.373
NEC for r=0.3 class 0 = 0.755 +- 0.293 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 1 = 0.498 +- 0.293 (in-sample avg dev_std = 0.457)
NEC for r=0.3 class 2 = 0.76 +- 0.293 (in-sample avg dev_std = 0.457)
NEC for r=0.3 all KL = 0.763 +- 0.293 (in-sample avg dev_std = 0.457)
NEC for r=0.3 all L1 = 0.672 +- 0.161 (in-sample avg dev_std = 0.457)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.914
Model XAI F1 of binarized graphs for r=0.6 =  0.4086337500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.9424800000000001
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.505
NEC for r=0.6 class 0 = 0.625 +- 0.249 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.507 +- 0.249 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.605 +- 0.249 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.566 +- 0.249 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.58 +- 0.121 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.29494
Model XAI WIoU of binarized graphs for r=0.9 =  0.9424800000000001
len(reference) = 800
Effective ratio: 0.906 +- 0.004
Model Accuracy over intervened graphs for r=0.9 =  0.578
NEC for r=0.9 class 0 = 0.509 +- 0.217 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 1 = 0.461 +- 0.217 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 2 = 0.512 +- 0.217 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all KL = 0.44 +- 0.217 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all L1 = 0.494 +- 0.110 (in-sample avg dev_std = 0.492)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  0.27168375
Model XAI WIoU of binarized graphs for r=1.0 =  0.9424800000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.579
NEC for r=1.0 class 0 = 0.491 +- 0.204 (in-sample avg dev_std = 0.476)
NEC for r=1.0 class 1 = 0.466 +- 0.204 (in-sample avg dev_std = 0.476)
NEC for r=1.0 class 2 = 0.481 +- 0.204 (in-sample avg dev_std = 0.476)
NEC for r=1.0 all KL = 0.405 +- 0.204 (in-sample avg dev_std = 0.476)
NEC for r=1.0 all L1 = 0.479 +- 0.109 (in-sample avg dev_std = 0.476)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.625
Model XAI F1 of binarized graphs for r=0.3 =  0.60086375
Model XAI WIoU of binarized graphs for r=0.3 =  0.68616625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.413
NEC for r=0.3 class 0 = 0.498 +- 0.318 (in-sample avg dev_std = 0.533)
NEC for r=0.3 class 1 = 0.432 +- 0.318 (in-sample avg dev_std = 0.533)
NEC for r=0.3 class 2 = 0.47 +- 0.318 (in-sample avg dev_std = 0.533)
NEC for r=0.3 all KL = 0.55 +- 0.318 (in-sample avg dev_std = 0.533)
NEC for r=0.3 all L1 = 0.466 +- 0.227 (in-sample avg dev_std = 0.533)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  0.5448375
Model XAI WIoU of binarized graphs for r=0.6 =  0.77765375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.538
NEC for r=0.6 class 0 = 0.555 +- 0.331 (in-sample avg dev_std = 0.523)
NEC for r=0.6 class 1 = 0.439 +- 0.331 (in-sample avg dev_std = 0.523)
NEC for r=0.6 class 2 = 0.553 +- 0.331 (in-sample avg dev_std = 0.523)
NEC for r=0.6 all KL = 0.52 +- 0.331 (in-sample avg dev_std = 0.523)
NEC for r=0.6 all L1 = 0.514 +- 0.189 (in-sample avg dev_std = 0.523)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  0.42370375000000005
Model XAI WIoU of binarized graphs for r=0.9 =  0.7538987500000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.471 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 1 = 0.444 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 2 = 0.429 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.9 all KL = 0.48 +- 0.328 (in-sample avg dev_std = 0.536)
NEC for r=0.9 all L1 = 0.447 +- 0.175 (in-sample avg dev_std = 0.536)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.7512624999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0 = 0.447 +- 0.322 (in-sample avg dev_std = 0.521)
NEC for r=1.0 class 1 = 0.436 +- 0.322 (in-sample avg dev_std = 0.521)
NEC for r=1.0 class 2 = 0.404 +- 0.322 (in-sample avg dev_std = 0.521)
NEC for r=1.0 all KL = 0.451 +- 0.322 (in-sample avg dev_std = 0.521)
NEC for r=1.0 all L1 = 0.429 +- 0.166 (in-sample avg dev_std = 0.521)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.426, 0.55, 0.83, 1.0], 'all_L1': [0.469, 0.615, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.468, 0.887, 1.0], 'all_L1': [0.483, 0.565, 0.839, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.522, 0.548, 0.876, 1.0], 'all_L1': [0.495, 0.6, 0.824, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.361, 0.495, 0.855, 1.0], 'all_L1': [0.462, 0.569, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.554, 0.526, 0.864, 1.0], 'all_L1': [0.608, 0.605, 0.835, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.592, 0.687, 0.585, 0.556], 'all_L1': [0.547, 0.599, 0.523, 0.51]}), defaultdict(<class 'list'>, {'all_KL': [0.823, 0.722, 0.61, 0.585], 'all_L1': [0.643, 0.607, 0.546, 0.535]}), defaultdict(<class 'list'>, {'all_KL': [0.53, 0.598, 0.532, 0.531], 'all_L1': [0.553, 0.546, 0.498, 0.497]}), defaultdict(<class 'list'>, {'all_KL': [0.749, 0.697, 0.558, 0.545], 'all_L1': [0.616, 0.6, 0.519, 0.514]}), defaultdict(<class 'list'>, {'all_KL': [0.499, 0.653, 0.574, 0.551], 'all_L1': [0.46, 0.579, 0.521, 0.514]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.326, 0.61, 0.9, 1.0], 'all_L1': [0.447, 0.563, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.282, 0.556, 0.898, 1.0], 'all_L1': [0.429, 0.534, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.308, 0.618, 0.91, 1.0], 'all_L1': [0.417, 0.545, 0.798, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.317, 0.598, 0.92, 1.0], 'all_L1': [0.454, 0.557, 0.824, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.281, 0.521, 0.923, 1.0], 'all_L1': [0.412, 0.501, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.776, 0.519, 0.399, 0.363], 'all_L1': [0.672, 0.544, 0.462, 0.448]}), defaultdict(<class 'list'>, {'all_KL': [0.821, 0.546, 0.408, 0.368], 'all_L1': [0.677, 0.559, 0.48, 0.462]}), defaultdict(<class 'list'>, {'all_KL': [0.75, 0.496, 0.368, 0.357], 'all_L1': [0.661, 0.549, 0.47, 0.462]}), defaultdict(<class 'list'>, {'all_KL': [0.814, 0.541, 0.406, 0.37], 'all_L1': [0.666, 0.558, 0.477, 0.456]}), defaultdict(<class 'list'>, {'all_KL': [0.763, 0.566, 0.44, 0.405], 'all_L1': [0.672, 0.58, 0.494, 0.479]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.47, 0.552, 0.667, 1.0], 'all_L1': [0.507, 0.533, 0.69, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.287, 0.453, 0.813, 1.0], 'all_L1': [0.445, 0.482, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.392, 0.617, 0.835, 1.0], 'all_L1': [0.455, 0.591, 0.782, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.313, 0.476, 0.78, 1.0], 'all_L1': [0.451, 0.571, 0.747, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.448, 0.488, 0.835, 1.0], 'all_L1': [0.585, 0.541, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.617, 0.497, 0.469, 0.424], 'all_L1': [0.583, 0.526, 0.441, 0.42]}), defaultdict(<class 'list'>, {'all_KL': [0.791, 0.516, 0.523, 0.503], 'all_L1': [0.638, 0.513, 0.479, 0.457]}), defaultdict(<class 'list'>, {'all_KL': [0.683, 0.499, 0.429, 0.431], 'all_L1': [0.611, 0.523, 0.412, 0.408]}), defaultdict(<class 'list'>, {'all_KL': [0.782, 0.643, 0.586, 0.506], 'all_L1': [0.628, 0.554, 0.521, 0.475]}), defaultdict(<class 'list'>, {'all_KL': [0.55, 0.52, 0.48, 0.451], 'all_L1': [0.466, 0.514, 0.447, 0.429]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.503 +- 0.054, 0.591 +- 0.020, 0.821 +- 0.016, 1.000 +- 0.000
suff++ class all_KL  =  0.431 +- 0.098, 0.517 +- 0.032, 0.862 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.403 +- 0.027, 0.678 +- 0.017, 0.873 +- 0.021
nec class all_L1  =  0.564 +- 0.064, 0.586 +- 0.022, 0.521 +- 0.015, 0.514 +- 0.012
nec class all_KL  =  0.639 +- 0.126, 0.671 +- 0.043, 0.572 +- 0.026, 0.554 +- 0.018
nec_acc_int  =  0.370 +- 0.017, 0.457 +- 0.023, 0.555 +- 0.025, 0.559 +- 0.019

Eval split val
suff++ class all_L1  =  0.432 +- 0.016, 0.540 +- 0.022, 0.807 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.303 +- 0.018, 0.581 +- 0.037, 0.910 +- 0.010, 1.000 +- 0.000
suff++_acc_int  =  0.501 +- 0.040, 0.638 +- 0.026, 0.867 +- 0.016
nec class all_L1  =  0.670 +- 0.006, 0.558 +- 0.012, 0.477 +- 0.011, 0.461 +- 0.010
nec class all_KL  =  0.785 +- 0.028, 0.534 +- 0.024, 0.404 +- 0.023, 0.373 +- 0.017
nec_acc_int  =  0.370 +- 0.008, 0.490 +- 0.010, 0.574 +- 0.013, 0.587 +- 0.015

Eval split test
suff++ class all_L1  =  0.489 +- 0.053, 0.544 +- 0.037, 0.767 +- 0.044, 1.000 +- 0.000
suff++ class all_KL  =  0.382 +- 0.072, 0.517 +- 0.060, 0.786 +- 0.063, 1.000 +- 0.000
suff++_acc_int  =  0.499 +- 0.034, 0.625 +- 0.048, 0.781 +- 0.095
nec class all_L1  =  0.585 +- 0.062, 0.526 +- 0.015, 0.460 +- 0.037, 0.438 +- 0.025
nec class all_KL  =  0.685 +- 0.093, 0.535 +- 0.055, 0.497 +- 0.053, 0.463 +- 0.035
nec_acc_int  =  0.419 +- 0.044, 0.509 +- 0.016, 0.600 +- 0.024, 0.611 +- 0.026


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.534 +- 0.018, 0.589 +- 0.011, 0.671 +- 0.013, 0.757 +- 0.006
Faith. Armon (L1)= 		  =  0.526 +- 0.015, 0.588 +- 0.011, 0.638 +- 0.014, 0.679 +- 0.011
Faith. GMean (L1)= 	  =  0.530 +- 0.016, 0.588 +- 0.011, 0.654 +- 0.013, 0.717 +- 0.008
Faith. Aritm (KL)= 		  =  0.535 +- 0.018, 0.594 +- 0.015, 0.717 +- 0.017, 0.777 +- 0.009
Faith. Armon (KL)= 		  =  0.493 +- 0.035, 0.582 +- 0.015, 0.687 +- 0.020, 0.712 +- 0.015
Faith. GMean (KL)= 	  =  0.512 +- 0.015, 0.588 +- 0.014, 0.702 +- 0.018, 0.744 +- 0.012

Eval split val
Faith. Aritm (L1)= 		  =  0.551 +- 0.009, 0.549 +- 0.006, 0.642 +- 0.010, 0.731 +- 0.005
Faith. Armon (L1)= 		  =  0.525 +- 0.012, 0.548 +- 0.007, 0.599 +- 0.011, 0.631 +- 0.010
Faith. GMean (L1)= 	  =  0.538 +- 0.010, 0.549 +- 0.006, 0.620 +- 0.010, 0.679 +- 0.007
Faith. Aritm (KL)= 		  =  0.544 +- 0.016, 0.557 +- 0.009, 0.657 +- 0.014, 0.686 +- 0.008
Faith. Armon (KL)= 		  =  0.437 +- 0.019, 0.555 +- 0.009, 0.559 +- 0.023, 0.543 +- 0.018
Faith. GMean (KL)= 	  =  0.487 +- 0.016, 0.556 +- 0.009, 0.606 +- 0.019, 0.610 +- 0.014

Eval split test
Faith. Aritm (L1)= 		  =  0.537 +- 0.007, 0.535 +- 0.023, 0.613 +- 0.029, 0.719 +- 0.012
Faith. Armon (L1)= 		  =  0.526 +- 0.008, 0.534 +- 0.023, 0.574 +- 0.031, 0.609 +- 0.024
Faith. GMean (L1)= 	  =  0.532 +- 0.007, 0.534 +- 0.023, 0.593 +- 0.029, 0.661 +- 0.019
Faith. Aritm (KL)= 		  =  0.533 +- 0.018, 0.526 +- 0.030, 0.642 +- 0.040, 0.731 +- 0.018
Faith. Armon (KL)= 		  =  0.479 +- 0.040, 0.522 +- 0.026, 0.607 +- 0.044, 0.632 +- 0.033
Faith. GMean (KL)= 	  =  0.505 +- 0.021, 0.524 +- 0.028, 0.624 +- 0.041, 0.680 +- 0.026
Computed for split load_split = id



Completed in  0:19:49.703471  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis anneal

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:31:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:01 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:01 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:31:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0754
ID Validation ACCURACY: 0.8772
ID Validation Loss: 0.4682
ID Test ACCURACY: 0.8700
ID Test Loss: 0.5178
OOD Validation ACCURACY: 0.8647
OOD Validation Loss: 0.6800
OOD Test ACCURACY: 0.7910
OOD Test Loss: 1.7902

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.9482
Train Loss: 0.0846
ID Validation ACCURACY: 0.8687
ID Validation Loss: 0.3490
ID Test ACCURACY: 0.8679
ID Test Loss: 0.3750
OOD Validation ACCURACY: 0.8723
OOD Validation Loss: 0.4503
OOD Test ACCURACY: 0.8267
OOD Test Loss: 0.8245

[0m[1;37mINFO[0m: [1mChartInfo 0.8700 0.7910 0.8679 0.8267 0.8687 0.8723[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:31:06 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
SUFF++ for r=0.6 class 0.0 = 0.934 +- 0.088 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.6 class 1.0 = 0.968 +- 0.088 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.6 all KL = 0.966 +- 0.088 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.6 all L1 = 0.954 +- 0.102 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0.0 = 0.923 +- 0.121 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 class 1.0 = 0.962 +- 0.121 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all KL = 0.962 +- 0.121 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.135 (in-sample avg dev_std = 0.121)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.805
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.796
SUFF++ for r=0.3 class 0.0 = 0.924 +- 0.090 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 class 1.0 = 0.95 +- 0.090 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all KL = 0.959 +- 0.090 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all L1 = 0.937 +- 0.101 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.833
SUFF++ for r=0.6 class 0.0 = 0.949 +- 0.075 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.6 class 1.0 = 0.971 +- 0.075 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.6 all KL = 0.977 +- 0.075 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.6 all L1 = 0.961 +- 0.088 (in-sample avg dev_std = 0.112)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0.0 = 0.981 +- 0.042 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.042 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.9 all KL = 0.992 +- 0.042 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.064 (in-sample avg dev_std = 0.075)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.736
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.73
SUFF++ for r=0.3 class 0.0 = 0.913 +- 0.098 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.3 class 1.0 = 0.97 +- 0.098 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.3 all KL = 0.957 +- 0.098 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.3 all L1 = 0.942 +- 0.101 (in-sample avg dev_std = 0.168)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.759
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.754
SUFF++ for r=0.6 class 0.0 = 0.934 +- 0.091 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.6 class 1.0 = 0.972 +- 0.091 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.6 all KL = 0.97 +- 0.091 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.6 all L1 = 0.954 +- 0.106 (in-sample avg dev_std = 0.128)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.792
SUFF++ for r=0.9 class 0.0 = 0.971 +- 0.042 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 class 1.0 = 0.989 +- 0.042 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all KL = 0.991 +- 0.042 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all L1 = 0.98 +- 0.062 (in-sample avg dev_std = 0.080)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.854
NEC for r=0.6 class 0.0 = 0.09 +- 0.122 (in-sample avg dev_std = 0.104)
NEC for r=0.6 class 1.0 = 0.048 +- 0.122 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all KL = 0.048 +- 0.122 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all L1 = 0.065 +- 0.126 (in-sample avg dev_std = 0.104)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.067 +- 0.103 (in-sample avg dev_std = 0.108)
NEC for r=0.9 class 1.0 = 0.03 +- 0.103 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all KL = 0.032 +- 0.103 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all L1 = 0.046 +- 0.118 (in-sample avg dev_std = 0.108)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.068 +- 0.110 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.032 +- 0.110 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.036 +- 0.110 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.047 +- 0.121 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.806
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.797
NEC for r=0.3 class 0.0 = 0.102 +- 0.139 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 1.0 = 0.07 +- 0.139 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all KL = 0.062 +- 0.139 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all L1 = 0.085 +- 0.141 (in-sample avg dev_std = 0.143)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.835
NEC for r=0.6 class 0.0 = 0.069 +- 0.096 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 1.0 = 0.036 +- 0.096 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all KL = 0.032 +- 0.096 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all L1 = 0.052 +- 0.109 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.856
NEC for r=0.9 class 0.0 = 0.061 +- 0.085 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 1.0 = 0.034 +- 0.085 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all KL = 0.027 +- 0.085 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all L1 = 0.047 +- 0.110 (in-sample avg dev_std = 0.116)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.053 +- 0.085 (in-sample avg dev_std = 0.112)
NEC for r=1.0 class 1.0 = 0.035 +- 0.085 (in-sample avg dev_std = 0.112)
NEC for r=1.0 all KL = 0.025 +- 0.085 (in-sample avg dev_std = 0.112)
NEC for r=1.0 all L1 = 0.043 +- 0.106 (in-sample avg dev_std = 0.112)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.736
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.739
NEC for r=0.3 class 0.0 = 0.094 +- 0.093 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1.0 = 0.04 +- 0.093 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.038 +- 0.093 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.066 +- 0.117 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.759
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.767
NEC for r=0.6 class 0.0 = 0.078 +- 0.086 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 1.0 = 0.031 +- 0.086 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all KL = 0.031 +- 0.086 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all L1 = 0.054 +- 0.114 (in-sample avg dev_std = 0.122)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.793
NEC for r=0.9 class 0.0 = 0.079 +- 0.094 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 1.0 = 0.031 +- 0.094 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all KL = 0.034 +- 0.094 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all L1 = 0.054 +- 0.123 (in-sample avg dev_std = 0.123)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.799
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.799
NEC for r=1.0 class 0.0 = 0.074 +- 0.099 (in-sample avg dev_std = 0.120)
NEC for r=1.0 class 1.0 = 0.032 +- 0.099 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all KL = 0.033 +- 0.099 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all L1 = 0.052 +- 0.122 (in-sample avg dev_std = 0.120)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:34:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:34:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0756
ID Validation ACCURACY: 0.8723
ID Validation Loss: 0.4465
ID Test ACCURACY: 0.8676
ID Test Loss: 0.5108
OOD Validation ACCURACY: 0.8666
OOD Validation Loss: 0.6408
OOD Test ACCURACY: 0.7975
OOD Test Loss: 1.4831

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9484
Train Loss: 0.0800
ID Validation ACCURACY: 0.8668
ID Validation Loss: 0.3737
ID Test ACCURACY: 0.8653
ID Test Loss: 0.4167
OOD Validation ACCURACY: 0.8711
OOD Validation Loss: 0.4745
OOD Test ACCURACY: 0.8178
OOD Test Loss: 0.8997

[0m[1;37mINFO[0m: [1mChartInfo 0.8676 0.7975 0.8653 0.8178 0.8668 0.8711[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:34:04 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.863
SUFF++ for r=0.6 class 0.0 = 0.931 +- 0.086 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.086 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all KL = 0.962 +- 0.086 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all L1 = 0.949 +- 0.094 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0.0 = 0.957 +- 0.078 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.9 class 1.0 = 0.958 +- 0.078 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.9 all KL = 0.975 +- 0.078 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.101 (in-sample avg dev_std = 0.097)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.808
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.801
SUFF++ for r=0.3 class 0.0 = 0.916 +- 0.098 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 class 1.0 = 0.945 +- 0.098 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 all KL = 0.954 +- 0.098 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.099 (in-sample avg dev_std = 0.171)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.819
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.821
SUFF++ for r=0.6 class 0.0 = 0.952 +- 0.070 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.6 class 1.0 = 0.972 +- 0.070 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.6 all KL = 0.98 +- 0.070 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.6 all L1 = 0.962 +- 0.086 (in-sample avg dev_std = 0.097)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.979 +- 0.038 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.9 class 1.0 = 0.986 +- 0.038 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.9 all KL = 0.992 +- 0.038 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.061 (in-sample avg dev_std = 0.072)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.73
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.733
SUFF++ for r=0.3 class 0.0 = 0.911 +- 0.103 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 class 1.0 = 0.963 +- 0.103 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 all KL = 0.956 +- 0.103 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 all L1 = 0.938 +- 0.100 (in-sample avg dev_std = 0.171)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.759
SUFF++ for r=0.6 class 0.0 = 0.922 +- 0.090 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 1.0 = 0.972 +- 0.090 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 all KL = 0.969 +- 0.090 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 all L1 = 0.948 +- 0.109 (in-sample avg dev_std = 0.127)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.801
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.8
SUFF++ for r=0.9 class 0.0 = 0.971 +- 0.040 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.9 class 1.0 = 0.987 +- 0.040 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.9 all KL = 0.991 +- 0.040 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.9 all L1 = 0.979 +- 0.060 (in-sample avg dev_std = 0.082)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.856
NEC for r=0.6 class 0.0 = 0.092 +- 0.140 (in-sample avg dev_std = 0.127)
NEC for r=0.6 class 1.0 = 0.059 +- 0.140 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all KL = 0.055 +- 0.140 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all L1 = 0.073 +- 0.130 (in-sample avg dev_std = 0.127)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.057 +- 0.100 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1.0 = 0.04 +- 0.100 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.034 +- 0.100 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.047 +- 0.119 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.868
NEC for r=1.0 class 0.0 = 0.062 +- 0.103 (in-sample avg dev_std = 0.097)
NEC for r=1.0 class 1.0 = 0.041 +- 0.103 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all KL = 0.036 +- 0.103 (in-sample avg dev_std = 0.097)
NEC for r=1.0 all L1 = 0.05 +- 0.124 (in-sample avg dev_std = 0.097)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.809
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.799
NEC for r=0.3 class 0.0 = 0.124 +- 0.150 (in-sample avg dev_std = 0.141)
NEC for r=0.3 class 1.0 = 0.07 +- 0.150 (in-sample avg dev_std = 0.141)
NEC for r=0.3 all KL = 0.071 +- 0.150 (in-sample avg dev_std = 0.141)
NEC for r=0.3 all L1 = 0.096 +- 0.138 (in-sample avg dev_std = 0.141)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.819
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.82
NEC for r=0.6 class 0.0 = 0.082 +- 0.103 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1.0 = 0.037 +- 0.103 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.035 +- 0.103 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.058 +- 0.115 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.855
NEC for r=0.9 class 0.0 = 0.06 +- 0.084 (in-sample avg dev_std = 0.111)
NEC for r=0.9 class 1.0 = 0.036 +- 0.084 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all KL = 0.026 +- 0.084 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all L1 = 0.047 +- 0.106 (in-sample avg dev_std = 0.111)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.868
NEC for r=1.0 class 0.0 = 0.058 +- 0.082 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 1.0 = 0.03 +- 0.082 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all KL = 0.025 +- 0.082 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all L1 = 0.043 +- 0.098 (in-sample avg dev_std = 0.111)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.73
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.741
NEC for r=0.3 class 0.0 = 0.103 +- 0.091 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 1.0 = 0.046 +- 0.091 (in-sample avg dev_std = 0.119)
NEC for r=0.3 all KL = 0.039 +- 0.091 (in-sample avg dev_std = 0.119)
NEC for r=0.3 all L1 = 0.074 +- 0.117 (in-sample avg dev_std = 0.119)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.762
NEC for r=0.6 class 0.0 = 0.091 +- 0.085 (in-sample avg dev_std = 0.116)
NEC for r=0.6 class 1.0 = 0.032 +- 0.085 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all KL = 0.033 +- 0.085 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all L1 = 0.061 +- 0.113 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.801
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.791
NEC for r=0.9 class 0.0 = 0.085 +- 0.102 (in-sample avg dev_std = 0.119)
NEC for r=0.9 class 1.0 = 0.036 +- 0.102 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all KL = 0.037 +- 0.102 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all L1 = 0.059 +- 0.125 (in-sample avg dev_std = 0.119)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.803
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.796
NEC for r=1.0 class 0.0 = 0.082 +- 0.096 (in-sample avg dev_std = 0.121)
NEC for r=1.0 class 1.0 = 0.034 +- 0.096 (in-sample avg dev_std = 0.121)
NEC for r=1.0 all KL = 0.036 +- 0.096 (in-sample avg dev_std = 0.121)
NEC for r=1.0 all L1 = 0.057 +- 0.126 (in-sample avg dev_std = 0.121)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:37:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:37:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9486
Train Loss: 0.0779
ID Validation ACCURACY: 0.8753
ID Validation Loss: 0.3924
ID Test ACCURACY: 0.8663
ID Test Loss: 0.4411
OOD Validation ACCURACY: 0.8641
OOD Validation Loss: 0.5632
OOD Test ACCURACY: 0.8001
OOD Test Loss: 1.3902

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.9482
Train Loss: 0.0802
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.3589
ID Test ACCURACY: 0.8689
ID Test Loss: 0.4134
OOD Validation ACCURACY: 0.8710
OOD Validation Loss: 0.4958
OOD Test ACCURACY: 0.8212
OOD Test Loss: 0.9489

[0m[1;37mINFO[0m: [1mChartInfo 0.8663 0.8001 0.8689 0.8212 0.8710 0.8710[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:37:04 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.854
SUFF++ for r=0.6 class 0.0 = 0.931 +- 0.089 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 class 1.0 = 0.951 +- 0.089 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all KL = 0.963 +- 0.089 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.102 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.858
SUFF++ for r=0.9 class 0.0 = 0.926 +- 0.103 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 class 1.0 = 0.954 +- 0.103 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all KL = 0.963 +- 0.103 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.127 (in-sample avg dev_std = 0.119)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.795
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.793
SUFF++ for r=0.3 class 0.0 = 0.924 +- 0.069 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.3 class 1.0 = 0.945 +- 0.069 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.3 all KL = 0.966 +- 0.069 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.3 all L1 = 0.935 +- 0.089 (in-sample avg dev_std = 0.141)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.838
SUFF++ for r=0.6 class 0.0 = 0.953 +- 0.049 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.6 class 1.0 = 0.975 +- 0.049 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.6 all KL = 0.984 +- 0.049 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.6 all L1 = 0.964 +- 0.071 (in-sample avg dev_std = 0.088)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0.0 = 0.978 +- 0.025 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.025 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 all KL = 0.994 +- 0.025 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 all L1 = 0.981 +- 0.056 (in-sample avg dev_std = 0.064)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.72
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.719
SUFF++ for r=0.3 class 0.0 = 0.918 +- 0.073 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.3 class 1.0 = 0.956 +- 0.073 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.3 all KL = 0.966 +- 0.073 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.3 all L1 = 0.938 +- 0.090 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.777
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.773
SUFF++ for r=0.6 class 0.0 = 0.926 +- 0.053 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.6 class 1.0 = 0.967 +- 0.053 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.6 all KL = 0.978 +- 0.053 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.6 all L1 = 0.947 +- 0.096 (in-sample avg dev_std = 0.098)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.805
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.036 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.036 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.9 all KL = 0.991 +- 0.036 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.060 (in-sample avg dev_std = 0.074)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.841
NEC for r=0.6 class 0.0 = 0.103 +- 0.138 (in-sample avg dev_std = 0.119)
NEC for r=0.6 class 1.0 = 0.064 +- 0.138 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all KL = 0.054 +- 0.138 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all L1 = 0.081 +- 0.131 (in-sample avg dev_std = 0.119)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.075 +- 0.098 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 1.0 = 0.048 +- 0.098 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all KL = 0.038 +- 0.098 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all L1 = 0.059 +- 0.129 (in-sample avg dev_std = 0.099)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.079 +- 0.109 (in-sample avg dev_std = 0.099)
NEC for r=1.0 class 1.0 = 0.049 +- 0.109 (in-sample avg dev_std = 0.099)
NEC for r=1.0 all KL = 0.043 +- 0.109 (in-sample avg dev_std = 0.099)
NEC for r=1.0 all L1 = 0.061 +- 0.132 (in-sample avg dev_std = 0.099)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.796
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.799
NEC for r=0.3 class 0.0 = 0.121 +- 0.114 (in-sample avg dev_std = 0.124)
NEC for r=0.3 class 1.0 = 0.071 +- 0.114 (in-sample avg dev_std = 0.124)
NEC for r=0.3 all KL = 0.058 +- 0.114 (in-sample avg dev_std = 0.124)
NEC for r=0.3 all L1 = 0.095 +- 0.124 (in-sample avg dev_std = 0.124)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.835
NEC for r=0.6 class 0.0 = 0.079 +- 0.071 (in-sample avg dev_std = 0.098)
NEC for r=0.6 class 1.0 = 0.041 +- 0.071 (in-sample avg dev_std = 0.098)
NEC for r=0.6 all KL = 0.028 +- 0.071 (in-sample avg dev_std = 0.098)
NEC for r=0.6 all L1 = 0.059 +- 0.099 (in-sample avg dev_std = 0.098)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.056 +- 0.042 (in-sample avg dev_std = 0.080)
NEC for r=0.9 class 1.0 = 0.037 +- 0.042 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all KL = 0.018 +- 0.042 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all L1 = 0.046 +- 0.087 (in-sample avg dev_std = 0.080)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.88
NEC for r=1.0 class 0.0 = 0.056 +- 0.055 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 1.0 = 0.037 +- 0.055 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all KL = 0.019 +- 0.055 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all L1 = 0.046 +- 0.092 (in-sample avg dev_std = 0.088)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.72
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.732
NEC for r=0.3 class 0.0 = 0.107 +- 0.077 (in-sample avg dev_std = 0.108)
NEC for r=0.3 class 1.0 = 0.055 +- 0.077 (in-sample avg dev_std = 0.108)
NEC for r=0.3 all KL = 0.037 +- 0.077 (in-sample avg dev_std = 0.108)
NEC for r=0.3 all L1 = 0.08 +- 0.109 (in-sample avg dev_std = 0.108)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.777
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.778
NEC for r=0.6 class 0.0 = 0.096 +- 0.057 (in-sample avg dev_std = 0.099)
NEC for r=0.6 class 1.0 = 0.038 +- 0.057 (in-sample avg dev_std = 0.099)
NEC for r=0.6 all KL = 0.027 +- 0.057 (in-sample avg dev_std = 0.099)
NEC for r=0.6 all L1 = 0.066 +- 0.107 (in-sample avg dev_std = 0.099)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.802
NEC for r=0.9 class 0.0 = 0.084 +- 0.075 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1.0 = 0.041 +- 0.075 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.031 +- 0.075 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.062 +- 0.111 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.82
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.808
NEC for r=1.0 class 0.0 = 0.09 +- 0.088 (in-sample avg dev_std = 0.111)
NEC for r=1.0 class 1.0 = 0.043 +- 0.088 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all KL = 0.035 +- 0.088 (in-sample avg dev_std = 0.111)
NEC for r=1.0 all L1 = 0.066 +- 0.121 (in-sample avg dev_std = 0.111)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:40:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:40:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0755
ID Validation ACCURACY: 0.8736
ID Validation Loss: 0.4811
ID Test ACCURACY: 0.8710
ID Test Loss: 0.5250
OOD Validation ACCURACY: 0.8702
OOD Validation Loss: 0.6926
OOD Test ACCURACY: 0.8091
OOD Test Loss: 1.7159

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0762
ID Validation ACCURACY: 0.8672
ID Validation Loss: 0.4375
ID Test ACCURACY: 0.8708
ID Test Loss: 0.4836
OOD Validation ACCURACY: 0.8713
OOD Validation Loss: 0.5891
OOD Test ACCURACY: 0.8152
OOD Test Loss: 1.4220

[0m[1;37mINFO[0m: [1mChartInfo 0.8710 0.8091 0.8708 0.8152 0.8672 0.8713[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:40:07 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.877
SUFF++ for r=0.6 class 0.0 = 0.931 +- 0.105 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.105 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 all KL = 0.958 +- 0.105 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.6 all L1 = 0.949 +- 0.103 (in-sample avg dev_std = 0.148)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.894
SUFF++ for r=0.9 class 0.0 = 0.968 +- 0.077 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.077 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.976 +- 0.077 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.963 +- 0.089 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.814
SUFF++ for r=0.3 class 0.0 = 0.921 +- 0.090 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.3 class 1.0 = 0.946 +- 0.090 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.3 all KL = 0.957 +- 0.090 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.3 all L1 = 0.934 +- 0.098 (in-sample avg dev_std = 0.165)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.848
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.847
SUFF++ for r=0.6 class 0.0 = 0.953 +- 0.074 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.6 class 1.0 = 0.977 +- 0.074 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.6 all KL = 0.979 +- 0.074 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.6 all L1 = 0.965 +- 0.083 (in-sample avg dev_std = 0.092)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.978 +- 0.042 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 class 1.0 = 0.986 +- 0.042 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all KL = 0.992 +- 0.042 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.062 (in-sample avg dev_std = 0.080)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.733
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.726
SUFF++ for r=0.3 class 0.0 = 0.909 +- 0.114 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 1.0 = 0.965 +- 0.114 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 all KL = 0.951 +- 0.114 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 all L1 = 0.938 +- 0.109 (in-sample avg dev_std = 0.179)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.778
SUFF++ for r=0.6 class 0.0 = 0.934 +- 0.095 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 1.0 = 0.968 +- 0.095 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all KL = 0.967 +- 0.095 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all L1 = 0.952 +- 0.108 (in-sample avg dev_std = 0.136)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.815
SUFF++ for r=0.9 class 0.0 = 0.972 +- 0.048 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.048 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.989 +- 0.048 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.978 +- 0.066 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.1 +- 0.155 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1.0 = 0.051 +- 0.155 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.059 +- 0.155 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.072 +- 0.139 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.885
NEC for r=0.9 class 0.0 = 0.049 +- 0.100 (in-sample avg dev_std = 0.104)
NEC for r=0.9 class 1.0 = 0.039 +- 0.100 (in-sample avg dev_std = 0.104)
NEC for r=0.9 all KL = 0.032 +- 0.100 (in-sample avg dev_std = 0.104)
NEC for r=0.9 all L1 = 0.043 +- 0.112 (in-sample avg dev_std = 0.104)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.885
NEC for r=1.0 class 0.0 = 0.056 +- 0.115 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.04 +- 0.115 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.037 +- 0.115 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.047 +- 0.123 (in-sample avg dev_std = 0.105)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.809
NEC for r=0.3 class 0.0 = 0.118 +- 0.150 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 1.0 = 0.066 +- 0.150 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all KL = 0.067 +- 0.150 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all L1 = 0.091 +- 0.139 (in-sample avg dev_std = 0.135)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.848
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.847
NEC for r=0.6 class 0.0 = 0.067 +- 0.095 (in-sample avg dev_std = 0.120)
NEC for r=0.6 class 1.0 = 0.036 +- 0.095 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all KL = 0.031 +- 0.095 (in-sample avg dev_std = 0.120)
NEC for r=0.6 all L1 = 0.051 +- 0.107 (in-sample avg dev_std = 0.120)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.867
NEC for r=0.9 class 0.0 = 0.054 +- 0.086 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1.0 = 0.03 +- 0.086 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.025 +- 0.086 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.042 +- 0.105 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.053 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=1.0 class 1.0 = 0.032 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all KL = 0.026 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all L1 = 0.042 +- 0.106 (in-sample avg dev_std = 0.106)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.733
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.741
NEC for r=0.3 class 0.0 = 0.1 +- 0.110 (in-sample avg dev_std = 0.127)
NEC for r=0.3 class 1.0 = 0.047 +- 0.110 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all KL = 0.044 +- 0.110 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all L1 = 0.073 +- 0.128 (in-sample avg dev_std = 0.127)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.776
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.775
NEC for r=0.6 class 0.0 = 0.086 +- 0.100 (in-sample avg dev_std = 0.142)
NEC for r=0.6 class 1.0 = 0.037 +- 0.100 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all KL = 0.039 +- 0.100 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all L1 = 0.061 +- 0.124 (in-sample avg dev_std = 0.142)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.811
NEC for r=0.9 class 0.0 = 0.08 +- 0.113 (in-sample avg dev_std = 0.136)
NEC for r=0.9 class 1.0 = 0.042 +- 0.113 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all KL = 0.042 +- 0.113 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all L1 = 0.061 +- 0.133 (in-sample avg dev_std = 0.136)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.818
NEC for r=1.0 class 0.0 = 0.078 +- 0.106 (in-sample avg dev_std = 0.138)
NEC for r=1.0 class 1.0 = 0.044 +- 0.106 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all KL = 0.041 +- 0.106 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all L1 = 0.06 +- 0.129 (in-sample avg dev_std = 0.138)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:43:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:43:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0755
ID Validation ACCURACY: 0.8725
ID Validation Loss: 0.4457
ID Test ACCURACY: 0.8729
ID Test Loss: 0.5184
OOD Validation ACCURACY: 0.8678
OOD Validation Loss: 0.6866
OOD Test ACCURACY: 0.7890
OOD Test Loss: 1.6341

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.9483
Train Loss: 0.0810
ID Validation ACCURACY: 0.8712
ID Validation Loss: 0.3622
ID Test ACCURACY: 0.8691
ID Test Loss: 0.4151
OOD Validation ACCURACY: 0.8721
OOD Validation Loss: 0.5108
OOD Test ACCURACY: 0.8097
OOD Test Loss: 0.9870

[0m[1;37mINFO[0m: [1mChartInfo 0.8729 0.7890 0.8691 0.8097 0.8712 0.8721[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:43:05 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.875
SUFF++ for r=0.6 class 0.0 = 0.937 +- 0.096 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.096 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 all KL = 0.961 +- 0.096 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 all L1 = 0.951 +- 0.102 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.927 +- 0.111 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.111 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.966 +- 0.111 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.135 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.789
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.784
SUFF++ for r=0.3 class 0.0 = 0.917 +- 0.095 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.3 class 1.0 = 0.954 +- 0.095 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.3 all KL = 0.956 +- 0.095 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.3 all L1 = 0.937 +- 0.102 (in-sample avg dev_std = 0.170)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.821
SUFF++ for r=0.6 class 0.0 = 0.948 +- 0.077 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 1.0 = 0.97 +- 0.077 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 all KL = 0.975 +- 0.077 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 all L1 = 0.959 +- 0.098 (in-sample avg dev_std = 0.120)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0.0 = 0.977 +- 0.051 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.051 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.99 +- 0.051 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.98 +- 0.068 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.727
SUFF++ for r=0.3 class 0.0 = 0.913 +- 0.098 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 class 1.0 = 0.971 +- 0.098 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 all KL = 0.959 +- 0.098 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.3 all L1 = 0.943 +- 0.100 (in-sample avg dev_std = 0.171)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.755
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.743
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.110 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 1.0 = 0.97 +- 0.110 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all KL = 0.962 +- 0.110 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all L1 = 0.945 +- 0.120 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.793
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.79
SUFF++ for r=0.9 class 0.0 = 0.969 +- 0.048 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.048 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all KL = 0.988 +- 0.048 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.067 (in-sample avg dev_std = 0.095)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.865
NEC for r=0.6 class 0.0 = 0.086 +- 0.147 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.055 +- 0.147 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.058 +- 0.147 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.068 +- 0.134 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.869
NEC for r=0.9 class 0.0 = 0.072 +- 0.128 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.036 +- 0.128 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.042 +- 0.128 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.051 +- 0.129 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.869
NEC for r=1.0 class 0.0 = 0.078 +- 0.132 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.038 +- 0.132 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.045 +- 0.132 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.055 +- 0.135 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.788
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.784
NEC for r=0.3 class 0.0 = 0.116 +- 0.147 (in-sample avg dev_std = 0.139)
NEC for r=0.3 class 1.0 = 0.061 +- 0.147 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all KL = 0.066 +- 0.147 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all L1 = 0.087 +- 0.137 (in-sample avg dev_std = 0.139)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.827
NEC for r=0.6 class 0.0 = 0.075 +- 0.094 (in-sample avg dev_std = 0.124)
NEC for r=0.6 class 1.0 = 0.038 +- 0.094 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all KL = 0.033 +- 0.094 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all L1 = 0.056 +- 0.116 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.865
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.856
NEC for r=0.9 class 0.0 = 0.059 +- 0.084 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1.0 = 0.034 +- 0.084 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.028 +- 0.084 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.046 +- 0.108 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.869
NEC for r=1.0 class 0.0 = 0.056 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.029 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.025 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.042 +- 0.106 (in-sample avg dev_std = 0.105)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.729
NEC for r=0.3 class 0.0 = 0.1 +- 0.096 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 1.0 = 0.043 +- 0.096 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all KL = 0.042 +- 0.096 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all L1 = 0.071 +- 0.124 (in-sample avg dev_std = 0.123)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.755
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.749
NEC for r=0.6 class 0.0 = 0.094 +- 0.090 (in-sample avg dev_std = 0.135)
NEC for r=0.6 class 1.0 = 0.029 +- 0.090 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all KL = 0.035 +- 0.090 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all L1 = 0.06 +- 0.125 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.793
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.78
NEC for r=0.9 class 0.0 = 0.086 +- 0.116 (in-sample avg dev_std = 0.137)
NEC for r=0.9 class 1.0 = 0.039 +- 0.116 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all KL = 0.041 +- 0.116 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all L1 = 0.062 +- 0.137 (in-sample avg dev_std = 0.137)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.801
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.789
NEC for r=1.0 class 0.0 = 0.086 +- 0.124 (in-sample avg dev_std = 0.143)
NEC for r=1.0 class 1.0 = 0.044 +- 0.124 (in-sample avg dev_std = 0.143)
NEC for r=1.0 all KL = 0.044 +- 0.124 (in-sample avg dev_std = 0.143)
NEC for r=1.0 all L1 = 0.064 +- 0.143 (in-sample avg dev_std = 0.143)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.966, 0.962, 1.0], 'all_L1': [0.954, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.962, 0.975, 1.0], 'all_L1': [0.949, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.963, 0.963, 1.0], 'all_L1': [0.943, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.958, 0.976, 1.0], 'all_L1': [0.949, 0.963, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.961, 0.966, 1.0], 'all_L1': [0.951, 0.947, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.048, 0.032, 0.036], 'all_L1': [0.065, 0.046, 0.047]}), defaultdict(<class 'list'>, {'all_KL': [0.055, 0.034, 0.036], 'all_L1': [0.073, 0.047, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.054, 0.038, 0.043], 'all_L1': [0.081, 0.059, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.059, 0.032, 0.037], 'all_L1': [0.072, 0.043, 0.047]}), defaultdict(<class 'list'>, {'all_KL': [0.058, 0.042, 0.045], 'all_L1': [0.068, 0.051, 0.055]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.959, 0.977, 0.992, 1.0], 'all_L1': [0.937, 0.961, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.954, 0.98, 0.992, 1.0], 'all_L1': [0.931, 0.962, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.966, 0.984, 0.994, 1.0], 'all_L1': [0.935, 0.964, 0.981, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.957, 0.979, 0.992, 1.0], 'all_L1': [0.934, 0.965, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.956, 0.975, 0.99, 1.0], 'all_L1': [0.937, 0.959, 0.98, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.062, 0.032, 0.027, 0.025], 'all_L1': [0.085, 0.052, 0.047, 0.043]}), defaultdict(<class 'list'>, {'all_KL': [0.071, 0.035, 0.026, 0.025], 'all_L1': [0.096, 0.058, 0.047, 0.043]}), defaultdict(<class 'list'>, {'all_KL': [0.058, 0.028, 0.018, 0.019], 'all_L1': [0.095, 0.059, 0.046, 0.046]}), defaultdict(<class 'list'>, {'all_KL': [0.067, 0.031, 0.025, 0.026], 'all_L1': [0.091, 0.051, 0.042, 0.042]}), defaultdict(<class 'list'>, {'all_KL': [0.066, 0.033, 0.028, 0.025], 'all_L1': [0.087, 0.056, 0.046, 0.042]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.957, 0.97, 0.991, 1.0], 'all_L1': [0.942, 0.954, 0.98, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.956, 0.969, 0.991, 1.0], 'all_L1': [0.938, 0.948, 0.979, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.966, 0.978, 0.991, 1.0], 'all_L1': [0.938, 0.947, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.951, 0.967, 0.989, 1.0], 'all_L1': [0.938, 0.952, 0.978, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.959, 0.962, 0.988, 1.0], 'all_L1': [0.943, 0.945, 0.977, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.038, 0.031, 0.034, 0.033], 'all_L1': [0.066, 0.054, 0.054, 0.052]}), defaultdict(<class 'list'>, {'all_KL': [0.039, 0.033, 0.037, 0.036], 'all_L1': [0.074, 0.061, 0.059, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.027, 0.031, 0.035], 'all_L1': [0.08, 0.066, 0.062, 0.066]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.039, 0.042, 0.041], 'all_L1': [0.073, 0.061, 0.061, 0.06]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.035, 0.041, 0.044], 'all_L1': [0.071, 0.06, 0.062, 0.064]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.949 +- 0.004, 0.951 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.962 +- 0.003, 0.968 +- 0.006, 1.000 +- 0.000
suff++_acc_int  =  0.867 +- 0.009, 0.875 +- 0.012
nec class all_L1  =  0.072 +- 0.005, 0.049 +- 0.006, 0.052 +- 0.005
nec class all_KL  =  0.055 +- 0.004, 0.036 +- 0.004, 0.039 +- 0.004
nec_acc_int  =  0.856 +- 0.009, 0.873 +- 0.006, 0.873 +- 0.006

Eval split val
suff++ class all_L1  =  0.935 +- 0.002, 0.962 +- 0.002, 0.981 +- 0.001, 1.000 +- 0.000
suff++ class all_KL  =  0.958 +- 0.004, 0.979 +- 0.003, 0.992 +- 0.001, 1.000 +- 0.000
suff++_acc_int  =  0.797 +- 0.010, 0.832 +- 0.010, 0.869 +- 0.008
nec class all_L1  =  0.091 +- 0.004, 0.055 +- 0.003, 0.046 +- 0.002, 0.043 +- 0.001
nec class all_KL  =  0.065 +- 0.004, 0.032 +- 0.002, 0.025 +- 0.004, 0.024 +- 0.003
nec_acc_int  =  0.797 +- 0.008, 0.833 +- 0.009, 0.860 +- 0.005, 0.871 +- 0.006

Eval split test
suff++ class all_L1  =  0.940 +- 0.002, 0.949 +- 0.003, 0.978 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.958 +- 0.005, 0.969 +- 0.005, 0.990 +- 0.001, 1.000 +- 0.000
suff++_acc_int  =  0.727 +- 0.005, 0.762 +- 0.013, 0.800 +- 0.009
nec class all_L1  =  0.073 +- 0.005, 0.060 +- 0.004, 0.060 +- 0.003, 0.060 +- 0.005
nec class all_KL  =  0.040 +- 0.003, 0.033 +- 0.004, 0.037 +- 0.004, 0.038 +- 0.004
nec_acc_int  =  0.736 +- 0.005, 0.766 +- 0.010, 0.795 +- 0.011, 0.802 +- 0.010


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.511 +- 0.001, 0.500 +- 0.003, 0.526 +- 0.003
Faith. Armon (L1)= 		  =  0.133 +- 0.009, 0.093 +- 0.010, 0.099 +- 0.010
Faith. GMean (L1)= 	  =  0.261 +- 0.009, 0.216 +- 0.011, 0.228 +- 0.012
Faith. Aritm (KL)= 		  =  0.508 +- 0.001, 0.502 +- 0.003, 0.520 +- 0.002
Faith. Armon (KL)= 		  =  0.104 +- 0.007, 0.069 +- 0.007, 0.076 +- 0.007
Faith. GMean (KL)= 	  =  0.229 +- 0.008, 0.185 +- 0.010, 0.198 +- 0.010

Eval split val
Faith. Aritm (L1)= 		  =  0.513 +- 0.001, 0.509 +- 0.002, 0.514 +- 0.001, 0.522 +- 0.001
Faith. Armon (L1)= 		  =  0.165 +- 0.007, 0.104 +- 0.006, 0.087 +- 0.003, 0.083 +- 0.003
Faith. GMean (L1)= 	  =  0.291 +- 0.007, 0.230 +- 0.007, 0.212 +- 0.004, 0.208 +- 0.004
Faith. Aritm (KL)= 		  =  0.512 +- 0.001, 0.505 +- 0.001, 0.508 +- 0.001, 0.512 +- 0.001
Faith. Armon (KL)= 		  =  0.121 +- 0.008, 0.062 +- 0.004, 0.048 +- 0.007, 0.047 +- 0.005
Faith. GMean (KL)= 	  =  0.249 +- 0.008, 0.176 +- 0.006, 0.156 +- 0.012, 0.155 +- 0.009

Eval split test
Faith. Aritm (L1)= 		  =  0.506 +- 0.002, 0.505 +- 0.002, 0.519 +- 0.001, 0.530 +- 0.002
Faith. Armon (L1)= 		  =  0.135 +- 0.008, 0.114 +- 0.007, 0.112 +- 0.005, 0.113 +- 0.009
Faith. GMean (L1)= 	  =  0.261 +- 0.008, 0.239 +- 0.007, 0.241 +- 0.006, 0.244 +- 0.010
Faith. Aritm (KL)= 		  =  0.499 +- 0.002, 0.501 +- 0.002, 0.513 +- 0.002, 0.519 +- 0.002
Faith. Armon (KL)= 		  =  0.077 +- 0.005, 0.064 +- 0.007, 0.071 +- 0.008, 0.073 +- 0.008
Faith. GMean (KL)= 	  =  0.196 +- 0.006, 0.178 +- 0.011, 0.191 +- 0.011, 0.194 +- 0.010
Computed for split load_split = id



Completed in  0:14:58.756144  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length topk

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:46:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:46:29 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0752
ID Validation ACCURACY: 0.8791
ID Validation Loss: 0.4321
ID Test ACCURACY: 0.8746
ID Test Loss: 0.5077
OOD Validation ACCURACY: 0.8755
OOD Validation Loss: 0.6420
OOD Test ACCURACY: 0.8066
OOD Test Loss: 1.9192

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8774
ID Validation Loss: 0.4881
ID Test ACCURACY: 0.8768
ID Test Loss: 0.5823
OOD Validation ACCURACY: 0.8812
OOD Validation Loss: 0.7157
OOD Test ACCURACY: 0.8217
OOD Test Loss: 1.7909

[0m[1;37mINFO[0m: [1mChartInfo 0.8746 0.8066 0.8768 0.8217 0.8774 0.8812[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:46:31 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.857
SUFF++ for r=0.6 class 0.0 = 0.919 +- 0.170 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 1.0 = 0.956 +- 0.170 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all KL = 0.932 +- 0.170 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all L1 = 0.941 +- 0.118 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.869
SUFF++ for r=0.9 class 0.0 = 0.924 +- 0.156 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.156 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.9 all KL = 0.954 +- 0.156 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.150 (in-sample avg dev_std = 0.123)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.776
SUFF++ for r=0.3 class 0.0 = 0.897 +- 0.193 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 1.0 = 0.922 +- 0.193 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all KL = 0.899 +- 0.193 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all L1 = 0.91 +- 0.135 (in-sample avg dev_std = 0.266)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.819
SUFF++ for r=0.6 class 0.0 = 0.927 +- 0.150 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 1.0 = 0.961 +- 0.150 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all KL = 0.947 +- 0.150 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all L1 = 0.945 +- 0.125 (in-sample avg dev_std = 0.158)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.876
SUFF++ for r=0.9 class 0.0 = 0.955 +- 0.089 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.089 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.97 +- 0.089 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.965 +- 0.084 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.74
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.724
SUFF++ for r=0.3 class 0.0 = 0.879 +- 0.155 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 class 1.0 = 0.951 +- 0.155 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 all KL = 0.919 +- 0.155 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.3 all L1 = 0.916 +- 0.131 (in-sample avg dev_std = 0.237)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0.0 = 0.903 +- 0.120 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 class 1.0 = 0.956 +- 0.120 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 all KL = 0.946 +- 0.120 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.6 all L1 = 0.931 +- 0.128 (in-sample avg dev_std = 0.169)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0.0 = 0.954 +- 0.068 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.068 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.981 +- 0.068 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.083 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.856
NEC for r=0.6 class 0.0 = 0.071 +- 0.143 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.044 +- 0.143 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.046 +- 0.143 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.055 +- 0.130 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.07 +- 0.154 (in-sample avg dev_std = 0.097)
NEC for r=0.9 class 1.0 = 0.035 +- 0.154 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all KL = 0.041 +- 0.154 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all L1 = 0.05 +- 0.141 (in-sample avg dev_std = 0.097)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.049 +- 0.139 (in-sample avg dev_std = 0.089)
NEC for r=1.0 class 1.0 = 0.033 +- 0.139 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all KL = 0.031 +- 0.139 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all L1 = 0.04 +- 0.121 (in-sample avg dev_std = 0.089)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.791
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.783
NEC for r=0.3 class 0.0 = 0.111 +- 0.168 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 1.0 = 0.059 +- 0.168 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all KL = 0.065 +- 0.168 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all L1 = 0.084 +- 0.156 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.837
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.83
NEC for r=0.6 class 0.0 = 0.062 +- 0.109 (in-sample avg dev_std = 0.125)
NEC for r=0.6 class 1.0 = 0.031 +- 0.109 (in-sample avg dev_std = 0.125)
NEC for r=0.6 all KL = 0.032 +- 0.109 (in-sample avg dev_std = 0.125)
NEC for r=0.6 all L1 = 0.046 +- 0.109 (in-sample avg dev_std = 0.125)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.879
NEC for r=0.9 class 0.0 = 0.053 +- 0.086 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1.0 = 0.029 +- 0.086 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.023 +- 0.086 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.04 +- 0.103 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.887
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.88
NEC for r=1.0 class 0.0 = 0.046 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.026 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.02 +- 0.085 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.036 +- 0.099 (in-sample avg dev_std = 0.092)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.74
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.739
NEC for r=0.3 class 0.0 = 0.1 +- 0.102 (in-sample avg dev_std = 0.122)
NEC for r=0.3 class 1.0 = 0.04 +- 0.102 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all KL = 0.04 +- 0.102 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all L1 = 0.069 +- 0.127 (in-sample avg dev_std = 0.122)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.089 +- 0.093 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1.0 = 0.041 +- 0.093 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.037 +- 0.093 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.064 +- 0.128 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.812
NEC for r=0.9 class 0.0 = 0.082 +- 0.110 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.037 +- 0.110 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.038 +- 0.110 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.059 +- 0.131 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.816
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.817
NEC for r=1.0 class 0.0 = 0.071 +- 0.095 (in-sample avg dev_std = 0.118)
NEC for r=1.0 class 1.0 = 0.03 +- 0.095 (in-sample avg dev_std = 0.118)
NEC for r=1.0 all KL = 0.032 +- 0.095 (in-sample avg dev_std = 0.118)
NEC for r=1.0 all L1 = 0.05 +- 0.120 (in-sample avg dev_std = 0.118)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:49:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:49:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8776
ID Validation Loss: 0.4757
ID Test ACCURACY: 0.8753
ID Test Loss: 0.5535
OOD Validation ACCURACY: 0.8785
OOD Validation Loss: 0.7425
OOD Test ACCURACY: 0.8070
OOD Test Loss: 1.9222

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0763
ID Validation ACCURACY: 0.8740
ID Validation Loss: 0.4109
ID Test ACCURACY: 0.8668
ID Test Loss: 0.4781
OOD Validation ACCURACY: 0.8817
OOD Validation Loss: 0.5226
OOD Test ACCURACY: 0.8245
OOD Test Loss: 1.0518

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8070 0.8668 0.8245 0.8740 0.8817[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:49:43 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.857
SUFF++ for r=0.6 class 0.0 = 0.916 +- 0.219 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.6 class 1.0 = 0.945 +- 0.219 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.6 all KL = 0.911 +- 0.219 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.6 all L1 = 0.933 +- 0.141 (in-sample avg dev_std = 0.226)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.861
SUFF++ for r=0.9 class 0.0 = 0.954 +- 0.135 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1.0 = 0.952 +- 0.135 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.961 +- 0.135 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.131 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.797
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.779
SUFF++ for r=0.3 class 0.0 = 0.894 +- 0.223 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.3 class 1.0 = 0.909 +- 0.223 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.3 all KL = 0.874 +- 0.223 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.3 all L1 = 0.901 +- 0.142 (in-sample avg dev_std = 0.300)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.832
SUFF++ for r=0.6 class 0.0 = 0.934 +- 0.158 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 1.0 = 0.955 +- 0.158 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 all KL = 0.94 +- 0.158 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 all L1 = 0.945 +- 0.125 (in-sample avg dev_std = 0.175)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.879
SUFF++ for r=0.9 class 0.0 = 0.957 +- 0.103 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.103 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all KL = 0.963 +- 0.103 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.094 (in-sample avg dev_std = 0.170)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.746
SUFF++ for r=0.3 class 0.0 = 0.882 +- 0.177 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 class 1.0 = 0.943 +- 0.177 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all KL = 0.902 +- 0.177 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.3 all L1 = 0.914 +- 0.133 (in-sample avg dev_std = 0.247)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.772
SUFF++ for r=0.6 class 0.0 = 0.899 +- 0.157 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 class 1.0 = 0.954 +- 0.157 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all KL = 0.932 +- 0.157 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.6 all L1 = 0.927 +- 0.149 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.822
SUFF++ for r=0.9 class 0.0 = 0.957 +- 0.095 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 1.0 = 0.975 +- 0.095 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all KL = 0.972 +- 0.095 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.094 (in-sample avg dev_std = 0.129)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.86
NEC for r=0.6 class 0.0 = 0.077 +- 0.175 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 1.0 = 0.051 +- 0.175 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all KL = 0.059 +- 0.175 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all L1 = 0.062 +- 0.145 (in-sample avg dev_std = 0.153)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.038 +- 0.113 (in-sample avg dev_std = 0.095)
NEC for r=0.9 class 1.0 = 0.035 +- 0.113 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all KL = 0.029 +- 0.113 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all L1 = 0.036 +- 0.108 (in-sample avg dev_std = 0.095)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.03 +- 0.108 (in-sample avg dev_std = 0.067)
NEC for r=1.0 class 1.0 = 0.029 +- 0.108 (in-sample avg dev_std = 0.067)
NEC for r=1.0 all KL = 0.024 +- 0.108 (in-sample avg dev_std = 0.067)
NEC for r=1.0 all L1 = 0.03 +- 0.097 (in-sample avg dev_std = 0.067)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.799
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.792
NEC for r=0.3 class 0.0 = 0.09 +- 0.143 (in-sample avg dev_std = 0.137)
NEC for r=0.3 class 1.0 = 0.058 +- 0.143 (in-sample avg dev_std = 0.137)
NEC for r=0.3 all KL = 0.058 +- 0.143 (in-sample avg dev_std = 0.137)
NEC for r=0.3 all L1 = 0.074 +- 0.137 (in-sample avg dev_std = 0.137)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.836
NEC for r=0.6 class 0.0 = 0.045 +- 0.093 (in-sample avg dev_std = 0.113)
NEC for r=0.6 class 1.0 = 0.036 +- 0.093 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all KL = 0.026 +- 0.093 (in-sample avg dev_std = 0.113)
NEC for r=0.6 all L1 = 0.04 +- 0.106 (in-sample avg dev_std = 0.113)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.877
NEC for r=0.9 class 0.0 = 0.045 +- 0.100 (in-sample avg dev_std = 0.104)
NEC for r=0.9 class 1.0 = 0.034 +- 0.100 (in-sample avg dev_std = 0.104)
NEC for r=0.9 all KL = 0.026 +- 0.100 (in-sample avg dev_std = 0.104)
NEC for r=0.9 all L1 = 0.039 +- 0.114 (in-sample avg dev_std = 0.104)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.884
NEC for r=1.0 class 0.0 = 0.042 +- 0.094 (in-sample avg dev_std = 0.103)
NEC for r=1.0 class 1.0 = 0.025 +- 0.094 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all KL = 0.022 +- 0.094 (in-sample avg dev_std = 0.103)
NEC for r=1.0 all L1 = 0.033 +- 0.103 (in-sample avg dev_std = 0.103)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.759
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.762
NEC for r=0.3 class 0.0 = 0.08 +- 0.107 (in-sample avg dev_std = 0.127)
NEC for r=0.3 class 1.0 = 0.042 +- 0.107 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all KL = 0.037 +- 0.107 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all L1 = 0.061 +- 0.124 (in-sample avg dev_std = 0.127)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.781
NEC for r=0.6 class 0.0 = 0.083 +- 0.112 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 1.0 = 0.037 +- 0.112 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all KL = 0.038 +- 0.112 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all L1 = 0.059 +- 0.134 (in-sample avg dev_std = 0.122)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
NEC for r=0.9 class 0.0 = 0.06 +- 0.110 (in-sample avg dev_std = 0.127)
NEC for r=0.9 class 1.0 = 0.04 +- 0.110 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all KL = 0.036 +- 0.110 (in-sample avg dev_std = 0.127)
NEC for r=0.9 all L1 = 0.049 +- 0.127 (in-sample avg dev_std = 0.127)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.814
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.825
NEC for r=1.0 class 0.0 = 0.063 +- 0.125 (in-sample avg dev_std = 0.141)
NEC for r=1.0 class 1.0 = 0.034 +- 0.125 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all KL = 0.039 +- 0.125 (in-sample avg dev_std = 0.141)
NEC for r=1.0 all L1 = 0.048 +- 0.131 (in-sample avg dev_std = 0.141)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:52:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:52:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9486
Train Loss: 0.0798
ID Validation ACCURACY: 0.8746
ID Validation Loss: 0.3678
ID Test ACCURACY: 0.8704
ID Test Loss: 0.3944
OOD Validation ACCURACY: 0.8745
OOD Validation Loss: 0.4302
OOD Test ACCURACY: 0.8230
OOD Test Loss: 0.6355

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 159...
[0m[1;37mINFO[0m: [1mCheckpoint 159: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8740
ID Validation Loss: 0.4532
ID Test ACCURACY: 0.8734
ID Test Loss: 0.4768
OOD Validation ACCURACY: 0.8804
OOD Validation Loss: 0.6063
OOD Test ACCURACY: 0.8281
OOD Test Loss: 1.3425

[0m[1;37mINFO[0m: [1mChartInfo 0.8704 0.8230 0.8734 0.8281 0.8740 0.8804[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:52:50 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.858
SUFF++ for r=0.6 class 0.0 = 0.902 +- 0.164 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.6 class 1.0 = 0.899 +- 0.164 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.6 all KL = 0.914 +- 0.164 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.6 all L1 = 0.9 +- 0.148 (in-sample avg dev_std = 0.227)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0.0 = 0.93 +- 0.098 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.938 +- 0.098 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.963 +- 0.098 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.128 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.769
SUFF++ for r=0.3 class 0.0 = 0.878 +- 0.162 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 1.0 = 0.852 +- 0.162 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all KL = 0.89 +- 0.162 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all L1 = 0.864 +- 0.149 (in-sample avg dev_std = 0.272)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.827
SUFF++ for r=0.6 class 0.0 = 0.904 +- 0.122 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 1.0 = 0.914 +- 0.122 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all KL = 0.941 +- 0.122 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all L1 = 0.909 +- 0.134 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0.0 = 0.955 +- 0.066 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1.0 = 0.95 +- 0.066 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.973 +- 0.066 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.086 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.764
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.762
SUFF++ for r=0.3 class 0.0 = 0.855 +- 0.102 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 1.0 = 0.885 +- 0.102 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all KL = 0.928 +- 0.102 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all L1 = 0.87 +- 0.133 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.805
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.795
SUFF++ for r=0.6 class 0.0 = 0.885 +- 0.095 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 1.0 = 0.918 +- 0.095 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all KL = 0.949 +- 0.095 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all L1 = 0.902 +- 0.131 (in-sample avg dev_std = 0.155)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.851
SUFF++ for r=0.9 class 0.0 = 0.942 +- 0.054 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.054 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.98 +- 0.054 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.090 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.874
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.865
NEC for r=0.6 class 0.0 = 0.078 +- 0.117 (in-sample avg dev_std = 0.135)
NEC for r=0.6 class 1.0 = 0.103 +- 0.117 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all KL = 0.059 +- 0.117 (in-sample avg dev_std = 0.135)
NEC for r=0.6 all L1 = 0.093 +- 0.138 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.861
NEC for r=0.9 class 0.0 = 0.061 +- 0.096 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.052 +- 0.096 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.031 +- 0.096 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.056 +- 0.125 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.04 +- 0.086 (in-sample avg dev_std = 0.087)
NEC for r=1.0 class 1.0 = 0.045 +- 0.086 (in-sample avg dev_std = 0.087)
NEC for r=1.0 all KL = 0.022 +- 0.086 (in-sample avg dev_std = 0.087)
NEC for r=1.0 all L1 = 0.043 +- 0.110 (in-sample avg dev_std = 0.087)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.791
NEC for r=0.3 class 0.0 = 0.127 +- 0.121 (in-sample avg dev_std = 0.148)
NEC for r=0.3 class 1.0 = 0.133 +- 0.121 (in-sample avg dev_std = 0.148)
NEC for r=0.3 all KL = 0.073 +- 0.121 (in-sample avg dev_std = 0.148)
NEC for r=0.3 all L1 = 0.13 +- 0.155 (in-sample avg dev_std = 0.148)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.841
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.837
NEC for r=0.6 class 0.0 = 0.074 +- 0.073 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.079 +- 0.073 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.034 +- 0.073 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.077 +- 0.116 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.06 +- 0.066 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 1.0 = 0.049 +- 0.066 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all KL = 0.023 +- 0.066 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all L1 = 0.054 +- 0.101 (in-sample avg dev_std = 0.099)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.053 +- 0.056 (in-sample avg dev_std = 0.091)
NEC for r=1.0 class 1.0 = 0.035 +- 0.056 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all KL = 0.018 +- 0.056 (in-sample avg dev_std = 0.091)
NEC for r=1.0 all L1 = 0.044 +- 0.088 (in-sample avg dev_std = 0.091)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.764
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.762
NEC for r=0.3 class 0.0 = 0.156 +- 0.116 (in-sample avg dev_std = 0.131)
NEC for r=0.3 class 1.0 = 0.127 +- 0.116 (in-sample avg dev_std = 0.131)
NEC for r=0.3 all KL = 0.069 +- 0.116 (in-sample avg dev_std = 0.131)
NEC for r=0.3 all L1 = 0.141 +- 0.158 (in-sample avg dev_std = 0.131)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.805
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.798
NEC for r=0.6 class 0.0 = 0.106 +- 0.068 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 1.0 = 0.079 +- 0.068 (in-sample avg dev_std = 0.110)
NEC for r=0.6 all KL = 0.037 +- 0.068 (in-sample avg dev_std = 0.110)
NEC for r=0.6 all L1 = 0.092 +- 0.124 (in-sample avg dev_std = 0.110)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.845
NEC for r=0.9 class 0.0 = 0.085 +- 0.075 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 1.0 = 0.069 +- 0.075 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all KL = 0.034 +- 0.075 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all L1 = 0.077 +- 0.118 (in-sample avg dev_std = 0.116)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.846
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.852
NEC for r=1.0 class 0.0 = 0.079 +- 0.072 (in-sample avg dev_std = 0.106)
NEC for r=1.0 class 1.0 = 0.051 +- 0.072 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all KL = 0.029 +- 0.072 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all L1 = 0.065 +- 0.109 (in-sample avg dev_std = 0.106)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:55:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:55:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8793
ID Validation Loss: 0.4574
ID Test ACCURACY: 0.8747
ID Test Loss: 0.5052
OOD Validation ACCURACY: 0.8760
OOD Validation Loss: 0.6415
OOD Test ACCURACY: 0.8009
OOD Test Loss: 1.5796

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0759
ID Validation ACCURACY: 0.8734
ID Validation Loss: 0.4221
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4630
OOD Validation ACCURACY: 0.8807
OOD Validation Loss: 0.5911
OOD Test ACCURACY: 0.8228
OOD Test Loss: 1.2879

[0m[1;37mINFO[0m: [1mChartInfo 0.8747 0.8009 0.8727 0.8228 0.8734 0.8807[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:55:39 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.866
SUFF++ for r=0.6 class 0.0 = 0.919 +- 0.183 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.6 class 1.0 = 0.95 +- 0.183 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.6 all KL = 0.925 +- 0.183 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.6 all L1 = 0.937 +- 0.129 (in-sample avg dev_std = 0.212)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.134 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 class 1.0 = 0.97 +- 0.134 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all KL = 0.965 +- 0.134 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.126 (in-sample avg dev_std = 0.136)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.803
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.787
SUFF++ for r=0.3 class 0.0 = 0.896 +- 0.202 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 class 1.0 = 0.914 +- 0.202 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all KL = 0.887 +- 0.202 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.3 all L1 = 0.905 +- 0.138 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.826
SUFF++ for r=0.6 class 0.0 = 0.923 +- 0.162 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 class 1.0 = 0.954 +- 0.162 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all KL = 0.938 +- 0.162 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.133 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.95 +- 0.103 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 class 1.0 = 0.972 +- 0.103 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all KL = 0.964 +- 0.103 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.091 (in-sample avg dev_std = 0.171)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.722
SUFF++ for r=0.3 class 0.0 = 0.868 +- 0.177 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 class 1.0 = 0.937 +- 0.177 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 all KL = 0.901 +- 0.177 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.3 all L1 = 0.904 +- 0.144 (in-sample avg dev_std = 0.253)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.754
SUFF++ for r=0.6 class 0.0 = 0.88 +- 0.163 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 1.0 = 0.955 +- 0.163 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all KL = 0.924 +- 0.163 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all L1 = 0.918 +- 0.150 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.955 +- 0.085 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.085 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all KL = 0.974 +- 0.085 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.095 (in-sample avg dev_std = 0.122)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.876
NEC for r=0.6 class 0.0 = 0.065 +- 0.137 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1.0 = 0.045 +- 0.137 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.047 +- 0.137 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.054 +- 0.123 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.868
NEC for r=0.9 class 0.0 = 0.053 +- 0.138 (in-sample avg dev_std = 0.111)
NEC for r=0.9 class 1.0 = 0.033 +- 0.138 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all KL = 0.033 +- 0.138 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all L1 = 0.041 +- 0.126 (in-sample avg dev_std = 0.111)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.861
NEC for r=1.0 class 0.0 = 0.035 +- 0.098 (in-sample avg dev_std = 0.068)
NEC for r=1.0 class 1.0 = 0.029 +- 0.098 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all KL = 0.02 +- 0.098 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all L1 = 0.032 +- 0.111 (in-sample avg dev_std = 0.068)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.806
NEC for r=0.3 class 0.0 = 0.098 +- 0.167 (in-sample avg dev_std = 0.147)
NEC for r=0.3 class 1.0 = 0.066 +- 0.167 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all KL = 0.068 +- 0.167 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all L1 = 0.081 +- 0.150 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.836
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.83
NEC for r=0.6 class 0.0 = 0.057 +- 0.096 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 1.0 = 0.026 +- 0.096 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all KL = 0.026 +- 0.096 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all L1 = 0.041 +- 0.105 (in-sample avg dev_std = 0.117)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.875
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.872
NEC for r=0.9 class 0.0 = 0.057 +- 0.094 (in-sample avg dev_std = 0.109)
NEC for r=0.9 class 1.0 = 0.026 +- 0.094 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all KL = 0.025 +- 0.094 (in-sample avg dev_std = 0.109)
NEC for r=0.9 all L1 = 0.041 +- 0.108 (in-sample avg dev_std = 0.109)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.047 +- 0.081 (in-sample avg dev_std = 0.089)
NEC for r=1.0 class 1.0 = 0.021 +- 0.081 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all KL = 0.019 +- 0.081 (in-sample avg dev_std = 0.089)
NEC for r=1.0 all L1 = 0.033 +- 0.092 (in-sample avg dev_std = 0.089)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.737
NEC for r=0.3 class 0.0 = 0.093 +- 0.131 (in-sample avg dev_std = 0.147)
NEC for r=0.3 class 1.0 = 0.053 +- 0.131 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all KL = 0.049 +- 0.131 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all L1 = 0.072 +- 0.136 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.767
NEC for r=0.6 class 0.0 = 0.092 +- 0.113 (in-sample avg dev_std = 0.130)
NEC for r=0.6 class 1.0 = 0.037 +- 0.113 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all KL = 0.039 +- 0.113 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all L1 = 0.064 +- 0.134 (in-sample avg dev_std = 0.130)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.811
NEC for r=0.9 class 0.0 = 0.069 +- 0.114 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.048 +- 0.114 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.038 +- 0.114 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.058 +- 0.132 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.811
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.818
NEC for r=1.0 class 0.0 = 0.058 +- 0.099 (in-sample avg dev_std = 0.107)
NEC for r=1.0 class 1.0 = 0.04 +- 0.099 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all KL = 0.03 +- 0.099 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all L1 = 0.049 +- 0.124 (in-sample avg dev_std = 0.107)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 19:58:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 07:58:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 165...
[0m[1;37mINFO[0m: [1mCheckpoint 165: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0752
ID Validation ACCURACY: 0.8787
ID Validation Loss: 0.4736
ID Test ACCURACY: 0.8770
ID Test Loss: 0.5346
OOD Validation ACCURACY: 0.8793
OOD Validation Loss: 0.6619
OOD Test ACCURACY: 0.8293
OOD Test Loss: 1.2360

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8768
ID Validation Loss: 0.4849
ID Test ACCURACY: 0.8776
ID Test Loss: 0.5464
OOD Validation ACCURACY: 0.8830
OOD Validation Loss: 0.6621
OOD Test ACCURACY: 0.8302
OOD Test Loss: 1.2689

[0m[1;37mINFO[0m: [1mChartInfo 0.8770 0.8293 0.8776 0.8302 0.8768 0.8830[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 07:58:38 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.875
SUFF++ for r=0.6 class 0.0 = 0.908 +- 0.186 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 1.0 = 0.953 +- 0.186 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all KL = 0.92 +- 0.186 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all L1 = 0.935 +- 0.132 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
SUFF++ for r=0.9 class 0.0 = 0.902 +- 0.186 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 1.0 = 0.947 +- 0.186 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all KL = 0.939 +- 0.186 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all L1 = 0.927 +- 0.181 (in-sample avg dev_std = 0.163)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.791
SUFF++ for r=0.3 class 0.0 = 0.87 +- 0.210 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 class 1.0 = 0.901 +- 0.210 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 all KL = 0.866 +- 0.210 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.3 all L1 = 0.886 +- 0.153 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.84
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.827
SUFF++ for r=0.6 class 0.0 = 0.923 +- 0.169 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 class 1.0 = 0.951 +- 0.169 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all KL = 0.935 +- 0.169 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.132 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.100 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.100 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.9 all KL = 0.963 +- 0.100 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.090 (in-sample avg dev_std = 0.166)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.748
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.735
SUFF++ for r=0.3 class 0.0 = 0.867 +- 0.177 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.3 class 1.0 = 0.931 +- 0.177 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.3 all KL = 0.903 +- 0.177 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.3 all L1 = 0.9 +- 0.146 (in-sample avg dev_std = 0.254)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.888 +- 0.148 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 1.0 = 0.951 +- 0.148 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all KL = 0.933 +- 0.148 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.150 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.839
SUFF++ for r=0.9 class 0.0 = 0.955 +- 0.075 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.075 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.976 +- 0.075 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.094 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.879
NEC for r=0.6 class 0.0 = 0.084 +- 0.117 (in-sample avg dev_std = 0.124)
NEC for r=0.6 class 1.0 = 0.035 +- 0.117 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all KL = 0.043 +- 0.117 (in-sample avg dev_std = 0.124)
NEC for r=0.6 all L1 = 0.055 +- 0.115 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.076 +- 0.161 (in-sample avg dev_std = 0.140)
NEC for r=0.9 class 1.0 = 0.043 +- 0.161 (in-sample avg dev_std = 0.140)
NEC for r=0.9 all KL = 0.047 +- 0.161 (in-sample avg dev_std = 0.140)
NEC for r=0.9 all L1 = 0.057 +- 0.157 (in-sample avg dev_std = 0.140)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.869
NEC for r=1.0 class 0.0 = 0.046 +- 0.139 (in-sample avg dev_std = 0.098)
NEC for r=1.0 class 1.0 = 0.039 +- 0.139 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all KL = 0.034 +- 0.139 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all L1 = 0.042 +- 0.130 (in-sample avg dev_std = 0.098)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.803
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.797
NEC for r=0.3 class 0.0 = 0.125 +- 0.166 (in-sample avg dev_std = 0.158)
NEC for r=0.3 class 1.0 = 0.076 +- 0.166 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all KL = 0.076 +- 0.166 (in-sample avg dev_std = 0.158)
NEC for r=0.3 all L1 = 0.099 +- 0.167 (in-sample avg dev_std = 0.158)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.84
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.838
NEC for r=0.6 class 0.0 = 0.058 +- 0.101 (in-sample avg dev_std = 0.121)
NEC for r=0.6 class 1.0 = 0.04 +- 0.101 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all KL = 0.033 +- 0.101 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all L1 = 0.049 +- 0.114 (in-sample avg dev_std = 0.121)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.867
NEC for r=0.9 class 0.0 = 0.042 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1.0 = 0.035 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.025 +- 0.093 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.038 +- 0.102 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.036 +- 0.063 (in-sample avg dev_std = 0.083)
NEC for r=1.0 class 1.0 = 0.024 +- 0.063 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all KL = 0.016 +- 0.063 (in-sample avg dev_std = 0.083)
NEC for r=1.0 all L1 = 0.03 +- 0.086 (in-sample avg dev_std = 0.083)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.748
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.756
NEC for r=0.3 class 0.0 = 0.109 +- 0.131 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 1.0 = 0.062 +- 0.131 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all KL = 0.055 +- 0.131 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all L1 = 0.085 +- 0.147 (in-sample avg dev_std = 0.135)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.798
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.793
NEC for r=0.6 class 0.0 = 0.092 +- 0.120 (in-sample avg dev_std = 0.133)
NEC for r=0.6 class 1.0 = 0.048 +- 0.120 (in-sample avg dev_std = 0.133)
NEC for r=0.6 all KL = 0.044 +- 0.120 (in-sample avg dev_std = 0.133)
NEC for r=0.6 all L1 = 0.07 +- 0.140 (in-sample avg dev_std = 0.133)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.841
NEC for r=0.9 class 0.0 = 0.063 +- 0.113 (in-sample avg dev_std = 0.130)
NEC for r=0.9 class 1.0 = 0.049 +- 0.113 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all KL = 0.04 +- 0.113 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all L1 = 0.056 +- 0.130 (in-sample avg dev_std = 0.130)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.854
NEC for r=1.0 class 0.0 = 0.059 +- 0.117 (in-sample avg dev_std = 0.120)
NEC for r=1.0 class 1.0 = 0.038 +- 0.117 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all KL = 0.035 +- 0.117 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all L1 = 0.048 +- 0.125 (in-sample avg dev_std = 0.120)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.932, 0.954, 1.0], 'all_L1': [0.941, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.961, 1.0], 'all_L1': [0.933, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.914, 0.963, 1.0], 'all_L1': [0.9, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.925, 0.965, 1.0], 'all_L1': [0.937, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.92, 0.939, 1.0], 'all_L1': [0.935, 0.927, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.046, 0.041, 0.031], 'all_L1': [0.055, 0.05, 0.04]}), defaultdict(<class 'list'>, {'all_KL': [0.059, 0.029, 0.024], 'all_L1': [0.062, 0.036, 0.03]}), defaultdict(<class 'list'>, {'all_KL': [0.059, 0.031, 0.022], 'all_L1': [0.093, 0.056, 0.043]}), defaultdict(<class 'list'>, {'all_KL': [0.047, 0.033, 0.02], 'all_L1': [0.054, 0.041, 0.032]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.047, 0.034], 'all_L1': [0.055, 0.057, 0.042]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.899, 0.947, 0.97, 1.0], 'all_L1': [0.91, 0.945, 0.965, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.874, 0.94, 0.963, 1.0], 'all_L1': [0.901, 0.945, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.89, 0.941, 0.973, 1.0], 'all_L1': [0.864, 0.909, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.887, 0.938, 0.964, 1.0], 'all_L1': [0.905, 0.939, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.866, 0.935, 0.963, 1.0], 'all_L1': [0.886, 0.938, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.065, 0.032, 0.023, 0.02], 'all_L1': [0.084, 0.046, 0.04, 0.036]}), defaultdict(<class 'list'>, {'all_KL': [0.058, 0.026, 0.026, 0.022], 'all_L1': [0.074, 0.04, 0.039, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.073, 0.034, 0.023, 0.018], 'all_L1': [0.13, 0.077, 0.054, 0.044]}), defaultdict(<class 'list'>, {'all_KL': [0.068, 0.026, 0.025, 0.019], 'all_L1': [0.081, 0.041, 0.041, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.076, 0.033, 0.025, 0.016], 'all_L1': [0.099, 0.049, 0.038, 0.03]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.919, 0.946, 0.981, 1.0], 'all_L1': [0.916, 0.931, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.902, 0.932, 0.972, 1.0], 'all_L1': [0.914, 0.927, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.928, 0.949, 0.98, 1.0], 'all_L1': [0.87, 0.902, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.901, 0.924, 0.974, 1.0], 'all_L1': [0.904, 0.918, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.903, 0.933, 0.976, 1.0], 'all_L1': [0.9, 0.92, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.04, 0.037, 0.038, 0.032], 'all_L1': [0.069, 0.064, 0.059, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.038, 0.036, 0.039], 'all_L1': [0.061, 0.059, 0.049, 0.048]}), defaultdict(<class 'list'>, {'all_KL': [0.069, 0.037, 0.034, 0.029], 'all_L1': [0.141, 0.092, 0.077, 0.065]}), defaultdict(<class 'list'>, {'all_KL': [0.049, 0.039, 0.038, 0.03], 'all_L1': [0.072, 0.064, 0.058, 0.049]}), defaultdict(<class 'list'>, {'all_KL': [0.055, 0.044, 0.04, 0.035], 'all_L1': [0.085, 0.07, 0.056, 0.048]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.929 +- 0.015, 0.942 +- 0.011, 1.000 +- 0.000
suff++ class all_KL  =  0.920 +- 0.008, 0.956 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.863 +- 0.007, 0.862 +- 0.003
nec class all_L1  =  0.064 +- 0.015, 0.048 +- 0.008, 0.037 +- 0.005
nec class all_KL  =  0.051 +- 0.007, 0.036 +- 0.007, 0.026 +- 0.005
nec_acc_int  =  0.867 +- 0.009, 0.866 +- 0.003, 0.867 +- 0.004

Eval split val
suff++ class all_L1  =  0.893 +- 0.017, 0.935 +- 0.013, 0.960 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.883 +- 0.012, 0.940 +- 0.004, 0.967 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.781 +- 0.008, 0.826 +- 0.004, 0.874 +- 0.003
nec class all_L1  =  0.094 +- 0.020, 0.051 +- 0.014, 0.042 +- 0.006, 0.035 +- 0.005
nec class all_KL  =  0.068 +- 0.006, 0.030 +- 0.003, 0.024 +- 0.001, 0.019 +- 0.002
nec_acc_int  =  0.794 +- 0.007, 0.834 +- 0.003, 0.873 +- 0.005, 0.879 +- 0.003

Eval split test
suff++ class all_L1  =  0.901 +- 0.017, 0.920 +- 0.010, 0.962 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.911 +- 0.011, 0.937 +- 0.009, 0.977 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.738 +- 0.015, 0.774 +- 0.013, 0.826 +- 0.016
nec class all_L1  =  0.086 +- 0.029, 0.070 +- 0.012, 0.060 +- 0.009, 0.052 +- 0.007
nec class all_KL  =  0.050 +- 0.011, 0.039 +- 0.003, 0.037 +- 0.002, 0.033 +- 0.004
nec_acc_int  =  0.751 +- 0.011, 0.782 +- 0.012, 0.827 +- 0.014, 0.833 +- 0.017


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.497 +- 0.001, 0.495 +- 0.002, 0.519 +- 0.003
Faith. Armon (L1)= 		  =  0.119 +- 0.025, 0.091 +- 0.015, 0.072 +- 0.010
Faith. GMean (L1)= 	  =  0.242 +- 0.024, 0.212 +- 0.018, 0.193 +- 0.014
Faith. Aritm (KL)= 		  =  0.486 +- 0.002, 0.496 +- 0.002, 0.513 +- 0.003
Faith. Armon (KL)= 		  =  0.096 +- 0.012, 0.070 +- 0.012, 0.051 +- 0.010
Faith. GMean (KL)= 	  =  0.216 +- 0.014, 0.185 +- 0.016, 0.161 +- 0.016

Eval split val
Faith. Aritm (L1)= 		  =  0.493 +- 0.004, 0.493 +- 0.002, 0.501 +- 0.001, 0.518 +- 0.002
Faith. Armon (L1)= 		  =  0.169 +- 0.032, 0.096 +- 0.024, 0.081 +- 0.011, 0.068 +- 0.009
Faith. GMean (L1)= 	  =  0.287 +- 0.027, 0.216 +- 0.026, 0.201 +- 0.013, 0.187 +- 0.012
Faith. Aritm (KL)= 		  =  0.476 +- 0.006, 0.485 +- 0.003, 0.495 +- 0.002, 0.510 +- 0.001
Faith. Armon (KL)= 		  =  0.126 +- 0.011, 0.058 +- 0.007, 0.048 +- 0.002, 0.037 +- 0.004
Faith. GMean (KL)= 	  =  0.245 +- 0.011, 0.168 +- 0.010, 0.154 +- 0.003, 0.138 +- 0.007

Eval split test
Faith. Aritm (L1)= 		  =  0.493 +- 0.007, 0.495 +- 0.002, 0.511 +- 0.002, 0.526 +- 0.003
Faith. Armon (L1)= 		  =  0.155 +- 0.046, 0.129 +- 0.020, 0.112 +- 0.016, 0.099 +- 0.012
Faith. GMean (L1)= 	  =  0.274 +- 0.040, 0.252 +- 0.019, 0.239 +- 0.017, 0.228 +- 0.014
Faith. Aritm (KL)= 		  =  0.480 +- 0.010, 0.488 +- 0.004, 0.507 +- 0.002, 0.516 +- 0.002
Faith. Armon (KL)= 		  =  0.095 +- 0.021, 0.075 +- 0.005, 0.072 +- 0.004, 0.064 +- 0.007
Faith. GMean (KL)= 	  =  0.212 +- 0.025, 0.191 +- 0.006, 0.191 +- 0.005, 0.181 +- 0.010
Computed for split load_split = id



Completed in  0:15:08.091348  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length hard

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:02:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:02:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.9470
Train Loss: 0.1360
ID Validation ACCURACY: 0.8757
ID Validation Loss: 0.4038
ID Test ACCURACY: 0.8721
ID Test Loss: 0.3978
OOD Validation ACCURACY: 0.8703
OOD Validation Loss: 0.3953
OOD Test ACCURACY: 0.7508
OOD Test Loss: 2.4105

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.9380
Train Loss: 0.1395
ID Validation ACCURACY: 0.8613
ID Validation Loss: 0.4161
ID Test ACCURACY: 0.8572
ID Test Loss: 0.4232
OOD Validation ACCURACY: 0.8794
OOD Validation Loss: 0.3750
OOD Test ACCURACY: 0.8283
OOD Test Loss: 0.7416

[0m[1;37mINFO[0m: [1mChartInfo 0.8721 0.7508 0.8572 0.8283 0.8613 0.8794[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 08:02:05 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.845
SUFF++ for r=0.6 class 0.0 = 0.887 +- 0.250 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 class 1.0 = 0.914 +- 0.250 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 all KL = 0.856 +- 0.250 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 all L1 = 0.903 +- 0.159 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.201 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 1.0 = 0.927 +- 0.201 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all KL = 0.913 +- 0.201 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all L1 = 0.922 +- 0.138 (in-sample avg dev_std = 0.160)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.884
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.854
SUFF++ for r=0.3 class 0.0 = 0.911 +- 0.300 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 class 1.0 = 0.868 +- 0.300 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all KL = 0.787 +- 0.300 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all L1 = 0.888 +- 0.161 (in-sample avg dev_std = 0.346)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.873
SUFF++ for r=0.6 class 0.0 = 0.933 +- 0.126 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 1.0 = 0.919 +- 0.126 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all KL = 0.933 +- 0.126 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all L1 = 0.926 +- 0.117 (in-sample avg dev_std = 0.187)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.051 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.051 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all KL = 0.985 +- 0.051 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all L1 = 0.965 +- 0.071 (in-sample avg dev_std = 0.086)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.822
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.788
SUFF++ for r=0.3 class 0.0 = 0.868 +- 0.327 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 class 1.0 = 0.817 +- 0.327 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all KL = 0.719 +- 0.327 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.3 all L1 = 0.842 +- 0.191 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.954 +- 0.241 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 class 1.0 = 0.856 +- 0.241 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 all KL = 0.862 +- 0.241 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.6 all L1 = 0.904 +- 0.165 (in-sample avg dev_std = 0.278)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.769
SUFF++ for r=0.9 class 0.0 = 0.969 +- 0.137 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1.0 = 0.91 +- 0.137 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.947 +- 0.137 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.136 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.853
NEC for r=0.6 class 0.0 = 0.083 +- 0.235 (in-sample avg dev_std = 0.155)
NEC for r=0.6 class 1.0 = 0.067 +- 0.235 (in-sample avg dev_std = 0.155)
NEC for r=0.6 all KL = 0.099 +- 0.235 (in-sample avg dev_std = 0.155)
NEC for r=0.6 all L1 = 0.074 +- 0.152 (in-sample avg dev_std = 0.155)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.858
NEC for r=0.9 class 0.0 = 0.085 +- 0.207 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1.0 = 0.072 +- 0.207 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.084 +- 0.207 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.077 +- 0.146 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.859
NEC for r=1.0 class 0.0 = 0.086 +- 0.205 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 1.0 = 0.07 +- 0.205 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all KL = 0.083 +- 0.205 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all L1 = 0.077 +- 0.145 (in-sample avg dev_std = 0.146)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.884
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.87
NEC for r=0.3 class 0.0 = 0.068 +- 0.193 (in-sample avg dev_std = 0.152)
NEC for r=0.3 class 1.0 = 0.073 +- 0.193 (in-sample avg dev_std = 0.152)
NEC for r=0.3 all KL = 0.073 +- 0.193 (in-sample avg dev_std = 0.152)
NEC for r=0.3 all L1 = 0.07 +- 0.164 (in-sample avg dev_std = 0.152)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.882
NEC for r=0.6 class 0.0 = 0.057 +- 0.107 (in-sample avg dev_std = 0.107)
NEC for r=0.6 class 1.0 = 0.058 +- 0.107 (in-sample avg dev_std = 0.107)
NEC for r=0.6 all KL = 0.038 +- 0.107 (in-sample avg dev_std = 0.107)
NEC for r=0.6 all L1 = 0.057 +- 0.115 (in-sample avg dev_std = 0.107)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.878
NEC for r=0.9 class 0.0 = 0.06 +- 0.089 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 1.0 = 0.055 +- 0.089 (in-sample avg dev_std = 0.093)
NEC for r=0.9 all KL = 0.031 +- 0.089 (in-sample avg dev_std = 0.093)
NEC for r=0.9 all L1 = 0.057 +- 0.100 (in-sample avg dev_std = 0.093)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.887
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.059 +- 0.086 (in-sample avg dev_std = 0.100)
NEC for r=1.0 class 1.0 = 0.054 +- 0.086 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all KL = 0.029 +- 0.086 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all L1 = 0.057 +- 0.097 (in-sample avg dev_std = 0.100)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.822
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.818
NEC for r=0.3 class 0.0 = 0.086 +- 0.235 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 1.0 = 0.127 +- 0.235 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all KL = 0.119 +- 0.235 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all L1 = 0.107 +- 0.193 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.81
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.804
NEC for r=0.6 class 0.0 = 0.043 +- 0.158 (in-sample avg dev_std = 0.175)
NEC for r=0.6 class 1.0 = 0.094 +- 0.158 (in-sample avg dev_std = 0.175)
NEC for r=0.6 all KL = 0.063 +- 0.158 (in-sample avg dev_std = 0.175)
NEC for r=0.6 all L1 = 0.069 +- 0.147 (in-sample avg dev_std = 0.175)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.781
NEC for r=0.9 class 0.0 = 0.038 +- 0.140 (in-sample avg dev_std = 0.159)
NEC for r=0.9 class 1.0 = 0.094 +- 0.140 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all KL = 0.055 +- 0.140 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all L1 = 0.066 +- 0.143 (in-sample avg dev_std = 0.159)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.784
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.77
NEC for r=1.0 class 0.0 = 0.038 +- 0.140 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 1.0 = 0.094 +- 0.140 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all KL = 0.054 +- 0.140 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all L1 = 0.067 +- 0.140 (in-sample avg dev_std = 0.151)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:05:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:05:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 161...
[0m[1;37mINFO[0m: [1mCheckpoint 161: 
-----------------------------------
Train ACCURACY: 0.9487
Train Loss: 0.1122
ID Validation ACCURACY: 0.8761
ID Validation Loss: 0.4442
ID Test ACCURACY: 0.8736
ID Test Loss: 0.4660
OOD Validation ACCURACY: 0.8728
OOD Validation Loss: 0.5549
OOD Test ACCURACY: 0.7867
OOD Test Loss: 1.1781

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.9435
Train Loss: 0.1492
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.3778
ID Test ACCURACY: 0.8634
ID Test Loss: 0.4123
OOD Validation ACCURACY: 0.8799
OOD Validation Loss: 0.3863
OOD Test ACCURACY: 0.8243
OOD Test Loss: 0.7581

[0m[1;37mINFO[0m: [1mChartInfo 0.8736 0.7867 0.8634 0.8243 0.8630 0.8799[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 08:05:58 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.877
SUFF++ for r=0.6 class 0.0 = 0.868 +- 0.285 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 class 1.0 = 0.923 +- 0.285 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 all KL = 0.817 +- 0.285 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.6 all L1 = 0.9 +- 0.161 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.898
SUFF++ for r=0.9 class 0.0 = 0.903 +- 0.223 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1.0 = 0.944 +- 0.223 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.908 +- 0.223 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.926 +- 0.142 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.879
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.844
SUFF++ for r=0.3 class 0.0 = 0.865 +- 0.376 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 class 1.0 = 0.882 +- 0.376 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all KL = 0.715 +- 0.376 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.3 all L1 = 0.874 +- 0.190 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.875
SUFF++ for r=0.6 class 0.0 = 0.912 +- 0.206 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 class 1.0 = 0.945 +- 0.206 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 all KL = 0.894 +- 0.206 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.6 all L1 = 0.929 +- 0.138 (in-sample avg dev_std = 0.256)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.074 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 class 1.0 = 0.981 +- 0.074 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all KL = 0.984 +- 0.074 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all L1 = 0.974 +- 0.077 (in-sample avg dev_std = 0.099)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.756
SUFF++ for r=0.3 class 0.0 = 0.822 +- 0.357 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 class 1.0 = 0.9 +- 0.357 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all KL = 0.729 +- 0.357 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all L1 = 0.862 +- 0.205 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.772
SUFF++ for r=0.6 class 0.0 = 0.883 +- 0.242 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 1.0 = 0.939 +- 0.242 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 all KL = 0.871 +- 0.242 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 all L1 = 0.912 +- 0.166 (in-sample avg dev_std = 0.261)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.79
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.794
SUFF++ for r=0.9 class 0.0 = 0.943 +- 0.109 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.109 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all KL = 0.967 +- 0.109 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.113 (in-sample avg dev_std = 0.131)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.881
NEC for r=0.6 class 0.0 = 0.109 +- 0.251 (in-sample avg dev_std = 0.160)
NEC for r=0.6 class 1.0 = 0.052 +- 0.251 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all KL = 0.108 +- 0.251 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all L1 = 0.076 +- 0.162 (in-sample avg dev_std = 0.160)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.898
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.89
NEC for r=0.9 class 0.0 = 0.104 +- 0.217 (in-sample avg dev_std = 0.136)
NEC for r=0.9 class 1.0 = 0.047 +- 0.217 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all KL = 0.088 +- 0.217 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all L1 = 0.071 +- 0.143 (in-sample avg dev_std = 0.136)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.898
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.89
NEC for r=1.0 class 0.0 = 0.104 +- 0.214 (in-sample avg dev_std = 0.138)
NEC for r=1.0 class 1.0 = 0.046 +- 0.214 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all KL = 0.086 +- 0.214 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all L1 = 0.07 +- 0.142 (in-sample avg dev_std = 0.138)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.879
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.87
NEC for r=0.3 class 0.0 = 0.08 +- 0.240 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 1.0 = 0.053 +- 0.240 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all KL = 0.089 +- 0.240 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all L1 = 0.066 +- 0.174 (in-sample avg dev_std = 0.209)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.877
NEC for r=0.6 class 0.0 = 0.062 +- 0.150 (in-sample avg dev_std = 0.144)
NEC for r=0.6 class 1.0 = 0.036 +- 0.150 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all KL = 0.046 +- 0.150 (in-sample avg dev_std = 0.144)
NEC for r=0.6 all L1 = 0.048 +- 0.132 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.879
NEC for r=0.9 class 0.0 = 0.057 +- 0.126 (in-sample avg dev_std = 0.117)
NEC for r=0.9 class 1.0 = 0.031 +- 0.126 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all KL = 0.033 +- 0.126 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all L1 = 0.043 +- 0.115 (in-sample avg dev_std = 0.117)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.889
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.055 +- 0.117 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.031 +- 0.117 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.032 +- 0.117 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.043 +- 0.110 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.773
NEC for r=0.3 class 0.0 = 0.142 +- 0.282 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 1.0 = 0.067 +- 0.282 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all KL = 0.136 +- 0.282 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all L1 = 0.103 +- 0.215 (in-sample avg dev_std = 0.276)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.788
NEC for r=0.6 class 0.0 = 0.101 +- 0.211 (in-sample avg dev_std = 0.215)
NEC for r=0.6 class 1.0 = 0.054 +- 0.211 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all KL = 0.086 +- 0.211 (in-sample avg dev_std = 0.215)
NEC for r=0.6 all L1 = 0.077 +- 0.174 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.79
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.793
NEC for r=0.9 class 0.0 = 0.079 +- 0.138 (in-sample avg dev_std = 0.153)
NEC for r=0.9 class 1.0 = 0.034 +- 0.138 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all KL = 0.048 +- 0.138 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all L1 = 0.055 +- 0.135 (in-sample avg dev_std = 0.153)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.794
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.792
NEC for r=1.0 class 0.0 = 0.072 +- 0.132 (in-sample avg dev_std = 0.147)
NEC for r=1.0 class 1.0 = 0.037 +- 0.132 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all KL = 0.044 +- 0.132 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all L1 = 0.054 +- 0.134 (in-sample avg dev_std = 0.147)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:09:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:09:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0969
ID Validation ACCURACY: 0.8813
ID Validation Loss: 0.4444
ID Test ACCURACY: 0.8766
ID Test Loss: 0.4688
OOD Validation ACCURACY: 0.8725
OOD Validation Loss: 0.5990
OOD Test ACCURACY: 0.8002
OOD Test Loss: 1.6747

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.1108
ID Validation ACCURACY: 0.8779
ID Validation Loss: 0.4247
ID Test ACCURACY: 0.8751
ID Test Loss: 0.4394
OOD Validation ACCURACY: 0.8784
OOD Validation Loss: 0.5628
OOD Test ACCURACY: 0.8241
OOD Test Loss: 1.5133

[0m[1;37mINFO[0m: [1mChartInfo 0.8766 0.8002 0.8751 0.8241 0.8779 0.8784[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 08:09:26 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.875
SUFF++ for r=0.6 class 0.0 = 0.883 +- 0.307 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 1.0 = 0.909 +- 0.307 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all KL = 0.815 +- 0.307 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all L1 = 0.898 +- 0.159 (in-sample avg dev_std = 0.285)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.891
SUFF++ for r=0.9 class 0.0 = 0.912 +- 0.277 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 class 1.0 = 0.907 +- 0.277 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 all KL = 0.879 +- 0.277 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.9 all L1 = 0.909 +- 0.163 (in-sample avg dev_std = 0.168)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.879
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.853
SUFF++ for r=0.3 class 0.0 = 0.866 +- 0.364 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.3 class 1.0 = 0.905 +- 0.364 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.3 all KL = 0.728 +- 0.364 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.3 all L1 = 0.886 +- 0.169 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.871
SUFF++ for r=0.6 class 0.0 = 0.902 +- 0.239 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 1.0 = 0.942 +- 0.239 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all KL = 0.877 +- 0.239 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all L1 = 0.923 +- 0.138 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.876
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.126 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 1.0 = 0.974 +- 0.126 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all KL = 0.967 +- 0.126 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.083 (in-sample avg dev_std = 0.133)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.804
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.776
SUFF++ for r=0.3 class 0.0 = 0.83 +- 0.385 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 class 1.0 = 0.927 +- 0.385 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 all KL = 0.725 +- 0.385 (in-sample avg dev_std = 0.400)
SUFF++ for r=0.3 all L1 = 0.88 +- 0.191 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.824
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.807
SUFF++ for r=0.6 class 0.0 = 0.879 +- 0.297 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.6 class 1.0 = 0.941 +- 0.297 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.6 all KL = 0.829 +- 0.297 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.6 all L1 = 0.911 +- 0.162 (in-sample avg dev_std = 0.307)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
SUFF++ for r=0.9 class 0.0 = 0.936 +- 0.157 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.157 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all KL = 0.946 +- 0.157 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.120 (in-sample avg dev_std = 0.164)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.876
NEC for r=0.6 class 0.0 = 0.092 +- 0.315 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.104 +- 0.315 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.151 +- 0.315 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.099 +- 0.179 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.098 +- 0.299 (in-sample avg dev_std = 0.178)
NEC for r=0.9 class 1.0 = 0.103 +- 0.299 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all KL = 0.139 +- 0.299 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all L1 = 0.101 +- 0.173 (in-sample avg dev_std = 0.178)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.895
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.098 +- 0.299 (in-sample avg dev_std = 0.182)
NEC for r=1.0 class 1.0 = 0.103 +- 0.299 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all KL = 0.138 +- 0.299 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all L1 = 0.101 +- 0.173 (in-sample avg dev_std = 0.182)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.879
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.871
NEC for r=0.3 class 0.0 = 0.083 +- 0.274 (in-sample avg dev_std = 0.184)
NEC for r=0.3 class 1.0 = 0.065 +- 0.274 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all KL = 0.114 +- 0.274 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all L1 = 0.074 +- 0.179 (in-sample avg dev_std = 0.184)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.881
NEC for r=0.6 class 0.0 = 0.069 +- 0.220 (in-sample avg dev_std = 0.148)
NEC for r=0.6 class 1.0 = 0.053 +- 0.220 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all KL = 0.083 +- 0.220 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all L1 = 0.061 +- 0.134 (in-sample avg dev_std = 0.148)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.88
NEC for r=0.9 class 0.0 = 0.067 +- 0.203 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.056 +- 0.203 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.074 +- 0.203 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.061 +- 0.130 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.877
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.877
NEC for r=1.0 class 0.0 = 0.066 +- 0.195 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 1.0 = 0.056 +- 0.195 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all KL = 0.071 +- 0.195 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all L1 = 0.061 +- 0.125 (in-sample avg dev_std = 0.148)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.804
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.8
NEC for r=0.3 class 0.0 = 0.119 +- 0.307 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 1.0 = 0.064 +- 0.307 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all KL = 0.15 +- 0.307 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all L1 = 0.09 +- 0.202 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.824
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.815
NEC for r=0.6 class 0.0 = 0.085 +- 0.247 (in-sample avg dev_std = 0.212)
NEC for r=0.6 class 1.0 = 0.061 +- 0.247 (in-sample avg dev_std = 0.212)
NEC for r=0.6 all KL = 0.113 +- 0.247 (in-sample avg dev_std = 0.212)
NEC for r=0.6 all L1 = 0.072 +- 0.162 (in-sample avg dev_std = 0.212)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.822
NEC for r=0.9 class 0.0 = 0.082 +- 0.230 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 1.0 = 0.068 +- 0.230 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all KL = 0.106 +- 0.230 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all L1 = 0.075 +- 0.150 (in-sample avg dev_std = 0.196)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.83
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.823
NEC for r=1.0 class 0.0 = 0.083 +- 0.217 (in-sample avg dev_std = 0.179)
NEC for r=1.0 class 1.0 = 0.071 +- 0.217 (in-sample avg dev_std = 0.179)
NEC for r=1.0 all KL = 0.1 +- 0.217 (in-sample avg dev_std = 0.179)
NEC for r=1.0 all L1 = 0.077 +- 0.154 (in-sample avg dev_std = 0.179)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:12:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:12:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0769
ID Validation ACCURACY: 0.8785
ID Validation Loss: 0.4039
ID Test ACCURACY: 0.8738
ID Test Loss: 0.4486
OOD Validation ACCURACY: 0.8764
OOD Validation Loss: 0.5046
OOD Test ACCURACY: 0.7869
OOD Test Loss: 1.0322

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.9483
Train Loss: 0.0928
ID Validation ACCURACY: 0.8746
ID Validation Loss: 0.3863
ID Test ACCURACY: 0.8721
ID Test Loss: 0.4039
OOD Validation ACCURACY: 0.8821
OOD Validation Loss: 0.3949
OOD Test ACCURACY: 0.8396
OOD Test Loss: 0.4654

[0m[1;37mINFO[0m: [1mChartInfo 0.8738 0.7869 0.8721 0.8396 0.8746 0.8821[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 08:12:42 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.873
SUFF++ for r=0.6 class 0.0 = 0.9 +- 0.273 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 class 1.0 = 0.918 +- 0.273 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all KL = 0.841 +- 0.273 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.6 all L1 = 0.911 +- 0.152 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0.0 = 0.927 +- 0.241 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.9 class 1.0 = 0.927 +- 0.241 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.9 all KL = 0.905 +- 0.241 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.9 all L1 = 0.927 +- 0.149 (in-sample avg dev_std = 0.167)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.863
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.82
SUFF++ for r=0.3 class 0.0 = 0.834 +- 0.324 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 1.0 = 0.862 +- 0.324 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all KL = 0.731 +- 0.324 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all L1 = 0.849 +- 0.189 (in-sample avg dev_std = 0.419)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.889
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.856
SUFF++ for r=0.6 class 0.0 = 0.9 +- 0.213 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 1.0 = 0.918 +- 0.213 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all KL = 0.874 +- 0.213 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all L1 = 0.91 +- 0.148 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.883
SUFF++ for r=0.9 class 0.0 = 0.956 +- 0.075 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.075 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all KL = 0.981 +- 0.075 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.081 (in-sample avg dev_std = 0.098)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.755
SUFF++ for r=0.3 class 0.0 = 0.801 +- 0.290 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 class 1.0 = 0.869 +- 0.290 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all KL = 0.754 +- 0.290 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.3 all L1 = 0.836 +- 0.185 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.787
SUFF++ for r=0.6 class 0.0 = 0.86 +- 0.268 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1.0 = 0.871 +- 0.268 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.796 +- 0.268 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.866 +- 0.171 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.929 +- 0.121 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.121 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 all KL = 0.953 +- 0.121 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.9 all L1 = 0.938 +- 0.124 (in-sample avg dev_std = 0.157)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.88
NEC for r=0.6 class 0.0 = 0.084 +- 0.276 (in-sample avg dev_std = 0.170)
NEC for r=0.6 class 1.0 = 0.086 +- 0.276 (in-sample avg dev_std = 0.170)
NEC for r=0.6 all KL = 0.121 +- 0.276 (in-sample avg dev_std = 0.170)
NEC for r=0.6 all L1 = 0.085 +- 0.177 (in-sample avg dev_std = 0.170)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.898
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
NEC for r=0.9 class 0.0 = 0.075 +- 0.268 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1.0 = 0.087 +- 0.268 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.114 +- 0.268 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.082 +- 0.162 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.076 +- 0.267 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1.0 = 0.086 +- 0.267 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.114 +- 0.267 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.082 +- 0.162 (in-sample avg dev_std = 0.161)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.864
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.849
NEC for r=0.3 class 0.0 = 0.12 +- 0.245 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1.0 = 0.083 +- 0.245 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.113 +- 0.245 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.101 +- 0.196 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.889
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.871
NEC for r=0.6 class 0.0 = 0.071 +- 0.159 (in-sample avg dev_std = 0.150)
NEC for r=0.6 class 1.0 = 0.056 +- 0.159 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all KL = 0.058 +- 0.159 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all L1 = 0.063 +- 0.140 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.059 +- 0.126 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 1.0 = 0.037 +- 0.126 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all KL = 0.037 +- 0.126 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all L1 = 0.048 +- 0.105 (in-sample avg dev_std = 0.113)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.885
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.055 +- 0.122 (in-sample avg dev_std = 0.105)
NEC for r=1.0 class 1.0 = 0.038 +- 0.122 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all KL = 0.035 +- 0.122 (in-sample avg dev_std = 0.105)
NEC for r=1.0 all L1 = 0.046 +- 0.104 (in-sample avg dev_std = 0.105)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.781
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.785
NEC for r=0.3 class 0.0 = 0.153 +- 0.206 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 1.0 = 0.088 +- 0.206 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all KL = 0.107 +- 0.206 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all L1 = 0.12 +- 0.193 (in-sample avg dev_std = 0.222)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.814
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.815
NEC for r=0.6 class 0.0 = 0.099 +- 0.183 (in-sample avg dev_std = 0.199)
NEC for r=0.6 class 1.0 = 0.081 +- 0.183 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all KL = 0.083 +- 0.183 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all L1 = 0.09 +- 0.171 (in-sample avg dev_std = 0.199)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.812
NEC for r=0.9 class 0.0 = 0.072 +- 0.135 (in-sample avg dev_std = 0.154)
NEC for r=0.9 class 1.0 = 0.062 +- 0.135 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all KL = 0.052 +- 0.135 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all L1 = 0.067 +- 0.136 (in-sample avg dev_std = 0.154)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.81
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.811
NEC for r=1.0 class 0.0 = 0.064 +- 0.117 (in-sample avg dev_std = 0.124)
NEC for r=1.0 class 1.0 = 0.057 +- 0.117 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all KL = 0.042 +- 0.117 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all L1 = 0.06 +- 0.123 (in-sample avg dev_std = 0.124)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:15:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:15:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 165...
[0m[1;37mINFO[0m: [1mCheckpoint 165: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.1037
ID Validation ACCURACY: 0.8781
ID Validation Loss: 0.4436
ID Test ACCURACY: 0.8749
ID Test Loss: 0.4566
OOD Validation ACCURACY: 0.8808
OOD Validation Loss: 0.6391
OOD Test ACCURACY: 0.7534
OOD Test Loss: 3.0807

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.1001
ID Validation ACCURACY: 0.8755
ID Validation Loss: 0.4596
ID Test ACCURACY: 0.8749
ID Test Loss: 0.4703
OOD Validation ACCURACY: 0.8823
OOD Validation Loss: 0.6955
OOD Test ACCURACY: 0.7510
OOD Test Loss: 3.1539

[0m[1;37mINFO[0m: [1mChartInfo 0.8749 0.7534 0.8749 0.7510 0.8755 0.8823[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 04/17/2024 08:15:39 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17206)
Data example from val: Data(x=[8, 768], edge_index=[2, 14], y=[1, 1], idx=[1], sentence_tokens=[8], length=[1], domain_id=[1])
Label distribution from val: (tensor([0., 1.]), tensor([8233, 8973]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.841
SUFF++ for r=0.6 class 0.0 = 0.89 +- 0.329 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 class 1.0 = 0.891 +- 0.329 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 all KL = 0.781 +- 0.329 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.164 (in-sample avg dev_std = 0.333)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.861
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.280 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1.0 = 0.903 +- 0.280 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.863 +- 0.280 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.909 +- 0.155 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.885
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.848
SUFF++ for r=0.3 class 0.0 = 0.864 +- 0.388 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 class 1.0 = 0.9 +- 0.388 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all KL = 0.693 +- 0.388 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.3 all L1 = 0.883 +- 0.166 (in-sample avg dev_std = 0.421)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.87
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.233 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 1.0 = 0.943 +- 0.233 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all KL = 0.885 +- 0.233 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all L1 = 0.931 +- 0.134 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.887
SUFF++ for r=0.9 class 0.0 = 0.967 +- 0.091 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.091 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.9 all KL = 0.976 +- 0.091 (in-sample avg dev_std = 0.117)
SUFF++ for r=0.9 all L1 = 0.97 +- 0.083 (in-sample avg dev_std = 0.117)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.766
SUFF++ for r=0.3 class 0.0 = 0.866 +- 0.393 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 class 1.0 = 0.774 +- 0.393 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 all KL = 0.606 +- 0.393 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.3 all L1 = 0.819 +- 0.214 (in-sample avg dev_std = 0.492)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.752
SUFF++ for r=0.6 class 0.0 = 0.906 +- 0.320 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 class 1.0 = 0.78 +- 0.320 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all KL = 0.743 +- 0.320 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.6 all L1 = 0.841 +- 0.208 (in-sample avg dev_std = 0.411)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.771
SUFF++ for r=0.9 class 0.0 = 0.96 +- 0.184 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1.0 = 0.895 +- 0.184 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.923 +- 0.184 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.926 +- 0.151 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.86
NEC for r=0.6 class 0.0 = 0.081 +- 0.329 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 1.0 = 0.105 +- 0.329 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all KL = 0.169 +- 0.329 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all L1 = 0.095 +- 0.177 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.088 +- 0.307 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1.0 = 0.109 +- 0.307 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.154 +- 0.307 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.1 +- 0.173 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.862
NEC for r=1.0 class 0.0 = 0.086 +- 0.306 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1.0 = 0.107 +- 0.306 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.152 +- 0.306 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.098 +- 0.170 (in-sample avg dev_std = 0.173)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.885
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.324 +- 0.019
Model Accuracy over intervened graphs for r=0.3 =  0.871
NEC for r=0.3 class 0.0 = 0.063 +- 0.235 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 1.0 = 0.043 +- 0.235 (in-sample avg dev_std = 0.173)
NEC for r=0.3 all KL = 0.081 +- 0.235 (in-sample avg dev_std = 0.173)
NEC for r=0.3 all L1 = 0.053 +- 0.151 (in-sample avg dev_std = 0.173)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.623 +- 0.014
Model Accuracy over intervened graphs for r=0.6 =  0.881
NEC for r=0.6 class 0.0 = 0.056 +- 0.174 (in-sample avg dev_std = 0.129)
NEC for r=0.6 class 1.0 = 0.035 +- 0.174 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all KL = 0.056 +- 0.174 (in-sample avg dev_std = 0.129)
NEC for r=0.6 all L1 = 0.045 +- 0.112 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.924 +- 0.014
Model Accuracy over intervened graphs for r=0.9 =  0.874
NEC for r=0.9 class 0.0 = 0.061 +- 0.156 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 1.0 = 0.032 +- 0.156 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all KL = 0.048 +- 0.156 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all L1 = 0.046 +- 0.111 (in-sample avg dev_std = 0.123)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.058 +- 0.148 (in-sample avg dev_std = 0.114)
NEC for r=1.0 class 1.0 = 0.029 +- 0.148 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all KL = 0.045 +- 0.148 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all L1 = 0.043 +- 0.102 (in-sample avg dev_std = 0.114)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.792
NEC for r=0.3 class 0.0 = 0.096 +- 0.312 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 1.0 = 0.123 +- 0.312 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all KL = 0.175 +- 0.312 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all L1 = 0.11 +- 0.209 (in-sample avg dev_std = 0.298)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.786
NEC for r=0.6 class 0.0 = 0.066 +- 0.249 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 1.0 = 0.144 +- 0.249 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all KL = 0.13 +- 0.249 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all L1 = 0.106 +- 0.195 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.781
NEC for r=0.9 class 0.0 = 0.055 +- 0.192 (in-sample avg dev_std = 0.202)
NEC for r=0.9 class 1.0 = 0.107 +- 0.192 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all KL = 0.089 +- 0.192 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all L1 = 0.082 +- 0.161 (in-sample avg dev_std = 0.202)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.769
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.783
NEC for r=1.0 class 0.0 = 0.05 +- 0.189 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1.0 = 0.109 +- 0.189 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.085 +- 0.189 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.081 +- 0.159 (in-sample avg dev_std = 0.191)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.856, 0.913, 1.0], 'all_L1': [0.903, 0.922, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.817, 0.908, 1.0], 'all_L1': [0.9, 0.926, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.815, 0.879, 1.0], 'all_L1': [0.898, 0.909, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.841, 0.905, 1.0], 'all_L1': [0.911, 0.927, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.781, 0.863, 1.0], 'all_L1': [0.89, 0.909, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.099, 0.084, 0.083], 'all_L1': [0.074, 0.077, 0.077]}), defaultdict(<class 'list'>, {'all_KL': [0.108, 0.088, 0.086], 'all_L1': [0.076, 0.071, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.151, 0.139, 0.138], 'all_L1': [0.099, 0.101, 0.101]}), defaultdict(<class 'list'>, {'all_KL': [0.121, 0.114, 0.114], 'all_L1': [0.085, 0.082, 0.082]}), defaultdict(<class 'list'>, {'all_KL': [0.169, 0.154, 0.152], 'all_L1': [0.095, 0.1, 0.098]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.787, 0.933, 0.985, 1.0], 'all_L1': [0.888, 0.926, 0.965, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.715, 0.894, 0.984, 1.0], 'all_L1': [0.874, 0.929, 0.974, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.728, 0.877, 0.967, 1.0], 'all_L1': [0.886, 0.923, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.731, 0.874, 0.981, 1.0], 'all_L1': [0.849, 0.91, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.693, 0.885, 0.976, 1.0], 'all_L1': [0.883, 0.931, 0.97, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.073, 0.038, 0.031, 0.029], 'all_L1': [0.07, 0.057, 0.057, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.046, 0.033, 0.032], 'all_L1': [0.066, 0.048, 0.043, 0.043]}), defaultdict(<class 'list'>, {'all_KL': [0.114, 0.083, 0.074, 0.071], 'all_L1': [0.074, 0.061, 0.061, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.113, 0.058, 0.037, 0.035], 'all_L1': [0.101, 0.063, 0.048, 0.046]}), defaultdict(<class 'list'>, {'all_KL': [0.081, 0.056, 0.048, 0.045], 'all_L1': [0.053, 0.045, 0.046, 0.043]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.719, 0.862, 0.947, 1.0], 'all_L1': [0.842, 0.904, 0.939, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.729, 0.871, 0.967, 1.0], 'all_L1': [0.862, 0.912, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.725, 0.829, 0.946, 1.0], 'all_L1': [0.88, 0.911, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.754, 0.796, 0.953, 1.0], 'all_L1': [0.836, 0.866, 0.938, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.606, 0.743, 0.923, 1.0], 'all_L1': [0.819, 0.841, 0.926, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.119, 0.063, 0.055, 0.054], 'all_L1': [0.107, 0.069, 0.066, 0.067]}), defaultdict(<class 'list'>, {'all_KL': [0.136, 0.086, 0.048, 0.044], 'all_L1': [0.103, 0.077, 0.055, 0.054]}), defaultdict(<class 'list'>, {'all_KL': [0.15, 0.113, 0.106, 0.1], 'all_L1': [0.09, 0.072, 0.075, 0.077]}), defaultdict(<class 'list'>, {'all_KL': [0.107, 0.083, 0.052, 0.042], 'all_L1': [0.12, 0.09, 0.067, 0.06]}), defaultdict(<class 'list'>, {'all_KL': [0.175, 0.13, 0.089, 0.085], 'all_L1': [0.11, 0.106, 0.082, 0.081]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.900 +- 0.007, 0.919 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.822 +- 0.026, 0.894 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.862 +- 0.016, 0.877 +- 0.016
nec class all_L1  =  0.086 +- 0.010, 0.086 +- 0.012, 0.086 +- 0.012
nec class all_KL  =  0.130 +- 0.026, 0.116 +- 0.028, 0.115 +- 0.027
nec_acc_int  =  0.870 +- 0.011, 0.872 +- 0.011, 0.873 +- 0.011

Eval split val
suff++ class all_L1  =  0.876 +- 0.014, 0.924 +- 0.007, 0.968 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.731 +- 0.031, 0.893 +- 0.021, 0.979 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.844 +- 0.012, 0.869 +- 0.007, 0.882 +- 0.004
nec class all_L1  =  0.073 +- 0.016, 0.055 +- 0.007, 0.051 +- 0.007, 0.050 +- 0.008
nec class all_KL  =  0.094 +- 0.017, 0.056 +- 0.015, 0.045 +- 0.016, 0.042 +- 0.015
nec_acc_int  =  0.866 +- 0.009, 0.878 +- 0.004, 0.877 +- 0.002, 0.877 +- 0.002

Eval split test
suff++ class all_L1  =  0.848 +- 0.021, 0.887 +- 0.028, 0.942 +- 0.011, 1.000 +- 0.000
suff++ class all_KL  =  0.707 +- 0.052, 0.820 +- 0.047, 0.947 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.768 +- 0.012, 0.779 +- 0.018, 0.793 +- 0.022
nec class all_L1  =  0.106 +- 0.010, 0.083 +- 0.014, 0.069 +- 0.009, 0.068 +- 0.010
nec class all_KL  =  0.137 +- 0.024, 0.095 +- 0.024, 0.070 +- 0.023, 0.065 +- 0.023
nec_acc_int  =  0.794 +- 0.015, 0.802 +- 0.013, 0.798 +- 0.017, 0.796 +- 0.019


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.493 +- 0.004, 0.502 +- 0.003, 0.543 +- 0.006
Faith. Armon (L1)= 		  =  0.156 +- 0.017, 0.157 +- 0.020, 0.157 +- 0.020
Faith. GMean (L1)= 	  =  0.277 +- 0.016, 0.281 +- 0.019, 0.292 +- 0.021
Faith. Aritm (KL)= 		  =  0.476 +- 0.007, 0.505 +- 0.005, 0.557 +- 0.014
Faith. Armon (KL)= 		  =  0.222 +- 0.038, 0.204 +- 0.042, 0.205 +- 0.044
Faith. GMean (KL)= 	  =  0.324 +- 0.029, 0.319 +- 0.035, 0.336 +- 0.041

Eval split val
Faith. Aritm (L1)= 		  =  0.474 +- 0.005, 0.489 +- 0.002, 0.510 +- 0.003, 0.525 +- 0.004
Faith. Armon (L1)= 		  =  0.134 +- 0.026, 0.103 +- 0.013, 0.097 +- 0.012, 0.095 +- 0.014
Faith. GMean (L1)= 	  =  0.251 +- 0.025, 0.224 +- 0.014, 0.222 +- 0.015, 0.223 +- 0.017
Faith. Aritm (KL)= 		  =  0.412 +- 0.016, 0.474 +- 0.007, 0.512 +- 0.005, 0.521 +- 0.008
Faith. Armon (KL)= 		  =  0.166 +- 0.026, 0.105 +- 0.027, 0.085 +- 0.028, 0.081 +- 0.028
Faith. GMean (KL)= 	  =  0.261 +- 0.023, 0.222 +- 0.028, 0.206 +- 0.034, 0.203 +- 0.035

Eval split test
Faith. Aritm (L1)= 		  =  0.477 +- 0.007, 0.485 +- 0.008, 0.506 +- 0.004, 0.534 +- 0.005
Faith. Armon (L1)= 		  =  0.188 +- 0.015, 0.151 +- 0.022, 0.128 +- 0.016, 0.127 +- 0.018
Faith. GMean (L1)= 	  =  0.299 +- 0.011, 0.270 +- 0.017, 0.254 +- 0.016, 0.260 +- 0.020
Faith. Aritm (KL)= 		  =  0.422 +- 0.017, 0.458 +- 0.017, 0.509 +- 0.009, 0.532 +- 0.012
Faith. Armon (KL)= 		  =  0.228 +- 0.030, 0.169 +- 0.037, 0.129 +- 0.040, 0.121 +- 0.041
Faith. GMean (KL)= 	  =  0.309 +- 0.018, 0.276 +- 0.029, 0.254 +- 0.040, 0.251 +- 0.045
Computed for split load_split = id



Completed in  0:16:36.812917  for LECIvGIN GOODSST2/length



DONE LECI GOODSST2/length anneal

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:19:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:05 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:06 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:19:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0021
ID Validation ACCURACY: 0.6949
ID Validation Loss: 2.0644
ID Test ACCURACY: 0.6606
ID Test Loss: 2.4951
OOD Validation ACCURACY: 0.5944
OOD Validation Loss: 2.4192
OOD Test ACCURACY: 0.5587
OOD Test Loss: 2.6052

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 16...
[0m[1;37mINFO[0m: [1mCheckpoint 16: 
-----------------------------------
Train ACCURACY: 0.8444
Train Loss: 0.4108
ID Validation ACCURACY: 0.6697
ID Validation Loss: 0.8242
ID Test ACCURACY: 0.6859
ID Test Loss: 0.8513
OOD Validation ACCURACY: 0.6319
OOD Validation Loss: 1.0023
OOD Test ACCURACY: 0.5820
OOD Test Loss: 1.2838

[0m[1;37mINFO[0m: [1mChartInfo 0.6606 0.5587 0.6859 0.5820 0.6697 0.6319[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.624
SUFF++ for r=0.3 class 0 = 0.615 +- 0.386 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 1 = 0.785 +- 0.386 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 class 2 = 0.794 +- 0.386 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all KL = 0.541 +- 0.386 (in-sample avg dev_std = 0.574)
SUFF++ for r=0.3 all L1 = 0.746 +- 0.241 (in-sample avg dev_std = 0.574)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.646
SUFF++ for r=0.6 class 0 = 0.765 +- 0.313 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 1 = 0.828 +- 0.313 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 2 = 0.836 +- 0.313 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all KL = 0.737 +- 0.313 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all L1 = 0.815 +- 0.224 (in-sample avg dev_std = 0.407)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.676
SUFF++ for r=0.9 class 0 = 0.885 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 1 = 0.889 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 2 = 0.92 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all KL = 0.907 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all L1 = 0.896 +- 0.164 (in-sample avg dev_std = 0.234)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.574
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.564
SUFF++ for r=0.3 class 0 = 0.68 +- 0.364 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 1 = 0.749 +- 0.364 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 2 = 0.744 +- 0.364 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all KL = 0.559 +- 0.364 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all L1 = 0.731 +- 0.247 (in-sample avg dev_std = 0.552)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.588
SUFF++ for r=0.6 class 0 = 0.785 +- 0.290 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 1 = 0.816 +- 0.290 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 class 2 = 0.79 +- 0.290 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all KL = 0.748 +- 0.290 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.6 all L1 = 0.803 +- 0.222 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.595
SUFF++ for r=0.9 class 0 = 0.866 +- 0.191 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1 = 0.865 +- 0.191 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.191 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.885 +- 0.191 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.186 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.518
SUFF++ for r=0.3 class 0 = 0.694 +- 0.349 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 1 = 0.712 +- 0.349 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 2 = 0.754 +- 0.349 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 all KL = 0.552 +- 0.349 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 all L1 = 0.718 +- 0.244 (in-sample avg dev_std = 0.554)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.555
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.541
SUFF++ for r=0.6 class 0 = 0.788 +- 0.277 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1 = 0.787 +- 0.277 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 2 = 0.814 +- 0.277 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.742 +- 0.277 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.794 +- 0.217 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.56
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.545
SUFF++ for r=0.9 class 0 = 0.88 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1 = 0.854 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 2 = 0.873 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.891 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.865 +- 0.185 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.652
NEC for r=0.3 class 0 = 0.227 +- 0.350 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 1 = 0.171 +- 0.350 (in-sample avg dev_std = 0.378)
NEC for r=0.3 class 2 = 0.141 +- 0.350 (in-sample avg dev_std = 0.378)
NEC for r=0.3 all KL = 0.244 +- 0.350 (in-sample avg dev_std = 0.378)
NEC for r=0.3 all L1 = 0.176 +- 0.252 (in-sample avg dev_std = 0.378)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0 = 0.158 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=0.6 class 1 = 0.147 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=0.6 class 2 = 0.136 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=0.6 all KL = 0.167 +- 0.269 (in-sample avg dev_std = 0.303)
NEC for r=0.6 all L1 = 0.147 +- 0.221 (in-sample avg dev_std = 0.303)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0 = 0.126 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.9 class 1 = 0.124 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.9 class 2 = 0.11 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.9 all KL = 0.107 +- 0.202 (in-sample avg dev_std = 0.237)
NEC for r=0.9 all L1 = 0.121 +- 0.186 (in-sample avg dev_std = 0.237)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.692
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.68
NEC for r=1.0 class 0 = 0.107 +- 0.176 (in-sample avg dev_std = 0.221)
NEC for r=1.0 class 1 = 0.112 +- 0.176 (in-sample avg dev_std = 0.221)
NEC for r=1.0 class 2 = 0.105 +- 0.176 (in-sample avg dev_std = 0.221)
NEC for r=1.0 all KL = 0.089 +- 0.176 (in-sample avg dev_std = 0.221)
NEC for r=1.0 all L1 = 0.109 +- 0.174 (in-sample avg dev_std = 0.221)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.574
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.588
NEC for r=0.3 class 0 = 0.22 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.3 class 1 = 0.218 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.3 class 2 = 0.222 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.3 all KL = 0.291 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.3 all L1 = 0.219 +- 0.269 (in-sample avg dev_std = 0.402)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.599
NEC for r=0.6 class 0 = 0.175 +- 0.271 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1 = 0.17 +- 0.271 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 2 = 0.188 +- 0.271 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.193 +- 0.271 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.175 +- 0.224 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.605
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.143 +- 0.204 (in-sample avg dev_std = 0.253)
NEC for r=0.9 class 1 = 0.148 +- 0.204 (in-sample avg dev_std = 0.253)
NEC for r=0.9 class 2 = 0.166 +- 0.204 (in-sample avg dev_std = 0.253)
NEC for r=0.9 all KL = 0.131 +- 0.204 (in-sample avg dev_std = 0.253)
NEC for r=0.9 all L1 = 0.151 +- 0.198 (in-sample avg dev_std = 0.253)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.596
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.604
NEC for r=1.0 class 0 = 0.135 +- 0.186 (in-sample avg dev_std = 0.230)
NEC for r=1.0 class 1 = 0.146 +- 0.186 (in-sample avg dev_std = 0.230)
NEC for r=1.0 class 2 = 0.141 +- 0.186 (in-sample avg dev_std = 0.230)
NEC for r=1.0 all KL = 0.112 +- 0.186 (in-sample avg dev_std = 0.230)
NEC for r=1.0 all L1 = 0.142 +- 0.188 (in-sample avg dev_std = 0.230)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.545
NEC for r=0.3 class 0 = 0.219 +- 0.339 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 1 = 0.229 +- 0.339 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 2 = 0.213 +- 0.339 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all KL = 0.286 +- 0.339 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all L1 = 0.222 +- 0.262 (in-sample avg dev_std = 0.395)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.555
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.554
NEC for r=0.6 class 0 = 0.173 +- 0.253 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 1 = 0.178 +- 0.253 (in-sample avg dev_std = 0.297)
NEC for r=0.6 class 2 = 0.153 +- 0.253 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all KL = 0.175 +- 0.253 (in-sample avg dev_std = 0.297)
NEC for r=0.6 all L1 = 0.171 +- 0.224 (in-sample avg dev_std = 0.297)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.56
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.55
NEC for r=0.9 class 0 = 0.124 +- 0.179 (in-sample avg dev_std = 0.230)
NEC for r=0.9 class 1 = 0.152 +- 0.179 (in-sample avg dev_std = 0.230)
NEC for r=0.9 class 2 = 0.138 +- 0.179 (in-sample avg dev_std = 0.230)
NEC for r=0.9 all KL = 0.112 +- 0.179 (in-sample avg dev_std = 0.230)
NEC for r=0.9 all L1 = 0.141 +- 0.190 (in-sample avg dev_std = 0.230)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.556
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.554
NEC for r=1.0 class 0 = 0.108 +- 0.159 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 1 = 0.136 +- 0.159 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 2 = 0.128 +- 0.159 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all KL = 0.089 +- 0.159 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all L1 = 0.127 +- 0.178 (in-sample avg dev_std = 0.203)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:23:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:40 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:42 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:43 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:43 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:45 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:23:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ACCURACY: 0.9969
Train Loss: 0.0140
ID Validation ACCURACY: 0.6986
ID Validation Loss: 1.9127
ID Test ACCURACY: 0.6787
ID Test Loss: 1.8849
OOD Validation ACCURACY: 0.5927
OOD Validation Loss: 2.8308
OOD Test ACCURACY: 0.5381
OOD Test Loss: 4.2017

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 22...
[0m[1;37mINFO[0m: [1mCheckpoint 22: 
-----------------------------------
Train ACCURACY: 0.9023
Train Loss: 0.2771
ID Validation ACCURACY: 0.6968
ID Validation Loss: 0.8613
ID Test ACCURACY: 0.6769
ID Test Loss: 0.9319
OOD Validation ACCURACY: 0.6190
OOD Validation Loss: 1.1423
OOD Test ACCURACY: 0.5793
OOD Test Loss: 1.4137

[0m[1;37mINFO[0m: [1mChartInfo 0.6787 0.5381 0.6769 0.5793 0.6968 0.6190[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.606
SUFF++ for r=0.3 class 0 = 0.712 +- 0.315 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 class 1 = 0.671 +- 0.315 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 class 2 = 0.761 +- 0.315 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 all KL = 0.57 +- 0.315 (in-sample avg dev_std = 0.564)
SUFF++ for r=0.3 all L1 = 0.706 +- 0.213 (in-sample avg dev_std = 0.564)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.654
SUFF++ for r=0.6 class 0 = 0.838 +- 0.241 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 class 1 = 0.82 +- 0.241 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 class 2 = 0.811 +- 0.241 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all KL = 0.797 +- 0.241 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.6 all L1 = 0.822 +- 0.196 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.682
SUFF++ for r=0.9 class 0 = 0.897 +- 0.150 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1 = 0.891 +- 0.150 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 2 = 0.891 +- 0.150 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.918 +- 0.150 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.893 +- 0.158 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.544
SUFF++ for r=0.3 class 0 = 0.701 +- 0.312 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 1 = 0.647 +- 0.312 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 2 = 0.646 +- 0.312 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all KL = 0.509 +- 0.312 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.216 (in-sample avg dev_std = 0.577)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.575
SUFF++ for r=0.6 class 0 = 0.818 +- 0.283 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.283 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 class 2 = 0.753 +- 0.283 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all KL = 0.721 +- 0.283 (in-sample avg dev_std = 0.412)
SUFF++ for r=0.6 all L1 = 0.776 +- 0.218 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.584
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.591
SUFF++ for r=0.9 class 0 = 0.891 +- 0.189 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.851 +- 0.189 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.829 +- 0.189 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.879 +- 0.189 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.190 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.495
SUFF++ for r=0.3 class 0 = 0.73 +- 0.310 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.310 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 2 = 0.64 +- 0.310 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all KL = 0.526 +- 0.310 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all L1 = 0.676 +- 0.222 (in-sample avg dev_std = 0.577)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.527
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.519
SUFF++ for r=0.6 class 0 = 0.839 +- 0.275 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 1 = 0.769 +- 0.275 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 2 = 0.727 +- 0.275 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all KL = 0.731 +- 0.275 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all L1 = 0.777 +- 0.220 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.531
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.527
SUFF++ for r=0.9 class 0 = 0.909 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 1 = 0.856 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 class 2 = 0.831 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all KL = 0.887 +- 0.180 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.181 (in-sample avg dev_std = 0.234)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.64
NEC for r=0.3 class 0 = 0.167 +- 0.267 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 1 = 0.226 +- 0.267 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 2 = 0.173 +- 0.267 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all KL = 0.196 +- 0.267 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all L1 = 0.197 +- 0.227 (in-sample avg dev_std = 0.298)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.66
NEC for r=0.6 class 0 = 0.12 +- 0.217 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 1 = 0.163 +- 0.217 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 2 = 0.155 +- 0.217 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all KL = 0.133 +- 0.217 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all L1 = 0.15 +- 0.199 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0 = 0.095 +- 0.158 (in-sample avg dev_std = 0.215)
NEC for r=0.9 class 1 = 0.124 +- 0.158 (in-sample avg dev_std = 0.215)
NEC for r=0.9 class 2 = 0.126 +- 0.158 (in-sample avg dev_std = 0.215)
NEC for r=0.9 all KL = 0.087 +- 0.158 (in-sample avg dev_std = 0.215)
NEC for r=0.9 all L1 = 0.118 +- 0.168 (in-sample avg dev_std = 0.215)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.677
NEC for r=1.0 class 0 = 0.097 +- 0.151 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 1 = 0.118 +- 0.151 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 2 = 0.114 +- 0.151 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all KL = 0.079 +- 0.151 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all L1 = 0.111 +- 0.164 (in-sample avg dev_std = 0.192)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0 = 0.169 +- 0.295 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 1 = 0.259 +- 0.295 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 2 = 0.243 +- 0.295 (in-sample avg dev_std = 0.361)
NEC for r=0.3 all KL = 0.256 +- 0.295 (in-sample avg dev_std = 0.361)
NEC for r=0.3 all L1 = 0.233 +- 0.239 (in-sample avg dev_std = 0.361)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.582
NEC for r=0.6 class 0 = 0.146 +- 0.251 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 1 = 0.191 +- 0.251 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 2 = 0.184 +- 0.251 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all KL = 0.181 +- 0.251 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all L1 = 0.178 +- 0.213 (in-sample avg dev_std = 0.286)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.584
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.6
NEC for r=0.9 class 0 = 0.114 +- 0.201 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 1 = 0.161 +- 0.201 (in-sample avg dev_std = 0.243)
NEC for r=0.9 class 2 = 0.151 +- 0.201 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all KL = 0.13 +- 0.201 (in-sample avg dev_std = 0.243)
NEC for r=0.9 all L1 = 0.147 +- 0.189 (in-sample avg dev_std = 0.243)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.586
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.601
NEC for r=1.0 class 0 = 0.109 +- 0.178 (in-sample avg dev_std = 0.225)
NEC for r=1.0 class 1 = 0.143 +- 0.178 (in-sample avg dev_std = 0.225)
NEC for r=1.0 class 2 = 0.142 +- 0.178 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all KL = 0.106 +- 0.178 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all L1 = 0.134 +- 0.178 (in-sample avg dev_std = 0.225)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.522
NEC for r=0.3 class 0 = 0.169 +- 0.276 (in-sample avg dev_std = 0.312)
NEC for r=0.3 class 1 = 0.218 +- 0.276 (in-sample avg dev_std = 0.312)
NEC for r=0.3 class 2 = 0.231 +- 0.276 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all KL = 0.222 +- 0.276 (in-sample avg dev_std = 0.312)
NEC for r=0.3 all L1 = 0.209 +- 0.234 (in-sample avg dev_std = 0.312)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.527
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.533
NEC for r=0.6 class 0 = 0.12 +- 0.241 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 1 = 0.182 +- 0.241 (in-sample avg dev_std = 0.266)
NEC for r=0.6 class 2 = 0.209 +- 0.241 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all KL = 0.166 +- 0.241 (in-sample avg dev_std = 0.266)
NEC for r=0.6 all L1 = 0.173 +- 0.216 (in-sample avg dev_std = 0.266)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.531
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.536
NEC for r=0.9 class 0 = 0.09 +- 0.194 (in-sample avg dev_std = 0.216)
NEC for r=0.9 class 1 = 0.151 +- 0.194 (in-sample avg dev_std = 0.216)
NEC for r=0.9 class 2 = 0.171 +- 0.194 (in-sample avg dev_std = 0.216)
NEC for r=0.9 all KL = 0.115 +- 0.194 (in-sample avg dev_std = 0.216)
NEC for r=0.9 all L1 = 0.14 +- 0.189 (in-sample avg dev_std = 0.216)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.525
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.081 +- 0.170 (in-sample avg dev_std = 0.193)
NEC for r=1.0 class 1 = 0.132 +- 0.170 (in-sample avg dev_std = 0.193)
NEC for r=1.0 class 2 = 0.157 +- 0.170 (in-sample avg dev_std = 0.193)
NEC for r=1.0 all KL = 0.094 +- 0.170 (in-sample avg dev_std = 0.193)
NEC for r=1.0 all L1 = 0.125 +- 0.175 (in-sample avg dev_std = 0.193)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:28:22 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:22 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:24 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:28:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 16...
[0m[1;37mINFO[0m: [1mCheckpoint 16: 
-----------------------------------
Train ACCURACY: 0.8351
Train Loss: 0.4187
ID Validation ACCURACY: 0.7329
ID Validation Loss: 0.7702
ID Test ACCURACY: 0.6769
ID Test Loss: 0.8577
OOD Validation ACCURACY: 0.6331
OOD Validation Loss: 1.0039
OOD Test ACCURACY: 0.5704
OOD Test Loss: 1.3426

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ACCURACY: 0.9166
Train Loss: 0.2417
ID Validation ACCURACY: 0.6913
ID Validation Loss: 0.8846
ID Test ACCURACY: 0.6751
ID Test Loss: 0.9796
OOD Validation ACCURACY: 0.6336
OOD Validation Loss: 1.1147
OOD Test ACCURACY: 0.5889
OOD Test Loss: 1.4575

[0m[1;37mINFO[0m: [1mChartInfo 0.6769 0.5704 0.6751 0.5889 0.6913 0.6336[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.609
SUFF++ for r=0.3 class 0 = 0.699 +- 0.104 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.3 class 1 = 0.742 +- 0.104 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.3 class 2 = 0.712 +- 0.104 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.3 all KL = 0.861 +- 0.104 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.3 all L1 = 0.723 +- 0.104 (in-sample avg dev_std = 0.301)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.706
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.669
SUFF++ for r=0.6 class 0 = 0.738 +- 0.100 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 1 = 0.796 +- 0.100 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 class 2 = 0.77 +- 0.100 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all KL = 0.892 +- 0.100 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.120 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.719
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.699
SUFF++ for r=0.9 class 0 = 0.867 +- 0.058 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 1 = 0.88 +- 0.058 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 class 2 = 0.868 +- 0.058 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all KL = 0.959 +- 0.058 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.9 all L1 = 0.874 +- 0.100 (in-sample avg dev_std = 0.144)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.6
SUFF++ for r=0.3 class 0 = 0.712 +- 0.099 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.3 class 1 = 0.754 +- 0.099 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.3 class 2 = 0.709 +- 0.099 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.3 all KL = 0.879 +- 0.099 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.3 all L1 = 0.734 +- 0.110 (in-sample avg dev_std = 0.261)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.787 +- 0.091 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 class 1 = 0.804 +- 0.091 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 class 2 = 0.762 +- 0.091 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 all KL = 0.91 +- 0.091 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.6 all L1 = 0.791 +- 0.123 (in-sample avg dev_std = 0.215)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.632
SUFF++ for r=0.9 class 0 = 0.854 +- 0.069 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.069 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 2 = 0.846 +- 0.069 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all KL = 0.951 +- 0.069 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all L1 = 0.854 +- 0.117 (in-sample avg dev_std = 0.137)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0 = 0.771 +- 0.079 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.3 class 1 = 0.774 +- 0.079 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.3 class 2 = 0.733 +- 0.079 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.3 all KL = 0.907 +- 0.079 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.3 all L1 = 0.763 +- 0.106 (in-sample avg dev_std = 0.218)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.558
SUFF++ for r=0.6 class 0 = 0.82 +- 0.075 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.6 class 1 = 0.807 +- 0.075 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.6 class 2 = 0.776 +- 0.075 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.6 all KL = 0.923 +- 0.075 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.6 all L1 = 0.803 +- 0.117 (in-sample avg dev_std = 0.199)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.558
SUFF++ for r=0.9 class 0 = 0.875 +- 0.073 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 1 = 0.86 +- 0.073 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 2 = 0.84 +- 0.073 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all KL = 0.952 +- 0.073 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all L1 = 0.859 +- 0.122 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.661
NEC for r=0.3 class 0 = 0.241 +- 0.108 (in-sample avg dev_std = 0.183)
NEC for r=0.3 class 1 = 0.208 +- 0.108 (in-sample avg dev_std = 0.183)
NEC for r=0.3 class 2 = 0.246 +- 0.108 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all KL = 0.089 +- 0.108 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all L1 = 0.227 +- 0.134 (in-sample avg dev_std = 0.183)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.706
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.695
NEC for r=0.6 class 0 = 0.195 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.6 class 1 = 0.165 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.6 class 2 = 0.184 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.6 all KL = 0.062 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.6 all L1 = 0.178 +- 0.123 (in-sample avg dev_std = 0.157)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.721
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.709
NEC for r=0.9 class 0 = 0.148 +- 0.056 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 1 = 0.123 +- 0.056 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 2 = 0.145 +- 0.056 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all KL = 0.04 +- 0.056 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all L1 = 0.135 +- 0.108 (in-sample avg dev_std = 0.128)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.728
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.71
NEC for r=1.0 class 0 = 0.136 +- 0.051 (in-sample avg dev_std = 0.121)
NEC for r=1.0 class 1 = 0.109 +- 0.051 (in-sample avg dev_std = 0.121)
NEC for r=1.0 class 2 = 0.133 +- 0.051 (in-sample avg dev_std = 0.121)
NEC for r=1.0 all KL = 0.034 +- 0.051 (in-sample avg dev_std = 0.121)
NEC for r=1.0 all L1 = 0.122 +- 0.101 (in-sample avg dev_std = 0.121)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.624
NEC for r=0.3 class 0 = 0.233 +- 0.086 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 1 = 0.205 +- 0.086 (in-sample avg dev_std = 0.172)
NEC for r=0.3 class 2 = 0.246 +- 0.086 (in-sample avg dev_std = 0.172)
NEC for r=0.3 all KL = 0.078 +- 0.086 (in-sample avg dev_std = 0.172)
NEC for r=0.3 all L1 = 0.221 +- 0.120 (in-sample avg dev_std = 0.172)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0 = 0.183 +- 0.075 (in-sample avg dev_std = 0.152)
NEC for r=0.6 class 1 = 0.162 +- 0.075 (in-sample avg dev_std = 0.152)
NEC for r=0.6 class 2 = 0.201 +- 0.075 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all KL = 0.06 +- 0.075 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all L1 = 0.176 +- 0.120 (in-sample avg dev_std = 0.152)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.64
NEC for r=0.9 class 0 = 0.146 +- 0.062 (in-sample avg dev_std = 0.129)
NEC for r=0.9 class 1 = 0.133 +- 0.062 (in-sample avg dev_std = 0.129)
NEC for r=0.9 class 2 = 0.151 +- 0.062 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all KL = 0.044 +- 0.062 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all L1 = 0.14 +- 0.113 (in-sample avg dev_std = 0.129)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.634
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0 = 0.125 +- 0.051 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1 = 0.119 +- 0.051 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 2 = 0.127 +- 0.051 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.034 +- 0.051 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.123 +- 0.104 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.558
NEC for r=0.3 class 0 = 0.216 +- 0.086 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 1 = 0.207 +- 0.086 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 2 = 0.247 +- 0.086 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all KL = 0.076 +- 0.086 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all L1 = 0.219 +- 0.121 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.567
NEC for r=0.6 class 0 = 0.157 +- 0.069 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 1 = 0.168 +- 0.069 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 2 = 0.191 +- 0.069 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all KL = 0.056 +- 0.069 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all L1 = 0.171 +- 0.118 (in-sample avg dev_std = 0.146)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0 = 0.114 +- 0.049 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1 = 0.129 +- 0.049 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 2 = 0.145 +- 0.049 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.037 +- 0.049 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.129 +- 0.105 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.575
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.564
NEC for r=1.0 class 0 = 0.103 +- 0.039 (in-sample avg dev_std = 0.108)
NEC for r=1.0 class 1 = 0.117 +- 0.039 (in-sample avg dev_std = 0.108)
NEC for r=1.0 class 2 = 0.128 +- 0.039 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all KL = 0.029 +- 0.039 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all L1 = 0.116 +- 0.096 (in-sample avg dev_std = 0.108)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:33:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:13 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:15 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:15 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:16 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:33:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0005
ID Validation ACCURACY: 0.7184
ID Validation Loss: 1.8039
ID Test ACCURACY: 0.6625
ID Test Loss: 1.9706
OOD Validation ACCURACY: 0.6196
OOD Validation Loss: 2.1974
OOD Test ACCURACY: 0.5573
OOD Test Loss: 2.5645

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.7734
Train Loss: 0.5442
ID Validation ACCURACY: 0.6895
ID Validation Loss: 0.7770
ID Test ACCURACY: 0.6769
ID Test Loss: 0.7748
OOD Validation ACCURACY: 0.6381
OOD Validation Loss: 0.9093
OOD Test ACCURACY: 0.5868
OOD Test Loss: 1.0791

[0m[1;37mINFO[0m: [1mChartInfo 0.6625 0.5573 0.6769 0.5868 0.6895 0.6381[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.631
SUFF++ for r=0.3 class 0 = 0.826 +- 0.374 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 class 1 = 0.775 +- 0.374 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 class 2 = 0.679 +- 0.374 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all KL = 0.561 +- 0.374 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all L1 = 0.761 +- 0.228 (in-sample avg dev_std = 0.562)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.668
SUFF++ for r=0.6 class 0 = 0.851 +- 0.304 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 1 = 0.822 +- 0.304 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 2 = 0.783 +- 0.304 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all KL = 0.749 +- 0.304 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all L1 = 0.818 +- 0.221 (in-sample avg dev_std = 0.403)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.706
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.697
SUFF++ for r=0.9 class 0 = 0.92 +- 0.155 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 1 = 0.909 +- 0.155 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 2 = 0.883 +- 0.155 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all KL = 0.925 +- 0.155 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all L1 = 0.904 +- 0.157 (in-sample avg dev_std = 0.220)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0 = 0.823 +- 0.371 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.3 class 1 = 0.773 +- 0.371 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.3 class 2 = 0.667 +- 0.371 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.3 all KL = 0.615 +- 0.371 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.3 all L1 = 0.763 +- 0.241 (in-sample avg dev_std = 0.535)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.593
SUFF++ for r=0.6 class 0 = 0.855 +- 0.266 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 class 1 = 0.827 +- 0.266 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 class 2 = 0.761 +- 0.266 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 all KL = 0.783 +- 0.266 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.211 (in-sample avg dev_std = 0.376)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.613
SUFF++ for r=0.9 class 0 = 0.904 +- 0.159 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.159 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 2 = 0.85 +- 0.159 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all KL = 0.915 +- 0.159 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.172 (in-sample avg dev_std = 0.221)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.505
SUFF++ for r=0.3 class 0 = 0.829 +- 0.358 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 1 = 0.753 +- 0.358 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.358 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all KL = 0.62 +- 0.358 (in-sample avg dev_std = 0.533)
SUFF++ for r=0.3 all L1 = 0.759 +- 0.237 (in-sample avg dev_std = 0.533)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.541
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 799
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.53
SUFF++ for r=0.6 class 0 = 0.867 +- 0.266 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 class 1 = 0.81 +- 0.266 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 class 2 = 0.791 +- 0.266 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all KL = 0.787 +- 0.266 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.205 (in-sample avg dev_std = 0.377)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.538
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.533
SUFF++ for r=0.9 class 0 = 0.912 +- 0.146 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 1 = 0.87 +- 0.146 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 2 = 0.864 +- 0.146 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all KL = 0.919 +- 0.146 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.162 (in-sample avg dev_std = 0.223)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.665
NEC for r=0.3 class 0 = 0.151 +- 0.339 (in-sample avg dev_std = 0.370)
NEC for r=0.3 class 1 = 0.171 +- 0.339 (in-sample avg dev_std = 0.370)
NEC for r=0.3 class 2 = 0.192 +- 0.339 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all KL = 0.227 +- 0.339 (in-sample avg dev_std = 0.370)
NEC for r=0.3 all L1 = 0.172 +- 0.250 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.695
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.68
NEC for r=0.6 class 0 = 0.13 +- 0.263 (in-sample avg dev_std = 0.313)
NEC for r=0.6 class 1 = 0.143 +- 0.263 (in-sample avg dev_std = 0.313)
NEC for r=0.6 class 2 = 0.164 +- 0.263 (in-sample avg dev_std = 0.313)
NEC for r=0.6 all KL = 0.16 +- 0.263 (in-sample avg dev_std = 0.313)
NEC for r=0.6 all L1 = 0.146 +- 0.219 (in-sample avg dev_std = 0.313)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.706
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.684
NEC for r=0.9 class 0 = 0.108 +- 0.185 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 1 = 0.11 +- 0.185 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 2 = 0.121 +- 0.185 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all KL = 0.093 +- 0.185 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all L1 = 0.112 +- 0.174 (in-sample avg dev_std = 0.232)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0 = 0.111 +- 0.169 (in-sample avg dev_std = 0.227)
NEC for r=1.0 class 1 = 0.104 +- 0.169 (in-sample avg dev_std = 0.227)
NEC for r=1.0 class 2 = 0.123 +- 0.169 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all KL = 0.085 +- 0.169 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all L1 = 0.111 +- 0.172 (in-sample avg dev_std = 0.227)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.585
NEC for r=0.3 class 0 = 0.168 +- 0.345 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 1 = 0.201 +- 0.345 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 2 = 0.227 +- 0.345 (in-sample avg dev_std = 0.396)
NEC for r=0.3 all KL = 0.27 +- 0.345 (in-sample avg dev_std = 0.396)
NEC for r=0.3 all L1 = 0.198 +- 0.257 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.62
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.6
NEC for r=0.6 class 0 = 0.156 +- 0.258 (in-sample avg dev_std = 0.312)
NEC for r=0.6 class 1 = 0.168 +- 0.258 (in-sample avg dev_std = 0.312)
NEC for r=0.6 class 2 = 0.194 +- 0.258 (in-sample avg dev_std = 0.312)
NEC for r=0.6 all KL = 0.181 +- 0.258 (in-sample avg dev_std = 0.312)
NEC for r=0.6 all L1 = 0.17 +- 0.225 (in-sample avg dev_std = 0.312)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.127 +- 0.179 (in-sample avg dev_std = 0.229)
NEC for r=0.9 class 1 = 0.135 +- 0.179 (in-sample avg dev_std = 0.229)
NEC for r=0.9 class 2 = 0.16 +- 0.179 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all KL = 0.109 +- 0.179 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all L1 = 0.138 +- 0.189 (in-sample avg dev_std = 0.229)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.616
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.605
NEC for r=1.0 class 0 = 0.12 +- 0.161 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 1 = 0.122 +- 0.161 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 2 = 0.154 +- 0.161 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all KL = 0.09 +- 0.161 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all L1 = 0.128 +- 0.180 (in-sample avg dev_std = 0.203)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.532
NEC for r=0.3 class 0 = 0.184 +- 0.341 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 1 = 0.216 +- 0.341 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 2 = 0.202 +- 0.341 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all KL = 0.272 +- 0.341 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all L1 = 0.204 +- 0.254 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.533
NEC for r=0.6 class 0 = 0.139 +- 0.262 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 1 = 0.186 +- 0.262 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 2 = 0.189 +- 0.262 (in-sample avg dev_std = 0.306)
NEC for r=0.6 all KL = 0.178 +- 0.262 (in-sample avg dev_std = 0.306)
NEC for r=0.6 all L1 = 0.174 +- 0.228 (in-sample avg dev_std = 0.306)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.538
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.538
NEC for r=0.9 class 0 = 0.114 +- 0.172 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 1 = 0.156 +- 0.172 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 2 = 0.156 +- 0.172 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all KL = 0.105 +- 0.172 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all L1 = 0.145 +- 0.187 (in-sample avg dev_std = 0.232)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.544
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.543
NEC for r=1.0 class 0 = 0.11 +- 0.147 (in-sample avg dev_std = 0.207)
NEC for r=1.0 class 1 = 0.146 +- 0.147 (in-sample avg dev_std = 0.207)
NEC for r=1.0 class 2 = 0.145 +- 0.147 (in-sample avg dev_std = 0.207)
NEC for r=1.0 all KL = 0.089 +- 0.147 (in-sample avg dev_std = 0.207)
NEC for r=1.0 all L1 = 0.136 +- 0.175 (in-sample avg dev_std = 0.207)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:37:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:37:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:37:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:37:57 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:37:57 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:37:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:38:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0014
ID Validation ACCURACY: 0.6968
ID Validation Loss: 1.7745
ID Test ACCURACY: 0.6823
ID Test Loss: 1.8627
OOD Validation ACCURACY: 0.6196
OOD Validation Loss: 2.2253
OOD Test ACCURACY: 0.5546
OOD Test Loss: 3.1307

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 28...
[0m[1;37mINFO[0m: [1mCheckpoint 28: 
-----------------------------------
Train ACCURACY: 0.9154
Train Loss: 0.2284
ID Validation ACCURACY: 0.6805
ID Validation Loss: 1.1078
ID Test ACCURACY: 0.6787
ID Test Loss: 1.1798
OOD Validation ACCURACY: 0.6465
OOD Validation Loss: 1.3904
OOD Test ACCURACY: 0.5875
OOD Test Loss: 1.8903

[0m[1;37mINFO[0m: [1mChartInfo 0.6823 0.5546 0.6787 0.5875 0.6805 0.6465[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.61
SUFF++ for r=0.3 class 0 = 0.867 +- 0.353 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 1 = 0.776 +- 0.353 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 class 2 = 0.688 +- 0.353 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all KL = 0.632 +- 0.353 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.3 all L1 = 0.774 +- 0.232 (in-sample avg dev_std = 0.509)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0 = 0.894 +- 0.257 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 1 = 0.831 +- 0.257 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 class 2 = 0.777 +- 0.257 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all KL = 0.803 +- 0.257 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.6 all L1 = 0.832 +- 0.203 (in-sample avg dev_std = 0.355)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.667
SUFF++ for r=0.9 class 0 = 0.907 +- 0.156 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.156 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 2 = 0.878 +- 0.156 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.926 +- 0.156 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.898 +- 0.160 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.583
SUFF++ for r=0.3 class 0 = 0.812 +- 0.340 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 class 1 = 0.773 +- 0.340 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 class 2 = 0.731 +- 0.340 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 all KL = 0.657 +- 0.340 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.3 all L1 = 0.774 +- 0.227 (in-sample avg dev_std = 0.489)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.614
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.61
SUFF++ for r=0.6 class 0 = 0.848 +- 0.234 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 class 1 = 0.831 +- 0.234 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 class 2 = 0.791 +- 0.234 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 all KL = 0.819 +- 0.234 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.6 all L1 = 0.827 +- 0.204 (in-sample avg dev_std = 0.334)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.618
SUFF++ for r=0.9 class 0 = 0.907 +- 0.166 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.876 +- 0.166 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.166 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.911 +- 0.166 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.170 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.509
SUFF++ for r=0.3 class 0 = 0.804 +- 0.326 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 1 = 0.751 +- 0.326 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 class 2 = 0.69 +- 0.326 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all KL = 0.639 +- 0.326 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.3 all L1 = 0.75 +- 0.232 (in-sample avg dev_std = 0.494)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.531
SUFF++ for r=0.6 class 0 = 0.853 +- 0.230 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 1 = 0.825 +- 0.230 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 class 2 = 0.78 +- 0.230 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all KL = 0.813 +- 0.230 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.203 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.539
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.541
SUFF++ for r=0.9 class 0 = 0.905 +- 0.142 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 1 = 0.88 +- 0.142 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.142 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all KL = 0.924 +- 0.142 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.160 (in-sample avg dev_std = 0.203)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.644
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.64
NEC for r=0.3 class 0 = 0.118 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 class 1 = 0.187 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 class 2 = 0.23 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all KL = 0.221 +- 0.320 (in-sample avg dev_std = 0.351)
NEC for r=0.3 all L1 = 0.182 +- 0.250 (in-sample avg dev_std = 0.351)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.659
NEC for r=0.6 class 0 = 0.107 +- 0.230 (in-sample avg dev_std = 0.292)
NEC for r=0.6 class 1 = 0.15 +- 0.230 (in-sample avg dev_std = 0.292)
NEC for r=0.6 class 2 = 0.197 +- 0.230 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all KL = 0.151 +- 0.230 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all L1 = 0.152 +- 0.205 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0 = 0.116 +- 0.181 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 1 = 0.117 +- 0.181 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 2 = 0.162 +- 0.181 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all KL = 0.098 +- 0.181 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all L1 = 0.129 +- 0.187 (in-sample avg dev_std = 0.221)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0 = 0.107 +- 0.160 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 1 = 0.112 +- 0.160 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 2 = 0.148 +- 0.160 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all KL = 0.084 +- 0.160 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all L1 = 0.121 +- 0.179 (in-sample avg dev_std = 0.208)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.594
NEC for r=0.3 class 0 = 0.223 +- 0.356 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 1 = 0.225 +- 0.356 (in-sample avg dev_std = 0.390)
NEC for r=0.3 class 2 = 0.276 +- 0.356 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all KL = 0.301 +- 0.356 (in-sample avg dev_std = 0.390)
NEC for r=0.3 all L1 = 0.235 +- 0.276 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.614
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.613
NEC for r=0.6 class 0 = 0.157 +- 0.250 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 1 = 0.18 +- 0.250 (in-sample avg dev_std = 0.291)
NEC for r=0.6 class 2 = 0.222 +- 0.250 (in-sample avg dev_std = 0.291)
NEC for r=0.6 all KL = 0.186 +- 0.250 (in-sample avg dev_std = 0.291)
NEC for r=0.6 all L1 = 0.183 +- 0.222 (in-sample avg dev_std = 0.291)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.632
NEC for r=0.9 class 0 = 0.104 +- 0.174 (in-sample avg dev_std = 0.220)
NEC for r=0.9 class 1 = 0.144 +- 0.174 (in-sample avg dev_std = 0.220)
NEC for r=0.9 class 2 = 0.181 +- 0.174 (in-sample avg dev_std = 0.220)
NEC for r=0.9 all KL = 0.108 +- 0.174 (in-sample avg dev_std = 0.220)
NEC for r=0.9 all L1 = 0.142 +- 0.186 (in-sample avg dev_std = 0.220)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.627
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.627
NEC for r=1.0 class 0 = 0.102 +- 0.151 (in-sample avg dev_std = 0.196)
NEC for r=1.0 class 1 = 0.129 +- 0.151 (in-sample avg dev_std = 0.196)
NEC for r=1.0 class 2 = 0.168 +- 0.151 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all KL = 0.089 +- 0.151 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all L1 = 0.13 +- 0.173 (in-sample avg dev_std = 0.196)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.524
NEC for r=0.3 class 0 = 0.225 +- 0.345 (in-sample avg dev_std = 0.397)
NEC for r=0.3 class 1 = 0.261 +- 0.345 (in-sample avg dev_std = 0.397)
NEC for r=0.3 class 2 = 0.279 +- 0.345 (in-sample avg dev_std = 0.397)
NEC for r=0.3 all KL = 0.322 +- 0.345 (in-sample avg dev_std = 0.397)
NEC for r=0.3 all L1 = 0.256 +- 0.273 (in-sample avg dev_std = 0.397)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.544
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.541
NEC for r=0.6 class 0 = 0.15 +- 0.243 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 1 = 0.18 +- 0.243 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 2 = 0.222 +- 0.243 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all KL = 0.176 +- 0.243 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all L1 = 0.183 +- 0.223 (in-sample avg dev_std = 0.278)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.539
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.546
NEC for r=0.9 class 0 = 0.118 +- 0.168 (in-sample avg dev_std = 0.213)
NEC for r=0.9 class 1 = 0.146 +- 0.168 (in-sample avg dev_std = 0.213)
NEC for r=0.9 class 2 = 0.175 +- 0.168 (in-sample avg dev_std = 0.213)
NEC for r=0.9 all KL = 0.105 +- 0.168 (in-sample avg dev_std = 0.213)
NEC for r=0.9 all L1 = 0.146 +- 0.186 (in-sample avg dev_std = 0.213)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.55
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.116 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 1 = 0.14 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 2 = 0.164 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all KL = 0.094 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all L1 = 0.14 +- 0.180 (in-sample avg dev_std = 0.203)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.541, 0.737, 0.907, 1.0], 'all_L1': [0.746, 0.815, 0.896, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.57, 0.797, 0.918, 1.0], 'all_L1': [0.706, 0.822, 0.893, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.861, 0.892, 0.959, 1.0], 'all_L1': [0.723, 0.774, 0.874, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.561, 0.749, 0.925, 1.0], 'all_L1': [0.761, 0.818, 0.904, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.632, 0.803, 0.926, 1.0], 'all_L1': [0.774, 0.832, 0.898, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.244, 0.167, 0.107, 0.089], 'all_L1': [0.176, 0.147, 0.121, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.196, 0.133, 0.087, 0.079], 'all_L1': [0.197, 0.15, 0.118, 0.111]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.062, 0.04, 0.034], 'all_L1': [0.227, 0.178, 0.135, 0.122]}), defaultdict(<class 'list'>, {'all_KL': [0.227, 0.16, 0.093, 0.085], 'all_L1': [0.172, 0.146, 0.112, 0.111]}), defaultdict(<class 'list'>, {'all_KL': [0.221, 0.151, 0.098, 0.084], 'all_L1': [0.182, 0.152, 0.129, 0.121]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.559, 0.748, 0.885, 1.0], 'all_L1': [0.731, 0.803, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.509, 0.721, 0.879, 1.0], 'all_L1': [0.661, 0.776, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.879, 0.91, 0.951, 1.0], 'all_L1': [0.734, 0.791, 0.854, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.615, 0.783, 0.915, 1.0], 'all_L1': [0.763, 0.82, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.819, 0.911, 1.0], 'all_L1': [0.774, 0.827, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.291, 0.193, 0.131, 0.112], 'all_L1': [0.219, 0.175, 0.151, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.256, 0.181, 0.13, 0.106], 'all_L1': [0.233, 0.178, 0.147, 0.134]}), defaultdict(<class 'list'>, {'all_KL': [0.078, 0.06, 0.044, 0.034], 'all_L1': [0.221, 0.176, 0.14, 0.123]}), defaultdict(<class 'list'>, {'all_KL': [0.27, 0.181, 0.109, 0.09], 'all_L1': [0.198, 0.17, 0.138, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.301, 0.186, 0.108, 0.089], 'all_L1': [0.235, 0.183, 0.142, 0.13]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.552, 0.742, 0.891, 1.0], 'all_L1': [0.718, 0.794, 0.865, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.526, 0.731, 0.887, 1.0], 'all_L1': [0.676, 0.777, 0.863, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.907, 0.923, 0.952, 1.0], 'all_L1': [0.763, 0.803, 0.859, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.62, 0.787, 0.919, 1.0], 'all_L1': [0.759, 0.82, 0.88, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.639, 0.813, 0.924, 1.0], 'all_L1': [0.75, 0.821, 0.882, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.286, 0.175, 0.112, 0.089], 'all_L1': [0.222, 0.171, 0.141, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.222, 0.166, 0.115, 0.094], 'all_L1': [0.209, 0.173, 0.14, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.076, 0.056, 0.037, 0.029], 'all_L1': [0.219, 0.171, 0.129, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.272, 0.178, 0.105, 0.089], 'all_L1': [0.204, 0.174, 0.145, 0.136]}), defaultdict(<class 'list'>, {'all_KL': [0.322, 0.176, 0.105, 0.094], 'all_L1': [0.256, 0.183, 0.146, 0.14]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.742 +- 0.025, 0.812 +- 0.020, 0.893 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.633 +- 0.118, 0.796 +- 0.055, 0.927 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.616 +- 0.010, 0.657 +- 0.009, 0.684 +- 0.012
nec class all_L1  =  0.191 +- 0.020, 0.155 +- 0.012, 0.123 +- 0.008, 0.115 +- 0.006
nec class all_KL  =  0.195 +- 0.055, 0.135 +- 0.038, 0.085 +- 0.023, 0.074 +- 0.020
nec_acc_int  =  0.652 +- 0.010, 0.672 +- 0.014, 0.682 +- 0.015, 0.682 +- 0.015

Eval split val
suff++ class all_L1  =  0.733 +- 0.039, 0.803 +- 0.019, 0.867 +- 0.012, 1.000 +- 0.000
suff++ class all_KL  =  0.644 +- 0.128, 0.796 +- 0.066, 0.908 +- 0.026, 1.000 +- 0.000
suff++_acc_int  =  0.572 +- 0.019, 0.599 +- 0.018, 0.610 +- 0.015
nec class all_L1  =  0.221 +- 0.013, 0.176 +- 0.004, 0.144 +- 0.005, 0.131 +- 0.006
nec class all_KL  =  0.239 +- 0.082, 0.160 +- 0.050, 0.104 +- 0.032, 0.086 +- 0.028
nec_acc_int  =  0.591 +- 0.019, 0.606 +- 0.017, 0.615 +- 0.017, 0.615 +- 0.015

Eval split test
suff++ class all_L1  =  0.733 +- 0.033, 0.803 +- 0.017, 0.870 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.649 +- 0.136, 0.799 +- 0.069, 0.915 +- 0.024, 1.000 +- 0.000
suff++_acc_int  =  0.516 +- 0.020, 0.536 +- 0.013, 0.541 +- 0.011
nec class all_L1  =  0.222 +- 0.018, 0.174 +- 0.004, 0.140 +- 0.006, 0.129 +- 0.008
nec class all_KL  =  0.236 +- 0.086, 0.150 +- 0.047, 0.095 +- 0.029, 0.079 +- 0.025
nec_acc_int  =  0.536 +- 0.014, 0.545 +- 0.013, 0.547 +- 0.010, 0.547 +- 0.011


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.466 +- 0.010, 0.483 +- 0.005, 0.508 +- 0.003, 0.557 +- 0.003
Faith. Armon (L1)= 		  =  0.303 +- 0.023, 0.259 +- 0.015, 0.216 +- 0.012, 0.206 +- 0.009
Faith. GMean (L1)= 	  =  0.376 +- 0.016, 0.354 +- 0.009, 0.331 +- 0.010, 0.339 +- 0.008
Faith. Aritm (KL)= 		  =  0.414 +- 0.034, 0.465 +- 0.011, 0.506 +- 0.004, 0.537 +- 0.010
Faith. Armon (KL)= 		  =  0.288 +- 0.065, 0.227 +- 0.057, 0.155 +- 0.040, 0.137 +- 0.036
Faith. GMean (KL)= 	  =  0.341 +- 0.035, 0.321 +- 0.044, 0.277 +- 0.042, 0.269 +- 0.043

Eval split val
Faith. Aritm (L1)= 		  =  0.477 +- 0.018, 0.490 +- 0.010, 0.505 +- 0.005, 0.566 +- 0.003
Faith. Armon (L1)= 		  =  0.339 +- 0.015, 0.289 +- 0.006, 0.246 +- 0.007, 0.232 +- 0.010
Faith. GMean (L1)= 	  =  0.402 +- 0.013, 0.376 +- 0.006, 0.353 +- 0.005, 0.362 +- 0.009
Faith. Aritm (KL)= 		  =  0.442 +- 0.036, 0.478 +- 0.017, 0.506 +- 0.005, 0.543 +- 0.014
Faith. Armon (KL)= 		  =  0.331 +- 0.097, 0.261 +- 0.075, 0.185 +- 0.053, 0.157 +- 0.048
Faith. GMean (KL)= 	  =  0.376 +- 0.063, 0.348 +- 0.058, 0.303 +- 0.050, 0.289 +- 0.054

Eval split test
Faith. Aritm (L1)= 		  =  0.478 +- 0.021, 0.489 +- 0.010, 0.505 +- 0.007, 0.564 +- 0.004
Faith. Armon (L1)= 		  =  0.340 +- 0.022, 0.287 +- 0.007, 0.241 +- 0.009, 0.228 +- 0.013
Faith. GMean (L1)= 	  =  0.403 +- 0.021, 0.374 +- 0.008, 0.349 +- 0.009, 0.359 +- 0.012
Faith. Aritm (KL)= 		  =  0.442 +- 0.043, 0.475 +- 0.018, 0.505 +- 0.007, 0.539 +- 0.013
Faith. Armon (KL)= 		  =  0.327 +- 0.100, 0.248 +- 0.071, 0.170 +- 0.050, 0.145 +- 0.045
Faith. GMean (KL)= 	  =  0.373 +- 0.066, 0.338 +- 0.056, 0.289 +- 0.051, 0.276 +- 0.053
Computed for split load_split = id



Completed in  0:23:26.013484  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length topk

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:42:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:42:57 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:42:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:42:59 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:42:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:01 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:43:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.8606
Train Loss: 0.4005
ID Validation ACCURACY: 0.6968
ID Validation Loss: 1.3027
ID Test ACCURACY: 0.6805
ID Test Loss: 1.3993
OOD Validation ACCURACY: 0.6280
OOD Validation Loss: 1.6906
OOD Test ACCURACY: 0.5553
OOD Test Loss: 2.2598

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ACCURACY: 0.7996
Train Loss: 0.6090
ID Validation ACCURACY: 0.6534
ID Validation Loss: 1.4484
ID Test ACCURACY: 0.6661
ID Test Loss: 1.4663
OOD Validation ACCURACY: 0.6409
OOD Validation Loss: 1.8687
OOD Test ACCURACY: 0.6081
OOD Test Loss: 2.3519

[0m[1;37mINFO[0m: [1mChartInfo 0.6805 0.5553 0.6661 0.6081 0.6534 0.6409[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 435
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.563
SUFF++ for r=0.3 class 0 = 0.776 +- 0.156 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 1 = 0.746 +- 0.156 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 2 = 0.771 +- 0.156 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all KL = 0.836 +- 0.156 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all L1 = 0.76 +- 0.153 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.638
SUFF++ for r=0.6 class 0 = 0.819 +- 0.126 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 class 1 = 0.805 +- 0.126 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 class 2 = 0.835 +- 0.126 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 all KL = 0.897 +- 0.126 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.151 (in-sample avg dev_std = 0.254)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.689
SUFF++ for r=0.9 class 0 = 0.941 +- 0.037 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 1 = 0.94 +- 0.037 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 2 = 0.937 +- 0.037 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all KL = 0.98 +- 0.037 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.074 (in-sample avg dev_std = 0.129)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 772
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.531
SUFF++ for r=0.3 class 0 = 0.754 +- 0.129 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 class 1 = 0.721 +- 0.129 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 class 2 = 0.716 +- 0.129 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all KL = 0.839 +- 0.129 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all L1 = 0.728 +- 0.139 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0 = 0.821 +- 0.108 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.6 class 1 = 0.788 +- 0.108 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.6 class 2 = 0.794 +- 0.108 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.6 all KL = 0.904 +- 0.108 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.149 (in-sample avg dev_std = 0.231)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.627
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.63
SUFF++ for r=0.9 class 0 = 0.951 +- 0.027 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 1 = 0.948 +- 0.027 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 2 = 0.941 +- 0.027 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all KL = 0.986 +- 0.027 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.066 (in-sample avg dev_std = 0.103)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.473
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.481
SUFF++ for r=0.3 class 0 = 0.785 +- 0.124 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.3 class 1 = 0.735 +- 0.124 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.3 class 2 = 0.747 +- 0.124 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.3 all KL = 0.853 +- 0.124 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.3 all L1 = 0.751 +- 0.140 (in-sample avg dev_std = 0.333)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.541
SUFF++ for r=0.6 class 0 = 0.838 +- 0.111 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 1 = 0.782 +- 0.111 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 2 = 0.817 +- 0.111 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all KL = 0.905 +- 0.111 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all L1 = 0.805 +- 0.154 (in-sample avg dev_std = 0.234)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.54
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.554
SUFF++ for r=0.9 class 0 = 0.957 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 1 = 0.932 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 2 = 0.942 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all KL = 0.984 +- 0.032 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.074 (in-sample avg dev_std = 0.109)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.555
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.568
NEC for r=0.3 class 0 = 0.144 +- 0.154 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 1 = 0.19 +- 0.154 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 2 = 0.156 +- 0.154 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all KL = 0.099 +- 0.154 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all L1 = 0.17 +- 0.162 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.631
NEC for r=0.6 class 0 = 0.117 +- 0.104 (in-sample avg dev_std = 0.176)
NEC for r=0.6 class 1 = 0.128 +- 0.104 (in-sample avg dev_std = 0.176)
NEC for r=0.6 class 2 = 0.101 +- 0.104 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all KL = 0.053 +- 0.104 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all L1 = 0.117 +- 0.127 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.692
NEC for r=0.9 class 0 = 0.102 +- 0.077 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 1 = 0.082 +- 0.077 (in-sample avg dev_std = 0.123)
NEC for r=0.9 class 2 = 0.095 +- 0.077 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all KL = 0.032 +- 0.077 (in-sample avg dev_std = 0.123)
NEC for r=0.9 all L1 = 0.09 +- 0.112 (in-sample avg dev_std = 0.123)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0 = 0.116 +- 0.079 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1 = 0.073 +- 0.079 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 2 = 0.086 +- 0.079 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.034 +- 0.079 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.087 +- 0.117 (in-sample avg dev_std = 0.132)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.54
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.52
NEC for r=0.3 class 0 = 0.153 +- 0.086 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1 = 0.196 +- 0.086 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 2 = 0.2 +- 0.086 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.072 +- 0.086 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.186 +- 0.126 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.595
NEC for r=0.6 class 0 = 0.115 +- 0.068 (in-sample avg dev_std = 0.154)
NEC for r=0.6 class 1 = 0.145 +- 0.068 (in-sample avg dev_std = 0.154)
NEC for r=0.6 class 2 = 0.153 +- 0.068 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all KL = 0.047 +- 0.068 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all L1 = 0.139 +- 0.115 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.627
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.628
NEC for r=0.9 class 0 = 0.107 +- 0.074 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 1 = 0.101 +- 0.074 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 2 = 0.11 +- 0.074 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all KL = 0.039 +- 0.074 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all L1 = 0.104 +- 0.118 (in-sample avg dev_std = 0.126)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.632
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0 = 0.1 +- 0.088 (in-sample avg dev_std = 0.128)
NEC for r=1.0 class 1 = 0.098 +- 0.088 (in-sample avg dev_std = 0.128)
NEC for r=1.0 class 2 = 0.119 +- 0.088 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all KL = 0.046 +- 0.088 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all L1 = 0.103 +- 0.135 (in-sample avg dev_std = 0.128)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.476
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.483
NEC for r=0.3 class 0 = 0.131 +- 0.073 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 1 = 0.188 +- 0.073 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 2 = 0.177 +- 0.073 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all KL = 0.06 +- 0.073 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all L1 = 0.17 +- 0.124 (in-sample avg dev_std = 0.165)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.53
NEC for r=0.6 class 0 = 0.087 +- 0.074 (in-sample avg dev_std = 0.142)
NEC for r=0.6 class 1 = 0.148 +- 0.074 (in-sample avg dev_std = 0.142)
NEC for r=0.6 class 2 = 0.137 +- 0.074 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all KL = 0.044 +- 0.074 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all L1 = 0.13 +- 0.119 (in-sample avg dev_std = 0.142)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.54
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.561
NEC for r=0.9 class 0 = 0.093 +- 0.089 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 1 = 0.135 +- 0.089 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 2 = 0.134 +- 0.089 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all KL = 0.052 +- 0.089 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all L1 = 0.124 +- 0.140 (in-sample avg dev_std = 0.143)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.549
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.092 +- 0.120 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 1 = 0.141 +- 0.120 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 2 = 0.136 +- 0.120 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all KL = 0.064 +- 0.120 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all L1 = 0.127 +- 0.163 (in-sample avg dev_std = 0.148)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:47:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:05 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:05 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:06 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:47:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 75...
[0m[1;37mINFO[0m: [1mCheckpoint 75: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0009
ID Validation ACCURACY: 0.7130
ID Validation Loss: 2.6791
ID Test ACCURACY: 0.6715
ID Test Loss: 3.0893
OOD Validation ACCURACY: 0.6084
OOD Validation Loss: 3.9236
OOD Test ACCURACY: 0.5491
OOD Test Loss: 6.5761

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ACCURACY: 0.9239
Train Loss: 0.2076
ID Validation ACCURACY: 0.6931
ID Validation Loss: 1.4965
ID Test ACCURACY: 0.6751
ID Test Loss: 1.6150
OOD Validation ACCURACY: 0.6487
OOD Validation Loss: 1.9067
OOD Test ACCURACY: 0.6095
OOD Test Loss: 2.2038

[0m[1;37mINFO[0m: [1mChartInfo 0.6715 0.5491 0.6751 0.6095 0.6931 0.6487[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 432
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0 = 0.802 +- 0.268 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 1 = 0.802 +- 0.268 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 2 = 0.79 +- 0.268 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 all KL = 0.753 +- 0.268 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 all L1 = 0.799 +- 0.204 (in-sample avg dev_std = 0.427)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.655
SUFF++ for r=0.6 class 0 = 0.866 +- 0.204 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 1 = 0.871 +- 0.204 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 class 2 = 0.853 +- 0.204 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all KL = 0.88 +- 0.204 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.6 all L1 = 0.865 +- 0.190 (in-sample avg dev_std = 0.275)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.694
SUFF++ for r=0.9 class 0 = 0.956 +- 0.078 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1 = 0.953 +- 0.078 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 2 = 0.956 +- 0.078 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.97 +- 0.078 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.955 +- 0.086 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 765
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.501
SUFF++ for r=0.3 class 0 = 0.804 +- 0.234 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 1 = 0.742 +- 0.234 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 2 = 0.734 +- 0.234 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all KL = 0.761 +- 0.234 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all L1 = 0.756 +- 0.202 (in-sample avg dev_std = 0.423)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.58
SUFF++ for r=0.6 class 0 = 0.886 +- 0.144 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 class 1 = 0.856 +- 0.144 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 class 2 = 0.848 +- 0.144 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 all KL = 0.913 +- 0.144 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.6 all L1 = 0.862 +- 0.177 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.613
SUFF++ for r=0.9 class 0 = 0.964 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1 = 0.953 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 2 = 0.958 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.98 +- 0.054 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.084 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 779
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.448
SUFF++ for r=0.3 class 0 = 0.813 +- 0.213 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 class 1 = 0.765 +- 0.213 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 class 2 = 0.764 +- 0.213 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 all KL = 0.792 +- 0.213 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 all L1 = 0.777 +- 0.188 (in-sample avg dev_std = 0.413)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.511
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.515
SUFF++ for r=0.6 class 0 = 0.896 +- 0.128 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 1 = 0.866 +- 0.128 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 2 = 0.847 +- 0.128 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all KL = 0.923 +- 0.128 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all L1 = 0.869 +- 0.163 (in-sample avg dev_std = 0.216)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.536
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.538
SUFF++ for r=0.9 class 0 = 0.961 +- 0.070 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 1 = 0.955 +- 0.070 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 2 = 0.936 +- 0.070 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all KL = 0.976 +- 0.070 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.092 (in-sample avg dev_std = 0.137)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.574
NEC for r=0.3 class 0 = 0.125 +- 0.224 (in-sample avg dev_std = 0.302)
NEC for r=0.3 class 1 = 0.146 +- 0.224 (in-sample avg dev_std = 0.302)
NEC for r=0.3 class 2 = 0.147 +- 0.224 (in-sample avg dev_std = 0.302)
NEC for r=0.3 all KL = 0.133 +- 0.224 (in-sample avg dev_std = 0.302)
NEC for r=0.3 all L1 = 0.141 +- 0.185 (in-sample avg dev_std = 0.302)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.656
NEC for r=0.6 class 0 = 0.096 +- 0.173 (in-sample avg dev_std = 0.232)
NEC for r=0.6 class 1 = 0.104 +- 0.173 (in-sample avg dev_std = 0.232)
NEC for r=0.6 class 2 = 0.107 +- 0.173 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all KL = 0.084 +- 0.173 (in-sample avg dev_std = 0.232)
NEC for r=0.6 all L1 = 0.103 +- 0.158 (in-sample avg dev_std = 0.232)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.678
NEC for r=0.9 class 0 = 0.08 +- 0.159 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 1 = 0.081 +- 0.159 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 2 = 0.095 +- 0.159 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all KL = 0.068 +- 0.159 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all L1 = 0.085 +- 0.150 (in-sample avg dev_std = 0.184)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.71
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.694
NEC for r=1.0 class 0 = 0.078 +- 0.174 (in-sample avg dev_std = 0.211)
NEC for r=1.0 class 1 = 0.083 +- 0.174 (in-sample avg dev_std = 0.211)
NEC for r=1.0 class 2 = 0.097 +- 0.174 (in-sample avg dev_std = 0.211)
NEC for r=1.0 all KL = 0.072 +- 0.174 (in-sample avg dev_std = 0.211)
NEC for r=1.0 all L1 = 0.086 +- 0.164 (in-sample avg dev_std = 0.211)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.515
NEC for r=0.3 class 0 = 0.105 +- 0.165 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 1 = 0.184 +- 0.165 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 2 = 0.19 +- 0.165 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all KL = 0.111 +- 0.165 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all L1 = 0.165 +- 0.180 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.584
NEC for r=0.6 class 0 = 0.104 +- 0.136 (in-sample avg dev_std = 0.194)
NEC for r=0.6 class 1 = 0.125 +- 0.136 (in-sample avg dev_std = 0.194)
NEC for r=0.6 class 2 = 0.149 +- 0.136 (in-sample avg dev_std = 0.194)
NEC for r=0.6 all KL = 0.077 +- 0.136 (in-sample avg dev_std = 0.194)
NEC for r=0.6 all L1 = 0.125 +- 0.159 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.609
NEC for r=0.9 class 0 = 0.107 +- 0.185 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 1 = 0.119 +- 0.185 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 2 = 0.133 +- 0.185 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all KL = 0.096 +- 0.185 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all L1 = 0.119 +- 0.183 (in-sample avg dev_std = 0.210)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.611
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.611
NEC for r=1.0 class 0 = 0.099 +- 0.198 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 1 = 0.116 +- 0.198 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 2 = 0.138 +- 0.198 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all KL = 0.105 +- 0.198 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all L1 = 0.116 +- 0.188 (in-sample avg dev_std = 0.222)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.455
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.45
NEC for r=0.3 class 0 = 0.115 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1 = 0.161 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 2 = 0.165 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.086 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.15 +- 0.168 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.511
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.511
NEC for r=0.6 class 0 = 0.078 +- 0.105 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 1 = 0.101 +- 0.105 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 2 = 0.138 +- 0.105 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all KL = 0.053 +- 0.105 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all L1 = 0.104 +- 0.135 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.536
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.102 +- 0.158 (in-sample avg dev_std = 0.195)
NEC for r=0.9 class 1 = 0.105 +- 0.158 (in-sample avg dev_std = 0.195)
NEC for r=0.9 class 2 = 0.136 +- 0.158 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all KL = 0.082 +- 0.158 (in-sample avg dev_std = 0.195)
NEC for r=0.9 all L1 = 0.112 +- 0.171 (in-sample avg dev_std = 0.195)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.538
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0 = 0.085 +- 0.191 (in-sample avg dev_std = 0.213)
NEC for r=1.0 class 1 = 0.11 +- 0.191 (in-sample avg dev_std = 0.213)
NEC for r=1.0 class 2 = 0.133 +- 0.191 (in-sample avg dev_std = 0.213)
NEC for r=1.0 all KL = 0.095 +- 0.191 (in-sample avg dev_std = 0.213)
NEC for r=1.0 all L1 = 0.11 +- 0.182 (in-sample avg dev_std = 0.213)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:51:22 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:22 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:23 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:51:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ACCURACY: 0.9544
Train Loss: 0.1164
ID Validation ACCURACY: 0.7202
ID Validation Loss: 1.4198
ID Test ACCURACY: 0.6823
ID Test Loss: 1.7132
OOD Validation ACCURACY: 0.6235
OOD Validation Loss: 2.1769
OOD Test ACCURACY: 0.5402
OOD Test Loss: 3.6324

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 16...
[0m[1;37mINFO[0m: [1mCheckpoint 16: 
-----------------------------------
Train ACCURACY: 0.8154
Train Loss: 0.5320
ID Validation ACCURACY: 0.6805
ID Validation Loss: 1.2901
ID Test ACCURACY: 0.6697
ID Test Loss: 1.3277
OOD Validation ACCURACY: 0.6448
OOD Validation Loss: 1.6768
OOD Test ACCURACY: 0.5916
OOD Test Loss: 2.2474

[0m[1;37mINFO[0m: [1mChartInfo 0.6823 0.5402 0.6697 0.5916 0.6805 0.6448[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.593
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 420
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0 = 0.779 +- 0.201 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.3 class 1 = 0.79 +- 0.201 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.3 class 2 = 0.78 +- 0.201 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.3 all KL = 0.818 +- 0.201 (in-sample avg dev_std = 0.374)
SUFF++ for r=0.3 all L1 = 0.785 +- 0.185 (in-sample avg dev_std = 0.374)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.873 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 1 = 0.851 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 2 = 0.858 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all KL = 0.909 +- 0.147 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all L1 = 0.859 +- 0.163 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.698
SUFF++ for r=0.9 class 0 = 0.939 +- 0.051 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 class 1 = 0.947 +- 0.051 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 class 2 = 0.933 +- 0.051 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all KL = 0.975 +- 0.051 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.080 (in-sample avg dev_std = 0.146)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.509
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 763
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.52
SUFF++ for r=0.3 class 0 = 0.815 +- 0.167 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 1 = 0.751 +- 0.167 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 class 2 = 0.759 +- 0.167 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 all KL = 0.837 +- 0.167 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.3 all L1 = 0.769 +- 0.172 (in-sample avg dev_std = 0.339)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.58
SUFF++ for r=0.6 class 0 = 0.861 +- 0.116 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 1 = 0.847 +- 0.116 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 2 = 0.843 +- 0.116 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all KL = 0.923 +- 0.116 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all L1 = 0.85 +- 0.160 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.619
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.622
SUFF++ for r=0.9 class 0 = 0.969 +- 0.022 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1 = 0.965 +- 0.022 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 2 = 0.956 +- 0.022 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.991 +- 0.022 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.057 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.467
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 779
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.468
SUFF++ for r=0.3 class 0 = 0.832 +- 0.171 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 1 = 0.781 +- 0.171 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 2 = 0.754 +- 0.171 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 all KL = 0.846 +- 0.171 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 all L1 = 0.787 +- 0.173 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.501
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.519
SUFF++ for r=0.6 class 0 = 0.902 +- 0.097 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 class 1 = 0.854 +- 0.097 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 class 2 = 0.833 +- 0.097 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all KL = 0.935 +- 0.097 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all L1 = 0.861 +- 0.148 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.525
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.533
SUFF++ for r=0.9 class 0 = 0.975 +- 0.020 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.9 class 1 = 0.958 +- 0.020 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.9 class 2 = 0.957 +- 0.020 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.9 all KL = 0.991 +- 0.020 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.061 (in-sample avg dev_std = 0.082)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.581
NEC for r=0.3 class 0 = 0.137 +- 0.171 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 1 = 0.183 +- 0.171 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 2 = 0.162 +- 0.171 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all KL = 0.113 +- 0.171 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all L1 = 0.166 +- 0.169 (in-sample avg dev_std = 0.267)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.634
NEC for r=0.6 class 0 = 0.092 +- 0.121 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 1 = 0.11 +- 0.121 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 2 = 0.114 +- 0.121 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all KL = 0.062 +- 0.121 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all L1 = 0.107 +- 0.137 (in-sample avg dev_std = 0.207)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.687
NEC for r=0.9 class 0 = 0.124 +- 0.108 (in-sample avg dev_std = 0.173)
NEC for r=0.9 class 1 = 0.096 +- 0.108 (in-sample avg dev_std = 0.173)
NEC for r=0.9 class 2 = 0.106 +- 0.108 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all KL = 0.055 +- 0.108 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all L1 = 0.106 +- 0.143 (in-sample avg dev_std = 0.173)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.719
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.69
NEC for r=1.0 class 0 = 0.113 +- 0.131 (in-sample avg dev_std = 0.180)
NEC for r=1.0 class 1 = 0.091 +- 0.131 (in-sample avg dev_std = 0.180)
NEC for r=1.0 class 2 = 0.105 +- 0.131 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all KL = 0.059 +- 0.131 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all L1 = 0.1 +- 0.151 (in-sample avg dev_std = 0.180)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.496
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.502
NEC for r=0.3 class 0 = 0.126 +- 0.135 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 1 = 0.194 +- 0.135 (in-sample avg dev_std = 0.226)
NEC for r=0.3 class 2 = 0.205 +- 0.135 (in-sample avg dev_std = 0.226)
NEC for r=0.3 all KL = 0.098 +- 0.135 (in-sample avg dev_std = 0.226)
NEC for r=0.3 all L1 = 0.179 +- 0.162 (in-sample avg dev_std = 0.226)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.584
NEC for r=0.6 class 0 = 0.106 +- 0.095 (in-sample avg dev_std = 0.176)
NEC for r=0.6 class 1 = 0.132 +- 0.095 (in-sample avg dev_std = 0.176)
NEC for r=0.6 class 2 = 0.149 +- 0.095 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all KL = 0.06 +- 0.095 (in-sample avg dev_std = 0.176)
NEC for r=0.6 all L1 = 0.129 +- 0.144 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.619
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.62
NEC for r=0.9 class 0 = 0.1 +- 0.113 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 1 = 0.099 +- 0.113 (in-sample avg dev_std = 0.158)
NEC for r=0.9 class 2 = 0.126 +- 0.113 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all KL = 0.058 +- 0.113 (in-sample avg dev_std = 0.158)
NEC for r=0.9 all L1 = 0.105 +- 0.142 (in-sample avg dev_std = 0.158)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.634
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.63
NEC for r=1.0 class 0 = 0.093 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=1.0 class 1 = 0.093 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=1.0 class 2 = 0.122 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all KL = 0.06 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all L1 = 0.099 +- 0.145 (in-sample avg dev_std = 0.160)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.463
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.459
NEC for r=0.3 class 0 = 0.1 +- 0.109 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 1 = 0.163 +- 0.109 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 2 = 0.175 +- 0.109 (in-sample avg dev_std = 0.186)
NEC for r=0.3 all KL = 0.07 +- 0.109 (in-sample avg dev_std = 0.186)
NEC for r=0.3 all L1 = 0.149 +- 0.146 (in-sample avg dev_std = 0.186)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.501
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.503
NEC for r=0.6 class 0 = 0.078 +- 0.073 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 1 = 0.123 +- 0.073 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 2 = 0.138 +- 0.073 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all KL = 0.046 +- 0.073 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all L1 = 0.115 +- 0.124 (in-sample avg dev_std = 0.159)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.525
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.063 +- 0.099 (in-sample avg dev_std = 0.152)
NEC for r=0.9 class 1 = 0.118 +- 0.099 (in-sample avg dev_std = 0.152)
NEC for r=0.9 class 2 = 0.123 +- 0.099 (in-sample avg dev_std = 0.152)
NEC for r=0.9 all KL = 0.053 +- 0.099 (in-sample avg dev_std = 0.152)
NEC for r=0.9 all L1 = 0.105 +- 0.142 (in-sample avg dev_std = 0.152)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.531
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.066 +- 0.130 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 1 = 0.115 +- 0.130 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 2 = 0.13 +- 0.130 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all KL = 0.065 +- 0.130 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all L1 = 0.106 +- 0.159 (in-sample avg dev_std = 0.164)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 20:55:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:42 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:44 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:45 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:46 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 08:55:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0014
ID Validation ACCURACY: 0.7148
ID Validation Loss: 2.7177
ID Test ACCURACY: 0.6913
ID Test Loss: 3.0848
OOD Validation ACCURACY: 0.6325
OOD Validation Loss: 3.3770
OOD Test ACCURACY: 0.5820
OOD Test Loss: 3.4157

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 116...
[0m[1;37mINFO[0m: [1mCheckpoint 116: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0007
ID Validation ACCURACY: 0.6643
ID Validation Loss: 2.8800
ID Test ACCURACY: 0.6534
ID Test Loss: 3.1282
OOD Validation ACCURACY: 0.6431
OOD Validation Loss: 3.1743
OOD Test ACCURACY: 0.5752
OOD Test Loss: 3.6941

[0m[1;37mINFO[0m: [1mChartInfo 0.6913 0.5820 0.6534 0.5752 0.6643 0.6431[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.599
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 454
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.577
SUFF++ for r=0.3 class 0 = 0.766 +- 0.293 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 1 = 0.787 +- 0.293 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 2 = 0.806 +- 0.293 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all KL = 0.724 +- 0.293 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all L1 = 0.787 +- 0.216 (in-sample avg dev_std = 0.455)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0 = 0.81 +- 0.237 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 1 = 0.856 +- 0.237 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 class 2 = 0.838 +- 0.237 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all KL = 0.845 +- 0.237 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.6 all L1 = 0.84 +- 0.205 (in-sample avg dev_std = 0.311)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0 = 0.935 +- 0.133 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 1 = 0.941 +- 0.133 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 2 = 0.92 +- 0.133 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all KL = 0.944 +- 0.133 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.118 (in-sample avg dev_std = 0.219)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.536
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 768
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0 = 0.726 +- 0.277 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 1 = 0.721 +- 0.277 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 2 = 0.748 +- 0.277 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all KL = 0.704 +- 0.277 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all L1 = 0.728 +- 0.219 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.609
SUFF++ for r=0.6 class 0 = 0.814 +- 0.182 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 1 = 0.861 +- 0.182 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 2 = 0.847 +- 0.182 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all KL = 0.886 +- 0.182 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all L1 = 0.846 +- 0.195 (in-sample avg dev_std = 0.238)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.616
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.613
SUFF++ for r=0.9 class 0 = 0.931 +- 0.083 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 class 1 = 0.961 +- 0.083 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 class 2 = 0.955 +- 0.083 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 all KL = 0.971 +- 0.083 (in-sample avg dev_std = 0.150)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.099 (in-sample avg dev_std = 0.150)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 788
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.505
SUFF++ for r=0.3 class 0 = 0.74 +- 0.265 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 1 = 0.724 +- 0.265 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 2 = 0.729 +- 0.265 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 all KL = 0.706 +- 0.265 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 all L1 = 0.73 +- 0.210 (in-sample avg dev_std = 0.478)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.579
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.563
SUFF++ for r=0.6 class 0 = 0.828 +- 0.187 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 class 1 = 0.851 +- 0.187 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 class 2 = 0.83 +- 0.187 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 all KL = 0.879 +- 0.187 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.6 all L1 = 0.84 +- 0.189 (in-sample avg dev_std = 0.269)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.579
SUFF++ for r=0.9 class 0 = 0.945 +- 0.078 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 1 = 0.952 +- 0.078 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 2 = 0.94 +- 0.078 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all KL = 0.97 +- 0.078 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.103 (in-sample avg dev_std = 0.142)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.588
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.586
NEC for r=0.3 class 0 = 0.145 +- 0.237 (in-sample avg dev_std = 0.289)
NEC for r=0.3 class 1 = 0.15 +- 0.237 (in-sample avg dev_std = 0.289)
NEC for r=0.3 class 2 = 0.112 +- 0.237 (in-sample avg dev_std = 0.289)
NEC for r=0.3 all KL = 0.137 +- 0.237 (in-sample avg dev_std = 0.289)
NEC for r=0.3 all L1 = 0.138 +- 0.194 (in-sample avg dev_std = 0.289)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.643
NEC for r=0.6 class 0 = 0.143 +- 0.184 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 1 = 0.106 +- 0.184 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 2 = 0.106 +- 0.184 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all KL = 0.098 +- 0.184 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all L1 = 0.115 +- 0.165 (in-sample avg dev_std = 0.241)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0 = 0.122 +- 0.180 (in-sample avg dev_std = 0.202)
NEC for r=0.9 class 1 = 0.082 +- 0.180 (in-sample avg dev_std = 0.202)
NEC for r=0.9 class 2 = 0.11 +- 0.180 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all KL = 0.086 +- 0.180 (in-sample avg dev_std = 0.202)
NEC for r=0.9 all L1 = 0.099 +- 0.159 (in-sample avg dev_std = 0.202)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.714
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.684
NEC for r=1.0 class 0 = 0.117 +- 0.183 (in-sample avg dev_std = 0.209)
NEC for r=1.0 class 1 = 0.077 +- 0.183 (in-sample avg dev_std = 0.209)
NEC for r=1.0 class 2 = 0.107 +- 0.183 (in-sample avg dev_std = 0.209)
NEC for r=1.0 all KL = 0.085 +- 0.183 (in-sample avg dev_std = 0.209)
NEC for r=1.0 all L1 = 0.095 +- 0.162 (in-sample avg dev_std = 0.209)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.533
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.527
NEC for r=0.3 class 0 = 0.207 +- 0.202 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 1 = 0.194 +- 0.202 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 2 = 0.164 +- 0.202 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all KL = 0.156 +- 0.202 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all L1 = 0.191 +- 0.192 (in-sample avg dev_std = 0.303)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.608
NEC for r=0.6 class 0 = 0.175 +- 0.162 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 1 = 0.123 +- 0.162 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 2 = 0.129 +- 0.162 (in-sample avg dev_std = 0.219)
NEC for r=0.6 all KL = 0.097 +- 0.162 (in-sample avg dev_std = 0.219)
NEC for r=0.6 all L1 = 0.137 +- 0.175 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.616
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.628
NEC for r=0.9 class 0 = 0.145 +- 0.168 (in-sample avg dev_std = 0.200)
NEC for r=0.9 class 1 = 0.093 +- 0.168 (in-sample avg dev_std = 0.200)
NEC for r=0.9 class 2 = 0.092 +- 0.168 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all KL = 0.088 +- 0.168 (in-sample avg dev_std = 0.200)
NEC for r=0.9 all L1 = 0.106 +- 0.168 (in-sample avg dev_std = 0.200)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.637
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.63
NEC for r=1.0 class 0 = 0.127 +- 0.195 (in-sample avg dev_std = 0.216)
NEC for r=1.0 class 1 = 0.084 +- 0.195 (in-sample avg dev_std = 0.216)
NEC for r=1.0 class 2 = 0.102 +- 0.195 (in-sample avg dev_std = 0.216)
NEC for r=1.0 all KL = 0.092 +- 0.195 (in-sample avg dev_std = 0.216)
NEC for r=1.0 all L1 = 0.099 +- 0.175 (in-sample avg dev_std = 0.216)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.522
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.514
NEC for r=0.3 class 0 = 0.171 +- 0.184 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 1 = 0.187 +- 0.184 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 2 = 0.151 +- 0.184 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all KL = 0.129 +- 0.184 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all L1 = 0.174 +- 0.180 (in-sample avg dev_std = 0.245)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.579
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.567
NEC for r=0.6 class 0 = 0.154 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 1 = 0.119 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.6 class 2 = 0.136 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all KL = 0.088 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.6 all L1 = 0.132 +- 0.165 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.581
NEC for r=0.9 class 0 = 0.132 +- 0.168 (in-sample avg dev_std = 0.201)
NEC for r=0.9 class 1 = 0.103 +- 0.168 (in-sample avg dev_std = 0.201)
NEC for r=0.9 class 2 = 0.129 +- 0.168 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all KL = 0.091 +- 0.168 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all L1 = 0.117 +- 0.181 (in-sample avg dev_std = 0.201)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.574
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.581
NEC for r=1.0 class 0 = 0.129 +- 0.193 (in-sample avg dev_std = 0.218)
NEC for r=1.0 class 1 = 0.105 +- 0.193 (in-sample avg dev_std = 0.218)
NEC for r=1.0 class 2 = 0.125 +- 0.193 (in-sample avg dev_std = 0.218)
NEC for r=1.0 all KL = 0.1 +- 0.193 (in-sample avg dev_std = 0.218)
NEC for r=1.0 all L1 = 0.116 +- 0.192 (in-sample avg dev_std = 0.218)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:00:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:00:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0009
ID Validation ACCURACY: 0.7076
ID Validation Loss: 2.7026
ID Test ACCURACY: 0.6733
ID Test Loss: 3.4081
OOD Validation ACCURACY: 0.6375
OOD Validation Loss: 3.0555
OOD Test ACCURACY: 0.5820
OOD Test Loss: 3.0040

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 125...
[0m[1;37mINFO[0m: [1mCheckpoint 125: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.6931
ID Validation Loss: 2.7255
ID Test ACCURACY: 0.6625
ID Test Loss: 3.2942
OOD Validation ACCURACY: 0.6443
OOD Validation Loss: 3.6934
OOD Test ACCURACY: 0.5745
OOD Test Loss: 4.8844

[0m[1;37mINFO[0m: [1mChartInfo 0.6733 0.5820 0.6625 0.5745 0.6931 0.6443[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.583
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 427
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.566
SUFF++ for r=0.3 class 0 = 0.788 +- 0.307 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 class 1 = 0.747 +- 0.307 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 class 2 = 0.734 +- 0.307 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all KL = 0.687 +- 0.307 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all L1 = 0.754 +- 0.224 (in-sample avg dev_std = 0.500)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.629
SUFF++ for r=0.6 class 0 = 0.848 +- 0.234 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 class 1 = 0.846 +- 0.234 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 class 2 = 0.823 +- 0.234 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 all KL = 0.839 +- 0.234 (in-sample avg dev_std = 0.333)
SUFF++ for r=0.6 all L1 = 0.84 +- 0.198 (in-sample avg dev_std = 0.333)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
SUFF++ for r=0.9 class 0 = 0.946 +- 0.139 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 1 = 0.945 +- 0.139 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 2 = 0.91 +- 0.139 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all KL = 0.939 +- 0.139 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all L1 = 0.936 +- 0.114 (in-sample avg dev_std = 0.219)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.546
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 767
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.514
SUFF++ for r=0.3 class 0 = 0.69 +- 0.268 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 1 = 0.694 +- 0.268 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 2 = 0.686 +- 0.268 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all KL = 0.671 +- 0.268 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all L1 = 0.691 +- 0.207 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.602
SUFF++ for r=0.6 class 0 = 0.795 +- 0.192 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 1 = 0.845 +- 0.192 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 class 2 = 0.807 +- 0.192 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 all KL = 0.859 +- 0.192 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.6 all L1 = 0.824 +- 0.192 (in-sample avg dev_std = 0.282)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.639
SUFF++ for r=0.9 class 0 = 0.914 +- 0.098 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 1 = 0.938 +- 0.098 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 class 2 = 0.944 +- 0.098 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all KL = 0.959 +- 0.098 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.116 (in-sample avg dev_std = 0.170)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 792
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.492
SUFF++ for r=0.3 class 0 = 0.684 +- 0.248 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 1 = 0.7 +- 0.248 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 2 = 0.665 +- 0.248 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all KL = 0.676 +- 0.248 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all L1 = 0.687 +- 0.202 (in-sample avg dev_std = 0.498)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.556
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0 = 0.798 +- 0.194 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 class 1 = 0.831 +- 0.194 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 class 2 = 0.785 +- 0.194 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 all KL = 0.845 +- 0.194 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 all L1 = 0.811 +- 0.184 (in-sample avg dev_std = 0.309)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.565
SUFF++ for r=0.9 class 0 = 0.899 +- 0.105 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 class 1 = 0.935 +- 0.105 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 class 2 = 0.904 +- 0.105 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all KL = 0.954 +- 0.105 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all L1 = 0.918 +- 0.129 (in-sample avg dev_std = 0.169)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.564
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.57
NEC for r=0.3 class 0 = 0.115 +- 0.245 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 1 = 0.178 +- 0.245 (in-sample avg dev_std = 0.303)
NEC for r=0.3 class 2 = 0.148 +- 0.245 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all KL = 0.148 +- 0.245 (in-sample avg dev_std = 0.303)
NEC for r=0.3 all L1 = 0.154 +- 0.201 (in-sample avg dev_std = 0.303)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.633
NEC for r=0.6 class 0 = 0.113 +- 0.176 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 1 = 0.108 +- 0.176 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 2 = 0.117 +- 0.176 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all KL = 0.093 +- 0.176 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all L1 = 0.112 +- 0.159 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.685
NEC for r=0.9 class 0 = 0.112 +- 0.161 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 1 = 0.087 +- 0.161 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 2 = 0.087 +- 0.161 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all KL = 0.076 +- 0.161 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all L1 = 0.093 +- 0.161 (in-sample avg dev_std = 0.196)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0 = 0.107 +- 0.187 (in-sample avg dev_std = 0.223)
NEC for r=1.0 class 1 = 0.077 +- 0.187 (in-sample avg dev_std = 0.223)
NEC for r=1.0 class 2 = 0.121 +- 0.187 (in-sample avg dev_std = 0.223)
NEC for r=1.0 all KL = 0.084 +- 0.187 (in-sample avg dev_std = 0.223)
NEC for r=1.0 all L1 = 0.096 +- 0.173 (in-sample avg dev_std = 0.223)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.525
NEC for r=0.3 class 0 = 0.235 +- 0.241 (in-sample avg dev_std = 0.306)
NEC for r=0.3 class 1 = 0.199 +- 0.241 (in-sample avg dev_std = 0.306)
NEC for r=0.3 class 2 = 0.229 +- 0.241 (in-sample avg dev_std = 0.306)
NEC for r=0.3 all KL = 0.175 +- 0.241 (in-sample avg dev_std = 0.306)
NEC for r=0.3 all L1 = 0.214 +- 0.207 (in-sample avg dev_std = 0.306)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.611
NEC for r=0.6 class 0 = 0.178 +- 0.170 (in-sample avg dev_std = 0.226)
NEC for r=0.6 class 1 = 0.133 +- 0.170 (in-sample avg dev_std = 0.226)
NEC for r=0.6 class 2 = 0.157 +- 0.170 (in-sample avg dev_std = 0.226)
NEC for r=0.6 all KL = 0.106 +- 0.170 (in-sample avg dev_std = 0.226)
NEC for r=0.6 all L1 = 0.149 +- 0.178 (in-sample avg dev_std = 0.226)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.634
NEC for r=0.9 class 0 = 0.135 +- 0.173 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 1 = 0.108 +- 0.173 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 2 = 0.126 +- 0.173 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all KL = 0.093 +- 0.173 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all L1 = 0.119 +- 0.178 (in-sample avg dev_std = 0.210)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.642
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0 = 0.131 +- 0.179 (in-sample avg dev_std = 0.207)
NEC for r=1.0 class 1 = 0.107 +- 0.179 (in-sample avg dev_std = 0.207)
NEC for r=1.0 class 2 = 0.12 +- 0.179 (in-sample avg dev_std = 0.207)
NEC for r=1.0 all KL = 0.094 +- 0.179 (in-sample avg dev_std = 0.207)
NEC for r=1.0 all L1 = 0.116 +- 0.181 (in-sample avg dev_std = 0.207)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.514
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.526
NEC for r=0.3 class 0 = 0.244 +- 0.238 (in-sample avg dev_std = 0.296)
NEC for r=0.3 class 1 = 0.223 +- 0.238 (in-sample avg dev_std = 0.296)
NEC for r=0.3 class 2 = 0.227 +- 0.238 (in-sample avg dev_std = 0.296)
NEC for r=0.3 all KL = 0.178 +- 0.238 (in-sample avg dev_std = 0.296)
NEC for r=0.3 all L1 = 0.23 +- 0.216 (in-sample avg dev_std = 0.296)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.556
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.549
NEC for r=0.6 class 0 = 0.18 +- 0.188 (in-sample avg dev_std = 0.240)
NEC for r=0.6 class 1 = 0.153 +- 0.188 (in-sample avg dev_std = 0.240)
NEC for r=0.6 class 2 = 0.19 +- 0.188 (in-sample avg dev_std = 0.240)
NEC for r=0.6 all KL = 0.121 +- 0.188 (in-sample avg dev_std = 0.240)
NEC for r=0.6 all L1 = 0.169 +- 0.188 (in-sample avg dev_std = 0.240)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.563
NEC for r=0.9 class 0 = 0.142 +- 0.152 (in-sample avg dev_std = 0.191)
NEC for r=0.9 class 1 = 0.113 +- 0.152 (in-sample avg dev_std = 0.191)
NEC for r=0.9 class 2 = 0.139 +- 0.152 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all KL = 0.082 +- 0.152 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all L1 = 0.127 +- 0.171 (in-sample avg dev_std = 0.191)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.564
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0 = 0.136 +- 0.156 (in-sample avg dev_std = 0.185)
NEC for r=1.0 class 1 = 0.113 +- 0.156 (in-sample avg dev_std = 0.185)
NEC for r=1.0 class 2 = 0.135 +- 0.156 (in-sample avg dev_std = 0.185)
NEC for r=1.0 all KL = 0.082 +- 0.156 (in-sample avg dev_std = 0.185)
NEC for r=1.0 all L1 = 0.125 +- 0.175 (in-sample avg dev_std = 0.185)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.836, 0.897, 0.98, 1.0], 'all_L1': [0.76, 0.817, 0.939, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.753, 0.88, 0.97, 1.0], 'all_L1': [0.799, 0.865, 0.955, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.818, 0.909, 0.975, 1.0], 'all_L1': [0.785, 0.859, 0.941, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.724, 0.845, 0.944, 1.0], 'all_L1': [0.787, 0.84, 0.934, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.687, 0.839, 0.939, 1.0], 'all_L1': [0.754, 0.84, 0.936, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.099, 0.053, 0.032, 0.034], 'all_L1': [0.17, 0.117, 0.09, 0.087]}), defaultdict(<class 'list'>, {'all_KL': [0.133, 0.084, 0.068, 0.072], 'all_L1': [0.141, 0.103, 0.085, 0.086]}), defaultdict(<class 'list'>, {'all_KL': [0.113, 0.062, 0.055, 0.059], 'all_L1': [0.166, 0.107, 0.106, 0.1]}), defaultdict(<class 'list'>, {'all_KL': [0.137, 0.098, 0.086, 0.085], 'all_L1': [0.138, 0.115, 0.099, 0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.148, 0.093, 0.076, 0.084], 'all_L1': [0.154, 0.112, 0.093, 0.096]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.839, 0.904, 0.986, 1.0], 'all_L1': [0.728, 0.798, 0.947, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.761, 0.913, 0.98, 1.0], 'all_L1': [0.756, 0.862, 0.957, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.837, 0.923, 0.991, 1.0], 'all_L1': [0.769, 0.85, 0.964, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.704, 0.886, 0.971, 1.0], 'all_L1': [0.728, 0.846, 0.952, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.671, 0.859, 0.959, 1.0], 'all_L1': [0.691, 0.824, 0.933, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.072, 0.047, 0.039, 0.046], 'all_L1': [0.186, 0.139, 0.104, 0.103]}), defaultdict(<class 'list'>, {'all_KL': [0.111, 0.077, 0.096, 0.105], 'all_L1': [0.165, 0.125, 0.119, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.06, 0.058, 0.06], 'all_L1': [0.179, 0.129, 0.105, 0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.156, 0.097, 0.088, 0.092], 'all_L1': [0.191, 0.137, 0.106, 0.099]}), defaultdict(<class 'list'>, {'all_KL': [0.175, 0.106, 0.093, 0.094], 'all_L1': [0.214, 0.149, 0.119, 0.116]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.853, 0.905, 0.984, 1.0], 'all_L1': [0.751, 0.805, 0.941, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.792, 0.923, 0.976, 1.0], 'all_L1': [0.777, 0.869, 0.952, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.846, 0.935, 0.991, 1.0], 'all_L1': [0.787, 0.861, 0.962, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.706, 0.879, 0.97, 1.0], 'all_L1': [0.73, 0.84, 0.947, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.676, 0.845, 0.954, 1.0], 'all_L1': [0.687, 0.811, 0.918, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.06, 0.044, 0.052, 0.064], 'all_L1': [0.17, 0.13, 0.124, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.086, 0.053, 0.082, 0.095], 'all_L1': [0.15, 0.104, 0.112, 0.11]}), defaultdict(<class 'list'>, {'all_KL': [0.07, 0.046, 0.053, 0.065], 'all_L1': [0.149, 0.115, 0.105, 0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.129, 0.088, 0.091, 0.1], 'all_L1': [0.174, 0.132, 0.117, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.178, 0.121, 0.082, 0.082], 'all_L1': [0.23, 0.169, 0.127, 0.125]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.777 +- 0.017, 0.844 +- 0.017, 0.941 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.764 +- 0.056, 0.874 +- 0.028, 0.962 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.571 +- 0.008, 0.640 +- 0.009, 0.690 +- 0.006
nec class all_L1  =  0.154 +- 0.013, 0.111 +- 0.005, 0.095 +- 0.007, 0.093 +- 0.005
nec class all_KL  =  0.126 +- 0.018, 0.078 +- 0.018, 0.063 +- 0.019, 0.067 +- 0.019
nec_acc_int  =  0.576 +- 0.007, 0.639 +- 0.009, 0.685 +- 0.005, 0.688 +- 0.004

Eval split val
suff++ class all_L1  =  0.734 +- 0.027, 0.836 +- 0.023, 0.951 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.762 +- 0.068, 0.897 +- 0.023, 0.977 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.520 +- 0.012, 0.593 +- 0.011, 0.624 +- 0.010
nec class all_L1  =  0.187 +- 0.016, 0.136 +- 0.008, 0.111 +- 0.007, 0.107 +- 0.008
nec class all_KL  =  0.122 +- 0.038, 0.077 +- 0.022, 0.075 +- 0.022, 0.079 +- 0.022
nec_acc_int  =  0.518 +- 0.009, 0.597 +- 0.011, 0.624 +- 0.009, 0.629 +- 0.010

Eval split test
suff++ class all_L1  =  0.746 +- 0.036, 0.837 +- 0.026, 0.944 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.775 +- 0.072, 0.897 +- 0.032, 0.975 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.479 +- 0.020, 0.537 +- 0.018, 0.553 +- 0.017
nec class all_L1  =  0.175 +- 0.029, 0.130 +- 0.022, 0.117 +- 0.008, 0.117 +- 0.008
nec class all_KL  =  0.105 +- 0.044, 0.070 +- 0.030, 0.072 +- 0.016, 0.081 +- 0.015
nec_acc_int  =  0.487 +- 0.030, 0.532 +- 0.024, 0.554 +- 0.019, 0.555 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.465 +- 0.007, 0.478 +- 0.006, 0.518 +- 0.003, 0.546 +- 0.003
Faith. Armon (L1)= 		  =  0.256 +- 0.017, 0.196 +- 0.008, 0.172 +- 0.012, 0.170 +- 0.009
Faith. GMean (L1)= 	  =  0.345 +- 0.013, 0.306 +- 0.004, 0.298 +- 0.011, 0.305 +- 0.009
Faith. Aritm (KL)= 		  =  0.445 +- 0.019, 0.476 +- 0.007, 0.512 +- 0.005, 0.533 +- 0.009
Faith. Armon (KL)= 		  =  0.215 +- 0.024, 0.143 +- 0.029, 0.118 +- 0.033, 0.125 +- 0.034
Faith. GMean (KL)= 	  =  0.308 +- 0.012, 0.259 +- 0.027, 0.244 +- 0.037, 0.255 +- 0.040

Eval split val
Faith. Aritm (L1)= 		  =  0.461 +- 0.007, 0.486 +- 0.009, 0.531 +- 0.005, 0.553 +- 0.004
Faith. Armon (L1)= 		  =  0.297 +- 0.018, 0.233 +- 0.012, 0.198 +- 0.011, 0.193 +- 0.013
Faith. GMean (L1)= 	  =  0.370 +- 0.010, 0.337 +- 0.008, 0.324 +- 0.009, 0.326 +- 0.012
Faith. Aritm (KL)= 		  =  0.442 +- 0.017, 0.487 +- 0.007, 0.526 +- 0.008, 0.540 +- 0.011
Faith. Armon (KL)= 		  =  0.207 +- 0.053, 0.142 +- 0.037, 0.138 +- 0.039, 0.146 +- 0.039
Faith. GMean (KL)= 	  =  0.299 +- 0.035, 0.260 +- 0.036, 0.267 +- 0.042, 0.279 +- 0.042

Eval split test
Faith. Aritm (L1)= 		  =  0.461 +- 0.005, 0.484 +- 0.008, 0.531 +- 0.004, 0.558 +- 0.004
Faith. Armon (L1)= 		  =  0.281 +- 0.034, 0.224 +- 0.032, 0.208 +- 0.012, 0.209 +- 0.013
Faith. GMean (L1)= 	  =  0.359 +- 0.020, 0.328 +- 0.023, 0.332 +- 0.009, 0.342 +- 0.012
Faith. Aritm (KL)= 		  =  0.440 +- 0.016, 0.484 +- 0.005, 0.523 +- 0.005, 0.541 +- 0.007
Faith. Armon (KL)= 		  =  0.179 +- 0.063, 0.129 +- 0.050, 0.134 +- 0.028, 0.150 +- 0.025
Faith. GMean (KL)= 	  =  0.276 +- 0.043, 0.245 +- 0.046, 0.263 +- 0.029, 0.284 +- 0.026
Computed for split load_split = id



Completed in  0:21:17.103065  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length hard

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:04:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:41 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:42 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:42 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:43 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:04:45 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.6913
ID Validation Loss: 2.3240
ID Test ACCURACY: 0.6534
ID Test Loss: 2.4833
OOD Validation ACCURACY: 0.5782
OOD Validation Loss: 2.8972
OOD Test ACCURACY: 0.5305
OOD Test Loss: 3.9868

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 12...
[0m[1;37mINFO[0m: [1mCheckpoint 12: 
-----------------------------------
Train ACCURACY: 0.8614
Train Loss: 0.3896
ID Validation ACCURACY: 0.6715
ID Validation Loss: 1.2104
ID Test ACCURACY: 0.6841
ID Test Loss: 1.2010
OOD Validation ACCURACY: 0.6207
OOD Validation Loss: 1.7232
OOD Test ACCURACY: 0.5820
OOD Test Loss: 2.6667

[0m[1;37mINFO[0m: [1mChartInfo 0.6534 0.5305 0.6841 0.5820 0.6715 0.6207[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.601
SUFF++ for r=0.3 class 0 = 0.71 +- 0.367 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 1 = 0.723 +- 0.367 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 class 2 = 0.684 +- 0.367 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 all KL = 0.477 +- 0.367 (in-sample avg dev_std = 0.593)
SUFF++ for r=0.3 all L1 = 0.709 +- 0.234 (in-sample avg dev_std = 0.593)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0 = 0.809 +- 0.306 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 class 1 = 0.811 +- 0.306 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 class 2 = 0.792 +- 0.306 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 all KL = 0.713 +- 0.306 (in-sample avg dev_std = 0.418)
SUFF++ for r=0.6 all L1 = 0.805 +- 0.216 (in-sample avg dev_std = 0.418)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.658
SUFF++ for r=0.9 class 0 = 0.921 +- 0.176 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1 = 0.888 +- 0.176 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 2 = 0.912 +- 0.176 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.914 +- 0.176 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.903 +- 0.162 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.498
SUFF++ for r=0.3 class 0 = 0.687 +- 0.337 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 1 = 0.652 +- 0.337 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 2 = 0.634 +- 0.337 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all KL = 0.466 +- 0.337 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all L1 = 0.657 +- 0.237 (in-sample avg dev_std = 0.611)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.562
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.545
SUFF++ for r=0.6 class 0 = 0.782 +- 0.283 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 1 = 0.736 +- 0.283 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 class 2 = 0.733 +- 0.283 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all KL = 0.677 +- 0.283 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.6 all L1 = 0.747 +- 0.221 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.576
SUFF++ for r=0.9 class 0 = 0.908 +- 0.154 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 1 = 0.87 +- 0.154 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.154 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all KL = 0.911 +- 0.154 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.169 (in-sample avg dev_std = 0.219)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.457
SUFF++ for r=0.3 class 0 = 0.743 +- 0.325 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 1 = 0.658 +- 0.325 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 2 = 0.625 +- 0.325 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all KL = 0.5 +- 0.325 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all L1 = 0.672 +- 0.233 (in-sample avg dev_std = 0.577)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.485
SUFF++ for r=0.6 class 0 = 0.824 +- 0.270 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 1 = 0.75 +- 0.270 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 2 = 0.748 +- 0.270 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all KL = 0.716 +- 0.270 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.213 (in-sample avg dev_std = 0.420)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.52
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.524
SUFF++ for r=0.9 class 0 = 0.914 +- 0.142 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 class 1 = 0.868 +- 0.142 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 class 2 = 0.887 +- 0.142 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 all KL = 0.92 +- 0.142 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.158 (in-sample avg dev_std = 0.209)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0 = 0.226 +- 0.368 (in-sample avg dev_std = 0.428)
NEC for r=0.3 class 1 = 0.232 +- 0.368 (in-sample avg dev_std = 0.428)
NEC for r=0.3 class 2 = 0.232 +- 0.368 (in-sample avg dev_std = 0.428)
NEC for r=0.3 all KL = 0.309 +- 0.368 (in-sample avg dev_std = 0.428)
NEC for r=0.3 all L1 = 0.231 +- 0.269 (in-sample avg dev_std = 0.428)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.641
NEC for r=0.6 class 0 = 0.162 +- 0.271 (in-sample avg dev_std = 0.314)
NEC for r=0.6 class 1 = 0.159 +- 0.271 (in-sample avg dev_std = 0.314)
NEC for r=0.6 class 2 = 0.129 +- 0.271 (in-sample avg dev_std = 0.314)
NEC for r=0.6 all KL = 0.178 +- 0.271 (in-sample avg dev_std = 0.314)
NEC for r=0.6 all L1 = 0.152 +- 0.213 (in-sample avg dev_std = 0.314)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.659
NEC for r=0.9 class 0 = 0.116 +- 0.181 (in-sample avg dev_std = 0.217)
NEC for r=0.9 class 1 = 0.112 +- 0.181 (in-sample avg dev_std = 0.217)
NEC for r=0.9 class 2 = 0.097 +- 0.181 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all KL = 0.093 +- 0.181 (in-sample avg dev_std = 0.217)
NEC for r=0.9 all L1 = 0.109 +- 0.174 (in-sample avg dev_std = 0.217)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.69
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.664
NEC for r=1.0 class 0 = 0.105 +- 0.158 (in-sample avg dev_std = 0.200)
NEC for r=1.0 class 1 = 0.097 +- 0.158 (in-sample avg dev_std = 0.200)
NEC for r=1.0 class 2 = 0.083 +- 0.158 (in-sample avg dev_std = 0.200)
NEC for r=1.0 all KL = 0.074 +- 0.158 (in-sample avg dev_std = 0.200)
NEC for r=1.0 all L1 = 0.095 +- 0.160 (in-sample avg dev_std = 0.200)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.51
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.513
NEC for r=0.3 class 0 = 0.284 +- 0.369 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 1 = 0.327 +- 0.369 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 2 = 0.304 +- 0.369 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all KL = 0.42 +- 0.369 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all L1 = 0.311 +- 0.279 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.562
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.554
NEC for r=0.6 class 0 = 0.168 +- 0.275 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 1 = 0.224 +- 0.275 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 2 = 0.239 +- 0.275 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all KL = 0.227 +- 0.275 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all L1 = 0.213 +- 0.233 (in-sample avg dev_std = 0.345)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.569
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.566
NEC for r=0.9 class 0 = 0.111 +- 0.191 (in-sample avg dev_std = 0.231)
NEC for r=0.9 class 1 = 0.149 +- 0.191 (in-sample avg dev_std = 0.231)
NEC for r=0.9 class 2 = 0.161 +- 0.191 (in-sample avg dev_std = 0.231)
NEC for r=0.9 all KL = 0.113 +- 0.191 (in-sample avg dev_std = 0.231)
NEC for r=0.9 all L1 = 0.142 +- 0.193 (in-sample avg dev_std = 0.231)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.571
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.574
NEC for r=1.0 class 0 = 0.104 +- 0.174 (in-sample avg dev_std = 0.212)
NEC for r=1.0 class 1 = 0.133 +- 0.174 (in-sample avg dev_std = 0.212)
NEC for r=1.0 class 2 = 0.154 +- 0.174 (in-sample avg dev_std = 0.212)
NEC for r=1.0 all KL = 0.099 +- 0.174 (in-sample avg dev_std = 0.212)
NEC for r=1.0 all L1 = 0.13 +- 0.183 (in-sample avg dev_std = 0.212)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.488
NEC for r=0.3 class 0 = 0.227 +- 0.340 (in-sample avg dev_std = 0.442)
NEC for r=0.3 class 1 = 0.299 +- 0.340 (in-sample avg dev_std = 0.442)
NEC for r=0.3 class 2 = 0.285 +- 0.340 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all KL = 0.349 +- 0.340 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all L1 = 0.277 +- 0.263 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.506
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.505
NEC for r=0.6 class 0 = 0.147 +- 0.237 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 1 = 0.206 +- 0.237 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 2 = 0.175 +- 0.237 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all KL = 0.175 +- 0.237 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all L1 = 0.183 +- 0.214 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.52
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.517
NEC for r=0.9 class 0 = 0.096 +- 0.158 (in-sample avg dev_std = 0.199)
NEC for r=0.9 class 1 = 0.148 +- 0.158 (in-sample avg dev_std = 0.199)
NEC for r=0.9 class 2 = 0.121 +- 0.158 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all KL = 0.092 +- 0.158 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all L1 = 0.128 +- 0.177 (in-sample avg dev_std = 0.199)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.527
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.082 +- 0.147 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 1 = 0.126 +- 0.147 (in-sample avg dev_std = 0.186)
NEC for r=1.0 class 2 = 0.117 +- 0.147 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all KL = 0.079 +- 0.147 (in-sample avg dev_std = 0.186)
NEC for r=1.0 all L1 = 0.112 +- 0.165 (in-sample avg dev_std = 0.186)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:09:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:13 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:15 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:15 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:09:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 8...
[0m[1;37mINFO[0m: [1mCheckpoint 8: 
-----------------------------------
Train ACCURACY: 0.8139
Train Loss: 0.5301
ID Validation ACCURACY: 0.6913
ID Validation Loss: 1.0614
ID Test ACCURACY: 0.7058
ID Test Loss: 1.0733
OOD Validation ACCURACY: 0.6303
OOD Validation Loss: 1.5443
OOD Test ACCURACY: 0.5758
OOD Test Loss: 2.2754

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 8...
[0m[1;37mINFO[0m: [1mCheckpoint 8: 
-----------------------------------
Train ACCURACY: 0.8139
Train Loss: 0.5301
ID Validation ACCURACY: 0.6913
ID Validation Loss: 1.0614
ID Test ACCURACY: 0.7058
ID Test Loss: 1.0733
OOD Validation ACCURACY: 0.6303
OOD Validation Loss: 1.5443
OOD Test ACCURACY: 0.5758
OOD Test Loss: 2.2754

[0m[1;37mINFO[0m: [1mChartInfo 0.7058 0.5758 0.7058 0.5758 0.6913 0.6303[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.595
SUFF++ for r=0.3 class 0 = 0.659 +- 0.162 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 class 1 = 0.72 +- 0.162 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 class 2 = 0.694 +- 0.162 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 all KL = 0.813 +- 0.162 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 all L1 = 0.698 +- 0.127 (in-sample avg dev_std = 0.334)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.648
SUFF++ for r=0.6 class 0 = 0.722 +- 0.169 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 class 1 = 0.762 +- 0.169 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 class 2 = 0.735 +- 0.169 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 all KL = 0.83 +- 0.169 (in-sample avg dev_std = 0.309)
SUFF++ for r=0.6 all L1 = 0.745 +- 0.147 (in-sample avg dev_std = 0.309)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.672
SUFF++ for r=0.9 class 0 = 0.867 +- 0.079 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 class 1 = 0.87 +- 0.079 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 class 2 = 0.879 +- 0.079 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all KL = 0.947 +- 0.079 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all L1 = 0.872 +- 0.115 (in-sample avg dev_std = 0.161)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.593
SUFF++ for r=0.3 class 0 = 0.695 +- 0.141 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 1 = 0.753 +- 0.141 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 class 2 = 0.707 +- 0.141 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all KL = 0.855 +- 0.141 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.3 all L1 = 0.728 +- 0.129 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.627
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.618
SUFF++ for r=0.6 class 0 = 0.782 +- 0.131 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 class 1 = 0.795 +- 0.131 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 class 2 = 0.763 +- 0.131 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all KL = 0.878 +- 0.131 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all L1 = 0.785 +- 0.137 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.627
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.624
SUFF++ for r=0.9 class 0 = 0.871 +- 0.102 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1 = 0.846 +- 0.102 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.102 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.933 +- 0.102 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.855 +- 0.135 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.749 +- 0.121 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 1 = 0.765 +- 0.121 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 class 2 = 0.725 +- 0.121 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 all KL = 0.877 +- 0.121 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.3 all L1 = 0.751 +- 0.123 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.58
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.572
SUFF++ for r=0.6 class 0 = 0.819 +- 0.119 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.6 class 1 = 0.789 +- 0.119 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.6 class 2 = 0.776 +- 0.119 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.6 all KL = 0.886 +- 0.119 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.6 all L1 = 0.794 +- 0.140 (in-sample avg dev_std = 0.236)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.585
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.581
SUFF++ for r=0.9 class 0 = 0.885 +- 0.093 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 1 = 0.84 +- 0.093 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 2 = 0.855 +- 0.093 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all KL = 0.934 +- 0.093 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all L1 = 0.856 +- 0.138 (in-sample avg dev_std = 0.160)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.642
NEC for r=0.3 class 0 = 0.26 +- 0.136 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 1 = 0.216 +- 0.136 (in-sample avg dev_std = 0.205)
NEC for r=0.3 class 2 = 0.264 +- 0.136 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all KL = 0.112 +- 0.136 (in-sample avg dev_std = 0.205)
NEC for r=0.3 all L1 = 0.24 +- 0.142 (in-sample avg dev_std = 0.205)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.646
NEC for r=0.6 class 0 = 0.186 +- 0.131 (in-sample avg dev_std = 0.197)
NEC for r=0.6 class 1 = 0.162 +- 0.131 (in-sample avg dev_std = 0.197)
NEC for r=0.6 class 2 = 0.199 +- 0.131 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all KL = 0.083 +- 0.131 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all L1 = 0.178 +- 0.143 (in-sample avg dev_std = 0.197)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.672
NEC for r=0.9 class 0 = 0.123 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.9 class 1 = 0.117 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.9 class 2 = 0.119 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all KL = 0.046 +- 0.091 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all L1 = 0.119 +- 0.110 (in-sample avg dev_std = 0.139)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.688
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.671
NEC for r=1.0 class 0 = 0.103 +- 0.094 (in-sample avg dev_std = 0.127)
NEC for r=1.0 class 1 = 0.102 +- 0.094 (in-sample avg dev_std = 0.127)
NEC for r=1.0 class 2 = 0.1 +- 0.094 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all KL = 0.039 +- 0.094 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all L1 = 0.102 +- 0.105 (in-sample avg dev_std = 0.127)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.614
NEC for r=0.3 class 0 = 0.262 +- 0.113 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1 = 0.222 +- 0.113 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 2 = 0.252 +- 0.113 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.103 +- 0.113 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.238 +- 0.128 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.627
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.629
NEC for r=0.6 class 0 = 0.178 +- 0.104 (in-sample avg dev_std = 0.166)
NEC for r=0.6 class 1 = 0.167 +- 0.104 (in-sample avg dev_std = 0.166)
NEC for r=0.6 class 2 = 0.172 +- 0.104 (in-sample avg dev_std = 0.166)
NEC for r=0.6 all KL = 0.074 +- 0.104 (in-sample avg dev_std = 0.166)
NEC for r=0.6 all L1 = 0.171 +- 0.132 (in-sample avg dev_std = 0.166)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.627
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.63
NEC for r=0.9 class 0 = 0.118 +- 0.087 (in-sample avg dev_std = 0.141)
NEC for r=0.9 class 1 = 0.131 +- 0.087 (in-sample avg dev_std = 0.141)
NEC for r=0.9 class 2 = 0.13 +- 0.087 (in-sample avg dev_std = 0.141)
NEC for r=0.9 all KL = 0.053 +- 0.087 (in-sample avg dev_std = 0.141)
NEC for r=0.9 all L1 = 0.127 +- 0.124 (in-sample avg dev_std = 0.141)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.636
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.635
NEC for r=1.0 class 0 = 0.111 +- 0.081 (in-sample avg dev_std = 0.129)
NEC for r=1.0 class 1 = 0.111 +- 0.081 (in-sample avg dev_std = 0.129)
NEC for r=1.0 class 2 = 0.107 +- 0.081 (in-sample avg dev_std = 0.129)
NEC for r=1.0 all KL = 0.045 +- 0.081 (in-sample avg dev_std = 0.129)
NEC for r=1.0 all L1 = 0.11 +- 0.113 (in-sample avg dev_std = 0.129)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.579
NEC for r=0.3 class 0 = 0.221 +- 0.108 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 1 = 0.213 +- 0.108 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 2 = 0.226 +- 0.108 (in-sample avg dev_std = 0.186)
NEC for r=0.3 all KL = 0.09 +- 0.108 (in-sample avg dev_std = 0.186)
NEC for r=0.3 all L1 = 0.218 +- 0.129 (in-sample avg dev_std = 0.186)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.58
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.583
NEC for r=0.6 class 0 = 0.15 +- 0.106 (in-sample avg dev_std = 0.169)
NEC for r=0.6 class 1 = 0.174 +- 0.106 (in-sample avg dev_std = 0.169)
NEC for r=0.6 class 2 = 0.175 +- 0.106 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all KL = 0.075 +- 0.106 (in-sample avg dev_std = 0.169)
NEC for r=0.6 all L1 = 0.168 +- 0.140 (in-sample avg dev_std = 0.169)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.585
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.583
NEC for r=0.9 class 0 = 0.103 +- 0.096 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1 = 0.141 +- 0.096 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 2 = 0.131 +- 0.096 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.057 +- 0.096 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.129 +- 0.130 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.579
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0 = 0.097 +- 0.094 (in-sample avg dev_std = 0.144)
NEC for r=1.0 class 1 = 0.13 +- 0.094 (in-sample avg dev_std = 0.144)
NEC for r=1.0 class 2 = 0.114 +- 0.094 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all KL = 0.054 +- 0.094 (in-sample avg dev_std = 0.144)
NEC for r=1.0 all L1 = 0.118 +- 0.131 (in-sample avg dev_std = 0.144)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:13:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:53 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:13:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 12...
[0m[1;37mINFO[0m: [1mCheckpoint 12: 
-----------------------------------
Train ACCURACY: 0.8722
Train Loss: 0.3564
ID Validation ACCURACY: 0.7148
ID Validation Loss: 0.9736
ID Test ACCURACY: 0.6805
ID Test Loss: 1.1741
OOD Validation ACCURACY: 0.6353
OOD Validation Loss: 1.6169
OOD Test ACCURACY: 0.5649
OOD Test Loss: 2.5936

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 8...
[0m[1;37mINFO[0m: [1mCheckpoint 8: 
-----------------------------------
Train ACCURACY: 0.8143
Train Loss: 0.5150
ID Validation ACCURACY: 0.6968
ID Validation Loss: 0.9382
ID Test ACCURACY: 0.6913
ID Test Loss: 1.0195
OOD Validation ACCURACY: 0.6375
OOD Validation Loss: 1.2855
OOD Test ACCURACY: 0.5827
OOD Test Loss: 1.7088

[0m[1;37mINFO[0m: [1mChartInfo 0.6805 0.5649 0.6913 0.5827 0.6968 0.6375[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.607
SUFF++ for r=0.3 class 0 = 0.671 +- 0.167 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 1 = 0.73 +- 0.167 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 2 = 0.676 +- 0.167 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all KL = 0.8 +- 0.167 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all L1 = 0.701 +- 0.147 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0 = 0.749 +- 0.171 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 class 1 = 0.774 +- 0.171 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 class 2 = 0.721 +- 0.171 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 all KL = 0.816 +- 0.171 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.6 all L1 = 0.753 +- 0.167 (in-sample avg dev_std = 0.345)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.69
SUFF++ for r=0.9 class 0 = 0.896 +- 0.100 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1 = 0.885 +- 0.100 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 2 = 0.872 +- 0.100 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.947 +- 0.100 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.884 +- 0.128 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.587
SUFF++ for r=0.3 class 0 = 0.674 +- 0.175 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.3 class 1 = 0.709 +- 0.175 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.3 class 2 = 0.647 +- 0.175 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.3 all KL = 0.772 +- 0.175 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.3 all L1 = 0.687 +- 0.154 (in-sample avg dev_std = 0.351)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.604
SUFF++ for r=0.6 class 0 = 0.761 +- 0.176 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.6 class 1 = 0.758 +- 0.176 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.6 class 2 = 0.691 +- 0.176 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.6 all KL = 0.801 +- 0.176 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.6 all L1 = 0.744 +- 0.171 (in-sample avg dev_std = 0.342)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.617
SUFF++ for r=0.9 class 0 = 0.871 +- 0.114 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.114 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 2 = 0.843 +- 0.114 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all KL = 0.926 +- 0.114 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.151 (in-sample avg dev_std = 0.185)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.528
SUFF++ for r=0.3 class 0 = 0.725 +- 0.159 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 1 = 0.714 +- 0.159 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 2 = 0.657 +- 0.159 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all KL = 0.796 +- 0.159 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all L1 = 0.703 +- 0.150 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.548
SUFF++ for r=0.6 class 0 = 0.817 +- 0.151 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.151 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.6 class 2 = 0.733 +- 0.151 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.6 all KL = 0.843 +- 0.151 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.6 all L1 = 0.77 +- 0.166 (in-sample avg dev_std = 0.300)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.566
SUFF++ for r=0.9 class 0 = 0.889 +- 0.114 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1 = 0.839 +- 0.114 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 2 = 0.839 +- 0.114 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.921 +- 0.114 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.852 +- 0.154 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.64
NEC for r=0.3 class 0 = 0.252 +- 0.137 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 1 = 0.195 +- 0.137 (in-sample avg dev_std = 0.211)
NEC for r=0.3 class 2 = 0.26 +- 0.137 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all KL = 0.11 +- 0.137 (in-sample avg dev_std = 0.211)
NEC for r=0.3 all L1 = 0.227 +- 0.149 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.682
NEC for r=0.6 class 0 = 0.196 +- 0.129 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 1 = 0.156 +- 0.129 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 2 = 0.196 +- 0.129 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all KL = 0.092 +- 0.129 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all L1 = 0.177 +- 0.152 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.693
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.693
NEC for r=0.9 class 0 = 0.123 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=0.9 class 1 = 0.118 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=0.9 class 2 = 0.129 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all KL = 0.053 +- 0.094 (in-sample avg dev_std = 0.168)
NEC for r=0.9 all L1 = 0.122 +- 0.127 (in-sample avg dev_std = 0.168)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.708
NEC for r=1.0 class 0 = 0.1 +- 0.091 (in-sample avg dev_std = 0.143)
NEC for r=1.0 class 1 = 0.103 +- 0.091 (in-sample avg dev_std = 0.143)
NEC for r=1.0 class 2 = 0.096 +- 0.091 (in-sample avg dev_std = 0.143)
NEC for r=1.0 all KL = 0.041 +- 0.091 (in-sample avg dev_std = 0.143)
NEC for r=1.0 all L1 = 0.1 +- 0.112 (in-sample avg dev_std = 0.143)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.601
NEC for r=0.3 class 0 = 0.273 +- 0.167 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 1 = 0.229 +- 0.167 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 2 = 0.272 +- 0.167 (in-sample avg dev_std = 0.239)
NEC for r=0.3 all KL = 0.142 +- 0.167 (in-sample avg dev_std = 0.239)
NEC for r=0.3 all L1 = 0.249 +- 0.166 (in-sample avg dev_std = 0.239)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.622
NEC for r=0.6 class 0 = 0.204 +- 0.137 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 1 = 0.171 +- 0.137 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 2 = 0.199 +- 0.137 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all KL = 0.103 +- 0.137 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all L1 = 0.185 +- 0.157 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.123 +- 0.110 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1 = 0.135 +- 0.110 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 2 = 0.147 +- 0.110 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.068 +- 0.110 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.134 +- 0.150 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.625
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.622
NEC for r=1.0 class 0 = 0.101 +- 0.099 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 1 = 0.115 +- 0.099 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 2 = 0.124 +- 0.099 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all KL = 0.053 +- 0.099 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all L1 = 0.113 +- 0.139 (in-sample avg dev_std = 0.146)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.545
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.556
NEC for r=0.3 class 0 = 0.231 +- 0.146 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 1 = 0.233 +- 0.146 (in-sample avg dev_std = 0.243)
NEC for r=0.3 class 2 = 0.252 +- 0.146 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all KL = 0.129 +- 0.146 (in-sample avg dev_std = 0.243)
NEC for r=0.3 all L1 = 0.237 +- 0.159 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.566
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.562
NEC for r=0.6 class 0 = 0.162 +- 0.128 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1 = 0.182 +- 0.128 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 2 = 0.193 +- 0.128 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.095 +- 0.128 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.179 +- 0.156 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.575
NEC for r=0.9 class 0 = 0.104 +- 0.113 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1 = 0.131 +- 0.113 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 2 = 0.153 +- 0.113 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.064 +- 0.113 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.129 +- 0.146 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.567
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.569
NEC for r=1.0 class 0 = 0.092 +- 0.119 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1 = 0.12 +- 0.119 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 2 = 0.135 +- 0.119 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.061 +- 0.119 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.116 +- 0.143 (in-sample avg dev_std = 0.159)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:18:22 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:22 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:23 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:24 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:18:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0003
ID Validation ACCURACY: 0.6986
ID Validation Loss: 4.1286
ID Test ACCURACY: 0.6625
ID Test Loss: 4.8247
OOD Validation ACCURACY: 0.6179
OOD Validation Loss: 6.0801
OOD Test ACCURACY: 0.5559
OOD Test Loss: 10.5476

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ACCURACY: 0.7571
Train Loss: 0.8064
ID Validation ACCURACY: 0.6751
ID Validation Loss: 1.2743
ID Test ACCURACY: 0.6823
ID Test Loss: 1.2239
OOD Validation ACCURACY: 0.6246
OOD Validation Loss: 1.6824
OOD Test ACCURACY: 0.5738
OOD Test Loss: 2.4078

[0m[1;37mINFO[0m: [1mChartInfo 0.6625 0.5559 0.6823 0.5738 0.6751 0.6246[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.597
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.545
SUFF++ for r=0.3 class 0 = 0.573 +- 0.333 (in-sample avg dev_std = 0.714)
SUFF++ for r=0.3 class 1 = 0.638 +- 0.333 (in-sample avg dev_std = 0.714)
SUFF++ for r=0.3 class 2 = 0.585 +- 0.333 (in-sample avg dev_std = 0.714)
SUFF++ for r=0.3 all KL = 0.308 +- 0.333 (in-sample avg dev_std = 0.714)
SUFF++ for r=0.3 all L1 = 0.608 +- 0.222 (in-sample avg dev_std = 0.714)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.672
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.618
SUFF++ for r=0.6 class 0 = 0.649 +- 0.379 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.6 class 1 = 0.76 +- 0.379 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.6 class 2 = 0.698 +- 0.379 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.6 all KL = 0.454 +- 0.379 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.6 all L1 = 0.716 +- 0.227 (in-sample avg dev_std = 0.596)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0 = 0.857 +- 0.262 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 1 = 0.885 +- 0.262 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 2 = 0.872 +- 0.262 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all KL = 0.835 +- 0.262 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all L1 = 0.875 +- 0.194 (in-sample avg dev_std = 0.316)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.512
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0 = 0.52 +- 0.310 (in-sample avg dev_std = 0.710)
SUFF++ for r=0.3 class 1 = 0.602 +- 0.310 (in-sample avg dev_std = 0.710)
SUFF++ for r=0.3 class 2 = 0.523 +- 0.310 (in-sample avg dev_std = 0.710)
SUFF++ for r=0.3 all KL = 0.302 +- 0.310 (in-sample avg dev_std = 0.710)
SUFF++ for r=0.3 all L1 = 0.564 +- 0.211 (in-sample avg dev_std = 0.710)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.615
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.571
SUFF++ for r=0.6 class 0 = 0.614 +- 0.362 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 class 1 = 0.729 +- 0.362 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 class 2 = 0.677 +- 0.362 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 all KL = 0.47 +- 0.362 (in-sample avg dev_std = 0.597)
SUFF++ for r=0.6 all L1 = 0.689 +- 0.230 (in-sample avg dev_std = 0.597)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.621
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.621
SUFF++ for r=0.9 class 0 = 0.83 +- 0.283 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 1 = 0.875 +- 0.283 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 2 = 0.839 +- 0.283 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 all KL = 0.814 +- 0.283 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 all L1 = 0.856 +- 0.207 (in-sample avg dev_std = 0.320)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.454
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.446
SUFF++ for r=0.3 class 0 = 0.581 +- 0.295 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 class 1 = 0.559 +- 0.295 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 class 2 = 0.517 +- 0.295 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 all KL = 0.261 +- 0.295 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 all L1 = 0.554 +- 0.211 (in-sample avg dev_std = 0.728)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.533
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.517
SUFF++ for r=0.6 class 0 = 0.686 +- 0.346 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.6 class 1 = 0.667 +- 0.346 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.6 class 2 = 0.659 +- 0.346 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.6 all KL = 0.413 +- 0.346 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.6 all L1 = 0.67 +- 0.223 (in-sample avg dev_std = 0.613)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.556
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.548
SUFF++ for r=0.9 class 0 = 0.837 +- 0.289 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 class 1 = 0.838 +- 0.289 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 class 2 = 0.86 +- 0.289 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 all KL = 0.792 +- 0.289 (in-sample avg dev_std = 0.347)
SUFF++ for r=0.9 all L1 = 0.843 +- 0.213 (in-sample avg dev_std = 0.347)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.597
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.585
NEC for r=0.3 class 0 = 0.317 +- 0.406 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 1 = 0.317 +- 0.406 (in-sample avg dev_std = 0.489)
NEC for r=0.3 class 2 = 0.32 +- 0.406 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all KL = 0.438 +- 0.406 (in-sample avg dev_std = 0.489)
NEC for r=0.3 all L1 = 0.318 +- 0.304 (in-sample avg dev_std = 0.489)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.672
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.657
NEC for r=0.6 class 0 = 0.203 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 1 = 0.173 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 2 = 0.216 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all KL = 0.271 +- 0.357 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all L1 = 0.193 +- 0.253 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.666
NEC for r=0.9 class 0 = 0.13 +- 0.258 (in-sample avg dev_std = 0.271)
NEC for r=0.9 class 1 = 0.102 +- 0.258 (in-sample avg dev_std = 0.271)
NEC for r=0.9 class 2 = 0.137 +- 0.258 (in-sample avg dev_std = 0.271)
NEC for r=0.9 all KL = 0.136 +- 0.258 (in-sample avg dev_std = 0.271)
NEC for r=0.9 all L1 = 0.119 +- 0.207 (in-sample avg dev_std = 0.271)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.695
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.678
NEC for r=1.0 class 0 = 0.106 +- 0.234 (in-sample avg dev_std = 0.259)
NEC for r=1.0 class 1 = 0.097 +- 0.234 (in-sample avg dev_std = 0.259)
NEC for r=1.0 class 2 = 0.117 +- 0.234 (in-sample avg dev_std = 0.259)
NEC for r=1.0 all KL = 0.118 +- 0.234 (in-sample avg dev_std = 0.259)
NEC for r=1.0 all L1 = 0.105 +- 0.186 (in-sample avg dev_std = 0.259)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.512
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.543
NEC for r=0.3 class 0 = 0.402 +- 0.378 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 1 = 0.346 +- 0.378 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 2 = 0.407 +- 0.378 (in-sample avg dev_std = 0.536)
NEC for r=0.3 all KL = 0.518 +- 0.378 (in-sample avg dev_std = 0.536)
NEC for r=0.3 all L1 = 0.373 +- 0.281 (in-sample avg dev_std = 0.536)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.615
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.604
NEC for r=0.6 class 0 = 0.242 +- 0.347 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 1 = 0.21 +- 0.347 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 2 = 0.248 +- 0.347 (in-sample avg dev_std = 0.405)
NEC for r=0.6 all KL = 0.301 +- 0.347 (in-sample avg dev_std = 0.405)
NEC for r=0.6 all L1 = 0.226 +- 0.260 (in-sample avg dev_std = 0.405)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.621
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.616
NEC for r=0.9 class 0 = 0.14 +- 0.258 (in-sample avg dev_std = 0.272)
NEC for r=0.9 class 1 = 0.12 +- 0.258 (in-sample avg dev_std = 0.272)
NEC for r=0.9 class 2 = 0.147 +- 0.258 (in-sample avg dev_std = 0.272)
NEC for r=0.9 all KL = 0.151 +- 0.258 (in-sample avg dev_std = 0.272)
NEC for r=0.9 all L1 = 0.131 +- 0.207 (in-sample avg dev_std = 0.272)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.615
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.61
NEC for r=1.0 class 0 = 0.113 +- 0.247 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 1 = 0.114 +- 0.247 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 2 = 0.137 +- 0.247 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all KL = 0.132 +- 0.247 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all L1 = 0.119 +- 0.202 (in-sample avg dev_std = 0.257)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.454
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.489
NEC for r=0.3 class 0 = 0.317 +- 0.380 (in-sample avg dev_std = 0.525)
NEC for r=0.3 class 1 = 0.348 +- 0.380 (in-sample avg dev_std = 0.525)
NEC for r=0.3 class 2 = 0.398 +- 0.380 (in-sample avg dev_std = 0.525)
NEC for r=0.3 all KL = 0.497 +- 0.380 (in-sample avg dev_std = 0.525)
NEC for r=0.3 all L1 = 0.352 +- 0.286 (in-sample avg dev_std = 0.525)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.533
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.545
NEC for r=0.6 class 0 = 0.216 +- 0.350 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 1 = 0.24 +- 0.350 (in-sample avg dev_std = 0.402)
NEC for r=0.6 class 2 = 0.233 +- 0.350 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all KL = 0.305 +- 0.350 (in-sample avg dev_std = 0.402)
NEC for r=0.6 all L1 = 0.232 +- 0.261 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.556
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.556
NEC for r=0.9 class 0 = 0.132 +- 0.274 (in-sample avg dev_std = 0.283)
NEC for r=0.9 class 1 = 0.14 +- 0.274 (in-sample avg dev_std = 0.283)
NEC for r=0.9 class 2 = 0.149 +- 0.274 (in-sample avg dev_std = 0.283)
NEC for r=0.9 all KL = 0.164 +- 0.274 (in-sample avg dev_std = 0.283)
NEC for r=0.9 all L1 = 0.14 +- 0.217 (in-sample avg dev_std = 0.283)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.55
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.106 +- 0.261 (in-sample avg dev_std = 0.279)
NEC for r=1.0 class 1 = 0.131 +- 0.261 (in-sample avg dev_std = 0.279)
NEC for r=1.0 class 2 = 0.134 +- 0.261 (in-sample avg dev_std = 0.279)
NEC for r=1.0 all KL = 0.144 +- 0.261 (in-sample avg dev_std = 0.279)
NEC for r=1.0 all L1 = 0.125 +- 0.208 (in-sample avg dev_std = 0.279)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:22:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 04/17/2024 09:22:59 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:23:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.6968
ID Validation Loss: 4.4539
ID Test ACCURACY: 0.6625
ID Test Loss: 4.7849
OOD Validation ACCURACY: 0.6118
OOD Validation Loss: 5.8906
OOD Test ACCURACY: 0.5436
OOD Test Loss: 9.0054

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ACCURACY: 0.8278
Train Loss: 0.4617
ID Validation ACCURACY: 0.6841
ID Validation Loss: 0.9630
ID Test ACCURACY: 0.6859
ID Test Loss: 1.0097
OOD Validation ACCURACY: 0.6431
OOD Validation Loss: 1.3558
OOD Test ACCURACY: 0.5841
OOD Test Loss: 2.0410

[0m[1;37mINFO[0m: [1mChartInfo 0.6625 0.5436 0.6859 0.5841 0.6841 0.6431[0mGOODTwitter(554)
Data example from id_val: Data(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
Label distribution from id_val: (tensor([0, 1, 2]), tensor([138, 264, 152]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1785)
Data example from val: Data(x=[23, 768], edge_index=[2, 44], y=[1], idx=[1], sentence_tokens=[23], length=[1], domain_id=[1], ori_edge_index=[2, 44], node_perm=[23])
Label distribution from val: (tensor([0, 1, 2]), tensor([453, 956, 376]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.591
SUFF++ for r=0.3 class 0 = 0.71 +- 0.395 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 class 1 = 0.716 +- 0.395 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 class 2 = 0.687 +- 0.395 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 all KL = 0.391 +- 0.395 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 all L1 = 0.707 +- 0.232 (in-sample avg dev_std = 0.650)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.64
SUFF++ for r=0.6 class 0 = 0.835 +- 0.371 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 1 = 0.808 +- 0.371 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 2 = 0.782 +- 0.371 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all KL = 0.633 +- 0.371 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all L1 = 0.808 +- 0.226 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.681
SUFF++ for r=0.9 class 0 = 0.919 +- 0.233 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 1 = 0.901 +- 0.233 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 2 = 0.9 +- 0.233 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all KL = 0.878 +- 0.233 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.176 (in-sample avg dev_std = 0.275)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.53
SUFF++ for r=0.3 class 0 = 0.673 +- 0.355 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 class 1 = 0.648 +- 0.355 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 class 2 = 0.625 +- 0.355 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 all KL = 0.349 +- 0.355 (in-sample avg dev_std = 0.658)
SUFF++ for r=0.3 all L1 = 0.649 +- 0.234 (in-sample avg dev_std = 0.658)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.575
SUFF++ for r=0.6 class 0 = 0.832 +- 0.335 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1 = 0.772 +- 0.335 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 2 = 0.759 +- 0.335 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.654 +- 0.335 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.784 +- 0.227 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.604
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.606
SUFF++ for r=0.9 class 0 = 0.924 +- 0.189 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 1 = 0.898 +- 0.189 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.189 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all KL = 0.904 +- 0.189 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all L1 = 0.9 +- 0.172 (in-sample avg dev_std = 0.227)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.519
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.491
SUFF++ for r=0.3 class 0 = 0.662 +- 0.343 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.3 class 1 = 0.624 +- 0.343 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.3 class 2 = 0.615 +- 0.343 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.3 all KL = 0.329 +- 0.343 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.3 all L1 = 0.632 +- 0.230 (in-sample avg dev_std = 0.669)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.517
SUFF++ for r=0.6 class 0 = 0.827 +- 0.350 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 1 = 0.771 +- 0.350 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 class 2 = 0.742 +- 0.350 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all KL = 0.638 +- 0.350 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.6 all L1 = 0.778 +- 0.229 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.525
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.518
SUFF++ for r=0.9 class 0 = 0.922 +- 0.186 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 1 = 0.901 +- 0.186 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 2 = 0.895 +- 0.186 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all KL = 0.903 +- 0.186 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.164 (in-sample avg dev_std = 0.237)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 548
Effective ratio: 0.316 +- 0.016
Model Accuracy over intervened graphs for r=0.3 =  0.647
NEC for r=0.3 class 0 = 0.222 +- 0.411 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 1 = 0.226 +- 0.411 (in-sample avg dev_std = 0.462)
NEC for r=0.3 class 2 = 0.233 +- 0.411 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all KL = 0.351 +- 0.411 (in-sample avg dev_std = 0.462)
NEC for r=0.3 all L1 = 0.227 +- 0.285 (in-sample avg dev_std = 0.462)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 548
Effective ratio: 0.617 +- 0.017
Model Accuracy over intervened graphs for r=0.6 =  0.656
NEC for r=0.6 class 0 = 0.154 +- 0.346 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 1 = 0.146 +- 0.346 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 2 = 0.168 +- 0.346 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all KL = 0.234 +- 0.346 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all L1 = 0.154 +- 0.235 (in-sample avg dev_std = 0.363)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 548
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.678
NEC for r=0.9 class 0 = 0.099 +- 0.252 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 1 = 0.105 +- 0.252 (in-sample avg dev_std = 0.270)
NEC for r=0.9 class 2 = 0.111 +- 0.252 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all KL = 0.13 +- 0.252 (in-sample avg dev_std = 0.270)
NEC for r=0.9 all L1 = 0.105 +- 0.190 (in-sample avg dev_std = 0.270)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.693
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 548
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.679
NEC for r=1.0 class 0 = 0.088 +- 0.238 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 1 = 0.092 +- 0.238 (in-sample avg dev_std = 0.246)
NEC for r=1.0 class 2 = 0.114 +- 0.238 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all KL = 0.114 +- 0.238 (in-sample avg dev_std = 0.246)
NEC for r=1.0 all L1 = 0.097 +- 0.184 (in-sample avg dev_std = 0.246)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.558
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.312 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.558
NEC for r=0.3 class 0 = 0.292 +- 0.409 (in-sample avg dev_std = 0.463)
NEC for r=0.3 class 1 = 0.29 +- 0.409 (in-sample avg dev_std = 0.463)
NEC for r=0.3 class 2 = 0.326 +- 0.409 (in-sample avg dev_std = 0.463)
NEC for r=0.3 all KL = 0.434 +- 0.409 (in-sample avg dev_std = 0.463)
NEC for r=0.3 all L1 = 0.298 +- 0.302 (in-sample avg dev_std = 0.463)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.594
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.612 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.585
NEC for r=0.6 class 0 = 0.149 +- 0.340 (in-sample avg dev_std = 0.361)
NEC for r=0.6 class 1 = 0.206 +- 0.340 (in-sample avg dev_std = 0.361)
NEC for r=0.6 class 2 = 0.221 +- 0.340 (in-sample avg dev_std = 0.361)
NEC for r=0.6 all KL = 0.261 +- 0.340 (in-sample avg dev_std = 0.361)
NEC for r=0.6 all L1 = 0.195 +- 0.251 (in-sample avg dev_std = 0.361)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.604
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.909 +- 0.006
Model Accuracy over intervened graphs for r=0.9 =  0.598
NEC for r=0.9 class 0 = 0.106 +- 0.266 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 1 = 0.137 +- 0.266 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 2 = 0.154 +- 0.266 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all KL = 0.156 +- 0.266 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all L1 = 0.133 +- 0.210 (in-sample avg dev_std = 0.273)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.606
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.599
NEC for r=1.0 class 0 = 0.107 +- 0.258 (in-sample avg dev_std = 0.265)
NEC for r=1.0 class 1 = 0.121 +- 0.258 (in-sample avg dev_std = 0.265)
NEC for r=1.0 class 2 = 0.149 +- 0.258 (in-sample avg dev_std = 0.265)
NEC for r=1.0 all KL = 0.144 +- 0.258 (in-sample avg dev_std = 0.265)
NEC for r=1.0 all L1 = 0.123 +- 0.204 (in-sample avg dev_std = 0.265)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.519
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.516
NEC for r=0.3 class 0 = 0.294 +- 0.399 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 1 = 0.318 +- 0.399 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 2 = 0.328 +- 0.399 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all KL = 0.461 +- 0.399 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all L1 = 0.314 +- 0.295 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.524
NEC for r=0.6 class 0 = 0.148 +- 0.324 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 1 = 0.206 +- 0.324 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 2 = 0.207 +- 0.324 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all KL = 0.261 +- 0.324 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all L1 = 0.192 +- 0.247 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.525
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.103 +- 0.271 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 1 = 0.146 +- 0.271 (in-sample avg dev_std = 0.274)
NEC for r=0.9 class 2 = 0.152 +- 0.271 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all KL = 0.162 +- 0.271 (in-sample avg dev_std = 0.274)
NEC for r=0.9 all L1 = 0.136 +- 0.217 (in-sample avg dev_std = 0.274)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.526
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.527
NEC for r=1.0 class 0 = 0.087 +- 0.248 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 1 = 0.132 +- 0.248 (in-sample avg dev_std = 0.257)
NEC for r=1.0 class 2 = 0.129 +- 0.248 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all KL = 0.135 +- 0.248 (in-sample avg dev_std = 0.257)
NEC for r=1.0 all L1 = 0.12 +- 0.202 (in-sample avg dev_std = 0.257)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.477, 0.713, 0.914, 1.0], 'all_L1': [0.709, 0.805, 0.903, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.813, 0.83, 0.947, 1.0], 'all_L1': [0.698, 0.745, 0.872, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.8, 0.816, 0.947, 1.0], 'all_L1': [0.701, 0.753, 0.884, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.308, 0.454, 0.835, 1.0], 'all_L1': [0.608, 0.716, 0.875, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.391, 0.633, 0.878, 1.0], 'all_L1': [0.707, 0.808, 0.905, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.309, 0.178, 0.093, 0.074], 'all_L1': [0.231, 0.152, 0.109, 0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.112, 0.083, 0.046, 0.039], 'all_L1': [0.24, 0.178, 0.119, 0.102]}), defaultdict(<class 'list'>, {'all_KL': [0.11, 0.092, 0.053, 0.041], 'all_L1': [0.227, 0.177, 0.122, 0.1]}), defaultdict(<class 'list'>, {'all_KL': [0.438, 0.271, 0.136, 0.118], 'all_L1': [0.318, 0.193, 0.119, 0.105]}), defaultdict(<class 'list'>, {'all_KL': [0.351, 0.234, 0.13, 0.114], 'all_L1': [0.227, 0.154, 0.105, 0.097]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.466, 0.677, 0.911, 1.0], 'all_L1': [0.657, 0.747, 0.877, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.855, 0.878, 0.933, 1.0], 'all_L1': [0.728, 0.785, 0.855, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.772, 0.801, 0.926, 1.0], 'all_L1': [0.687, 0.744, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.302, 0.47, 0.814, 1.0], 'all_L1': [0.564, 0.689, 0.856, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.349, 0.654, 0.904, 1.0], 'all_L1': [0.649, 0.784, 0.9, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.42, 0.227, 0.113, 0.099], 'all_L1': [0.311, 0.213, 0.142, 0.13]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.074, 0.053, 0.045], 'all_L1': [0.238, 0.171, 0.127, 0.11]}), defaultdict(<class 'list'>, {'all_KL': [0.142, 0.103, 0.068, 0.053], 'all_L1': [0.249, 0.185, 0.134, 0.113]}), defaultdict(<class 'list'>, {'all_KL': [0.518, 0.301, 0.151, 0.132], 'all_L1': [0.373, 0.226, 0.131, 0.119]}), defaultdict(<class 'list'>, {'all_KL': [0.434, 0.261, 0.156, 0.144], 'all_L1': [0.298, 0.195, 0.133, 0.123]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.5, 0.716, 0.92, 1.0], 'all_L1': [0.672, 0.769, 0.885, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.877, 0.886, 0.934, 1.0], 'all_L1': [0.751, 0.794, 0.856, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.796, 0.843, 0.921, 1.0], 'all_L1': [0.703, 0.77, 0.852, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.261, 0.413, 0.792, 1.0], 'all_L1': [0.554, 0.67, 0.843, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.329, 0.638, 0.903, 1.0], 'all_L1': [0.632, 0.778, 0.905, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.349, 0.175, 0.092, 0.079], 'all_L1': [0.277, 0.183, 0.128, 0.112]}), defaultdict(<class 'list'>, {'all_KL': [0.09, 0.075, 0.057, 0.054], 'all_L1': [0.218, 0.168, 0.129, 0.118]}), defaultdict(<class 'list'>, {'all_KL': [0.129, 0.095, 0.064, 0.061], 'all_L1': [0.237, 0.179, 0.129, 0.116]}), defaultdict(<class 'list'>, {'all_KL': [0.497, 0.305, 0.164, 0.144], 'all_L1': [0.352, 0.232, 0.14, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.461, 0.261, 0.162, 0.135], 'all_L1': [0.314, 0.192, 0.136, 0.12]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.685 +- 0.039, 0.765 +- 0.036, 0.888 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.558 +- 0.210, 0.689 +- 0.138, 0.904 +- 0.043, 1.000 +- 0.000
suff++_acc_int  =  0.588 +- 0.022, 0.639 +- 0.011, 0.676 +- 0.011
nec class all_L1  =  0.249 +- 0.035, 0.171 +- 0.016, 0.115 +- 0.007, 0.100 +- 0.004
nec class all_KL  =  0.264 +- 0.132, 0.172 +- 0.075, 0.092 +- 0.037, 0.077 +- 0.034
nec_acc_int  =  0.627 +- 0.023, 0.656 +- 0.014, 0.674 +- 0.011, 0.680 +- 0.015

Eval split val
suff++ class all_L1  =  0.657 +- 0.054, 0.750 +- 0.035, 0.869 +- 0.018, 1.000 +- 0.000
suff++ class all_KL  =  0.549 +- 0.224, 0.696 +- 0.140, 0.898 +- 0.043, 1.000 +- 0.000
suff++_acc_int  =  0.543 +- 0.040, 0.582 +- 0.026, 0.609 +- 0.017
nec class all_L1  =  0.294 +- 0.048, 0.198 +- 0.020, 0.133 +- 0.005, 0.119 +- 0.007
nec class all_KL  =  0.323 +- 0.168, 0.193 +- 0.089, 0.108 +- 0.042, 0.095 +- 0.040
nec_acc_int  =  0.566 +- 0.037, 0.599 +- 0.027, 0.607 +- 0.023, 0.608 +- 0.021

Eval split test
suff++ class all_L1  =  0.662 +- 0.067, 0.756 +- 0.044, 0.868 +- 0.023, 1.000 +- 0.000
suff++ class all_KL  =  0.553 +- 0.246, 0.699 +- 0.168, 0.894 +- 0.052, 1.000 +- 0.000
suff++_acc_int  =  0.496 +- 0.043, 0.528 +- 0.030, 0.547 +- 0.024
nec class all_L1  =  0.280 +- 0.049, 0.191 +- 0.022, 0.132 +- 0.005, 0.118 +- 0.004
nec class all_KL  =  0.305 +- 0.168, 0.182 +- 0.090, 0.108 +- 0.047, 0.095 +- 0.038
nec_acc_int  =  0.526 +- 0.036, 0.544 +- 0.027, 0.550 +- 0.027, 0.551 +- 0.022


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.467 +- 0.003, 0.468 +- 0.010, 0.501 +- 0.004, 0.550 +- 0.002
Faith. Armon (L1)= 		  =  0.362 +- 0.028, 0.278 +- 0.018, 0.203 +- 0.010, 0.181 +- 0.006
Faith. GMean (L1)= 	  =  0.411 +- 0.015, 0.361 +- 0.008, 0.319 +- 0.007, 0.316 +- 0.006
Faith. Aritm (KL)= 		  =  0.411 +- 0.040, 0.430 +- 0.035, 0.498 +- 0.007, 0.539 +- 0.017
Faith. Armon (KL)= 		  =  0.299 +- 0.085, 0.256 +- 0.083, 0.163 +- 0.061, 0.141 +- 0.059
Faith. GMean (KL)= 	  =  0.344 +- 0.037, 0.326 +- 0.048, 0.280 +- 0.055, 0.271 +- 0.063

Eval split val
Faith. Aritm (L1)= 		  =  0.475 +- 0.007, 0.474 +- 0.011, 0.501 +- 0.010, 0.560 +- 0.004
Faith. Armon (L1)= 		  =  0.401 +- 0.034, 0.312 +- 0.022, 0.231 +- 0.008, 0.213 +- 0.011
Faith. GMean (L1)= 	  =  0.436 +- 0.018, 0.384 +- 0.013, 0.340 +- 0.008, 0.345 +- 0.010
Faith. Aritm (KL)= 		  =  0.436 +- 0.032, 0.445 +- 0.031, 0.503 +- 0.017, 0.547 +- 0.020
Faith. Armon (KL)= 		  =  0.327 +- 0.098, 0.280 +- 0.100, 0.190 +- 0.067, 0.170 +- 0.067
Faith. GMean (KL)= 	  =  0.371 +- 0.051, 0.345 +- 0.062, 0.304 +- 0.058, 0.300 +- 0.068

Eval split test
Faith. Aritm (L1)= 		  =  0.471 +- 0.010, 0.473 +- 0.012, 0.500 +- 0.012, 0.559 +- 0.002
Faith. Armon (L1)= 		  =  0.387 +- 0.036, 0.303 +- 0.023, 0.230 +- 0.007, 0.211 +- 0.007
Faith. GMean (L1)= 	  =  0.426 +- 0.017, 0.378 +- 0.011, 0.339 +- 0.007, 0.344 +- 0.006
Faith. Aritm (KL)= 		  =  0.429 +- 0.039, 0.441 +- 0.043, 0.501 +- 0.018, 0.547 +- 0.019
Faith. Armon (KL)= 		  =  0.305 +- 0.096, 0.262 +- 0.093, 0.188 +- 0.072, 0.171 +- 0.062
Faith. GMean (KL)= 	  =  0.354 +- 0.049, 0.332 +- 0.054, 0.301 +- 0.061, 0.301 +- 0.061
Computed for split load_split = id



Completed in  0:22:59.694889  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length anneal

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:28:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:06 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:18 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:20 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:22 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:25 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:28:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ACCURACY: 0.9111
Train Loss: 0.5325
ID Validation ACCURACY: 0.9180
ID Validation Loss: 0.5243
ID Test ACCURACY: 0.9120
ID Test Loss: 0.5345
OOD Validation ACCURACY: 0.8440
OOD Validation Loss: 0.8130
OOD Test ACCURACY: 0.6297
OOD Test Loss: 1.0305

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ACCURACY: 0.9116
Train Loss: 0.5407
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.5415
ID Test ACCURACY: 0.9137
ID Test Loss: 0.5422
OOD Validation ACCURACY: 0.9047
OOD Validation Loss: 0.7690
OOD Test ACCURACY: 0.7100
OOD Test Loss: 0.9949

[0m[1;37mINFO[0m: [1mChartInfo 0.9120 0.6297 0.9137 0.7100 0.9127 0.9047[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.676
WIoU for r=0.3 = 0.657
F1 for r=0.6 = 0.624
WIoU for r=0.6 = 0.758
F1 for r=0.9 = 0.510
WIoU for r=0.9 = 0.764
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.763
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.540
WIoU for r=0.3 = 0.698
F1 for r=0.6 = 0.343
WIoU for r=0.6 = 0.697
F1 for r=0.9 = 0.255
WIoU for r=0.9 = 0.696
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.696
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.306
WIoU for r=0.3 = 0.564
F1 for r=0.6 = 0.174
WIoU for r=0.6 = 0.563
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.563
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.563


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.504
Model XAI F1 of binarized graphs for r=0.3 =  0.6760725
Model XAI WIoU of binarized graphs for r=0.3 =  0.6573875
len(reference) = 790
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.409
SUFF++ for r=0.3 class 0 = 0.537 +- 0.262 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.3 class 1 = 0.532 +- 0.262 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.3 class 2 = 0.533 +- 0.262 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.3 all KL = 0.512 +- 0.262 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.3 all L1 = 0.534 +- 0.164 (in-sample avg dev_std = 0.558)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  0.6243962499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7577562499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.646
SUFF++ for r=0.6 class 0 = 0.585 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 1 = 0.6 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 class 2 = 0.576 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all KL = 0.646 +- 0.266 (in-sample avg dev_std = 0.450)
SUFF++ for r=0.6 all L1 = 0.587 +- 0.201 (in-sample avg dev_std = 0.450)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.50976
Model XAI WIoU of binarized graphs for r=0.9 =  0.76363
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0 = 0.8 +- 0.220 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.822 +- 0.220 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.796 +- 0.220 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.883 +- 0.220 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.806 +- 0.204 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.811
Model XAI F1 of binarized graphs for r=0.3 =  0.5402
Model XAI WIoU of binarized graphs for r=0.3 =  0.6983737500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0 = 0.588 +- 0.229 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 1 = 0.598 +- 0.229 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 class 2 = 0.498 +- 0.229 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 all KL = 0.641 +- 0.229 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.3 all L1 = 0.562 +- 0.178 (in-sample avg dev_std = 0.471)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.3434625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6969425
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0 = 0.608 +- 0.194 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 class 1 = 0.719 +- 0.194 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 class 2 = 0.571 +- 0.194 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all KL = 0.755 +- 0.194 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.6 all L1 = 0.633 +- 0.188 (in-sample avg dev_std = 0.405)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.25533125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6956950000000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.739
SUFF++ for r=0.9 class 0 = 0.816 +- 0.120 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.867 +- 0.120 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.796 +- 0.120 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.928 +- 0.120 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.827 +- 0.163 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  0.30574124999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.5635112499999999
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.505
SUFF++ for r=0.3 class 0 = 0.524 +- 0.229 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 1 = 0.553 +- 0.229 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 2 = 0.494 +- 0.229 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all KL = 0.597 +- 0.229 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.187 (in-sample avg dev_std = 0.460)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.61
Model XAI F1 of binarized graphs for r=0.6 =  0.1740825
Model XAI WIoU of binarized graphs for r=0.6 =  0.5631324999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.498
SUFF++ for r=0.6 class 0 = 0.642 +- 0.126 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 1 = 0.614 +- 0.126 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 class 2 = 0.603 +- 0.126 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all KL = 0.784 +- 0.126 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.6 all L1 = 0.62 +- 0.155 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  0.12087375000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.56311375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.515
SUFF++ for r=0.9 class 0 = 0.783 +- 0.086 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 class 1 = 0.749 +- 0.086 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 class 2 = 0.759 +- 0.086 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all KL = 0.914 +- 0.086 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.9 all L1 = 0.764 +- 0.145 (in-sample avg dev_std = 0.211)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.499
Model XAI F1 of binarized graphs for r=0.3 =  0.6760725
Model XAI WIoU of binarized graphs for r=0.3 =  0.6573875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.387
NEC for r=0.3 class 0 = 0.513 +- 0.318 (in-sample avg dev_std = 0.363)
NEC for r=0.3 class 1 = 0.47 +- 0.318 (in-sample avg dev_std = 0.363)
NEC for r=0.3 class 2 = 0.54 +- 0.318 (in-sample avg dev_std = 0.363)
NEC for r=0.3 all KL = 0.494 +- 0.318 (in-sample avg dev_std = 0.363)
NEC for r=0.3 all L1 = 0.508 +- 0.197 (in-sample avg dev_std = 0.363)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  0.6243962499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7577562499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.475
NEC for r=0.6 class 0 = 0.549 +- 0.304 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 1 = 0.335 +- 0.304 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 2 = 0.551 +- 0.304 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all KL = 0.407 +- 0.304 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all L1 = 0.48 +- 0.219 (in-sample avg dev_std = 0.357)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.50976
Model XAI WIoU of binarized graphs for r=0.9 =  0.76363
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.569
NEC for r=0.9 class 0 = 0.487 +- 0.286 (in-sample avg dev_std = 0.320)
NEC for r=0.9 class 1 = 0.238 +- 0.286 (in-sample avg dev_std = 0.320)
NEC for r=0.9 class 2 = 0.496 +- 0.286 (in-sample avg dev_std = 0.320)
NEC for r=0.9 all KL = 0.299 +- 0.286 (in-sample avg dev_std = 0.320)
NEC for r=0.9 all L1 = 0.409 +- 0.230 (in-sample avg dev_std = 0.320)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.916
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.762765
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.574
NEC for r=1.0 class 0 = 0.467 +- 0.269 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 1 = 0.232 +- 0.269 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 2 = 0.474 +- 0.269 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all KL = 0.275 +- 0.269 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all L1 = 0.393 +- 0.224 (in-sample avg dev_std = 0.319)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.81
Model XAI F1 of binarized graphs for r=0.3 =  0.5402
Model XAI WIoU of binarized graphs for r=0.3 =  0.6983737500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.419
NEC for r=0.3 class 0 = 0.535 +- 0.307 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 1 = 0.245 +- 0.307 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 2 = 0.623 +- 0.307 (in-sample avg dev_std = 0.225)
NEC for r=0.3 all KL = 0.363 +- 0.307 (in-sample avg dev_std = 0.225)
NEC for r=0.3 all L1 = 0.466 +- 0.233 (in-sample avg dev_std = 0.225)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.3434625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6969425
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.513
NEC for r=0.6 class 0 = 0.374 +- 0.227 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.161 +- 0.227 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.455 +- 0.227 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.188 +- 0.227 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.329 +- 0.229 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  0.25533125
Model XAI WIoU of binarized graphs for r=0.9 =  0.6956950000000001
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.568
NEC for r=0.9 class 0 = 0.288 +- 0.169 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 1 = 0.134 +- 0.169 (in-sample avg dev_std = 0.169)
NEC for r=0.9 class 2 = 0.355 +- 0.169 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all KL = 0.118 +- 0.169 (in-sample avg dev_std = 0.169)
NEC for r=0.9 all L1 = 0.258 +- 0.198 (in-sample avg dev_std = 0.169)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.6955487499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.565
NEC for r=1.0 class 0 = 0.272 +- 0.156 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1 = 0.135 +- 0.156 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 2 = 0.341 +- 0.156 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.107 +- 0.156 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.248 +- 0.191 (in-sample avg dev_std = 0.161)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  0.30574124999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.5635112499999999
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.416
NEC for r=0.3 class 0 = 0.429 +- 0.299 (in-sample avg dev_std = 0.272)
NEC for r=0.3 class 1 = 0.397 +- 0.299 (in-sample avg dev_std = 0.272)
NEC for r=0.3 class 2 = 0.467 +- 0.299 (in-sample avg dev_std = 0.272)
NEC for r=0.3 all KL = 0.34 +- 0.299 (in-sample avg dev_std = 0.272)
NEC for r=0.3 all L1 = 0.43 +- 0.236 (in-sample avg dev_std = 0.272)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  0.1740825
Model XAI WIoU of binarized graphs for r=0.6 =  0.5631324999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.472
NEC for r=0.6 class 0 = 0.252 +- 0.143 (in-sample avg dev_std = 0.162)
NEC for r=0.6 class 1 = 0.273 +- 0.143 (in-sample avg dev_std = 0.162)
NEC for r=0.6 class 2 = 0.3 +- 0.143 (in-sample avg dev_std = 0.162)
NEC for r=0.6 all KL = 0.125 +- 0.143 (in-sample avg dev_std = 0.162)
NEC for r=0.6 all L1 = 0.275 +- 0.198 (in-sample avg dev_std = 0.162)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.613
Model XAI F1 of binarized graphs for r=0.9 =  0.12087375000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.56311375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.496
NEC for r=0.9 class 0 = 0.206 +- 0.097 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 1 = 0.232 +- 0.097 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 2 = 0.246 +- 0.097 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all KL = 0.078 +- 0.097 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all L1 = 0.228 +- 0.172 (in-sample avg dev_std = 0.116)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.615
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.5631125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.494
NEC for r=1.0 class 0 = 0.196 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=1.0 class 1 = 0.225 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=1.0 class 2 = 0.237 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all KL = 0.07 +- 0.089 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all L1 = 0.219 +- 0.165 (in-sample avg dev_std = 0.106)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:34:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 09:34:34 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:34:48 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:34:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:34:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:34:55 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:35:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.9284
Train Loss: 0.3922
ID Validation ACCURACY: 0.9353
ID Validation Loss: 0.3774
ID Test ACCURACY: 0.9303
ID Test Loss: 0.3972
OOD Validation ACCURACY: 0.8450
OOD Validation Loss: 0.6906
OOD Test ACCURACY: 0.4347
OOD Test Loss: 12.9272

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 98...
[0m[1;37mINFO[0m: [1mCheckpoint 98: 
-----------------------------------
Train ACCURACY: 0.9246
Train Loss: 0.3855
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3754
ID Test ACCURACY: 0.9247
ID Test Loss: 0.3899
OOD Validation ACCURACY: 0.9203
OOD Validation Loss: 0.5483
OOD Test ACCURACY: 0.4377
OOD Test Loss: 3.2678

[0m[1;37mINFO[0m: [1mChartInfo 0.9303 0.4347 0.9247 0.4377 0.9303 0.9203[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.667
WIoU for r=0.3 = 0.622
F1 for r=0.6 = 0.626
WIoU for r=0.6 = 0.685
F1 for r=0.9 = 0.517
WIoU for r=0.9 = 0.689
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.689
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.530
WIoU for r=0.3 = 0.590
F1 for r=0.6 = 0.341
WIoU for r=0.6 = 0.557
F1 for r=0.9 = 0.253
WIoU for r=0.9 = 0.556
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.556
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.307
WIoU for r=0.3 = 0.568
F1 for r=0.6 = 0.177
WIoU for r=0.6 = 0.564
F1 for r=0.9 = 0.123
WIoU for r=0.9 = 0.563
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.563


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.532
Model XAI F1 of binarized graphs for r=0.3 =  0.66716125
Model XAI WIoU of binarized graphs for r=0.3 =  0.62238125
len(reference) = 795
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.437
SUFF++ for r=0.3 class 0 = 0.67 +- 0.316 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 1 = 0.82 +- 0.316 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 class 2 = 0.666 +- 0.316 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all KL = 0.673 +- 0.316 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.3 all L1 = 0.718 +- 0.243 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.625815
Model XAI WIoU of binarized graphs for r=0.6 =  0.6853437499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.705
SUFF++ for r=0.6 class 0 = 0.559 +- 0.282 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.6 class 1 = 0.702 +- 0.282 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.6 class 2 = 0.662 +- 0.282 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.6 all KL = 0.623 +- 0.282 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.6 all L1 = 0.64 +- 0.199 (in-sample avg dev_std = 0.506)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.51656
Model XAI WIoU of binarized graphs for r=0.9 =  0.68943625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.848
SUFF++ for r=0.9 class 0 = 0.772 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 1 = 0.794 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 class 2 = 0.845 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all KL = 0.884 +- 0.169 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.9 all L1 = 0.804 +- 0.161 (in-sample avg dev_std = 0.279)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.815
Model XAI F1 of binarized graphs for r=0.3 =  0.530175
Model XAI WIoU of binarized graphs for r=0.3 =  0.590345
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.61
SUFF++ for r=0.3 class 0 = 0.445 +- 0.295 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.3 class 1 = 0.643 +- 0.295 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.3 class 2 = 0.504 +- 0.295 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.3 all KL = 0.521 +- 0.295 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.3 all L1 = 0.53 +- 0.203 (in-sample avg dev_std = 0.513)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.928
Model XAI F1 of binarized graphs for r=0.6 =  0.34062
Model XAI WIoU of binarized graphs for r=0.6 =  0.5569762500000001
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0 = 0.559 +- 0.240 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 1 = 0.622 +- 0.240 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 class 2 = 0.568 +- 0.240 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all KL = 0.677 +- 0.240 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.6 all L1 = 0.583 +- 0.170 (in-sample avg dev_std = 0.420)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.2533125
Model XAI WIoU of binarized graphs for r=0.9 =  0.55637125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.802
SUFF++ for r=0.9 class 0 = 0.721 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1 = 0.77 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 2 = 0.76 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.874 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.75 +- 0.164 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  0.30652999999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.5677075
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.546
SUFF++ for r=0.3 class 0 = 0.567 +- 0.281 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 1 = 0.623 +- 0.281 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 class 2 = 0.558 +- 0.281 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all KL = 0.67 +- 0.281 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.3 all L1 = 0.583 +- 0.201 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.479
Model XAI F1 of binarized graphs for r=0.6 =  0.176725
Model XAI WIoU of binarized graphs for r=0.6 =  0.56403125
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.524
SUFF++ for r=0.6 class 0 = 0.606 +- 0.275 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 class 1 = 0.664 +- 0.275 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 class 2 = 0.602 +- 0.275 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 all KL = 0.741 +- 0.275 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 all L1 = 0.625 +- 0.196 (in-sample avg dev_std = 0.305)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.425
Model XAI F1 of binarized graphs for r=0.9 =  0.12324625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.5627775
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.478
SUFF++ for r=0.9 class 0 = 0.755 +- 0.334 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 class 1 = 0.782 +- 0.334 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 class 2 = 0.751 +- 0.334 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 all KL = 0.832 +- 0.334 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.225 (in-sample avg dev_std = 0.192)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.529
Model XAI F1 of binarized graphs for r=0.3 =  0.66716125
Model XAI WIoU of binarized graphs for r=0.3 =  0.62238125
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.362
NEC for r=0.3 class 0 = 0.371 +- 0.373 (in-sample avg dev_std = 0.355)
NEC for r=0.3 class 1 = 0.296 +- 0.373 (in-sample avg dev_std = 0.355)
NEC for r=0.3 class 2 = 0.423 +- 0.373 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all KL = 0.4 +- 0.373 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all L1 = 0.364 +- 0.292 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.625815
Model XAI WIoU of binarized graphs for r=0.6 =  0.6853437499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.448
NEC for r=0.6 class 0 = 0.628 +- 0.337 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 1 = 0.337 +- 0.337 (in-sample avg dev_std = 0.511)
NEC for r=0.6 class 2 = 0.657 +- 0.337 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all KL = 0.579 +- 0.337 (in-sample avg dev_std = 0.511)
NEC for r=0.6 all L1 = 0.544 +- 0.234 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.51656
Model XAI WIoU of binarized graphs for r=0.9 =  0.68943625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.568 +- 0.293 (in-sample avg dev_std = 0.495)
NEC for r=0.9 class 1 = 0.313 +- 0.293 (in-sample avg dev_std = 0.495)
NEC for r=0.9 class 2 = 0.593 +- 0.293 (in-sample avg dev_std = 0.495)
NEC for r=0.9 all KL = 0.457 +- 0.293 (in-sample avg dev_std = 0.495)
NEC for r=0.9 all L1 = 0.494 +- 0.205 (in-sample avg dev_std = 0.495)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.68926
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0 = 0.55 +- 0.280 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 1 = 0.304 +- 0.280 (in-sample avg dev_std = 0.471)
NEC for r=1.0 class 2 = 0.57 +- 0.280 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all KL = 0.416 +- 0.280 (in-sample avg dev_std = 0.471)
NEC for r=1.0 all L1 = 0.477 +- 0.205 (in-sample avg dev_std = 0.471)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.815
Model XAI F1 of binarized graphs for r=0.3 =  0.530175
Model XAI WIoU of binarized graphs for r=0.3 =  0.590345
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.388
NEC for r=0.3 class 0 = 0.686 +- 0.361 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 1 = 0.314 +- 0.361 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 2 = 0.704 +- 0.361 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all KL = 0.557 +- 0.361 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all L1 = 0.567 +- 0.261 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.928
Model XAI F1 of binarized graphs for r=0.6 =  0.34062
Model XAI WIoU of binarized graphs for r=0.6 =  0.5569762500000001
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.46
NEC for r=0.6 class 0 = 0.601 +- 0.347 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 1 = 0.267 +- 0.347 (in-sample avg dev_std = 0.356)
NEC for r=0.6 class 2 = 0.618 +- 0.347 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all KL = 0.418 +- 0.347 (in-sample avg dev_std = 0.356)
NEC for r=0.6 all L1 = 0.494 +- 0.242 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  0.2533125
Model XAI WIoU of binarized graphs for r=0.9 =  0.55637125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.49
NEC for r=0.9 class 0 = 0.509 +- 0.286 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 1 = 0.218 +- 0.286 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 2 = 0.509 +- 0.286 (in-sample avg dev_std = 0.284)
NEC for r=0.9 all KL = 0.286 +- 0.286 (in-sample avg dev_std = 0.284)
NEC for r=0.9 all L1 = 0.411 +- 0.226 (in-sample avg dev_std = 0.284)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.871
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.5563525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.491
NEC for r=1.0 class 0 = 0.483 +- 0.262 (in-sample avg dev_std = 0.282)
NEC for r=1.0 class 1 = 0.213 +- 0.262 (in-sample avg dev_std = 0.282)
NEC for r=1.0 class 2 = 0.489 +- 0.262 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all KL = 0.258 +- 0.262 (in-sample avg dev_std = 0.282)
NEC for r=1.0 all L1 = 0.394 +- 0.215 (in-sample avg dev_std = 0.282)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  0.30652999999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.5677075
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.435 +- 0.361 (in-sample avg dev_std = 0.136)
NEC for r=0.3 class 1 = 0.34 +- 0.361 (in-sample avg dev_std = 0.136)
NEC for r=0.3 class 2 = 0.498 +- 0.361 (in-sample avg dev_std = 0.136)
NEC for r=0.3 all KL = 0.327 +- 0.361 (in-sample avg dev_std = 0.136)
NEC for r=0.3 all L1 = 0.423 +- 0.263 (in-sample avg dev_std = 0.136)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.477
Model XAI F1 of binarized graphs for r=0.6 =  0.176725
Model XAI WIoU of binarized graphs for r=0.6 =  0.56403125
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.384
NEC for r=0.6 class 0 = 0.346 +- 0.335 (in-sample avg dev_std = 0.190)
NEC for r=0.6 class 1 = 0.265 +- 0.335 (in-sample avg dev_std = 0.190)
NEC for r=0.6 class 2 = 0.38 +- 0.335 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all KL = 0.248 +- 0.335 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all L1 = 0.329 +- 0.269 (in-sample avg dev_std = 0.190)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.424
Model XAI F1 of binarized graphs for r=0.9 =  0.12324625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.5627775
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.384
NEC for r=0.9 class 0 = 0.302 +- 0.338 (in-sample avg dev_std = 0.153)
NEC for r=0.9 class 1 = 0.222 +- 0.338 (in-sample avg dev_std = 0.153)
NEC for r=0.9 class 2 = 0.333 +- 0.338 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all KL = 0.207 +- 0.338 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all L1 = 0.285 +- 0.256 (in-sample avg dev_std = 0.153)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.431
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.56255625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.381
NEC for r=1.0 class 0 = 0.287 +- 0.336 (in-sample avg dev_std = 0.139)
NEC for r=1.0 class 1 = 0.216 +- 0.336 (in-sample avg dev_std = 0.139)
NEC for r=1.0 class 2 = 0.316 +- 0.336 (in-sample avg dev_std = 0.139)
NEC for r=1.0 all KL = 0.194 +- 0.336 (in-sample avg dev_std = 0.139)
NEC for r=1.0 all L1 = 0.272 +- 0.249 (in-sample avg dev_std = 0.139)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:41:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:08 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:21 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:23 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:34 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:41:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 195...
[0m[1;37mINFO[0m: [1mCheckpoint 195: 
-----------------------------------
Train ACCURACY: 0.9298
Train Loss: 0.4066
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3965
ID Test ACCURACY: 0.9320
ID Test Loss: 0.4064
OOD Validation ACCURACY: 0.9110
OOD Validation Loss: 0.5855
OOD Test ACCURACY: 0.5410
OOD Test Loss: 1.9081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9216
Train Loss: 0.4124
ID Validation ACCURACY: 0.9270
ID Validation Loss: 0.3986
ID Test ACCURACY: 0.9253
ID Test Loss: 0.4168
OOD Validation ACCURACY: 0.9197
OOD Validation Loss: 0.5799
OOD Test ACCURACY: 0.7763
OOD Test Loss: 0.9148

[0m[1;37mINFO[0m: [1mChartInfo 0.9320 0.5410 0.9253 0.7763 0.9270 0.9197[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.695
WIoU for r=0.3 = 0.674
F1 for r=0.6 = 0.618
WIoU for r=0.6 = 0.774
F1 for r=0.9 = 0.508
WIoU for r=0.9 = 0.779
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.779
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.549
WIoU for r=0.3 = 0.675
F1 for r=0.6 = 0.345
WIoU for r=0.6 = 0.651
F1 for r=0.9 = 0.251
WIoU for r=0.9 = 0.651
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.651
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.314
WIoU for r=0.3 = 0.352
F1 for r=0.6 = 0.177
WIoU for r=0.6 = 0.322
F1 for r=0.9 = 0.123
WIoU for r=0.9 = 0.321
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.321


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.566
Model XAI F1 of binarized graphs for r=0.3 =  0.6953475
Model XAI WIoU of binarized graphs for r=0.3 =  0.673655
len(reference) = 797
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.476
SUFF++ for r=0.3 class 0 = 0.659 +- 0.300 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 1 = 0.769 +- 0.300 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 class 2 = 0.641 +- 0.300 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all KL = 0.645 +- 0.300 (in-sample avg dev_std = 0.537)
SUFF++ for r=0.3 all L1 = 0.689 +- 0.220 (in-sample avg dev_std = 0.537)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.618495
Model XAI WIoU of binarized graphs for r=0.6 =  0.7736762500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.744
SUFF++ for r=0.6 class 0 = 0.637 +- 0.266 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 class 1 = 0.666 +- 0.266 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 class 2 = 0.703 +- 0.266 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 all KL = 0.68 +- 0.266 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.6 all L1 = 0.669 +- 0.189 (in-sample avg dev_std = 0.493)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.50812125
Model XAI WIoU of binarized graphs for r=0.9 =  0.779015
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.849
SUFF++ for r=0.9 class 0 = 0.81 +- 0.184 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 1 = 0.757 +- 0.184 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 class 2 = 0.854 +- 0.184 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all KL = 0.886 +- 0.184 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.173 (in-sample avg dev_std = 0.272)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.5493124999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6754425000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.676
SUFF++ for r=0.3 class 0 = 0.503 +- 0.299 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 1 = 0.664 +- 0.299 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 2 = 0.497 +- 0.299 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all KL = 0.53 +- 0.299 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all L1 = 0.555 +- 0.209 (in-sample avg dev_std = 0.567)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.94
Model XAI F1 of binarized graphs for r=0.6 =  0.34542500000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.65105625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.752
SUFF++ for r=0.6 class 0 = 0.648 +- 0.191 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 1 = 0.608 +- 0.191 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 2 = 0.664 +- 0.191 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all KL = 0.74 +- 0.191 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all L1 = 0.639 +- 0.170 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.25093000000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.6507412499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0 = 0.767 +- 0.132 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 class 1 = 0.75 +- 0.132 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 class 2 = 0.814 +- 0.132 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 all KL = 0.901 +- 0.132 (in-sample avg dev_std = 0.215)
SUFF++ for r=0.9 all L1 = 0.776 +- 0.165 (in-sample avg dev_std = 0.215)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.707
Model XAI F1 of binarized graphs for r=0.3 =  0.3137475
Model XAI WIoU of binarized graphs for r=0.3 =  0.3516975
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.575
SUFF++ for r=0.3 class 0 = 0.512 +- 0.272 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 1 = 0.467 +- 0.272 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 class 2 = 0.504 +- 0.272 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 all KL = 0.459 +- 0.272 (in-sample avg dev_std = 0.546)
SUFF++ for r=0.3 all L1 = 0.494 +- 0.173 (in-sample avg dev_std = 0.546)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  0.17720875
Model XAI WIoU of binarized graphs for r=0.6 =  0.32159750000000004
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.621
SUFF++ for r=0.6 class 0 = 0.588 +- 0.297 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 class 1 = 0.526 +- 0.297 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 class 2 = 0.561 +- 0.297 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 all KL = 0.601 +- 0.297 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.6 all L1 = 0.558 +- 0.200 (in-sample avg dev_std = 0.439)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.574
Model XAI F1 of binarized graphs for r=0.9 =  0.12287000000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.32060249999999996
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.6
SUFF++ for r=0.9 class 0 = 0.642 +- 0.337 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 class 1 = 0.621 +- 0.337 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 class 2 = 0.652 +- 0.337 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 all KL = 0.69 +- 0.337 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.9 all L1 = 0.638 +- 0.221 (in-sample avg dev_std = 0.444)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.564
Model XAI F1 of binarized graphs for r=0.3 =  0.6953475
Model XAI WIoU of binarized graphs for r=0.3 =  0.673655
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.358
NEC for r=0.3 class 0 = 0.398 +- 0.353 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 1 = 0.315 +- 0.353 (in-sample avg dev_std = 0.425)
NEC for r=0.3 class 2 = 0.482 +- 0.353 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all KL = 0.419 +- 0.353 (in-sample avg dev_std = 0.425)
NEC for r=0.3 all L1 = 0.399 +- 0.280 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.879
Model XAI F1 of binarized graphs for r=0.6 =  0.618495
Model XAI WIoU of binarized graphs for r=0.6 =  0.7736762500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.457
NEC for r=0.6 class 0 = 0.639 +- 0.308 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 1 = 0.398 +- 0.308 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 2 = 0.644 +- 0.308 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all KL = 0.572 +- 0.308 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all L1 = 0.563 +- 0.209 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.50812125
Model XAI WIoU of binarized graphs for r=0.9 =  0.779015
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.542
NEC for r=0.9 class 0 = 0.567 +- 0.275 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 1 = 0.375 +- 0.275 (in-sample avg dev_std = 0.448)
NEC for r=0.9 class 2 = 0.544 +- 0.275 (in-sample avg dev_std = 0.448)
NEC for r=0.9 all KL = 0.428 +- 0.275 (in-sample avg dev_std = 0.448)
NEC for r=0.9 all L1 = 0.497 +- 0.190 (in-sample avg dev_std = 0.448)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.7790187500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.548 +- 0.259 (in-sample avg dev_std = 0.437)
NEC for r=1.0 class 1 = 0.364 +- 0.259 (in-sample avg dev_std = 0.437)
NEC for r=1.0 class 2 = 0.517 +- 0.259 (in-sample avg dev_std = 0.437)
NEC for r=1.0 all KL = 0.39 +- 0.259 (in-sample avg dev_std = 0.437)
NEC for r=1.0 all L1 = 0.478 +- 0.186 (in-sample avg dev_std = 0.437)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.928
Model XAI F1 of binarized graphs for r=0.3 =  0.5493124999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6754425000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.403
NEC for r=0.3 class 0 = 0.749 +- 0.351 (in-sample avg dev_std = 0.352)
NEC for r=0.3 class 1 = 0.276 +- 0.351 (in-sample avg dev_std = 0.352)
NEC for r=0.3 class 2 = 0.718 +- 0.351 (in-sample avg dev_std = 0.352)
NEC for r=0.3 all KL = 0.586 +- 0.351 (in-sample avg dev_std = 0.352)
NEC for r=0.3 all L1 = 0.58 +- 0.271 (in-sample avg dev_std = 0.352)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.94
Model XAI F1 of binarized graphs for r=0.6 =  0.34542500000000004
Model XAI WIoU of binarized graphs for r=0.6 =  0.65105625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.506
NEC for r=0.6 class 0 = 0.598 +- 0.317 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 1 = 0.297 +- 0.317 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 2 = 0.59 +- 0.317 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all KL = 0.409 +- 0.317 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all L1 = 0.494 +- 0.233 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.25093000000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.6507412499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.576
NEC for r=0.9 class 0 = 0.474 +- 0.228 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 1 = 0.282 +- 0.228 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 2 = 0.483 +- 0.228 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all KL = 0.264 +- 0.228 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all L1 = 0.412 +- 0.193 (in-sample avg dev_std = 0.316)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.650735
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.587
NEC for r=1.0 class 0 = 0.448 +- 0.197 (in-sample avg dev_std = 0.305)
NEC for r=1.0 class 1 = 0.272 +- 0.197 (in-sample avg dev_std = 0.305)
NEC for r=1.0 class 2 = 0.454 +- 0.197 (in-sample avg dev_std = 0.305)
NEC for r=1.0 all KL = 0.229 +- 0.197 (in-sample avg dev_std = 0.305)
NEC for r=1.0 all L1 = 0.391 +- 0.176 (in-sample avg dev_std = 0.305)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.704
Model XAI F1 of binarized graphs for r=0.3 =  0.3137475
Model XAI WIoU of binarized graphs for r=0.3 =  0.3516975
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.367
NEC for r=0.3 class 0 = 0.687 +- 0.360 (in-sample avg dev_std = 0.229)
NEC for r=0.3 class 1 = 0.509 +- 0.360 (in-sample avg dev_std = 0.229)
NEC for r=0.3 class 2 = 0.701 +- 0.360 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all KL = 0.657 +- 0.360 (in-sample avg dev_std = 0.229)
NEC for r=0.3 all L1 = 0.63 +- 0.247 (in-sample avg dev_std = 0.229)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  0.17720875
Model XAI WIoU of binarized graphs for r=0.6 =  0.32159750000000004
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.438
NEC for r=0.6 class 0 = 0.436 +- 0.314 (in-sample avg dev_std = 0.289)
NEC for r=0.6 class 1 = 0.389 +- 0.314 (in-sample avg dev_std = 0.289)
NEC for r=0.6 class 2 = 0.491 +- 0.314 (in-sample avg dev_std = 0.289)
NEC for r=0.6 all KL = 0.385 +- 0.314 (in-sample avg dev_std = 0.289)
NEC for r=0.6 all L1 = 0.438 +- 0.251 (in-sample avg dev_std = 0.289)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.574
Model XAI F1 of binarized graphs for r=0.9 =  0.12287000000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.32060249999999996
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.481
NEC for r=0.9 class 0 = 0.384 +- 0.264 (in-sample avg dev_std = 0.252)
NEC for r=0.9 class 1 = 0.343 +- 0.264 (in-sample avg dev_std = 0.252)
NEC for r=0.9 class 2 = 0.408 +- 0.264 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all KL = 0.273 +- 0.264 (in-sample avg dev_std = 0.252)
NEC for r=0.9 all L1 = 0.378 +- 0.226 (in-sample avg dev_std = 0.252)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.566
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.32055999999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.474
NEC for r=1.0 class 0 = 0.365 +- 0.255 (in-sample avg dev_std = 0.236)
NEC for r=1.0 class 1 = 0.328 +- 0.255 (in-sample avg dev_std = 0.236)
NEC for r=1.0 class 2 = 0.4 +- 0.255 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all KL = 0.249 +- 0.255 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all L1 = 0.363 +- 0.218 (in-sample avg dev_std = 0.236)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:47:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 09:47:40 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:47:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:47:53 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:47:55 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:47:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:48:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ACCURACY: 0.9003
Train Loss: 0.5830
ID Validation ACCURACY: 0.9067
ID Validation Loss: 0.5753
ID Test ACCURACY: 0.9023
ID Test Loss: 0.5805
OOD Validation ACCURACY: 0.7500
OOD Validation Loss: 0.8677
OOD Test ACCURACY: 0.5843
OOD Test Loss: 1.9320

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ACCURACY: 0.8668
Train Loss: 0.5434
ID Validation ACCURACY: 0.8773
ID Validation Loss: 0.5371
ID Test ACCURACY: 0.8717
ID Test Loss: 0.5416
OOD Validation ACCURACY: 0.8670
OOD Validation Loss: 0.8220
OOD Test ACCURACY: 0.6743
OOD Test Loss: 1.0398

[0m[1;37mINFO[0m: [1mChartInfo 0.9023 0.5843 0.8717 0.6743 0.8773 0.8670[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.608
WIoU for r=0.3 = 0.622
F1 for r=0.6 = 0.563
WIoU for r=0.6 = 0.719
F1 for r=0.9 = 0.497
WIoU for r=0.9 = 0.725
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.725
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.526
WIoU for r=0.3 = 0.699
F1 for r=0.6 = 0.331
WIoU for r=0.6 = 0.696
F1 for r=0.9 = 0.248
WIoU for r=0.9 = 0.695
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.695
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.284
WIoU for r=0.3 = 0.447
F1 for r=0.6 = 0.167
WIoU for r=0.6 = 0.441
F1 for r=0.9 = 0.118
WIoU for r=0.9 = 0.441
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.441


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.534
Model XAI F1 of binarized graphs for r=0.3 =  0.60778875
Model XAI WIoU of binarized graphs for r=0.3 =  0.62245125
len(reference) = 796
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.436
SUFF++ for r=0.3 class 0 = 0.479 +- 0.257 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 class 1 = 0.561 +- 0.257 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 class 2 = 0.497 +- 0.257 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 all KL = 0.52 +- 0.257 (in-sample avg dev_std = 0.556)
SUFF++ for r=0.3 all L1 = 0.512 +- 0.161 (in-sample avg dev_std = 0.556)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  0.56326
Model XAI WIoU of binarized graphs for r=0.6 =  0.7191875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.689
SUFF++ for r=0.6 class 0 = 0.611 +- 0.251 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1 = 0.643 +- 0.251 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 2 = 0.657 +- 0.251 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.723 +- 0.251 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.637 +- 0.194 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.49726
Model XAI WIoU of binarized graphs for r=0.9 =  0.72494
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.787
SUFF++ for r=0.9 class 0 = 0.747 +- 0.239 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.239 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 2 = 0.805 +- 0.239 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all KL = 0.875 +- 0.239 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all L1 = 0.802 +- 0.220 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  0.52550375
Model XAI WIoU of binarized graphs for r=0.3 =  0.69877375
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.668
SUFF++ for r=0.3 class 0 = 0.585 +- 0.220 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 1 = 0.503 +- 0.220 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 class 2 = 0.605 +- 0.220 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all KL = 0.663 +- 0.220 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.3 all L1 = 0.564 +- 0.170 (in-sample avg dev_std = 0.419)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.33125875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6956987499999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.691
SUFF++ for r=0.6 class 0 = 0.647 +- 0.215 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 class 1 = 0.636 +- 0.215 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.215 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 all KL = 0.783 +- 0.215 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.6 all L1 = 0.652 +- 0.201 (in-sample avg dev_std = 0.310)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.752
Model XAI F1 of binarized graphs for r=0.9 =  0.24841625
Model XAI WIoU of binarized graphs for r=0.9 =  0.6950775
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.7
SUFF++ for r=0.9 class 0 = 0.782 +- 0.237 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1 = 0.759 +- 0.237 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 2 = 0.748 +- 0.237 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.857 +- 0.237 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.245 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.541
Model XAI F1 of binarized graphs for r=0.3 =  0.28353875
Model XAI WIoU of binarized graphs for r=0.3 =  0.44663875000000003
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.527
SUFF++ for r=0.3 class 0 = 0.569 +- 0.184 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 class 1 = 0.568 +- 0.184 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 class 2 = 0.56 +- 0.184 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all KL = 0.678 +- 0.184 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all L1 = 0.566 +- 0.168 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.559
Model XAI F1 of binarized graphs for r=0.6 =  0.1672125
Model XAI WIoU of binarized graphs for r=0.6 =  0.44144125
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.526
SUFF++ for r=0.6 class 0 = 0.659 +- 0.269 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 1 = 0.65 +- 0.269 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 2 = 0.638 +- 0.269 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all KL = 0.712 +- 0.269 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.203 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  0.11787625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.441365
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.563
SUFF++ for r=0.9 class 0 = 0.809 +- 0.217 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.772 +- 0.217 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.806 +- 0.217 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.838 +- 0.217 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.795 +- 0.166 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  0.60778875
Model XAI WIoU of binarized graphs for r=0.3 =  0.62245125
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.386
NEC for r=0.3 class 0 = 0.564 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 1 = 0.333 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.3 class 2 = 0.56 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all KL = 0.447 +- 0.312 (in-sample avg dev_std = 0.350)
NEC for r=0.3 all L1 = 0.488 +- 0.224 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  0.56326
Model XAI WIoU of binarized graphs for r=0.6 =  0.7191875
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.491
NEC for r=0.6 class 0 = 0.524 +- 0.277 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 1 = 0.307 +- 0.277 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 2 = 0.542 +- 0.277 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all KL = 0.375 +- 0.277 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all L1 = 0.46 +- 0.212 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.908
Model XAI F1 of binarized graphs for r=0.9 =  0.49726
Model XAI WIoU of binarized graphs for r=0.9 =  0.72494
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.56
NEC for r=0.9 class 0 = 0.467 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.9 class 1 = 0.199 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.9 class 2 = 0.477 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.9 all KL = 0.283 +- 0.278 (in-sample avg dev_std = 0.332)
NEC for r=0.9 all L1 = 0.384 +- 0.232 (in-sample avg dev_std = 0.332)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.72478375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.575
NEC for r=1.0 class 0 = 0.441 +- 0.267 (in-sample avg dev_std = 0.323)
NEC for r=1.0 class 1 = 0.179 +- 0.267 (in-sample avg dev_std = 0.323)
NEC for r=1.0 class 2 = 0.468 +- 0.267 (in-sample avg dev_std = 0.323)
NEC for r=1.0 all KL = 0.259 +- 0.267 (in-sample avg dev_std = 0.323)
NEC for r=1.0 all L1 = 0.365 +- 0.235 (in-sample avg dev_std = 0.323)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.706
Model XAI F1 of binarized graphs for r=0.3 =  0.52550375
Model XAI WIoU of binarized graphs for r=0.3 =  0.69877375
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.406
NEC for r=0.3 class 0 = 0.563 +- 0.252 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 1 = 0.452 +- 0.252 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 2 = 0.619 +- 0.252 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all KL = 0.439 +- 0.252 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all L1 = 0.544 +- 0.171 (in-sample avg dev_std = 0.290)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  0.33125875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6956987499999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.524
NEC for r=0.6 class 0 = 0.384 +- 0.245 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 1 = 0.335 +- 0.245 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 2 = 0.461 +- 0.245 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all KL = 0.235 +- 0.245 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all L1 = 0.392 +- 0.210 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.752
Model XAI F1 of binarized graphs for r=0.9 =  0.24841625
Model XAI WIoU of binarized graphs for r=0.9 =  0.6950775
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.568
NEC for r=0.9 class 0 = 0.305 +- 0.236 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 1 = 0.272 +- 0.236 (in-sample avg dev_std = 0.170)
NEC for r=0.9 class 2 = 0.363 +- 0.236 (in-sample avg dev_std = 0.170)
NEC for r=0.9 all KL = 0.169 +- 0.236 (in-sample avg dev_std = 0.170)
NEC for r=0.9 all L1 = 0.312 +- 0.221 (in-sample avg dev_std = 0.170)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.754
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.69493375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.562
NEC for r=1.0 class 0 = 0.286 +- 0.238 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1 = 0.264 +- 0.238 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 2 = 0.36 +- 0.238 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.163 +- 0.238 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.302 +- 0.223 (in-sample avg dev_std = 0.161)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.541
Model XAI F1 of binarized graphs for r=0.3 =  0.28353875
Model XAI WIoU of binarized graphs for r=0.3 =  0.44663875000000003
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.374
NEC for r=0.3 class 0 = 0.435 +- 0.257 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 1 = 0.394 +- 0.257 (in-sample avg dev_std = 0.208)
NEC for r=0.3 class 2 = 0.485 +- 0.257 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all KL = 0.294 +- 0.257 (in-sample avg dev_std = 0.208)
NEC for r=0.3 all L1 = 0.437 +- 0.196 (in-sample avg dev_std = 0.208)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.558
Model XAI F1 of binarized graphs for r=0.6 =  0.1672125
Model XAI WIoU of binarized graphs for r=0.6 =  0.44144125
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.417
NEC for r=0.6 class 0 = 0.246 +- 0.179 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1 = 0.23 +- 0.179 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 2 = 0.283 +- 0.179 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.124 +- 0.179 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.252 +- 0.223 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  0.11787625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.441365
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.463
NEC for r=0.9 class 0 = 0.205 +- 0.192 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 1 = 0.217 +- 0.192 (in-sample avg dev_std = 0.155)
NEC for r=0.9 class 2 = 0.237 +- 0.192 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all KL = 0.13 +- 0.192 (in-sample avg dev_std = 0.155)
NEC for r=0.9 all L1 = 0.219 +- 0.208 (in-sample avg dev_std = 0.155)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.561
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.4413525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.464
NEC for r=1.0 class 0 = 0.206 +- 0.192 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 1 = 0.22 +- 0.192 (in-sample avg dev_std = 0.164)
NEC for r=1.0 class 2 = 0.227 +- 0.192 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all KL = 0.136 +- 0.192 (in-sample avg dev_std = 0.164)
NEC for r=1.0 all L1 = 0.217 +- 0.201 (in-sample avg dev_std = 0.164)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 21:53:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 09:53:59 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:19 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 09:54:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 0.9230
Train Loss: 0.5722
ID Validation ACCURACY: 0.9293
ID Validation Loss: 0.5634
ID Test ACCURACY: 0.9263
ID Test Loss: 0.5642
OOD Validation ACCURACY: 0.9113
OOD Validation Loss: 0.7982
OOD Test ACCURACY: 0.6523
OOD Test Loss: 1.0445

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.9141
Train Loss: 0.5796
ID Validation ACCURACY: 0.9187
ID Validation Loss: 0.5766
ID Test ACCURACY: 0.9203
ID Test Loss: 0.5731
OOD Validation ACCURACY: 0.9200
OOD Validation Loss: 0.8081
OOD Test ACCURACY: 0.6997
OOD Test Loss: 1.0229

[0m[1;37mINFO[0m: [1mChartInfo 0.9263 0.6523 0.9203 0.6997 0.9187 0.9200[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.687
WIoU for r=0.3 = 0.671
F1 for r=0.6 = 0.621
WIoU for r=0.6 = 0.769
F1 for r=0.9 = 0.504
WIoU for r=0.9 = 0.774
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.774
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.525
WIoU for r=0.3 = 0.710
F1 for r=0.6 = 0.330
WIoU for r=0.6 = 0.708
F1 for r=0.9 = 0.244
WIoU for r=0.9 = 0.708
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.707
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.290
WIoU for r=0.3 = 0.542
F1 for r=0.6 = 0.168
WIoU for r=0.6 = 0.530
F1 for r=0.9 = 0.117
WIoU for r=0.9 = 0.525
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.524


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  0.6873175
Model XAI WIoU of binarized graphs for r=0.3 =  0.67058
len(reference) = 794
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.43
SUFF++ for r=0.3 class 0 = 0.511 +- 0.272 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 1 = 0.546 +- 0.272 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 class 2 = 0.522 +- 0.272 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 all KL = 0.49 +- 0.272 (in-sample avg dev_std = 0.587)
SUFF++ for r=0.3 all L1 = 0.526 +- 0.170 (in-sample avg dev_std = 0.587)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.855
Model XAI F1 of binarized graphs for r=0.6 =  0.6206425000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7694975
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.66
SUFF++ for r=0.6 class 0 = 0.581 +- 0.291 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 1 = 0.622 +- 0.291 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 2 = 0.584 +- 0.291 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all KL = 0.654 +- 0.291 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all L1 = 0.595 +- 0.214 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.50421
Model XAI WIoU of binarized graphs for r=0.9 =  0.77377125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.793
SUFF++ for r=0.9 class 0 = 0.767 +- 0.261 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 1 = 0.844 +- 0.261 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 2 = 0.768 +- 0.261 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all KL = 0.862 +- 0.261 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.232 (in-sample avg dev_std = 0.241)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.906
Model XAI F1 of binarized graphs for r=0.3 =  0.52452
Model XAI WIoU of binarized graphs for r=0.3 =  0.7097437500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.68
SUFF++ for r=0.3 class 0 = 0.599 +- 0.275 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 1 = 0.651 +- 0.275 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 class 2 = 0.557 +- 0.275 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all KL = 0.675 +- 0.275 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.3 all L1 = 0.603 +- 0.198 (in-sample avg dev_std = 0.438)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.934
Model XAI F1 of binarized graphs for r=0.6 =  0.33032125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7083087499999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.697
SUFF++ for r=0.6 class 0 = 0.633 +- 0.248 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 1 = 0.78 +- 0.248 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 class 2 = 0.626 +- 0.248 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all KL = 0.784 +- 0.248 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.6 all L1 = 0.68 +- 0.223 (in-sample avg dev_std = 0.324)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.24397374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7075387499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.788
SUFF++ for r=0.9 class 0 = 0.813 +- 0.224 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1 = 0.872 +- 0.224 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 2 = 0.769 +- 0.224 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.89 +- 0.224 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.230 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.594
Model XAI F1 of binarized graphs for r=0.3 =  0.28975124999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.54162875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0 = 0.491 +- 0.221 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 1 = 0.595 +- 0.221 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 class 2 = 0.483 +- 0.221 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all KL = 0.619 +- 0.221 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.175 (in-sample avg dev_std = 0.425)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.16798375
Model XAI WIoU of binarized graphs for r=0.6 =  0.5299675
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.504
SUFF++ for r=0.6 class 0 = 0.539 +- 0.224 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 1 = 0.584 +- 0.224 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 class 2 = 0.51 +- 0.224 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all KL = 0.678 +- 0.224 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.6 all L1 = 0.546 +- 0.203 (in-sample avg dev_std = 0.304)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  0.11653750000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.52518375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.58
SUFF++ for r=0.9 class 0 = 0.692 +- 0.226 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1 = 0.722 +- 0.226 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 2 = 0.657 +- 0.226 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.821 +- 0.226 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.691 +- 0.221 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  0.6873175
Model XAI WIoU of binarized graphs for r=0.3 =  0.67058
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.378
NEC for r=0.3 class 0 = 0.578 +- 0.332 (in-sample avg dev_std = 0.381)
NEC for r=0.3 class 1 = 0.377 +- 0.332 (in-sample avg dev_std = 0.381)
NEC for r=0.3 class 2 = 0.557 +- 0.332 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all KL = 0.516 +- 0.332 (in-sample avg dev_std = 0.381)
NEC for r=0.3 all L1 = 0.506 +- 0.234 (in-sample avg dev_std = 0.381)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.855
Model XAI F1 of binarized graphs for r=0.6 =  0.6206425000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.7694975
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.476
NEC for r=0.6 class 0 = 0.564 +- 0.321 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 1 = 0.304 +- 0.321 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 2 = 0.552 +- 0.321 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all KL = 0.406 +- 0.321 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all L1 = 0.476 +- 0.243 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.50421
Model XAI WIoU of binarized graphs for r=0.9 =  0.77377125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.491 +- 0.304 (in-sample avg dev_std = 0.278)
NEC for r=0.9 class 1 = 0.225 +- 0.304 (in-sample avg dev_std = 0.278)
NEC for r=0.9 class 2 = 0.486 +- 0.304 (in-sample avg dev_std = 0.278)
NEC for r=0.9 all KL = 0.302 +- 0.304 (in-sample avg dev_std = 0.278)
NEC for r=0.9 all L1 = 0.403 +- 0.253 (in-sample avg dev_std = 0.278)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.7737225000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.538
NEC for r=1.0 class 0 = 0.467 +- 0.289 (in-sample avg dev_std = 0.265)
NEC for r=1.0 class 1 = 0.218 +- 0.289 (in-sample avg dev_std = 0.265)
NEC for r=1.0 class 2 = 0.471 +- 0.289 (in-sample avg dev_std = 0.265)
NEC for r=1.0 all KL = 0.277 +- 0.289 (in-sample avg dev_std = 0.265)
NEC for r=1.0 all L1 = 0.388 +- 0.250 (in-sample avg dev_std = 0.265)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.906
Model XAI F1 of binarized graphs for r=0.3 =  0.52452
Model XAI WIoU of binarized graphs for r=0.3 =  0.7097437500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.401
NEC for r=0.3 class 0 = 0.598 +- 0.309 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 1 = 0.255 +- 0.309 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 2 = 0.594 +- 0.309 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all KL = 0.385 +- 0.309 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all L1 = 0.481 +- 0.236 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.934
Model XAI F1 of binarized graphs for r=0.6 =  0.33032125
Model XAI WIoU of binarized graphs for r=0.6 =  0.7083087499999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.49
NEC for r=0.6 class 0 = 0.411 +- 0.258 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 1 = 0.173 +- 0.258 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 2 = 0.457 +- 0.258 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all KL = 0.204 +- 0.258 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all L1 = 0.346 +- 0.231 (in-sample avg dev_std = 0.159)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.24397374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7075387499999999
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.555
NEC for r=0.9 class 0 = 0.319 +- 0.245 (in-sample avg dev_std = 0.129)
NEC for r=0.9 class 1 = 0.148 +- 0.245 (in-sample avg dev_std = 0.129)
NEC for r=0.9 class 2 = 0.363 +- 0.245 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all KL = 0.154 +- 0.245 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all L1 = 0.276 +- 0.230 (in-sample avg dev_std = 0.129)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.70747375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.564
NEC for r=1.0 class 0 = 0.299 +- 0.243 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 1 = 0.142 +- 0.243 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 2 = 0.347 +- 0.243 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all KL = 0.146 +- 0.243 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all L1 = 0.262 +- 0.231 (in-sample avg dev_std = 0.122)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  0.28975124999999996
Model XAI WIoU of binarized graphs for r=0.3 =  0.54162875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.487 +- 0.252 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 1 = 0.333 +- 0.252 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 2 = 0.484 +- 0.252 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all KL = 0.307 +- 0.252 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all L1 = 0.433 +- 0.194 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.16798375
Model XAI WIoU of binarized graphs for r=0.6 =  0.5299675
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.468
NEC for r=0.6 class 0 = 0.395 +- 0.240 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1 = 0.299 +- 0.240 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 2 = 0.381 +- 0.240 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.215 +- 0.240 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.358 +- 0.215 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.629
Model XAI F1 of binarized graphs for r=0.9 =  0.11653750000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.52518375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.485
NEC for r=0.9 class 0 = 0.328 +- 0.252 (in-sample avg dev_std = 0.160)
NEC for r=0.9 class 1 = 0.266 +- 0.252 (in-sample avg dev_std = 0.160)
NEC for r=0.9 class 2 = 0.337 +- 0.252 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all KL = 0.184 +- 0.252 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all L1 = 0.31 +- 0.225 (in-sample avg dev_std = 0.160)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.626
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.52439625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.493
NEC for r=1.0 class 0 = 0.318 +- 0.274 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 1 = 0.259 +- 0.274 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 2 = 0.331 +- 0.274 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all KL = 0.188 +- 0.274 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all L1 = 0.302 +- 0.232 (in-sample avg dev_std = 0.142)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.512, 0.646, 0.883, 1.0], 'all_L1': [0.534, 0.587, 0.806, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.673, 0.623, 0.884, 1.0], 'all_L1': [0.718, 0.64, 0.804, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.645, 0.68, 0.886, 1.0], 'all_L1': [0.689, 0.669, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.52, 0.723, 0.875, 1.0], 'all_L1': [0.512, 0.637, 0.802, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.654, 0.862, 1.0], 'all_L1': [0.526, 0.595, 0.792, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.494, 0.407, 0.299, 0.275], 'all_L1': [0.508, 0.48, 0.409, 0.393]}), defaultdict(<class 'list'>, {'all_KL': [0.4, 0.579, 0.457, 0.416], 'all_L1': [0.364, 0.544, 0.494, 0.477]}), defaultdict(<class 'list'>, {'all_KL': [0.419, 0.572, 0.428, 0.39], 'all_L1': [0.399, 0.563, 0.497, 0.478]}), defaultdict(<class 'list'>, {'all_KL': [0.447, 0.375, 0.283, 0.259], 'all_L1': [0.488, 0.46, 0.384, 0.365]}), defaultdict(<class 'list'>, {'all_KL': [0.516, 0.406, 0.302, 0.277], 'all_L1': [0.506, 0.476, 0.403, 0.388]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.641, 0.755, 0.928, 1.0], 'all_L1': [0.562, 0.633, 0.827, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.521, 0.677, 0.874, 1.0], 'all_L1': [0.53, 0.583, 0.75, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.53, 0.74, 0.901, 1.0], 'all_L1': [0.555, 0.639, 0.776, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.663, 0.783, 0.857, 1.0], 'all_L1': [0.564, 0.652, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.675, 0.784, 0.89, 1.0], 'all_L1': [0.603, 0.68, 0.818, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.363, 0.188, 0.118, 0.107], 'all_L1': [0.466, 0.329, 0.258, 0.248]}), defaultdict(<class 'list'>, {'all_KL': [0.557, 0.418, 0.286, 0.258], 'all_L1': [0.567, 0.494, 0.411, 0.394]}), defaultdict(<class 'list'>, {'all_KL': [0.586, 0.409, 0.264, 0.229], 'all_L1': [0.58, 0.494, 0.412, 0.391]}), defaultdict(<class 'list'>, {'all_KL': [0.439, 0.235, 0.169, 0.163], 'all_L1': [0.544, 0.392, 0.312, 0.302]}), defaultdict(<class 'list'>, {'all_KL': [0.385, 0.204, 0.154, 0.146], 'all_L1': [0.481, 0.346, 0.276, 0.262]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.597, 0.784, 0.914, 1.0], 'all_L1': [0.524, 0.62, 0.764, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.67, 0.741, 0.832, 1.0], 'all_L1': [0.583, 0.625, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.459, 0.601, 0.69, 1.0], 'all_L1': [0.494, 0.558, 0.638, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.678, 0.712, 0.838, 1.0], 'all_L1': [0.566, 0.649, 0.795, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.619, 0.678, 0.821, 1.0], 'all_L1': [0.524, 0.546, 0.691, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.34, 0.125, 0.078, 0.07], 'all_L1': [0.43, 0.275, 0.228, 0.219]}), defaultdict(<class 'list'>, {'all_KL': [0.327, 0.248, 0.207, 0.194], 'all_L1': [0.423, 0.329, 0.285, 0.272]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.385, 0.273, 0.249], 'all_L1': [0.63, 0.438, 0.378, 0.363]}), defaultdict(<class 'list'>, {'all_KL': [0.294, 0.124, 0.13, 0.136], 'all_L1': [0.437, 0.252, 0.219, 0.217]}), defaultdict(<class 'list'>, {'all_KL': [0.307, 0.215, 0.184, 0.188], 'all_L1': [0.433, 0.358, 0.31, 0.302]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.596 +- 0.089, 0.626 +- 0.030, 0.802 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.568 +- 0.075, 0.665 +- 0.034, 0.878 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.437 +- 0.022, 0.689 +- 0.034, 0.818 +- 0.027
nec class all_L1  =  0.453 +- 0.060, 0.505 +- 0.041, 0.437 +- 0.048, 0.420 +- 0.048
nec class all_KL  =  0.455 +- 0.044, 0.468 +- 0.089, 0.354 +- 0.073, 0.323 +- 0.066
nec_acc_int  =  0.374 +- 0.012, 0.469 +- 0.015, 0.548 +- 0.014, 0.554 +- 0.017

Eval split val
suff++ class all_L1  =  0.563 +- 0.023, 0.637 +- 0.032, 0.787 +- 0.030, 1.000 +- 0.000
suff++ class all_KL  =  0.606 +- 0.067, 0.748 +- 0.039, 0.890 +- 0.024, 1.000 +- 0.000
suff++_acc_int  =  0.643 +- 0.040, 0.695 +- 0.033, 0.770 +- 0.044
nec class all_L1  =  0.528 +- 0.046, 0.411 +- 0.071, 0.334 +- 0.066, 0.319 +- 0.062
nec class all_KL  =  0.466 +- 0.090, 0.291 +- 0.101, 0.198 +- 0.065, 0.181 +- 0.055
nec_acc_int  =  0.404 +- 0.010, 0.499 +- 0.022, 0.551 +- 0.031, 0.554 +- 0.032

Eval split test
suff++ class all_L1  =  0.538 +- 0.032, 0.600 +- 0.040, 0.730 +- 0.057, 1.000 +- 0.000
suff++ class all_KL  =  0.605 +- 0.079, 0.703 +- 0.062, 0.819 +- 0.072, 1.000 +- 0.000
suff++_acc_int  =  0.536 +- 0.024, 0.535 +- 0.045, 0.547 +- 0.044
nec class all_L1  =  0.471 +- 0.080, 0.330 +- 0.066, 0.284 +- 0.058, 0.275 +- 0.055
nec class all_KL  =  0.385 +- 0.137, 0.219 +- 0.096, 0.174 +- 0.067, 0.167 +- 0.060
nec_acc_int  =  0.378 +- 0.021, 0.436 +- 0.033, 0.462 +- 0.041, 0.461 +- 0.042


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.524 +- 0.016, 0.565 +- 0.033, 0.620 +- 0.026, 0.710 +- 0.024
Faith. Armon (L1)= 		  =  0.505 +- 0.013, 0.558 +- 0.035, 0.565 +- 0.041, 0.590 +- 0.047
Faith. GMean (L1)= 	  =  0.514 +- 0.009, 0.562 +- 0.034, 0.592 +- 0.034, 0.647 +- 0.037
Faith. Aritm (KL)= 		  =  0.512 +- 0.020, 0.567 +- 0.040, 0.616 +- 0.039, 0.662 +- 0.033
Faith. Armon (KL)= 		  =  0.499 +- 0.009, 0.543 +- 0.056, 0.500 +- 0.074, 0.485 +- 0.074
Faith. GMean (KL)= 	  =  0.505 +- 0.014, 0.555 +- 0.048, 0.555 +- 0.059, 0.566 +- 0.057

Eval split val
Faith. Aritm (L1)= 		  =  0.545 +- 0.018, 0.524 +- 0.028, 0.560 +- 0.023, 0.660 +- 0.031
Faith. Armon (L1)= 		  =  0.543 +- 0.020, 0.495 +- 0.046, 0.464 +- 0.060, 0.481 +- 0.071
Faith. GMean (L1)= 	  =  0.544 +- 0.019, 0.509 +- 0.037, 0.509 +- 0.043, 0.562 +- 0.055
Faith. Aritm (KL)= 		  =  0.536 +- 0.020, 0.519 +- 0.037, 0.544 +- 0.031, 0.590 +- 0.028
Faith. Armon (KL)= 		  =  0.515 +- 0.034, 0.406 +- 0.097, 0.319 +- 0.086, 0.302 +- 0.079
Faith. GMean (KL)= 	  =  0.526 +- 0.026, 0.458 +- 0.070, 0.414 +- 0.067, 0.420 +- 0.066

Eval split test
Faith. Aritm (L1)= 		  =  0.504 +- 0.031, 0.465 +- 0.020, 0.507 +- 0.010, 0.637 +- 0.027
Faith. Armon (L1)= 		  =  0.497 +- 0.030, 0.420 +- 0.045, 0.402 +- 0.049, 0.428 +- 0.066
Faith. GMean (L1)= 	  =  0.501 +- 0.030, 0.441 +- 0.032, 0.451 +- 0.029, 0.521 +- 0.052
Faith. Aritm (KL)= 		  =  0.495 +- 0.034, 0.461 +- 0.029, 0.497 +- 0.014, 0.584 +- 0.030
Faith. Armon (KL)= 		  =  0.447 +- 0.048, 0.319 +- 0.098, 0.278 +- 0.086, 0.282 +- 0.091
Faith. GMean (KL)= 	  =  0.470 +- 0.041, 0.380 +- 0.069, 0.367 +- 0.061, 0.401 +- 0.080
Computed for split load_split = id



Completed in  0:32:17.104800  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size topk

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:00:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:00:50 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:04 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:06 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:10 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:01:16 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 108...
[0m[1;37mINFO[0m: [1mCheckpoint 108: 
-----------------------------------
Train ACCURACY: 0.9268
Train Loss: 0.3343
ID Validation ACCURACY: 0.9357
ID Validation Loss: 0.3200
ID Test ACCURACY: 0.9280
ID Test Loss: 0.3315
OOD Validation ACCURACY: 0.8403
OOD Validation Loss: 0.5718
OOD Test ACCURACY: 0.4643
OOD Test Loss: 5.1984

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.9226
Train Loss: 0.3441
ID Validation ACCURACY: 0.9303
ID Validation Loss: 0.3190
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3481
OOD Validation ACCURACY: 0.8803
OOD Validation Loss: 0.4919
OOD Test ACCURACY: 0.4687
OOD Test Loss: 1.3813

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.4643 0.9257 0.4687 0.9303 0.8803[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.434
WIoU for r=0.3 = 0.305
F1 for r=0.6 = 0.495
WIoU for r=0.6 = 0.363
F1 for r=0.9 = 0.496
WIoU for r=0.9 = 0.378
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.381
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.317
WIoU for r=0.3 = 0.286
F1 for r=0.6 = 0.265
WIoU for r=0.6 = 0.273
F1 for r=0.9 = 0.242
WIoU for r=0.9 = 0.269
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.269
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.176
WIoU for r=0.3 = 0.238
F1 for r=0.6 = 0.128
WIoU for r=0.6 = 0.232
F1 for r=0.9 = 0.113
WIoU for r=0.9 = 0.232
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.232


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.749
Model XAI F1 of binarized graphs for r=0.3 =  0.4344175
Model XAI WIoU of binarized graphs for r=0.3 =  0.3053375
len(reference) = 729
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.492
SUFF++ for r=0.3 class 0 = 0.513 +- 0.275 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 class 1 = 0.577 +- 0.275 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 class 2 = 0.347 +- 0.275 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 all KL = 0.415 +- 0.275 (in-sample avg dev_std = 0.616)
SUFF++ for r=0.3 all L1 = 0.478 +- 0.181 (in-sample avg dev_std = 0.616)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.49543374999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.36266875000000004
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.597
SUFF++ for r=0.6 class 0 = 0.576 +- 0.315 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 1 = 0.684 +- 0.315 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 class 2 = 0.45 +- 0.315 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 all KL = 0.515 +- 0.315 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.6 all L1 = 0.568 +- 0.242 (in-sample avg dev_std = 0.578)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.49558
Model XAI WIoU of binarized graphs for r=0.9 =  0.37757624999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.861
SUFF++ for r=0.9 class 0 = 0.847 +- 0.220 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 1 = 0.902 +- 0.220 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 class 2 = 0.831 +- 0.220 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all KL = 0.861 +- 0.220 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.174 (in-sample avg dev_std = 0.348)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.775
Model XAI F1 of binarized graphs for r=0.3 =  0.3170325
Model XAI WIoU of binarized graphs for r=0.3 =  0.28634125
len(reference) = 790
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.455
SUFF++ for r=0.3 class 0 = 0.352 +- 0.278 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 class 1 = 0.577 +- 0.278 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 class 2 = 0.355 +- 0.278 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 all KL = 0.37 +- 0.278 (in-sample avg dev_std = 0.578)
SUFF++ for r=0.3 all L1 = 0.429 +- 0.200 (in-sample avg dev_std = 0.578)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  0.26508125
Model XAI WIoU of binarized graphs for r=0.6 =  0.27251875
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.465
SUFF++ for r=0.6 class 0 = 0.363 +- 0.305 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 1 = 0.625 +- 0.305 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 class 2 = 0.402 +- 0.305 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 all KL = 0.425 +- 0.305 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.6 all L1 = 0.463 +- 0.237 (in-sample avg dev_std = 0.542)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  0.24209875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2694975
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.759
SUFF++ for r=0.9 class 0 = 0.728 +- 0.265 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.9 class 1 = 0.774 +- 0.265 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.9 class 2 = 0.781 +- 0.265 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.9 all KL = 0.779 +- 0.265 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.9 all L1 = 0.761 +- 0.202 (in-sample avg dev_std = 0.391)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.386
Model XAI F1 of binarized graphs for r=0.3 =  0.17606625
Model XAI WIoU of binarized graphs for r=0.3 =  0.23810625000000002
len(reference) = 795
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.323
SUFF++ for r=0.3 class 0 = 0.398 +- 0.231 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 class 1 = 0.411 +- 0.231 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 class 2 = 0.409 +- 0.231 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 all KL = 0.332 +- 0.231 (in-sample avg dev_std = 0.630)
SUFF++ for r=0.3 all L1 = 0.406 +- 0.172 (in-sample avg dev_std = 0.630)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.479
Model XAI F1 of binarized graphs for r=0.6 =  0.12763124999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.23239374999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.329
SUFF++ for r=0.6 class 0 = 0.318 +- 0.242 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 1 = 0.355 +- 0.242 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 class 2 = 0.379 +- 0.242 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 all KL = 0.284 +- 0.242 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.6 all L1 = 0.35 +- 0.174 (in-sample avg dev_std = 0.586)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.479
Model XAI F1 of binarized graphs for r=0.9 =  0.11305749999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.231585
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.451
SUFF++ for r=0.9 class 0 = 0.619 +- 0.381 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 1 = 0.641 +- 0.381 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 class 2 = 0.686 +- 0.381 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 all KL = 0.596 +- 0.381 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.9 all L1 = 0.648 +- 0.246 (in-sample avg dev_std = 0.486)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.726
Model XAI F1 of binarized graphs for r=0.3 =  0.4344175
Model XAI WIoU of binarized graphs for r=0.3 =  0.3053375
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.443
NEC for r=0.3 class 0 = 0.606 +- 0.338 (in-sample avg dev_std = 0.473)
NEC for r=0.3 class 1 = 0.358 +- 0.338 (in-sample avg dev_std = 0.473)
NEC for r=0.3 class 2 = 0.536 +- 0.338 (in-sample avg dev_std = 0.473)
NEC for r=0.3 all KL = 0.515 +- 0.338 (in-sample avg dev_std = 0.473)
NEC for r=0.3 all L1 = 0.502 +- 0.231 (in-sample avg dev_std = 0.473)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.892
Model XAI F1 of binarized graphs for r=0.6 =  0.49543374999999995
Model XAI WIoU of binarized graphs for r=0.6 =  0.36266875000000004
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.519
NEC for r=0.6 class 0 = 0.628 +- 0.337 (in-sample avg dev_std = 0.603)
NEC for r=0.6 class 1 = 0.267 +- 0.337 (in-sample avg dev_std = 0.603)
NEC for r=0.6 class 2 = 0.578 +- 0.337 (in-sample avg dev_std = 0.603)
NEC for r=0.6 all KL = 0.553 +- 0.337 (in-sample avg dev_std = 0.603)
NEC for r=0.6 all L1 = 0.494 +- 0.254 (in-sample avg dev_std = 0.603)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.49558
Model XAI WIoU of binarized graphs for r=0.9 =  0.37757624999999995
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.561
NEC for r=0.9 class 0 = 0.596 +- 0.324 (in-sample avg dev_std = 0.663)
NEC for r=0.9 class 1 = 0.256 +- 0.324 (in-sample avg dev_std = 0.663)
NEC for r=0.9 class 2 = 0.572 +- 0.324 (in-sample avg dev_std = 0.663)
NEC for r=0.9 all KL = 0.567 +- 0.324 (in-sample avg dev_std = 0.663)
NEC for r=0.9 all L1 = 0.478 +- 0.259 (in-sample avg dev_std = 0.663)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.38064875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.571
NEC for r=1.0 class 0 = 0.594 +- 0.331 (in-sample avg dev_std = 0.659)
NEC for r=1.0 class 1 = 0.251 +- 0.331 (in-sample avg dev_std = 0.659)
NEC for r=1.0 class 2 = 0.554 +- 0.331 (in-sample avg dev_std = 0.659)
NEC for r=1.0 all KL = 0.558 +- 0.331 (in-sample avg dev_std = 0.659)
NEC for r=1.0 all L1 = 0.469 +- 0.267 (in-sample avg dev_std = 0.659)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.774
Model XAI F1 of binarized graphs for r=0.3 =  0.3170325
Model XAI WIoU of binarized graphs for r=0.3 =  0.28634125
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.422
NEC for r=0.3 class 0 = 0.681 +- 0.346 (in-sample avg dev_std = 0.355)
NEC for r=0.3 class 1 = 0.295 +- 0.346 (in-sample avg dev_std = 0.355)
NEC for r=0.3 class 2 = 0.576 +- 0.346 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all KL = 0.529 +- 0.346 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all L1 = 0.518 +- 0.273 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  0.26508125
Model XAI WIoU of binarized graphs for r=0.6 =  0.27251875
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.418
NEC for r=0.6 class 0 = 0.677 +- 0.366 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 1 = 0.234 +- 0.366 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 2 = 0.629 +- 0.366 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all KL = 0.524 +- 0.366 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all L1 = 0.512 +- 0.300 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  0.24209875
Model XAI WIoU of binarized graphs for r=0.9 =  0.2694975
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.434
NEC for r=0.9 class 0 = 0.693 +- 0.361 (in-sample avg dev_std = 0.380)
NEC for r=0.9 class 1 = 0.268 +- 0.361 (in-sample avg dev_std = 0.380)
NEC for r=0.9 class 2 = 0.633 +- 0.361 (in-sample avg dev_std = 0.380)
NEC for r=0.9 all KL = 0.551 +- 0.361 (in-sample avg dev_std = 0.380)
NEC for r=0.9 all L1 = 0.531 +- 0.296 (in-sample avg dev_std = 0.380)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.26859125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.437
NEC for r=1.0 class 0 = 0.683 +- 0.361 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 1 = 0.279 +- 0.361 (in-sample avg dev_std = 0.367)
NEC for r=1.0 class 2 = 0.628 +- 0.361 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all KL = 0.551 +- 0.361 (in-sample avg dev_std = 0.367)
NEC for r=1.0 all L1 = 0.529 +- 0.295 (in-sample avg dev_std = 0.367)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.39
Model XAI F1 of binarized graphs for r=0.3 =  0.17606625
Model XAI WIoU of binarized graphs for r=0.3 =  0.23810625000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.338
NEC for r=0.3 class 0 = 0.523 +- 0.374 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 1 = 0.373 +- 0.374 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 2 = 0.444 +- 0.374 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all KL = 0.449 +- 0.374 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all L1 = 0.447 +- 0.286 (in-sample avg dev_std = 0.373)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.479
Model XAI F1 of binarized graphs for r=0.6 =  0.12763124999999997
Model XAI WIoU of binarized graphs for r=0.6 =  0.23239374999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.328
NEC for r=0.6 class 0 = 0.597 +- 0.402 (in-sample avg dev_std = 0.314)
NEC for r=0.6 class 1 = 0.426 +- 0.402 (in-sample avg dev_std = 0.314)
NEC for r=0.6 class 2 = 0.51 +- 0.402 (in-sample avg dev_std = 0.314)
NEC for r=0.6 all KL = 0.529 +- 0.402 (in-sample avg dev_std = 0.314)
NEC for r=0.6 all L1 = 0.511 +- 0.320 (in-sample avg dev_std = 0.314)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.479
Model XAI F1 of binarized graphs for r=0.9 =  0.11305749999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.231585
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.307
NEC for r=0.9 class 0 = 0.599 +- 0.423 (in-sample avg dev_std = 0.282)
NEC for r=0.9 class 1 = 0.46 +- 0.423 (in-sample avg dev_std = 0.282)
NEC for r=0.9 class 2 = 0.502 +- 0.423 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all KL = 0.539 +- 0.423 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all L1 = 0.521 +- 0.333 (in-sample avg dev_std = 0.282)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.472
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.23158375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.297
NEC for r=1.0 class 0 = 0.593 +- 0.426 (in-sample avg dev_std = 0.287)
NEC for r=1.0 class 1 = 0.468 +- 0.426 (in-sample avg dev_std = 0.287)
NEC for r=1.0 class 2 = 0.503 +- 0.426 (in-sample avg dev_std = 0.287)
NEC for r=1.0 all KL = 0.54 +- 0.426 (in-sample avg dev_std = 0.287)
NEC for r=1.0 all L1 = 0.522 +- 0.338 (in-sample avg dev_std = 0.287)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:06:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:06:53 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:07:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9288
Train Loss: 0.3489
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.3183
ID Test ACCURACY: 0.9320
ID Test Loss: 0.3503
OOD Validation ACCURACY: 0.8037
OOD Validation Loss: 0.8911
OOD Test ACCURACY: 0.4237
OOD Test Loss: 28.2234

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 151...
[0m[1;37mINFO[0m: [1mCheckpoint 151: 
-----------------------------------
Train ACCURACY: 0.9256
Train Loss: 0.3727
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3385
ID Test ACCURACY: 0.9270
ID Test Loss: 0.3867
OOD Validation ACCURACY: 0.8970
OOD Validation Loss: 0.4289
OOD Test ACCURACY: 0.3387
OOD Test Loss: 7.4305

[0m[1;37mINFO[0m: [1mChartInfo 0.9320 0.4237 0.9270 0.3387 0.9297 0.8970[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.551
WIoU for r=0.3 = 0.445
F1 for r=0.6 = 0.543
WIoU for r=0.6 = 0.502
F1 for r=0.9 = 0.502
WIoU for r=0.9 = 0.511
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.512
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.455
WIoU for r=0.3 = 0.497
F1 for r=0.6 = 0.312
WIoU for r=0.6 = 0.480
F1 for r=0.9 = 0.248
WIoU for r=0.9 = 0.473
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.471
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.249
WIoU for r=0.3 = 0.196
F1 for r=0.6 = 0.164
WIoU for r=0.6 = 0.156
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.138
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.134


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.782
Model XAI F1 of binarized graphs for r=0.3 =  0.5514100000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.44546375
len(reference) = 751
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0 = 0.429 +- 0.321 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 class 1 = 0.682 +- 0.321 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 class 2 = 0.586 +- 0.321 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 all KL = 0.409 +- 0.321 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 all L1 = 0.559 +- 0.244 (in-sample avg dev_std = 0.659)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.921
Model XAI F1 of binarized graphs for r=0.6 =  0.54347875
Model XAI WIoU of binarized graphs for r=0.6 =  0.50188125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.716
SUFF++ for r=0.6 class 0 = 0.575 +- 0.343 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.6 class 1 = 0.735 +- 0.343 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.6 class 2 = 0.728 +- 0.343 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.6 all KL = 0.606 +- 0.343 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.6 all L1 = 0.678 +- 0.260 (in-sample avg dev_std = 0.549)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.5019462499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5105937500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0 = 0.846 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 1 = 0.942 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 2 = 0.911 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all KL = 0.891 +- 0.236 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all L1 = 0.899 +- 0.173 (in-sample avg dev_std = 0.295)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.816
Model XAI F1 of binarized graphs for r=0.3 =  0.4552875
Model XAI WIoU of binarized graphs for r=0.3 =  0.4968875
len(reference) = 795
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.658
SUFF++ for r=0.3 class 0 = 0.465 +- 0.284 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 class 1 = 0.657 +- 0.284 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 class 2 = 0.618 +- 0.284 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 all KL = 0.53 +- 0.284 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.3 all L1 = 0.579 +- 0.206 (in-sample avg dev_std = 0.549)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  0.31184375
Model XAI WIoU of binarized graphs for r=0.6 =  0.47966375
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.675
SUFF++ for r=0.6 class 0 = 0.548 +- 0.229 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 1 = 0.729 +- 0.229 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 2 = 0.653 +- 0.229 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all KL = 0.715 +- 0.229 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all L1 = 0.643 +- 0.195 (in-sample avg dev_std = 0.409)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  0.24847125000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.47286125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.838
SUFF++ for r=0.9 class 0 = 0.825 +- 0.172 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.883 +- 0.172 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.815 +- 0.172 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.905 +- 0.172 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.841 +- 0.149 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.416
Model XAI F1 of binarized graphs for r=0.3 =  0.24926874999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.19568375000000005
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.409
SUFF++ for r=0.3 class 0 = 0.537 +- 0.290 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 1 = 0.622 +- 0.290 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 2 = 0.568 +- 0.290 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 all KL = 0.528 +- 0.290 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 all L1 = 0.576 +- 0.231 (in-sample avg dev_std = 0.461)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.449
Model XAI F1 of binarized graphs for r=0.6 =  0.16377125000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.15593625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.388
SUFF++ for r=0.6 class 0 = 0.715 +- 0.280 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 class 1 = 0.786 +- 0.280 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 class 2 = 0.731 +- 0.280 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 all KL = 0.704 +- 0.280 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 all L1 = 0.745 +- 0.205 (in-sample avg dev_std = 0.286)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.428
Model XAI F1 of binarized graphs for r=0.9 =  0.12146125000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.137575
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.387
SUFF++ for r=0.9 class 0 = 0.89 +- 0.219 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.219 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 class 2 = 0.887 +- 0.219 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all KL = 0.902 +- 0.219 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.154 (in-sample avg dev_std = 0.207)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.772
Model XAI F1 of binarized graphs for r=0.3 =  0.5514100000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.44546375
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.375
NEC for r=0.3 class 0 = 0.765 +- 0.424 (in-sample avg dev_std = 0.434)
NEC for r=0.3 class 1 = 0.158 +- 0.424 (in-sample avg dev_std = 0.434)
NEC for r=0.3 class 2 = 0.661 +- 0.424 (in-sample avg dev_std = 0.434)
NEC for r=0.3 all KL = 0.637 +- 0.424 (in-sample avg dev_std = 0.434)
NEC for r=0.3 all L1 = 0.533 +- 0.349 (in-sample avg dev_std = 0.434)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.921
Model XAI F1 of binarized graphs for r=0.6 =  0.54347875
Model XAI WIoU of binarized graphs for r=0.6 =  0.50188125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.489
NEC for r=0.6 class 0 = 0.696 +- 0.405 (in-sample avg dev_std = 0.586)
NEC for r=0.6 class 1 = 0.143 +- 0.405 (in-sample avg dev_std = 0.586)
NEC for r=0.6 class 2 = 0.63 +- 0.405 (in-sample avg dev_std = 0.586)
NEC for r=0.6 all KL = 0.609 +- 0.405 (in-sample avg dev_std = 0.586)
NEC for r=0.6 all L1 = 0.495 +- 0.324 (in-sample avg dev_std = 0.586)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.935
Model XAI F1 of binarized graphs for r=0.9 =  0.5019462499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5105937500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.647 +- 0.395 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 1 = 0.128 +- 0.395 (in-sample avg dev_std = 0.631)
NEC for r=0.9 class 2 = 0.597 +- 0.395 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all KL = 0.578 +- 0.395 (in-sample avg dev_std = 0.631)
NEC for r=0.9 all L1 = 0.462 +- 0.311 (in-sample avg dev_std = 0.631)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.51186375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.553
NEC for r=1.0 class 0 = 0.632 +- 0.394 (in-sample avg dev_std = 0.632)
NEC for r=1.0 class 1 = 0.126 +- 0.394 (in-sample avg dev_std = 0.632)
NEC for r=1.0 class 2 = 0.593 +- 0.394 (in-sample avg dev_std = 0.632)
NEC for r=1.0 all KL = 0.569 +- 0.394 (in-sample avg dev_std = 0.632)
NEC for r=1.0 all L1 = 0.455 +- 0.310 (in-sample avg dev_std = 0.632)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.817
Model XAI F1 of binarized graphs for r=0.3 =  0.4552875
Model XAI WIoU of binarized graphs for r=0.3 =  0.4968875
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.401
NEC for r=0.3 class 0 = 0.733 +- 0.392 (in-sample avg dev_std = 0.319)
NEC for r=0.3 class 1 = 0.225 +- 0.392 (in-sample avg dev_std = 0.319)
NEC for r=0.3 class 2 = 0.681 +- 0.392 (in-sample avg dev_std = 0.319)
NEC for r=0.3 all KL = 0.558 +- 0.392 (in-sample avg dev_std = 0.319)
NEC for r=0.3 all L1 = 0.546 +- 0.302 (in-sample avg dev_std = 0.319)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.83
Model XAI F1 of binarized graphs for r=0.6 =  0.31184375
Model XAI WIoU of binarized graphs for r=0.6 =  0.47966375
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.442
NEC for r=0.6 class 0 = 0.608 +- 0.329 (in-sample avg dev_std = 0.347)
NEC for r=0.6 class 1 = 0.163 +- 0.329 (in-sample avg dev_std = 0.347)
NEC for r=0.6 class 2 = 0.575 +- 0.329 (in-sample avg dev_std = 0.347)
NEC for r=0.6 all KL = 0.392 +- 0.329 (in-sample avg dev_std = 0.347)
NEC for r=0.6 all L1 = 0.448 +- 0.275 (in-sample avg dev_std = 0.347)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.817
Model XAI F1 of binarized graphs for r=0.9 =  0.24847125000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.47286125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.475
NEC for r=0.9 class 0 = 0.558 +- 0.285 (in-sample avg dev_std = 0.354)
NEC for r=0.9 class 1 = 0.145 +- 0.285 (in-sample avg dev_std = 0.354)
NEC for r=0.9 class 2 = 0.535 +- 0.285 (in-sample avg dev_std = 0.354)
NEC for r=0.9 all KL = 0.33 +- 0.285 (in-sample avg dev_std = 0.354)
NEC for r=0.9 all L1 = 0.411 +- 0.259 (in-sample avg dev_std = 0.354)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.824
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.47147125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.479
NEC for r=1.0 class 0 = 0.557 +- 0.295 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 1 = 0.14 +- 0.295 (in-sample avg dev_std = 0.359)
NEC for r=1.0 class 2 = 0.531 +- 0.295 (in-sample avg dev_std = 0.359)
NEC for r=1.0 all KL = 0.336 +- 0.295 (in-sample avg dev_std = 0.359)
NEC for r=1.0 all L1 = 0.409 +- 0.264 (in-sample avg dev_std = 0.359)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.416
Model XAI F1 of binarized graphs for r=0.3 =  0.24926874999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.19568375000000005
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.435 +- 0.378 (in-sample avg dev_std = 0.114)
NEC for r=0.3 class 1 = 0.365 +- 0.378 (in-sample avg dev_std = 0.114)
NEC for r=0.3 class 2 = 0.428 +- 0.378 (in-sample avg dev_std = 0.114)
NEC for r=0.3 all KL = 0.422 +- 0.378 (in-sample avg dev_std = 0.114)
NEC for r=0.3 all L1 = 0.409 +- 0.334 (in-sample avg dev_std = 0.114)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.449
Model XAI F1 of binarized graphs for r=0.6 =  0.16377125000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.15593625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.344
NEC for r=0.6 class 0 = 0.322 +- 0.330 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 1 = 0.232 +- 0.330 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 2 = 0.316 +- 0.330 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all KL = 0.308 +- 0.330 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all L1 = 0.289 +- 0.251 (in-sample avg dev_std = 0.096)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.428
Model XAI F1 of binarized graphs for r=0.9 =  0.12146125000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.137575
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.344
NEC for r=0.9 class 0 = 0.286 +- 0.350 (in-sample avg dev_std = 0.110)
NEC for r=0.9 class 1 = 0.211 +- 0.350 (in-sample avg dev_std = 0.110)
NEC for r=0.9 class 2 = 0.289 +- 0.350 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all KL = 0.282 +- 0.350 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all L1 = 0.261 +- 0.245 (in-sample avg dev_std = 0.110)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.428
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.13367125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.345
NEC for r=1.0 class 0 = 0.289 +- 0.350 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1 = 0.215 +- 0.350 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 2 = 0.298 +- 0.350 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.283 +- 0.350 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.267 +- 0.249 (in-sample avg dev_std = 0.132)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:12:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:12:52 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:07 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:11 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:13:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9257
Train Loss: 0.3862
ID Validation ACCURACY: 0.9350
ID Validation Loss: 0.3474
ID Test ACCURACY: 0.9247
ID Test Loss: 0.3808
OOD Validation ACCURACY: 0.8763
OOD Validation Loss: 0.4881
OOD Test ACCURACY: 0.3610
OOD Test Loss: 1.1810

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.9242
Train Loss: 0.4071
ID Validation ACCURACY: 0.9283
ID Validation Loss: 0.3718
ID Test ACCURACY: 0.9277
ID Test Loss: 0.3969
OOD Validation ACCURACY: 0.8980
OOD Validation Loss: 0.4527
OOD Test ACCURACY: 0.3973
OOD Test Loss: 1.1786

[0m[1;37mINFO[0m: [1mChartInfo 0.9247 0.3610 0.9277 0.3973 0.9283 0.8980[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.485
WIoU for r=0.3 = 0.426
F1 for r=0.6 = 0.512
WIoU for r=0.6 = 0.478
F1 for r=0.9 = 0.496
WIoU for r=0.9 = 0.481
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.481
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.359
WIoU for r=0.3 = 0.498
F1 for r=0.6 = 0.278
WIoU for r=0.6 = 0.497
F1 for r=0.9 = 0.241
WIoU for r=0.9 = 0.496
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.495
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.207
WIoU for r=0.3 = 0.390
F1 for r=0.6 = 0.142
WIoU for r=0.6 = 0.390
F1 for r=0.9 = 0.117
WIoU for r=0.9 = 0.390
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.390


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  0.4849549999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.42595749999999993
len(reference) = 760
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0 = 0.449 +- 0.304 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 class 1 = 0.72 +- 0.304 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 class 2 = 0.393 +- 0.304 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 all KL = 0.388 +- 0.304 (in-sample avg dev_std = 0.682)
SUFF++ for r=0.3 all L1 = 0.511 +- 0.225 (in-sample avg dev_std = 0.682)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.51186
Model XAI WIoU of binarized graphs for r=0.6 =  0.4782925
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0 = 0.642 +- 0.316 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.6 class 1 = 0.698 +- 0.316 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.6 class 2 = 0.452 +- 0.316 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.6 all KL = 0.502 +- 0.316 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.6 all L1 = 0.596 +- 0.255 (in-sample avg dev_std = 0.623)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.933
Model XAI F1 of binarized graphs for r=0.9 =  0.49593
Model XAI WIoU of binarized graphs for r=0.9 =  0.4809475
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0 = 0.874 +- 0.256 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 class 1 = 0.932 +- 0.256 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 class 2 = 0.803 +- 0.256 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 all KL = 0.851 +- 0.256 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.9 all L1 = 0.869 +- 0.192 (in-sample avg dev_std = 0.370)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.768
Model XAI F1 of binarized graphs for r=0.3 =  0.3591825
Model XAI WIoU of binarized graphs for r=0.3 =  0.49788375
len(reference) = 796
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0 = 0.64 +- 0.254 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 1 = 0.643 +- 0.254 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 2 = 0.449 +- 0.254 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all KL = 0.552 +- 0.254 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all L1 = 0.579 +- 0.198 (in-sample avg dev_std = 0.576)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.736
Model XAI F1 of binarized graphs for r=0.6 =  0.27757
Model XAI WIoU of binarized graphs for r=0.6 =  0.4968125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.576
SUFF++ for r=0.6 class 0 = 0.626 +- 0.246 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 class 1 = 0.631 +- 0.246 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 class 2 = 0.5 +- 0.246 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all KL = 0.637 +- 0.246 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all L1 = 0.587 +- 0.197 (in-sample avg dev_std = 0.502)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  0.24067875
Model XAI WIoU of binarized graphs for r=0.9 =  0.49566125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.77
SUFF++ for r=0.9 class 0 = 0.858 +- 0.174 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 1 = 0.827 +- 0.174 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 2 = 0.761 +- 0.174 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all KL = 0.881 +- 0.174 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.171 (in-sample avg dev_std = 0.304)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.452
Model XAI F1 of binarized graphs for r=0.3 =  0.20717750000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.390355
len(reference) = 795
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.393
SUFF++ for r=0.3 class 0 = 0.478 +- 0.279 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 1 = 0.565 +- 0.279 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.279 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all KL = 0.559 +- 0.279 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.3 all L1 = 0.517 +- 0.181 (in-sample avg dev_std = 0.498)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.374
Model XAI F1 of binarized graphs for r=0.6 =  0.14220750000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.39016000000000006
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.386
SUFF++ for r=0.6 class 0 = 0.614 +- 0.267 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1 = 0.638 +- 0.267 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 2 = 0.607 +- 0.267 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.712 +- 0.267 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.62 +- 0.206 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.37
Model XAI F1 of binarized graphs for r=0.9 =  0.11675750000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.39016000000000006
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.372
SUFF++ for r=0.9 class 0 = 0.845 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1 = 0.856 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 2 = 0.847 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.939 +- 0.091 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.85 +- 0.125 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.766
Model XAI F1 of binarized graphs for r=0.3 =  0.4849549999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.42595749999999993
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.406
NEC for r=0.3 class 0 = 0.683 +- 0.411 (in-sample avg dev_std = 0.442)
NEC for r=0.3 class 1 = 0.128 +- 0.411 (in-sample avg dev_std = 0.442)
NEC for r=0.3 class 2 = 0.682 +- 0.411 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all KL = 0.57 +- 0.411 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all L1 = 0.503 +- 0.340 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  0.51186
Model XAI WIoU of binarized graphs for r=0.6 =  0.4782925
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.489
NEC for r=0.6 class 0 = 0.714 +- 0.400 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 1 = 0.132 +- 0.400 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 2 = 0.585 +- 0.400 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all KL = 0.56 +- 0.400 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all L1 = 0.482 +- 0.321 (in-sample avg dev_std = 0.562)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.933
Model XAI F1 of binarized graphs for r=0.9 =  0.49593
Model XAI WIoU of binarized graphs for r=0.9 =  0.4809475
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.66 +- 0.398 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 1 = 0.122 +- 0.398 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 2 = 0.592 +- 0.398 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all KL = 0.57 +- 0.398 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all L1 = 0.463 +- 0.311 (in-sample avg dev_std = 0.624)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.48056875000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.546
NEC for r=1.0 class 0 = 0.662 +- 0.401 (in-sample avg dev_std = 0.639)
NEC for r=1.0 class 1 = 0.131 +- 0.401 (in-sample avg dev_std = 0.639)
NEC for r=1.0 class 2 = 0.581 +- 0.401 (in-sample avg dev_std = 0.639)
NEC for r=1.0 all KL = 0.586 +- 0.401 (in-sample avg dev_std = 0.639)
NEC for r=1.0 all L1 = 0.463 +- 0.312 (in-sample avg dev_std = 0.639)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.769
Model XAI F1 of binarized graphs for r=0.3 =  0.3591825
Model XAI WIoU of binarized graphs for r=0.3 =  0.49788375
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.732 +- 0.349 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 1 = 0.256 +- 0.349 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 2 = 0.581 +- 0.349 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all KL = 0.535 +- 0.349 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all L1 = 0.523 +- 0.279 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.736
Model XAI F1 of binarized graphs for r=0.6 =  0.27757
Model XAI WIoU of binarized graphs for r=0.6 =  0.4968125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.436
NEC for r=0.6 class 0 = 0.597 +- 0.285 (in-sample avg dev_std = 0.423)
NEC for r=0.6 class 1 = 0.219 +- 0.285 (in-sample avg dev_std = 0.423)
NEC for r=0.6 class 2 = 0.477 +- 0.285 (in-sample avg dev_std = 0.423)
NEC for r=0.6 all KL = 0.371 +- 0.285 (in-sample avg dev_std = 0.423)
NEC for r=0.6 all L1 = 0.431 +- 0.246 (in-sample avg dev_std = 0.423)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  0.24067875
Model XAI WIoU of binarized graphs for r=0.9 =  0.49566125
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.484
NEC for r=0.9 class 0 = 0.554 +- 0.259 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 1 = 0.253 +- 0.259 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 2 = 0.522 +- 0.259 (in-sample avg dev_std = 0.469)
NEC for r=0.9 all KL = 0.382 +- 0.259 (in-sample avg dev_std = 0.469)
NEC for r=0.9 all L1 = 0.442 +- 0.225 (in-sample avg dev_std = 0.469)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.4954725
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.512
NEC for r=1.0 class 0 = 0.558 +- 0.255 (in-sample avg dev_std = 0.491)
NEC for r=1.0 class 1 = 0.276 +- 0.255 (in-sample avg dev_std = 0.491)
NEC for r=1.0 class 2 = 0.55 +- 0.255 (in-sample avg dev_std = 0.491)
NEC for r=1.0 all KL = 0.412 +- 0.255 (in-sample avg dev_std = 0.491)
NEC for r=1.0 all L1 = 0.461 +- 0.222 (in-sample avg dev_std = 0.491)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.455
Model XAI F1 of binarized graphs for r=0.3 =  0.20717750000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.390355
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.355
NEC for r=0.3 class 0 = 0.539 +- 0.354 (in-sample avg dev_std = 0.300)
NEC for r=0.3 class 1 = 0.417 +- 0.354 (in-sample avg dev_std = 0.300)
NEC for r=0.3 class 2 = 0.485 +- 0.354 (in-sample avg dev_std = 0.300)
NEC for r=0.3 all KL = 0.418 +- 0.354 (in-sample avg dev_std = 0.300)
NEC for r=0.3 all L1 = 0.48 +- 0.267 (in-sample avg dev_std = 0.300)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.374
Model XAI F1 of binarized graphs for r=0.6 =  0.14220750000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.39016000000000006
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.346
NEC for r=0.6 class 0 = 0.396 +- 0.278 (in-sample avg dev_std = 0.196)
NEC for r=0.6 class 1 = 0.318 +- 0.278 (in-sample avg dev_std = 0.196)
NEC for r=0.6 class 2 = 0.367 +- 0.278 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all KL = 0.243 +- 0.278 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all L1 = 0.36 +- 0.239 (in-sample avg dev_std = 0.196)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.37
Model XAI F1 of binarized graphs for r=0.9 =  0.11675750000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.39016000000000006
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.358
NEC for r=0.9 class 0 = 0.404 +- 0.331 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1 = 0.344 +- 0.331 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 2 = 0.399 +- 0.331 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.271 +- 0.331 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.382 +- 0.263 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.375
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.39016000000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.362
NEC for r=1.0 class 0 = 0.408 +- 0.326 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 1 = 0.363 +- 0.326 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 2 = 0.426 +- 0.326 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all KL = 0.282 +- 0.326 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all L1 = 0.398 +- 0.258 (in-sample avg dev_std = 0.151)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:18:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:18:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:19:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 0.9216
Train Loss: 0.3644
ID Validation ACCURACY: 0.9307
ID Validation Loss: 0.3405
ID Test ACCURACY: 0.9260
ID Test Loss: 0.3557
OOD Validation ACCURACY: 0.5993
OOD Validation Loss: 0.7320
OOD Test ACCURACY: 0.3430
OOD Test Loss: 1.5205

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.9224
Train Loss: 0.3535
ID Validation ACCURACY: 0.9297
ID Validation Loss: 0.3378
ID Test ACCURACY: 0.9250
ID Test Loss: 0.3428
OOD Validation ACCURACY: 0.7393
OOD Validation Loss: 0.6328
OOD Test ACCURACY: 0.3503
OOD Test Loss: 1.5734

[0m[1;37mINFO[0m: [1mChartInfo 0.9260 0.3430 0.9250 0.3503 0.9297 0.7393[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.399
WIoU for r=0.3 = 0.305
F1 for r=0.6 = 0.447
WIoU for r=0.6 = 0.371
F1 for r=0.9 = 0.470
WIoU for r=0.9 = 0.385
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.388
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.389
WIoU for r=0.3 = 0.423
F1 for r=0.6 = 0.287
WIoU for r=0.6 = 0.421
F1 for r=0.9 = 0.240
WIoU for r=0.9 = 0.421
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.421
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.219
WIoU for r=0.3 = 0.360
F1 for r=0.6 = 0.146
WIoU for r=0.6 = 0.360
F1 for r=0.9 = 0.118
WIoU for r=0.9 = 0.360
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.360


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.572
Model XAI F1 of binarized graphs for r=0.3 =  0.39928125000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.30535625000000005
len(reference) = 759
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.436
SUFF++ for r=0.3 class 0 = 0.482 +- 0.321 (in-sample avg dev_std = 0.689)
SUFF++ for r=0.3 class 1 = 0.649 +- 0.321 (in-sample avg dev_std = 0.689)
SUFF++ for r=0.3 class 2 = 0.547 +- 0.321 (in-sample avg dev_std = 0.689)
SUFF++ for r=0.3 all KL = 0.426 +- 0.321 (in-sample avg dev_std = 0.689)
SUFF++ for r=0.3 all L1 = 0.556 +- 0.215 (in-sample avg dev_std = 0.689)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.733
Model XAI F1 of binarized graphs for r=0.6 =  0.44698375
Model XAI WIoU of binarized graphs for r=0.6 =  0.37084125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.6
SUFF++ for r=0.6 class 0 = 0.644 +- 0.333 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 1 = 0.718 +- 0.333 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 2 = 0.587 +- 0.333 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all KL = 0.635 +- 0.333 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.247 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.46974125
Model XAI WIoU of binarized graphs for r=0.9 =  0.38498625000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.789
SUFF++ for r=0.9 class 0 = 0.784 +- 0.325 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 1 = 0.841 +- 0.325 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 2 = 0.74 +- 0.325 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all KL = 0.773 +- 0.325 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all L1 = 0.788 +- 0.245 (in-sample avg dev_std = 0.421)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.758
Model XAI F1 of binarized graphs for r=0.3 =  0.38893875
Model XAI WIoU of binarized graphs for r=0.3 =  0.42327
len(reference) = 789
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.666
SUFF++ for r=0.3 class 0 = 0.599 +- 0.232 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 1 = 0.686 +- 0.232 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 2 = 0.667 +- 0.232 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all KL = 0.689 +- 0.232 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all L1 = 0.65 +- 0.169 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  0.28688375
Model XAI WIoU of binarized graphs for r=0.6 =  0.42054
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.629
SUFF++ for r=0.6 class 0 = 0.677 +- 0.163 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 1 = 0.798 +- 0.163 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 2 = 0.685 +- 0.163 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all KL = 0.82 +- 0.163 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all L1 = 0.72 +- 0.156 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  0.23969250000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.420775
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.558
SUFF++ for r=0.9 class 0 = 0.797 +- 0.198 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.866 +- 0.198 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.774 +- 0.198 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.882 +- 0.198 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.813 +- 0.181 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.47
Model XAI F1 of binarized graphs for r=0.3 =  0.21939
Model XAI WIoU of binarized graphs for r=0.3 =  0.35962625
len(reference) = 795
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.397
SUFF++ for r=0.3 class 0 = 0.549 +- 0.253 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.558 +- 0.253 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.543 +- 0.253 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.623 +- 0.253 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.55 +- 0.186 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.345
Model XAI F1 of binarized graphs for r=0.6 =  0.14562
Model XAI WIoU of binarized graphs for r=0.6 =  0.3595762500000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.344
SUFF++ for r=0.6 class 0 = 0.66 +- 0.294 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1 = 0.667 +- 0.294 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 2 = 0.645 +- 0.294 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.729 +- 0.294 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.657 +- 0.223 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.343
Model XAI F1 of binarized graphs for r=0.9 =  0.11837375
Model XAI WIoU of binarized graphs for r=0.9 =  0.3595762500000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.335
SUFF++ for r=0.9 class 0 = 0.871 +- 0.240 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 class 1 = 0.852 +- 0.240 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 class 2 = 0.847 +- 0.240 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 all KL = 0.878 +- 0.240 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 all L1 = 0.857 +- 0.196 (in-sample avg dev_std = 0.377)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.574
Model XAI F1 of binarized graphs for r=0.3 =  0.39928125000000003
Model XAI WIoU of binarized graphs for r=0.3 =  0.30535625000000005
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.391
NEC for r=0.3 class 0 = 0.586 +- 0.441 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 1 = 0.184 +- 0.441 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 2 = 0.507 +- 0.441 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all KL = 0.483 +- 0.441 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all L1 = 0.429 +- 0.340 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.733
Model XAI F1 of binarized graphs for r=0.6 =  0.44698375
Model XAI WIoU of binarized graphs for r=0.6 =  0.37084125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.475
NEC for r=0.6 class 0 = 0.604 +- 0.409 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 1 = 0.185 +- 0.409 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 2 = 0.524 +- 0.409 (in-sample avg dev_std = 0.462)
NEC for r=0.6 all KL = 0.478 +- 0.409 (in-sample avg dev_std = 0.462)
NEC for r=0.6 all L1 = 0.441 +- 0.316 (in-sample avg dev_std = 0.462)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  0.46974125
Model XAI WIoU of binarized graphs for r=0.9 =  0.38498625000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.542
NEC for r=0.9 class 0 = 0.644 +- 0.384 (in-sample avg dev_std = 0.546)
NEC for r=0.9 class 1 = 0.159 +- 0.384 (in-sample avg dev_std = 0.546)
NEC for r=0.9 class 2 = 0.549 +- 0.384 (in-sample avg dev_std = 0.546)
NEC for r=0.9 all KL = 0.522 +- 0.384 (in-sample avg dev_std = 0.546)
NEC for r=0.9 all L1 = 0.455 +- 0.304 (in-sample avg dev_std = 0.546)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.38790625000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.542
NEC for r=1.0 class 0 = 0.643 +- 0.386 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 1 = 0.137 +- 0.386 (in-sample avg dev_std = 0.568)
NEC for r=1.0 class 2 = 0.571 +- 0.386 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all KL = 0.53 +- 0.386 (in-sample avg dev_std = 0.568)
NEC for r=1.0 all L1 = 0.455 +- 0.306 (in-sample avg dev_std = 0.568)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.761
Model XAI F1 of binarized graphs for r=0.3 =  0.38893875
Model XAI WIoU of binarized graphs for r=0.3 =  0.42327
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.4
NEC for r=0.3 class 0 = 0.635 +- 0.407 (in-sample avg dev_std = 0.306)
NEC for r=0.3 class 1 = 0.167 +- 0.407 (in-sample avg dev_std = 0.306)
NEC for r=0.3 class 2 = 0.591 +- 0.407 (in-sample avg dev_std = 0.306)
NEC for r=0.3 all KL = 0.457 +- 0.407 (in-sample avg dev_std = 0.306)
NEC for r=0.3 all L1 = 0.464 +- 0.329 (in-sample avg dev_std = 0.306)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.639
Model XAI F1 of binarized graphs for r=0.6 =  0.28688375
Model XAI WIoU of binarized graphs for r=0.6 =  0.42054
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.438
NEC for r=0.6 class 0 = 0.442 +- 0.274 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1 = 0.108 +- 0.274 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 2 = 0.443 +- 0.274 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.228 +- 0.274 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.33 +- 0.260 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.558
Model XAI F1 of binarized graphs for r=0.9 =  0.23969250000000003
Model XAI WIoU of binarized graphs for r=0.9 =  0.420775
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.446
NEC for r=0.9 class 0 = 0.436 +- 0.238 (in-sample avg dev_std = 0.295)
NEC for r=0.9 class 1 = 0.156 +- 0.238 (in-sample avg dev_std = 0.295)
NEC for r=0.9 class 2 = 0.42 +- 0.238 (in-sample avg dev_std = 0.295)
NEC for r=0.9 all KL = 0.226 +- 0.238 (in-sample avg dev_std = 0.295)
NEC for r=0.9 all L1 = 0.336 +- 0.231 (in-sample avg dev_std = 0.295)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.604
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.4207599999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.468
NEC for r=1.0 class 0 = 0.443 +- 0.253 (in-sample avg dev_std = 0.333)
NEC for r=1.0 class 1 = 0.155 +- 0.253 (in-sample avg dev_std = 0.333)
NEC for r=1.0 class 2 = 0.437 +- 0.253 (in-sample avg dev_std = 0.333)
NEC for r=1.0 all KL = 0.246 +- 0.253 (in-sample avg dev_std = 0.333)
NEC for r=1.0 all L1 = 0.344 +- 0.233 (in-sample avg dev_std = 0.333)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.472
Model XAI F1 of binarized graphs for r=0.3 =  0.21939
Model XAI WIoU of binarized graphs for r=0.3 =  0.35962625
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.33
NEC for r=0.3 class 0 = 0.471 +- 0.314 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1 = 0.313 +- 0.314 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 2 = 0.523 +- 0.314 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.34 +- 0.314 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.433 +- 0.263 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.345
Model XAI F1 of binarized graphs for r=0.6 =  0.14562
Model XAI WIoU of binarized graphs for r=0.6 =  0.3595762500000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.317
NEC for r=0.6 class 0 = 0.229 +- 0.264 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 1 = 0.222 +- 0.264 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 2 = 0.291 +- 0.264 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all KL = 0.157 +- 0.264 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all L1 = 0.246 +- 0.215 (in-sample avg dev_std = 0.278)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.343
Model XAI F1 of binarized graphs for r=0.9 =  0.11837375
Model XAI WIoU of binarized graphs for r=0.9 =  0.3595762500000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.319
NEC for r=0.9 class 0 = 0.169 +- 0.229 (in-sample avg dev_std = 0.244)
NEC for r=0.9 class 1 = 0.187 +- 0.229 (in-sample avg dev_std = 0.244)
NEC for r=0.9 class 2 = 0.237 +- 0.229 (in-sample avg dev_std = 0.244)
NEC for r=0.9 all KL = 0.122 +- 0.229 (in-sample avg dev_std = 0.244)
NEC for r=0.9 all L1 = 0.197 +- 0.199 (in-sample avg dev_std = 0.244)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.343
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.3595762500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.321
NEC for r=1.0 class 0 = 0.169 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 1 = 0.175 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=1.0 class 2 = 0.23 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all KL = 0.116 +- 0.218 (in-sample avg dev_std = 0.233)
NEC for r=1.0 all L1 = 0.191 +- 0.194 (in-sample avg dev_std = 0.233)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:24:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:24:55 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:07 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:08 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:10 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:14 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:25:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.9208
Train Loss: 0.3971
ID Validation ACCURACY: 0.9267
ID Validation Loss: 0.3546
ID Test ACCURACY: 0.9247
ID Test Loss: 0.3907
OOD Validation ACCURACY: 0.7923
OOD Validation Loss: 0.6439
OOD Test ACCURACY: 0.3820
OOD Test Loss: 1.6710

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9054
Train Loss: 0.4283
ID Validation ACCURACY: 0.9060
ID Validation Loss: 0.3932
ID Test ACCURACY: 0.9053
ID Test Loss: 0.4316
OOD Validation ACCURACY: 0.8107
OOD Validation Loss: 0.5962
OOD Test ACCURACY: 0.4223
OOD Test Loss: 1.1148

[0m[1;37mINFO[0m: [1mChartInfo 0.9247 0.3820 0.9053 0.4223 0.9060 0.8107[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.488
WIoU for r=0.3 = 0.400
F1 for r=0.6 = 0.503
WIoU for r=0.6 = 0.452
F1 for r=0.9 = 0.495
WIoU for r=0.9 = 0.459
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.459
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.414
WIoU for r=0.3 = 0.422
F1 for r=0.6 = 0.299
WIoU for r=0.6 = 0.421
F1 for r=0.9 = 0.247
WIoU for r=0.9 = 0.420
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.420
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.239
WIoU for r=0.3 = 0.239
F1 for r=0.6 = 0.149
WIoU for r=0.6 = 0.217
F1 for r=0.9 = 0.119
WIoU for r=0.9 = 0.214
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.213


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  0.487975
Model XAI WIoU of binarized graphs for r=0.3 =  0.39953249999999996
len(reference) = 764
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.552
SUFF++ for r=0.3 class 0 = 0.444 +- 0.309 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 class 1 = 0.631 +- 0.309 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 class 2 = 0.477 +- 0.309 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 all KL = 0.341 +- 0.309 (in-sample avg dev_std = 0.681)
SUFF++ for r=0.3 all L1 = 0.513 +- 0.236 (in-sample avg dev_std = 0.681)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.889
Model XAI F1 of binarized graphs for r=0.6 =  0.50256875
Model XAI WIoU of binarized graphs for r=0.6 =  0.451945
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0 = 0.613 +- 0.347 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 class 1 = 0.702 +- 0.347 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 class 2 = 0.661 +- 0.347 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 all KL = 0.572 +- 0.347 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 all L1 = 0.658 +- 0.263 (in-sample avg dev_std = 0.552)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.49546125
Model XAI WIoU of binarized graphs for r=0.9 =  0.45904125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0 = 0.853 +- 0.203 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.919 +- 0.203 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.934 +- 0.203 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.902 +- 0.203 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.167 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.886
Model XAI F1 of binarized graphs for r=0.3 =  0.41382874999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.42199749999999997
len(reference) = 790
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.702
SUFF++ for r=0.3 class 0 = 0.55 +- 0.289 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 1 = 0.613 +- 0.289 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 class 2 = 0.759 +- 0.289 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all KL = 0.588 +- 0.289 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.3 all L1 = 0.639 +- 0.231 (in-sample avg dev_std = 0.545)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  0.2993775
Model XAI WIoU of binarized graphs for r=0.6 =  0.42101374999999996
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.741
SUFF++ for r=0.6 class 0 = 0.57 +- 0.273 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1 = 0.694 +- 0.273 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 2 = 0.681 +- 0.273 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.681 +- 0.273 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.647 +- 0.217 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.24702625000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.42017625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.809
SUFF++ for r=0.9 class 0 = 0.811 +- 0.164 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1 = 0.889 +- 0.164 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 2 = 0.851 +- 0.164 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.908 +- 0.164 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.85 +- 0.140 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  0.23915625
Model XAI WIoU of binarized graphs for r=0.3 =  0.23919625000000003
len(reference) = 789
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.471
SUFF++ for r=0.3 class 0 = 0.56 +- 0.252 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 1 = 0.563 +- 0.252 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 2 = 0.696 +- 0.252 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all KL = 0.61 +- 0.252 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all L1 = 0.605 +- 0.214 (in-sample avg dev_std = 0.436)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.409
Model XAI F1 of binarized graphs for r=0.6 =  0.14919374999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.21679875000000004
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.408
SUFF++ for r=0.6 class 0 = 0.608 +- 0.217 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 class 1 = 0.72 +- 0.217 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 class 2 = 0.677 +- 0.217 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 all KL = 0.742 +- 0.217 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 all L1 = 0.668 +- 0.236 (in-sample avg dev_std = 0.368)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.347
Model XAI F1 of binarized graphs for r=0.9 =  0.11854625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.213645
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.371
SUFF++ for r=0.9 class 0 = 0.74 +- 0.170 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1 = 0.838 +- 0.170 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 2 = 0.8 +- 0.170 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.873 +- 0.170 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.186 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.729
Model XAI F1 of binarized graphs for r=0.3 =  0.487975
Model XAI WIoU of binarized graphs for r=0.3 =  0.39953249999999996
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.741 +- 0.397 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 1 = 0.231 +- 0.397 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 2 = 0.712 +- 0.397 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all KL = 0.678 +- 0.397 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all L1 = 0.566 +- 0.321 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.889
Model XAI F1 of binarized graphs for r=0.6 =  0.50256875
Model XAI WIoU of binarized graphs for r=0.6 =  0.451945
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.48
NEC for r=0.6 class 0 = 0.684 +- 0.413 (in-sample avg dev_std = 0.572)
NEC for r=0.6 class 1 = 0.156 +- 0.413 (in-sample avg dev_std = 0.572)
NEC for r=0.6 class 2 = 0.644 +- 0.413 (in-sample avg dev_std = 0.572)
NEC for r=0.6 all KL = 0.602 +- 0.413 (in-sample avg dev_std = 0.572)
NEC for r=0.6 all L1 = 0.5 +- 0.323 (in-sample avg dev_std = 0.572)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.931
Model XAI F1 of binarized graphs for r=0.9 =  0.49546125
Model XAI WIoU of binarized graphs for r=0.9 =  0.45904125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.626 +- 0.402 (in-sample avg dev_std = 0.645)
NEC for r=0.9 class 1 = 0.143 +- 0.402 (in-sample avg dev_std = 0.645)
NEC for r=0.9 class 2 = 0.616 +- 0.402 (in-sample avg dev_std = 0.645)
NEC for r=0.9 all KL = 0.581 +- 0.402 (in-sample avg dev_std = 0.645)
NEC for r=0.9 all L1 = 0.466 +- 0.305 (in-sample avg dev_std = 0.645)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.45869125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.537
NEC for r=1.0 class 0 = 0.613 +- 0.406 (in-sample avg dev_std = 0.650)
NEC for r=1.0 class 1 = 0.145 +- 0.406 (in-sample avg dev_std = 0.650)
NEC for r=1.0 class 2 = 0.611 +- 0.406 (in-sample avg dev_std = 0.650)
NEC for r=1.0 all KL = 0.574 +- 0.406 (in-sample avg dev_std = 0.650)
NEC for r=1.0 all L1 = 0.461 +- 0.305 (in-sample avg dev_std = 0.650)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.887
Model XAI F1 of binarized graphs for r=0.3 =  0.41382874999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.42199749999999997
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.405
NEC for r=0.3 class 0 = 0.74 +- 0.383 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 1 = 0.243 +- 0.383 (in-sample avg dev_std = 0.403)
NEC for r=0.3 class 2 = 0.726 +- 0.383 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all KL = 0.622 +- 0.383 (in-sample avg dev_std = 0.403)
NEC for r=0.3 all L1 = 0.569 +- 0.306 (in-sample avg dev_std = 0.403)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  0.2993775
Model XAI WIoU of binarized graphs for r=0.6 =  0.42101374999999996
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.493
NEC for r=0.6 class 0 = 0.62 +- 0.337 (in-sample avg dev_std = 0.432)
NEC for r=0.6 class 1 = 0.168 +- 0.337 (in-sample avg dev_std = 0.432)
NEC for r=0.6 class 2 = 0.613 +- 0.337 (in-sample avg dev_std = 0.432)
NEC for r=0.6 all KL = 0.438 +- 0.337 (in-sample avg dev_std = 0.432)
NEC for r=0.6 all L1 = 0.466 +- 0.277 (in-sample avg dev_std = 0.432)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.24702625000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.42017625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.552 +- 0.294 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 1 = 0.145 +- 0.294 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 2 = 0.557 +- 0.294 (in-sample avg dev_std = 0.430)
NEC for r=0.9 all KL = 0.358 +- 0.294 (in-sample avg dev_std = 0.430)
NEC for r=0.9 all L1 = 0.417 +- 0.256 (in-sample avg dev_std = 0.430)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.811
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.42016624999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.529
NEC for r=1.0 class 0 = 0.557 +- 0.295 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 1 = 0.154 +- 0.295 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 2 = 0.551 +- 0.295 (in-sample avg dev_std = 0.423)
NEC for r=1.0 all KL = 0.359 +- 0.295 (in-sample avg dev_std = 0.423)
NEC for r=1.0 all L1 = 0.419 +- 0.259 (in-sample avg dev_std = 0.423)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.536
Model XAI F1 of binarized graphs for r=0.3 =  0.23915625
Model XAI WIoU of binarized graphs for r=0.3 =  0.23919625000000003
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.332
NEC for r=0.3 class 0 = 0.596 +- 0.333 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 1 = 0.43 +- 0.333 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 2 = 0.553 +- 0.333 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all KL = 0.522 +- 0.333 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all L1 = 0.526 +- 0.263 (in-sample avg dev_std = 0.329)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.409
Model XAI F1 of binarized graphs for r=0.6 =  0.14919374999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.21679875000000004
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.344
NEC for r=0.6 class 0 = 0.378 +- 0.181 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 1 = 0.203 +- 0.181 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 2 = 0.325 +- 0.181 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all KL = 0.21 +- 0.181 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all L1 = 0.301 +- 0.198 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.347
Model XAI F1 of binarized graphs for r=0.9 =  0.11854625000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.213645
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.337
NEC for r=0.9 class 0 = 0.342 +- 0.170 (in-sample avg dev_std = 0.137)
NEC for r=0.9 class 1 = 0.216 +- 0.170 (in-sample avg dev_std = 0.137)
NEC for r=0.9 class 2 = 0.274 +- 0.170 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all KL = 0.16 +- 0.170 (in-sample avg dev_std = 0.137)
NEC for r=0.9 all L1 = 0.277 +- 0.182 (in-sample avg dev_std = 0.137)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.357
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.21302125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.331
NEC for r=1.0 class 0 = 0.358 +- 0.185 (in-sample avg dev_std = 0.120)
NEC for r=1.0 class 1 = 0.22 +- 0.185 (in-sample avg dev_std = 0.120)
NEC for r=1.0 class 2 = 0.267 +- 0.185 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all KL = 0.162 +- 0.185 (in-sample avg dev_std = 0.120)
NEC for r=1.0 all L1 = 0.282 +- 0.192 (in-sample avg dev_std = 0.120)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.415, 0.515, 0.861, 1.0], 'all_L1': [0.478, 0.568, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.409, 0.606, 0.891, 1.0], 'all_L1': [0.559, 0.678, 0.899, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.388, 0.502, 0.851, 1.0], 'all_L1': [0.511, 0.596, 0.869, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.426, 0.635, 0.773, 1.0], 'all_L1': [0.556, 0.649, 0.788, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.341, 0.572, 0.902, 1.0], 'all_L1': [0.513, 0.658, 0.902, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.515, 0.553, 0.567, 0.558], 'all_L1': [0.502, 0.494, 0.478, 0.469]}), defaultdict(<class 'list'>, {'all_KL': [0.637, 0.609, 0.578, 0.569], 'all_L1': [0.533, 0.495, 0.462, 0.455]}), defaultdict(<class 'list'>, {'all_KL': [0.57, 0.56, 0.57, 0.586], 'all_L1': [0.503, 0.482, 0.463, 0.463]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.478, 0.522, 0.53], 'all_L1': [0.429, 0.441, 0.455, 0.455]}), defaultdict(<class 'list'>, {'all_KL': [0.678, 0.602, 0.581, 0.574], 'all_L1': [0.566, 0.5, 0.466, 0.461]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.37, 0.425, 0.779, 1.0], 'all_L1': [0.429, 0.463, 0.761, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.53, 0.715, 0.905, 1.0], 'all_L1': [0.579, 0.643, 0.841, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.552, 0.637, 0.881, 1.0], 'all_L1': [0.579, 0.587, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.689, 0.82, 0.882, 1.0], 'all_L1': [0.65, 0.72, 0.813, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.588, 0.681, 0.908, 1.0], 'all_L1': [0.639, 0.647, 0.85, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.529, 0.524, 0.551, 0.551], 'all_L1': [0.518, 0.512, 0.531, 0.529]}), defaultdict(<class 'list'>, {'all_KL': [0.558, 0.392, 0.33, 0.336], 'all_L1': [0.546, 0.448, 0.411, 0.409]}), defaultdict(<class 'list'>, {'all_KL': [0.535, 0.371, 0.382, 0.412], 'all_L1': [0.523, 0.431, 0.442, 0.461]}), defaultdict(<class 'list'>, {'all_KL': [0.457, 0.228, 0.226, 0.246], 'all_L1': [0.464, 0.33, 0.336, 0.344]}), defaultdict(<class 'list'>, {'all_KL': [0.622, 0.438, 0.358, 0.359], 'all_L1': [0.569, 0.466, 0.417, 0.419]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.332, 0.284, 0.596, 1.0], 'all_L1': [0.406, 0.35, 0.648, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.528, 0.704, 0.902, 1.0], 'all_L1': [0.576, 0.745, 0.878, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.559, 0.712, 0.939, 1.0], 'all_L1': [0.517, 0.62, 0.85, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.623, 0.729, 0.878, 1.0], 'all_L1': [0.55, 0.657, 0.857, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.61, 0.742, 0.873, 1.0], 'all_L1': [0.605, 0.668, 0.792, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.449, 0.529, 0.539, 0.54], 'all_L1': [0.447, 0.511, 0.521, 0.522]}), defaultdict(<class 'list'>, {'all_KL': [0.422, 0.308, 0.282, 0.283], 'all_L1': [0.409, 0.289, 0.261, 0.267]}), defaultdict(<class 'list'>, {'all_KL': [0.418, 0.243, 0.271, 0.282], 'all_L1': [0.48, 0.36, 0.382, 0.398]}), defaultdict(<class 'list'>, {'all_KL': [0.34, 0.157, 0.122, 0.116], 'all_L1': [0.433, 0.246, 0.197, 0.191]}), defaultdict(<class 'list'>, {'all_KL': [0.522, 0.21, 0.16, 0.162], 'all_L1': [0.526, 0.301, 0.277, 0.282]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.523 +- 0.031, 0.630 +- 0.041, 0.864 +- 0.041, 1.000 +- 0.000
suff++ class all_KL  =  0.396 +- 0.030, 0.566 +- 0.051, 0.856 +- 0.045, 1.000 +- 0.000
suff++_acc_int  =  0.506 +- 0.045, 0.643 +- 0.050, 0.852 +- 0.033
nec class all_L1  =  0.507 +- 0.045, 0.482 +- 0.022, 0.465 +- 0.008, 0.461 +- 0.005
nec class all_KL  =  0.577 +- 0.073, 0.560 +- 0.047, 0.564 +- 0.021, 0.563 +- 0.019
nec_acc_int  =  0.400 +- 0.024, 0.490 +- 0.015, 0.543 +- 0.010, 0.550 +- 0.012

Eval split val
suff++ class all_L1  =  0.575 +- 0.079, 0.612 +- 0.086, 0.816 +- 0.031, 1.000 +- 0.000
suff++ class all_KL  =  0.546 +- 0.103, 0.656 +- 0.130, 0.871 +- 0.047, 1.000 +- 0.000
suff++_acc_int  =  0.613 +- 0.088, 0.617 +- 0.093, 0.747 +- 0.099
nec class all_L1  =  0.524 +- 0.035, 0.437 +- 0.060, 0.427 +- 0.063, 0.432 +- 0.061
nec class all_KL  =  0.540 +- 0.053, 0.391 +- 0.097, 0.369 +- 0.105, 0.381 +- 0.101
nec_acc_int  =  0.402 +- 0.013, 0.446 +- 0.025, 0.474 +- 0.035, 0.485 +- 0.033

Eval split test
suff++ class all_L1  =  0.531 +- 0.069, 0.608 +- 0.135, 0.805 +- 0.084, 1.000 +- 0.000
suff++ class all_KL  =  0.530 +- 0.105, 0.634 +- 0.176, 0.838 +- 0.123, 1.000 +- 0.000
suff++_acc_int  =  0.399 +- 0.047, 0.371 +- 0.030, 0.383 +- 0.038
nec class all_L1  =  0.459 +- 0.041, 0.341 +- 0.092, 0.328 +- 0.114, 0.332 +- 0.116
nec class all_KL  =  0.430 +- 0.059, 0.289 +- 0.129, 0.275 +- 0.146, 0.277 +- 0.147
nec_acc_int  =  0.340 +- 0.009, 0.336 +- 0.011, 0.333 +- 0.018, 0.331 +- 0.022


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.515 +- 0.023, 0.556 +- 0.022, 0.664 +- 0.022, 0.730 +- 0.003
Faith. Armon (L1)= 		  =  0.513 +- 0.025, 0.545 +- 0.020, 0.604 +- 0.014, 0.631 +- 0.005
Faith. GMean (L1)= 	  =  0.514 +- 0.024, 0.551 +- 0.021, 0.633 +- 0.018, 0.679 +- 0.004
Faith. Aritm (KL)= 		  =  0.486 +- 0.026, 0.563 +- 0.030, 0.710 +- 0.033, 0.782 +- 0.009
Faith. Armon (KL)= 		  =  0.465 +- 0.017, 0.560 +- 0.031, 0.680 +- 0.030, 0.721 +- 0.016
Faith. GMean (KL)= 	  =  0.475 +- 0.020, 0.562 +- 0.030, 0.694 +- 0.031, 0.750 +- 0.013

Eval split val
Faith. Aritm (L1)= 		  =  0.550 +- 0.042, 0.525 +- 0.025, 0.622 +- 0.025, 0.716 +- 0.031
Faith. Armon (L1)= 		  =  0.545 +- 0.043, 0.501 +- 0.032, 0.557 +- 0.048, 0.601 +- 0.059
Faith. GMean (L1)= 	  =  0.547 +- 0.043, 0.513 +- 0.026, 0.588 +- 0.037, 0.656 +- 0.046
Faith. Aritm (KL)= 		  =  0.543 +- 0.052, 0.523 +- 0.032, 0.620 +- 0.037, 0.690 +- 0.050
Faith. Armon (KL)= 		  =  0.535 +- 0.055, 0.467 +- 0.060, 0.507 +- 0.092, 0.544 +- 0.103
Faith. GMean (KL)= 	  =  0.539 +- 0.053, 0.493 +- 0.041, 0.560 +- 0.067, 0.612 +- 0.081

Eval split test
Faith. Aritm (L1)= 		  =  0.495 +- 0.044, 0.475 +- 0.030, 0.566 +- 0.033, 0.666 +- 0.058
Faith. Armon (L1)= 		  =  0.490 +- 0.044, 0.412 +- 0.031, 0.448 +- 0.093, 0.487 +- 0.127
Faith. GMean (L1)= 	  =  0.492 +- 0.044, 0.442 +- 0.026, 0.502 +- 0.065, 0.568 +- 0.099
Faith. Aritm (KL)= 		  =  0.480 +- 0.056, 0.462 +- 0.034, 0.556 +- 0.041, 0.638 +- 0.074
Faith. Armon (KL)= 		  =  0.466 +- 0.059, 0.349 +- 0.056, 0.380 +- 0.125, 0.414 +- 0.170
Faith. GMean (KL)= 	  =  0.473 +- 0.057, 0.400 +- 0.041, 0.455 +- 0.090, 0.508 +- 0.135
Computed for split load_split = id



Completed in  0:30:24.138415  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size hard

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:31:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:31:43 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:31:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:31:59 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:01 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:32:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ACCURACY: 0.9067
Train Loss: 0.4357
ID Validation ACCURACY: 0.9160
ID Validation Loss: 0.4145
ID Test ACCURACY: 0.9107
ID Test Loss: 0.4298
OOD Validation ACCURACY: 0.7780
OOD Validation Loss: 1.3030
OOD Test ACCURACY: 0.3493
OOD Test Loss: 6.1444

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.8508
Train Loss: 0.5833
ID Validation ACCURACY: 0.8597
ID Validation Loss: 0.5646
ID Test ACCURACY: 0.8540
ID Test Loss: 0.5901
OOD Validation ACCURACY: 0.8430
OOD Validation Loss: 1.5695
OOD Test ACCURACY: 0.4797
OOD Test Loss: 7.7113

[0m[1;37mINFO[0m: [1mChartInfo 0.9107 0.3493 0.8540 0.4797 0.8597 0.8430[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.691
WIoU for r=0.3 = 0.595
F1 for r=0.6 = 0.654
WIoU for r=0.6 = 0.658
F1 for r=0.9 = 0.523
WIoU for r=0.9 = 0.630
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.625
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.576
WIoU for r=0.3 = 0.620
F1 for r=0.6 = 0.360
WIoU for r=0.6 = 0.518
F1 for r=0.9 = 0.259
WIoU for r=0.9 = 0.483
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.477
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.274
WIoU for r=0.3 = 0.213
F1 for r=0.6 = 0.179
WIoU for r=0.6 = 0.135
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.104
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.098


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  0.6911
Model XAI WIoU of binarized graphs for r=0.3 =  0.59549875
len(reference) = 786
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.441
SUFF++ for r=0.3 class 0 = 0.622 +- 0.286 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 class 1 = 0.747 +- 0.286 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 class 2 = 0.589 +- 0.286 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 all KL = 0.654 +- 0.286 (in-sample avg dev_std = 0.486)
SUFF++ for r=0.3 all L1 = 0.652 +- 0.229 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.764
Model XAI F1 of binarized graphs for r=0.6 =  0.6536700000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6583012500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.715
SUFF++ for r=0.6 class 0 = 0.625 +- 0.290 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 1 = 0.767 +- 0.290 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 2 = 0.726 +- 0.290 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all KL = 0.712 +- 0.290 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all L1 = 0.705 +- 0.219 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  0.5229362500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.63004125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.814
SUFF++ for r=0.9 class 0 = 0.833 +- 0.177 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 1 = 0.836 +- 0.177 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 class 2 = 0.893 +- 0.177 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all KL = 0.91 +- 0.177 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.9 all L1 = 0.854 +- 0.174 (in-sample avg dev_std = 0.221)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  0.5763174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.61993875
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.69
SUFF++ for r=0.3 class 0 = 0.557 +- 0.289 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 1 = 0.658 +- 0.289 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 class 2 = 0.603 +- 0.289 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all KL = 0.595 +- 0.289 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.3 all L1 = 0.605 +- 0.211 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  0.359515
Model XAI WIoU of binarized graphs for r=0.6 =  0.51834625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.692
SUFF++ for r=0.6 class 0 = 0.665 +- 0.208 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 1 = 0.709 +- 0.208 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 2 = 0.715 +- 0.208 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all KL = 0.727 +- 0.208 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all L1 = 0.696 +- 0.150 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  0.2593275
Model XAI WIoU of binarized graphs for r=0.9 =  0.48262625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.81
SUFF++ for r=0.9 class 0 = 0.865 +- 0.135 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 1 = 0.851 +- 0.135 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 2 = 0.877 +- 0.135 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all KL = 0.93 +- 0.135 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all L1 = 0.864 +- 0.117 (in-sample avg dev_std = 0.185)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  0.27433
Model XAI WIoU of binarized graphs for r=0.3 =  0.21265375000000003
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.491
SUFF++ for r=0.3 class 0 = 0.534 +- 0.245 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.3 class 1 = 0.531 +- 0.245 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.3 class 2 = 0.506 +- 0.245 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.3 all KL = 0.546 +- 0.245 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.159 (in-sample avg dev_std = 0.491)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.438
Model XAI F1 of binarized graphs for r=0.6 =  0.179315
Model XAI WIoU of binarized graphs for r=0.6 =  0.13471249999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.42
SUFF++ for r=0.6 class 0 = 0.73 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 class 1 = 0.707 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 class 2 = 0.747 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 all KL = 0.732 +- 0.304 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.6 all L1 = 0.728 +- 0.174 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.357
Model XAI F1 of binarized graphs for r=0.9 =  0.1244625
Model XAI WIoU of binarized graphs for r=0.9 =  0.10392625000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.444
SUFF++ for r=0.9 class 0 = 0.743 +- 0.207 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 class 1 = 0.766 +- 0.207 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 class 2 = 0.772 +- 0.207 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 all KL = 0.793 +- 0.207 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.9 all L1 = 0.76 +- 0.189 (in-sample avg dev_std = 0.379)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.548
Model XAI F1 of binarized graphs for r=0.3 =  0.6911
Model XAI WIoU of binarized graphs for r=0.3 =  0.59549875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.29
NEC for r=0.3 class 0 = 0.47 +- 0.303 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 1 = 0.466 +- 0.303 (in-sample avg dev_std = 0.449)
NEC for r=0.3 class 2 = 0.554 +- 0.303 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all KL = 0.507 +- 0.303 (in-sample avg dev_std = 0.449)
NEC for r=0.3 all L1 = 0.497 +- 0.231 (in-sample avg dev_std = 0.449)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.764
Model XAI F1 of binarized graphs for r=0.6 =  0.6536700000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.6583012500000001
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.393
NEC for r=0.6 class 0 = 0.594 +- 0.298 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 1 = 0.499 +- 0.298 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 2 = 0.599 +- 0.298 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all KL = 0.585 +- 0.298 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all L1 = 0.565 +- 0.196 (in-sample avg dev_std = 0.486)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  0.5229362500000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.63004125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.481
NEC for r=0.9 class 0 = 0.509 +- 0.268 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 1 = 0.436 +- 0.268 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 2 = 0.52 +- 0.268 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all KL = 0.434 +- 0.268 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all L1 = 0.489 +- 0.188 (in-sample avg dev_std = 0.472)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.62548
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.519
NEC for r=1.0 class 0 = 0.511 +- 0.267 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 1 = 0.405 +- 0.267 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 2 = 0.518 +- 0.267 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all KL = 0.415 +- 0.267 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all L1 = 0.479 +- 0.188 (in-sample avg dev_std = 0.475)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  0.5763174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.61993875
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.646 +- 0.254 (in-sample avg dev_std = 0.392)
NEC for r=0.3 class 1 = 0.532 +- 0.254 (in-sample avg dev_std = 0.392)
NEC for r=0.3 class 2 = 0.693 +- 0.254 (in-sample avg dev_std = 0.392)
NEC for r=0.3 all KL = 0.622 +- 0.254 (in-sample avg dev_std = 0.392)
NEC for r=0.3 all L1 = 0.623 +- 0.173 (in-sample avg dev_std = 0.392)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  0.359515
Model XAI WIoU of binarized graphs for r=0.6 =  0.51834625
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.442
NEC for r=0.6 class 0 = 0.425 +- 0.236 (in-sample avg dev_std = 0.310)
NEC for r=0.6 class 1 = 0.32 +- 0.236 (in-sample avg dev_std = 0.310)
NEC for r=0.6 class 2 = 0.45 +- 0.236 (in-sample avg dev_std = 0.310)
NEC for r=0.6 all KL = 0.31 +- 0.236 (in-sample avg dev_std = 0.310)
NEC for r=0.6 all L1 = 0.398 +- 0.222 (in-sample avg dev_std = 0.310)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  0.2593275
Model XAI WIoU of binarized graphs for r=0.9 =  0.48262625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.519
NEC for r=0.9 class 0 = 0.359 +- 0.190 (in-sample avg dev_std = 0.283)
NEC for r=0.9 class 1 = 0.3 +- 0.190 (in-sample avg dev_std = 0.283)
NEC for r=0.9 class 2 = 0.367 +- 0.190 (in-sample avg dev_std = 0.283)
NEC for r=0.9 all KL = 0.222 +- 0.190 (in-sample avg dev_std = 0.283)
NEC for r=0.9 all L1 = 0.342 +- 0.194 (in-sample avg dev_std = 0.283)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.821
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.47661625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.529
NEC for r=1.0 class 0 = 0.339 +- 0.171 (in-sample avg dev_std = 0.271)
NEC for r=1.0 class 1 = 0.27 +- 0.171 (in-sample avg dev_std = 0.271)
NEC for r=1.0 class 2 = 0.353 +- 0.171 (in-sample avg dev_std = 0.271)
NEC for r=1.0 all KL = 0.188 +- 0.171 (in-sample avg dev_std = 0.271)
NEC for r=1.0 all L1 = 0.321 +- 0.194 (in-sample avg dev_std = 0.271)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  0.27433
Model XAI WIoU of binarized graphs for r=0.3 =  0.21265375000000003
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.379
NEC for r=0.3 class 0 = 0.531 +- 0.321 (in-sample avg dev_std = 0.320)
NEC for r=0.3 class 1 = 0.434 +- 0.321 (in-sample avg dev_std = 0.320)
NEC for r=0.3 class 2 = 0.523 +- 0.321 (in-sample avg dev_std = 0.320)
NEC for r=0.3 all KL = 0.463 +- 0.321 (in-sample avg dev_std = 0.320)
NEC for r=0.3 all L1 = 0.496 +- 0.254 (in-sample avg dev_std = 0.320)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.438
Model XAI F1 of binarized graphs for r=0.6 =  0.179315
Model XAI WIoU of binarized graphs for r=0.6 =  0.13471249999999999
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.4
NEC for r=0.6 class 0 = 0.35 +- 0.349 (in-sample avg dev_std = 0.214)
NEC for r=0.6 class 1 = 0.339 +- 0.349 (in-sample avg dev_std = 0.214)
NEC for r=0.6 class 2 = 0.353 +- 0.349 (in-sample avg dev_std = 0.214)
NEC for r=0.6 all KL = 0.296 +- 0.349 (in-sample avg dev_std = 0.214)
NEC for r=0.6 all L1 = 0.347 +- 0.286 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.357
Model XAI F1 of binarized graphs for r=0.9 =  0.1244625
Model XAI WIoU of binarized graphs for r=0.9 =  0.10392625000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.395
NEC for r=0.9 class 0 = 0.297 +- 0.297 (in-sample avg dev_std = 0.245)
NEC for r=0.9 class 1 = 0.289 +- 0.297 (in-sample avg dev_std = 0.245)
NEC for r=0.9 class 2 = 0.285 +- 0.297 (in-sample avg dev_std = 0.245)
NEC for r=0.9 all KL = 0.243 +- 0.297 (in-sample avg dev_std = 0.245)
NEC for r=0.9 all L1 = 0.29 +- 0.266 (in-sample avg dev_std = 0.245)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.359
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.09828625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.395
NEC for r=1.0 class 0 = 0.28 +- 0.287 (in-sample avg dev_std = 0.245)
NEC for r=1.0 class 1 = 0.276 +- 0.287 (in-sample avg dev_std = 0.245)
NEC for r=1.0 class 2 = 0.259 +- 0.287 (in-sample avg dev_std = 0.245)
NEC for r=1.0 all KL = 0.229 +- 0.287 (in-sample avg dev_std = 0.245)
NEC for r=1.0 all L1 = 0.272 +- 0.266 (in-sample avg dev_std = 0.245)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:38:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:37 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:39 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:41 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:44 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:38:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:38:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 73...
[0m[1;37mINFO[0m: [1mCheckpoint 73: 
-----------------------------------
Train ACCURACY: 0.9268
Train Loss: 0.3716
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3587
ID Test ACCURACY: 0.9270
ID Test Loss: 0.3806
OOD Validation ACCURACY: 0.9070
OOD Validation Loss: 0.5365
OOD Test ACCURACY: 0.4853
OOD Test Loss: 3.0914

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9215
Train Loss: 0.3623
ID Validation ACCURACY: 0.9293
ID Validation Loss: 0.3515
ID Test ACCURACY: 0.9263
ID Test Loss: 0.3679
OOD Validation ACCURACY: 0.9147
OOD Validation Loss: 0.4576
OOD Test ACCURACY: 0.5323
OOD Test Loss: 3.4874

[0m[1;37mINFO[0m: [1mChartInfo 0.9270 0.4853 0.9263 0.5323 0.9293 0.9147[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.562
WIoU for r=0.3 = 0.442
F1 for r=0.6 = 0.619
WIoU for r=0.6 = 0.555
F1 for r=0.9 = 0.520
WIoU for r=0.9 = 0.541
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.536
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.460
WIoU for r=0.3 = 0.463
F1 for r=0.6 = 0.333
WIoU for r=0.6 = 0.441
F1 for r=0.9 = 0.254
WIoU for r=0.9 = 0.423
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.419
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.276
WIoU for r=0.3 = 0.249
F1 for r=0.6 = 0.166
WIoU for r=0.6 = 0.185
F1 for r=0.9 = 0.121
WIoU for r=0.9 = 0.166
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.162


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.387
Model XAI F1 of binarized graphs for r=0.3 =  0.56200875
Model XAI WIoU of binarized graphs for r=0.3 =  0.44155625
len(reference) = 775
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.353
SUFF++ for r=0.3 class 0 = 0.836 +- 0.212 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 1 = 0.891 +- 0.212 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 2 = 0.808 +- 0.212 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all KL = 0.871 +- 0.212 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all L1 = 0.844 +- 0.168 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  0.6193712499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.55532125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0 = 0.642 +- 0.267 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 class 1 = 0.79 +- 0.267 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 class 2 = 0.663 +- 0.267 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 all KL = 0.717 +- 0.267 (in-sample avg dev_std = 0.462)
SUFF++ for r=0.6 all L1 = 0.697 +- 0.195 (in-sample avg dev_std = 0.462)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  0.5203924999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5412724999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.797
SUFF++ for r=0.9 class 0 = 0.787 +- 0.191 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.811 +- 0.191 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.191 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.878 +- 0.191 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.182 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.673
Model XAI F1 of binarized graphs for r=0.3 =  0.46002125
Model XAI WIoU of binarized graphs for r=0.3 =  0.46255624999999995
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.62
SUFF++ for r=0.3 class 0 = 0.681 +- 0.253 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 1 = 0.816 +- 0.253 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 class 2 = 0.75 +- 0.253 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 all KL = 0.762 +- 0.253 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.3 all L1 = 0.749 +- 0.186 (in-sample avg dev_std = 0.448)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  0.33274750000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.44060625000000003
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.732
SUFF++ for r=0.6 class 0 = 0.635 +- 0.218 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 1 = 0.703 +- 0.218 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 class 2 = 0.678 +- 0.218 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all KL = 0.745 +- 0.218 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.6 all L1 = 0.672 +- 0.148 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  0.25439875
Model XAI WIoU of binarized graphs for r=0.9 =  0.42274
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.822
SUFF++ for r=0.9 class 0 = 0.829 +- 0.157 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 class 1 = 0.829 +- 0.157 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 class 2 = 0.79 +- 0.157 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 all KL = 0.9 +- 0.157 (in-sample avg dev_std = 0.218)
SUFF++ for r=0.9 all L1 = 0.817 +- 0.156 (in-sample avg dev_std = 0.218)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.471
Model XAI F1 of binarized graphs for r=0.3 =  0.27588
Model XAI WIoU of binarized graphs for r=0.3 =  0.24858375000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.576
SUFF++ for r=0.3 class 0 = 0.476 +- 0.256 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 class 1 = 0.577 +- 0.256 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 class 2 = 0.586 +- 0.256 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 all KL = 0.532 +- 0.256 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 all L1 = 0.545 +- 0.165 (in-sample avg dev_std = 0.542)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.466
Model XAI F1 of binarized graphs for r=0.6 =  0.16629375
Model XAI WIoU of binarized graphs for r=0.6 =  0.18503124999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.535
SUFF++ for r=0.6 class 0 = 0.628 +- 0.285 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 class 1 = 0.681 +- 0.285 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 class 2 = 0.731 +- 0.285 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all KL = 0.707 +- 0.285 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.6 all L1 = 0.679 +- 0.225 (in-sample avg dev_std = 0.381)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.549
Model XAI F1 of binarized graphs for r=0.9 =  0.1212425
Model XAI WIoU of binarized graphs for r=0.9 =  0.16552250000000002
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.552
SUFF++ for r=0.9 class 0 = 0.766 +- 0.204 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 class 1 = 0.815 +- 0.204 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 class 2 = 0.784 +- 0.204 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 all KL = 0.841 +- 0.204 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.9 all L1 = 0.789 +- 0.164 (in-sample avg dev_std = 0.327)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.39
Model XAI F1 of binarized graphs for r=0.3 =  0.56200875
Model XAI WIoU of binarized graphs for r=0.3 =  0.44155625
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.319
NEC for r=0.3 class 0 = 0.196 +- 0.249 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 1 = 0.166 +- 0.249 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 2 = 0.217 +- 0.249 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all KL = 0.162 +- 0.249 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all L1 = 0.193 +- 0.216 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  0.6193712499999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.55532125
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.406
NEC for r=0.6 class 0 = 0.513 +- 0.331 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 1 = 0.319 +- 0.331 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 2 = 0.559 +- 0.331 (in-sample avg dev_std = 0.438)
NEC for r=0.6 all KL = 0.459 +- 0.331 (in-sample avg dev_std = 0.438)
NEC for r=0.6 all L1 = 0.466 +- 0.252 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  0.5203924999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.5412724999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.487
NEC for r=0.9 class 0 = 0.55 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 1 = 0.345 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.9 class 2 = 0.561 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all KL = 0.449 +- 0.282 (in-sample avg dev_std = 0.485)
NEC for r=0.9 all L1 = 0.487 +- 0.207 (in-sample avg dev_std = 0.485)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.53596625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.561 +- 0.296 (in-sample avg dev_std = 0.518)
NEC for r=1.0 class 1 = 0.296 +- 0.296 (in-sample avg dev_std = 0.518)
NEC for r=1.0 class 2 = 0.534 +- 0.296 (in-sample avg dev_std = 0.518)
NEC for r=1.0 all KL = 0.456 +- 0.296 (in-sample avg dev_std = 0.518)
NEC for r=1.0 all L1 = 0.466 +- 0.221 (in-sample avg dev_std = 0.518)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.673
Model XAI F1 of binarized graphs for r=0.3 =  0.46002125
Model XAI WIoU of binarized graphs for r=0.3 =  0.46255624999999995
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.483 +- 0.344 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 1 = 0.235 +- 0.344 (in-sample avg dev_std = 0.290)
NEC for r=0.3 class 2 = 0.455 +- 0.344 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all KL = 0.367 +- 0.344 (in-sample avg dev_std = 0.290)
NEC for r=0.3 all L1 = 0.391 +- 0.301 (in-sample avg dev_std = 0.290)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  0.33274750000000003
Model XAI WIoU of binarized graphs for r=0.6 =  0.44060625000000003
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.475
NEC for r=0.6 class 0 = 0.473 +- 0.254 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 1 = 0.256 +- 0.254 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 2 = 0.497 +- 0.254 (in-sample avg dev_std = 0.344)
NEC for r=0.6 all KL = 0.319 +- 0.254 (in-sample avg dev_std = 0.344)
NEC for r=0.6 all L1 = 0.408 +- 0.193 (in-sample avg dev_std = 0.344)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  0.25439875
Model XAI WIoU of binarized graphs for r=0.9 =  0.42274
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.548
NEC for r=0.9 class 0 = 0.436 +- 0.265 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 1 = 0.239 +- 0.265 (in-sample avg dev_std = 0.346)
NEC for r=0.9 class 2 = 0.456 +- 0.265 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all KL = 0.272 +- 0.265 (in-sample avg dev_std = 0.346)
NEC for r=0.9 all L1 = 0.377 +- 0.183 (in-sample avg dev_std = 0.346)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.4191175
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.583
NEC for r=1.0 class 0 = 0.464 +- 0.287 (in-sample avg dev_std = 0.335)
NEC for r=1.0 class 1 = 0.253 +- 0.287 (in-sample avg dev_std = 0.335)
NEC for r=1.0 class 2 = 0.432 +- 0.287 (in-sample avg dev_std = 0.335)
NEC for r=1.0 all KL = 0.286 +- 0.287 (in-sample avg dev_std = 0.335)
NEC for r=1.0 all L1 = 0.383 +- 0.205 (in-sample avg dev_std = 0.335)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.471
Model XAI F1 of binarized graphs for r=0.3 =  0.27588
Model XAI WIoU of binarized graphs for r=0.3 =  0.24858375000000002
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.399 +- 0.331 (in-sample avg dev_std = 0.294)
NEC for r=0.3 class 1 = 0.299 +- 0.331 (in-sample avg dev_std = 0.294)
NEC for r=0.3 class 2 = 0.491 +- 0.331 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all KL = 0.343 +- 0.331 (in-sample avg dev_std = 0.294)
NEC for r=0.3 all L1 = 0.394 +- 0.230 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.468
Model XAI F1 of binarized graphs for r=0.6 =  0.16629375
Model XAI WIoU of binarized graphs for r=0.6 =  0.18503124999999998
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.385
NEC for r=0.6 class 0 = 0.358 +- 0.338 (in-sample avg dev_std = 0.276)
NEC for r=0.6 class 1 = 0.26 +- 0.338 (in-sample avg dev_std = 0.276)
NEC for r=0.6 class 2 = 0.404 +- 0.338 (in-sample avg dev_std = 0.276)
NEC for r=0.6 all KL = 0.287 +- 0.338 (in-sample avg dev_std = 0.276)
NEC for r=0.6 all L1 = 0.339 +- 0.282 (in-sample avg dev_std = 0.276)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.549
Model XAI F1 of binarized graphs for r=0.9 =  0.1212425
Model XAI WIoU of binarized graphs for r=0.9 =  0.16552250000000002
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.455
NEC for r=0.9 class 0 = 0.346 +- 0.290 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 1 = 0.236 +- 0.290 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 2 = 0.451 +- 0.290 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all KL = 0.291 +- 0.290 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all L1 = 0.342 +- 0.223 (in-sample avg dev_std = 0.368)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.498
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.16218875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.454
NEC for r=1.0 class 0 = 0.228 +- 0.218 (in-sample avg dev_std = 0.234)
NEC for r=1.0 class 1 = 0.195 +- 0.218 (in-sample avg dev_std = 0.234)
NEC for r=1.0 class 2 = 0.349 +- 0.218 (in-sample avg dev_std = 0.234)
NEC for r=1.0 all KL = 0.204 +- 0.218 (in-sample avg dev_std = 0.234)
NEC for r=1.0 all L1 = 0.255 +- 0.210 (in-sample avg dev_std = 0.234)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:44:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:44:44 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:44:55 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:44:57 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:44:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:45:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 152...
[0m[1;37mINFO[0m: [1mCheckpoint 152: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3483
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.3374
ID Test ACCURACY: 0.9317
ID Test Loss: 0.3536
OOD Validation ACCURACY: 0.9087
OOD Validation Loss: 0.4583
OOD Test ACCURACY: 0.5253
OOD Test Loss: 4.8854

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ACCURACY: 0.9257
Train Loss: 0.3584
ID Validation ACCURACY: 0.9320
ID Validation Loss: 0.3513
ID Test ACCURACY: 0.9287
ID Test Loss: 0.3601
OOD Validation ACCURACY: 0.9197
OOD Validation Loss: 0.5184
OOD Test ACCURACY: 0.8117
OOD Test Loss: 0.7350

[0m[1;37mINFO[0m: [1mChartInfo 0.9317 0.5253 0.9287 0.8117 0.9320 0.9197[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.639
WIoU for r=0.3 = 0.566
F1 for r=0.6 = 0.619
WIoU for r=0.6 = 0.650
F1 for r=0.9 = 0.516
WIoU for r=0.9 = 0.656
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.657
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.527
WIoU for r=0.3 = 0.524
F1 for r=0.6 = 0.348
WIoU for r=0.6 = 0.441
F1 for r=0.9 = 0.257
WIoU for r=0.9 = 0.431
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.430
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.292
WIoU for r=0.3 = 0.237
F1 for r=0.6 = 0.169
WIoU for r=0.6 = 0.143
F1 for r=0.9 = 0.122
WIoU for r=0.9 = 0.122
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.118


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.492
Model XAI F1 of binarized graphs for r=0.3 =  0.63944625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5655374999999999
len(reference) = 783
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.415
SUFF++ for r=0.3 class 0 = 0.78 +- 0.289 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 class 1 = 0.887 +- 0.289 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 class 2 = 0.782 +- 0.289 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 all KL = 0.796 +- 0.289 (in-sample avg dev_std = 0.408)
SUFF++ for r=0.3 all L1 = 0.816 +- 0.207 (in-sample avg dev_std = 0.408)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.711
Model XAI F1 of binarized graphs for r=0.6 =  0.61890125
Model XAI WIoU of binarized graphs for r=0.6 =  0.6497825
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.681
SUFF++ for r=0.6 class 0 = 0.693 +- 0.278 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 class 1 = 0.785 +- 0.278 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 class 2 = 0.724 +- 0.278 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 all KL = 0.718 +- 0.278 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 all L1 = 0.733 +- 0.202 (in-sample avg dev_std = 0.491)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.51583
Model XAI WIoU of binarized graphs for r=0.9 =  0.65631625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0 = 0.871 +- 0.139 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.865 +- 0.139 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.896 +- 0.139 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.929 +- 0.139 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.133 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.749
Model XAI F1 of binarized graphs for r=0.3 =  0.52741875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5239
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.679
SUFF++ for r=0.3 class 0 = 0.617 +- 0.292 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 1 = 0.779 +- 0.292 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 2 = 0.788 +- 0.292 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all KL = 0.697 +- 0.292 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all L1 = 0.727 +- 0.199 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  0.34756375000000006
Model XAI WIoU of binarized graphs for r=0.6 =  0.44100500000000004
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.739
SUFF++ for r=0.6 class 0 = 0.679 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 1 = 0.682 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 2 = 0.778 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all KL = 0.739 +- 0.237 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all L1 = 0.712 +- 0.169 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  0.256975
Model XAI WIoU of binarized graphs for r=0.9 =  0.4310875
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0 = 0.863 +- 0.149 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.84 +- 0.149 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.149 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.914 +- 0.149 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.859 +- 0.133 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.29161625
Model XAI WIoU of binarized graphs for r=0.3 =  0.23726875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.547 +- 0.207 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 1 = 0.66 +- 0.207 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 2 = 0.681 +- 0.207 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all KL = 0.697 +- 0.207 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all L1 = 0.628 +- 0.171 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.481
Model XAI F1 of binarized graphs for r=0.6 =  0.16861625
Model XAI WIoU of binarized graphs for r=0.6 =  0.14349125000000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.47
SUFF++ for r=0.6 class 0 = 0.664 +- 0.280 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 1 = 0.666 +- 0.280 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 class 2 = 0.807 +- 0.280 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all KL = 0.695 +- 0.280 (in-sample avg dev_std = 0.432)
SUFF++ for r=0.6 all L1 = 0.71 +- 0.215 (in-sample avg dev_std = 0.432)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.538
Model XAI F1 of binarized graphs for r=0.9 =  0.12228750000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.12171499999999998
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.501
SUFF++ for r=0.9 class 0 = 0.782 +- 0.175 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.798 +- 0.175 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.855 +- 0.175 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.871 +- 0.175 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.81 +- 0.160 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.486
Model XAI F1 of binarized graphs for r=0.3 =  0.63944625
Model XAI WIoU of binarized graphs for r=0.3 =  0.5655374999999999
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.316
NEC for r=0.3 class 0 = 0.293 +- 0.367 (in-sample avg dev_std = 0.278)
NEC for r=0.3 class 1 = 0.198 +- 0.367 (in-sample avg dev_std = 0.278)
NEC for r=0.3 class 2 = 0.303 +- 0.367 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all KL = 0.282 +- 0.367 (in-sample avg dev_std = 0.278)
NEC for r=0.3 all L1 = 0.266 +- 0.296 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.711
Model XAI F1 of binarized graphs for r=0.6 =  0.61890125
Model XAI WIoU of binarized graphs for r=0.6 =  0.6497825
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.388
NEC for r=0.6 class 0 = 0.571 +- 0.332 (in-sample avg dev_std = 0.519)
NEC for r=0.6 class 1 = 0.382 +- 0.332 (in-sample avg dev_std = 0.519)
NEC for r=0.6 class 2 = 0.578 +- 0.332 (in-sample avg dev_std = 0.519)
NEC for r=0.6 all KL = 0.554 +- 0.332 (in-sample avg dev_std = 0.519)
NEC for r=0.6 all L1 = 0.512 +- 0.244 (in-sample avg dev_std = 0.519)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.51583
Model XAI WIoU of binarized graphs for r=0.9 =  0.65631625
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.498
NEC for r=0.9 class 0 = 0.553 +- 0.288 (in-sample avg dev_std = 0.500)
NEC for r=0.9 class 1 = 0.354 +- 0.288 (in-sample avg dev_std = 0.500)
NEC for r=0.9 class 2 = 0.543 +- 0.288 (in-sample avg dev_std = 0.500)
NEC for r=0.9 all KL = 0.453 +- 0.288 (in-sample avg dev_std = 0.500)
NEC for r=0.9 all L1 = 0.485 +- 0.211 (in-sample avg dev_std = 0.500)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.6573187500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.565 +- 0.291 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 1 = 0.325 +- 0.291 (in-sample avg dev_std = 0.522)
NEC for r=1.0 class 2 = 0.542 +- 0.291 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all KL = 0.464 +- 0.291 (in-sample avg dev_std = 0.522)
NEC for r=1.0 all L1 = 0.48 +- 0.215 (in-sample avg dev_std = 0.522)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.749
Model XAI F1 of binarized graphs for r=0.3 =  0.52741875
Model XAI WIoU of binarized graphs for r=0.3 =  0.5239
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.55 +- 0.421 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 1 = 0.202 +- 0.421 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 2 = 0.582 +- 0.421 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all KL = 0.45 +- 0.421 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all L1 = 0.443 +- 0.350 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  0.34756375000000006
Model XAI WIoU of binarized graphs for r=0.6 =  0.44100500000000004
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.554 +- 0.370 (in-sample avg dev_std = 0.409)
NEC for r=0.6 class 1 = 0.171 +- 0.370 (in-sample avg dev_std = 0.409)
NEC for r=0.6 class 2 = 0.54 +- 0.370 (in-sample avg dev_std = 0.409)
NEC for r=0.6 all KL = 0.395 +- 0.370 (in-sample avg dev_std = 0.409)
NEC for r=0.6 all L1 = 0.421 +- 0.282 (in-sample avg dev_std = 0.409)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  0.256975
Model XAI WIoU of binarized graphs for r=0.9 =  0.4310875
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.536
NEC for r=0.9 class 0 = 0.478 +- 0.303 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 1 = 0.174 +- 0.303 (in-sample avg dev_std = 0.438)
NEC for r=0.9 class 2 = 0.466 +- 0.303 (in-sample avg dev_std = 0.438)
NEC for r=0.9 all KL = 0.332 +- 0.303 (in-sample avg dev_std = 0.438)
NEC for r=0.9 all L1 = 0.372 +- 0.239 (in-sample avg dev_std = 0.438)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.42984625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.58
NEC for r=1.0 class 0 = 0.529 +- 0.303 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 1 = 0.212 +- 0.303 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 2 = 0.489 +- 0.303 (in-sample avg dev_std = 0.451)
NEC for r=1.0 all KL = 0.361 +- 0.303 (in-sample avg dev_std = 0.451)
NEC for r=1.0 all L1 = 0.409 +- 0.231 (in-sample avg dev_std = 0.451)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.29161625
Model XAI WIoU of binarized graphs for r=0.3 =  0.23726875
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.353
NEC for r=0.3 class 0 = 0.462 +- 0.342 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1 = 0.275 +- 0.342 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 2 = 0.548 +- 0.342 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.368 +- 0.342 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.425 +- 0.288 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.481
Model XAI F1 of binarized graphs for r=0.6 =  0.16861625
Model XAI WIoU of binarized graphs for r=0.6 =  0.14349125000000001
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.378
NEC for r=0.6 class 0 = 0.371 +- 0.295 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 1 = 0.25 +- 0.295 (in-sample avg dev_std = 0.335)
NEC for r=0.6 class 2 = 0.377 +- 0.295 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all KL = 0.284 +- 0.295 (in-sample avg dev_std = 0.335)
NEC for r=0.6 all L1 = 0.331 +- 0.258 (in-sample avg dev_std = 0.335)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.538
Model XAI F1 of binarized graphs for r=0.9 =  0.12228750000000002
Model XAI WIoU of binarized graphs for r=0.9 =  0.12171499999999998
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.425
NEC for r=0.9 class 0 = 0.357 +- 0.285 (in-sample avg dev_std = 0.344)
NEC for r=0.9 class 1 = 0.267 +- 0.285 (in-sample avg dev_std = 0.344)
NEC for r=0.9 class 2 = 0.386 +- 0.285 (in-sample avg dev_std = 0.344)
NEC for r=0.9 all KL = 0.279 +- 0.285 (in-sample avg dev_std = 0.344)
NEC for r=0.9 all L1 = 0.335 +- 0.234 (in-sample avg dev_std = 0.344)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.529
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.1176525
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.431
NEC for r=1.0 class 0 = 0.411 +- 0.268 (in-sample avg dev_std = 0.311)
NEC for r=1.0 class 1 = 0.408 +- 0.268 (in-sample avg dev_std = 0.311)
NEC for r=1.0 class 2 = 0.41 +- 0.268 (in-sample avg dev_std = 0.311)
NEC for r=1.0 all KL = 0.349 +- 0.268 (in-sample avg dev_std = 0.311)
NEC for r=1.0 all L1 = 0.41 +- 0.216 (in-sample avg dev_std = 0.311)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:51:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:19 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:51:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 73...
[0m[1;37mINFO[0m: [1mCheckpoint 73: 
-----------------------------------
Train ACCURACY: 0.9245
Train Loss: 0.4191
ID Validation ACCURACY: 0.9333
ID Validation Loss: 0.4084
ID Test ACCURACY: 0.9257
ID Test Loss: 0.4239
OOD Validation ACCURACY: 0.8957
OOD Validation Loss: 0.5254
OOD Test ACCURACY: 0.5077
OOD Test Loss: 2.5942

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ACCURACY: 0.9233
Train Loss: 0.4017
ID Validation ACCURACY: 0.9287
ID Validation Loss: 0.3881
ID Test ACCURACY: 0.9240
ID Test Loss: 0.4049
OOD Validation ACCURACY: 0.9063
OOD Validation Loss: 0.6279
OOD Test ACCURACY: 0.5550
OOD Test Loss: 57.6877

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.5077 0.9240 0.5550 0.9287 0.9063[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.704
WIoU for r=0.3 = 0.620
F1 for r=0.6 = 0.645
WIoU for r=0.6 = 0.664
F1 for r=0.9 = 0.523
WIoU for r=0.9 = 0.646
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.640
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.548
WIoU for r=0.3 = 0.558
F1 for r=0.6 = 0.354
WIoU for r=0.6 = 0.458
F1 for r=0.9 = 0.259
WIoU for r=0.9 = 0.420
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.412
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.308
WIoU for r=0.3 = 0.228
F1 for r=0.6 = 0.178
WIoU for r=0.6 = 0.153
F1 for r=0.9 = 0.124
WIoU for r=0.9 = 0.131
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.126


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  0.7037737499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6197775
len(reference) = 784
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.439
SUFF++ for r=0.3 class 0 = 0.726 +- 0.273 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 class 1 = 0.821 +- 0.273 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 class 2 = 0.674 +- 0.273 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all KL = 0.754 +- 0.273 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.3 all L1 = 0.74 +- 0.209 (in-sample avg dev_std = 0.430)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  0.64529875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6644012499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.724
SUFF++ for r=0.6 class 0 = 0.668 +- 0.239 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 1 = 0.739 +- 0.239 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 class 2 = 0.751 +- 0.239 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all KL = 0.765 +- 0.239 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.6 all L1 = 0.719 +- 0.184 (in-sample avg dev_std = 0.428)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.836
Model XAI F1 of binarized graphs for r=0.9 =  0.52260875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6456274999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.828
SUFF++ for r=0.9 class 0 = 0.811 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1 = 0.836 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 2 = 0.865 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.899 +- 0.186 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.837 +- 0.172 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.81
Model XAI F1 of binarized graphs for r=0.3 =  0.547905
Model XAI WIoU of binarized graphs for r=0.3 =  0.5582075000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.695
SUFF++ for r=0.3 class 0 = 0.603 +- 0.256 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 1 = 0.728 +- 0.256 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 class 2 = 0.651 +- 0.256 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all KL = 0.684 +- 0.256 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.203 (in-sample avg dev_std = 0.488)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  0.3537475
Model XAI WIoU of binarized graphs for r=0.6 =  0.4575199999999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.723
SUFF++ for r=0.6 class 0 = 0.625 +- 0.169 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 class 1 = 0.621 +- 0.169 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 class 2 = 0.736 +- 0.169 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all KL = 0.775 +- 0.169 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all L1 = 0.66 +- 0.142 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  0.25878625
Model XAI WIoU of binarized graphs for r=0.9 =  0.42020625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0 = 0.786 +- 0.183 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 1 = 0.788 +- 0.183 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 2 = 0.803 +- 0.183 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all KL = 0.886 +- 0.183 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.163 (in-sample avg dev_std = 0.259)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.30786
Model XAI WIoU of binarized graphs for r=0.3 =  0.22769999999999999
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.57
SUFF++ for r=0.3 class 0 = 0.517 +- 0.188 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 1 = 0.637 +- 0.188 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 2 = 0.585 +- 0.188 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 all KL = 0.668 +- 0.188 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 all L1 = 0.58 +- 0.145 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.586
Model XAI F1 of binarized graphs for r=0.6 =  0.17795375
Model XAI WIoU of binarized graphs for r=0.6 =  0.15262375000000003
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.515
SUFF++ for r=0.6 class 0 = 0.638 +- 0.188 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 class 1 = 0.667 +- 0.188 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 class 2 = 0.733 +- 0.188 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all KL = 0.761 +- 0.188 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.6 all L1 = 0.678 +- 0.152 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.509
Model XAI F1 of binarized graphs for r=0.9 =  0.12435500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.13093375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.496
SUFF++ for r=0.9 class 0 = 0.78 +- 0.266 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 1 = 0.717 +- 0.266 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 2 = 0.842 +- 0.266 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all KL = 0.785 +- 0.266 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all L1 = 0.778 +- 0.151 (in-sample avg dev_std = 0.375)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.525
Model XAI F1 of binarized graphs for r=0.3 =  0.7037737499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6197775
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.335
NEC for r=0.3 class 0 = 0.441 +- 0.307 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 1 = 0.436 +- 0.307 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 2 = 0.502 +- 0.307 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all KL = 0.454 +- 0.307 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all L1 = 0.46 +- 0.245 (in-sample avg dev_std = 0.375)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.771
Model XAI F1 of binarized graphs for r=0.6 =  0.64529875
Model XAI WIoU of binarized graphs for r=0.6 =  0.6644012499999999
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.403
NEC for r=0.6 class 0 = 0.587 +- 0.272 (in-sample avg dev_std = 0.445)
NEC for r=0.6 class 1 = 0.498 +- 0.272 (in-sample avg dev_std = 0.445)
NEC for r=0.6 class 2 = 0.583 +- 0.272 (in-sample avg dev_std = 0.445)
NEC for r=0.6 all KL = 0.528 +- 0.272 (in-sample avg dev_std = 0.445)
NEC for r=0.6 all L1 = 0.557 +- 0.178 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.836
Model XAI F1 of binarized graphs for r=0.9 =  0.52260875
Model XAI WIoU of binarized graphs for r=0.9 =  0.6456274999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.496
NEC for r=0.9 class 0 = 0.507 +- 0.245 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 1 = 0.399 +- 0.245 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 2 = 0.515 +- 0.245 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all KL = 0.386 +- 0.245 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all L1 = 0.475 +- 0.176 (in-sample avg dev_std = 0.447)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.6399875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.531
NEC for r=1.0 class 0 = 0.519 +- 0.254 (in-sample avg dev_std = 0.448)
NEC for r=1.0 class 1 = 0.365 +- 0.254 (in-sample avg dev_std = 0.448)
NEC for r=1.0 class 2 = 0.497 +- 0.254 (in-sample avg dev_std = 0.448)
NEC for r=1.0 all KL = 0.377 +- 0.254 (in-sample avg dev_std = 0.448)
NEC for r=1.0 all L1 = 0.462 +- 0.189 (in-sample avg dev_std = 0.448)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.811
Model XAI F1 of binarized graphs for r=0.3 =  0.547905
Model XAI WIoU of binarized graphs for r=0.3 =  0.5582075000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.387
NEC for r=0.3 class 0 = 0.668 +- 0.344 (in-sample avg dev_std = 0.341)
NEC for r=0.3 class 1 = 0.314 +- 0.344 (in-sample avg dev_std = 0.341)
NEC for r=0.3 class 2 = 0.7 +- 0.344 (in-sample avg dev_std = 0.341)
NEC for r=0.3 all KL = 0.557 +- 0.344 (in-sample avg dev_std = 0.341)
NEC for r=0.3 all L1 = 0.559 +- 0.266 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  0.3537475
Model XAI WIoU of binarized graphs for r=0.6 =  0.4575199999999999
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.48
NEC for r=0.6 class 0 = 0.561 +- 0.272 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 1 = 0.261 +- 0.272 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 2 = 0.557 +- 0.272 (in-sample avg dev_std = 0.408)
NEC for r=0.6 all KL = 0.377 +- 0.272 (in-sample avg dev_std = 0.408)
NEC for r=0.6 all L1 = 0.459 +- 0.216 (in-sample avg dev_std = 0.408)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  0.25878625
Model XAI WIoU of binarized graphs for r=0.9 =  0.42020625
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.552
NEC for r=0.9 class 0 = 0.503 +- 0.232 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 1 = 0.247 +- 0.232 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 2 = 0.506 +- 0.232 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all KL = 0.321 +- 0.232 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all L1 = 0.418 +- 0.187 (in-sample avg dev_std = 0.443)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.41154375000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.574
NEC for r=1.0 class 0 = 0.495 +- 0.219 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 1 = 0.255 +- 0.219 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 2 = 0.453 +- 0.219 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all KL = 0.286 +- 0.219 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all L1 = 0.4 +- 0.192 (in-sample avg dev_std = 0.400)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.30786
Model XAI WIoU of binarized graphs for r=0.3 =  0.22769999999999999
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.586 +- 0.337 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 1 = 0.286 +- 0.337 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 2 = 0.639 +- 0.337 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all KL = 0.416 +- 0.337 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all L1 = 0.5 +- 0.258 (in-sample avg dev_std = 0.215)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.586
Model XAI F1 of binarized graphs for r=0.6 =  0.17795375
Model XAI WIoU of binarized graphs for r=0.6 =  0.15262375000000003
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.382
NEC for r=0.6 class 0 = 0.409 +- 0.229 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1 = 0.24 +- 0.229 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 2 = 0.377 +- 0.229 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.247 +- 0.229 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.341 +- 0.225 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.509
Model XAI F1 of binarized graphs for r=0.9 =  0.12435500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.13093375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.408
NEC for r=0.9 class 0 = 0.309 +- 0.243 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 1 = 0.278 +- 0.243 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 2 = 0.306 +- 0.243 (in-sample avg dev_std = 0.340)
NEC for r=0.9 all KL = 0.228 +- 0.243 (in-sample avg dev_std = 0.340)
NEC for r=0.9 all L1 = 0.298 +- 0.181 (in-sample avg dev_std = 0.340)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.505
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.12637625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.399
NEC for r=1.0 class 0 = 0.291 +- 0.128 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 1 = 0.257 +- 0.128 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 2 = 0.247 +- 0.128 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all KL = 0.138 +- 0.128 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all L1 = 0.265 +- 0.181 (in-sample avg dev_std = 0.192)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed Apr 17 22:57:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:26 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:42 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:45 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/17/2024 10:57:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9293
Train Loss: 0.3691
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.3634
ID Test ACCURACY: 0.9310
ID Test Loss: 0.3766
OOD Validation ACCURACY: 0.8987
OOD Validation Loss: 0.5162
OOD Test ACCURACY: 0.3797
OOD Test Loss: 16.5304

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9284
Train Loss: 0.3817
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.3761
ID Test ACCURACY: 0.9300
ID Test Loss: 0.3854
OOD Validation ACCURACY: 0.9173
OOD Validation Loss: 0.5604
OOD Test ACCURACY: 0.6487
OOD Test Loss: 1.9005

[0m[1;37mINFO[0m: [1mChartInfo 0.9310 0.3797 0.9300 0.6487 0.9360 0.9173[0mGOODMotif(3000)
Data example from id_val: Data(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1019,  973, 1008]))

Gold ratio (id_val) =  tensor(0.3486) +- tensor(0.1769)
F1 for r=0.3 = 0.523
WIoU for r=0.3 = 0.448
F1 for r=0.6 = 0.568
WIoU for r=0.6 = 0.564
F1 for r=0.9 = 0.511
WIoU for r=0.9 = 0.579
F1 for r=1.0 = 0.493
WIoU for r=1.0 = 0.580
GOODMotif(3000)
Data example from val: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from val: (tensor([0, 1, 2]), tensor([1025, 1009,  966]))

Gold ratio (val) =  tensor(0.1390) +- tensor(0.0663)
F1 for r=0.3 = 0.360
WIoU for r=0.3 = 0.410
F1 for r=0.6 = 0.280
WIoU for r=0.6 = 0.405
F1 for r=0.9 = 0.245
WIoU for r=0.9 = 0.397
F1 for r=1.0 = 0.238
WIoU for r=1.0 = 0.396
GOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.173
WIoU for r=0.3 = 0.136
F1 for r=0.6 = 0.138
WIoU for r=0.6 = 0.098
F1 for r=0.9 = 0.117
WIoU for r=0.9 = 0.081
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.078


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.46
Model XAI F1 of binarized graphs for r=0.3 =  0.52265125
Model XAI WIoU of binarized graphs for r=0.3 =  0.4481875
len(reference) = 769
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.392
SUFF++ for r=0.3 class 0 = 0.619 +- 0.202 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 class 1 = 0.674 +- 0.202 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 class 2 = 0.635 +- 0.202 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all KL = 0.757 +- 0.202 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.3 all L1 = 0.642 +- 0.150 (in-sample avg dev_std = 0.405)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.603
Model XAI F1 of binarized graphs for r=0.6 =  0.5680025000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.56400625
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.579
SUFF++ for r=0.6 class 0 = 0.725 +- 0.238 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 1 = 0.788 +- 0.238 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 2 = 0.696 +- 0.238 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all KL = 0.779 +- 0.238 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all L1 = 0.736 +- 0.175 (in-sample avg dev_std = 0.403)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  0.51085375
Model XAI WIoU of binarized graphs for r=0.9 =  0.57883
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.781
SUFF++ for r=0.9 class 0 = 0.841 +- 0.167 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 1 = 0.87 +- 0.167 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 class 2 = 0.883 +- 0.167 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all KL = 0.908 +- 0.167 (in-sample avg dev_std = 0.289)
SUFF++ for r=0.9 all L1 = 0.864 +- 0.149 (in-sample avg dev_std = 0.289)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  0.36016625
Model XAI WIoU of binarized graphs for r=0.3 =  0.4101725
len(reference) = 793
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0 = 0.614 +- 0.161 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 1 = 0.659 +- 0.161 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 class 2 = 0.652 +- 0.161 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 all KL = 0.754 +- 0.161 (in-sample avg dev_std = 0.424)
SUFF++ for r=0.3 all L1 = 0.642 +- 0.149 (in-sample avg dev_std = 0.424)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  0.28044
Model XAI WIoU of binarized graphs for r=0.6 =  0.40461125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.58
SUFF++ for r=0.6 class 0 = 0.687 +- 0.164 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 1 = 0.733 +- 0.164 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 class 2 = 0.699 +- 0.164 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all KL = 0.812 +- 0.164 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.6 all L1 = 0.706 +- 0.147 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  0.24480625
Model XAI WIoU of binarized graphs for r=0.9 =  0.3974525
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0 = 0.799 +- 0.177 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.832 +- 0.177 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.81 +- 0.177 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.874 +- 0.177 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.814 +- 0.138 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.363
Model XAI F1 of binarized graphs for r=0.3 =  0.17339624999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.13580499999999998
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.398
SUFF++ for r=0.3 class 0 = 0.571 +- 0.221 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 1 = 0.568 +- 0.221 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 2 = 0.63 +- 0.221 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all KL = 0.54 +- 0.221 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all L1 = 0.589 +- 0.140 (in-sample avg dev_std = 0.610)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.375
Model XAI F1 of binarized graphs for r=0.6 =  0.13769
Model XAI WIoU of binarized graphs for r=0.6 =  0.09834625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.386
SUFF++ for r=0.6 class 0 = 0.601 +- 0.316 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 1 = 0.653 +- 0.316 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 class 2 = 0.677 +- 0.316 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 all KL = 0.497 +- 0.316 (in-sample avg dev_std = 0.528)
SUFF++ for r=0.6 all L1 = 0.643 +- 0.187 (in-sample avg dev_std = 0.528)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.354
Model XAI F1 of binarized graphs for r=0.9 =  0.11681625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.08100000000000002
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.362
SUFF++ for r=0.9 class 0 = 0.866 +- 0.290 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 1 = 0.859 +- 0.290 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 2 = 0.863 +- 0.290 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all KL = 0.811 +- 0.290 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all L1 = 0.863 +- 0.158 (in-sample avg dev_std = 0.319)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.459
Model XAI F1 of binarized graphs for r=0.3 =  0.52265125
Model XAI WIoU of binarized graphs for r=0.3 =  0.4481875
len(reference) = 800
Effective ratio: 0.313 +- 0.011
Model Accuracy over intervened graphs for r=0.3 =  0.352
NEC for r=0.3 class 0 = 0.404 +- 0.262 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1 = 0.351 +- 0.262 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 2 = 0.401 +- 0.262 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.271 +- 0.262 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.386 +- 0.214 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.603
Model XAI F1 of binarized graphs for r=0.6 =  0.5680025000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.56400625
len(reference) = 800
Effective ratio: 0.613 +- 0.010
Model Accuracy over intervened graphs for r=0.6 =  0.418
NEC for r=0.6 class 0 = 0.434 +- 0.321 (in-sample avg dev_std = 0.400)
NEC for r=0.6 class 1 = 0.321 +- 0.321 (in-sample avg dev_std = 0.400)
NEC for r=0.6 class 2 = 0.459 +- 0.321 (in-sample avg dev_std = 0.400)
NEC for r=0.6 all KL = 0.376 +- 0.321 (in-sample avg dev_std = 0.400)
NEC for r=0.6 all L1 = 0.406 +- 0.248 (in-sample avg dev_std = 0.400)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  0.51085375
Model XAI WIoU of binarized graphs for r=0.9 =  0.57883
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.512
NEC for r=0.9 class 0 = 0.531 +- 0.303 (in-sample avg dev_std = 0.488)
NEC for r=0.9 class 1 = 0.362 +- 0.303 (in-sample avg dev_std = 0.488)
NEC for r=0.9 class 2 = 0.521 +- 0.303 (in-sample avg dev_std = 0.488)
NEC for r=0.9 all KL = 0.442 +- 0.303 (in-sample avg dev_std = 0.488)
NEC for r=0.9 all L1 = 0.473 +- 0.220 (in-sample avg dev_std = 0.488)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.938
Model XAI F1 of binarized graphs for r=1.0 =  0.49294499999999997
Model XAI WIoU of binarized graphs for r=1.0 =  0.5801612500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.573
NEC for r=1.0 class 0 = 0.552 +- 0.317 (in-sample avg dev_std = 0.523)
NEC for r=1.0 class 1 = 0.313 +- 0.317 (in-sample avg dev_std = 0.523)
NEC for r=1.0 class 2 = 0.559 +- 0.317 (in-sample avg dev_std = 0.523)
NEC for r=1.0 all KL = 0.474 +- 0.317 (in-sample avg dev_std = 0.523)
NEC for r=1.0 all L1 = 0.477 +- 0.224 (in-sample avg dev_std = 0.523)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.596
Model XAI F1 of binarized graphs for r=0.3 =  0.36016625
Model XAI WIoU of binarized graphs for r=0.3 =  0.4101725
len(reference) = 800
Effective ratio: 0.306 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.501 +- 0.297 (in-sample avg dev_std = 0.339)
NEC for r=0.3 class 1 = 0.34 +- 0.297 (in-sample avg dev_std = 0.339)
NEC for r=0.3 class 2 = 0.489 +- 0.297 (in-sample avg dev_std = 0.339)
NEC for r=0.3 all KL = 0.35 +- 0.297 (in-sample avg dev_std = 0.339)
NEC for r=0.3 all L1 = 0.443 +- 0.230 (in-sample avg dev_std = 0.339)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  0.28044
Model XAI WIoU of binarized graphs for r=0.6 =  0.40461125
len(reference) = 800
Effective ratio: 0.606 +- 0.005
Model Accuracy over intervened graphs for r=0.6 =  0.44
NEC for r=0.6 class 0 = 0.362 +- 0.200 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 1 = 0.289 +- 0.200 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 2 = 0.387 +- 0.200 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all KL = 0.232 +- 0.200 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all L1 = 0.346 +- 0.161 (in-sample avg dev_std = 0.342)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  0.24480625
Model XAI WIoU of binarized graphs for r=0.9 =  0.3974525
len(reference) = 800
Effective ratio: 0.905 +- 0.003
Model Accuracy over intervened graphs for r=0.9 =  0.51
NEC for r=0.9 class 0 = 0.321 +- 0.229 (in-sample avg dev_std = 0.306)
NEC for r=0.9 class 1 = 0.253 +- 0.229 (in-sample avg dev_std = 0.306)
NEC for r=0.9 class 2 = 0.379 +- 0.229 (in-sample avg dev_std = 0.306)
NEC for r=0.9 all KL = 0.218 +- 0.229 (in-sample avg dev_std = 0.306)
NEC for r=0.9 all L1 = 0.317 +- 0.200 (in-sample avg dev_std = 0.306)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.23826
Model XAI WIoU of binarized graphs for r=1.0 =  0.39593000000000006
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.557 +- 0.335 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 1 = 0.28 +- 0.335 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 2 = 0.53 +- 0.335 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all KL = 0.412 +- 0.335 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all L1 = 0.455 +- 0.246 (in-sample avg dev_std = 0.364)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.363
Model XAI F1 of binarized graphs for r=0.3 =  0.17339624999999997
Model XAI WIoU of binarized graphs for r=0.3 =  0.13580499999999998
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.317
NEC for r=0.3 class 0 = 0.239 +- 0.251 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 1 = 0.213 +- 0.251 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 2 = 0.229 +- 0.251 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all KL = 0.181 +- 0.251 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all L1 = 0.227 +- 0.220 (in-sample avg dev_std = 0.216)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.375
Model XAI F1 of binarized graphs for r=0.6 =  0.13769
Model XAI WIoU of binarized graphs for r=0.6 =  0.09834625
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.35
NEC for r=0.6 class 0 = 0.338 +- 0.378 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 1 = 0.289 +- 0.378 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 2 = 0.319 +- 0.378 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all KL = 0.348 +- 0.378 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all L1 = 0.315 +- 0.252 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.354
Model XAI F1 of binarized graphs for r=0.9 =  0.11681625000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.08100000000000002
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.321
NEC for r=0.9 class 0 = 0.27 +- 0.303 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 1 = 0.233 +- 0.303 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 2 = 0.237 +- 0.303 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all KL = 0.229 +- 0.303 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all L1 = 0.247 +- 0.310 (in-sample avg dev_std = 0.232)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.369
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.07761625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.331
NEC for r=1.0 class 0 = 0.37 +- 0.429 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 1 = 0.358 +- 0.429 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 2 = 0.378 +- 0.429 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all KL = 0.467 +- 0.429 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all L1 = 0.368 +- 0.334 (in-sample avg dev_std = 0.418)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.654, 0.712, 0.91, 1.0], 'all_L1': [0.652, 0.705, 0.854, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.871, 0.717, 0.878, 1.0], 'all_L1': [0.844, 0.697, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.796, 0.718, 0.929, 1.0], 'all_L1': [0.816, 0.733, 0.877, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.754, 0.765, 0.899, 1.0], 'all_L1': [0.74, 0.719, 0.837, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.757, 0.779, 0.908, 1.0], 'all_L1': [0.642, 0.736, 0.864, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.507, 0.585, 0.434, 0.415], 'all_L1': [0.497, 0.565, 0.489, 0.479]}), defaultdict(<class 'list'>, {'all_KL': [0.162, 0.459, 0.449, 0.456], 'all_L1': [0.193, 0.466, 0.487, 0.466]}), defaultdict(<class 'list'>, {'all_KL': [0.282, 0.554, 0.453, 0.464], 'all_L1': [0.266, 0.512, 0.485, 0.48]}), defaultdict(<class 'list'>, {'all_KL': [0.454, 0.528, 0.386, 0.377], 'all_L1': [0.46, 0.557, 0.475, 0.462]}), defaultdict(<class 'list'>, {'all_KL': [0.271, 0.376, 0.442, 0.474], 'all_L1': [0.386, 0.406, 0.473, 0.477]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.595, 0.727, 0.93, 1.0], 'all_L1': [0.605, 0.696, 0.864, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.762, 0.745, 0.9, 1.0], 'all_L1': [0.749, 0.672, 0.817, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.697, 0.739, 0.914, 1.0], 'all_L1': [0.727, 0.712, 0.859, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.684, 0.775, 0.886, 1.0], 'all_L1': [0.661, 0.66, 0.792, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.754, 0.812, 0.874, 1.0], 'all_L1': [0.642, 0.706, 0.814, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.622, 0.31, 0.222, 0.188], 'all_L1': [0.623, 0.398, 0.342, 0.321]}), defaultdict(<class 'list'>, {'all_KL': [0.367, 0.319, 0.272, 0.286], 'all_L1': [0.391, 0.408, 0.377, 0.383]}), defaultdict(<class 'list'>, {'all_KL': [0.45, 0.395, 0.332, 0.361], 'all_L1': [0.443, 0.421, 0.372, 0.409]}), defaultdict(<class 'list'>, {'all_KL': [0.557, 0.377, 0.321, 0.286], 'all_L1': [0.559, 0.459, 0.418, 0.4]}), defaultdict(<class 'list'>, {'all_KL': [0.35, 0.232, 0.218, 0.412], 'all_L1': [0.443, 0.346, 0.317, 0.455]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.546, 0.732, 0.793, 1.0], 'all_L1': [0.524, 0.728, 0.76, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.532, 0.707, 0.841, 1.0], 'all_L1': [0.545, 0.679, 0.789, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.697, 0.695, 0.871, 1.0], 'all_L1': [0.628, 0.71, 0.81, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.668, 0.761, 0.785, 1.0], 'all_L1': [0.58, 0.678, 0.778, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.54, 0.497, 0.811, 1.0], 'all_L1': [0.589, 0.643, 0.863, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.463, 0.296, 0.243, 0.229], 'all_L1': [0.496, 0.347, 0.29, 0.272]}), defaultdict(<class 'list'>, {'all_KL': [0.343, 0.287, 0.291, 0.204], 'all_L1': [0.394, 0.339, 0.342, 0.255]}), defaultdict(<class 'list'>, {'all_KL': [0.368, 0.284, 0.279, 0.349], 'all_L1': [0.425, 0.331, 0.335, 0.41]}), defaultdict(<class 'list'>, {'all_KL': [0.416, 0.247, 0.228, 0.138], 'all_L1': [0.5, 0.341, 0.298, 0.265]}), defaultdict(<class 'list'>, {'all_KL': [0.181, 0.348, 0.229, 0.467], 'all_L1': [0.227, 0.315, 0.247, 0.368]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.739 +- 0.082, 0.718 +- 0.015, 0.850 +- 0.021, 1.000 +- 0.000
suff++ class all_KL  =  0.766 +- 0.070, 0.738 +- 0.028, 0.905 +- 0.017, 1.000 +- 0.000
suff++_acc_int  =  0.408 +- 0.033, 0.667 +- 0.054, 0.806 +- 0.016
nec class all_L1  =  0.360 +- 0.115, 0.501 +- 0.059, 0.482 +- 0.007, 0.473 +- 0.007
nec class all_KL  =  0.335 +- 0.127, 0.500 +- 0.075, 0.433 +- 0.024, 0.437 +- 0.036
nec_acc_int  =  0.322 +- 0.021, 0.402 +- 0.011, 0.495 +- 0.011, 0.541 +- 0.018

Eval split val
suff++ class all_L1  =  0.677 +- 0.054, 0.689 +- 0.020, 0.829 +- 0.028, 1.000 +- 0.000
suff++ class all_KL  =  0.698 +- 0.060, 0.760 +- 0.031, 0.901 +- 0.020, 1.000 +- 0.000
suff++_acc_int  =  0.649 +- 0.052, 0.693 +- 0.059, 0.793 +- 0.055
nec class all_L1  =  0.492 +- 0.086, 0.406 +- 0.037, 0.365 +- 0.034, 0.394 +- 0.043
nec class all_KL  =  0.469 +- 0.106, 0.327 +- 0.057, 0.273 +- 0.048, 0.307 +- 0.076
nec_acc_int  =  0.357 +- 0.015, 0.460 +- 0.017, 0.533 +- 0.016, 0.562 +- 0.022

Eval split test
suff++ class all_L1  =  0.573 +- 0.036, 0.688 +- 0.029, 0.800 +- 0.035, 1.000 +- 0.000
suff++ class all_KL  =  0.597 +- 0.071, 0.678 +- 0.093, 0.820 +- 0.032, 1.000 +- 0.000
suff++_acc_int  =  0.519 +- 0.068, 0.465 +- 0.056, 0.471 +- 0.064
nec class all_L1  =  0.408 +- 0.099, 0.335 +- 0.011, 0.302 +- 0.034, 0.314 +- 0.063
nec class all_KL  =  0.354 +- 0.096, 0.292 +- 0.032, 0.254 +- 0.026, 0.277 +- 0.117
nec_acc_int  =  0.348 +- 0.020, 0.379 +- 0.016, 0.401 +- 0.045, 0.402 +- 0.042


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.550 +- 0.033, 0.610 +- 0.028, 0.666 +- 0.011, 0.736 +- 0.004
Faith. Armon (L1)= 		  =  0.466 +- 0.097, 0.588 +- 0.041, 0.615 +- 0.007, 0.642 +- 0.007
Faith. GMean (L1)= 	  =  0.504 +- 0.067, 0.599 +- 0.034, 0.640 +- 0.009, 0.688 +- 0.005
Faith. Aritm (KL)= 		  =  0.551 +- 0.036, 0.619 +- 0.030, 0.669 +- 0.016, 0.719 +- 0.018
Faith. Armon (KL)= 		  =  0.445 +- 0.112, 0.592 +- 0.051, 0.585 +- 0.024, 0.608 +- 0.036
Faith. GMean (KL)= 	  =  0.493 +- 0.079, 0.605 +- 0.041, 0.626 +- 0.020, 0.661 +- 0.028

Eval split val
Faith. Aritm (L1)= 		  =  0.584 +- 0.026, 0.548 +- 0.014, 0.597 +- 0.017, 0.697 +- 0.022
Faith. Armon (L1)= 		  =  0.562 +- 0.041, 0.510 +- 0.026, 0.506 +- 0.031, 0.563 +- 0.045
Faith. GMean (L1)= 	  =  0.573 +- 0.033, 0.528 +- 0.020, 0.549 +- 0.023, 0.626 +- 0.035
Faith. Aritm (KL)= 		  =  0.584 +- 0.026, 0.543 +- 0.024, 0.587 +- 0.026, 0.653 +- 0.038
Faith. Armon (KL)= 		  =  0.549 +- 0.056, 0.453 +- 0.056, 0.417 +- 0.056, 0.464 +- 0.091
Faith. GMean (KL)= 	  =  0.566 +- 0.041, 0.495 +- 0.041, 0.494 +- 0.044, 0.549 +- 0.071

Eval split test
Faith. Aritm (L1)= 		  =  0.491 +- 0.048, 0.511 +- 0.019, 0.551 +- 0.018, 0.657 +- 0.031
Faith. Armon (L1)= 		  =  0.468 +- 0.075, 0.450 +- 0.015, 0.437 +- 0.035, 0.475 +- 0.071
Faith. GMean (L1)= 	  =  0.479 +- 0.062, 0.480 +- 0.017, 0.491 +- 0.025, 0.558 +- 0.055
Faith. Aritm (KL)= 		  =  0.475 +- 0.068, 0.485 +- 0.032, 0.537 +- 0.028, 0.639 +- 0.058
Faith. Armon (KL)= 		  =  0.437 +- 0.089, 0.403 +- 0.016, 0.388 +- 0.033, 0.422 +- 0.139
Faith. GMean (KL)= 	  =  0.455 +- 0.079, 0.442 +- 0.017, 0.456 +- 0.031, 0.515 +- 0.110
Computed for split load_split = id



Completed in  0:31:52.318191  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size anneal
DONE all :)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 11:46:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:14 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 11:46:15 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 169...
[0m[1;37mINFO[0m: [1mCheckpoint 169: 
-----------------------------------
Train ACCURACY: 0.9590
Train Loss: 0.1317
ID Validation ACCURACY: 0.8503
ID Validation Loss: 0.4872
ID Test ACCURACY: 0.8486
ID Test Loss: 0.4811
OOD Validation ACCURACY: 0.8050
OOD Validation Loss: 0.6386
OOD Test ACCURACY: 0.4063
OOD Test Loss: 3.3602

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9512
Train Loss: 0.1469
ID Validation ACCURACY: 0.8397
ID Validation Loss: 0.5150
ID Test ACCURACY: 0.8423
ID Test Loss: 0.5006
OOD Validation ACCURACY: 0.8247
OOD Validation Loss: 0.5858
OOD Test ACCURACY: 0.4470
OOD Test Loss: 2.9775

[0m[1;37mINFO[0m: [1mChartInfo 0.8486 0.4063 0.8423 0.4470 0.8397 0.8247[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.611 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 1 = 0.597 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 2 = 0.585 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 3 = 0.61 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 4 = 0.585 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 5 = 0.589 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 6 = 0.614 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 7 = 0.596 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 8 = 0.608 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 class 9 = 0.604 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 all KL = 0.76 +- 0.137 (in-sample avg dev_std = 0.310)
SUFF++ for r=0.3 all L1 = 0.6 +- 0.100 (in-sample avg dev_std = 0.310)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.124
SUFF++ for r=0.6 class 0 = 0.591 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 1 = 0.635 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 2 = 0.619 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 3 = 0.61 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 4 = 0.591 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 5 = 0.611 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 6 = 0.605 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 7 = 0.584 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 8 = 0.576 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 class 9 = 0.574 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 all KL = 0.747 +- 0.197 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.6 all L1 = 0.6 +- 0.165 (in-sample avg dev_std = 0.137)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.521
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.475
SUFF++ for r=0.9 class 0 = 0.845 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1 = 0.736 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 2 = 0.753 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 3 = 0.727 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 4 = 0.73 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 5 = 0.696 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 6 = 0.69 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 7 = 0.784 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 8 = 0.706 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 9 = 0.702 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.829 +- 0.183 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.738 +- 0.178 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.643 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 1 = 0.603 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 2 = 0.629 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 3 = 0.636 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 4 = 0.636 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 5 = 0.628 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 6 = 0.626 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 7 = 0.631 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 8 = 0.643 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 class 9 = 0.612 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 all KL = 0.801 +- 0.115 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.3 all L1 = 0.628 +- 0.093 (in-sample avg dev_std = 0.277)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.126
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.105
SUFF++ for r=0.6 class 0 = 0.574 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 1 = 0.625 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 2 = 0.612 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 3 = 0.617 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 4 = 0.587 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 5 = 0.603 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 6 = 0.602 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 7 = 0.594 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 8 = 0.576 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 class 9 = 0.55 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 all KL = 0.735 +- 0.206 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.6 all L1 = 0.594 +- 0.170 (in-sample avg dev_std = 0.133)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.506
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.466
SUFF++ for r=0.9 class 0 = 0.813 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 1 = 0.76 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 2 = 0.797 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 3 = 0.736 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 4 = 0.748 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 5 = 0.724 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 6 = 0.711 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 7 = 0.829 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 8 = 0.737 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 class 9 = 0.703 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all KL = 0.847 +- 0.169 (in-sample avg dev_std = 0.237)
SUFF++ for r=0.9 all L1 = 0.756 +- 0.176 (in-sample avg dev_std = 0.237)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.673 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 1 = 0.595 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 2 = 0.627 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 3 = 0.655 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 4 = 0.647 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 5 = 0.637 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 6 = 0.64 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 7 = 0.634 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 8 = 0.627 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 class 9 = 0.636 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 all KL = 0.812 +- 0.112 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.3 all L1 = 0.637 +- 0.095 (in-sample avg dev_std = 0.270)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.142
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.126
SUFF++ for r=0.6 class 0 = 0.655 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 1 = 0.615 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 2 = 0.611 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 3 = 0.613 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 4 = 0.592 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 5 = 0.615 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 6 = 0.599 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 7 = 0.628 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 8 = 0.584 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 9 = 0.571 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 all KL = 0.747 +- 0.197 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 all L1 = 0.609 +- 0.169 (in-sample avg dev_std = 0.127)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.295
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.286
SUFF++ for r=0.9 class 0 = 0.771 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 1 = 0.746 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 2 = 0.811 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 3 = 0.763 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 4 = 0.784 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 5 = 0.77 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 6 = 0.728 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 7 = 0.802 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 8 = 0.715 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 class 9 = 0.739 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all KL = 0.88 +- 0.126 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.147 (in-sample avg dev_std = 0.205)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.315 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1 = 0.322 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 2 = 0.322 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 3 = 0.327 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 4 = 0.349 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 5 = 0.349 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 6 = 0.306 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 7 = 0.346 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 8 = 0.325 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 9 = 0.355 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.155 +- 0.114 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.331 +- 0.105 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
NEC for r=0.6 class 0 = 0.409 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 1 = 0.37 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 2 = 0.363 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 3 = 0.39 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 4 = 0.395 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 5 = 0.396 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 6 = 0.402 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 7 = 0.367 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 8 = 0.408 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 9 = 0.415 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 all KL = 0.239 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.6 all L1 = 0.391 +- 0.123 (in-sample avg dev_std = 0.239)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.521
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.363
NEC for r=0.9 class 0 = 0.324 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 1 = 0.478 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 2 = 0.434 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 3 = 0.517 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 4 = 0.509 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 5 = 0.521 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 6 = 0.484 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 7 = 0.412 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 8 = 0.545 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 class 9 = 0.52 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 all KL = 0.48 +- 0.231 (in-sample avg dev_std = 0.366)
NEC for r=0.9 all L1 = 0.473 +- 0.185 (in-sample avg dev_std = 0.366)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.658
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.548
NEC for r=1.0 class 0 = 0.18 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 1 = 0.289 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 2 = 0.411 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 3 = 0.515 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 4 = 0.408 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 5 = 0.511 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 6 = 0.429 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 7 = 0.345 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 8 = 0.472 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 9 = 0.494 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 all KL = 0.445 +- 0.279 (in-sample avg dev_std = 0.368)
NEC for r=1.0 all L1 = 0.402 +- 0.235 (in-sample avg dev_std = 0.368)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.091
NEC for r=0.3 class 0 = 0.301 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 1 = 0.318 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 2 = 0.313 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 3 = 0.293 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 4 = 0.315 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 5 = 0.316 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 6 = 0.33 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 7 = 0.316 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 8 = 0.303 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 class 9 = 0.314 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 all KL = 0.128 +- 0.090 (in-sample avg dev_std = 0.175)
NEC for r=0.3 all L1 = 0.312 +- 0.098 (in-sample avg dev_std = 0.175)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.126
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.114
NEC for r=0.6 class 0 = 0.399 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 1 = 0.358 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 2 = 0.373 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 3 = 0.361 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 4 = 0.389 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 5 = 0.391 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 6 = 0.406 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 7 = 0.371 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 8 = 0.42 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 9 = 0.418 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all KL = 0.241 +- 0.150 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all L1 = 0.388 +- 0.124 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.506
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.375
NEC for r=0.9 class 0 = 0.319 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 1 = 0.458 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 2 = 0.325 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 3 = 0.487 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 4 = 0.467 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 5 = 0.504 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 6 = 0.505 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 7 = 0.359 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 8 = 0.5 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 class 9 = 0.518 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 all KL = 0.438 +- 0.234 (in-sample avg dev_std = 0.350)
NEC for r=0.9 all L1 = 0.444 +- 0.199 (in-sample avg dev_std = 0.350)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.642
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.546
NEC for r=1.0 class 0 = 0.258 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 1 = 0.207 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 2 = 0.355 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 3 = 0.53 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 4 = 0.358 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 5 = 0.507 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 6 = 0.481 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 7 = 0.317 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 8 = 0.465 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 9 = 0.484 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all KL = 0.424 +- 0.274 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all L1 = 0.393 +- 0.241 (in-sample avg dev_std = 0.360)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.281 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 1 = 0.33 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 2 = 0.305 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 3 = 0.288 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 4 = 0.311 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 5 = 0.284 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 6 = 0.329 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 7 = 0.279 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 8 = 0.329 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 9 = 0.322 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all KL = 0.12 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all L1 = 0.306 +- 0.099 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.142
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.131
NEC for r=0.6 class 0 = 0.345 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1 = 0.388 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 2 = 0.357 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 3 = 0.371 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 4 = 0.393 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 5 = 0.368 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 6 = 0.403 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 7 = 0.372 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 8 = 0.402 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 9 = 0.404 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.228 +- 0.135 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.38 +- 0.121 (in-sample avg dev_std = 0.237)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.295
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.241
NEC for r=0.9 class 0 = 0.421 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 1 = 0.45 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 2 = 0.348 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 3 = 0.425 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 4 = 0.368 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 5 = 0.43 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 6 = 0.47 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 7 = 0.39 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 8 = 0.474 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 class 9 = 0.479 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 all KL = 0.353 +- 0.207 (in-sample avg dev_std = 0.314)
NEC for r=0.9 all L1 = 0.425 +- 0.177 (in-sample avg dev_std = 0.314)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.296
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.274
NEC for r=1.0 class 0 = 0.477 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 1 = 0.485 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 2 = 0.362 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 3 = 0.474 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 4 = 0.383 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 5 = 0.464 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 6 = 0.517 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 7 = 0.392 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 8 = 0.491 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 class 9 = 0.485 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all KL = 0.418 +- 0.240 (in-sample avg dev_std = 0.347)
NEC for r=1.0 all L1 = 0.453 +- 0.192 (in-sample avg dev_std = 0.347)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 12:07:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:41 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:07:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9541
Train Loss: 0.1409
ID Validation ACCURACY: 0.8577
ID Validation Loss: 0.4648
ID Test ACCURACY: 0.8544
ID Test Loss: 0.4642
OOD Validation ACCURACY: 0.8204
OOD Validation Loss: 0.6094
OOD Test ACCURACY: 0.4389
OOD Test Loss: 3.9847

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.8858
Train Loss: 0.3337
ID Validation ACCURACY: 0.8416
ID Validation Loss: 0.4784
ID Test ACCURACY: 0.8420
ID Test Loss: 0.4720
OOD Validation ACCURACY: 0.8317
OOD Validation Loss: 0.5210
OOD Test ACCURACY: 0.6044
OOD Test Loss: 1.4900

[0m[1;37mINFO[0m: [1mChartInfo 0.8544 0.4389 0.8420 0.6044 0.8416 0.8317[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.113
SUFF++ for r=0.3 class 0 = 0.694 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 1 = 0.691 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 2 = 0.705 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 3 = 0.703 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 4 = 0.686 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 5 = 0.692 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 6 = 0.703 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 7 = 0.687 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 8 = 0.699 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 class 9 = 0.673 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 all KL = 0.874 +- 0.086 (in-sample avg dev_std = 0.210)
SUFF++ for r=0.3 all L1 = 0.694 +- 0.087 (in-sample avg dev_std = 0.210)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.097
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.1
SUFF++ for r=0.6 class 0 = 0.673 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 1 = 0.725 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 2 = 0.672 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 3 = 0.686 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 4 = 0.681 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 5 = 0.635 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 6 = 0.678 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 7 = 0.671 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 8 = 0.638 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 class 9 = 0.634 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 all KL = 0.833 +- 0.154 (in-sample avg dev_std = 0.110)
SUFF++ for r=0.6 all L1 = 0.671 +- 0.160 (in-sample avg dev_std = 0.110)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.504
SUFF++ for r=0.9 class 0 = 0.835 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 1 = 0.811 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 2 = 0.724 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 3 = 0.756 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 4 = 0.745 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 5 = 0.696 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 6 = 0.692 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 7 = 0.726 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 8 = 0.731 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 9 = 0.71 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all KL = 0.849 +- 0.162 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all L1 = 0.745 +- 0.166 (in-sample avg dev_std = 0.238)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.721 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 1 = 0.713 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 2 = 0.715 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 3 = 0.727 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 4 = 0.712 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 5 = 0.709 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 6 = 0.71 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 7 = 0.712 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 8 = 0.722 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 class 9 = 0.705 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 all KL = 0.894 +- 0.067 (in-sample avg dev_std = 0.190)
SUFF++ for r=0.3 all L1 = 0.714 +- 0.078 (in-sample avg dev_std = 0.190)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.097
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.087
SUFF++ for r=0.6 class 0 = 0.689 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 1 = 0.691 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 2 = 0.69 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 3 = 0.7 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 4 = 0.671 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 5 = 0.664 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 6 = 0.69 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 7 = 0.677 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 8 = 0.677 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 9 = 0.681 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 all KL = 0.845 +- 0.144 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 all L1 = 0.683 +- 0.154 (in-sample avg dev_std = 0.107)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.549
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.515
SUFF++ for r=0.9 class 0 = 0.806 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 1 = 0.89 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 2 = 0.776 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 3 = 0.756 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 4 = 0.762 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 5 = 0.73 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 6 = 0.692 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 7 = 0.753 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 8 = 0.723 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 class 9 = 0.712 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all KL = 0.858 +- 0.153 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.9 all L1 = 0.762 +- 0.164 (in-sample avg dev_std = 0.231)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
SUFF++ for r=0.3 class 0 = 0.713 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 1 = 0.713 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 2 = 0.707 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 3 = 0.729 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 4 = 0.722 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 5 = 0.726 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 6 = 0.706 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 7 = 0.724 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 8 = 0.707 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 class 9 = 0.709 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 all KL = 0.893 +- 0.071 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.3 all L1 = 0.716 +- 0.081 (in-sample avg dev_std = 0.197)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
SUFF++ for r=0.6 class 0 = 0.658 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 1 = 0.582 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 2 = 0.647 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 3 = 0.629 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 4 = 0.586 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 5 = 0.637 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 6 = 0.612 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 7 = 0.625 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 8 = 0.643 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 class 9 = 0.58 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 all KL = 0.778 +- 0.179 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.6 all L1 = 0.62 +- 0.164 (in-sample avg dev_std = 0.119)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.406
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.393
SUFF++ for r=0.9 class 0 = 0.776 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 1 = 0.966 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 2 = 0.803 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 3 = 0.755 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 4 = 0.819 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 5 = 0.742 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 6 = 0.714 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 7 = 0.761 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 8 = 0.73 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 9 = 0.749 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all KL = 0.88 +- 0.142 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all L1 = 0.784 +- 0.164 (in-sample avg dev_std = 0.220)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.294 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 1 = 0.259 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 2 = 0.28 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 3 = 0.265 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 4 = 0.281 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 5 = 0.294 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 6 = 0.26 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 7 = 0.283 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 8 = 0.26 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 9 = 0.273 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all KL = 0.093 +- 0.072 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all L1 = 0.274 +- 0.084 (in-sample avg dev_std = 0.143)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.097
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.097
NEC for r=0.6 class 0 = 0.331 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 1 = 0.259 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 2 = 0.32 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 3 = 0.299 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 4 = 0.299 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 5 = 0.328 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 6 = 0.309 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 7 = 0.298 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 8 = 0.321 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 class 9 = 0.338 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all KL = 0.143 +- 0.106 (in-sample avg dev_std = 0.185)
NEC for r=0.6 all L1 = 0.309 +- 0.116 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.377
NEC for r=0.9 class 0 = 0.368 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 1 = 0.337 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 2 = 0.534 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 3 = 0.5 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 4 = 0.514 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 5 = 0.547 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 6 = 0.481 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 7 = 0.527 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 8 = 0.522 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 9 = 0.558 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all KL = 0.471 +- 0.226 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all L1 = 0.486 +- 0.177 (in-sample avg dev_std = 0.316)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.577
NEC for r=1.0 class 0 = 0.24 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 1 = 0.134 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 2 = 0.473 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 3 = 0.456 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 4 = 0.388 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 5 = 0.507 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 6 = 0.447 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 7 = 0.453 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 8 = 0.454 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 9 = 0.494 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 all KL = 0.414 +- 0.242 (in-sample avg dev_std = 0.331)
NEC for r=1.0 all L1 = 0.4 +- 0.214 (in-sample avg dev_std = 0.331)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
NEC for r=0.3 class 0 = 0.26 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 1 = 0.264 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 2 = 0.272 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 3 = 0.255 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 4 = 0.264 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 5 = 0.271 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 6 = 0.255 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 7 = 0.269 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 8 = 0.265 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 class 9 = 0.269 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 all KL = 0.084 +- 0.060 (in-sample avg dev_std = 0.129)
NEC for r=0.3 all L1 = 0.264 +- 0.081 (in-sample avg dev_std = 0.129)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.097
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.088
NEC for r=0.6 class 0 = 0.306 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1 = 0.288 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 2 = 0.305 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 3 = 0.293 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 4 = 0.319 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 5 = 0.313 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 6 = 0.325 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 7 = 0.321 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 8 = 0.331 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 9 = 0.326 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.145 +- 0.106 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.312 +- 0.110 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.549
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.427
NEC for r=0.9 class 0 = 0.36 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 1 = 0.248 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 2 = 0.452 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 3 = 0.511 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 4 = 0.487 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 5 = 0.487 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 6 = 0.541 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 7 = 0.51 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 8 = 0.516 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 class 9 = 0.536 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all KL = 0.448 +- 0.232 (in-sample avg dev_std = 0.316)
NEC for r=0.9 all L1 = 0.463 +- 0.197 (in-sample avg dev_std = 0.316)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.689
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.577
NEC for r=1.0 class 0 = 0.25 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 1 = 0.058 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 2 = 0.454 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 3 = 0.471 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 4 = 0.378 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 5 = 0.479 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 6 = 0.488 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 7 = 0.349 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 8 = 0.492 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 class 9 = 0.437 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 all KL = 0.387 +- 0.253 (in-sample avg dev_std = 0.326)
NEC for r=1.0 all L1 = 0.38 +- 0.227 (in-sample avg dev_std = 0.326)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.262 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 1 = 0.261 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 2 = 0.279 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 3 = 0.244 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 4 = 0.265 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 5 = 0.249 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 6 = 0.275 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 7 = 0.25 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 8 = 0.271 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 class 9 = 0.265 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all KL = 0.082 +- 0.061 (in-sample avg dev_std = 0.123)
NEC for r=0.3 all L1 = 0.262 +- 0.085 (in-sample avg dev_std = 0.123)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.131
NEC for r=0.6 class 0 = 0.334 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 1 = 0.399 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 2 = 0.327 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 3 = 0.348 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 4 = 0.38 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 5 = 0.346 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 6 = 0.383 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 7 = 0.362 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 8 = 0.361 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 9 = 0.39 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all KL = 0.198 +- 0.134 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all L1 = 0.363 +- 0.123 (in-sample avg dev_std = 0.207)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.406
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.37
NEC for r=0.9 class 0 = 0.424 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 1 = 0.108 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 2 = 0.398 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 3 = 0.453 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 4 = 0.337 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 5 = 0.457 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 6 = 0.527 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 7 = 0.449 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 8 = 0.486 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 class 9 = 0.477 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 all KL = 0.378 +- 0.223 (in-sample avg dev_std = 0.308)
NEC for r=0.9 all L1 = 0.407 +- 0.204 (in-sample avg dev_std = 0.308)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.403
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.386
NEC for r=1.0 class 0 = 0.442 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 1 = 0.038 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 2 = 0.389 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 3 = 0.456 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 4 = 0.302 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 5 = 0.442 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 6 = 0.506 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 7 = 0.402 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 8 = 0.469 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 class 9 = 0.482 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 all KL = 0.376 +- 0.263 (in-sample avg dev_std = 0.317)
NEC for r=1.0 all L1 = 0.388 +- 0.236 (in-sample avg dev_std = 0.317)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 12:28:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:00 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:00 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:00 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:29:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9618
Train Loss: 0.1216
ID Validation ACCURACY: 0.8683
ID Validation Loss: 0.4260
ID Test ACCURACY: 0.8626
ID Test Loss: 0.4301
OOD Validation ACCURACY: 0.8326
OOD Validation Loss: 0.5495
OOD Test ACCURACY: 0.3693
OOD Test Loss: 3.0963

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.9485
Train Loss: 0.1549
ID Validation ACCURACY: 0.8634
ID Validation Loss: 0.4307
ID Test ACCURACY: 0.8596
ID Test Loss: 0.4377
OOD Validation ACCURACY: 0.8451
OOD Validation Loss: 0.5034
OOD Test ACCURACY: 0.3470
OOD Test Loss: 4.3429

[0m[1;37mINFO[0m: [1mChartInfo 0.8626 0.3693 0.8596 0.3470 0.8634 0.8451[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.676 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 1 = 0.67 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 2 = 0.667 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 3 = 0.698 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 4 = 0.66 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 5 = 0.672 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 6 = 0.677 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 7 = 0.677 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 8 = 0.657 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 9 = 0.668 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all KL = 0.851 +- 0.108 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all L1 = 0.673 +- 0.100 (in-sample avg dev_std = 0.233)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.112
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
SUFF++ for r=0.6 class 0 = 0.66 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 1 = 0.611 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 2 = 0.662 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 3 = 0.657 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 4 = 0.588 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 5 = 0.61 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 6 = 0.615 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 7 = 0.59 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 8 = 0.636 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 class 9 = 0.556 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 all KL = 0.734 +- 0.220 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.6 all L1 = 0.619 +- 0.204 (in-sample avg dev_std = 0.127)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.554
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.515
SUFF++ for r=0.9 class 0 = 0.783 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 1 = 0.822 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 2 = 0.74 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 3 = 0.713 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 4 = 0.726 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 5 = 0.696 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 6 = 0.729 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 7 = 0.799 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 8 = 0.708 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 9 = 0.709 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all KL = 0.812 +- 0.211 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all L1 = 0.745 +- 0.191 (in-sample avg dev_std = 0.277)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.705 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 1 = 0.686 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 2 = 0.716 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 3 = 0.717 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 4 = 0.733 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 5 = 0.719 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 6 = 0.71 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 7 = 0.693 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 8 = 0.726 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 9 = 0.679 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all KL = 0.882 +- 0.089 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all L1 = 0.708 +- 0.091 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.129
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.104
SUFF++ for r=0.6 class 0 = 0.561 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 1 = 0.628 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 2 = 0.658 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 3 = 0.637 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 4 = 0.596 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 5 = 0.607 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 6 = 0.617 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 7 = 0.583 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 8 = 0.576 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 9 = 0.584 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all KL = 0.721 +- 0.225 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all L1 = 0.605 +- 0.203 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.486
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.433
SUFF++ for r=0.9 class 0 = 0.831 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.773 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.745 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 3 = 0.713 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 4 = 0.722 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 5 = 0.706 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 6 = 0.717 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 7 = 0.874 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 8 = 0.71 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 9 = 0.747 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.819 +- 0.210 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.755 +- 0.191 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.714 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 1 = 0.704 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 2 = 0.699 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 3 = 0.705 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 4 = 0.711 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 5 = 0.711 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 6 = 0.718 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 7 = 0.7 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 8 = 0.73 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 9 = 0.713 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all KL = 0.885 +- 0.079 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all L1 = 0.71 +- 0.085 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.125
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.115
SUFF++ for r=0.6 class 0 = 0.622 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 1 = 0.586 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 2 = 0.576 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 3 = 0.591 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 4 = 0.555 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 5 = 0.6 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 6 = 0.574 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 7 = 0.631 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 8 = 0.57 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 class 9 = 0.512 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 all KL = 0.694 +- 0.228 (in-sample avg dev_std = 0.144)
SUFF++ for r=0.6 all L1 = 0.582 +- 0.192 (in-sample avg dev_std = 0.144)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.316
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.283
SUFF++ for r=0.9 class 0 = 0.747 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.708 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.766 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 3 = 0.716 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 4 = 0.777 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 5 = 0.731 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 6 = 0.713 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 7 = 0.718 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 8 = 0.698 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 9 = 0.722 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.834 +- 0.173 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.73 +- 0.163 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
NEC for r=0.3 class 0 = 0.285 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 1 = 0.264 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 2 = 0.275 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 3 = 0.275 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 4 = 0.283 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 5 = 0.287 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 6 = 0.253 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 7 = 0.298 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 8 = 0.276 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 9 = 0.283 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all KL = 0.103 +- 0.081 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all L1 = 0.278 +- 0.090 (in-sample avg dev_std = 0.157)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.112
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
NEC for r=0.6 class 0 = 0.299 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 1 = 0.363 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 2 = 0.275 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 3 = 0.342 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 4 = 0.403 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 5 = 0.357 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 6 = 0.378 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 7 = 0.387 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 8 = 0.343 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 9 = 0.428 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all KL = 0.229 +- 0.177 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all L1 = 0.357 +- 0.182 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.554
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.397
NEC for r=0.9 class 0 = 0.487 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 1 = 0.395 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 2 = 0.518 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 3 = 0.539 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 4 = 0.559 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 5 = 0.583 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 6 = 0.496 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 7 = 0.426 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 8 = 0.523 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 class 9 = 0.557 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 all KL = 0.557 +- 0.259 (in-sample avg dev_std = 0.382)
NEC for r=0.9 all L1 = 0.504 +- 0.206 (in-sample avg dev_std = 0.382)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.697
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.576
NEC for r=1.0 class 0 = 0.291 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 1 = 0.14 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 2 = 0.429 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 3 = 0.487 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 4 = 0.431 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 5 = 0.518 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 6 = 0.416 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 7 = 0.317 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 8 = 0.504 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 9 = 0.497 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all KL = 0.466 +- 0.296 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all L1 = 0.397 +- 0.250 (in-sample avg dev_std = 0.387)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.231 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 1 = 0.24 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 2 = 0.249 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 3 = 0.219 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 4 = 0.24 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 5 = 0.229 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 6 = 0.24 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 7 = 0.254 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 8 = 0.236 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 9 = 0.254 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all KL = 0.076 +- 0.065 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all L1 = 0.239 +- 0.087 (in-sample avg dev_std = 0.135)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.129
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.097
NEC for r=0.6 class 0 = 0.395 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 1 = 0.348 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 2 = 0.334 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 3 = 0.354 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 4 = 0.373 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 5 = 0.359 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 6 = 0.381 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 7 = 0.395 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 8 = 0.424 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 9 = 0.421 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all KL = 0.249 +- 0.183 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all L1 = 0.378 +- 0.172 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.486
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.348
NEC for r=0.9 class 0 = 0.372 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 1 = 0.476 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 2 = 0.44 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 3 = 0.555 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 4 = 0.517 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 5 = 0.553 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 6 = 0.525 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 7 = 0.28 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 8 = 0.581 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 9 = 0.495 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all KL = 0.514 +- 0.276 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all L1 = 0.478 +- 0.228 (in-sample avg dev_std = 0.368)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.632
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.521
NEC for r=1.0 class 0 = 0.279 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 1 = 0.134 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 2 = 0.445 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 3 = 0.549 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 4 = 0.398 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 5 = 0.503 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 6 = 0.5 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 7 = 0.238 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 8 = 0.55 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 class 9 = 0.473 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 all KL = 0.457 +- 0.308 (in-sample avg dev_std = 0.370)
NEC for r=1.0 all L1 = 0.402 +- 0.260 (in-sample avg dev_std = 0.370)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.22 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1 = 0.217 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 2 = 0.234 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 3 = 0.206 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 4 = 0.221 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 5 = 0.214 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 6 = 0.214 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 7 = 0.203 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 8 = 0.229 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 9 = 0.225 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.062 +- 0.053 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.218 +- 0.081 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.125
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.115
NEC for r=0.6 class 0 = 0.341 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 1 = 0.384 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 2 = 0.4 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 3 = 0.37 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 4 = 0.419 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 5 = 0.368 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 6 = 0.423 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 7 = 0.381 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 8 = 0.401 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 class 9 = 0.434 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all KL = 0.258 +- 0.155 (in-sample avg dev_std = 0.255)
NEC for r=0.6 all L1 = 0.392 +- 0.142 (in-sample avg dev_std = 0.255)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.316
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.262
NEC for r=0.9 class 0 = 0.466 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 1 = 0.551 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 2 = 0.446 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 3 = 0.485 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 4 = 0.423 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 5 = 0.489 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 6 = 0.528 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 7 = 0.471 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 8 = 0.558 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 class 9 = 0.46 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 all KL = 0.461 +- 0.228 (in-sample avg dev_std = 0.351)
NEC for r=0.9 all L1 = 0.488 +- 0.174 (in-sample avg dev_std = 0.351)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.298
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.292
NEC for r=1.0 class 0 = 0.519 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 1 = 0.522 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 2 = 0.455 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 3 = 0.489 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 4 = 0.444 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 5 = 0.503 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 6 = 0.565 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 7 = 0.455 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 8 = 0.551 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 class 9 = 0.512 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 all KL = 0.51 +- 0.267 (in-sample avg dev_std = 0.346)
NEC for r=1.0 all L1 = 0.501 +- 0.205 (in-sample avg dev_std = 0.346)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 12:50:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:14 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:14 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 12:50:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.9720
Train Loss: 0.0943
ID Validation ACCURACY: 0.8586
ID Validation Loss: 0.4701
ID Test ACCURACY: 0.8504
ID Test Loss: 0.4775
OOD Validation ACCURACY: 0.8157
OOD Validation Loss: 0.6277
OOD Test ACCURACY: 0.3134
OOD Test Loss: 5.7139

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 177...
[0m[1;37mINFO[0m: [1mCheckpoint 177: 
-----------------------------------
Train ACCURACY: 0.9667
Train Loss: 0.1136
ID Validation ACCURACY: 0.8546
ID Validation Loss: 0.4593
ID Test ACCURACY: 0.8567
ID Test Loss: 0.4537
OOD Validation ACCURACY: 0.8301
OOD Validation Loss: 0.5667
OOD Test ACCURACY: 0.4320
OOD Test Loss: 2.7154

[0m[1;37mINFO[0m: [1mChartInfo 0.8504 0.3134 0.8567 0.4320 0.8546 0.8301[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
SUFF++ for r=0.3 class 0 = 0.681 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 1 = 0.706 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 2 = 0.681 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 3 = 0.701 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 4 = 0.667 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 5 = 0.679 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 6 = 0.688 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 7 = 0.677 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 8 = 0.671 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 9 = 0.666 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all KL = 0.844 +- 0.114 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all L1 = 0.682 +- 0.117 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.104
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.111
SUFF++ for r=0.6 class 0 = 0.748 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 1 = 0.515 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 2 = 0.728 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 3 = 0.655 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 4 = 0.535 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 5 = 0.656 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 6 = 0.644 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 7 = 0.633 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 8 = 0.661 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 9 = 0.572 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all KL = 0.726 +- 0.267 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all L1 = 0.634 +- 0.246 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.522
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.464
SUFF++ for r=0.9 class 0 = 0.815 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 1 = 0.799 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 2 = 0.806 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 3 = 0.729 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 4 = 0.707 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 5 = 0.719 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 6 = 0.716 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 7 = 0.788 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 8 = 0.725 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 class 9 = 0.692 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all KL = 0.819 +- 0.207 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.9 all L1 = 0.752 +- 0.189 (in-sample avg dev_std = 0.268)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.738 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 1 = 0.739 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 2 = 0.724 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 3 = 0.76 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 4 = 0.76 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 5 = 0.732 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 6 = 0.751 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 7 = 0.744 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 8 = 0.753 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 class 9 = 0.748 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 all KL = 0.894 +- 0.083 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.3 all L1 = 0.745 +- 0.097 (in-sample avg dev_std = 0.179)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.114
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.106
SUFF++ for r=0.6 class 0 = 0.7 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 1 = 0.564 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 2 = 0.796 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 3 = 0.753 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 4 = 0.599 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 5 = 0.726 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 6 = 0.639 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 7 = 0.625 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 8 = 0.657 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 class 9 = 0.564 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 all KL = 0.738 +- 0.283 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.6 all L1 = 0.659 +- 0.268 (in-sample avg dev_std = 0.126)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.475
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.431
SUFF++ for r=0.9 class 0 = 0.807 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.824 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.834 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 3 = 0.777 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 4 = 0.725 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 5 = 0.73 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 6 = 0.697 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 7 = 0.815 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 8 = 0.746 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 9 = 0.726 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.846 +- 0.179 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.769 +- 0.188 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.731 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 1 = 0.752 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 2 = 0.742 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 3 = 0.751 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 4 = 0.755 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 5 = 0.751 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 6 = 0.75 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 7 = 0.742 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 8 = 0.749 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 9 = 0.756 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 all KL = 0.892 +- 0.091 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 all L1 = 0.748 +- 0.099 (in-sample avg dev_std = 0.186)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.123
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
SUFF++ for r=0.6 class 0 = 0.684 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 1 = 0.463 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 2 = 0.647 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 3 = 0.672 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 4 = 0.502 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 5 = 0.601 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 6 = 0.594 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 7 = 0.598 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 8 = 0.628 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 9 = 0.462 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all KL = 0.654 +- 0.304 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all L1 = 0.585 +- 0.259 (in-sample avg dev_std = 0.149)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.257
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.248
SUFF++ for r=0.9 class 0 = 0.798 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 1 = 0.768 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 2 = 0.87 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 3 = 0.785 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 4 = 0.783 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 5 = 0.797 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 6 = 0.727 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 7 = 0.778 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 8 = 0.773 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 class 9 = 0.764 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all KL = 0.874 +- 0.157 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.9 all L1 = 0.785 +- 0.169 (in-sample avg dev_std = 0.232)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.295 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 1 = 0.265 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 2 = 0.274 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 3 = 0.278 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 4 = 0.296 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 5 = 0.293 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 6 = 0.257 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 7 = 0.293 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 8 = 0.287 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 class 9 = 0.278 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 all KL = 0.124 +- 0.099 (in-sample avg dev_std = 0.186)
NEC for r=0.3 all L1 = 0.281 +- 0.112 (in-sample avg dev_std = 0.186)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.104
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.106
NEC for r=0.6 class 0 = 0.25 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 1 = 0.436 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 2 = 0.256 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 3 = 0.315 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 4 = 0.427 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 5 = 0.32 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 6 = 0.391 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 7 = 0.354 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 8 = 0.313 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 9 = 0.416 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 all KL = 0.249 +- 0.224 (in-sample avg dev_std = 0.239)
NEC for r=0.6 all L1 = 0.348 +- 0.216 (in-sample avg dev_std = 0.239)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.522
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.37
NEC for r=0.9 class 0 = 0.294 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 1 = 0.406 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 2 = 0.413 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 3 = 0.51 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 4 = 0.513 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 5 = 0.493 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 6 = 0.51 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 7 = 0.417 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 8 = 0.546 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 class 9 = 0.56 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 all KL = 0.507 +- 0.265 (in-sample avg dev_std = 0.373)
NEC for r=0.9 all L1 = 0.464 +- 0.216 (in-sample avg dev_std = 0.373)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.66
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.537
NEC for r=1.0 class 0 = 0.227 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 1 = 0.149 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 2 = 0.286 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 3 = 0.521 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 4 = 0.45 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 5 = 0.522 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 6 = 0.446 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 7 = 0.351 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 8 = 0.51 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 9 = 0.497 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all KL = 0.458 +- 0.298 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all L1 = 0.39 +- 0.249 (in-sample avg dev_std = 0.376)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.211 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 1 = 0.198 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 2 = 0.227 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 3 = 0.191 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 4 = 0.208 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 5 = 0.21 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 6 = 0.205 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 7 = 0.207 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 8 = 0.199 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 class 9 = 0.218 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all KL = 0.072 +- 0.071 (in-sample avg dev_std = 0.135)
NEC for r=0.3 all L1 = 0.207 +- 0.096 (in-sample avg dev_std = 0.135)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.114
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.108
NEC for r=0.6 class 0 = 0.264 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 1 = 0.397 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 2 = 0.199 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 3 = 0.252 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 4 = 0.365 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 5 = 0.263 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 6 = 0.348 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 7 = 0.357 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 8 = 0.334 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 9 = 0.392 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all KL = 0.233 +- 0.241 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all L1 = 0.32 +- 0.238 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.475
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.343
NEC for r=0.9 class 0 = 0.359 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 1 = 0.359 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 2 = 0.286 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 3 = 0.444 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 4 = 0.467 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 5 = 0.484 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 6 = 0.513 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 7 = 0.335 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 8 = 0.541 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 9 = 0.532 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all KL = 0.44 +- 0.266 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all L1 = 0.43 +- 0.229 (in-sample avg dev_std = 0.357)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.62
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.491
NEC for r=1.0 class 0 = 0.292 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 1 = 0.09 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 2 = 0.32 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 3 = 0.555 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 4 = 0.452 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 5 = 0.512 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 6 = 0.501 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 7 = 0.292 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 8 = 0.503 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 9 = 0.512 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 all KL = 0.431 +- 0.304 (in-sample avg dev_std = 0.352)
NEC for r=1.0 all L1 = 0.398 +- 0.262 (in-sample avg dev_std = 0.352)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
NEC for r=0.3 class 0 = 0.195 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 1 = 0.212 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 2 = 0.207 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 3 = 0.181 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 4 = 0.211 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 5 = 0.176 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 6 = 0.208 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 7 = 0.183 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 8 = 0.224 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 class 9 = 0.212 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 all KL = 0.065 +- 0.068 (in-sample avg dev_std = 0.119)
NEC for r=0.3 all L1 = 0.201 +- 0.098 (in-sample avg dev_std = 0.119)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.123
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
NEC for r=0.6 class 0 = 0.322 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 1 = 0.49 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 2 = 0.333 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 3 = 0.325 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 4 = 0.487 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 5 = 0.371 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 6 = 0.415 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 7 = 0.4 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 8 = 0.372 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 class 9 = 0.478 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all KL = 0.319 +- 0.254 (in-sample avg dev_std = 0.248)
NEC for r=0.6 all L1 = 0.399 +- 0.229 (in-sample avg dev_std = 0.248)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.257
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.213
NEC for r=0.9 class 0 = 0.39 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 1 = 0.418 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 2 = 0.249 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 3 = 0.356 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 4 = 0.356 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 5 = 0.36 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 6 = 0.448 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 7 = 0.371 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 8 = 0.403 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 9 = 0.396 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 all KL = 0.329 +- 0.233 (in-sample avg dev_std = 0.324)
NEC for r=0.9 all L1 = 0.374 +- 0.206 (in-sample avg dev_std = 0.324)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.271
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.251
NEC for r=1.0 class 0 = 0.442 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 1 = 0.493 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 2 = 0.311 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 3 = 0.429 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 4 = 0.466 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 5 = 0.412 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 6 = 0.514 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 7 = 0.398 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 8 = 0.448 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 class 9 = 0.492 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 all KL = 0.416 +- 0.276 (in-sample avg dev_std = 0.338)
NEC for r=1.0 all L1 = 0.44 +- 0.223 (in-sample avg dev_std = 0.338)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 13:11:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 01:11:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9751
Train Loss: 0.0878
ID Validation ACCURACY: 0.8569
ID Validation Loss: 0.4755
ID Test ACCURACY: 0.8540
ID Test Loss: 0.4896
OOD Validation ACCURACY: 0.8344
OOD Validation Loss: 0.5740
OOD Test ACCURACY: 0.4331
OOD Test Loss: 2.9005

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ACCURACY: 0.9335
Train Loss: 0.1980
ID Validation ACCURACY: 0.8477
ID Validation Loss: 0.4621
ID Test ACCURACY: 0.8503
ID Test Loss: 0.4622
OOD Validation ACCURACY: 0.8393
OOD Validation Loss: 0.5163
OOD Test ACCURACY: 0.5437
OOD Test Loss: 2.1691

[0m[1;37mINFO[0m: [1mChartInfo 0.8540 0.4331 0.8503 0.5437 0.8477 0.8393[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.646 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 1 = 0.645 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 2 = 0.651 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 3 = 0.656 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 4 = 0.635 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 5 = 0.642 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 6 = 0.662 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 7 = 0.652 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 8 = 0.631 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 9 = 0.654 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all KL = 0.822 +- 0.116 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all L1 = 0.648 +- 0.100 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.117
SUFF++ for r=0.6 class 0 = 0.739 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 1 = 0.568 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 2 = 0.739 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 3 = 0.762 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 4 = 0.607 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 5 = 0.72 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 6 = 0.677 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 7 = 0.667 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 8 = 0.639 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 9 = 0.641 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 all KL = 0.776 +- 0.220 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 all L1 = 0.675 +- 0.214 (in-sample avg dev_std = 0.120)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.533
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.477
SUFF++ for r=0.9 class 0 = 0.792 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 1 = 0.795 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 2 = 0.728 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 3 = 0.744 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 4 = 0.73 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 5 = 0.672 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 6 = 0.715 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 7 = 0.752 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 8 = 0.713 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 9 = 0.696 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all KL = 0.825 +- 0.181 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all L1 = 0.736 +- 0.174 (in-sample avg dev_std = 0.249)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.669 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 1 = 0.655 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 2 = 0.669 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 3 = 0.658 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 4 = 0.664 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 5 = 0.654 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 6 = 0.674 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 7 = 0.664 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 8 = 0.668 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 9 = 0.641 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all KL = 0.84 +- 0.090 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all L1 = 0.662 +- 0.090 (in-sample avg dev_std = 0.249)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.116
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.106
SUFF++ for r=0.6 class 0 = 0.703 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 1 = 0.575 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 2 = 0.729 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 3 = 0.721 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 4 = 0.619 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 5 = 0.712 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 6 = 0.66 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 7 = 0.653 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 8 = 0.659 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 class 9 = 0.581 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 all KL = 0.763 +- 0.216 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.6 all L1 = 0.659 +- 0.205 (in-sample avg dev_std = 0.120)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.514
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.487
SUFF++ for r=0.9 class 0 = 0.812 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1 = 0.816 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 2 = 0.756 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 3 = 0.743 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 4 = 0.744 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 5 = 0.674 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 6 = 0.694 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 7 = 0.835 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 8 = 0.682 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 9 = 0.713 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.838 +- 0.169 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.749 +- 0.182 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.683 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 1 = 0.653 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 2 = 0.678 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 3 = 0.665 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 4 = 0.675 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 5 = 0.667 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 6 = 0.658 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 7 = 0.661 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 8 = 0.658 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 9 = 0.661 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all KL = 0.847 +- 0.088 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.087 (in-sample avg dev_std = 0.241)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.097
SUFF++ for r=0.6 class 0 = 0.653 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 1 = 0.5 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 2 = 0.641 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 3 = 0.654 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 4 = 0.541 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 5 = 0.618 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 6 = 0.606 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 7 = 0.618 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 8 = 0.605 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 9 = 0.521 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all KL = 0.705 +- 0.223 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all L1 = 0.595 +- 0.186 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.329
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.316
SUFF++ for r=0.9 class 0 = 0.713 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.713 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.793 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 3 = 0.712 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 4 = 0.836 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 5 = 0.711 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 6 = 0.736 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 7 = 0.771 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 8 = 0.702 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 9 = 0.745 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.852 +- 0.157 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.743 +- 0.166 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.313 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 1 = 0.288 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 2 = 0.299 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 3 = 0.292 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 4 = 0.291 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 5 = 0.322 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 6 = 0.271 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 7 = 0.314 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 8 = 0.293 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 9 = 0.296 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 all KL = 0.12 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.3 all L1 = 0.297 +- 0.098 (in-sample avg dev_std = 0.174)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.119
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
NEC for r=0.6 class 0 = 0.22 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 1 = 0.435 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 2 = 0.203 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 3 = 0.262 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 4 = 0.352 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 5 = 0.282 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 6 = 0.343 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 7 = 0.321 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 8 = 0.357 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 9 = 0.394 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all KL = 0.206 +- 0.185 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all L1 = 0.317 +- 0.198 (in-sample avg dev_std = 0.200)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.533
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.394
NEC for r=0.9 class 0 = 0.441 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 1 = 0.387 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 2 = 0.516 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 3 = 0.497 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 4 = 0.514 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 5 = 0.554 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 6 = 0.488 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 7 = 0.458 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 8 = 0.571 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 class 9 = 0.57 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all KL = 0.516 +- 0.238 (in-sample avg dev_std = 0.368)
NEC for r=0.9 all L1 = 0.496 +- 0.188 (in-sample avg dev_std = 0.368)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.671
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.552
NEC for r=1.0 class 0 = 0.252 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 1 = 0.21 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 2 = 0.443 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 3 = 0.513 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 4 = 0.372 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 5 = 0.546 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 6 = 0.396 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 7 = 0.37 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 8 = 0.547 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 class 9 = 0.516 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 all KL = 0.47 +- 0.275 (in-sample avg dev_std = 0.368)
NEC for r=1.0 all L1 = 0.412 +- 0.237 (in-sample avg dev_std = 0.368)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.279 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 1 = 0.286 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 2 = 0.28 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 3 = 0.27 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 4 = 0.276 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 5 = 0.271 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 6 = 0.269 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 7 = 0.283 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 8 = 0.277 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 class 9 = 0.3 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all KL = 0.103 +- 0.081 (in-sample avg dev_std = 0.153)
NEC for r=0.3 all L1 = 0.279 +- 0.094 (in-sample avg dev_std = 0.153)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.116
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.103
NEC for r=0.6 class 0 = 0.277 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 1 = 0.42 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 2 = 0.266 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 3 = 0.258 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 4 = 0.361 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 5 = 0.293 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 6 = 0.321 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 7 = 0.325 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 8 = 0.36 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 class 9 = 0.41 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all KL = 0.217 +- 0.185 (in-sample avg dev_std = 0.207)
NEC for r=0.6 all L1 = 0.331 +- 0.187 (in-sample avg dev_std = 0.207)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.514
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.404
NEC for r=0.9 class 0 = 0.43 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 1 = 0.368 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 2 = 0.442 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 3 = 0.55 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 4 = 0.447 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 5 = 0.567 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 6 = 0.519 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 7 = 0.36 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 8 = 0.573 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 class 9 = 0.498 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 all KL = 0.488 +- 0.245 (in-sample avg dev_std = 0.363)
NEC for r=0.9 all L1 = 0.472 +- 0.204 (in-sample avg dev_std = 0.363)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.647
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.534
NEC for r=1.0 class 0 = 0.276 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 1 = 0.13 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 2 = 0.444 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 3 = 0.521 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 4 = 0.346 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 5 = 0.511 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 6 = 0.472 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 7 = 0.256 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 8 = 0.555 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 class 9 = 0.452 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 all KL = 0.432 +- 0.285 (in-sample avg dev_std = 0.351)
NEC for r=1.0 all L1 = 0.391 +- 0.245 (in-sample avg dev_std = 0.351)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
NEC for r=0.3 class 0 = 0.25 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1 = 0.301 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 2 = 0.27 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 3 = 0.254 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 4 = 0.281 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 5 = 0.267 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 6 = 0.286 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 7 = 0.255 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 8 = 0.287 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 9 = 0.272 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.097 +- 0.073 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.273 +- 0.087 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.131
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.114
NEC for r=0.6 class 0 = 0.285 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 1 = 0.455 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 2 = 0.303 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 3 = 0.321 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 4 = 0.417 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 5 = 0.339 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 6 = 0.391 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 7 = 0.361 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 8 = 0.389 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 class 9 = 0.436 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 all KL = 0.248 +- 0.172 (in-sample avg dev_std = 0.219)
NEC for r=0.6 all L1 = 0.37 +- 0.158 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.329
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.28
NEC for r=0.9 class 0 = 0.542 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 1 = 0.492 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 2 = 0.422 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 3 = 0.51 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 4 = 0.301 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 5 = 0.495 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 6 = 0.461 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 7 = 0.454 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 8 = 0.517 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 class 9 = 0.44 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 all KL = 0.441 +- 0.239 (in-sample avg dev_std = 0.340)
NEC for r=0.9 all L1 = 0.464 +- 0.189 (in-sample avg dev_std = 0.340)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.39
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.33
NEC for r=1.0 class 0 = 0.561 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 1 = 0.367 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 2 = 0.415 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 3 = 0.487 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 4 = 0.336 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 5 = 0.515 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 6 = 0.494 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 7 = 0.402 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 8 = 0.511 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 class 9 = 0.501 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 all KL = 0.454 +- 0.260 (in-sample avg dev_std = 0.369)
NEC for r=1.0 all L1 = 0.458 +- 0.213 (in-sample avg dev_std = 0.369)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.76, 0.747, 0.829, 1.0], 'all_L1': [0.6, 0.6, 0.738, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.874, 0.833, 0.849, 1.0], 'all_L1': [0.694, 0.671, 0.745, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.851, 0.734, 0.812, 1.0], 'all_L1': [0.673, 0.619, 0.745, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.844, 0.726, 0.819, 1.0], 'all_L1': [0.682, 0.634, 0.752, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.822, 0.776, 0.825, 1.0], 'all_L1': [0.648, 0.675, 0.736, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.155, 0.239, 0.48, 0.445], 'all_L1': [0.331, 0.391, 0.473, 0.402]}), defaultdict(<class 'list'>, {'all_KL': [0.093, 0.143, 0.471, 0.414], 'all_L1': [0.274, 0.309, 0.486, 0.4]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.229, 0.557, 0.466], 'all_L1': [0.278, 0.357, 0.504, 0.397]}), defaultdict(<class 'list'>, {'all_KL': [0.124, 0.249, 0.507, 0.458], 'all_L1': [0.281, 0.348, 0.464, 0.39]}), defaultdict(<class 'list'>, {'all_KL': [0.12, 0.206, 0.516, 0.47], 'all_L1': [0.297, 0.317, 0.496, 0.412]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.801, 0.735, 0.847, 1.0], 'all_L1': [0.628, 0.594, 0.756, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.894, 0.845, 0.858, 1.0], 'all_L1': [0.714, 0.683, 0.762, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.882, 0.721, 0.819, 1.0], 'all_L1': [0.708, 0.605, 0.755, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.894, 0.738, 0.846, 1.0], 'all_L1': [0.745, 0.659, 0.769, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.84, 0.763, 0.838, 1.0], 'all_L1': [0.662, 0.659, 0.749, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.128, 0.241, 0.438, 0.424], 'all_L1': [0.312, 0.388, 0.444, 0.393]}), defaultdict(<class 'list'>, {'all_KL': [0.084, 0.145, 0.448, 0.387], 'all_L1': [0.264, 0.312, 0.463, 0.38]}), defaultdict(<class 'list'>, {'all_KL': [0.076, 0.249, 0.514, 0.457], 'all_L1': [0.239, 0.378, 0.478, 0.402]}), defaultdict(<class 'list'>, {'all_KL': [0.072, 0.233, 0.44, 0.431], 'all_L1': [0.207, 0.32, 0.43, 0.398]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.217, 0.488, 0.432], 'all_L1': [0.279, 0.331, 0.472, 0.391]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.812, 0.747, 0.88, 1.0], 'all_L1': [0.637, 0.609, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.893, 0.778, 0.88, 1.0], 'all_L1': [0.716, 0.62, 0.784, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.885, 0.694, 0.834, 1.0], 'all_L1': [0.71, 0.582, 0.73, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.892, 0.654, 0.874, 1.0], 'all_L1': [0.748, 0.585, 0.785, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.847, 0.705, 0.852, 1.0], 'all_L1': [0.666, 0.595, 0.743, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.12, 0.228, 0.353, 0.418], 'all_L1': [0.306, 0.38, 0.425, 0.453]}), defaultdict(<class 'list'>, {'all_KL': [0.082, 0.198, 0.378, 0.376], 'all_L1': [0.262, 0.363, 0.407, 0.388]}), defaultdict(<class 'list'>, {'all_KL': [0.062, 0.258, 0.461, 0.51], 'all_L1': [0.218, 0.392, 0.488, 0.501]}), defaultdict(<class 'list'>, {'all_KL': [0.065, 0.319, 0.329, 0.416], 'all_L1': [0.201, 0.399, 0.374, 0.44]}), defaultdict(<class 'list'>, {'all_KL': [0.097, 0.248, 0.441, 0.454], 'all_L1': [0.273, 0.37, 0.464, 0.458]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.659 +- 0.033, 0.640 +- 0.029, 0.743 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.830 +- 0.039, 0.763 +- 0.039, 0.827 +- 0.012, 1.000 +- 0.000
suff++_acc_int  =  0.107 +- 0.004, 0.115 +- 0.008, 0.487 +- 0.019
nec class all_L1  =  0.292 +- 0.021, 0.344 +- 0.029, 0.485 +- 0.015, 0.400 +- 0.007
nec class all_KL  =  0.119 +- 0.021, 0.213 +- 0.038, 0.506 +- 0.030, 0.451 +- 0.020
nec_acc_int  =  0.108 +- 0.003, 0.111 +- 0.010, 0.380 +- 0.013, 0.558 +- 0.016

Eval split val
suff++ class all_L1  =  0.691 +- 0.041, 0.640 +- 0.034, 0.758 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.862 +- 0.036, 0.760 +- 0.044, 0.842 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.103 +- 0.003, 0.102 +- 0.007, 0.466 +- 0.032
nec class all_L1  =  0.260 +- 0.036, 0.346 +- 0.031, 0.457 +- 0.018, 0.393 +- 0.007
nec class all_KL  =  0.093 +- 0.021, 0.217 +- 0.038, 0.466 +- 0.030, 0.426 +- 0.023
nec_acc_int  =  0.099 +- 0.005, 0.102 +- 0.009, 0.379 +- 0.032, 0.534 +- 0.028

Eval split test
suff++ class all_L1  =  0.695 +- 0.039, 0.598 +- 0.014, 0.761 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.866 +- 0.032, 0.716 +- 0.043, 0.864 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.105 +- 0.005, 0.117 +- 0.011, 0.305 +- 0.049
nec class all_L1  =  0.252 +- 0.038, 0.381 +- 0.013, 0.432 +- 0.040, 0.448 +- 0.036
nec class all_KL  =  0.085 +- 0.021, 0.250 +- 0.040, 0.392 +- 0.051, 0.435 +- 0.045
nec_acc_int  =  0.109 +- 0.004, 0.122 +- 0.008, 0.273 +- 0.053, 0.307 +- 0.047


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.476 +- 0.007, 0.492 +- 0.003, 0.614 +- 0.007, 0.700 +- 0.004
Faith. Armon (L1)= 		  =  0.404 +- 0.013, 0.446 +- 0.018, 0.587 +- 0.010, 0.572 +- 0.007
Faith. GMean (L1)= 	  =  0.438 +- 0.004, 0.468 +- 0.010, 0.600 +- 0.008, 0.633 +- 0.006
Faith. Aritm (KL)= 		  =  0.475 +- 0.010, 0.488 +- 0.004, 0.666 +- 0.010, 0.725 +- 0.010
Faith. Armon (KL)= 		  =  0.207 +- 0.031, 0.330 +- 0.046, 0.627 +- 0.020, 0.621 +- 0.019
Faith. GMean (KL)= 	  =  0.312 +- 0.020, 0.401 +- 0.029, 0.647 +- 0.015, 0.671 +- 0.015

Eval split val
Faith. Aritm (L1)= 		  =  0.476 +- 0.007, 0.493 +- 0.003, 0.608 +- 0.007, 0.696 +- 0.004
Faith. Armon (L1)= 		  =  0.375 +- 0.032, 0.447 +- 0.017, 0.570 +- 0.013, 0.564 +- 0.008
Faith. GMean (L1)= 	  =  0.422 +- 0.018, 0.469 +- 0.009, 0.589 +- 0.010, 0.627 +- 0.006
Faith. Aritm (KL)= 		  =  0.477 +- 0.009, 0.489 +- 0.004, 0.654 +- 0.010, 0.713 +- 0.011
Faith. Armon (KL)= 		  =  0.166 +- 0.032, 0.335 +- 0.045, 0.599 +- 0.022, 0.597 +- 0.022
Faith. GMean (KL)= 	  =  0.280 +- 0.024, 0.403 +- 0.027, 0.625 +- 0.016, 0.653 +- 0.017

Eval split test
Faith. Aritm (L1)= 		  =  0.474 +- 0.008, 0.489 +- 0.004, 0.596 +- 0.010, 0.724 +- 0.018
Faith. Armon (L1)= 		  =  0.367 +- 0.036, 0.465 +- 0.007, 0.549 +- 0.027, 0.618 +- 0.035
Faith. GMean (L1)= 	  =  0.416 +- 0.022, 0.477 +- 0.005, 0.572 +- 0.019, 0.669 +- 0.027
Faith. Aritm (KL)= 		  =  0.476 +- 0.007, 0.483 +- 0.005, 0.628 +- 0.018, 0.717 +- 0.022
Faith. Armon (KL)= 		  =  0.154 +- 0.035, 0.367 +- 0.037, 0.537 +- 0.044, 0.605 +- 0.043
Faith. GMean (KL)= 	  =  0.269 +- 0.029, 0.421 +- 0.021, 0.581 +- 0.032, 0.659 +- 0.034
Computed for split load_split = id



Completed in  1:46:44.029223  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color topk
DONE all :)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:02:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:02:56 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:03:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 50...
[0m[1;37mINFO[0m: [1mCheckpoint 50: 
-----------------------------------
Train ROC-AUC: 0.8515
Train Loss: 0.1876
ID Validation ROC-AUC: 0.8260
ID Validation Loss: 0.2096
ID Test ROC-AUC: 0.8114
ID Test Loss: 0.1783
OOD Validation ROC-AUC: 0.7474
OOD Validation Loss: 0.1663
OOD Test ROC-AUC: 0.7251
OOD Test Loss: 0.1837

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 52...
[0m[1;37mINFO[0m: [1mCheckpoint 52: 
-----------------------------------
Train ROC-AUC: 0.8396
Train Loss: 0.2966
ID Validation ROC-AUC: 0.8034
ID Validation Loss: 0.3181
ID Test ROC-AUC: 0.8082
ID Test Loss: 0.2525
OOD Validation ROC-AUC: 0.7510
OOD Validation Loss: 0.1827
OOD Test ROC-AUC: 0.6925
OOD Test Loss: 0.2853

[0m[1;37mINFO[0m: [1mChartInfo 0.8114 0.7251 0.8082 0.6925 0.8034 0.7510[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:03:14 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:03:22 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:03:24 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 340
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0.0 = 0.896 +- 0.052 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.3 class 1.0 = 0.868 +- 0.052 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.3 all KL = 0.952 +- 0.052 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.3 all L1 = 0.882 +- 0.097 (in-sample avg dev_std = 0.121)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.657
SUFF++ for r=0.6 class 0.0 = 0.99 +- 0.085 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 1.0 = 0.915 +- 0.085 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all KL = 0.974 +- 0.085 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all L1 = 0.952 +- 0.119 (in-sample avg dev_std = 0.095)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.763
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.756
SUFF++ for r=0.9 class 0.0 = 0.997 +- 0.083 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.083 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.987 +- 0.083 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.979 +- 0.078 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 243
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0.0 = 0.894 +- 0.063 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 1.0 = 0.85 +- 0.063 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 all KL = 0.943 +- 0.063 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 all L1 = 0.872 +- 0.108 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
SUFF++ for r=0.6 class 0.0 = 0.983 +- 0.078 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 1.0 = 0.928 +- 0.078 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all KL = 0.979 +- 0.078 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all L1 = 0.956 +- 0.106 (in-sample avg dev_std = 0.095)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.758
SUFF++ for r=0.9 class 0.0 = 0.997 +- 0.060 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.9 class 1.0 = 0.969 +- 0.060 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.9 all KL = 0.99 +- 0.060 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.9 all L1 = 0.983 +- 0.069 (in-sample avg dev_std = 0.071)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.552
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 147
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0.0 = 0.905 +- 0.049 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.3 class 1.0 = 0.898 +- 0.049 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.3 all KL = 0.959 +- 0.049 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.3 all L1 = 0.902 +- 0.088 (in-sample avg dev_std = 0.114)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.481
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.507
SUFF++ for r=0.6 class 0.0 = 0.988 +- 0.048 (in-sample avg dev_std = 0.067)
SUFF++ for r=0.6 class 1.0 = 0.969 +- 0.048 (in-sample avg dev_std = 0.067)
SUFF++ for r=0.6 all KL = 0.989 +- 0.048 (in-sample avg dev_std = 0.067)
SUFF++ for r=0.6 all L1 = 0.979 +- 0.062 (in-sample avg dev_std = 0.067)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.633
SUFF++ for r=0.9 class 0.0 = 0.999 +- 0.031 (in-sample avg dev_std = 0.041)
SUFF++ for r=0.9 class 1.0 = 0.982 +- 0.031 (in-sample avg dev_std = 0.041)
SUFF++ for r=0.9 all KL = 0.995 +- 0.031 (in-sample avg dev_std = 0.041)
SUFF++ for r=0.9 all L1 = 0.99 +- 0.051 (in-sample avg dev_std = 0.041)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.594
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.569
NEC for r=0.3 class 0.0 = 0.084 +- 0.037 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1.0 = 0.086 +- 0.037 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.028 +- 0.037 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.085 +- 0.071 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.676
NEC for r=0.6 class 0.0 = 0.006 +- 0.097 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 1.0 = 0.078 +- 0.097 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all KL = 0.025 +- 0.097 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all L1 = 0.042 +- 0.118 (in-sample avg dev_std = 0.109)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.763
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
NEC for r=0.9 class 0.0 = 0.01 +- 0.164 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.105 +- 0.164 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.055 +- 0.164 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.058 +- 0.147 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.796
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.748
NEC for r=1.0 class 0.0 = 0.008 +- 0.168 (in-sample avg dev_std = 0.150)
NEC for r=1.0 class 1.0 = 0.105 +- 0.168 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all KL = 0.054 +- 0.168 (in-sample avg dev_std = 0.150)
NEC for r=1.0 all L1 = 0.057 +- 0.148 (in-sample avg dev_std = 0.150)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.62
NEC for r=0.3 class 0.0 = 0.094 +- 0.050 (in-sample avg dev_std = 0.108)
NEC for r=0.3 class 1.0 = 0.102 +- 0.050 (in-sample avg dev_std = 0.108)
NEC for r=0.3 all KL = 0.035 +- 0.050 (in-sample avg dev_std = 0.108)
NEC for r=0.3 all L1 = 0.098 +- 0.087 (in-sample avg dev_std = 0.108)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.709
NEC for r=0.6 class 0.0 = 0.011 +- 0.050 (in-sample avg dev_std = 0.094)
NEC for r=0.6 class 1.0 = 0.063 +- 0.050 (in-sample avg dev_std = 0.094)
NEC for r=0.6 all KL = 0.015 +- 0.050 (in-sample avg dev_std = 0.094)
NEC for r=0.6 all L1 = 0.037 +- 0.088 (in-sample avg dev_std = 0.094)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.743
NEC for r=0.9 class 0.0 = 0.006 +- 0.105 (in-sample avg dev_std = 0.111)
NEC for r=0.9 class 1.0 = 0.074 +- 0.105 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all KL = 0.032 +- 0.105 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all L1 = 0.04 +- 0.110 (in-sample avg dev_std = 0.111)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.765
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.751
NEC for r=1.0 class 0.0 = 0.006 +- 0.112 (in-sample avg dev_std = 0.106)
NEC for r=1.0 class 1.0 = 0.063 +- 0.112 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all KL = 0.031 +- 0.112 (in-sample avg dev_std = 0.106)
NEC for r=1.0 all L1 = 0.035 +- 0.104 (in-sample avg dev_std = 0.106)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.53
NEC for r=0.3 class 0.0 = 0.074 +- 0.042 (in-sample avg dev_std = 0.107)
NEC for r=0.3 class 1.0 = 0.08 +- 0.042 (in-sample avg dev_std = 0.107)
NEC for r=0.3 all KL = 0.028 +- 0.042 (in-sample avg dev_std = 0.107)
NEC for r=0.3 all L1 = 0.077 +- 0.076 (in-sample avg dev_std = 0.107)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.481
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.49
NEC for r=0.6 class 0.0 = 0.007 +- 0.042 (in-sample avg dev_std = 0.053)
NEC for r=0.6 class 1.0 = 0.023 +- 0.042 (in-sample avg dev_std = 0.053)
NEC for r=0.6 all KL = 0.007 +- 0.042 (in-sample avg dev_std = 0.053)
NEC for r=0.6 all L1 = 0.015 +- 0.053 (in-sample avg dev_std = 0.053)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.583
NEC for r=0.9 class 0.0 = 0.003 +- 0.050 (in-sample avg dev_std = 0.042)
NEC for r=0.9 class 1.0 = 0.024 +- 0.050 (in-sample avg dev_std = 0.042)
NEC for r=0.9 all KL = 0.009 +- 0.050 (in-sample avg dev_std = 0.042)
NEC for r=0.9 all L1 = 0.014 +- 0.068 (in-sample avg dev_std = 0.042)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0.0 = 0.003 +- 0.060 (in-sample avg dev_std = 0.070)
NEC for r=1.0 class 1.0 = 0.025 +- 0.060 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all KL = 0.011 +- 0.060 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all L1 = 0.014 +- 0.060 (in-sample avg dev_std = 0.070)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:04:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:37 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:41 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:45 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:48 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:04:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ROC-AUC: 0.8466
Train Loss: 0.2065
ID Validation ROC-AUC: 0.8305
ID Validation Loss: 0.2242
ID Test ROC-AUC: 0.8147
ID Test Loss: 0.2101
OOD Validation ROC-AUC: 0.7579
OOD Validation Loss: 0.1559
OOD Test ROC-AUC: 0.6987
OOD Test Loss: 0.1979

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 55...
[0m[1;37mINFO[0m: [1mCheckpoint 55: 
-----------------------------------
Train ROC-AUC: 0.8277
Train Loss: 0.2904
ID Validation ROC-AUC: 0.7929
ID Validation Loss: 0.2998
ID Test ROC-AUC: 0.7978
ID Test Loss: 0.2547
OOD Validation ROC-AUC: 0.7610
OOD Validation Loss: 0.1935
OOD Test ROC-AUC: 0.7206
OOD Test Loss: 0.2147

[0m[1;37mINFO[0m: [1mChartInfo 0.8147 0.6987 0.7978 0.7206 0.7929 0.7610[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:04:53 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:04:56 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:04:57 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.614
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.542
SUFF++ for r=0.3 class 0.0 = 0.939 +- 0.029 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.3 class 1.0 = 0.909 +- 0.029 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.3 all KL = 0.971 +- 0.029 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.3 all L1 = 0.924 +- 0.064 (in-sample avg dev_std = 0.079)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
SUFF++ for r=0.6 class 0.0 = 0.988 +- 0.054 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 class 1.0 = 0.939 +- 0.054 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 all KL = 0.983 +- 0.054 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 all L1 = 0.963 +- 0.089 (in-sample avg dev_std = 0.084)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.772
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.767
SUFF++ for r=0.9 class 0.0 = 0.996 +- 0.101 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.101 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all KL = 0.979 +- 0.101 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.9 all L1 = 0.97 +- 0.091 (in-sample avg dev_std = 0.118)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 245
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.533
SUFF++ for r=0.3 class 0.0 = 0.935 +- 0.045 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.3 class 1.0 = 0.907 +- 0.045 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.3 all KL = 0.966 +- 0.045 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.3 all L1 = 0.921 +- 0.074 (in-sample avg dev_std = 0.098)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.722
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0.0 = 0.99 +- 0.054 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.6 class 1.0 = 0.928 +- 0.054 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.6 all KL = 0.983 +- 0.054 (in-sample avg dev_std = 0.077)
SUFF++ for r=0.6 all L1 = 0.959 +- 0.097 (in-sample avg dev_std = 0.077)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.734
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.732
SUFF++ for r=0.9 class 0.0 = 0.996 +- 0.046 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.046 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.9 all KL = 0.99 +- 0.046 (in-sample avg dev_std = 0.071)
SUFF++ for r=0.9 all L1 = 0.979 +- 0.059 (in-sample avg dev_std = 0.071)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 149
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.527
SUFF++ for r=0.3 class 0.0 = 0.947 +- 0.045 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.3 class 1.0 = 0.925 +- 0.045 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.3 all KL = 0.972 +- 0.045 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.3 all L1 = 0.936 +- 0.060 (in-sample avg dev_std = 0.074)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.542
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.549
SUFF++ for r=0.6 class 0.0 = 0.99 +- 0.038 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 class 1.0 = 0.966 +- 0.038 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 all KL = 0.992 +- 0.038 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 all L1 = 0.978 +- 0.067 (in-sample avg dev_std = 0.046)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.647
SUFF++ for r=0.9 class 0.0 = 0.997 +- 0.077 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1.0 = 0.967 +- 0.077 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.987 +- 0.077 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.073 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
NEC for r=0.3 class 0.0 = 0.062 +- 0.028 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 1.0 = 0.059 +- 0.028 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all KL = 0.019 +- 0.028 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all L1 = 0.06 +- 0.057 (in-sample avg dev_std = 0.066)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.665
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0.0 = 0.006 +- 0.065 (in-sample avg dev_std = 0.078)
NEC for r=0.6 class 1.0 = 0.056 +- 0.065 (in-sample avg dev_std = 0.078)
NEC for r=0.6 all KL = 0.015 +- 0.065 (in-sample avg dev_std = 0.078)
NEC for r=0.6 all L1 = 0.031 +- 0.094 (in-sample avg dev_std = 0.078)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.772
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.718
NEC for r=0.9 class 0.0 = 0.013 +- 0.195 (in-sample avg dev_std = 0.165)
NEC for r=0.9 class 1.0 = 0.13 +- 0.195 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all KL = 0.065 +- 0.195 (in-sample avg dev_std = 0.165)
NEC for r=0.9 all L1 = 0.071 +- 0.170 (in-sample avg dev_std = 0.165)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.804
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.739
NEC for r=1.0 class 0.0 = 0.012 +- 0.243 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 1.0 = 0.156 +- 0.243 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all KL = 0.093 +- 0.243 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all L1 = 0.084 +- 0.186 (in-sample avg dev_std = 0.198)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.623
NEC for r=0.3 class 0.0 = 0.047 +- 0.019 (in-sample avg dev_std = 0.063)
NEC for r=0.3 class 1.0 = 0.055 +- 0.019 (in-sample avg dev_std = 0.063)
NEC for r=0.3 all KL = 0.014 +- 0.019 (in-sample avg dev_std = 0.063)
NEC for r=0.3 all L1 = 0.051 +- 0.047 (in-sample avg dev_std = 0.063)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.722
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.7
NEC for r=0.6 class 0.0 = 0.008 +- 0.045 (in-sample avg dev_std = 0.079)
NEC for r=0.6 class 1.0 = 0.063 +- 0.045 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all KL = 0.014 +- 0.045 (in-sample avg dev_std = 0.079)
NEC for r=0.6 all L1 = 0.035 +- 0.086 (in-sample avg dev_std = 0.079)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.734
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.721
NEC for r=0.9 class 0.0 = 0.014 +- 0.103 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 1.0 = 0.115 +- 0.103 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all KL = 0.04 +- 0.103 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all L1 = 0.064 +- 0.131 (in-sample avg dev_std = 0.126)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.758
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.732
NEC for r=1.0 class 0.0 = 0.013 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 class 1.0 = 0.108 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all KL = 0.04 +- 0.098 (in-sample avg dev_std = 0.107)
NEC for r=1.0 all L1 = 0.061 +- 0.127 (in-sample avg dev_std = 0.107)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.559
NEC for r=0.3 class 0.0 = 0.051 +- 0.027 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 1.0 = 0.054 +- 0.027 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all KL = 0.018 +- 0.027 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all L1 = 0.052 +- 0.056 (in-sample avg dev_std = 0.057)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.542
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.551
NEC for r=0.6 class 0.0 = 0.006 +- 0.020 (in-sample avg dev_std = 0.034)
NEC for r=0.6 class 1.0 = 0.027 +- 0.020 (in-sample avg dev_std = 0.034)
NEC for r=0.6 all KL = 0.005 +- 0.020 (in-sample avg dev_std = 0.034)
NEC for r=0.6 all L1 = 0.016 +- 0.048 (in-sample avg dev_std = 0.034)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.639
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0.0 = 0.007 +- 0.107 (in-sample avg dev_std = 0.054)
NEC for r=0.9 class 1.0 = 0.055 +- 0.107 (in-sample avg dev_std = 0.054)
NEC for r=0.9 all KL = 0.023 +- 0.107 (in-sample avg dev_std = 0.054)
NEC for r=0.9 all L1 = 0.031 +- 0.113 (in-sample avg dev_std = 0.054)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.696
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0.0 = 0.009 +- 0.092 (in-sample avg dev_std = 0.061)
NEC for r=1.0 class 1.0 = 0.055 +- 0.092 (in-sample avg dev_std = 0.061)
NEC for r=1.0 all KL = 0.02 +- 0.092 (in-sample avg dev_std = 0.061)
NEC for r=1.0 all L1 = 0.032 +- 0.101 (in-sample avg dev_std = 0.061)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:06:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:12 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:16 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:19 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:23 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:06:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 66...
[0m[1;37mINFO[0m: [1mCheckpoint 66: 
-----------------------------------
Train ROC-AUC: 0.8774
Train Loss: 0.1532
ID Validation ROC-AUC: 0.8281
ID Validation Loss: 0.1938
ID Test ROC-AUC: 0.8235
ID Test Loss: 0.1577
OOD Validation ROC-AUC: 0.7407
OOD Validation Loss: 0.1490
OOD Test ROC-AUC: 0.6990
OOD Test Loss: 0.1458

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ROC-AUC: 0.8529
Train Loss: 0.1797
ID Validation ROC-AUC: 0.8094
ID Validation Loss: 0.2178
ID Test ROC-AUC: 0.7950
ID Test Loss: 0.1783
OOD Validation ROC-AUC: 0.7539
OOD Validation Loss: 0.1456
OOD Test ROC-AUC: 0.6995
OOD Test Loss: 0.1580

[0m[1;37mINFO[0m: [1mChartInfo 0.8235 0.6990 0.7950 0.6995 0.8094 0.7539[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:06:27 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:06:30 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:06:32 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.633
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.555
SUFF++ for r=0.3 class 0.0 = 0.933 +- 0.037 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.3 class 1.0 = 0.901 +- 0.037 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.3 all KL = 0.97 +- 0.037 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.3 all L1 = 0.916 +- 0.071 (in-sample avg dev_std = 0.098)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.722
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.703
SUFF++ for r=0.6 class 0.0 = 0.99 +- 0.073 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.6 class 1.0 = 0.923 +- 0.073 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.6 all KL = 0.98 +- 0.073 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.6 all L1 = 0.957 +- 0.098 (in-sample avg dev_std = 0.097)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.768
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.758
SUFF++ for r=0.9 class 0.0 = 0.998 +- 0.109 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.109 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all KL = 0.978 +- 0.109 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.101 (in-sample avg dev_std = 0.137)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.715
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 239
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.601
SUFF++ for r=0.3 class 0.0 = 0.933 +- 0.051 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.3 class 1.0 = 0.88 +- 0.051 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.3 all KL = 0.962 +- 0.051 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.3 all L1 = 0.906 +- 0.084 (in-sample avg dev_std = 0.121)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.721
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.701
SUFF++ for r=0.6 class 0.0 = 0.99 +- 0.047 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.6 class 1.0 = 0.926 +- 0.047 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.6 all KL = 0.983 +- 0.047 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.6 all L1 = 0.958 +- 0.095 (in-sample avg dev_std = 0.081)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.706
SUFF++ for r=0.9 class 0.0 = 0.999 +- 0.085 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.085 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all KL = 0.985 +- 0.085 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.078 (in-sample avg dev_std = 0.109)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.571
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 148
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0.0 = 0.94 +- 0.025 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.3 class 1.0 = 0.924 +- 0.025 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.3 all KL = 0.978 +- 0.025 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.3 all L1 = 0.932 +- 0.058 (in-sample avg dev_std = 0.068)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0.0 = 0.991 +- 0.027 (in-sample avg dev_std = 0.049)
SUFF++ for r=0.6 class 1.0 = 0.969 +- 0.027 (in-sample avg dev_std = 0.049)
SUFF++ for r=0.6 all KL = 0.993 +- 0.027 (in-sample avg dev_std = 0.049)
SUFF++ for r=0.6 all L1 = 0.98 +- 0.053 (in-sample avg dev_std = 0.049)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 161
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.69
SUFF++ for r=0.9 class 0.0 = 0.999 +- 0.058 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.058 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.9 all KL = 0.992 +- 0.058 (in-sample avg dev_std = 0.076)
SUFF++ for r=0.9 all L1 = 0.988 +- 0.063 (in-sample avg dev_std = 0.076)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.61
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0.0 = 0.058 +- 0.024 (in-sample avg dev_std = 0.070)
NEC for r=0.3 class 1.0 = 0.074 +- 0.024 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all KL = 0.017 +- 0.024 (in-sample avg dev_std = 0.070)
NEC for r=0.3 all L1 = 0.066 +- 0.060 (in-sample avg dev_std = 0.070)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.722
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.694
NEC for r=0.6 class 0.0 = 0.007 +- 0.110 (in-sample avg dev_std = 0.139)
NEC for r=0.6 class 1.0 = 0.084 +- 0.110 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all KL = 0.029 +- 0.110 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all L1 = 0.046 +- 0.120 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.768
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.723
NEC for r=0.9 class 0.0 = 0.007 +- 0.207 (in-sample avg dev_std = 0.181)
NEC for r=0.9 class 1.0 = 0.137 +- 0.207 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all KL = 0.069 +- 0.207 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all L1 = 0.072 +- 0.181 (in-sample avg dev_std = 0.181)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.799
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.749
NEC for r=1.0 class 0.0 = 0.006 +- 0.243 (in-sample avg dev_std = 0.223)
NEC for r=1.0 class 1.0 = 0.17 +- 0.243 (in-sample avg dev_std = 0.223)
NEC for r=1.0 all KL = 0.095 +- 0.243 (in-sample avg dev_std = 0.223)
NEC for r=1.0 all L1 = 0.088 +- 0.201 (in-sample avg dev_std = 0.223)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.696
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.688
NEC for r=0.3 class 0.0 = 0.048 +- 0.033 (in-sample avg dev_std = 0.072)
NEC for r=0.3 class 1.0 = 0.078 +- 0.033 (in-sample avg dev_std = 0.072)
NEC for r=0.3 all KL = 0.017 +- 0.033 (in-sample avg dev_std = 0.072)
NEC for r=0.3 all L1 = 0.063 +- 0.069 (in-sample avg dev_std = 0.072)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.721
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.728
NEC for r=0.6 class 0.0 = 0.006 +- 0.076 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 1.0 = 0.074 +- 0.076 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all KL = 0.02 +- 0.076 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all L1 = 0.04 +- 0.106 (in-sample avg dev_std = 0.117)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.702
NEC for r=0.9 class 0.0 = 0.011 +- 0.217 (in-sample avg dev_std = 0.233)
NEC for r=0.9 class 1.0 = 0.154 +- 0.217 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all KL = 0.085 +- 0.217 (in-sample avg dev_std = 0.233)
NEC for r=0.9 all L1 = 0.083 +- 0.188 (in-sample avg dev_std = 0.233)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.72
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.706
NEC for r=1.0 class 0.0 = 0.01 +- 0.236 (in-sample avg dev_std = 0.253)
NEC for r=1.0 class 1.0 = 0.155 +- 0.236 (in-sample avg dev_std = 0.253)
NEC for r=1.0 all KL = 0.093 +- 0.236 (in-sample avg dev_std = 0.253)
NEC for r=1.0 all L1 = 0.083 +- 0.185 (in-sample avg dev_std = 0.253)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
NEC for r=0.3 class 0.0 = 0.052 +- 0.024 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 1.0 = 0.065 +- 0.024 (in-sample avg dev_std = 0.060)
NEC for r=0.3 all KL = 0.016 +- 0.024 (in-sample avg dev_std = 0.060)
NEC for r=0.3 all L1 = 0.059 +- 0.060 (in-sample avg dev_std = 0.060)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.66
NEC for r=0.6 class 0.0 = 0.006 +- 0.032 (in-sample avg dev_std = 0.036)
NEC for r=0.6 class 1.0 = 0.03 +- 0.032 (in-sample avg dev_std = 0.036)
NEC for r=0.6 all KL = 0.007 +- 0.032 (in-sample avg dev_std = 0.036)
NEC for r=0.6 all L1 = 0.018 +- 0.062 (in-sample avg dev_std = 0.036)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0.0 = 0.001 +- 0.087 (in-sample avg dev_std = 0.068)
NEC for r=0.9 class 1.0 = 0.034 +- 0.087 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all KL = 0.013 +- 0.087 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all L1 = 0.018 +- 0.087 (in-sample avg dev_std = 0.068)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.684
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.678
NEC for r=1.0 class 0.0 = 0.001 +- 0.121 (in-sample avg dev_std = 0.060)
NEC for r=1.0 class 1.0 = 0.048 +- 0.121 (in-sample avg dev_std = 0.060)
NEC for r=1.0 all KL = 0.022 +- 0.121 (in-sample avg dev_std = 0.060)
NEC for r=1.0 all L1 = 0.025 +- 0.114 (in-sample avg dev_std = 0.060)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:08:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:10 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:14 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:17 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:21 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:08:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ROC-AUC: 0.8747
Train Loss: 0.1465
ID Validation ROC-AUC: 0.8312
ID Validation Loss: 0.1839
ID Test ROC-AUC: 0.8064
ID Test Loss: 0.1615
OOD Validation ROC-AUC: 0.6823
OOD Validation Loss: 0.1468
OOD Test ROC-AUC: 0.7168
OOD Test Loss: 0.1357

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ROC-AUC: 0.8655
Train Loss: 0.1251
ID Validation ROC-AUC: 0.8218
ID Validation Loss: 0.1546
ID Test ROC-AUC: 0.8298
ID Test Loss: 0.1244
OOD Validation ROC-AUC: 0.7600
OOD Validation Loss: 0.1362
OOD Test ROC-AUC: 0.7231
OOD Test Loss: 0.0992

[0m[1;37mINFO[0m: [1mChartInfo 0.8064 0.7168 0.8298 0.7231 0.8218 0.7600[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:08:25 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:08:27 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:08:29 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.656
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0.0 = 0.873 +- 0.094 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 class 1.0 = 0.819 +- 0.094 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 all KL = 0.922 +- 0.094 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 all L1 = 0.845 +- 0.134 (in-sample avg dev_std = 0.204)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
SUFF++ for r=0.6 class 0.0 = 0.979 +- 0.078 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.6 class 1.0 = 0.917 +- 0.078 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.6 all KL = 0.974 +- 0.078 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.6 all L1 = 0.948 +- 0.108 (in-sample avg dev_std = 0.102)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.782
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.767
SUFF++ for r=0.9 class 0.0 = 0.997 +- 0.123 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 1.0 = 0.949 +- 0.123 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all KL = 0.975 +- 0.123 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.091 (in-sample avg dev_std = 0.137)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.661
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 244
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.556
SUFF++ for r=0.3 class 0.0 = 0.872 +- 0.130 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 1.0 = 0.796 +- 0.130 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 all KL = 0.903 +- 0.130 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 all L1 = 0.833 +- 0.154 (in-sample avg dev_std = 0.258)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.702
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.683
SUFF++ for r=0.6 class 0.0 = 0.987 +- 0.101 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.6 class 1.0 = 0.906 +- 0.101 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.6 all KL = 0.967 +- 0.101 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.6 all L1 = 0.947 +- 0.116 (in-sample avg dev_std = 0.122)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.731
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.73
SUFF++ for r=0.9 class 0.0 = 0.998 +- 0.097 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.097 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all KL = 0.983 +- 0.097 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.9 all L1 = 0.981 +- 0.077 (in-sample avg dev_std = 0.099)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.55
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 153
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.518
SUFF++ for r=0.3 class 0.0 = 0.906 +- 0.082 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.3 class 1.0 = 0.873 +- 0.082 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.3 all KL = 0.944 +- 0.082 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.3 all L1 = 0.889 +- 0.112 (in-sample avg dev_std = 0.165)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0.0 = 0.987 +- 0.043 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 class 1.0 = 0.952 +- 0.043 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 all KL = 0.986 +- 0.043 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 all L1 = 0.97 +- 0.063 (in-sample avg dev_std = 0.072)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.687
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.683
SUFF++ for r=0.9 class 0.0 = 0.999 +- 0.012 (in-sample avg dev_std = 0.040)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.012 (in-sample avg dev_std = 0.040)
SUFF++ for r=0.9 all KL = 0.997 +- 0.012 (in-sample avg dev_std = 0.040)
SUFF++ for r=0.9 all L1 = 0.991 +- 0.029 (in-sample avg dev_std = 0.040)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
NEC for r=0.3 class 0.0 = 0.118 +- 0.065 (in-sample avg dev_std = 0.146)
NEC for r=0.3 class 1.0 = 0.129 +- 0.065 (in-sample avg dev_std = 0.146)
NEC for r=0.3 all KL = 0.049 +- 0.065 (in-sample avg dev_std = 0.146)
NEC for r=0.3 all L1 = 0.124 +- 0.111 (in-sample avg dev_std = 0.146)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.665
NEC for r=0.6 class 0.0 = 0.014 +- 0.085 (in-sample avg dev_std = 0.095)
NEC for r=0.6 class 1.0 = 0.084 +- 0.085 (in-sample avg dev_std = 0.095)
NEC for r=0.6 all KL = 0.027 +- 0.085 (in-sample avg dev_std = 0.095)
NEC for r=0.6 all L1 = 0.049 +- 0.116 (in-sample avg dev_std = 0.095)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.782
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.712
NEC for r=0.9 class 0.0 = 0.006 +- 0.224 (in-sample avg dev_std = 0.203)
NEC for r=0.9 class 1.0 = 0.14 +- 0.224 (in-sample avg dev_std = 0.203)
NEC for r=0.9 all KL = 0.079 +- 0.224 (in-sample avg dev_std = 0.203)
NEC for r=0.9 all L1 = 0.073 +- 0.180 (in-sample avg dev_std = 0.203)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.815
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.725
NEC for r=1.0 class 0.0 = 0.006 +- 0.252 (in-sample avg dev_std = 0.225)
NEC for r=1.0 class 1.0 = 0.169 +- 0.252 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all KL = 0.097 +- 0.252 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all L1 = 0.088 +- 0.196 (in-sample avg dev_std = 0.225)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.647
NEC for r=0.3 class 0.0 = 0.103 +- 0.060 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 1.0 = 0.126 +- 0.060 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all KL = 0.046 +- 0.060 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all L1 = 0.115 +- 0.104 (in-sample avg dev_std = 0.157)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.702
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.692
NEC for r=0.6 class 0.0 = 0.007 +- 0.124 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 1.0 = 0.096 +- 0.124 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all KL = 0.039 +- 0.124 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all L1 = 0.052 +- 0.117 (in-sample avg dev_std = 0.159)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.731
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.72
NEC for r=0.9 class 0.0 = 0.012 +- 0.175 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.097 +- 0.175 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.065 +- 0.175 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.054 +- 0.129 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.733
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.719
NEC for r=1.0 class 0.0 = 0.017 +- 0.188 (in-sample avg dev_std = 0.193)
NEC for r=1.0 class 1.0 = 0.102 +- 0.188 (in-sample avg dev_std = 0.193)
NEC for r=1.0 all KL = 0.07 +- 0.188 (in-sample avg dev_std = 0.193)
NEC for r=1.0 all L1 = 0.059 +- 0.142 (in-sample avg dev_std = 0.193)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
NEC for r=0.3 class 0.0 = 0.074 +- 0.042 (in-sample avg dev_std = 0.133)
NEC for r=0.3 class 1.0 = 0.085 +- 0.042 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all KL = 0.031 +- 0.042 (in-sample avg dev_std = 0.133)
NEC for r=0.3 all L1 = 0.079 +- 0.069 (in-sample avg dev_std = 0.133)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.636
NEC for r=0.6 class 0.0 = 0.009 +- 0.044 (in-sample avg dev_std = 0.077)
NEC for r=0.6 class 1.0 = 0.044 +- 0.044 (in-sample avg dev_std = 0.077)
NEC for r=0.6 all KL = 0.013 +- 0.044 (in-sample avg dev_std = 0.077)
NEC for r=0.6 all L1 = 0.026 +- 0.057 (in-sample avg dev_std = 0.077)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.687
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.67
NEC for r=0.9 class 0.0 = 0.003 +- 0.124 (in-sample avg dev_std = 0.129)
NEC for r=0.9 class 1.0 = 0.062 +- 0.124 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all KL = 0.029 +- 0.124 (in-sample avg dev_std = 0.129)
NEC for r=0.9 all L1 = 0.032 +- 0.109 (in-sample avg dev_std = 0.129)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.681
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.662
NEC for r=1.0 class 0.0 = 0.003 +- 0.134 (in-sample avg dev_std = 0.140)
NEC for r=1.0 class 1.0 = 0.064 +- 0.134 (in-sample avg dev_std = 0.140)
NEC for r=1.0 all KL = 0.032 +- 0.134 (in-sample avg dev_std = 0.140)
NEC for r=1.0 all L1 = 0.034 +- 0.115 (in-sample avg dev_std = 0.140)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:09:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:47 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:09:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ROC-AUC: 0.9216
Train Loss: 0.1587
ID Validation ROC-AUC: 0.8239
ID Validation Loss: 0.2093
ID Test ROC-AUC: 0.8121
ID Test Loss: 0.1913
OOD Validation ROC-AUC: 0.7026
OOD Validation Loss: 0.2185
OOD Test ROC-AUC: 0.7026
OOD Test Loss: 0.1160

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ROC-AUC: 0.8624
Train Loss: 0.2266
ID Validation ROC-AUC: 0.7887
ID Validation Loss: 0.2593
ID Test ROC-AUC: 0.7984
ID Test Loss: 0.1975
OOD Validation ROC-AUC: 0.7591
OOD Validation Loss: 0.1365
OOD Test ROC-AUC: 0.6958
OOD Test Loss: 0.2618

[0m[1;37mINFO[0m: [1mChartInfo 0.8121 0.7026 0.7984 0.6958 0.7887 0.7591[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:09:59 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:10:03 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:10:04 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.649
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
SUFF++ for r=0.3 class 0.0 = 0.858 +- 0.100 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 class 1.0 = 0.821 +- 0.100 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 all KL = 0.916 +- 0.100 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 all L1 = 0.84 +- 0.130 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.734
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.739
SUFF++ for r=0.6 class 0.0 = 0.96 +- 0.069 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.6 class 1.0 = 0.879 +- 0.069 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.6 all KL = 0.965 +- 0.069 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.6 all L1 = 0.919 +- 0.121 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.804
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.073 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 class 1.0 = 0.929 +- 0.073 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all KL = 0.981 +- 0.073 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.087 (in-sample avg dev_std = 0.120)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 243
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.548
SUFF++ for r=0.3 class 0.0 = 0.876 +- 0.090 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 1.0 = 0.826 +- 0.090 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 all KL = 0.923 +- 0.090 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 all L1 = 0.85 +- 0.137 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.713
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.69
SUFF++ for r=0.6 class 0.0 = 0.976 +- 0.056 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 class 1.0 = 0.891 +- 0.056 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all KL = 0.973 +- 0.056 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all L1 = 0.933 +- 0.110 (in-sample avg dev_std = 0.103)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
SUFF++ for r=0.9 class 0.0 = 0.994 +- 0.045 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 class 1.0 = 0.944 +- 0.045 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all KL = 0.986 +- 0.045 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.073 (in-sample avg dev_std = 0.086)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.62
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 144
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.591
SUFF++ for r=0.3 class 0.0 = 0.911 +- 0.107 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.3 class 1.0 = 0.849 +- 0.107 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.3 all KL = 0.933 +- 0.107 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.3 all L1 = 0.88 +- 0.136 (in-sample avg dev_std = 0.183)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.671
SUFF++ for r=0.6 class 0.0 = 0.98 +- 0.075 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 class 1.0 = 0.924 +- 0.075 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all KL = 0.975 +- 0.075 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all L1 = 0.952 +- 0.100 (in-sample avg dev_std = 0.103)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.749
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.739
SUFF++ for r=0.9 class 0.0 = 0.997 +- 0.057 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.057 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.9 all KL = 0.986 +- 0.057 (in-sample avg dev_std = 0.097)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.075 (in-sample avg dev_std = 0.097)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.655
NEC for r=0.3 class 0.0 = 0.101 +- 0.059 (in-sample avg dev_std = 0.147)
NEC for r=0.3 class 1.0 = 0.131 +- 0.059 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all KL = 0.045 +- 0.059 (in-sample avg dev_std = 0.147)
NEC for r=0.3 all L1 = 0.116 +- 0.092 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.734
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.708
NEC for r=0.6 class 0.0 = 0.03 +- 0.067 (in-sample avg dev_std = 0.121)
NEC for r=0.6 class 1.0 = 0.111 +- 0.067 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all KL = 0.031 +- 0.067 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all L1 = 0.071 +- 0.112 (in-sample avg dev_std = 0.121)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.76
NEC for r=0.9 class 0.0 = 0.02 +- 0.154 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.195 +- 0.154 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.075 +- 0.154 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.108 +- 0.182 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.825
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.778
NEC for r=1.0 class 0.0 = 0.02 +- 0.188 (in-sample avg dev_std = 0.197)
NEC for r=1.0 class 1.0 = 0.217 +- 0.188 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all KL = 0.098 +- 0.188 (in-sample avg dev_std = 0.197)
NEC for r=1.0 all L1 = 0.119 +- 0.197 (in-sample avg dev_std = 0.197)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.616
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0.0 = 0.108 +- 0.065 (in-sample avg dev_std = 0.144)
NEC for r=0.3 class 1.0 = 0.124 +- 0.065 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all KL = 0.047 +- 0.065 (in-sample avg dev_std = 0.144)
NEC for r=0.3 all L1 = 0.116 +- 0.104 (in-sample avg dev_std = 0.144)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.713
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.708
NEC for r=0.6 class 0.0 = 0.017 +- 0.055 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.109 +- 0.055 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.024 +- 0.055 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.063 +- 0.110 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.727
NEC for r=0.9 class 0.0 = 0.015 +- 0.123 (in-sample avg dev_std = 0.154)
NEC for r=0.9 class 1.0 = 0.153 +- 0.123 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all KL = 0.058 +- 0.123 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all L1 = 0.084 +- 0.149 (in-sample avg dev_std = 0.154)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.722
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.713
NEC for r=1.0 class 0.0 = 0.024 +- 0.182 (in-sample avg dev_std = 0.158)
NEC for r=1.0 class 1.0 = 0.172 +- 0.182 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all KL = 0.087 +- 0.182 (in-sample avg dev_std = 0.158)
NEC for r=1.0 all L1 = 0.098 +- 0.175 (in-sample avg dev_std = 0.158)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
NEC for r=0.3 class 0.0 = 0.09 +- 0.090 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 1.0 = 0.136 +- 0.090 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all KL = 0.055 +- 0.090 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all L1 = 0.113 +- 0.126 (in-sample avg dev_std = 0.163)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.681
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.641
NEC for r=0.6 class 0.0 = 0.018 +- 0.095 (in-sample avg dev_std = 0.133)
NEC for r=0.6 class 1.0 = 0.075 +- 0.095 (in-sample avg dev_std = 0.133)
NEC for r=0.6 all KL = 0.028 +- 0.095 (in-sample avg dev_std = 0.133)
NEC for r=0.6 all L1 = 0.046 +- 0.098 (in-sample avg dev_std = 0.133)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.749
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.703
NEC for r=0.9 class 0.0 = 0.007 +- 0.132 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 1.0 = 0.097 +- 0.132 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all KL = 0.037 +- 0.132 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all L1 = 0.052 +- 0.136 (in-sample avg dev_std = 0.128)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.726
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.701
NEC for r=1.0 class 0.0 = 0.006 +- 0.141 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1.0 = 0.099 +- 0.141 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.041 +- 0.141 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.053 +- 0.142 (in-sample avg dev_std = 0.132)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.952, 0.974, 0.987, 1.0], 'all_L1': [0.882, 0.952, 0.979, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.971, 0.983, 0.979, 1.0], 'all_L1': [0.924, 0.963, 0.97, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.97, 0.98, 0.978, 1.0], 'all_L1': [0.916, 0.957, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.974, 0.975, 1.0], 'all_L1': [0.845, 0.948, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.916, 0.965, 0.981, 1.0], 'all_L1': [0.84, 0.919, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.028, 0.025, 0.055, 0.054], 'all_L1': [0.085, 0.042, 0.058, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.019, 0.015, 0.065, 0.093], 'all_L1': [0.06, 0.031, 0.071, 0.084]}), defaultdict(<class 'list'>, {'all_KL': [0.017, 0.029, 0.069, 0.095], 'all_L1': [0.066, 0.046, 0.072, 0.088]}), defaultdict(<class 'list'>, {'all_KL': [0.049, 0.027, 0.079, 0.097], 'all_L1': [0.124, 0.049, 0.073, 0.088]}), defaultdict(<class 'list'>, {'all_KL': [0.045, 0.031, 0.075, 0.098], 'all_L1': [0.116, 0.071, 0.108, 0.119]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.943, 0.979, 0.99, 1.0], 'all_L1': [0.872, 0.956, 0.983, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.966, 0.983, 0.99, 1.0], 'all_L1': [0.921, 0.959, 0.979, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.962, 0.983, 0.985, 1.0], 'all_L1': [0.906, 0.958, 0.977, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.903, 0.967, 0.983, 1.0], 'all_L1': [0.833, 0.947, 0.981, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.923, 0.973, 0.986, 1.0], 'all_L1': [0.85, 0.933, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.035, 0.015, 0.032, 0.031], 'all_L1': [0.098, 0.037, 0.04, 0.035]}), defaultdict(<class 'list'>, {'all_KL': [0.014, 0.014, 0.04, 0.04], 'all_L1': [0.051, 0.035, 0.064, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.017, 0.02, 0.085, 0.093], 'all_L1': [0.063, 0.04, 0.083, 0.083]}), defaultdict(<class 'list'>, {'all_KL': [0.046, 0.039, 0.065, 0.07], 'all_L1': [0.115, 0.052, 0.054, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.047, 0.024, 0.058, 0.087], 'all_L1': [0.116, 0.063, 0.084, 0.098]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.959, 0.989, 0.995, 1.0], 'all_L1': [0.902, 0.979, 0.99, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.972, 0.992, 0.987, 1.0], 'all_L1': [0.936, 0.978, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.978, 0.993, 0.992, 1.0], 'all_L1': [0.932, 0.98, 0.988, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.944, 0.986, 0.997, 1.0], 'all_L1': [0.889, 0.97, 0.991, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.933, 0.975, 0.986, 1.0], 'all_L1': [0.88, 0.952, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.028, 0.007, 0.009, 0.011], 'all_L1': [0.077, 0.015, 0.014, 0.014]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.005, 0.023, 0.02], 'all_L1': [0.052, 0.016, 0.031, 0.032]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.007, 0.013, 0.022], 'all_L1': [0.059, 0.018, 0.018, 0.025]}), defaultdict(<class 'list'>, {'all_KL': [0.031, 0.013, 0.029, 0.032], 'all_L1': [0.079, 0.026, 0.032, 0.034]}), defaultdict(<class 'list'>, {'all_KL': [0.055, 0.028, 0.037, 0.041], 'all_L1': [0.113, 0.046, 0.052, 0.053]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.881 +- 0.035, 0.948 +- 0.015, 0.970 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.946 +- 0.023, 0.975 +- 0.006, 0.980 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.558 +- 0.020, 0.687 +- 0.033, 0.770 +- 0.017
nec class all_L1  =  0.090 +- 0.026, 0.048 +- 0.013, 0.076 +- 0.017, 0.087 +- 0.020
nec class all_KL  =  0.032 +- 0.013, 0.025 +- 0.006, 0.069 +- 0.008, 0.087 +- 0.017
nec_acc_int  =  0.606 +- 0.028, 0.679 +- 0.021, 0.725 +- 0.018, 0.748 +- 0.017

Eval split val
suff++ class all_L1  =  0.876 +- 0.033, 0.951 +- 0.010, 0.978 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.939 +- 0.024, 0.977 +- 0.006, 0.987 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.558 +- 0.023, 0.681 +- 0.014, 0.728 +- 0.018
nec class all_L1  =  0.089 +- 0.027, 0.045 +- 0.011, 0.065 +- 0.017, 0.067 +- 0.022
nec class all_KL  =  0.032 +- 0.014, 0.022 +- 0.009, 0.056 +- 0.019, 0.064 +- 0.025
nec_acc_int  =  0.642 +- 0.025, 0.707 +- 0.012, 0.723 +- 0.013, 0.724 +- 0.016

Eval split test
suff++ class all_L1  =  0.908 +- 0.023, 0.972 +- 0.011, 0.985 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.957 +- 0.017, 0.987 +- 0.006, 0.991 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.541 +- 0.026, 0.596 +- 0.060, 0.678 +- 0.037
nec class all_L1  =  0.076 +- 0.021, 0.024 +- 0.012, 0.029 +- 0.013, 0.032 +- 0.013
nec class all_KL  =  0.030 +- 0.014, 0.012 +- 0.008, 0.022 +- 0.010, 0.025 +- 0.010
nec_acc_int  =  0.565 +- 0.021, 0.595 +- 0.065, 0.647 +- 0.043, 0.668 +- 0.021


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.486 +- 0.005, 0.498 +- 0.002, 0.523 +- 0.006, 0.544 +- 0.010
Faith. Armon (L1)= 		  =  0.162 +- 0.042, 0.091 +- 0.023, 0.141 +- 0.028, 0.160 +- 0.033
Faith. GMean (L1)= 	  =  0.278 +- 0.035, 0.211 +- 0.027, 0.271 +- 0.028, 0.293 +- 0.034
Faith. Aritm (KL)= 		  =  0.489 +- 0.005, 0.500 +- 0.002, 0.524 +- 0.003, 0.544 +- 0.008
Faith. Armon (KL)= 		  =  0.061 +- 0.025, 0.049 +- 0.011, 0.128 +- 0.015, 0.160 +- 0.029
Faith. GMean (KL)= 	  =  0.169 +- 0.034, 0.156 +- 0.018, 0.259 +- 0.016, 0.294 +- 0.031

Eval split val
Faith. Aritm (L1)= 		  =  0.482 +- 0.004, 0.498 +- 0.001, 0.521 +- 0.007, 0.534 +- 0.011
Faith. Armon (L1)= 		  =  0.159 +- 0.044, 0.086 +- 0.019, 0.121 +- 0.030, 0.125 +- 0.038
Faith. GMean (L1)= 	  =  0.274 +- 0.039, 0.206 +- 0.022, 0.250 +- 0.033, 0.256 +- 0.043
Faith. Aritm (KL)= 		  =  0.486 +- 0.006, 0.500 +- 0.002, 0.521 +- 0.008, 0.532 +- 0.012
Faith. Armon (KL)= 		  =  0.061 +- 0.026, 0.044 +- 0.017, 0.105 +- 0.033, 0.120 +- 0.044
Faith. GMean (KL)= 	  =  0.168 +- 0.038, 0.145 +- 0.028, 0.232 +- 0.039, 0.248 +- 0.051

Eval split test
Faith. Aritm (L1)= 		  =  0.492 +- 0.005, 0.498 +- 0.001, 0.507 +- 0.005, 0.516 +- 0.006
Faith. Armon (L1)= 		  =  0.139 +- 0.035, 0.047 +- 0.022, 0.057 +- 0.025, 0.061 +- 0.024
Faith. GMean (L1)= 	  =  0.260 +- 0.033, 0.149 +- 0.033, 0.166 +- 0.038, 0.174 +- 0.036
Faith. Aritm (KL)= 		  =  0.493 +- 0.003, 0.499 +- 0.001, 0.507 +- 0.005, 0.513 +- 0.005
Faith. Armon (KL)= 		  =  0.057 +- 0.026, 0.024 +- 0.016, 0.043 +- 0.020, 0.049 +- 0.020
Faith. GMean (KL)= 	  =  0.164 +- 0.036, 0.103 +- 0.034, 0.144 +- 0.035, 0.155 +- 0.033
Computed for split load_split = id



Completed in  0:08:35.174263  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold hard

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:12:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:07 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:10 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:14 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:12:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ROC-AUC: 0.9532
Train Loss: 0.0980
ID Validation ROC-AUC: 0.8305
ID Validation Loss: 0.2062
ID Test ROC-AUC: 0.7788
ID Test Loss: 0.1925
OOD Validation ROC-AUC: 0.7671
OOD Validation Loss: 0.2052
OOD Test ROC-AUC: 0.6244
OOD Test Loss: 0.1479

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ROC-AUC: 0.9402
Train Loss: 0.1061
ID Validation ROC-AUC: 0.8141
ID Validation Loss: 0.2306
ID Test ROC-AUC: 0.7451
ID Test Loss: 0.2142
OOD Validation ROC-AUC: 0.7692
OOD Validation Loss: 0.2394
OOD Test ROC-AUC: 0.6166
OOD Test Loss: 0.1630

[0m[1;37mINFO[0m: [1mChartInfo 0.7788 0.6244 0.7451 0.6166 0.8141 0.7692[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:12:27 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:12:34 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:12:36 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.509
SUFF++ for r=0.3 class 0.0 = 0.922 +- 0.107 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.3 class 1.0 = 0.881 +- 0.107 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.3 all KL = 0.929 +- 0.107 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.3 all L1 = 0.902 +- 0.105 (in-sample avg dev_std = 0.136)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.761
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.715
SUFF++ for r=0.6 class 0.0 = 0.946 +- 0.125 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 class 1.0 = 0.833 +- 0.125 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 all KL = 0.912 +- 0.125 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.6 all L1 = 0.889 +- 0.134 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0.0 = 0.984 +- 0.117 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 class 1.0 = 0.877 +- 0.117 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all KL = 0.951 +- 0.117 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.9 all L1 = 0.93 +- 0.125 (in-sample avg dev_std = 0.162)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.41
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.455
SUFF++ for r=0.3 class 0.0 = 0.922 +- 0.086 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 1.0 = 0.914 +- 0.086 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 all KL = 0.938 +- 0.086 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 all L1 = 0.918 +- 0.065 (in-sample avg dev_std = 0.119)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.601
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.64
SUFF++ for r=0.6 class 0.0 = 0.951 +- 0.145 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.145 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all KL = 0.917 +- 0.145 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all L1 = 0.901 +- 0.130 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.734
SUFF++ for r=0.9 class 0.0 = 0.979 +- 0.075 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 class 1.0 = 0.891 +- 0.075 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 all KL = 0.964 +- 0.075 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.112 (in-sample avg dev_std = 0.127)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.579
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.552
SUFF++ for r=0.3 class 0.0 = 0.921 +- 0.113 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 class 1.0 = 0.881 +- 0.113 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 all KL = 0.938 +- 0.113 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 all L1 = 0.901 +- 0.080 (in-sample avg dev_std = 0.146)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.597
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0.0 = 0.951 +- 0.095 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 class 1.0 = 0.902 +- 0.095 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all KL = 0.951 +- 0.095 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all L1 = 0.927 +- 0.108 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.711
SUFF++ for r=0.9 class 0.0 = 0.991 +- 0.099 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.93 +- 0.099 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.969 +- 0.099 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.104 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.531
NEC for r=0.3 class 0.0 = 0.062 +- 0.104 (in-sample avg dev_std = 0.109)
NEC for r=0.3 class 1.0 = 0.103 +- 0.104 (in-sample avg dev_std = 0.109)
NEC for r=0.3 all KL = 0.06 +- 0.104 (in-sample avg dev_std = 0.109)
NEC for r=0.3 all L1 = 0.082 +- 0.096 (in-sample avg dev_std = 0.109)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.761
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.735
NEC for r=0.6 class 0.0 = 0.032 +- 0.128 (in-sample avg dev_std = 0.160)
NEC for r=0.6 class 1.0 = 0.164 +- 0.128 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all KL = 0.066 +- 0.128 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all L1 = 0.098 +- 0.149 (in-sample avg dev_std = 0.160)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.842
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.795
NEC for r=0.9 class 0.0 = 0.022 +- 0.184 (in-sample avg dev_std = 0.197)
NEC for r=0.9 class 1.0 = 0.188 +- 0.184 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all KL = 0.09 +- 0.184 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all L1 = 0.105 +- 0.182 (in-sample avg dev_std = 0.197)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.85
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0.0 = 0.02 +- 0.205 (in-sample avg dev_std = 0.221)
NEC for r=1.0 class 1.0 = 0.187 +- 0.205 (in-sample avg dev_std = 0.221)
NEC for r=1.0 all KL = 0.1 +- 0.205 (in-sample avg dev_std = 0.221)
NEC for r=1.0 all L1 = 0.104 +- 0.190 (in-sample avg dev_std = 0.221)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.41
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.523
NEC for r=0.3 class 0.0 = 0.057 +- 0.127 (in-sample avg dev_std = 0.101)
NEC for r=0.3 class 1.0 = 0.089 +- 0.127 (in-sample avg dev_std = 0.101)
NEC for r=0.3 all KL = 0.071 +- 0.127 (in-sample avg dev_std = 0.101)
NEC for r=0.3 all L1 = 0.073 +- 0.073 (in-sample avg dev_std = 0.101)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.601
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.637
NEC for r=0.6 class 0.0 = 0.041 +- 0.130 (in-sample avg dev_std = 0.136)
NEC for r=0.6 class 1.0 = 0.122 +- 0.130 (in-sample avg dev_std = 0.136)
NEC for r=0.6 all KL = 0.066 +- 0.130 (in-sample avg dev_std = 0.136)
NEC for r=0.6 all L1 = 0.081 +- 0.114 (in-sample avg dev_std = 0.136)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.699
NEC for r=0.9 class 0.0 = 0.03 +- 0.142 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1.0 = 0.145 +- 0.142 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.064 +- 0.142 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.087 +- 0.151 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.748
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.71
NEC for r=1.0 class 0.0 = 0.021 +- 0.159 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 1.0 = 0.155 +- 0.159 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all KL = 0.072 +- 0.159 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all L1 = 0.088 +- 0.160 (in-sample avg dev_std = 0.177)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.579
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.564
NEC for r=0.3 class 0.0 = 0.047 +- 0.063 (in-sample avg dev_std = 0.079)
NEC for r=0.3 class 1.0 = 0.062 +- 0.063 (in-sample avg dev_std = 0.079)
NEC for r=0.3 all KL = 0.028 +- 0.063 (in-sample avg dev_std = 0.079)
NEC for r=0.3 all L1 = 0.055 +- 0.053 (in-sample avg dev_std = 0.079)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.597
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.558
NEC for r=0.6 class 0.0 = 0.037 +- 0.055 (in-sample avg dev_std = 0.103)
NEC for r=0.6 class 1.0 = 0.069 +- 0.055 (in-sample avg dev_std = 0.103)
NEC for r=0.6 all KL = 0.027 +- 0.055 (in-sample avg dev_std = 0.103)
NEC for r=0.6 all L1 = 0.053 +- 0.087 (in-sample avg dev_std = 0.103)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.689
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.638
NEC for r=0.9 class 0.0 = 0.01 +- 0.142 (in-sample avg dev_std = 0.147)
NEC for r=0.9 class 1.0 = 0.097 +- 0.142 (in-sample avg dev_std = 0.147)
NEC for r=0.9 all KL = 0.048 +- 0.142 (in-sample avg dev_std = 0.147)
NEC for r=0.9 all L1 = 0.054 +- 0.141 (in-sample avg dev_std = 0.147)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.665
NEC for r=1.0 class 0.0 = 0.006 +- 0.160 (in-sample avg dev_std = 0.160)
NEC for r=1.0 class 1.0 = 0.096 +- 0.160 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all KL = 0.053 +- 0.160 (in-sample avg dev_std = 0.160)
NEC for r=1.0 all L1 = 0.051 +- 0.139 (in-sample avg dev_std = 0.160)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:13:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:13:55 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:13:59 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:14:08 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:14:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ROC-AUC: 0.9445
Train Loss: 0.0912
ID Validation ROC-AUC: 0.8320
ID Validation Loss: 0.1578
ID Test ROC-AUC: 0.8266
ID Test Loss: 0.1367
OOD Validation ROC-AUC: 0.7409
OOD Validation Loss: 0.1376
OOD Test ROC-AUC: 0.7327
OOD Test Loss: 0.0912

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 52...
[0m[1;37mINFO[0m: [1mCheckpoint 52: 
-----------------------------------
Train ROC-AUC: 0.8751
Train Loss: 0.1104
ID Validation ROC-AUC: 0.7922
ID Validation Loss: 0.1529
ID Test ROC-AUC: 0.8015
ID Test Loss: 0.1309
OOD Validation ROC-AUC: 0.7719
OOD Validation Loss: 0.1266
OOD Test ROC-AUC: 0.7217
OOD Test Loss: 0.0854

[0m[1;37mINFO[0m: [1mChartInfo 0.8266 0.7327 0.8015 0.7217 0.7922 0.7719[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:14:09 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:14:11 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:14:13 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.61
SUFF++ for r=0.3 class 0.0 = 0.962 +- 0.055 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.3 class 1.0 = 0.932 +- 0.055 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.3 all KL = 0.966 +- 0.055 (in-sample avg dev_std = 0.090)
SUFF++ for r=0.3 all L1 = 0.947 +- 0.068 (in-sample avg dev_std = 0.090)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.761
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.708
SUFF++ for r=0.6 class 0.0 = 0.927 +- 0.124 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 class 1.0 = 0.829 +- 0.124 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all KL = 0.909 +- 0.124 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all L1 = 0.878 +- 0.130 (in-sample avg dev_std = 0.209)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.801
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.768
SUFF++ for r=0.9 class 0.0 = 0.947 +- 0.112 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 class 1.0 = 0.856 +- 0.112 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all KL = 0.941 +- 0.112 (in-sample avg dev_std = 0.173)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.128 (in-sample avg dev_std = 0.173)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0.0 = 0.977 +- 0.037 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.3 class 1.0 = 0.955 +- 0.037 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.3 all KL = 0.978 +- 0.037 (in-sample avg dev_std = 0.074)
SUFF++ for r=0.3 all L1 = 0.966 +- 0.043 (in-sample avg dev_std = 0.074)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
SUFF++ for r=0.6 class 0.0 = 0.942 +- 0.143 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 class 1.0 = 0.859 +- 0.143 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all KL = 0.912 +- 0.143 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all L1 = 0.9 +- 0.122 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.694
SUFF++ for r=0.9 class 0.0 = 0.965 +- 0.081 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 1.0 = 0.915 +- 0.081 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all KL = 0.97 +- 0.081 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.101 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.695
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.63
SUFF++ for r=0.3 class 0.0 = 0.978 +- 0.043 (in-sample avg dev_std = 0.057)
SUFF++ for r=0.3 class 1.0 = 0.934 +- 0.043 (in-sample avg dev_std = 0.057)
SUFF++ for r=0.3 all KL = 0.98 +- 0.043 (in-sample avg dev_std = 0.057)
SUFF++ for r=0.3 all L1 = 0.956 +- 0.071 (in-sample avg dev_std = 0.057)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.727
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.694
SUFF++ for r=0.6 class 0.0 = 0.97 +- 0.079 (in-sample avg dev_std = 0.116)
SUFF++ for r=0.6 class 1.0 = 0.897 +- 0.079 (in-sample avg dev_std = 0.116)
SUFF++ for r=0.6 all KL = 0.964 +- 0.079 (in-sample avg dev_std = 0.116)
SUFF++ for r=0.6 all L1 = 0.933 +- 0.105 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.769
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.737
SUFF++ for r=0.9 class 0.0 = 0.98 +- 0.057 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 1.0 = 0.923 +- 0.057 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all KL = 0.98 +- 0.057 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.093 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
NEC for r=0.3 class 0.0 = 0.023 +- 0.053 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 1.0 = 0.067 +- 0.053 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all KL = 0.022 +- 0.053 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all L1 = 0.045 +- 0.068 (in-sample avg dev_std = 0.051)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.761
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.724
NEC for r=0.6 class 0.0 = 0.03 +- 0.101 (in-sample avg dev_std = 0.127)
NEC for r=0.6 class 1.0 = 0.155 +- 0.101 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all KL = 0.048 +- 0.101 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all L1 = 0.093 +- 0.142 (in-sample avg dev_std = 0.127)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.801
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.771
NEC for r=0.9 class 0.0 = 0.042 +- 0.142 (in-sample avg dev_std = 0.160)
NEC for r=0.9 class 1.0 = 0.198 +- 0.142 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all KL = 0.076 +- 0.142 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all L1 = 0.12 +- 0.169 (in-sample avg dev_std = 0.160)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.816
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.782
NEC for r=1.0 class 0.0 = 0.046 +- 0.154 (in-sample avg dev_std = 0.181)
NEC for r=1.0 class 1.0 = 0.194 +- 0.154 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all KL = 0.084 +- 0.154 (in-sample avg dev_std = 0.181)
NEC for r=1.0 all L1 = 0.12 +- 0.167 (in-sample avg dev_std = 0.181)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.63
NEC for r=0.3 class 0.0 = 0.016 +- 0.048 (in-sample avg dev_std = 0.047)
NEC for r=0.3 class 1.0 = 0.048 +- 0.048 (in-sample avg dev_std = 0.047)
NEC for r=0.3 all KL = 0.018 +- 0.048 (in-sample avg dev_std = 0.047)
NEC for r=0.3 all L1 = 0.032 +- 0.052 (in-sample avg dev_std = 0.047)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.689
NEC for r=0.6 class 0.0 = 0.031 +- 0.129 (in-sample avg dev_std = 0.111)
NEC for r=0.6 class 1.0 = 0.103 +- 0.129 (in-sample avg dev_std = 0.111)
NEC for r=0.6 all KL = 0.043 +- 0.129 (in-sample avg dev_std = 0.111)
NEC for r=0.6 all L1 = 0.067 +- 0.121 (in-sample avg dev_std = 0.111)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.699
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.708
NEC for r=0.9 class 0.0 = 0.044 +- 0.101 (in-sample avg dev_std = 0.116)
NEC for r=0.9 class 1.0 = 0.112 +- 0.101 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all KL = 0.044 +- 0.101 (in-sample avg dev_std = 0.116)
NEC for r=0.9 all L1 = 0.078 +- 0.123 (in-sample avg dev_std = 0.116)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.725
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.715
NEC for r=1.0 class 0.0 = 0.037 +- 0.082 (in-sample avg dev_std = 0.114)
NEC for r=1.0 class 1.0 = 0.106 +- 0.082 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all KL = 0.04 +- 0.082 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all L1 = 0.071 +- 0.112 (in-sample avg dev_std = 0.114)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.695
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
NEC for r=0.3 class 0.0 = 0.022 +- 0.041 (in-sample avg dev_std = 0.039)
NEC for r=0.3 class 1.0 = 0.064 +- 0.041 (in-sample avg dev_std = 0.039)
NEC for r=0.3 all KL = 0.018 +- 0.041 (in-sample avg dev_std = 0.039)
NEC for r=0.3 all L1 = 0.043 +- 0.071 (in-sample avg dev_std = 0.039)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.727
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.675
NEC for r=0.6 class 0.0 = 0.027 +- 0.074 (in-sample avg dev_std = 0.074)
NEC for r=0.6 class 1.0 = 0.092 +- 0.074 (in-sample avg dev_std = 0.074)
NEC for r=0.6 all KL = 0.027 +- 0.074 (in-sample avg dev_std = 0.074)
NEC for r=0.6 all L1 = 0.059 +- 0.108 (in-sample avg dev_std = 0.074)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.769
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.74
NEC for r=0.9 class 0.0 = 0.019 +- 0.097 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 1.0 = 0.1 +- 0.097 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all KL = 0.03 +- 0.097 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all L1 = 0.059 +- 0.120 (in-sample avg dev_std = 0.114)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.77
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.742
NEC for r=1.0 class 0.0 = 0.017 +- 0.111 (in-sample avg dev_std = 0.147)
NEC for r=1.0 class 1.0 = 0.107 +- 0.111 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all KL = 0.038 +- 0.111 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all L1 = 0.062 +- 0.118 (in-sample avg dev_std = 0.147)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:15:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:30 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:33 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:37 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:15:43 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 96...
[0m[1;37mINFO[0m: [1mCheckpoint 96: 
-----------------------------------
Train ROC-AUC: 0.9257
Train Loss: 0.1199
ID Validation ROC-AUC: 0.8221
ID Validation Loss: 0.1791
ID Test ROC-AUC: 0.8010
ID Test Loss: 0.1595
OOD Validation ROC-AUC: 0.7722
OOD Validation Loss: 0.1543
OOD Test ROC-AUC: 0.6686
OOD Test Loss: 0.1149

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ROC-AUC: 0.8824
Train Loss: 0.1310
ID Validation ROC-AUC: 0.7935
ID Validation Loss: 0.1621
ID Test ROC-AUC: 0.7773
ID Test Loss: 0.1540
OOD Validation ROC-AUC: 0.7771
OOD Validation Loss: 0.1514
OOD Test ROC-AUC: 0.6831
OOD Test Loss: 0.0953

[0m[1;37mINFO[0m: [1mChartInfo 0.8010 0.6686 0.7773 0.6831 0.7935 0.7771[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:15:44 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:15:46 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:15:48 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.538
SUFF++ for r=0.3 class 0.0 = 0.935 +- 0.042 (in-sample avg dev_std = 0.085)
SUFF++ for r=0.3 class 1.0 = 0.909 +- 0.042 (in-sample avg dev_std = 0.085)
SUFF++ for r=0.3 all KL = 0.97 +- 0.042 (in-sample avg dev_std = 0.085)
SUFF++ for r=0.3 all L1 = 0.922 +- 0.066 (in-sample avg dev_std = 0.085)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.754
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.686
SUFF++ for r=0.6 class 0.0 = 0.967 +- 0.115 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 class 1.0 = 0.876 +- 0.115 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all KL = 0.955 +- 0.115 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all L1 = 0.922 +- 0.113 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.793
SUFF++ for r=0.9 class 0.0 = 0.986 +- 0.116 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 class 1.0 = 0.858 +- 0.116 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all KL = 0.953 +- 0.116 (in-sample avg dev_std = 0.137)
SUFF++ for r=0.9 all L1 = 0.922 +- 0.141 (in-sample avg dev_std = 0.137)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.653
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0.0 = 0.938 +- 0.017 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 class 1.0 = 0.92 +- 0.017 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 all KL = 0.98 +- 0.017 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 all L1 = 0.929 +- 0.039 (in-sample avg dev_std = 0.060)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.756
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.634
SUFF++ for r=0.6 class 0.0 = 0.962 +- 0.058 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 class 1.0 = 0.895 +- 0.058 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all KL = 0.967 +- 0.058 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all L1 = 0.928 +- 0.088 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.75
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.732
SUFF++ for r=0.9 class 0.0 = 0.983 +- 0.115 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 1.0 = 0.88 +- 0.115 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all KL = 0.957 +- 0.115 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all L1 = 0.932 +- 0.145 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.607
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.561
SUFF++ for r=0.3 class 0.0 = 0.939 +- 0.015 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.3 class 1.0 = 0.928 +- 0.015 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.3 all KL = 0.981 +- 0.015 (in-sample avg dev_std = 0.054)
SUFF++ for r=0.3 all L1 = 0.934 +- 0.035 (in-sample avg dev_std = 0.054)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.617
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.593
SUFF++ for r=0.6 class 0.0 = 0.966 +- 0.021 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.6 class 1.0 = 0.942 +- 0.021 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.6 all KL = 0.986 +- 0.021 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.6 all L1 = 0.954 +- 0.053 (in-sample avg dev_std = 0.053)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.694
SUFF++ for r=0.9 class 0.0 = 0.991 +- 0.033 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.9 class 1.0 = 0.943 +- 0.033 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.9 all KL = 0.989 +- 0.033 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.077 (in-sample avg dev_std = 0.061)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.527
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.513
NEC for r=0.3 class 0.0 = 0.033 +- 0.052 (in-sample avg dev_std = 0.048)
NEC for r=0.3 class 1.0 = 0.063 +- 0.052 (in-sample avg dev_std = 0.048)
NEC for r=0.3 all KL = 0.016 +- 0.052 (in-sample avg dev_std = 0.048)
NEC for r=0.3 all L1 = 0.048 +- 0.075 (in-sample avg dev_std = 0.048)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.754
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.705
NEC for r=0.6 class 0.0 = 0.019 +- 0.119 (in-sample avg dev_std = 0.088)
NEC for r=0.6 class 1.0 = 0.095 +- 0.119 (in-sample avg dev_std = 0.088)
NEC for r=0.6 all KL = 0.031 +- 0.119 (in-sample avg dev_std = 0.088)
NEC for r=0.6 all L1 = 0.057 +- 0.119 (in-sample avg dev_std = 0.088)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.792
NEC for r=0.9 class 0.0 = 0.015 +- 0.153 (in-sample avg dev_std = 0.152)
NEC for r=0.9 class 1.0 = 0.158 +- 0.153 (in-sample avg dev_std = 0.152)
NEC for r=0.9 all KL = 0.058 +- 0.153 (in-sample avg dev_std = 0.152)
NEC for r=0.9 all L1 = 0.087 +- 0.163 (in-sample avg dev_std = 0.152)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.842
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.802
NEC for r=1.0 class 0.0 = 0.016 +- 0.156 (in-sample avg dev_std = 0.167)
NEC for r=1.0 class 1.0 = 0.162 +- 0.156 (in-sample avg dev_std = 0.167)
NEC for r=1.0 all KL = 0.065 +- 0.156 (in-sample avg dev_std = 0.167)
NEC for r=1.0 all L1 = 0.089 +- 0.163 (in-sample avg dev_std = 0.167)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.653
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.611
NEC for r=0.3 class 0.0 = 0.035 +- 0.014 (in-sample avg dev_std = 0.033)
NEC for r=0.3 class 1.0 = 0.043 +- 0.014 (in-sample avg dev_std = 0.033)
NEC for r=0.3 all KL = 0.007 +- 0.014 (in-sample avg dev_std = 0.033)
NEC for r=0.3 all L1 = 0.039 +- 0.035 (in-sample avg dev_std = 0.033)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.756
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.745
NEC for r=0.6 class 0.0 = 0.019 +- 0.046 (in-sample avg dev_std = 0.083)
NEC for r=0.6 class 1.0 = 0.066 +- 0.046 (in-sample avg dev_std = 0.083)
NEC for r=0.6 all KL = 0.015 +- 0.046 (in-sample avg dev_std = 0.083)
NEC for r=0.6 all L1 = 0.043 +- 0.074 (in-sample avg dev_std = 0.083)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.75
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.752
NEC for r=0.9 class 0.0 = 0.014 +- 0.068 (in-sample avg dev_std = 0.110)
NEC for r=0.9 class 1.0 = 0.091 +- 0.068 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all KL = 0.024 +- 0.068 (in-sample avg dev_std = 0.110)
NEC for r=0.9 all L1 = 0.052 +- 0.102 (in-sample avg dev_std = 0.110)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.754
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.747
NEC for r=1.0 class 0.0 = 0.011 +- 0.081 (in-sample avg dev_std = 0.112)
NEC for r=1.0 class 1.0 = 0.084 +- 0.081 (in-sample avg dev_std = 0.112)
NEC for r=1.0 all KL = 0.031 +- 0.081 (in-sample avg dev_std = 0.112)
NEC for r=1.0 all L1 = 0.047 +- 0.101 (in-sample avg dev_std = 0.112)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.607
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.581
NEC for r=0.3 class 0.0 = 0.028 +- 0.015 (in-sample avg dev_std = 0.024)
NEC for r=0.3 class 1.0 = 0.039 +- 0.015 (in-sample avg dev_std = 0.024)
NEC for r=0.3 all KL = 0.006 +- 0.015 (in-sample avg dev_std = 0.024)
NEC for r=0.3 all L1 = 0.033 +- 0.030 (in-sample avg dev_std = 0.024)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.617
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.626
NEC for r=0.6 class 0.0 = 0.017 +- 0.013 (in-sample avg dev_std = 0.029)
NEC for r=0.6 class 1.0 = 0.036 +- 0.013 (in-sample avg dev_std = 0.029)
NEC for r=0.6 all KL = 0.006 +- 0.013 (in-sample avg dev_std = 0.029)
NEC for r=0.6 all L1 = 0.027 +- 0.036 (in-sample avg dev_std = 0.029)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.671
NEC for r=0.9 class 0.0 = 0.009 +- 0.054 (in-sample avg dev_std = 0.090)
NEC for r=0.9 class 1.0 = 0.059 +- 0.054 (in-sample avg dev_std = 0.090)
NEC for r=0.9 all KL = 0.015 +- 0.054 (in-sample avg dev_std = 0.090)
NEC for r=0.9 all L1 = 0.034 +- 0.085 (in-sample avg dev_std = 0.090)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.69
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.669
NEC for r=1.0 class 0.0 = 0.007 +- 0.108 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1.0 = 0.07 +- 0.108 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.028 +- 0.108 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.039 +- 0.113 (in-sample avg dev_std = 0.123)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:17:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:06 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:09 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:13 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:19 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:17:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 159...
[0m[1;37mINFO[0m: [1mCheckpoint 159: 
-----------------------------------
Train ROC-AUC: 0.9613
Train Loss: 0.0956
ID Validation ROC-AUC: 0.8348
ID Validation Loss: 0.2750
ID Test ROC-AUC: 0.7847
ID Test Loss: 0.2525
OOD Validation ROC-AUC: 0.7516
OOD Validation Loss: 0.2752
OOD Test ROC-AUC: 0.6661
OOD Test Loss: 0.1766

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 135...
[0m[1;37mINFO[0m: [1mCheckpoint 135: 
-----------------------------------
Train ROC-AUC: 0.9435
Train Loss: 0.1015
ID Validation ROC-AUC: 0.8158
ID Validation Loss: 0.2158
ID Test ROC-AUC: 0.8056
ID Test Loss: 0.1825
OOD Validation ROC-AUC: 0.7903
OOD Validation Loss: 0.2058
OOD Test ROC-AUC: 0.7035
OOD Test Loss: 0.1318

[0m[1;37mINFO[0m: [1mChartInfo 0.7847 0.6661 0.8056 0.7035 0.8158 0.7903[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:17:21 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:17:23 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:17:24 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0.0 = 0.951 +- 0.095 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.3 class 1.0 = 0.91 +- 0.095 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.3 all KL = 0.954 +- 0.095 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.087 (in-sample avg dev_std = 0.112)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.772
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.706
SUFF++ for r=0.6 class 0.0 = 0.976 +- 0.169 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 class 1.0 = 0.84 +- 0.169 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all KL = 0.912 +- 0.169 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.6 all L1 = 0.908 +- 0.160 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.793
SUFF++ for r=0.9 class 0.0 = 0.978 +- 0.241 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1.0 = 0.809 +- 0.241 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.887 +- 0.241 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.894 +- 0.198 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.502
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.55
SUFF++ for r=0.3 class 0.0 = 0.949 +- 0.042 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.3 class 1.0 = 0.945 +- 0.042 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.3 all KL = 0.97 +- 0.042 (in-sample avg dev_std = 0.068)
SUFF++ for r=0.3 all L1 = 0.947 +- 0.042 (in-sample avg dev_std = 0.068)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.674
SUFF++ for r=0.6 class 0.0 = 0.968 +- 0.155 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 class 1.0 = 0.851 +- 0.155 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all KL = 0.909 +- 0.155 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all L1 = 0.91 +- 0.142 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.726
SUFF++ for r=0.9 class 0.0 = 0.988 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 class 1.0 = 0.882 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all KL = 0.949 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.145 (in-sample avg dev_std = 0.171)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.491
SUFF++ for r=0.3 class 0.0 = 0.97 +- 0.086 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.3 class 1.0 = 0.966 +- 0.086 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.3 all KL = 0.972 +- 0.086 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.3 all L1 = 0.968 +- 0.053 (in-sample avg dev_std = 0.096)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.616
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.605
SUFF++ for r=0.6 class 0.0 = 0.978 +- 0.138 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.6 class 1.0 = 0.937 +- 0.138 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.6 all KL = 0.946 +- 0.138 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.6 all L1 = 0.958 +- 0.100 (in-sample avg dev_std = 0.166)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0.0 = 0.994 +- 0.094 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 class 1.0 = 0.942 +- 0.094 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all KL = 0.974 +- 0.094 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.110 (in-sample avg dev_std = 0.104)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.582
NEC for r=0.3 class 0.0 = 0.032 +- 0.106 (in-sample avg dev_std = 0.072)
NEC for r=0.3 class 1.0 = 0.062 +- 0.106 (in-sample avg dev_std = 0.072)
NEC for r=0.3 all KL = 0.039 +- 0.106 (in-sample avg dev_std = 0.072)
NEC for r=0.3 all L1 = 0.047 +- 0.073 (in-sample avg dev_std = 0.072)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.772
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.729
NEC for r=0.6 class 0.0 = 0.012 +- 0.104 (in-sample avg dev_std = 0.115)
NEC for r=0.6 class 1.0 = 0.096 +- 0.104 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all KL = 0.036 +- 0.104 (in-sample avg dev_std = 0.115)
NEC for r=0.6 all L1 = 0.054 +- 0.118 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.832
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.78
NEC for r=0.9 class 0.0 = 0.017 +- 0.253 (in-sample avg dev_std = 0.259)
NEC for r=0.9 class 1.0 = 0.214 +- 0.253 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all KL = 0.122 +- 0.253 (in-sample avg dev_std = 0.259)
NEC for r=0.9 all L1 = 0.116 +- 0.215 (in-sample avg dev_std = 0.259)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.832
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.779
NEC for r=1.0 class 0.0 = 0.024 +- 0.314 (in-sample avg dev_std = 0.296)
NEC for r=1.0 class 1.0 = 0.236 +- 0.314 (in-sample avg dev_std = 0.296)
NEC for r=1.0 all KL = 0.17 +- 0.314 (in-sample avg dev_std = 0.296)
NEC for r=1.0 all L1 = 0.13 +- 0.233 (in-sample avg dev_std = 0.296)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.502
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.513
NEC for r=0.3 class 0.0 = 0.04 +- 0.087 (in-sample avg dev_std = 0.045)
NEC for r=0.3 class 1.0 = 0.047 +- 0.087 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all KL = 0.037 +- 0.087 (in-sample avg dev_std = 0.045)
NEC for r=0.3 all L1 = 0.044 +- 0.044 (in-sample avg dev_std = 0.045)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
NEC for r=0.6 class 0.0 = 0.014 +- 0.074 (in-sample avg dev_std = 0.087)
NEC for r=0.6 class 1.0 = 0.074 +- 0.074 (in-sample avg dev_std = 0.087)
NEC for r=0.6 all KL = 0.027 +- 0.074 (in-sample avg dev_std = 0.087)
NEC for r=0.6 all L1 = 0.044 +- 0.086 (in-sample avg dev_std = 0.087)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.691
NEC for r=0.9 class 0.0 = 0.016 +- 0.174 (in-sample avg dev_std = 0.182)
NEC for r=0.9 class 1.0 = 0.13 +- 0.174 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all KL = 0.073 +- 0.174 (in-sample avg dev_std = 0.182)
NEC for r=0.9 all L1 = 0.073 +- 0.153 (in-sample avg dev_std = 0.182)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.728
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.701
NEC for r=1.0 class 0.0 = 0.015 +- 0.230 (in-sample avg dev_std = 0.231)
NEC for r=1.0 class 1.0 = 0.185 +- 0.230 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all KL = 0.121 +- 0.230 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all L1 = 0.1 +- 0.198 (in-sample avg dev_std = 0.231)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.484
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.532
NEC for r=0.3 class 0.0 = 0.031 +- 0.103 (in-sample avg dev_std = 0.069)
NEC for r=0.3 class 1.0 = 0.039 +- 0.103 (in-sample avg dev_std = 0.069)
NEC for r=0.3 all KL = 0.04 +- 0.103 (in-sample avg dev_std = 0.069)
NEC for r=0.3 all L1 = 0.035 +- 0.053 (in-sample avg dev_std = 0.069)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.616
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.614
NEC for r=0.6 class 0.0 = 0.008 +- 0.086 (in-sample avg dev_std = 0.081)
NEC for r=0.6 class 1.0 = 0.049 +- 0.086 (in-sample avg dev_std = 0.081)
NEC for r=0.6 all KL = 0.028 +- 0.086 (in-sample avg dev_std = 0.081)
NEC for r=0.6 all L1 = 0.028 +- 0.077 (in-sample avg dev_std = 0.081)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.679
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.67
NEC for r=0.9 class 0.0 = 0.007 +- 0.171 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1.0 = 0.087 +- 0.171 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.055 +- 0.171 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.047 +- 0.138 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.661
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.66
NEC for r=1.0 class 0.0 = 0.008 +- 0.168 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 1.0 = 0.084 +- 0.168 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all KL = 0.057 +- 0.168 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all L1 = 0.046 +- 0.132 (in-sample avg dev_std = 0.177)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Thu Apr 18 20:18:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:41 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:44 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:48 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/18/2024 08:18:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 177...
[0m[1;37mINFO[0m: [1mCheckpoint 177: 
-----------------------------------
Train ROC-AUC: 0.9687
Train Loss: 0.1000
ID Validation ROC-AUC: 0.8357
ID Validation Loss: 0.2695
ID Test ROC-AUC: 0.7759
ID Test Loss: 0.2645
OOD Validation ROC-AUC: 0.7340
OOD Validation Loss: 0.2862
OOD Test ROC-AUC: 0.6302
OOD Test Loss: 0.1922

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 94...
[0m[1;37mINFO[0m: [1mCheckpoint 94: 
-----------------------------------
Train ROC-AUC: 0.9288
Train Loss: 0.1118
ID Validation ROC-AUC: 0.8038
ID Validation Loss: 0.1703
ID Test ROC-AUC: 0.8050
ID Test Loss: 0.1526
OOD Validation ROC-AUC: 0.7770
OOD Validation Loss: 0.1788
OOD Test ROC-AUC: 0.6727
OOD Test Loss: 0.1095

[0m[1;37mINFO[0m: [1mChartInfo 0.7759 0.6302 0.8050 0.6727 0.8038 0.7770[0mGOODHIV(4112)
Data example from id_val: Data(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
Label distribution from id_val: (tensor([0., 1.]), tensor([3936,  176]))
[1;34mDEBUG[0m: 04/18/2024 08:18:56 PM : [1mUnbalanced warning for GOODHIV (id_val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([176, 176]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4113)
Data example from val: Data(x=[33, 9], edge_index=[2, 74], edge_attr=[74, 3], y=[1, 1], smiles='OC(c1ccccc1)c1c(-c2ccccc2)[nH]c(-c2ccccc2)c1C(O)c1ccccc1', idx=[1], scaffold='c1ccc(Cc2c(-c3ccccc3)[nH]c(-c3ccccc3)c2Cc2ccccc2)cc1', domain_id=[1], ori_edge_index=[2, 74], node_perm=[33])
Label distribution from val: (tensor([0., 1.]), tensor([3987,  126]))
[1;34mDEBUG[0m: 04/18/2024 08:18:59 PM : [1mUnbalanced warning for GOODHIV (val)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([126, 126]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 04/18/2024 08:19:00 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 339
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.539
SUFF++ for r=0.3 class 0.0 = 0.941 +- 0.031 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 class 1.0 = 0.927 +- 0.031 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 all KL = 0.976 +- 0.031 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.3 all L1 = 0.934 +- 0.059 (in-sample avg dev_std = 0.072)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.748
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.7
SUFF++ for r=0.6 class 0.0 = 0.985 +- 0.078 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 class 1.0 = 0.9 +- 0.078 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all KL = 0.971 +- 0.078 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.115 (in-sample avg dev_std = 0.111)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.801
SUFF++ for r=0.9 class 0.0 = 0.995 +- 0.100 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 1.0 = 0.929 +- 0.100 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all KL = 0.974 +- 0.100 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.105 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.563
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 243
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.51
SUFF++ for r=0.3 class 0.0 = 0.948 +- 0.023 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 class 1.0 = 0.941 +- 0.023 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 all KL = 0.982 +- 0.023 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.3 all L1 = 0.944 +- 0.048 (in-sample avg dev_std = 0.060)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0.0 = 0.989 +- 0.059 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 class 1.0 = 0.93 +- 0.059 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 all KL = 0.981 +- 0.059 (in-sample avg dev_std = 0.072)
SUFF++ for r=0.6 all L1 = 0.96 +- 0.097 (in-sample avg dev_std = 0.072)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.697
SUFF++ for r=0.9 class 0.0 = 0.999 +- 0.080 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1.0 = 0.951 +- 0.080 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.983 +- 0.080 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.086 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 144
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.958 +- 0.020 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.3 class 1.0 = 0.944 +- 0.020 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.3 all KL = 0.983 +- 0.020 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.3 all L1 = 0.951 +- 0.048 (in-sample avg dev_std = 0.059)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.614
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0.0 = 0.99 +- 0.077 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.6 class 1.0 = 0.948 +- 0.077 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.6 all KL = 0.982 +- 0.077 (in-sample avg dev_std = 0.082)
SUFF++ for r=0.6 all L1 = 0.969 +- 0.086 (in-sample avg dev_std = 0.082)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
SUFF++ for r=0.9 class 0.0 = 0.999 +- 0.074 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 class 1.0 = 0.977 +- 0.074 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all KL = 0.99 +- 0.074 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all L1 = 0.988 +- 0.052 (in-sample avg dev_std = 0.081)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.609
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 352
Effective ratio: 0.308 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.618
NEC for r=0.3 class 0.0 = 0.042 +- 0.019 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 1.0 = 0.05 +- 0.019 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all KL = 0.011 +- 0.019 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all L1 = 0.046 +- 0.044 (in-sample avg dev_std = 0.053)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.748
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 352
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.714
NEC for r=0.6 class 0.0 = 0.016 +- 0.073 (in-sample avg dev_std = 0.105)
NEC for r=0.6 class 1.0 = 0.094 +- 0.073 (in-sample avg dev_std = 0.105)
NEC for r=0.6 all KL = 0.028 +- 0.073 (in-sample avg dev_std = 0.105)
NEC for r=0.6 all L1 = 0.055 +- 0.110 (in-sample avg dev_std = 0.105)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 352
Effective ratio: 0.907 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.779
NEC for r=0.9 class 0.0 = 0.012 +- 0.217 (in-sample avg dev_std = 0.227)
NEC for r=0.9 class 1.0 = 0.194 +- 0.217 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all KL = 0.1 +- 0.217 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all L1 = 0.103 +- 0.204 (in-sample avg dev_std = 0.227)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.839
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 352
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.792
NEC for r=1.0 class 0.0 = 0.01 +- 0.244 (in-sample avg dev_std = 0.259)
NEC for r=1.0 class 1.0 = 0.205 +- 0.244 (in-sample avg dev_std = 0.259)
NEC for r=1.0 all KL = 0.119 +- 0.244 (in-sample avg dev_std = 0.259)
NEC for r=1.0 all L1 = 0.108 +- 0.208 (in-sample avg dev_std = 0.259)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.554
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 252
Effective ratio: 0.309 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.581
NEC for r=0.3 class 0.0 = 0.04 +- 0.016 (in-sample avg dev_std = 0.043)
NEC for r=0.3 class 1.0 = 0.041 +- 0.016 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all KL = 0.009 +- 0.016 (in-sample avg dev_std = 0.043)
NEC for r=0.3 all L1 = 0.04 +- 0.036 (in-sample avg dev_std = 0.043)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.67
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 252
Effective ratio: 0.609 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.669
NEC for r=0.6 class 0.0 = 0.01 +- 0.066 (in-sample avg dev_std = 0.094)
NEC for r=0.6 class 1.0 = 0.064 +- 0.066 (in-sample avg dev_std = 0.094)
NEC for r=0.6 all KL = 0.019 +- 0.066 (in-sample avg dev_std = 0.094)
NEC for r=0.6 all L1 = 0.037 +- 0.084 (in-sample avg dev_std = 0.094)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 252
Effective ratio: 0.907 +- 0.006
Model ROC-AUC over intervened graphs for r=0.9 =  0.702
NEC for r=0.9 class 0.0 = 0.009 +- 0.207 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1.0 = 0.143 +- 0.207 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.083 +- 0.207 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.076 +- 0.180 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.709
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 252
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.698
NEC for r=1.0 class 0.0 = 0.004 +- 0.253 (in-sample avg dev_std = 0.225)
NEC for r=1.0 class 1.0 = 0.166 +- 0.253 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all KL = 0.105 +- 0.253 (in-sample avg dev_std = 0.225)
NEC for r=1.0 all L1 = 0.085 +- 0.200 (in-sample avg dev_std = 0.225)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.564
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.563
NEC for r=0.3 class 0.0 = 0.033 +- 0.060 (in-sample avg dev_std = 0.088)
NEC for r=0.3 class 1.0 = 0.053 +- 0.060 (in-sample avg dev_std = 0.088)
NEC for r=0.3 all KL = 0.015 +- 0.060 (in-sample avg dev_std = 0.088)
NEC for r=0.3 all L1 = 0.043 +- 0.066 (in-sample avg dev_std = 0.088)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.614
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.595
NEC for r=0.6 class 0.0 = 0.008 +- 0.044 (in-sample avg dev_std = 0.072)
NEC for r=0.6 class 1.0 = 0.044 +- 0.044 (in-sample avg dev_std = 0.072)
NEC for r=0.6 all KL = 0.013 +- 0.044 (in-sample avg dev_std = 0.072)
NEC for r=0.6 all L1 = 0.026 +- 0.071 (in-sample avg dev_std = 0.072)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.661
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.641
NEC for r=0.9 class 0.0 = 0.003 +- 0.185 (in-sample avg dev_std = 0.194)
NEC for r=0.9 class 1.0 = 0.078 +- 0.185 (in-sample avg dev_std = 0.194)
NEC for r=0.9 all KL = 0.049 +- 0.185 (in-sample avg dev_std = 0.194)
NEC for r=0.9 all L1 = 0.041 +- 0.133 (in-sample avg dev_std = 0.194)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.634
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.615
NEC for r=1.0 class 0.0 = 0.003 +- 0.170 (in-sample avg dev_std = 0.187)
NEC for r=1.0 class 1.0 = 0.075 +- 0.170 (in-sample avg dev_std = 0.187)
NEC for r=1.0 all KL = 0.049 +- 0.170 (in-sample avg dev_std = 0.187)
NEC for r=1.0 all L1 = 0.039 +- 0.123 (in-sample avg dev_std = 0.187)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.929, 0.912, 0.951, 1.0], 'all_L1': [0.902, 0.889, 0.93, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.966, 0.909, 0.941, 1.0], 'all_L1': [0.947, 0.878, 0.902, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.97, 0.955, 0.953, 1.0], 'all_L1': [0.922, 0.922, 0.922, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.954, 0.912, 0.887, 1.0], 'all_L1': [0.931, 0.908, 0.894, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.976, 0.971, 0.974, 1.0], 'all_L1': [0.934, 0.943, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.06, 0.066, 0.09, 0.1], 'all_L1': [0.082, 0.098, 0.105, 0.104]}), defaultdict(<class 'list'>, {'all_KL': [0.022, 0.048, 0.076, 0.084], 'all_L1': [0.045, 0.093, 0.12, 0.12]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.031, 0.058, 0.065], 'all_L1': [0.048, 0.057, 0.087, 0.089]}), defaultdict(<class 'list'>, {'all_KL': [0.039, 0.036, 0.122, 0.17], 'all_L1': [0.047, 0.054, 0.116, 0.13]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.028, 0.1, 0.119], 'all_L1': [0.046, 0.055, 0.103, 0.108]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.938, 0.917, 0.964, 1.0], 'all_L1': [0.918, 0.901, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.978, 0.912, 0.97, 1.0], 'all_L1': [0.966, 0.9, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.98, 0.967, 0.957, 1.0], 'all_L1': [0.929, 0.928, 0.932, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.97, 0.909, 0.949, 1.0], 'all_L1': [0.947, 0.91, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.982, 0.981, 0.983, 1.0], 'all_L1': [0.944, 0.96, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.071, 0.066, 0.064, 0.072], 'all_L1': [0.073, 0.081, 0.087, 0.088]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.043, 0.044, 0.04], 'all_L1': [0.032, 0.067, 0.078, 0.071]}), defaultdict(<class 'list'>, {'all_KL': [0.007, 0.015, 0.024, 0.031], 'all_L1': [0.039, 0.043, 0.052, 0.047]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.027, 0.073, 0.121], 'all_L1': [0.044, 0.044, 0.073, 0.1]}), defaultdict(<class 'list'>, {'all_KL': [0.009, 0.019, 0.083, 0.105], 'all_L1': [0.04, 0.037, 0.076, 0.085]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.938, 0.951, 0.969, 1.0], 'all_L1': [0.901, 0.927, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.98, 0.964, 0.98, 1.0], 'all_L1': [0.956, 0.933, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.981, 0.986, 0.989, 1.0], 'all_L1': [0.934, 0.954, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.972, 0.946, 0.974, 1.0], 'all_L1': [0.968, 0.958, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.983, 0.982, 0.99, 1.0], 'all_L1': [0.951, 0.969, 0.988, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.028, 0.027, 0.048, 0.053], 'all_L1': [0.055, 0.053, 0.054, 0.051]}), defaultdict(<class 'list'>, {'all_KL': [0.018, 0.027, 0.03, 0.038], 'all_L1': [0.043, 0.059, 0.059, 0.062]}), defaultdict(<class 'list'>, {'all_KL': [0.006, 0.006, 0.015, 0.028], 'all_L1': [0.033, 0.027, 0.034, 0.039]}), defaultdict(<class 'list'>, {'all_KL': [0.04, 0.028, 0.055, 0.057], 'all_L1': [0.035, 0.028, 0.047, 0.046]}), defaultdict(<class 'list'>, {'all_KL': [0.015, 0.013, 0.049, 0.049], 'all_L1': [0.043, 0.026, 0.041, 0.039]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.927 +- 0.015, 0.908 +- 0.023, 0.922 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.959 +- 0.017, 0.932 +- 0.026, 0.941 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.555 +- 0.036, 0.703 +- 0.010, 0.795 +- 0.017
nec class all_L1  =  0.054 +- 0.014, 0.071 +- 0.020, 0.106 +- 0.012, 0.110 +- 0.014
nec class all_KL  =  0.030 +- 0.018, 0.042 +- 0.014, 0.089 +- 0.022, 0.108 +- 0.036
nec_acc_int  =  0.572 +- 0.044, 0.722 +- 0.010, 0.784 +- 0.009, 0.791 +- 0.010

Eval split val
suff++ class all_L1  =  0.941 +- 0.016, 0.920 +- 0.022, 0.943 +- 0.016, 1.000 +- 0.000
suff++ class all_KL  =  0.970 +- 0.016, 0.937 +- 0.030, 0.965 +- 0.012, 1.000 +- 0.000
suff++_acc_int  =  0.529 +- 0.042, 0.647 +- 0.026, 0.717 +- 0.017
nec class all_L1  =  0.046 +- 0.014, 0.054 +- 0.017, 0.073 +- 0.012, 0.078 +- 0.018
nec class all_KL  =  0.028 +- 0.024, 0.034 +- 0.019, 0.058 +- 0.021, 0.074 +- 0.035
nec_acc_int  =  0.572 +- 0.047, 0.684 +- 0.035, 0.710 +- 0.021, 0.714 +- 0.018

Eval split test
suff++ class all_L1  =  0.942 +- 0.023, 0.948 +- 0.016, 0.967 +- 0.012, 1.000 +- 0.000
suff++ class all_KL  =  0.971 +- 0.017, 0.966 +- 0.016, 0.980 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.564 +- 0.045, 0.627 +- 0.035, 0.698 +- 0.024
nec class all_L1  =  0.042 +- 0.008, 0.039 +- 0.014, 0.047 +- 0.009, 0.047 +- 0.009
nec class all_KL  =  0.021 +- 0.012, 0.020 +- 0.009, 0.039 +- 0.015, 0.045 +- 0.011
nec_acc_int  =  0.576 +- 0.035, 0.614 +- 0.039, 0.672 +- 0.037, 0.670 +- 0.041


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.490 +- 0.004, 0.490 +- 0.006, 0.514 +- 0.010, 0.555 +- 0.007
Faith. Armon (L1)= 		  =  0.101 +- 0.025, 0.132 +- 0.033, 0.190 +- 0.018, 0.198 +- 0.023
Faith. GMean (L1)= 	  =  0.221 +- 0.025, 0.252 +- 0.032, 0.312 +- 0.016, 0.331 +- 0.021
Faith. Aritm (KL)= 		  =  0.494 +- 0.001, 0.487 +- 0.009, 0.515 +- 0.012, 0.554 +- 0.018
Faith. Armon (KL)= 		  =  0.057 +- 0.033, 0.080 +- 0.025, 0.162 +- 0.036, 0.192 +- 0.057
Faith. GMean (KL)= 	  =  0.161 +- 0.048, 0.194 +- 0.029, 0.287 +- 0.033, 0.324 +- 0.053

Eval split val
Faith. Aritm (L1)= 		  =  0.493 +- 0.005, 0.487 +- 0.007, 0.508 +- 0.011, 0.539 +- 0.009
Faith. Armon (L1)= 		  =  0.087 +- 0.025, 0.102 +- 0.030, 0.136 +- 0.020, 0.145 +- 0.032
Faith. GMean (L1)= 	  =  0.205 +- 0.029, 0.221 +- 0.032, 0.262 +- 0.022, 0.278 +- 0.034
Faith. Aritm (KL)= 		  =  0.499 +- 0.004, 0.486 +- 0.011, 0.511 +- 0.014, 0.537 +- 0.018
Faith. Armon (KL)= 		  =  0.054 +- 0.044, 0.065 +- 0.034, 0.108 +- 0.038, 0.135 +- 0.061
Faith. GMean (KL)= 	  =  0.151 +- 0.065, 0.172 +- 0.045, 0.231 +- 0.047, 0.263 +- 0.067

Eval split test
Faith. Aritm (L1)= 		  =  0.492 +- 0.009, 0.493 +- 0.003, 0.507 +- 0.004, 0.524 +- 0.004
Faith. Armon (L1)= 		  =  0.080 +- 0.014, 0.074 +- 0.026, 0.089 +- 0.016, 0.090 +- 0.016
Faith. GMean (L1)= 	  =  0.197 +- 0.016, 0.188 +- 0.033, 0.212 +- 0.020, 0.217 +- 0.019
Faith. Aritm (KL)= 		  =  0.496 +- 0.008, 0.493 +- 0.004, 0.510 +- 0.006, 0.523 +- 0.005
Faith. Armon (KL)= 		  =  0.042 +- 0.022, 0.039 +- 0.017, 0.075 +- 0.028, 0.086 +- 0.020
Faith. GMean (KL)= 	  =  0.138 +- 0.040, 0.135 +- 0.035, 0.192 +- 0.041, 0.211 +- 0.026
Computed for split load_split = id



Completed in  0:08:16.767093  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold anneal

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 15:54:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:58 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:58 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 03:54:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9965
Train Loss: 0.0188
ID Validation ACCURACY: 0.9021
ID Validation Loss: 0.3701
ID Test ACCURACY: 0.8993
ID Test Loss: 0.3816
OOD Validation ACCURACY: 0.8900
OOD Validation Loss: 0.4106
OOD Test ACCURACY: 0.7266
OOD Test Loss: 1.3252

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 81...
[0m[1;37mINFO[0m: [1mCheckpoint 81: 
-----------------------------------
Train ACCURACY: 0.9572
Train Loss: 0.1281
ID Validation ACCURACY: 0.8943
ID Validation Loss: 0.3424
ID Test ACCURACY: 0.8924
ID Test Loss: 0.3408
OOD Validation ACCURACY: 0.8981
OOD Validation Loss: 0.3382
OOD Test ACCURACY: 0.7973
OOD Test Loss: 0.7115

[0m[1;37mINFO[0m: [1mChartInfo 0.8993 0.7266 0.8924 0.7973 0.8943 0.8981[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.089
SUFF++ for r=0.3 class 0 = 0.54 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 1 = 0.509 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 2 = 0.523 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 3 = 0.543 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 4 = 0.491 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 5 = 0.502 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 6 = 0.483 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 7 = 0.5 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 8 = 0.548 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 class 9 = 0.503 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 all KL = 0.54 +- 0.184 (in-sample avg dev_std = 0.420)
SUFF++ for r=0.3 all L1 = 0.514 +- 0.136 (in-sample avg dev_std = 0.420)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.158
SUFF++ for r=0.6 class 0 = 0.491 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 1 = 0.532 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 2 = 0.511 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 3 = 0.506 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 4 = 0.457 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 5 = 0.487 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 6 = 0.489 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 7 = 0.526 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 8 = 0.487 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 class 9 = 0.45 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 all KL = 0.534 +- 0.287 (in-sample avg dev_std = 0.175)
SUFF++ for r=0.6 all L1 = 0.494 +- 0.214 (in-sample avg dev_std = 0.175)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.767
SUFF++ for r=0.9 class 0 = 0.899 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1 = 0.942 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 2 = 0.804 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 3 = 0.774 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 4 = 0.805 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 5 = 0.75 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 6 = 0.848 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 7 = 0.853 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 8 = 0.82 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 9 = 0.777 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.853 +- 0.219 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.829 +- 0.208 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.081
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.091
SUFF++ for r=0.3 class 0 = 0.536 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 1 = 0.499 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 2 = 0.498 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 3 = 0.498 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 4 = 0.48 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 5 = 0.514 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 6 = 0.513 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 7 = 0.525 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 8 = 0.532 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 class 9 = 0.501 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 all KL = 0.533 +- 0.178 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.3 all L1 = 0.51 +- 0.128 (in-sample avg dev_std = 0.439)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.216
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.182
SUFF++ for r=0.6 class 0 = 0.478 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 1 = 0.538 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 2 = 0.497 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 3 = 0.458 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 4 = 0.527 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 5 = 0.493 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 6 = 0.491 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 7 = 0.453 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 8 = 0.462 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 9 = 0.477 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 all KL = 0.531 +- 0.290 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 all L1 = 0.487 +- 0.212 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.772
SUFF++ for r=0.9 class 0 = 0.966 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1 = 0.959 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 2 = 0.8 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 3 = 0.751 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 4 = 0.802 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 5 = 0.73 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 6 = 0.832 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 7 = 0.808 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 8 = 0.855 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 9 = 0.814 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.848 +- 0.229 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.834 +- 0.204 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
SUFF++ for r=0.3 class 0 = 0.543 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 1 = 0.487 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 3 = 0.508 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 4 = 0.486 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 5 = 0.498 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 6 = 0.517 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 7 = 0.482 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 8 = 0.506 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 9 = 0.482 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all KL = 0.52 +- 0.186 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all L1 = 0.501 +- 0.129 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
SUFF++ for r=0.6 class 0 = 0.502 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 1 = 0.534 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 2 = 0.53 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 3 = 0.494 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 4 = 0.489 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 5 = 0.466 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 6 = 0.462 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 7 = 0.487 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 8 = 0.497 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 9 = 0.457 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all KL = 0.526 +- 0.282 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all L1 = 0.492 +- 0.209 (in-sample avg dev_std = 0.187)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.775
SUFF++ for r=0.9 class 0 = 0.917 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 1 = 0.949 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 2 = 0.781 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 3 = 0.757 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 4 = 0.8 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 5 = 0.711 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 6 = 0.814 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 7 = 0.859 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 8 = 0.837 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 9 = 0.763 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all KL = 0.833 +- 0.242 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.210 (in-sample avg dev_std = 0.251)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.552 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 1 = 0.497 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 2 = 0.527 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 3 = 0.534 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 4 = 0.484 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 5 = 0.527 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 6 = 0.496 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 7 = 0.508 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 8 = 0.506 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 9 = 0.517 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all KL = 0.527 +- 0.198 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all L1 = 0.515 +- 0.134 (in-sample avg dev_std = 0.460)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
SUFF++ for r=0.6 class 0 = 0.475 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 1 = 0.524 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 2 = 0.469 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 3 = 0.472 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 4 = 0.48 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 5 = 0.485 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 6 = 0.483 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 7 = 0.489 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 8 = 0.452 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 9 = 0.454 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all KL = 0.527 +- 0.266 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all L1 = 0.479 +- 0.191 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.66
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0 = 0.709 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.962 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.74 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 3 = 0.678 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 4 = 0.797 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 5 = 0.653 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 6 = 0.781 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 7 = 0.787 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 8 = 0.727 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 9 = 0.722 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.805 +- 0.227 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.759 +- 0.217 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.085
NEC for r=0.3 class 0 = 0.384 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 1 = 0.4 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 2 = 0.427 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 3 = 0.366 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 4 = 0.424 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 5 = 0.423 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 6 = 0.429 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 7 = 0.434 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 8 = 0.362 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 9 = 0.447 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 all KL = 0.271 +- 0.176 (in-sample avg dev_std = 0.241)
NEC for r=0.3 all L1 = 0.409 +- 0.159 (in-sample avg dev_std = 0.241)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.18
NEC for r=0.6 class 0 = 0.529 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 1 = 0.41 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 2 = 0.507 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 3 = 0.532 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 4 = 0.567 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 5 = 0.524 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 6 = 0.522 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 7 = 0.527 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 8 = 0.554 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 9 = 0.549 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all KL = 0.497 +- 0.245 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all L1 = 0.521 +- 0.171 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.636
NEC for r=0.9 class 0 = 0.333 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 1 = 0.133 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 2 = 0.431 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 3 = 0.551 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 4 = 0.378 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 5 = 0.55 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 6 = 0.379 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 7 = 0.4 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 8 = 0.372 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 9 = 0.451 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all KL = 0.557 +- 0.326 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all L1 = 0.394 +- 0.262 (in-sample avg dev_std = 0.449)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.947
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0 = 0.105 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 1 = 0.034 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 2 = 0.278 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 3 = 0.372 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 4 = 0.19 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 5 = 0.274 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 6 = 0.222 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 7 = 0.194 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 8 = 0.238 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 9 = 0.32 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all KL = 0.369 +- 0.352 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all L1 = 0.22 +- 0.246 (in-sample avg dev_std = 0.393)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.081
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.085
NEC for r=0.3 class 0 = 0.38 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 1 = 0.427 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 2 = 0.419 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 3 = 0.423 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 4 = 0.418 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 5 = 0.426 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 6 = 0.416 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 7 = 0.413 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 8 = 0.375 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 9 = 0.413 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all KL = 0.266 +- 0.175 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all L1 = 0.411 +- 0.158 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.216
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.174
NEC for r=0.6 class 0 = 0.533 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 1 = 0.439 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 2 = 0.507 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 3 = 0.552 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 4 = 0.497 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 5 = 0.523 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 6 = 0.52 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 7 = 0.529 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 8 = 0.575 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 9 = 0.55 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all KL = 0.498 +- 0.244 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all L1 = 0.521 +- 0.168 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.34 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 1 = 0.118 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 2 = 0.411 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 3 = 0.536 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 4 = 0.354 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 5 = 0.537 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 6 = 0.396 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 7 = 0.411 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 8 = 0.386 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 class 9 = 0.461 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 all KL = 0.549 +- 0.329 (in-sample avg dev_std = 0.455)
NEC for r=0.9 all L1 = 0.391 +- 0.263 (in-sample avg dev_std = 0.455)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.959
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.848
NEC for r=1.0 class 0 = 0.093 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 1 = 0.021 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 2 = 0.267 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 3 = 0.34 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 4 = 0.174 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 5 = 0.335 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 6 = 0.257 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 7 = 0.19 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 8 = 0.206 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 9 = 0.338 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all KL = 0.367 +- 0.351 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all L1 = 0.218 +- 0.244 (in-sample avg dev_std = 0.393)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
NEC for r=0.3 class 0 = 0.361 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 1 = 0.448 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 2 = 0.425 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 3 = 0.392 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 4 = 0.426 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 5 = 0.421 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 6 = 0.42 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 7 = 0.424 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 8 = 0.389 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 9 = 0.432 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all KL = 0.273 +- 0.173 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all L1 = 0.415 +- 0.154 (in-sample avg dev_std = 0.245)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.162
NEC for r=0.6 class 0 = 0.541 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 1 = 0.438 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 2 = 0.503 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 3 = 0.548 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 4 = 0.529 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 5 = 0.534 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 6 = 0.556 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 7 = 0.498 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 8 = 0.548 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 9 = 0.566 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all KL = 0.513 +- 0.240 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all L1 = 0.525 +- 0.166 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.448 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.099 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.388 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 3 = 0.586 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 4 = 0.326 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 5 = 0.569 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 6 = 0.428 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 7 = 0.378 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 8 = 0.412 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 9 = 0.489 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.568 +- 0.339 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.407 +- 0.269 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.95
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.817
NEC for r=1.0 class 0 = 0.151 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.02 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.312 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.406 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.228 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.338 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.246 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.17 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.203 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.354 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.379 +- 0.352 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.24 +- 0.256 (in-sample avg dev_std = 0.397)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.084
NEC for r=0.3 class 0 = 0.364 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 1 = 0.433 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 2 = 0.38 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 3 = 0.385 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 4 = 0.424 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 5 = 0.372 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 6 = 0.427 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 7 = 0.409 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 8 = 0.387 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 9 = 0.417 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 all KL = 0.254 +- 0.170 (in-sample avg dev_std = 0.246)
NEC for r=0.3 all L1 = 0.4 +- 0.149 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.168
NEC for r=0.6 class 0 = 0.509 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 1 = 0.464 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 2 = 0.511 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 3 = 0.521 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 4 = 0.547 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 5 = 0.539 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 6 = 0.522 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 7 = 0.524 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 8 = 0.562 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 9 = 0.586 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all KL = 0.494 +- 0.231 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all L1 = 0.527 +- 0.152 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.66
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.428
NEC for r=0.9 class 0 = 0.663 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 1 = 0.057 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 2 = 0.472 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 3 = 0.61 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 4 = 0.312 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 5 = 0.619 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 6 = 0.547 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 7 = 0.536 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 8 = 0.567 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 9 = 0.568 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 all KL = 0.585 +- 0.337 (in-sample avg dev_std = 0.405)
NEC for r=0.9 all L1 = 0.489 +- 0.277 (in-sample avg dev_std = 0.405)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.764
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.625
NEC for r=1.0 class 0 = 0.508 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 1 = 0.022 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 2 = 0.353 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 3 = 0.544 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 4 = 0.309 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 5 = 0.497 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 6 = 0.4 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 7 = 0.336 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 8 = 0.47 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 9 = 0.474 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 all KL = 0.504 +- 0.348 (in-sample avg dev_std = 0.421)
NEC for r=1.0 all L1 = 0.386 +- 0.281 (in-sample avg dev_std = 0.421)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 16:18:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:18:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9987
Train Loss: 0.0096
ID Validation ACCURACY: 0.9027
ID Validation Loss: 0.3864
ID Test ACCURACY: 0.8991
ID Test Loss: 0.3914
OOD Validation ACCURACY: 0.8763
OOD Validation Loss: 0.5115
OOD Test ACCURACY: 0.6363
OOD Test Loss: 2.4738

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9975
Train Loss: 0.0131
ID Validation ACCURACY: 0.8989
ID Validation Loss: 0.3964
ID Test ACCURACY: 0.8967
ID Test Loss: 0.4040
OOD Validation ACCURACY: 0.8867
OOD Validation Loss: 0.4606
OOD Test ACCURACY: 0.7444
OOD Test Loss: 1.2795

[0m[1;37mINFO[0m: [1mChartInfo 0.8991 0.6363 0.8967 0.7444 0.8989 0.8867[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.083
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.584 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 1 = 0.573 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 2 = 0.552 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 3 = 0.58 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 4 = 0.537 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 5 = 0.545 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 6 = 0.541 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 7 = 0.564 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 8 = 0.559 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 9 = 0.545 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all KL = 0.713 +- 0.128 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all L1 = 0.558 +- 0.094 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.146
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
SUFF++ for r=0.6 class 0 = 0.602 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 1 = 0.463 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 2 = 0.611 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 3 = 0.62 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 4 = 0.552 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 5 = 0.649 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 6 = 0.544 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 7 = 0.483 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 8 = 0.533 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 9 = 0.496 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all KL = 0.563 +- 0.335 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all L1 = 0.553 +- 0.268 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.756
SUFF++ for r=0.9 class 0 = 0.899 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 1 = 0.924 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 2 = 0.814 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 3 = 0.796 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 4 = 0.811 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 5 = 0.737 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 6 = 0.794 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 7 = 0.813 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 8 = 0.848 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 9 = 0.776 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all KL = 0.837 +- 0.237 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.215 (in-sample avg dev_std = 0.252)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
SUFF++ for r=0.3 class 0 = 0.59 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 1 = 0.545 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 2 = 0.546 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 3 = 0.555 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 4 = 0.541 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 5 = 0.571 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 6 = 0.537 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 7 = 0.547 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 8 = 0.556 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 class 9 = 0.518 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 all KL = 0.702 +- 0.128 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.3 all L1 = 0.55 +- 0.095 (in-sample avg dev_std = 0.283)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.154
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.142
SUFF++ for r=0.6 class 0 = 0.626 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 1 = 0.487 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 2 = 0.598 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 3 = 0.613 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 4 = 0.537 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 5 = 0.526 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 6 = 0.55 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 7 = 0.524 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 8 = 0.529 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 9 = 0.565 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all KL = 0.571 +- 0.320 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all L1 = 0.555 +- 0.262 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.946 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.934 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.798 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 3 = 0.75 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 4 = 0.84 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 5 = 0.693 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 6 = 0.786 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 7 = 0.778 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 8 = 0.859 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 9 = 0.749 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.822 +- 0.258 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.816 +- 0.222 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.591 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 1 = 0.563 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 2 = 0.559 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 3 = 0.571 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 4 = 0.56 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 5 = 0.567 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 6 = 0.566 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 7 = 0.524 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 8 = 0.529 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 9 = 0.543 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all KL = 0.711 +- 0.126 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all L1 = 0.557 +- 0.094 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
SUFF++ for r=0.6 class 0 = 0.583 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 1 = 0.431 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 3 = 0.602 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 4 = 0.558 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 5 = 0.497 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 6 = 0.524 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 7 = 0.514 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 8 = 0.552 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 9 = 0.487 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all KL = 0.55 +- 0.331 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all L1 = 0.54 +- 0.264 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.738
SUFF++ for r=0.9 class 0 = 0.891 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1 = 0.957 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 2 = 0.752 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 3 = 0.825 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 4 = 0.832 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 5 = 0.713 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 6 = 0.737 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 7 = 0.848 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 8 = 0.865 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 9 = 0.776 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.833 +- 0.248 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.822 +- 0.217 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.629 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 1 = 0.588 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 2 = 0.595 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 3 = 0.575 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 4 = 0.557 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 5 = 0.574 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 6 = 0.547 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 7 = 0.572 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 8 = 0.566 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 9 = 0.552 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all KL = 0.734 +- 0.130 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all L1 = 0.576 +- 0.100 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
SUFF++ for r=0.6 class 0 = 0.496 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 1 = 0.473 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 2 = 0.542 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 3 = 0.552 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 4 = 0.521 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 5 = 0.499 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 6 = 0.452 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 7 = 0.48 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 8 = 0.511 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 class 9 = 0.579 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all KL = 0.533 +- 0.316 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.6 all L1 = 0.51 +- 0.248 (in-sample avg dev_std = 0.187)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.555
SUFF++ for r=0.9 class 0 = 0.735 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 1 = 0.979 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 2 = 0.743 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 3 = 0.771 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 4 = 0.851 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 5 = 0.666 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 6 = 0.685 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 7 = 0.753 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 8 = 0.758 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 9 = 0.713 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 all KL = 0.804 +- 0.238 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 all L1 = 0.769 +- 0.220 (in-sample avg dev_std = 0.283)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.083
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.084
NEC for r=0.3 class 0 = 0.396 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 1 = 0.365 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 2 = 0.387 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 3 = 0.386 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 4 = 0.41 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 5 = 0.409 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 6 = 0.413 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 7 = 0.396 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 8 = 0.394 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 9 = 0.412 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all KL = 0.243 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all L1 = 0.396 +- 0.125 (in-sample avg dev_std = 0.222)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.146
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
NEC for r=0.6 class 0 = 0.428 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 1 = 0.511 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 2 = 0.442 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 3 = 0.443 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 4 = 0.455 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 5 = 0.414 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 6 = 0.534 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 7 = 0.501 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 8 = 0.553 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 9 = 0.543 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all KL = 0.514 +- 0.272 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all L1 = 0.483 +- 0.215 (in-sample avg dev_std = 0.388)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.592
NEC for r=0.9 class 0 = 0.253 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 1 = 0.182 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 2 = 0.418 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 3 = 0.514 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 4 = 0.372 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 5 = 0.6 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 6 = 0.496 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 7 = 0.51 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 8 = 0.27 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 9 = 0.525 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 all KL = 0.577 +- 0.343 (in-sample avg dev_std = 0.460)
NEC for r=0.9 all L1 = 0.41 +- 0.277 (in-sample avg dev_std = 0.460)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.954
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.834
NEC for r=1.0 class 0 = 0.117 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 1 = 0.041 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 2 = 0.222 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 3 = 0.338 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 4 = 0.179 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 5 = 0.36 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 6 = 0.303 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 7 = 0.192 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 8 = 0.167 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 9 = 0.37 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 all KL = 0.392 +- 0.371 (in-sample avg dev_std = 0.404)
NEC for r=1.0 all L1 = 0.226 +- 0.253 (in-sample avg dev_std = 0.404)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.375 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 1 = 0.412 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 2 = 0.393 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 3 = 0.425 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 4 = 0.403 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 5 = 0.391 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 6 = 0.442 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 7 = 0.405 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 8 = 0.408 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 9 = 0.422 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all KL = 0.254 +- 0.157 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all L1 = 0.408 +- 0.127 (in-sample avg dev_std = 0.222)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.154
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.142
NEC for r=0.6 class 0 = 0.449 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 1 = 0.539 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 2 = 0.424 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 3 = 0.413 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 4 = 0.496 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 5 = 0.466 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 6 = 0.494 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 7 = 0.485 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 8 = 0.529 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 9 = 0.495 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all KL = 0.498 +- 0.271 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all L1 = 0.479 +- 0.210 (in-sample avg dev_std = 0.385)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0 = 0.235 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 1 = 0.153 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 2 = 0.393 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 3 = 0.517 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 4 = 0.317 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 5 = 0.565 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 6 = 0.478 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 7 = 0.494 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 8 = 0.287 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 class 9 = 0.537 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 all KL = 0.556 +- 0.348 (in-sample avg dev_std = 0.453)
NEC for r=0.9 all L1 = 0.393 +- 0.281 (in-sample avg dev_std = 0.453)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.962
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0 = 0.079 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 1 = 0.016 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 2 = 0.221 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 3 = 0.311 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 4 = 0.149 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 5 = 0.426 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 6 = 0.299 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 7 = 0.212 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 8 = 0.146 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 class 9 = 0.363 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 all KL = 0.375 +- 0.373 (in-sample avg dev_std = 0.398)
NEC for r=1.0 all L1 = 0.216 +- 0.256 (in-sample avg dev_std = 0.398)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
NEC for r=0.3 class 0 = 0.383 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 1 = 0.396 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 2 = 0.423 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 3 = 0.377 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 4 = 0.389 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 5 = 0.387 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 6 = 0.419 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 7 = 0.42 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 8 = 0.415 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 class 9 = 0.444 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all KL = 0.251 +- 0.158 (in-sample avg dev_std = 0.222)
NEC for r=0.3 all L1 = 0.406 +- 0.128 (in-sample avg dev_std = 0.222)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.143
NEC for r=0.6 class 0 = 0.457 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 1 = 0.511 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 2 = 0.35 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 3 = 0.444 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 4 = 0.5 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 5 = 0.45 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 6 = 0.506 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 7 = 0.508 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 8 = 0.472 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 class 9 = 0.496 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all KL = 0.485 +- 0.280 (in-sample avg dev_std = 0.387)
NEC for r=0.6 all L1 = 0.471 +- 0.218 (in-sample avg dev_std = 0.387)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.568
NEC for r=0.9 class 0 = 0.401 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 1 = 0.096 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 2 = 0.479 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 3 = 0.517 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 4 = 0.321 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 5 = 0.674 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 6 = 0.541 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 7 = 0.417 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 8 = 0.264 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 9 = 0.563 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 all KL = 0.592 +- 0.357 (in-sample avg dev_std = 0.465)
NEC for r=0.9 all L1 = 0.422 +- 0.288 (in-sample avg dev_std = 0.465)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.93
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.791
NEC for r=1.0 class 0 = 0.181 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 1 = 0.027 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 2 = 0.344 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 3 = 0.344 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 4 = 0.227 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 5 = 0.406 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 6 = 0.343 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 7 = 0.171 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 8 = 0.227 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 9 = 0.382 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 all KL = 0.415 +- 0.374 (in-sample avg dev_std = 0.428)
NEC for r=1.0 all L1 = 0.261 +- 0.263 (in-sample avg dev_std = 0.428)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.094
NEC for r=0.3 class 0 = 0.367 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 1 = 0.405 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 2 = 0.39 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 3 = 0.407 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 4 = 0.419 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 5 = 0.378 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 6 = 0.421 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 7 = 0.399 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 8 = 0.433 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 class 9 = 0.425 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 all KL = 0.251 +- 0.170 (in-sample avg dev_std = 0.225)
NEC for r=0.3 all L1 = 0.404 +- 0.127 (in-sample avg dev_std = 0.225)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.158
NEC for r=0.6 class 0 = 0.499 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 1 = 0.473 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 2 = 0.486 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 3 = 0.464 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 4 = 0.492 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 5 = 0.524 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 6 = 0.512 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 7 = 0.522 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 8 = 0.508 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 9 = 0.469 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all KL = 0.498 +- 0.245 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all L1 = 0.494 +- 0.187 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.603
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.431
NEC for r=0.9 class 0 = 0.601 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 1 = 0.067 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 2 = 0.481 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 3 = 0.545 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 4 = 0.334 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 5 = 0.623 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 6 = 0.633 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 7 = 0.487 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 8 = 0.485 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 9 = 0.565 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all KL = 0.597 +- 0.347 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all L1 = 0.476 +- 0.284 (in-sample avg dev_std = 0.433)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.655
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.571
NEC for r=1.0 class 0 = 0.593 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 1 = 0.023 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 2 = 0.365 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 3 = 0.376 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 4 = 0.317 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 5 = 0.577 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 6 = 0.515 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 7 = 0.332 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 8 = 0.456 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 9 = 0.533 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all KL = 0.534 +- 0.366 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all L1 = 0.402 +- 0.293 (in-sample avg dev_std = 0.441)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 16:42:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:47 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:47 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 04:42:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9981
Train Loss: 0.0126
ID Validation ACCURACY: 0.9027
ID Validation Loss: 0.3942
ID Test ACCURACY: 0.8990
ID Test Loss: 0.4071
OOD Validation ACCURACY: 0.8723
OOD Validation Loss: 0.5590
OOD Test ACCURACY: 0.6226
OOD Test Loss: 2.3834

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9694
Train Loss: 0.0959
ID Validation ACCURACY: 0.8950
ID Validation Loss: 0.3451
ID Test ACCURACY: 0.8894
ID Test Loss: 0.3529
OOD Validation ACCURACY: 0.8829
OOD Validation Loss: 0.3770
OOD Test ACCURACY: 0.7373
OOD Test Loss: 1.0729

[0m[1;37mINFO[0m: [1mChartInfo 0.8990 0.6226 0.8894 0.7373 0.8950 0.8829[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.587 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 1 = 0.596 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 3 = 0.589 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 4 = 0.55 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 5 = 0.578 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 6 = 0.569 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 7 = 0.606 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 8 = 0.617 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 class 9 = 0.595 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 all KL = 0.726 +- 0.146 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.3 all L1 = 0.587 +- 0.135 (in-sample avg dev_std = 0.258)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.131
SUFF++ for r=0.6 class 0 = 0.482 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 1 = 0.575 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 2 = 0.558 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 3 = 0.544 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 4 = 0.507 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 5 = 0.554 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 6 = 0.532 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 7 = 0.511 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 8 = 0.525 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 9 = 0.465 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all KL = 0.544 +- 0.314 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all L1 = 0.526 +- 0.246 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.753
SUFF++ for r=0.9 class 0 = 0.909 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 1 = 0.908 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 2 = 0.818 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 3 = 0.789 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 4 = 0.803 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 5 = 0.749 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 6 = 0.818 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 7 = 0.822 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 8 = 0.833 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 9 = 0.767 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all KL = 0.836 +- 0.240 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.210 (in-sample avg dev_std = 0.257)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
SUFF++ for r=0.3 class 0 = 0.586 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 1 = 0.62 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 2 = 0.576 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 3 = 0.572 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 4 = 0.568 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 5 = 0.585 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 6 = 0.616 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 7 = 0.57 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 8 = 0.605 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 9 = 0.574 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all KL = 0.722 +- 0.151 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all L1 = 0.587 +- 0.141 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.141
SUFF++ for r=0.6 class 0 = 0.497 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 1 = 0.563 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 2 = 0.545 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 3 = 0.522 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 4 = 0.493 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 5 = 0.494 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 6 = 0.524 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 7 = 0.472 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 8 = 0.563 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 class 9 = 0.488 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all KL = 0.534 +- 0.311 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.6 all L1 = 0.517 +- 0.246 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.764
SUFF++ for r=0.9 class 0 = 0.901 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 1 = 0.921 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 2 = 0.804 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 3 = 0.802 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 4 = 0.811 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 5 = 0.719 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 6 = 0.805 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 7 = 0.83 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 8 = 0.84 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 9 = 0.761 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all KL = 0.836 +- 0.236 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.209 (in-sample avg dev_std = 0.257)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.089
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
SUFF++ for r=0.3 class 0 = 0.616 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 1 = 0.624 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 2 = 0.592 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 3 = 0.584 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 4 = 0.62 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 5 = 0.606 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 6 = 0.613 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 7 = 0.566 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 8 = 0.581 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 class 9 = 0.604 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all KL = 0.743 +- 0.133 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.3 all L1 = 0.601 +- 0.130 (in-sample avg dev_std = 0.250)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.14
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.125
SUFF++ for r=0.6 class 0 = 0.476 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 1 = 0.564 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 2 = 0.583 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 3 = 0.561 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 4 = 0.508 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 5 = 0.533 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 6 = 0.449 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 7 = 0.432 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 8 = 0.542 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 9 = 0.442 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all KL = 0.532 +- 0.316 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all L1 = 0.509 +- 0.250 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.748
SUFF++ for r=0.9 class 0 = 0.838 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.943 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.789 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 3 = 0.828 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 4 = 0.789 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 5 = 0.716 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 6 = 0.785 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 7 = 0.847 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 8 = 0.808 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 9 = 0.764 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.823 +- 0.250 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.814 +- 0.214 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.649 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 1 = 0.698 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 2 = 0.649 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 3 = 0.61 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 4 = 0.653 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 5 = 0.642 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 6 = 0.647 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 7 = 0.63 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 8 = 0.646 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 class 9 = 0.628 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 all KL = 0.778 +- 0.134 (in-sample avg dev_std = 0.231)
SUFF++ for r=0.3 all L1 = 0.646 +- 0.142 (in-sample avg dev_std = 0.231)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
SUFF++ for r=0.6 class 0 = 0.503 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 1 = 0.487 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 2 = 0.534 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 3 = 0.507 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 4 = 0.49 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 5 = 0.513 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 6 = 0.455 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 7 = 0.478 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 8 = 0.524 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 class 9 = 0.498 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all KL = 0.525 +- 0.298 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.6 all L1 = 0.499 +- 0.230 (in-sample avg dev_std = 0.204)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.554
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.525
SUFF++ for r=0.9 class 0 = 0.647 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 1 = 0.957 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 2 = 0.738 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 3 = 0.792 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 4 = 0.757 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 5 = 0.683 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 6 = 0.735 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 7 = 0.747 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 8 = 0.664 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 class 9 = 0.674 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all KL = 0.782 +- 0.242 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.9 all L1 = 0.742 +- 0.220 (in-sample avg dev_std = 0.300)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.425 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 1 = 0.412 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 2 = 0.413 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 3 = 0.428 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 4 = 0.453 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 5 = 0.43 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 6 = 0.459 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 7 = 0.45 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 8 = 0.421 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 class 9 = 0.46 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all KL = 0.314 +- 0.200 (in-sample avg dev_std = 0.276)
NEC for r=0.3 all L1 = 0.435 +- 0.153 (in-sample avg dev_std = 0.276)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
NEC for r=0.6 class 0 = 0.536 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 1 = 0.435 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 2 = 0.445 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 3 = 0.483 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 4 = 0.522 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 5 = 0.482 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 6 = 0.506 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 7 = 0.47 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 8 = 0.529 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 9 = 0.529 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all KL = 0.495 +- 0.263 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all L1 = 0.493 +- 0.204 (in-sample avg dev_std = 0.385)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.616
NEC for r=0.9 class 0 = 0.349 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 1 = 0.273 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 2 = 0.362 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 3 = 0.492 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 4 = 0.426 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 5 = 0.532 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 6 = 0.434 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 7 = 0.374 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 8 = 0.405 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 class 9 = 0.509 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 all KL = 0.596 +- 0.312 (in-sample avg dev_std = 0.474)
NEC for r=0.9 all L1 = 0.413 +- 0.255 (in-sample avg dev_std = 0.474)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.951
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0 = 0.127 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 1 = 0.048 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 2 = 0.232 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 3 = 0.271 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 4 = 0.2 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 5 = 0.276 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 6 = 0.279 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 7 = 0.18 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 8 = 0.246 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 9 = 0.306 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all KL = 0.381 +- 0.351 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all L1 = 0.214 +- 0.238 (in-sample avg dev_std = 0.400)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
NEC for r=0.3 class 0 = 0.408 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 1 = 0.418 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 2 = 0.427 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 3 = 0.437 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 4 = 0.448 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 5 = 0.427 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 6 = 0.427 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 7 = 0.446 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 8 = 0.442 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 9 = 0.447 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 all KL = 0.314 +- 0.194 (in-sample avg dev_std = 0.283)
NEC for r=0.3 all L1 = 0.432 +- 0.150 (in-sample avg dev_std = 0.283)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.192
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.145
NEC for r=0.6 class 0 = 0.536 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 1 = 0.424 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 2 = 0.462 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 3 = 0.474 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 4 = 0.538 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 5 = 0.525 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 6 = 0.456 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 7 = 0.523 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 8 = 0.492 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 9 = 0.525 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all KL = 0.499 +- 0.257 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all L1 = 0.494 +- 0.197 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.617
NEC for r=0.9 class 0 = 0.349 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 1 = 0.249 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 2 = 0.362 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 3 = 0.467 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 4 = 0.422 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 5 = 0.546 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 6 = 0.435 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 7 = 0.39 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 8 = 0.42 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 9 = 0.498 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all KL = 0.584 +- 0.319 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all L1 = 0.409 +- 0.261 (in-sample avg dev_std = 0.463)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.964
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.851
NEC for r=1.0 class 0 = 0.107 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 1 = 0.024 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 2 = 0.226 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 3 = 0.23 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 4 = 0.194 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 5 = 0.388 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 6 = 0.282 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 7 = 0.193 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 8 = 0.196 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 9 = 0.331 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 all KL = 0.373 +- 0.356 (in-sample avg dev_std = 0.401)
NEC for r=1.0 all L1 = 0.211 +- 0.240 (in-sample avg dev_std = 0.401)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.089
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.087
NEC for r=0.3 class 0 = 0.406 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 1 = 0.43 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 2 = 0.437 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 3 = 0.431 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 4 = 0.407 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 5 = 0.431 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 6 = 0.429 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 7 = 0.455 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 8 = 0.446 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 9 = 0.435 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all KL = 0.313 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all L1 = 0.431 +- 0.153 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.14
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.126
NEC for r=0.6 class 0 = 0.533 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 1 = 0.402 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 2 = 0.413 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 3 = 0.474 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 4 = 0.524 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 5 = 0.482 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 6 = 0.534 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 7 = 0.546 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 8 = 0.49 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 9 = 0.57 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all KL = 0.492 +- 0.277 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all L1 = 0.496 +- 0.214 (in-sample avg dev_std = 0.374)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.582
NEC for r=0.9 class 0 = 0.588 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 1 = 0.151 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 2 = 0.374 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 3 = 0.52 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 4 = 0.426 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 5 = 0.563 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 6 = 0.491 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 7 = 0.368 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 8 = 0.447 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 9 = 0.513 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all KL = 0.608 +- 0.328 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all L1 = 0.438 +- 0.268 (in-sample avg dev_std = 0.471)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.8
NEC for r=1.0 class 0 = 0.181 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 1 = 0.027 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 2 = 0.291 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 3 = 0.25 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 4 = 0.317 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 5 = 0.373 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 6 = 0.334 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 7 = 0.179 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 8 = 0.287 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 9 = 0.338 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all KL = 0.402 +- 0.358 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all L1 = 0.253 +- 0.258 (in-sample avg dev_std = 0.416)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.105
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.089
NEC for r=0.3 class 0 = 0.356 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 1 = 0.312 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 2 = 0.38 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 3 = 0.43 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 4 = 0.382 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 5 = 0.339 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 6 = 0.404 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 7 = 0.346 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 8 = 0.383 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 9 = 0.397 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all KL = 0.263 +- 0.196 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all L1 = 0.372 +- 0.170 (in-sample avg dev_std = 0.267)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.145
NEC for r=0.6 class 0 = 0.527 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 1 = 0.461 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 2 = 0.518 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 3 = 0.504 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 4 = 0.507 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 5 = 0.521 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 6 = 0.517 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 7 = 0.542 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 8 = 0.473 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 9 = 0.54 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all KL = 0.514 +- 0.246 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all L1 = 0.51 +- 0.181 (in-sample avg dev_std = 0.388)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.554
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.389
NEC for r=0.9 class 0 = 0.655 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 1 = 0.095 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 2 = 0.479 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 3 = 0.513 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 4 = 0.45 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 5 = 0.588 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 6 = 0.633 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 7 = 0.536 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 8 = 0.655 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 class 9 = 0.603 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 all KL = 0.632 +- 0.325 (in-sample avg dev_std = 0.417)
NEC for r=0.9 all L1 = 0.515 +- 0.266 (in-sample avg dev_std = 0.417)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.646
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.633 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 1 = 0.026 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 2 = 0.4 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 3 = 0.296 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 4 = 0.442 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 5 = 0.564 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 6 = 0.506 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 7 = 0.345 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 8 = 0.496 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 class 9 = 0.524 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 all KL = 0.565 +- 0.362 (in-sample avg dev_std = 0.431)
NEC for r=1.0 all L1 = 0.417 +- 0.293 (in-sample avg dev_std = 0.431)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 17:06:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:47 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:47 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:06:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9950
Train Loss: 0.0221
ID Validation ACCURACY: 0.9011
ID Validation Loss: 0.3793
ID Test ACCURACY: 0.8967
ID Test Loss: 0.3949
OOD Validation ACCURACY: 0.8807
OOD Validation Loss: 0.4585
OOD Test ACCURACY: 0.8033
OOD Test Loss: 0.8176

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.9931
Train Loss: 0.0297
ID Validation ACCURACY: 0.8957
ID Validation Loss: 0.3794
ID Test ACCURACY: 0.8986
ID Test Loss: 0.3639
OOD Validation ACCURACY: 0.8897
OOD Validation Loss: 0.3944
OOD Test ACCURACY: 0.8563
OOD Test Loss: 0.5230

[0m[1;37mINFO[0m: [1mChartInfo 0.8967 0.8033 0.8986 0.8563 0.8957 0.8897[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
SUFF++ for r=0.3 class 0 = 0.568 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 1 = 0.567 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 2 = 0.556 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 3 = 0.541 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 4 = 0.544 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 5 = 0.524 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 6 = 0.551 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 7 = 0.553 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 8 = 0.532 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 class 9 = 0.55 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all KL = 0.713 +- 0.101 (in-sample avg dev_std = 0.337)
SUFF++ for r=0.3 all L1 = 0.549 +- 0.075 (in-sample avg dev_std = 0.337)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.183
SUFF++ for r=0.6 class 0 = 0.486 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 1 = 0.51 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 2 = 0.472 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 3 = 0.517 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 4 = 0.445 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 5 = 0.464 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 6 = 0.489 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 7 = 0.523 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 8 = 0.47 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 9 = 0.494 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all KL = 0.561 +- 0.263 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all L1 = 0.488 +- 0.184 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.747
SUFF++ for r=0.9 class 0 = 0.891 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1 = 0.919 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 2 = 0.771 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 3 = 0.757 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 4 = 0.811 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 5 = 0.742 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 6 = 0.823 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 7 = 0.768 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 8 = 0.84 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 9 = 0.764 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.835 +- 0.226 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.81 +- 0.210 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
SUFF++ for r=0.3 class 0 = 0.565 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 1 = 0.562 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 2 = 0.548 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 3 = 0.529 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 4 = 0.535 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 5 = 0.541 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 6 = 0.53 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 7 = 0.55 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 8 = 0.545 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 class 9 = 0.535 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 all KL = 0.711 +- 0.099 (in-sample avg dev_std = 0.335)
SUFF++ for r=0.3 all L1 = 0.544 +- 0.072 (in-sample avg dev_std = 0.335)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.222
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.213
SUFF++ for r=0.6 class 0 = 0.417 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 1 = 0.504 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 2 = 0.512 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 3 = 0.455 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 4 = 0.513 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 5 = 0.508 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 6 = 0.491 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 7 = 0.472 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 8 = 0.479 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 9 = 0.458 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 all KL = 0.542 +- 0.275 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 all L1 = 0.48 +- 0.187 (in-sample avg dev_std = 0.157)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.804
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.763
SUFF++ for r=0.9 class 0 = 0.915 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.928 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.801 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 3 = 0.757 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 4 = 0.837 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 5 = 0.71 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 6 = 0.812 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 7 = 0.766 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 8 = 0.885 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 9 = 0.75 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.833 +- 0.244 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.211 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
SUFF++ for r=0.3 class 0 = 0.576 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 1 = 0.567 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 2 = 0.556 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 3 = 0.562 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 4 = 0.552 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 5 = 0.563 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 6 = 0.548 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 7 = 0.541 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 8 = 0.529 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 class 9 = 0.545 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all KL = 0.724 +- 0.099 (in-sample avg dev_std = 0.332)
SUFF++ for r=0.3 all L1 = 0.554 +- 0.074 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.218
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
SUFF++ for r=0.6 class 0 = 0.517 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 1 = 0.522 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 2 = 0.565 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 3 = 0.508 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 4 = 0.533 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 5 = 0.496 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 6 = 0.5 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 7 = 0.52 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 8 = 0.483 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 class 9 = 0.449 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 all KL = 0.593 +- 0.248 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.6 all L1 = 0.509 +- 0.182 (in-sample avg dev_std = 0.163)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.763
SUFF++ for r=0.9 class 0 = 0.885 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 1 = 0.949 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 2 = 0.77 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 3 = 0.794 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 4 = 0.804 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 5 = 0.759 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 6 = 0.772 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 7 = 0.788 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 8 = 0.808 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 class 9 = 0.739 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all KL = 0.831 +- 0.233 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.9 all L1 = 0.809 +- 0.214 (in-sample avg dev_std = 0.253)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.131
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.565 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 1 = 0.566 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 2 = 0.555 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 3 = 0.543 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 4 = 0.539 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 5 = 0.562 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 6 = 0.564 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 7 = 0.56 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 8 = 0.555 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 class 9 = 0.556 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 all KL = 0.729 +- 0.108 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.3 all L1 = 0.557 +- 0.083 (in-sample avg dev_std = 0.325)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.206
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.164
SUFF++ for r=0.6 class 0 = 0.571 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 1 = 0.553 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 2 = 0.667 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 3 = 0.618 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 4 = 0.584 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 5 = 0.572 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 6 = 0.558 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 7 = 0.577 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 8 = 0.57 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 9 = 0.526 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all KL = 0.69 +- 0.237 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all L1 = 0.58 +- 0.197 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.695
SUFF++ for r=0.9 class 0 = 0.864 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 1 = 0.969 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 2 = 0.784 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 3 = 0.698 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 4 = 0.847 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 5 = 0.702 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 6 = 0.736 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 7 = 0.765 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 8 = 0.766 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 9 = 0.732 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all KL = 0.823 +- 0.224 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all L1 = 0.79 +- 0.212 (in-sample avg dev_std = 0.267)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.363 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 1 = 0.362 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 2 = 0.345 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 3 = 0.352 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 4 = 0.353 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 5 = 0.361 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 6 = 0.367 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 7 = 0.366 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 8 = 0.376 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 9 = 0.377 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all KL = 0.178 +- 0.112 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all L1 = 0.362 +- 0.092 (in-sample avg dev_std = 0.169)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.205
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.181
NEC for r=0.6 class 0 = 0.526 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 1 = 0.47 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 2 = 0.516 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 3 = 0.51 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 4 = 0.553 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 5 = 0.511 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 6 = 0.53 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 7 = 0.501 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 8 = 0.533 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 class 9 = 0.499 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 all KL = 0.453 +- 0.205 (in-sample avg dev_std = 0.296)
NEC for r=0.6 all L1 = 0.514 +- 0.132 (in-sample avg dev_std = 0.296)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.598
NEC for r=0.9 class 0 = 0.304 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 1 = 0.229 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 2 = 0.468 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 3 = 0.506 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 4 = 0.376 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 5 = 0.574 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 6 = 0.482 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 7 = 0.497 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 8 = 0.314 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 9 = 0.516 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all KL = 0.585 +- 0.307 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all L1 = 0.424 +- 0.256 (in-sample avg dev_std = 0.447)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0 = 0.139 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.033 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.281 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.33 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.202 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.296 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.293 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.304 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.167 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.286 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.39 +- 0.353 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.231 +- 0.245 (in-sample avg dev_std = 0.397)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.352 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 1 = 0.343 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 2 = 0.362 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 3 = 0.369 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 4 = 0.362 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 5 = 0.351 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 6 = 0.379 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 7 = 0.364 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 8 = 0.368 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 class 9 = 0.368 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all KL = 0.178 +- 0.108 (in-sample avg dev_std = 0.170)
NEC for r=0.3 all L1 = 0.362 +- 0.094 (in-sample avg dev_std = 0.170)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.222
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.211
NEC for r=0.6 class 0 = 0.539 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 1 = 0.486 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 2 = 0.495 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 3 = 0.543 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 4 = 0.511 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 5 = 0.495 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 6 = 0.519 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 7 = 0.513 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 8 = 0.534 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 9 = 0.521 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all KL = 0.464 +- 0.215 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all L1 = 0.516 +- 0.137 (in-sample avg dev_std = 0.304)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.804
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0 = 0.297 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 1 = 0.216 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 2 = 0.435 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 3 = 0.544 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 4 = 0.321 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 5 = 0.604 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 6 = 0.474 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 7 = 0.494 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 8 = 0.3 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 9 = 0.487 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all KL = 0.574 +- 0.321 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all L1 = 0.413 +- 0.263 (in-sample avg dev_std = 0.443)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.951
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.829
NEC for r=1.0 class 0 = 0.101 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 1 = 0.02 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 2 = 0.275 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 3 = 0.304 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 4 = 0.168 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 5 = 0.375 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 6 = 0.296 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 7 = 0.297 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 8 = 0.162 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 9 = 0.344 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 all KL = 0.391 +- 0.357 (in-sample avg dev_std = 0.405)
NEC for r=1.0 all L1 = 0.23 +- 0.249 (in-sample avg dev_std = 0.405)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.357 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 1 = 0.372 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 2 = 0.36 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 3 = 0.356 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 4 = 0.344 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 5 = 0.336 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 6 = 0.38 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 7 = 0.353 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 8 = 0.371 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 class 9 = 0.375 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 all KL = 0.176 +- 0.113 (in-sample avg dev_std = 0.166)
NEC for r=0.3 all L1 = 0.361 +- 0.096 (in-sample avg dev_std = 0.166)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.218
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.183
NEC for r=0.6 class 0 = 0.507 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 1 = 0.462 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 2 = 0.439 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 3 = 0.502 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 4 = 0.49 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 5 = 0.469 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 6 = 0.516 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 7 = 0.457 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 8 = 0.529 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 class 9 = 0.535 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 all KL = 0.414 +- 0.200 (in-sample avg dev_std = 0.287)
NEC for r=0.6 all L1 = 0.49 +- 0.138 (in-sample avg dev_std = 0.287)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.602
NEC for r=0.9 class 0 = 0.363 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 1 = 0.148 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 2 = 0.409 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 3 = 0.541 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 4 = 0.318 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 5 = 0.546 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 6 = 0.526 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 7 = 0.442 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 8 = 0.4 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 class 9 = 0.539 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all KL = 0.573 +- 0.321 (in-sample avg dev_std = 0.437)
NEC for r=0.9 all L1 = 0.419 +- 0.267 (in-sample avg dev_std = 0.437)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.798
NEC for r=1.0 class 0 = 0.149 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 1 = 0.019 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 2 = 0.342 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 3 = 0.349 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 4 = 0.191 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 5 = 0.361 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 6 = 0.327 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 7 = 0.238 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 8 = 0.269 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 9 = 0.358 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all KL = 0.411 +- 0.358 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all L1 = 0.257 +- 0.256 (in-sample avg dev_std = 0.415)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.131
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.118
NEC for r=0.3 class 0 = 0.348 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 1 = 0.374 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 2 = 0.362 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 3 = 0.379 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 4 = 0.385 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 5 = 0.34 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 6 = 0.37 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 7 = 0.344 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 8 = 0.369 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 class 9 = 0.382 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 all KL = 0.183 +- 0.125 (in-sample avg dev_std = 0.173)
NEC for r=0.3 all L1 = 0.366 +- 0.099 (in-sample avg dev_std = 0.173)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.206
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.187
NEC for r=0.6 class 0 = 0.433 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 1 = 0.412 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 2 = 0.354 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 3 = 0.391 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 4 = 0.453 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 5 = 0.424 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 6 = 0.467 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 7 = 0.407 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 8 = 0.452 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 class 9 = 0.496 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all KL = 0.327 +- 0.196 (in-sample avg dev_std = 0.270)
NEC for r=0.6 all L1 = 0.428 +- 0.153 (in-sample avg dev_std = 0.270)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.413 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1 = 0.112 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 2 = 0.414 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 3 = 0.611 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 4 = 0.31 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 5 = 0.585 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 6 = 0.55 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 7 = 0.489 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 8 = 0.463 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 9 = 0.527 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.563 +- 0.327 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.441 +- 0.266 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.725
NEC for r=1.0 class 0 = 0.21 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 1 = 0.038 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 2 = 0.332 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 3 = 0.424 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 4 = 0.189 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 5 = 0.413 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 6 = 0.428 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 7 = 0.347 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 8 = 0.388 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 class 9 = 0.432 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 all KL = 0.464 +- 0.363 (in-sample avg dev_std = 0.428)
NEC for r=1.0 all L1 = 0.315 +- 0.272 (in-sample avg dev_std = 0.428)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 17:31:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:31:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9965
Train Loss: 0.0185
ID Validation ACCURACY: 0.9060
ID Validation Loss: 0.3752
ID Test ACCURACY: 0.8949
ID Test Loss: 0.3800
OOD Validation ACCURACY: 0.8710
OOD Validation Loss: 0.5198
OOD Test ACCURACY: 0.5793
OOD Test Loss: 5.7938

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9866
Train Loss: 0.0467
ID Validation ACCURACY: 0.9007
ID Validation Loss: 0.3570
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3570
OOD Validation ACCURACY: 0.8904
OOD Validation Loss: 0.3933
OOD Test ACCURACY: 0.5933
OOD Test Loss: 2.8155

[0m[1;37mINFO[0m: [1mChartInfo 0.8949 0.5793 0.8947 0.5933 0.9007 0.8904[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.094
SUFF++ for r=0.3 class 0 = 0.623 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 1 = 0.637 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 2 = 0.62 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 3 = 0.65 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 4 = 0.615 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 5 = 0.624 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 6 = 0.605 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 7 = 0.645 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 8 = 0.655 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 9 = 0.629 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all KL = 0.805 +- 0.106 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all L1 = 0.631 +- 0.122 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.153
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.126
SUFF++ for r=0.6 class 0 = 0.551 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 1 = 0.51 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 2 = 0.541 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 3 = 0.488 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 4 = 0.51 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 5 = 0.535 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 6 = 0.528 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 7 = 0.508 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 8 = 0.606 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 class 9 = 0.506 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 all KL = 0.568 +- 0.300 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.6 all L1 = 0.528 +- 0.235 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.76
SUFF++ for r=0.9 class 0 = 0.939 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 1 = 0.911 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 2 = 0.79 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 3 = 0.816 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 4 = 0.775 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 5 = 0.751 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 6 = 0.818 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 7 = 0.809 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 8 = 0.839 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 9 = 0.797 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all KL = 0.849 +- 0.226 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.207 (in-sample avg dev_std = 0.241)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.083
SUFF++ for r=0.3 class 0 = 0.64 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 1 = 0.645 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 2 = 0.619 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 3 = 0.62 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 4 = 0.596 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 5 = 0.623 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 6 = 0.645 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 7 = 0.61 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 8 = 0.663 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 9 = 0.613 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all KL = 0.801 +- 0.111 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all L1 = 0.627 +- 0.119 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.175
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
SUFF++ for r=0.6 class 0 = 0.543 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 1 = 0.553 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 2 = 0.503 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 3 = 0.511 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 4 = 0.541 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 5 = 0.536 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 6 = 0.542 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 7 = 0.504 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 8 = 0.62 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 class 9 = 0.529 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 all KL = 0.572 +- 0.302 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.6 all L1 = 0.538 +- 0.240 (in-sample avg dev_std = 0.180)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.763
SUFF++ for r=0.9 class 0 = 0.953 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.913 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.789 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 3 = 0.812 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 4 = 0.79 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 5 = 0.774 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 6 = 0.768 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 7 = 0.799 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 8 = 0.825 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 9 = 0.771 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.839 +- 0.232 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.822 +- 0.208 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.087
SUFF++ for r=0.3 class 0 = 0.656 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 1 = 0.622 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 2 = 0.632 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 3 = 0.625 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 4 = 0.651 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 5 = 0.648 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 6 = 0.652 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 7 = 0.615 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 8 = 0.631 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 class 9 = 0.638 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 all KL = 0.812 +- 0.103 (in-sample avg dev_std = 0.198)
SUFF++ for r=0.3 all L1 = 0.637 +- 0.117 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.107
SUFF++ for r=0.6 class 0 = 0.509 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 1 = 0.504 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 2 = 0.535 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 3 = 0.521 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 4 = 0.574 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 5 = 0.477 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 6 = 0.532 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 7 = 0.531 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 8 = 0.584 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 9 = 0.545 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all KL = 0.558 +- 0.304 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all L1 = 0.531 +- 0.240 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.74
SUFF++ for r=0.9 class 0 = 0.923 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1 = 0.951 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 2 = 0.729 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 3 = 0.856 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 4 = 0.76 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 5 = 0.72 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 6 = 0.744 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 7 = 0.862 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 8 = 0.786 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 9 = 0.792 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.827 +- 0.242 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.214 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.675 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 1 = 0.65 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 2 = 0.645 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 3 = 0.629 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 4 = 0.642 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 5 = 0.647 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 6 = 0.65 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 7 = 0.656 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 8 = 0.669 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 class 9 = 0.653 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 all KL = 0.824 +- 0.111 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.3 all L1 = 0.652 +- 0.120 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
SUFF++ for r=0.6 class 0 = 0.51 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 1 = 0.491 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 2 = 0.508 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 3 = 0.506 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 4 = 0.518 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 5 = 0.467 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 6 = 0.462 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 7 = 0.465 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 8 = 0.483 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 class 9 = 0.46 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all KL = 0.513 +- 0.290 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.6 all L1 = 0.488 +- 0.221 (in-sample avg dev_std = 0.185)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.579
SUFF++ for r=0.9 class 0 = 0.839 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 1 = 0.97 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 2 = 0.792 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 3 = 0.721 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 4 = 0.768 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 5 = 0.722 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 6 = 0.723 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 7 = 0.761 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 8 = 0.71 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 class 9 = 0.689 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all KL = 0.805 +- 0.237 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.9 all L1 = 0.773 +- 0.217 (in-sample avg dev_std = 0.280)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.087
NEC for r=0.3 class 0 = 0.395 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 1 = 0.376 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 2 = 0.4 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 3 = 0.377 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 4 = 0.392 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 5 = 0.396 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 6 = 0.425 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 7 = 0.388 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 8 = 0.376 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 class 9 = 0.423 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 all KL = 0.24 +- 0.165 (in-sample avg dev_std = 0.239)
NEC for r=0.3 all L1 = 0.395 +- 0.148 (in-sample avg dev_std = 0.239)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.153
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.126
NEC for r=0.6 class 0 = 0.475 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 1 = 0.481 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 2 = 0.527 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 3 = 0.518 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 4 = 0.496 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 5 = 0.478 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 6 = 0.472 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 7 = 0.485 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 8 = 0.453 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 class 9 = 0.509 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 all KL = 0.476 +- 0.235 (in-sample avg dev_std = 0.366)
NEC for r=0.6 all L1 = 0.489 +- 0.182 (in-sample avg dev_std = 0.366)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.623
NEC for r=0.9 class 0 = 0.228 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 1 = 0.221 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 2 = 0.422 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 3 = 0.461 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 4 = 0.468 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 5 = 0.538 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 6 = 0.492 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 7 = 0.503 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 8 = 0.318 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 9 = 0.458 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all KL = 0.566 +- 0.316 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all L1 = 0.408 +- 0.258 (in-sample avg dev_std = 0.462)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.846
NEC for r=1.0 class 0 = 0.074 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.06 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.249 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.267 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.253 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.269 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.325 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.253 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.233 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.281 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.383 +- 0.347 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.224 +- 0.239 (in-sample avg dev_std = 0.397)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
NEC for r=0.3 class 0 = 0.366 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 1 = 0.397 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 2 = 0.416 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 3 = 0.399 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 4 = 0.411 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 5 = 0.384 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 6 = 0.409 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 7 = 0.412 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 8 = 0.372 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 9 = 0.426 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all KL = 0.241 +- 0.165 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all L1 = 0.399 +- 0.142 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.175
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.154
NEC for r=0.6 class 0 = 0.495 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 1 = 0.458 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 2 = 0.489 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 3 = 0.504 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 4 = 0.465 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 5 = 0.476 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 6 = 0.434 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 7 = 0.492 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 8 = 0.423 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 9 = 0.491 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all KL = 0.449 +- 0.233 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all L1 = 0.473 +- 0.185 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.223 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 1 = 0.208 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 2 = 0.439 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 3 = 0.467 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 4 = 0.413 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 5 = 0.538 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 6 = 0.498 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 7 = 0.501 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 8 = 0.312 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 9 = 0.459 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 all KL = 0.568 +- 0.322 (in-sample avg dev_std = 0.476)
NEC for r=0.9 all L1 = 0.402 +- 0.257 (in-sample avg dev_std = 0.476)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.951
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.844
NEC for r=1.0 class 0 = 0.056 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 1 = 0.032 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 2 = 0.253 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 3 = 0.205 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 4 = 0.205 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 5 = 0.339 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 6 = 0.344 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 7 = 0.234 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 8 = 0.212 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 9 = 0.31 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all KL = 0.358 +- 0.343 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all L1 = 0.214 +- 0.242 (in-sample avg dev_std = 0.376)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.087
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.083
NEC for r=0.3 class 0 = 0.375 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 1 = 0.4 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 2 = 0.399 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 3 = 0.403 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 4 = 0.376 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 5 = 0.376 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 6 = 0.407 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 7 = 0.394 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 8 = 0.407 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 class 9 = 0.42 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 all KL = 0.24 +- 0.167 (in-sample avg dev_std = 0.230)
NEC for r=0.3 all L1 = 0.396 +- 0.148 (in-sample avg dev_std = 0.230)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.138
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.133
NEC for r=0.6 class 0 = 0.483 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 1 = 0.466 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 2 = 0.495 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 3 = 0.488 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 4 = 0.461 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 5 = 0.489 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 6 = 0.485 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 7 = 0.457 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 8 = 0.421 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 class 9 = 0.45 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 all KL = 0.457 +- 0.234 (in-sample avg dev_std = 0.370)
NEC for r=0.6 all L1 = 0.469 +- 0.190 (in-sample avg dev_std = 0.370)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.796
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.618
NEC for r=0.9 class 0 = 0.365 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 1 = 0.121 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 2 = 0.431 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 3 = 0.444 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 4 = 0.418 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 5 = 0.543 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 6 = 0.492 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 7 = 0.398 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 8 = 0.41 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 9 = 0.487 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all KL = 0.567 +- 0.325 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all L1 = 0.406 +- 0.264 (in-sample avg dev_std = 0.461)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.921
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.804
NEC for r=1.0 class 0 = 0.093 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 1 = 0.032 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 2 = 0.311 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 3 = 0.304 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 4 = 0.292 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 5 = 0.3 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 6 = 0.356 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 7 = 0.183 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 8 = 0.3 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 9 = 0.369 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 all KL = 0.385 +- 0.353 (in-sample avg dev_std = 0.408)
NEC for r=1.0 all L1 = 0.251 +- 0.260 (in-sample avg dev_std = 0.408)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
NEC for r=0.3 class 0 = 0.345 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1 = 0.375 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 2 = 0.376 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 3 = 0.413 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 4 = 0.423 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 5 = 0.35 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 6 = 0.391 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 7 = 0.362 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 8 = 0.373 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 9 = 0.391 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.218 +- 0.167 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.38 +- 0.150 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
NEC for r=0.6 class 0 = 0.466 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 1 = 0.52 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 2 = 0.499 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 3 = 0.512 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 4 = 0.505 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 5 = 0.549 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 6 = 0.52 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 7 = 0.52 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 8 = 0.495 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 class 9 = 0.511 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 all KL = 0.5 +- 0.232 (in-sample avg dev_std = 0.362)
NEC for r=0.6 all L1 = 0.509 +- 0.172 (in-sample avg dev_std = 0.362)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.609
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.48
NEC for r=0.9 class 0 = 0.545 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.079 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.361 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 3 = 0.566 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 4 = 0.422 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 5 = 0.562 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 6 = 0.599 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 7 = 0.415 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 8 = 0.542 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 9 = 0.592 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.57 +- 0.341 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.462 +- 0.276 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.577
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.595
NEC for r=1.0 class 0 = 0.39 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 1 = 0.018 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 2 = 0.411 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 3 = 0.488 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 4 = 0.434 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 5 = 0.422 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 6 = 0.578 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 7 = 0.373 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 8 = 0.523 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 class 9 = 0.494 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 all KL = 0.543 +- 0.378 (in-sample avg dev_std = 0.421)
NEC for r=1.0 all L1 = 0.408 +- 0.302 (in-sample avg dev_std = 0.421)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.54, 0.534, 0.853, 1.0], 'all_L1': [0.514, 0.494, 0.829, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.713, 0.563, 0.837, 1.0], 'all_L1': [0.558, 0.553, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.726, 0.544, 0.836, 1.0], 'all_L1': [0.587, 0.526, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.713, 0.561, 0.835, 1.0], 'all_L1': [0.549, 0.488, 0.81, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.805, 0.568, 0.849, 1.0], 'all_L1': [0.631, 0.528, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.271, 0.497, 0.557, 0.369], 'all_L1': [0.409, 0.521, 0.394, 0.22]}), defaultdict(<class 'list'>, {'all_KL': [0.243, 0.514, 0.577, 0.392], 'all_L1': [0.396, 0.483, 0.41, 0.226]}), defaultdict(<class 'list'>, {'all_KL': [0.314, 0.495, 0.596, 0.381], 'all_L1': [0.435, 0.493, 0.413, 0.214]}), defaultdict(<class 'list'>, {'all_KL': [0.178, 0.453, 0.585, 0.39], 'all_L1': [0.362, 0.514, 0.424, 0.231]}), defaultdict(<class 'list'>, {'all_KL': [0.24, 0.476, 0.566, 0.383], 'all_L1': [0.395, 0.489, 0.408, 0.224]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.533, 0.531, 0.848, 1.0], 'all_L1': [0.51, 0.487, 0.834, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.702, 0.571, 0.822, 1.0], 'all_L1': [0.55, 0.555, 0.816, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.722, 0.534, 0.836, 1.0], 'all_L1': [0.587, 0.517, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.711, 0.542, 0.833, 1.0], 'all_L1': [0.544, 0.48, 0.818, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.801, 0.572, 0.839, 1.0], 'all_L1': [0.627, 0.538, 0.822, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.266, 0.498, 0.549, 0.367], 'all_L1': [0.411, 0.521, 0.391, 0.218]}), defaultdict(<class 'list'>, {'all_KL': [0.254, 0.498, 0.556, 0.375], 'all_L1': [0.408, 0.479, 0.393, 0.216]}), defaultdict(<class 'list'>, {'all_KL': [0.314, 0.499, 0.584, 0.373], 'all_L1': [0.432, 0.494, 0.409, 0.211]}), defaultdict(<class 'list'>, {'all_KL': [0.178, 0.464, 0.574, 0.391], 'all_L1': [0.362, 0.516, 0.413, 0.23]}), defaultdict(<class 'list'>, {'all_KL': [0.241, 0.449, 0.568, 0.358], 'all_L1': [0.399, 0.473, 0.402, 0.214]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.52, 0.526, 0.833, 1.0], 'all_L1': [0.501, 0.492, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.711, 0.55, 0.833, 1.0], 'all_L1': [0.557, 0.54, 0.822, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.743, 0.532, 0.823, 1.0], 'all_L1': [0.601, 0.509, 0.814, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.724, 0.593, 0.831, 1.0], 'all_L1': [0.554, 0.509, 0.809, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.812, 0.558, 0.827, 1.0], 'all_L1': [0.637, 0.531, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.273, 0.513, 0.568, 0.379], 'all_L1': [0.415, 0.525, 0.407, 0.24]}), defaultdict(<class 'list'>, {'all_KL': [0.251, 0.485, 0.592, 0.415], 'all_L1': [0.406, 0.471, 0.422, 0.261]}), defaultdict(<class 'list'>, {'all_KL': [0.313, 0.492, 0.608, 0.402], 'all_L1': [0.431, 0.496, 0.438, 0.253]}), defaultdict(<class 'list'>, {'all_KL': [0.176, 0.414, 0.573, 0.411], 'all_L1': [0.361, 0.49, 0.419, 0.257]}), defaultdict(<class 'list'>, {'all_KL': [0.24, 0.457, 0.567, 0.385], 'all_L1': [0.396, 0.469, 0.406, 0.251]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.527, 0.527, 0.805, 1.0], 'all_L1': [0.515, 0.479, 0.759, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.734, 0.533, 0.804, 1.0], 'all_L1': [0.576, 0.51, 0.769, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.778, 0.525, 0.782, 1.0], 'all_L1': [0.646, 0.499, 0.742, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.729, 0.69, 0.823, 1.0], 'all_L1': [0.557, 0.58, 0.79, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.824, 0.513, 0.805, 1.0], 'all_L1': [0.652, 0.488, 0.773, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.254, 0.494, 0.585, 0.504], 'all_L1': [0.4, 0.527, 0.489, 0.386]}), defaultdict(<class 'list'>, {'all_KL': [0.251, 0.498, 0.597, 0.534], 'all_L1': [0.404, 0.494, 0.476, 0.402]}), defaultdict(<class 'list'>, {'all_KL': [0.263, 0.514, 0.632, 0.565], 'all_L1': [0.372, 0.51, 0.515, 0.417]}), defaultdict(<class 'list'>, {'all_KL': [0.183, 0.327, 0.563, 0.464], 'all_L1': [0.366, 0.428, 0.441, 0.315]}), defaultdict(<class 'list'>, {'all_KL': [0.218, 0.5, 0.57, 0.543], 'all_L1': [0.38, 0.509, 0.462, 0.408]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.568 +- 0.039, 0.518 +- 0.024, 0.822 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.699 +- 0.087, 0.554 +- 0.013, 0.842 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.095 +- 0.004, 0.145 +- 0.022, 0.757 +- 0.007
nec class all_L1  =  0.399 +- 0.024, 0.500 +- 0.015, 0.410 +- 0.010, 0.223 +- 0.006
nec class all_KL  =  0.249 +- 0.044, 0.487 +- 0.021, 0.576 +- 0.014, 0.383 +- 0.008
nec_acc_int  =  0.090 +- 0.005, 0.146 +- 0.028, 0.613 +- 0.016, 0.840 +- 0.005

Eval split id_val
suff++ class all_L1  =  0.564 +- 0.040, 0.515 +- 0.029, 0.823 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.694 +- 0.088, 0.550 +- 0.018, 0.836 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.098 +- 0.011, 0.167 +- 0.027, 0.764 +- 0.005
nec class all_L1  =  0.402 +- 0.023, 0.497 +- 0.019, 0.402 +- 0.009, 0.218 +- 0.007
nec class all_KL  =  0.251 +- 0.044, 0.482 +- 0.021, 0.566 +- 0.012, 0.373 +- 0.011
nec_acc_int  =  0.099 +- 0.009, 0.165 +- 0.025, 0.617 +- 0.008, 0.842 +- 0.008

Eval split val
suff++ class all_L1  =  0.570 +- 0.046, 0.516 +- 0.017, 0.816 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.702 +- 0.097, 0.552 +- 0.024, 0.829 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.095 +- 0.008, 0.136 +- 0.018, 0.753 +- 0.014
nec class all_L1  =  0.402 +- 0.023, 0.490 +- 0.020, 0.418 +- 0.012, 0.252 +- 0.007
nec class all_KL  =  0.251 +- 0.045, 0.472 +- 0.034, 0.582 +- 0.016, 0.398 +- 0.014
nec_acc_int  =  0.091 +- 0.009, 0.149 +- 0.021, 0.598 +- 0.020, 0.802 +- 0.009

Eval split test
suff++ class all_L1  =  0.589 +- 0.053, 0.511 +- 0.036, 0.767 +- 0.016, 1.000 +- 0.000
suff++ class all_KL  =  0.718 +- 0.102, 0.558 +- 0.067, 0.804 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.100 +- 0.007, 0.153 +- 0.006, 0.591 +- 0.058
nec class all_L1  =  0.384 +- 0.015, 0.494 +- 0.034, 0.477 +- 0.025, 0.386 +- 0.037
nec class all_KL  =  0.234 +- 0.030, 0.467 +- 0.070, 0.589 +- 0.024, 0.522 +- 0.035
nec_acc_int  =  0.096 +- 0.012, 0.162 +- 0.014, 0.453 +- 0.050, 0.612 +- 0.062


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.484 +- 0.024, 0.509 +- 0.005, 0.616 +- 0.002, 0.611 +- 0.003
Faith. Armon (L1)= 		  =  0.468 +- 0.022, 0.508 +- 0.005, 0.547 +- 0.007, 0.365 +- 0.008
Faith. GMean (L1)= 	  =  0.476 +- 0.023, 0.508 +- 0.005, 0.580 +- 0.005, 0.472 +- 0.006
Faith. Aritm (KL)= 		  =  0.474 +- 0.045, 0.521 +- 0.010, 0.709 +- 0.004, 0.692 +- 0.004
Faith. Armon (KL)= 		  =  0.363 +- 0.049, 0.518 +- 0.012, 0.684 +- 0.008, 0.554 +- 0.009
Faith. GMean (KL)= 	  =  0.414 +- 0.042, 0.519 +- 0.011, 0.696 +- 0.006, 0.619 +- 0.007

Eval split id_val
Faith. Aritm (L1)= 		  =  0.483 +- 0.025, 0.506 +- 0.006, 0.612 +- 0.004, 0.609 +- 0.003
Faith. Armon (L1)= 		  =  0.469 +- 0.023, 0.505 +- 0.005, 0.540 +- 0.007, 0.358 +- 0.009
Faith. GMean (L1)= 	  =  0.476 +- 0.023, 0.505 +- 0.006, 0.575 +- 0.006, 0.467 +- 0.007
Faith. Aritm (KL)= 		  =  0.472 +- 0.046, 0.516 +- 0.010, 0.701 +- 0.007, 0.686 +- 0.005
Faith. Armon (KL)= 		  =  0.364 +- 0.049, 0.513 +- 0.011, 0.675 +- 0.009, 0.543 +- 0.011
Faith. GMean (KL)= 	  =  0.414 +- 0.043, 0.514 +- 0.011, 0.688 +- 0.008, 0.611 +- 0.009

Eval split val
Faith. Aritm (L1)= 		  =  0.486 +- 0.026, 0.503 +- 0.003, 0.617 +- 0.006, 0.626 +- 0.004
Faith. Armon (L1)= 		  =  0.470 +- 0.023, 0.502 +- 0.003, 0.553 +- 0.010, 0.403 +- 0.009
Faith. GMean (L1)= 	  =  0.478 +- 0.024, 0.503 +- 0.003, 0.584 +- 0.008, 0.502 +- 0.007
Faith. Aritm (KL)= 		  =  0.476 +- 0.049, 0.512 +- 0.006, 0.706 +- 0.007, 0.699 +- 0.007
Faith. Armon (KL)= 		  =  0.365 +- 0.050, 0.507 +- 0.011, 0.684 +- 0.010, 0.570 +- 0.015
Faith. GMean (KL)= 	  =  0.416 +- 0.045, 0.510 +- 0.009, 0.694 +- 0.009, 0.631 +- 0.011

Eval split test
Faith. Aritm (L1)= 		  =  0.487 +- 0.024, 0.502 +- 0.002, 0.622 +- 0.005, 0.693 +- 0.018
Faith. Armon (L1)= 		  =  0.464 +- 0.015, 0.500 +- 0.004, 0.587 +- 0.014, 0.556 +- 0.040
Faith. GMean (L1)= 	  =  0.475 +- 0.019, 0.501 +- 0.002, 0.604 +- 0.010, 0.620 +- 0.031
Faith. Aritm (KL)= 		  =  0.476 +- 0.049, 0.512 +- 0.005, 0.697 +- 0.007, 0.761 +- 0.017
Faith. Armon (KL)= 		  =  0.349 +- 0.034, 0.499 +- 0.028, 0.680 +- 0.012, 0.685 +- 0.031
Faith. GMean (KL)= 	  =  0.407 +- 0.035, 0.505 +- 0.016, 0.688 +- 0.009, 0.722 +- 0.024
Computed for split load_split = id



Completed in  2:00:40.182072  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 17:56:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:14 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:14 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:14 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:14 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 05:56:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ACCURACY: 0.9954
Train Loss: 0.0231
ID Validation ACCURACY: 0.9054
ID Validation Loss: 0.3676
ID Test ACCURACY: 0.9003
ID Test Loss: 0.3717
OOD Validation ACCURACY: 0.8880
OOD Validation Loss: 0.4177
OOD Test ACCURACY: 0.7470
OOD Test Loss: 1.0631

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9843
Train Loss: 0.0525
ID Validation ACCURACY: 0.8973
ID Validation Loss: 0.3555
ID Test ACCURACY: 0.8986
ID Test Loss: 0.3473
OOD Validation ACCURACY: 0.8944
OOD Validation Loss: 0.3583
OOD Test ACCURACY: 0.7639
OOD Test Loss: 0.9545

[0m[1;37mINFO[0m: [1mChartInfo 0.9003 0.7470 0.8986 0.7639 0.8973 0.8944[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.089
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
SUFF++ for r=0.3 class 0 = 0.49 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 1 = 0.483 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 2 = 0.457 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 3 = 0.481 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 4 = 0.473 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 5 = 0.441 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 6 = 0.453 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 7 = 0.477 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 8 = 0.466 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 9 = 0.49 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 all KL = 0.537 +- 0.138 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 all L1 = 0.471 +- 0.084 (in-sample avg dev_std = 0.461)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.154
SUFF++ for r=0.6 class 0 = 0.547 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 1 = 0.475 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 2 = 0.519 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 3 = 0.48 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 4 = 0.457 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 5 = 0.519 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 6 = 0.521 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 7 = 0.48 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 8 = 0.504 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 9 = 0.491 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all KL = 0.569 +- 0.264 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all L1 = 0.499 +- 0.196 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.864 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 1 = 0.879 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 2 = 0.808 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 3 = 0.762 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 4 = 0.835 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 5 = 0.761 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 6 = 0.825 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 7 = 0.803 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 8 = 0.815 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 class 9 = 0.761 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all KL = 0.838 +- 0.221 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.206 (in-sample avg dev_std = 0.249)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
SUFF++ for r=0.3 class 0 = 0.469 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 1 = 0.481 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 2 = 0.458 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 3 = 0.455 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 4 = 0.465 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 5 = 0.472 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 6 = 0.46 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 7 = 0.469 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 8 = 0.474 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 9 = 0.443 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all KL = 0.532 +- 0.134 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all L1 = 0.465 +- 0.083 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
SUFF++ for r=0.6 class 0 = 0.48 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 1 = 0.501 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 2 = 0.559 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 3 = 0.503 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 4 = 0.528 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 5 = 0.513 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 6 = 0.498 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 7 = 0.489 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 8 = 0.55 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 9 = 0.479 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all KL = 0.575 +- 0.272 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all L1 = 0.51 +- 0.199 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.758
SUFF++ for r=0.9 class 0 = 0.889 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 1 = 0.921 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 2 = 0.804 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 3 = 0.729 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 4 = 0.839 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 5 = 0.719 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 6 = 0.792 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 7 = 0.794 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 8 = 0.837 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 9 = 0.77 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all KL = 0.83 +- 0.236 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all L1 = 0.812 +- 0.210 (in-sample avg dev_std = 0.263)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.479 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 1 = 0.495 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 3 = 0.472 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 4 = 0.452 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 5 = 0.472 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 6 = 0.477 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 7 = 0.46 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 8 = 0.441 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 9 = 0.473 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all KL = 0.542 +- 0.143 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all L1 = 0.47 +- 0.083 (in-sample avg dev_std = 0.463)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.119
SUFF++ for r=0.6 class 0 = 0.557 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 1 = 0.434 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 2 = 0.597 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 3 = 0.535 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 4 = 0.493 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 5 = 0.494 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 6 = 0.448 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 7 = 0.487 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 8 = 0.481 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 9 = 0.498 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all KL = 0.557 +- 0.265 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all L1 = 0.501 +- 0.199 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.744
SUFF++ for r=0.9 class 0 = 0.872 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.941 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.774 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 3 = 0.767 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 4 = 0.807 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 5 = 0.747 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 6 = 0.807 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 7 = 0.848 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 8 = 0.801 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 9 = 0.781 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.838 +- 0.230 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.817 +- 0.209 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
SUFF++ for r=0.3 class 0 = 0.474 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 1 = 0.492 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 2 = 0.463 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 3 = 0.452 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 4 = 0.454 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 5 = 0.463 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 6 = 0.459 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 7 = 0.473 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 8 = 0.47 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 class 9 = 0.463 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 all KL = 0.541 +- 0.158 (in-sample avg dev_std = 0.472)
SUFF++ for r=0.3 all L1 = 0.467 +- 0.092 (in-sample avg dev_std = 0.472)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.14
SUFF++ for r=0.6 class 0 = 0.574 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 1 = 0.502 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 2 = 0.579 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 3 = 0.546 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 4 = 0.549 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 5 = 0.569 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 6 = 0.544 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 7 = 0.524 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 8 = 0.512 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 9 = 0.54 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all KL = 0.609 +- 0.259 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all L1 = 0.543 +- 0.210 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.66
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.608
SUFF++ for r=0.9 class 0 = 0.708 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 1 = 0.94 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 2 = 0.774 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 3 = 0.698 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 4 = 0.823 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 5 = 0.693 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 6 = 0.756 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 7 = 0.815 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 8 = 0.737 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 9 = 0.692 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all KL = 0.806 +- 0.229 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all L1 = 0.767 +- 0.212 (in-sample avg dev_std = 0.278)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.089
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.086
NEC for r=0.3 class 0 = 0.418 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1 = 0.394 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 2 = 0.43 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 3 = 0.396 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 4 = 0.401 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 5 = 0.415 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 6 = 0.44 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 7 = 0.429 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 8 = 0.391 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 9 = 0.409 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.245 +- 0.138 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.412 +- 0.115 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.149
NEC for r=0.6 class 0 = 0.516 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 1 = 0.481 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 2 = 0.507 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 3 = 0.489 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 4 = 0.521 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 5 = 0.496 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 6 = 0.495 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 7 = 0.506 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 8 = 0.537 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 class 9 = 0.521 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 all KL = 0.448 +- 0.214 (in-sample avg dev_std = 0.333)
NEC for r=0.6 all L1 = 0.507 +- 0.143 (in-sample avg dev_std = 0.333)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.595
NEC for r=0.9 class 0 = 0.406 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 1 = 0.236 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 2 = 0.365 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 3 = 0.56 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 4 = 0.342 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 5 = 0.547 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 6 = 0.471 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 7 = 0.501 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 8 = 0.38 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 9 = 0.472 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all KL = 0.57 +- 0.312 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all L1 = 0.425 +- 0.254 (in-sample avg dev_std = 0.463)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.945
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0 = 0.147 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 1 = 0.053 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 2 = 0.257 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 3 = 0.322 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 4 = 0.16 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 5 = 0.308 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 6 = 0.309 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 7 = 0.213 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 8 = 0.223 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 9 = 0.378 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all KL = 0.389 +- 0.343 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all L1 = 0.234 +- 0.242 (in-sample avg dev_std = 0.400)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
NEC for r=0.3 class 0 = 0.42 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 1 = 0.396 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 2 = 0.403 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 3 = 0.407 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 4 = 0.408 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 5 = 0.393 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 6 = 0.423 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 7 = 0.406 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 8 = 0.406 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 class 9 = 0.44 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 all KL = 0.241 +- 0.137 (in-sample avg dev_std = 0.218)
NEC for r=0.3 all L1 = 0.41 +- 0.115 (in-sample avg dev_std = 0.218)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.158
NEC for r=0.6 class 0 = 0.529 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 1 = 0.493 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 2 = 0.46 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 3 = 0.506 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 4 = 0.517 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 5 = 0.52 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 6 = 0.493 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 7 = 0.504 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 8 = 0.508 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 9 = 0.535 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all KL = 0.455 +- 0.226 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all L1 = 0.506 +- 0.151 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.586
NEC for r=0.9 class 0 = 0.444 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 1 = 0.204 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 2 = 0.341 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 3 = 0.541 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 4 = 0.299 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 5 = 0.583 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 6 = 0.455 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 7 = 0.514 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 8 = 0.403 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 class 9 = 0.512 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all KL = 0.576 +- 0.320 (in-sample avg dev_std = 0.456)
NEC for r=0.9 all L1 = 0.426 +- 0.263 (in-sample avg dev_std = 0.456)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.962
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.829
NEC for r=1.0 class 0 = 0.152 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 1 = 0.028 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 2 = 0.23 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 3 = 0.32 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 4 = 0.162 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 5 = 0.391 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 6 = 0.342 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 7 = 0.208 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 8 = 0.199 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 9 = 0.398 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 all KL = 0.394 +- 0.353 (in-sample avg dev_std = 0.401)
NEC for r=1.0 all L1 = 0.237 +- 0.253 (in-sample avg dev_std = 0.401)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.099
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.094
NEC for r=0.3 class 0 = 0.409 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 1 = 0.413 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 2 = 0.42 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 3 = 0.399 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 4 = 0.395 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 5 = 0.412 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 6 = 0.432 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 7 = 0.417 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 8 = 0.408 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 class 9 = 0.426 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all KL = 0.245 +- 0.144 (in-sample avg dev_std = 0.214)
NEC for r=0.3 all L1 = 0.413 +- 0.120 (in-sample avg dev_std = 0.214)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
NEC for r=0.6 class 0 = 0.468 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 1 = 0.529 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 2 = 0.426 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 3 = 0.476 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 4 = 0.52 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 5 = 0.459 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 6 = 0.545 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 7 = 0.495 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 8 = 0.513 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 class 9 = 0.51 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all KL = 0.451 +- 0.215 (in-sample avg dev_std = 0.348)
NEC for r=0.6 all L1 = 0.495 +- 0.153 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.576
NEC for r=0.9 class 0 = 0.547 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 1 = 0.15 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 2 = 0.364 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 3 = 0.557 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 4 = 0.339 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 5 = 0.551 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 6 = 0.512 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 7 = 0.475 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 8 = 0.436 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 class 9 = 0.506 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 all KL = 0.594 +- 0.321 (in-sample avg dev_std = 0.459)
NEC for r=0.9 all L1 = 0.439 +- 0.263 (in-sample avg dev_std = 0.459)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.933
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.797
NEC for r=1.0 class 0 = 0.178 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 1 = 0.046 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 2 = 0.267 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 3 = 0.383 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 4 = 0.224 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 5 = 0.369 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 6 = 0.33 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 7 = 0.202 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 8 = 0.247 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 class 9 = 0.403 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 all KL = 0.403 +- 0.352 (in-sample avg dev_std = 0.404)
NEC for r=1.0 all L1 = 0.262 +- 0.261 (in-sample avg dev_std = 0.404)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
NEC for r=0.3 class 0 = 0.398 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 1 = 0.429 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 2 = 0.41 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 3 = 0.439 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 4 = 0.439 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 5 = 0.398 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 6 = 0.421 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 7 = 0.418 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 8 = 0.434 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 9 = 0.433 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all KL = 0.262 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all L1 = 0.422 +- 0.119 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
NEC for r=0.6 class 0 = 0.425 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 1 = 0.459 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 2 = 0.445 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 3 = 0.452 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 4 = 0.482 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 5 = 0.453 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 6 = 0.484 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 7 = 0.485 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 8 = 0.486 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 class 9 = 0.501 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all KL = 0.417 +- 0.212 (in-sample avg dev_std = 0.339)
NEC for r=0.6 all L1 = 0.467 +- 0.163 (in-sample avg dev_std = 0.339)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.66
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.442
NEC for r=0.9 class 0 = 0.625 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 1 = 0.159 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 2 = 0.379 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 3 = 0.605 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 4 = 0.324 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 5 = 0.591 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 6 = 0.614 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 7 = 0.466 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 8 = 0.553 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 9 = 0.597 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 all KL = 0.588 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=0.9 all L1 = 0.486 +- 0.266 (in-sample avg dev_std = 0.413)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.762
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.629
NEC for r=1.0 class 0 = 0.643 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 1 = 0.029 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 2 = 0.373 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 3 = 0.476 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 4 = 0.317 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 5 = 0.506 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 6 = 0.414 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 7 = 0.248 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 8 = 0.441 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 class 9 = 0.561 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 all KL = 0.513 +- 0.357 (in-sample avg dev_std = 0.429)
NEC for r=1.0 all L1 = 0.396 +- 0.286 (in-sample avg dev_std = 0.429)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 18:19:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:19:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:19:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9975
Train Loss: 0.0137
ID Validation ACCURACY: 0.8991
ID Validation Loss: 0.3905
ID Test ACCURACY: 0.8954
ID Test Loss: 0.4022
OOD Validation ACCURACY: 0.8833
OOD Validation Loss: 0.4775
OOD Test ACCURACY: 0.6750
OOD Test Loss: 1.6410

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ACCURACY: 0.9799
Train Loss: 0.0696
ID Validation ACCURACY: 0.8897
ID Validation Loss: 0.3598
ID Test ACCURACY: 0.8921
ID Test Loss: 0.3559
OOD Validation ACCURACY: 0.8977
OOD Validation Loss: 0.3375
OOD Test ACCURACY: 0.8036
OOD Test Loss: 0.7369

[0m[1;37mINFO[0m: [1mChartInfo 0.8954 0.6750 0.8921 0.8036 0.8897 0.8977[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.089
SUFF++ for r=0.3 class 0 = 0.519 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 1 = 0.533 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 2 = 0.514 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 3 = 0.523 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 4 = 0.515 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 5 = 0.499 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 6 = 0.514 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 7 = 0.524 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 8 = 0.506 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 9 = 0.518 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all KL = 0.667 +- 0.090 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all L1 = 0.517 +- 0.060 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
SUFF++ for r=0.6 class 0 = 0.53 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 1 = 0.514 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 2 = 0.491 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 3 = 0.538 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 4 = 0.478 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 5 = 0.518 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 6 = 0.473 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 7 = 0.484 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 8 = 0.5 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 9 = 0.486 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 all KL = 0.561 +- 0.256 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 all L1 = 0.501 +- 0.180 (in-sample avg dev_std = 0.151)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.762
SUFF++ for r=0.9 class 0 = 0.937 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1 = 0.912 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 2 = 0.822 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 3 = 0.795 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 4 = 0.749 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 5 = 0.778 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 6 = 0.812 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 7 = 0.837 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 8 = 0.825 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 9 = 0.775 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.847 +- 0.223 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.201 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.089
SUFF++ for r=0.3 class 0 = 0.527 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 1 = 0.527 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 2 = 0.505 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 3 = 0.495 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 4 = 0.503 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 5 = 0.524 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 6 = 0.499 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 7 = 0.519 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 8 = 0.526 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 9 = 0.493 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 all KL = 0.659 +- 0.095 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 all L1 = 0.512 +- 0.064 (in-sample avg dev_std = 0.397)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.2
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.161
SUFF++ for r=0.6 class 0 = 0.513 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 1 = 0.542 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 2 = 0.52 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 3 = 0.485 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 4 = 0.483 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 5 = 0.479 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 6 = 0.514 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 7 = 0.46 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 8 = 0.538 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 9 = 0.479 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 all KL = 0.561 +- 0.262 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 all L1 = 0.502 +- 0.184 (in-sample avg dev_std = 0.157)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.782
SUFF++ for r=0.9 class 0 = 0.964 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 1 = 0.92 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 2 = 0.82 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 3 = 0.758 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 4 = 0.784 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 5 = 0.713 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 6 = 0.761 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 7 = 0.805 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 8 = 0.848 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 class 9 = 0.783 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all KL = 0.83 +- 0.236 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.208 (in-sample avg dev_std = 0.261)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.531 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 1 = 0.537 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 2 = 0.521 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 3 = 0.531 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 4 = 0.524 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 5 = 0.524 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 6 = 0.524 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 7 = 0.515 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 8 = 0.513 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 class 9 = 0.514 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 all KL = 0.673 +- 0.089 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.061 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.165
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.144
SUFF++ for r=0.6 class 0 = 0.511 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 1 = 0.572 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 2 = 0.511 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 3 = 0.496 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 4 = 0.512 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 5 = 0.487 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 6 = 0.461 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 7 = 0.481 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 8 = 0.521 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 class 9 = 0.482 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all KL = 0.565 +- 0.253 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.6 all L1 = 0.504 +- 0.178 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.749
SUFF++ for r=0.9 class 0 = 0.936 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.926 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.791 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 3 = 0.831 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 4 = 0.765 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 5 = 0.735 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 6 = 0.725 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 7 = 0.833 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 8 = 0.852 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 9 = 0.811 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.835 +- 0.230 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.822 +- 0.204 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.543 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 1 = 0.534 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 2 = 0.52 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 3 = 0.526 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 4 = 0.52 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 5 = 0.519 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 6 = 0.521 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 7 = 0.532 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 8 = 0.521 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 9 = 0.524 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all KL = 0.683 +- 0.094 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all L1 = 0.526 +- 0.065 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.164
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
SUFF++ for r=0.6 class 0 = 0.59 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 1 = 0.559 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 2 = 0.536 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 3 = 0.517 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 4 = 0.5 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 5 = 0.502 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 6 = 0.459 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 7 = 0.506 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 8 = 0.484 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 9 = 0.493 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all KL = 0.598 +- 0.248 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all L1 = 0.516 +- 0.183 (in-sample avg dev_std = 0.136)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.615
SUFF++ for r=0.9 class 0 = 0.736 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 1 = 0.938 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 2 = 0.766 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 3 = 0.752 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 4 = 0.77 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 5 = 0.684 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 6 = 0.696 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 7 = 0.814 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 8 = 0.757 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 9 = 0.688 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all KL = 0.807 +- 0.229 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all L1 = 0.763 +- 0.212 (in-sample avg dev_std = 0.267)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.083
NEC for r=0.3 class 0 = 0.402 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 1 = 0.342 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 2 = 0.386 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 3 = 0.389 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 4 = 0.373 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 5 = 0.401 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 6 = 0.386 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 7 = 0.394 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 8 = 0.403 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 9 = 0.389 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all KL = 0.19 +- 0.105 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all L1 = 0.386 +- 0.097 (in-sample avg dev_std = 0.161)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.172
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.158
NEC for r=0.6 class 0 = 0.494 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 1 = 0.453 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 2 = 0.523 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 3 = 0.508 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 4 = 0.525 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 5 = 0.513 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 6 = 0.565 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 7 = 0.514 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 8 = 0.555 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 9 = 0.548 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all KL = 0.473 +- 0.211 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all L1 = 0.519 +- 0.133 (in-sample avg dev_std = 0.293)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.216 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 1 = 0.22 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 2 = 0.36 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 3 = 0.533 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 4 = 0.473 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 5 = 0.516 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 6 = 0.513 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 7 = 0.406 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 8 = 0.349 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 9 = 0.442 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all KL = 0.557 +- 0.313 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all L1 = 0.4 +- 0.256 (in-sample avg dev_std = 0.449)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.95
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.834
NEC for r=1.0 class 0 = 0.095 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 1 = 0.063 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 2 = 0.206 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 3 = 0.329 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 4 = 0.263 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 5 = 0.272 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 6 = 0.367 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 7 = 0.191 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 8 = 0.226 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 9 = 0.312 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 all KL = 0.392 +- 0.354 (in-sample avg dev_std = 0.403)
NEC for r=1.0 all L1 = 0.23 +- 0.244 (in-sample avg dev_std = 0.403)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.087
NEC for r=0.3 class 0 = 0.391 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 1 = 0.355 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 2 = 0.395 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 3 = 0.39 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 4 = 0.379 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 5 = 0.367 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 6 = 0.404 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 7 = 0.378 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 8 = 0.382 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 9 = 0.398 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all KL = 0.189 +- 0.105 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all L1 = 0.384 +- 0.097 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.2
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.187
NEC for r=0.6 class 0 = 0.517 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 1 = 0.429 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 2 = 0.52 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 3 = 0.551 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 4 = 0.54 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 5 = 0.502 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 6 = 0.52 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 7 = 0.497 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 8 = 0.543 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 class 9 = 0.556 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all KL = 0.472 +- 0.219 (in-sample avg dev_std = 0.299)
NEC for r=0.6 all L1 = 0.516 +- 0.137 (in-sample avg dev_std = 0.299)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.633
NEC for r=0.9 class 0 = 0.22 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 1 = 0.229 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 2 = 0.335 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 3 = 0.526 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 4 = 0.424 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 5 = 0.529 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 6 = 0.514 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 7 = 0.401 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 8 = 0.346 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 class 9 = 0.444 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all KL = 0.546 +- 0.322 (in-sample avg dev_std = 0.440)
NEC for r=0.9 all L1 = 0.393 +- 0.263 (in-sample avg dev_std = 0.440)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.947
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.835
NEC for r=1.0 class 0 = 0.066 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.045 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.217 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.312 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.224 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.349 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.353 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.21 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.175 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.313 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.383 +- 0.357 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.222 +- 0.245 (in-sample avg dev_std = 0.397)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
NEC for r=0.3 class 0 = 0.394 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 1 = 0.355 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 2 = 0.383 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 3 = 0.369 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 4 = 0.358 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 5 = 0.371 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 6 = 0.384 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 7 = 0.367 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 8 = 0.388 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 9 = 0.38 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 all KL = 0.182 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=0.3 all L1 = 0.375 +- 0.098 (in-sample avg dev_std = 0.159)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.165
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.487 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 1 = 0.42 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 2 = 0.53 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 3 = 0.507 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 4 = 0.505 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 5 = 0.488 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 6 = 0.535 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 7 = 0.511 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 8 = 0.494 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 9 = 0.535 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all KL = 0.452 +- 0.210 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all L1 = 0.501 +- 0.135 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.612
NEC for r=0.9 class 0 = 0.358 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 1 = 0.193 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 2 = 0.35 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 3 = 0.478 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 4 = 0.457 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 5 = 0.493 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 6 = 0.54 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 7 = 0.369 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 8 = 0.341 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 9 = 0.463 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all KL = 0.561 +- 0.314 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all L1 = 0.401 +- 0.257 (in-sample avg dev_std = 0.449)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.811
NEC for r=1.0 class 0 = 0.144 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 1 = 0.036 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 2 = 0.286 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 3 = 0.311 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 4 = 0.277 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 5 = 0.271 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 6 = 0.375 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 7 = 0.166 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 8 = 0.237 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 9 = 0.347 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all KL = 0.385 +- 0.354 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all L1 = 0.243 +- 0.259 (in-sample avg dev_std = 0.393)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.086
NEC for r=0.3 class 0 = 0.39 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 1 = 0.337 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 2 = 0.396 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 3 = 0.393 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 4 = 0.385 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 5 = 0.367 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 6 = 0.381 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 7 = 0.365 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 8 = 0.382 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 class 9 = 0.387 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all KL = 0.181 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=0.3 all L1 = 0.378 +- 0.099 (in-sample avg dev_std = 0.161)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.164
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.141
NEC for r=0.6 class 0 = 0.445 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 1 = 0.403 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 2 = 0.516 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 3 = 0.512 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 4 = 0.521 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 5 = 0.507 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 6 = 0.548 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 7 = 0.473 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 8 = 0.537 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 9 = 0.534 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all KL = 0.424 +- 0.204 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all L1 = 0.498 +- 0.141 (in-sample avg dev_std = 0.282)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.656
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.486
NEC for r=0.9 class 0 = 0.648 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 1 = 0.143 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 2 = 0.413 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 3 = 0.528 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 4 = 0.496 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 5 = 0.523 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 6 = 0.622 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 7 = 0.414 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 8 = 0.432 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 class 9 = 0.569 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 all KL = 0.576 +- 0.302 (in-sample avg dev_std = 0.412)
NEC for r=0.9 all L1 = 0.474 +- 0.251 (in-sample avg dev_std = 0.412)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.625
NEC for r=1.0 class 0 = 0.647 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 1 = 0.043 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 2 = 0.371 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 3 = 0.419 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 4 = 0.402 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 5 = 0.485 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 6 = 0.52 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 7 = 0.263 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 8 = 0.495 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 9 = 0.506 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 all KL = 0.535 +- 0.354 (in-sample avg dev_std = 0.412)
NEC for r=1.0 all L1 = 0.41 +- 0.287 (in-sample avg dev_std = 0.412)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 18:43:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:55 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:55 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:55 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:55 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 06:43:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9987
Train Loss: 0.0093
ID Validation ACCURACY: 0.9010
ID Validation Loss: 0.3953
ID Test ACCURACY: 0.8993
ID Test Loss: 0.4113
OOD Validation ACCURACY: 0.8810
OOD Validation Loss: 0.4983
OOD Test ACCURACY: 0.6443
OOD Test Loss: 1.7605

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9765
Train Loss: 0.0755
ID Validation ACCURACY: 0.8950
ID Validation Loss: 0.3475
ID Test ACCURACY: 0.8920
ID Test Loss: 0.3450
OOD Validation ACCURACY: 0.8911
OOD Validation Loss: 0.3769
OOD Test ACCURACY: 0.6546
OOD Test Loss: 1.4901

[0m[1;37mINFO[0m: [1mChartInfo 0.8993 0.6443 0.8920 0.6546 0.8950 0.8911[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
SUFF++ for r=0.3 class 0 = 0.545 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 1 = 0.545 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 2 = 0.526 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 3 = 0.537 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 4 = 0.514 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 5 = 0.498 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 6 = 0.515 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 7 = 0.531 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 8 = 0.498 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 class 9 = 0.53 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 all KL = 0.66 +- 0.164 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.108 (in-sample avg dev_std = 0.354)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
SUFF++ for r=0.6 class 0 = 0.53 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 1 = 0.523 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 2 = 0.484 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 3 = 0.52 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 4 = 0.434 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 5 = 0.496 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 6 = 0.509 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 7 = 0.476 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 8 = 0.507 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 class 9 = 0.48 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 all KL = 0.517 +- 0.296 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.6 all L1 = 0.496 +- 0.221 (in-sample avg dev_std = 0.191)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.769
SUFF++ for r=0.9 class 0 = 0.92 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 1 = 0.918 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 2 = 0.804 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 3 = 0.773 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 4 = 0.835 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 5 = 0.719 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 6 = 0.845 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 7 = 0.846 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 8 = 0.825 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 class 9 = 0.759 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all KL = 0.835 +- 0.245 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.215 (in-sample avg dev_std = 0.263)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.093
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
SUFF++ for r=0.3 class 0 = 0.545 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 1 = 0.541 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 2 = 0.522 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 3 = 0.495 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 4 = 0.512 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 5 = 0.526 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 6 = 0.51 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 7 = 0.53 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 8 = 0.523 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 class 9 = 0.502 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all KL = 0.655 +- 0.160 (in-sample avg dev_std = 0.350)
SUFF++ for r=0.3 all L1 = 0.521 +- 0.108 (in-sample avg dev_std = 0.350)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.194
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.177
SUFF++ for r=0.6 class 0 = 0.477 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 1 = 0.516 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 2 = 0.487 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 3 = 0.491 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 4 = 0.501 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 5 = 0.488 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 6 = 0.501 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 7 = 0.438 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 8 = 0.578 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 class 9 = 0.462 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all KL = 0.51 +- 0.298 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.6 all L1 = 0.494 +- 0.217 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.943 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 1 = 0.934 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 2 = 0.812 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 3 = 0.746 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 4 = 0.858 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 5 = 0.679 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 6 = 0.787 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 7 = 0.794 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 8 = 0.875 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 9 = 0.759 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all KL = 0.824 +- 0.255 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all L1 = 0.822 +- 0.217 (in-sample avg dev_std = 0.273)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.541 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 1 = 0.55 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 2 = 0.522 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 3 = 0.506 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 4 = 0.509 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 5 = 0.532 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 6 = 0.52 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 7 = 0.512 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 8 = 0.475 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 9 = 0.521 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all KL = 0.651 +- 0.161 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all L1 = 0.519 +- 0.107 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.153
SUFF++ for r=0.6 class 0 = 0.524 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 1 = 0.541 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 2 = 0.534 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 3 = 0.51 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 4 = 0.474 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 5 = 0.518 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 6 = 0.448 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 7 = 0.476 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 8 = 0.507 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 class 9 = 0.417 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all KL = 0.511 +- 0.296 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.6 all L1 = 0.495 +- 0.225 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.751
SUFF++ for r=0.9 class 0 = 0.929 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 1 = 0.96 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 2 = 0.782 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 3 = 0.782 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 4 = 0.838 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 5 = 0.745 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 6 = 0.805 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 7 = 0.848 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 8 = 0.796 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 9 = 0.735 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all KL = 0.835 +- 0.237 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all L1 = 0.824 +- 0.211 (in-sample avg dev_std = 0.251)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.086
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.556 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 1 = 0.56 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 2 = 0.543 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 3 = 0.508 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 4 = 0.539 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 5 = 0.524 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 6 = 0.52 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 7 = 0.543 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 8 = 0.528 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 class 9 = 0.511 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 all KL = 0.665 +- 0.168 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.3 all L1 = 0.534 +- 0.113 (in-sample avg dev_std = 0.378)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
SUFF++ for r=0.6 class 0 = 0.475 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 1 = 0.511 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 2 = 0.484 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 3 = 0.505 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 4 = 0.492 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 5 = 0.487 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 6 = 0.432 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 7 = 0.46 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 8 = 0.509 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 9 = 0.509 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all KL = 0.495 +- 0.301 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all L1 = 0.487 +- 0.220 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.524
SUFF++ for r=0.9 class 0 = 0.701 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 2 = 0.799 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 3 = 0.677 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 4 = 0.807 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 5 = 0.687 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 6 = 0.689 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 7 = 0.751 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 8 = 0.666 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 9 = 0.666 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all KL = 0.784 +- 0.234 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all L1 = 0.735 +- 0.219 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.089
NEC for r=0.3 class 0 = 0.452 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 1 = 0.426 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 2 = 0.468 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 3 = 0.424 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 4 = 0.466 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 5 = 0.459 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 6 = 0.462 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 7 = 0.462 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 8 = 0.464 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 9 = 0.495 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all KL = 0.318 +- 0.183 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all L1 = 0.457 +- 0.123 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
NEC for r=0.6 class 0 = 0.553 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 1 = 0.497 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 2 = 0.567 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 3 = 0.507 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 4 = 0.551 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 5 = 0.537 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 6 = 0.588 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 7 = 0.534 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 8 = 0.533 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 9 = 0.521 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all KL = 0.552 +- 0.250 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all L1 = 0.538 +- 0.177 (in-sample avg dev_std = 0.374)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.608
NEC for r=0.9 class 0 = 0.239 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 1 = 0.208 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 2 = 0.424 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 3 = 0.581 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 4 = 0.351 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 5 = 0.596 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 6 = 0.451 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 7 = 0.443 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 8 = 0.346 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 class 9 = 0.554 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all KL = 0.598 +- 0.337 (in-sample avg dev_std = 0.475)
NEC for r=0.9 all L1 = 0.416 +- 0.275 (in-sample avg dev_std = 0.475)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.952
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0 = 0.106 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 1 = 0.049 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 2 = 0.262 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 3 = 0.286 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 4 = 0.162 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 5 = 0.292 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 6 = 0.305 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 7 = 0.208 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 8 = 0.229 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 9 = 0.355 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 all KL = 0.392 +- 0.366 (in-sample avg dev_std = 0.409)
NEC for r=1.0 all L1 = 0.223 +- 0.249 (in-sample avg dev_std = 0.409)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.093
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.432 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 1 = 0.439 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 2 = 0.459 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 3 = 0.471 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 4 = 0.458 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 5 = 0.453 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 6 = 0.479 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 7 = 0.448 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 8 = 0.442 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 class 9 = 0.477 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all KL = 0.31 +- 0.174 (in-sample avg dev_std = 0.251)
NEC for r=0.3 all L1 = 0.456 +- 0.121 (in-sample avg dev_std = 0.251)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.194
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.184
NEC for r=0.6 class 0 = 0.571 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 1 = 0.5 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 2 = 0.515 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 3 = 0.549 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 4 = 0.531 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 5 = 0.542 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 6 = 0.532 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 7 = 0.569 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 8 = 0.493 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 9 = 0.539 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 all KL = 0.556 +- 0.248 (in-sample avg dev_std = 0.393)
NEC for r=0.6 all L1 = 0.534 +- 0.170 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.811
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.616
NEC for r=0.9 class 0 = 0.257 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 1 = 0.194 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 2 = 0.418 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 3 = 0.525 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 4 = 0.292 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 5 = 0.589 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 6 = 0.422 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 7 = 0.451 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 8 = 0.333 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 class 9 = 0.517 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 all KL = 0.575 +- 0.339 (in-sample avg dev_std = 0.469)
NEC for r=0.9 all L1 = 0.396 +- 0.272 (in-sample avg dev_std = 0.469)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.962
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.84
NEC for r=1.0 class 0 = 0.091 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 1 = 0.025 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 2 = 0.257 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 3 = 0.301 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 4 = 0.154 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 5 = 0.39 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 6 = 0.328 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 7 = 0.226 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 8 = 0.18 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 class 9 = 0.391 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all KL = 0.402 +- 0.374 (in-sample avg dev_std = 0.416)
NEC for r=1.0 all L1 = 0.229 +- 0.253 (in-sample avg dev_std = 0.416)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.086
NEC for r=0.3 class 0 = 0.448 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 1 = 0.44 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 2 = 0.448 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 3 = 0.438 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 4 = 0.452 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 5 = 0.454 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 6 = 0.464 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 7 = 0.441 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 8 = 0.461 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 class 9 = 0.456 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 all KL = 0.305 +- 0.167 (in-sample avg dev_std = 0.255)
NEC for r=0.3 all L1 = 0.45 +- 0.117 (in-sample avg dev_std = 0.255)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.162
NEC for r=0.6 class 0 = 0.517 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 1 = 0.455 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 2 = 0.498 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 3 = 0.513 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 4 = 0.535 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 5 = 0.509 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 6 = 0.571 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 7 = 0.543 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 8 = 0.467 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 9 = 0.563 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all KL = 0.527 +- 0.241 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all L1 = 0.517 +- 0.173 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.812
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.587
NEC for r=0.9 class 0 = 0.365 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 1 = 0.134 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 2 = 0.369 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 3 = 0.58 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 4 = 0.315 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 5 = 0.554 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 6 = 0.454 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 7 = 0.407 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 8 = 0.428 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 9 = 0.579 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all KL = 0.588 +- 0.345 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all L1 = 0.414 +- 0.276 (in-sample avg dev_std = 0.467)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.928
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0 = 0.115 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 1 = 0.027 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 2 = 0.298 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 3 = 0.35 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 4 = 0.228 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 5 = 0.326 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 6 = 0.31 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 7 = 0.196 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 8 = 0.312 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 9 = 0.388 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all KL = 0.402 +- 0.368 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all L1 = 0.252 +- 0.267 (in-sample avg dev_std = 0.414)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.086
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
NEC for r=0.3 class 0 = 0.402 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 1 = 0.44 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 2 = 0.41 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 3 = 0.429 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 4 = 0.472 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 5 = 0.411 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 6 = 0.425 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 7 = 0.45 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 8 = 0.422 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 class 9 = 0.43 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all KL = 0.275 +- 0.165 (in-sample avg dev_std = 0.245)
NEC for r=0.3 all L1 = 0.429 +- 0.124 (in-sample avg dev_std = 0.245)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.152
NEC for r=0.6 class 0 = 0.508 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 1 = 0.501 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 2 = 0.509 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 3 = 0.516 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 4 = 0.522 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 5 = 0.536 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 6 = 0.546 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 7 = 0.553 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 8 = 0.528 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 9 = 0.518 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all KL = 0.556 +- 0.239 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all L1 = 0.523 +- 0.160 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.387
NEC for r=0.9 class 0 = 0.616 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 1 = 0.281 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 2 = 0.34 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 3 = 0.589 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 4 = 0.346 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 5 = 0.573 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 6 = 0.584 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 7 = 0.539 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 8 = 0.595 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 class 9 = 0.573 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 all KL = 0.591 +- 0.328 (in-sample avg dev_std = 0.411)
NEC for r=0.9 all L1 = 0.5 +- 0.269 (in-sample avg dev_std = 0.411)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.663
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.567
NEC for r=1.0 class 0 = 0.603 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 1 = 0.172 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 2 = 0.307 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 3 = 0.472 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 4 = 0.356 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 5 = 0.538 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 6 = 0.507 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 7 = 0.388 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 8 = 0.584 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 class 9 = 0.526 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 all KL = 0.564 +- 0.335 (in-sample avg dev_std = 0.447)
NEC for r=1.0 all L1 = 0.441 +- 0.269 (in-sample avg dev_std = 0.447)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 19:08:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:08:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 169...
[0m[1;37mINFO[0m: [1mCheckpoint 169: 
-----------------------------------
Train ACCURACY: 0.9956
Train Loss: 0.0185
ID Validation ACCURACY: 0.9013
ID Validation Loss: 0.3966
ID Test ACCURACY: 0.8984
ID Test Loss: 0.3930
OOD Validation ACCURACY: 0.8676
OOD Validation Loss: 0.5263
OOD Test ACCURACY: 0.5251
OOD Test Loss: 3.6081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9882
Train Loss: 0.0423
ID Validation ACCURACY: 0.8970
ID Validation Loss: 0.3739
ID Test ACCURACY: 0.8970
ID Test Loss: 0.3832
OOD Validation ACCURACY: 0.8820
OOD Validation Loss: 0.4335
OOD Test ACCURACY: 0.6056
OOD Test Loss: 2.1596

[0m[1;37mINFO[0m: [1mChartInfo 0.8984 0.5251 0.8970 0.6056 0.8970 0.8820[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.537 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 1 = 0.559 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 2 = 0.522 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 3 = 0.525 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 4 = 0.516 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 5 = 0.523 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 6 = 0.526 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 7 = 0.535 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 8 = 0.513 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 class 9 = 0.537 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all KL = 0.686 +- 0.119 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.3 all L1 = 0.53 +- 0.091 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.139
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.117
SUFF++ for r=0.6 class 0 = 0.504 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 1 = 0.435 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 2 = 0.477 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 3 = 0.488 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 4 = 0.507 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 5 = 0.502 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 6 = 0.499 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 7 = 0.475 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 8 = 0.539 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 9 = 0.507 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all KL = 0.521 +- 0.303 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all L1 = 0.492 +- 0.225 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.799
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.759
SUFF++ for r=0.9 class 0 = 0.911 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.934 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.773 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 3 = 0.776 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 4 = 0.805 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 5 = 0.744 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 6 = 0.839 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 7 = 0.851 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 8 = 0.761 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 9 = 0.788 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.837 +- 0.229 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.82 +- 0.210 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.122
SUFF++ for r=0.3 class 0 = 0.539 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 1 = 0.53 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 2 = 0.517 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 3 = 0.53 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 4 = 0.504 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 5 = 0.533 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 6 = 0.513 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 7 = 0.537 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 8 = 0.532 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 9 = 0.517 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all KL = 0.682 +- 0.113 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all L1 = 0.525 +- 0.084 (in-sample avg dev_std = 0.342)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
SUFF++ for r=0.6 class 0 = 0.481 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 1 = 0.447 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 2 = 0.504 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 3 = 0.493 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 4 = 0.515 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 5 = 0.472 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 6 = 0.521 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 7 = 0.478 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 8 = 0.617 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 9 = 0.525 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all KL = 0.544 +- 0.299 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all L1 = 0.504 +- 0.223 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.769
SUFF++ for r=0.9 class 0 = 0.95 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 1 = 0.945 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 2 = 0.777 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 3 = 0.76 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 4 = 0.779 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 5 = 0.745 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 6 = 0.841 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 7 = 0.805 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 8 = 0.809 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 class 9 = 0.799 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all KL = 0.831 +- 0.238 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.206 (in-sample avg dev_std = 0.262)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
SUFF++ for r=0.3 class 0 = 0.544 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 1 = 0.551 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 2 = 0.546 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 3 = 0.548 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 4 = 0.54 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 5 = 0.532 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 6 = 0.532 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 7 = 0.535 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 8 = 0.53 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 9 = 0.543 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all KL = 0.71 +- 0.107 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all L1 = 0.54 +- 0.088 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.185
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.146
SUFF++ for r=0.6 class 0 = 0.55 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 1 = 0.437 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 2 = 0.573 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 3 = 0.545 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 4 = 0.518 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 5 = 0.52 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 6 = 0.492 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 7 = 0.492 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 8 = 0.571 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 class 9 = 0.49 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all KL = 0.53 +- 0.312 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.6 all L1 = 0.517 +- 0.241 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.785
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.735
SUFF++ for r=0.9 class 0 = 0.911 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.963 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.754 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 3 = 0.741 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 4 = 0.788 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 5 = 0.728 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 6 = 0.762 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 7 = 0.831 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 8 = 0.785 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 9 = 0.784 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.825 +- 0.243 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.215 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.132
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.117
SUFF++ for r=0.3 class 0 = 0.585 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 1 = 0.628 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 3 = 0.562 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 4 = 0.574 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 5 = 0.59 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 6 = 0.579 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 7 = 0.584 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 8 = 0.567 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 class 9 = 0.575 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 all KL = 0.763 +- 0.110 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.3 all L1 = 0.583 +- 0.098 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.164
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.149
SUFF++ for r=0.6 class 0 = 0.69 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 1 = 0.555 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 3 = 0.608 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 4 = 0.576 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 5 = 0.6 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 6 = 0.544 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 7 = 0.584 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 8 = 0.513 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 class 9 = 0.467 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 all KL = 0.6 +- 0.316 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.6 all L1 = 0.582 +- 0.256 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.476
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.437
SUFF++ for r=0.9 class 0 = 0.715 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 1 = 0.924 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 2 = 0.779 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 3 = 0.636 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 4 = 0.781 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 5 = 0.71 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 6 = 0.682 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 7 = 0.718 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 8 = 0.713 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 class 9 = 0.69 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 all KL = 0.787 +- 0.237 (in-sample avg dev_std = 0.293)
SUFF++ for r=0.9 all L1 = 0.738 +- 0.215 (in-sample avg dev_std = 0.293)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
NEC for r=0.3 class 0 = 0.422 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1 = 0.393 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 2 = 0.431 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 3 = 0.422 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 4 = 0.423 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 5 = 0.428 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 6 = 0.435 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 7 = 0.406 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 8 = 0.435 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 9 = 0.43 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.261 +- 0.160 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.422 +- 0.124 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.139
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.116
NEC for r=0.6 class 0 = 0.526 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 1 = 0.524 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 2 = 0.549 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 3 = 0.541 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 4 = 0.531 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 5 = 0.516 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 6 = 0.511 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 7 = 0.514 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 8 = 0.475 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 class 9 = 0.518 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 all KL = 0.525 +- 0.229 (in-sample avg dev_std = 0.391)
NEC for r=0.6 all L1 = 0.521 +- 0.168 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.799
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.607
NEC for r=0.9 class 0 = 0.228 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 1 = 0.198 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 2 = 0.451 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 3 = 0.629 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 4 = 0.417 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 5 = 0.558 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 6 = 0.429 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 7 = 0.389 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 8 = 0.453 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 9 = 0.441 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 all KL = 0.584 +- 0.326 (in-sample avg dev_std = 0.466)
NEC for r=0.9 all L1 = 0.416 +- 0.270 (in-sample avg dev_std = 0.466)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.952
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.842
NEC for r=1.0 class 0 = 0.064 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 1 = 0.03 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 2 = 0.276 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 3 = 0.367 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 4 = 0.241 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 5 = 0.281 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 6 = 0.279 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 7 = 0.186 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 8 = 0.284 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 class 9 = 0.286 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all KL = 0.376 +- 0.362 (in-sample avg dev_std = 0.399)
NEC for r=1.0 all L1 = 0.226 +- 0.252 (in-sample avg dev_std = 0.399)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.117
NEC for r=0.3 class 0 = 0.416 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 1 = 0.424 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 2 = 0.429 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 3 = 0.435 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 4 = 0.442 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 5 = 0.418 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 6 = 0.443 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 7 = 0.412 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 8 = 0.438 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 class 9 = 0.429 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all KL = 0.268 +- 0.161 (in-sample avg dev_std = 0.224)
NEC for r=0.3 all L1 = 0.429 +- 0.120 (in-sample avg dev_std = 0.224)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.15
NEC for r=0.6 class 0 = 0.562 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 1 = 0.544 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 2 = 0.503 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 3 = 0.542 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 4 = 0.493 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 5 = 0.538 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 6 = 0.46 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 7 = 0.501 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 8 = 0.475 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 9 = 0.494 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all KL = 0.515 +- 0.239 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all L1 = 0.512 +- 0.170 (in-sample avg dev_std = 0.388)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.251 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 1 = 0.187 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 2 = 0.429 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 3 = 0.573 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 4 = 0.406 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 5 = 0.548 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 6 = 0.378 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 7 = 0.413 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 8 = 0.439 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 class 9 = 0.426 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 all KL = 0.567 +- 0.328 (in-sample avg dev_std = 0.473)
NEC for r=0.9 all L1 = 0.401 +- 0.263 (in-sample avg dev_std = 0.473)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.843
NEC for r=1.0 class 0 = 0.057 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 1 = 0.022 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 2 = 0.276 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 3 = 0.342 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 4 = 0.22 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 5 = 0.343 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 6 = 0.295 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 7 = 0.198 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 8 = 0.225 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 class 9 = 0.299 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all KL = 0.379 +- 0.357 (in-sample avg dev_std = 0.400)
NEC for r=1.0 all L1 = 0.223 +- 0.245 (in-sample avg dev_std = 0.400)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
NEC for r=0.3 class 0 = 0.405 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 1 = 0.428 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 2 = 0.409 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 3 = 0.384 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 4 = 0.413 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 5 = 0.385 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 6 = 0.443 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 7 = 0.393 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 8 = 0.43 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 class 9 = 0.437 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all KL = 0.247 +- 0.152 (in-sample avg dev_std = 0.216)
NEC for r=0.3 all L1 = 0.413 +- 0.121 (in-sample avg dev_std = 0.216)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.185
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.127
NEC for r=0.6 class 0 = 0.499 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 1 = 0.515 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 2 = 0.465 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 3 = 0.482 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 4 = 0.48 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 5 = 0.499 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 6 = 0.51 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 7 = 0.478 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 8 = 0.493 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 class 9 = 0.508 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 all KL = 0.51 +- 0.246 (in-sample avg dev_std = 0.404)
NEC for r=0.6 all L1 = 0.493 +- 0.183 (in-sample avg dev_std = 0.404)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.785
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0 = 0.412 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 1 = 0.116 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 2 = 0.389 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 3 = 0.634 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 4 = 0.406 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 5 = 0.53 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 6 = 0.489 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 7 = 0.411 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 8 = 0.516 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 class 9 = 0.454 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 all KL = 0.588 +- 0.334 (in-sample avg dev_std = 0.465)
NEC for r=0.9 all L1 = 0.43 +- 0.271 (in-sample avg dev_std = 0.465)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.91
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.782
NEC for r=1.0 class 0 = 0.086 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 1 = 0.021 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 2 = 0.305 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 3 = 0.444 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 4 = 0.282 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 5 = 0.302 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 6 = 0.336 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 7 = 0.186 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 8 = 0.334 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 class 9 = 0.367 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all KL = 0.403 +- 0.356 (in-sample avg dev_std = 0.418)
NEC for r=1.0 all L1 = 0.263 +- 0.260 (in-sample avg dev_std = 0.418)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.132
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.347 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 1 = 0.338 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 2 = 0.366 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 3 = 0.383 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 4 = 0.401 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 5 = 0.346 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 6 = 0.397 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 7 = 0.358 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 8 = 0.39 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 class 9 = 0.424 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all KL = 0.2 +- 0.137 (in-sample avg dev_std = 0.182)
NEC for r=0.3 all L1 = 0.375 +- 0.124 (in-sample avg dev_std = 0.182)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.164
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
NEC for r=0.6 class 0 = 0.284 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 1 = 0.456 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 2 = 0.347 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 3 = 0.417 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 4 = 0.465 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 5 = 0.427 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 6 = 0.46 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 7 = 0.451 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 8 = 0.519 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 class 9 = 0.508 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all KL = 0.442 +- 0.260 (in-sample avg dev_std = 0.351)
NEC for r=0.6 all L1 = 0.433 +- 0.222 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.476
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.343
NEC for r=0.9 class 0 = 0.534 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 1 = 0.249 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 2 = 0.344 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 3 = 0.581 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 4 = 0.411 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 5 = 0.527 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 6 = 0.58 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 7 = 0.557 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 8 = 0.542 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 class 9 = 0.562 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 all KL = 0.558 +- 0.324 (in-sample avg dev_std = 0.383)
NEC for r=0.9 all L1 = 0.484 +- 0.268 (in-sample avg dev_std = 0.383)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.525
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.451
NEC for r=1.0 class 0 = 0.592 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 1 = 0.058 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 2 = 0.346 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 3 = 0.597 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 4 = 0.472 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 5 = 0.481 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 6 = 0.589 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 7 = 0.433 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 8 = 0.581 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 class 9 = 0.543 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 all KL = 0.577 +- 0.355 (in-sample avg dev_std = 0.408)
NEC for r=1.0 all L1 = 0.463 +- 0.292 (in-sample avg dev_std = 0.408)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 19:32:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:32:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 177...
[0m[1;37mINFO[0m: [1mCheckpoint 177: 
-----------------------------------
Train ACCURACY: 0.9971
Train Loss: 0.0157
ID Validation ACCURACY: 0.9033
ID Validation Loss: 0.3799
ID Test ACCURACY: 0.9001
ID Test Loss: 0.3824
OOD Validation ACCURACY: 0.8810
OOD Validation Loss: 0.4746
OOD Test ACCURACY: 0.6271
OOD Test Loss: 2.2334

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.9735
Train Loss: 0.0844
ID Validation ACCURACY: 0.8960
ID Validation Loss: 0.3366
ID Test ACCURACY: 0.8973
ID Test Loss: 0.3361
OOD Validation ACCURACY: 0.8916
OOD Validation Loss: 0.3805
OOD Test ACCURACY: 0.7356
OOD Test Loss: 1.0282

[0m[1;37mINFO[0m: [1mChartInfo 0.9001 0.6271 0.8973 0.7356 0.8960 0.8916[0mGOODCMNIST(42000)
Data example from train: Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
Label distribution from train: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([4156, 4700, 4167, 4257, 4108, 3835, 4128, 4339, 4085, 4225]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from val: Data(x=[75, 3], edge_index=[2, 1422], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1422], node_perm=[75])
Label distribution from val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([670, 794, 681, 716, 699, 616, 708, 732, 655, 729]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.758 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 1 = 0.783 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 2 = 0.747 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 3 = 0.75 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 4 = 0.758 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 5 = 0.719 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 6 = 0.741 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 7 = 0.755 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 8 = 0.73 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 class 9 = 0.728 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 all KL = 0.876 +- 0.103 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.3 all L1 = 0.748 +- 0.119 (in-sample avg dev_std = 0.148)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.146
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
SUFF++ for r=0.6 class 0 = 0.591 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 1 = 0.542 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 2 = 0.527 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 3 = 0.55 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 4 = 0.521 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 5 = 0.554 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 6 = 0.604 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 7 = 0.584 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 8 = 0.554 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 9 = 0.599 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all KL = 0.619 +- 0.282 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all L1 = 0.563 +- 0.227 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.815 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.932 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.823 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 3 = 0.753 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 4 = 0.792 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 5 = 0.75 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 6 = 0.84 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 7 = 0.847 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 8 = 0.785 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 9 = 0.77 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.823 +- 0.248 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.813 +- 0.214 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.09
SUFF++ for r=0.3 class 0 = 0.76 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 1 = 0.769 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 2 = 0.729 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 3 = 0.739 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 4 = 0.724 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 5 = 0.753 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 6 = 0.73 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 7 = 0.763 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 8 = 0.743 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 9 = 0.745 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 all KL = 0.871 +- 0.109 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 all L1 = 0.746 +- 0.118 (in-sample avg dev_std = 0.156)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
SUFF++ for r=0.6 class 0 = 0.605 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 1 = 0.615 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 2 = 0.53 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 3 = 0.55 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 4 = 0.553 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 5 = 0.556 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 6 = 0.599 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 7 = 0.567 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 8 = 0.579 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 class 9 = 0.497 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all KL = 0.621 +- 0.289 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.6 all L1 = 0.566 +- 0.233 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.788
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.75
SUFF++ for r=0.9 class 0 = 0.858 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 1 = 0.958 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 2 = 0.813 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 3 = 0.756 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 4 = 0.832 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 5 = 0.706 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 6 = 0.801 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 7 = 0.834 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 8 = 0.82 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 class 9 = 0.735 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all KL = 0.83 +- 0.236 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.209 (in-sample avg dev_std = 0.260)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.75 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 1 = 0.776 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 2 = 0.747 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 3 = 0.765 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 4 = 0.762 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 5 = 0.751 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 6 = 0.719 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 7 = 0.731 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 8 = 0.74 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 class 9 = 0.706 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 all KL = 0.88 +- 0.092 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.3 all L1 = 0.745 +- 0.113 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.124
SUFF++ for r=0.6 class 0 = 0.56 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 1 = 0.642 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 2 = 0.559 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 3 = 0.563 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 4 = 0.526 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 5 = 0.491 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 6 = 0.534 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 7 = 0.57 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 8 = 0.513 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 9 = 0.476 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 all KL = 0.593 +- 0.300 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 all L1 = 0.545 +- 0.242 (in-sample avg dev_std = 0.170)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.74
SUFF++ for r=0.9 class 0 = 0.781 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 1 = 0.966 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 2 = 0.779 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 3 = 0.772 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 4 = 0.78 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 5 = 0.709 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 6 = 0.811 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 7 = 0.88 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 8 = 0.794 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 9 = 0.765 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all KL = 0.827 +- 0.240 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all L1 = 0.808 +- 0.214 (in-sample avg dev_std = 0.270)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.756 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 1 = 0.766 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 2 = 0.737 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 3 = 0.738 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 4 = 0.749 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 5 = 0.756 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 6 = 0.744 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 7 = 0.747 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 8 = 0.732 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 class 9 = 0.743 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 all KL = 0.883 +- 0.099 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.3 all L1 = 0.747 +- 0.111 (in-sample avg dev_std = 0.155)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.123
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
SUFF++ for r=0.6 class 0 = 0.678 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 1 = 0.822 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 2 = 0.738 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 3 = 0.66 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 4 = 0.64 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 5 = 0.73 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 6 = 0.609 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 7 = 0.737 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 8 = 0.611 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 class 9 = 0.533 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 all KL = 0.705 +- 0.307 (in-sample avg dev_std = 0.157)
SUFF++ for r=0.6 all L1 = 0.678 +- 0.270 (in-sample avg dev_std = 0.157)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.553
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.507
SUFF++ for r=0.9 class 0 = 0.7 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 1 = 0.943 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 2 = 0.791 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 3 = 0.702 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 4 = 0.689 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 5 = 0.686 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 6 = 0.772 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 7 = 0.825 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 8 = 0.651 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 9 = 0.718 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 all KL = 0.794 +- 0.238 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 all L1 = 0.751 +- 0.218 (in-sample avg dev_std = 0.287)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
NEC for r=0.3 class 0 = 0.301 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 1 = 0.252 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 2 = 0.284 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 3 = 0.278 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 4 = 0.271 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 5 = 0.29 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 6 = 0.266 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 7 = 0.286 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 8 = 0.289 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 9 = 0.318 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all KL = 0.148 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all L1 = 0.283 +- 0.124 (in-sample avg dev_std = 0.163)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.146
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.124
NEC for r=0.6 class 0 = 0.473 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 1 = 0.431 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 2 = 0.496 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 3 = 0.496 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 4 = 0.517 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 5 = 0.491 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 6 = 0.426 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 7 = 0.44 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 8 = 0.487 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 class 9 = 0.46 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 all KL = 0.443 +- 0.243 (in-sample avg dev_std = 0.344)
NEC for r=0.6 all L1 = 0.471 +- 0.188 (in-sample avg dev_std = 0.344)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.597
NEC for r=0.9 class 0 = 0.543 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 1 = 0.187 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 2 = 0.396 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 3 = 0.546 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 4 = 0.372 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 5 = 0.587 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 6 = 0.408 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 7 = 0.356 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 8 = 0.421 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 9 = 0.544 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all KL = 0.595 +- 0.326 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all L1 = 0.432 +- 0.263 (in-sample avg dev_std = 0.467)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.827
NEC for r=1.0 class 0 = 0.248 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 1 = 0.026 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 2 = 0.262 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 3 = 0.36 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 4 = 0.167 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 5 = 0.321 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 6 = 0.249 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 7 = 0.181 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 8 = 0.25 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 class 9 = 0.365 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 all KL = 0.412 +- 0.361 (in-sample avg dev_std = 0.409)
NEC for r=1.0 all L1 = 0.24 +- 0.249 (in-sample avg dev_std = 0.409)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
NEC for r=0.3 class 0 = 0.259 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 1 = 0.282 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 2 = 0.308 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 3 = 0.294 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 4 = 0.285 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 5 = 0.277 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 6 = 0.314 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 7 = 0.283 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 8 = 0.311 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 class 9 = 0.279 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 all KL = 0.157 +- 0.132 (in-sample avg dev_std = 0.167)
NEC for r=0.3 all L1 = 0.289 +- 0.129 (in-sample avg dev_std = 0.167)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
NEC for r=0.6 class 0 = 0.457 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 1 = 0.389 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 2 = 0.499 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 3 = 0.495 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 4 = 0.497 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 5 = 0.419 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 6 = 0.378 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 7 = 0.461 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 8 = 0.482 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 class 9 = 0.511 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all KL = 0.432 +- 0.251 (in-sample avg dev_std = 0.349)
NEC for r=0.6 all L1 = 0.459 +- 0.195 (in-sample avg dev_std = 0.349)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.788
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.59
NEC for r=0.9 class 0 = 0.505 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 1 = 0.157 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 2 = 0.369 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 3 = 0.533 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 4 = 0.346 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 5 = 0.613 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 6 = 0.386 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 7 = 0.384 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 8 = 0.397 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 9 = 0.55 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all KL = 0.578 +- 0.330 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all L1 = 0.418 +- 0.269 (in-sample avg dev_std = 0.463)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.955
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.829
NEC for r=1.0 class 0 = 0.197 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 1 = 0.011 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 2 = 0.254 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 3 = 0.365 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 4 = 0.149 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 5 = 0.392 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 6 = 0.26 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 7 = 0.2 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 8 = 0.203 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 9 = 0.407 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all KL = 0.401 +- 0.363 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all L1 = 0.239 +- 0.256 (in-sample avg dev_std = 0.410)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.267 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 1 = 0.263 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 2 = 0.292 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 3 = 0.269 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 4 = 0.274 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 5 = 0.301 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 6 = 0.32 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 7 = 0.295 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 8 = 0.295 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 9 = 0.323 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all KL = 0.153 +- 0.128 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all L1 = 0.29 +- 0.127 (in-sample avg dev_std = 0.169)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
NEC for r=0.6 class 0 = 0.499 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 1 = 0.333 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 2 = 0.485 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 3 = 0.489 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 4 = 0.508 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 5 = 0.509 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 6 = 0.489 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 7 = 0.431 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 8 = 0.551 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 9 = 0.521 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all KL = 0.455 +- 0.252 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all L1 = 0.479 +- 0.204 (in-sample avg dev_std = 0.354)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.576
NEC for r=0.9 class 0 = 0.605 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.094 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.402 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 3 = 0.56 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 4 = 0.447 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 5 = 0.575 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 6 = 0.425 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 7 = 0.286 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 8 = 0.443 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 9 = 0.526 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.579 +- 0.331 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.429 +- 0.271 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.941
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.798
NEC for r=1.0 class 0 = 0.296 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 1 = 0.029 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 2 = 0.295 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 3 = 0.414 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 4 = 0.282 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 5 = 0.351 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 6 = 0.282 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 7 = 0.139 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 8 = 0.267 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 9 = 0.355 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all KL = 0.421 +- 0.365 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all L1 = 0.266 +- 0.262 (in-sample avg dev_std = 0.417)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
NEC for r=0.3 class 0 = 0.273 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 1 = 0.289 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 2 = 0.293 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 3 = 0.296 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 4 = 0.275 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 5 = 0.248 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 6 = 0.305 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 7 = 0.279 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 8 = 0.31 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 class 9 = 0.31 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all KL = 0.149 +- 0.126 (in-sample avg dev_std = 0.169)
NEC for r=0.3 all L1 = 0.288 +- 0.121 (in-sample avg dev_std = 0.169)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.123
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
NEC for r=0.6 class 0 = 0.333 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 1 = 0.156 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 2 = 0.275 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 3 = 0.384 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 4 = 0.378 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 5 = 0.302 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 6 = 0.426 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 7 = 0.246 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 8 = 0.428 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 9 = 0.439 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all KL = 0.314 +- 0.283 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all L1 = 0.334 +- 0.253 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.553
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.389
NEC for r=0.9 class 0 = 0.57 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 1 = 0.106 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 2 = 0.408 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 3 = 0.553 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 4 = 0.513 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 5 = 0.568 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 6 = 0.505 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 7 = 0.329 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 8 = 0.608 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 class 9 = 0.561 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 all KL = 0.556 +- 0.331 (in-sample avg dev_std = 0.401)
NEC for r=0.9 all L1 = 0.466 +- 0.275 (in-sample avg dev_std = 0.401)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.639
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.543
NEC for r=1.0 class 0 = 0.643 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 1 = 0.032 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 2 = 0.381 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 3 = 0.575 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 4 = 0.517 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 5 = 0.503 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 6 = 0.365 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 7 = 0.311 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 8 = 0.602 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 class 9 = 0.5 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 all KL = 0.561 +- 0.358 (in-sample avg dev_std = 0.423)
NEC for r=1.0 all L1 = 0.438 +- 0.291 (in-sample avg dev_std = 0.423)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.537, 0.569, 0.838, 1.0], 'all_L1': [0.471, 0.499, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.667, 0.561, 0.847, 1.0], 'all_L1': [0.517, 0.501, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.66, 0.517, 0.835, 1.0], 'all_L1': [0.524, 0.496, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.686, 0.521, 0.837, 1.0], 'all_L1': [0.53, 0.492, 0.82, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.876, 0.619, 0.823, 1.0], 'all_L1': [0.748, 0.563, 0.813, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.245, 0.448, 0.57, 0.389], 'all_L1': [0.412, 0.507, 0.425, 0.234]}), defaultdict(<class 'list'>, {'all_KL': [0.19, 0.473, 0.557, 0.392], 'all_L1': [0.386, 0.519, 0.4, 0.23]}), defaultdict(<class 'list'>, {'all_KL': [0.318, 0.552, 0.598, 0.392], 'all_L1': [0.457, 0.538, 0.416, 0.223]}), defaultdict(<class 'list'>, {'all_KL': [0.261, 0.525, 0.584, 0.376], 'all_L1': [0.422, 0.521, 0.416, 0.226]}), defaultdict(<class 'list'>, {'all_KL': [0.148, 0.443, 0.595, 0.412], 'all_L1': [0.283, 0.471, 0.432, 0.24]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.532, 0.575, 0.83, 1.0], 'all_L1': [0.465, 0.51, 0.812, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.659, 0.561, 0.83, 1.0], 'all_L1': [0.512, 0.502, 0.818, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.655, 0.51, 0.824, 1.0], 'all_L1': [0.521, 0.494, 0.822, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.682, 0.544, 0.831, 1.0], 'all_L1': [0.525, 0.504, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.871, 0.621, 0.83, 1.0], 'all_L1': [0.746, 0.566, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.241, 0.455, 0.576, 0.394], 'all_L1': [0.41, 0.506, 0.426, 0.237]}), defaultdict(<class 'list'>, {'all_KL': [0.189, 0.472, 0.546, 0.383], 'all_L1': [0.384, 0.516, 0.393, 0.222]}), defaultdict(<class 'list'>, {'all_KL': [0.31, 0.556, 0.575, 0.402], 'all_L1': [0.456, 0.534, 0.396, 0.229]}), defaultdict(<class 'list'>, {'all_KL': [0.268, 0.515, 0.567, 0.379], 'all_L1': [0.429, 0.512, 0.401, 0.223]}), defaultdict(<class 'list'>, {'all_KL': [0.157, 0.432, 0.578, 0.401], 'all_L1': [0.289, 0.459, 0.418, 0.239]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.542, 0.557, 0.838, 1.0], 'all_L1': [0.47, 0.501, 0.817, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.673, 0.565, 0.835, 1.0], 'all_L1': [0.524, 0.504, 0.822, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.651, 0.511, 0.835, 1.0], 'all_L1': [0.519, 0.495, 0.824, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.71, 0.53, 0.825, 1.0], 'all_L1': [0.54, 0.517, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.88, 0.593, 0.827, 1.0], 'all_L1': [0.745, 0.545, 0.808, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.245, 0.451, 0.594, 0.403], 'all_L1': [0.413, 0.495, 0.439, 0.262]}), defaultdict(<class 'list'>, {'all_KL': [0.182, 0.452, 0.561, 0.385], 'all_L1': [0.375, 0.501, 0.401, 0.243]}), defaultdict(<class 'list'>, {'all_KL': [0.305, 0.527, 0.588, 0.402], 'all_L1': [0.45, 0.517, 0.414, 0.252]}), defaultdict(<class 'list'>, {'all_KL': [0.247, 0.51, 0.588, 0.403], 'all_L1': [0.413, 0.493, 0.43, 0.263]}), defaultdict(<class 'list'>, {'all_KL': [0.153, 0.455, 0.579, 0.421], 'all_L1': [0.29, 0.479, 0.429, 0.266]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.541, 0.609, 0.806, 1.0], 'all_L1': [0.467, 0.543, 0.767, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.683, 0.598, 0.807, 1.0], 'all_L1': [0.526, 0.516, 0.763, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.665, 0.495, 0.784, 1.0], 'all_L1': [0.534, 0.487, 0.735, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.763, 0.6, 0.787, 1.0], 'all_L1': [0.583, 0.582, 0.738, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.883, 0.705, 0.794, 1.0], 'all_L1': [0.747, 0.678, 0.751, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.262, 0.417, 0.588, 0.513], 'all_L1': [0.422, 0.467, 0.486, 0.396]}), defaultdict(<class 'list'>, {'all_KL': [0.181, 0.424, 0.576, 0.535], 'all_L1': [0.378, 0.498, 0.474, 0.41]}), defaultdict(<class 'list'>, {'all_KL': [0.275, 0.556, 0.591, 0.564], 'all_L1': [0.429, 0.523, 0.5, 0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.2, 0.442, 0.558, 0.577], 'all_L1': [0.375, 0.433, 0.484, 0.463]}), defaultdict(<class 'list'>, {'all_KL': [0.149, 0.314, 0.556, 0.561], 'all_L1': [0.288, 0.334, 0.466, 0.438]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.558 +- 0.097, 0.510 +- 0.027, 0.819 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.685 +- 0.109, 0.557 +- 0.037, 0.836 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.095 +- 0.007, 0.139 +- 0.014, 0.761 +- 0.004
nec class all_L1  =  0.392 +- 0.059, 0.511 +- 0.022, 0.418 +- 0.011, 0.231 +- 0.006
nec class all_KL  =  0.232 +- 0.059, 0.488 +- 0.043, 0.581 +- 0.015, 0.392 +- 0.012
nec_acc_int  =  0.091 +- 0.006, 0.140 +- 0.017, 0.607 +- 0.011, 0.834 +- 0.005

Eval split id_val
suff++ class all_L1  =  0.554 +- 0.098, 0.515 +- 0.026, 0.818 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.680 +- 0.109, 0.562 +- 0.037, 0.829 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.096 +- 0.013, 0.161 +- 0.008, 0.763 +- 0.011
nec class all_L1  =  0.394 +- 0.057, 0.505 +- 0.025, 0.407 +- 0.013, 0.230 +- 0.007
nec class all_KL  =  0.233 +- 0.055, 0.486 +- 0.044, 0.568 +- 0.012, 0.392 +- 0.009
nec_acc_int  =  0.096 +- 0.011, 0.165 +- 0.017, 0.610 +- 0.019, 0.835 +- 0.006

Eval split val
suff++ class all_L1  =  0.560 +- 0.096, 0.512 +- 0.018, 0.816 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.691 +- 0.110, 0.551 +- 0.028, 0.832 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.101 +- 0.005, 0.137 +- 0.013, 0.744 +- 0.006
nec class all_L1  =  0.388 +- 0.055, 0.497 +- 0.012, 0.423 +- 0.013, 0.257 +- 0.009
nec class all_KL  =  0.226 +- 0.053, 0.479 +- 0.033, 0.582 +- 0.012, 0.403 +- 0.011
nec_acc_int  =  0.092 +- 0.003, 0.140 +- 0.017, 0.586 +- 0.013, 0.798 +- 0.009

Eval split test
suff++ class all_L1  =  0.571 +- 0.095, 0.561 +- 0.066, 0.751 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.707 +- 0.113, 0.601 +- 0.067, 0.796 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.103 +- 0.008, 0.139 +- 0.010, 0.538 +- 0.066
nec class all_L1  =  0.378 +- 0.050, 0.451 +- 0.066, 0.482 +- 0.012, 0.430 +- 0.024
nec class all_KL  =  0.213 +- 0.048, 0.431 +- 0.077, 0.574 +- 0.015, 0.550 +- 0.023
nec_acc_int  =  0.097 +- 0.010, 0.140 +- 0.011, 0.410 +- 0.049, 0.563 +- 0.065


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.475 +- 0.027, 0.511 +- 0.006, 0.619 +- 0.003, 0.615 +- 0.003
Faith. Armon (L1)= 		  =  0.450 +- 0.027, 0.510 +- 0.005, 0.553 +- 0.008, 0.375 +- 0.008
Faith. GMean (L1)= 	  =  0.462 +- 0.018, 0.510 +- 0.005, 0.585 +- 0.006, 0.480 +- 0.006
Faith. Aritm (KL)= 		  =  0.459 +- 0.044, 0.523 +- 0.009, 0.708 +- 0.005, 0.696 +- 0.006
Faith. Armon (KL)= 		  =  0.339 +- 0.061, 0.518 +- 0.011, 0.685 +- 0.009, 0.563 +- 0.012
Faith. GMean (KL)= 	  =  0.392 +- 0.041, 0.520 +- 0.010, 0.697 +- 0.007, 0.626 +- 0.009

Eval split id_val
Faith. Aritm (L1)= 		  =  0.474 +- 0.029, 0.510 +- 0.002, 0.612 +- 0.005, 0.615 +- 0.003
Faith. Armon (L1)= 		  =  0.450 +- 0.026, 0.509 +- 0.002, 0.543 +- 0.011, 0.374 +- 0.009
Faith. GMean (L1)= 	  =  0.461 +- 0.019, 0.510 +- 0.002, 0.577 +- 0.008, 0.480 +- 0.007
Faith. Aritm (KL)= 		  =  0.456 +- 0.045, 0.524 +- 0.007, 0.699 +- 0.006, 0.696 +- 0.005
Faith. Armon (KL)= 		  =  0.339 +- 0.057, 0.518 +- 0.010, 0.674 +- 0.008, 0.563 +- 0.010
Faith. GMean (KL)= 	  =  0.392 +- 0.040, 0.521 +- 0.008, 0.686 +- 0.007, 0.626 +- 0.007

Eval split val
Faith. Aritm (L1)= 		  =  0.474 +- 0.027, 0.505 +- 0.005, 0.619 +- 0.005, 0.629 +- 0.004
Faith. Armon (L1)= 		  =  0.449 +- 0.023, 0.504 +- 0.004, 0.557 +- 0.011, 0.409 +- 0.011
Faith. GMean (L1)= 	  =  0.461 +- 0.017, 0.504 +- 0.004, 0.587 +- 0.008, 0.507 +- 0.008
Faith. Aritm (KL)= 		  =  0.459 +- 0.043, 0.515 +- 0.008, 0.707 +- 0.006, 0.701 +- 0.006
Faith. Armon (KL)= 		  =  0.333 +- 0.055, 0.511 +- 0.009, 0.685 +- 0.008, 0.574 +- 0.012
Faith. GMean (KL)= 	  =  0.389 +- 0.037, 0.513 +- 0.008, 0.696 +- 0.007, 0.635 +- 0.009

Eval split test
Faith. Aritm (L1)= 		  =  0.475 +- 0.026, 0.506 +- 0.001, 0.616 +- 0.006, 0.715 +- 0.012
Faith. Armon (L1)= 		  =  0.446 +- 0.020, 0.491 +- 0.022, 0.587 +- 0.008, 0.601 +- 0.023
Faith. GMean (L1)= 	  =  0.460 +- 0.013, 0.499 +- 0.011, 0.601 +- 0.007, 0.655 +- 0.018
Faith. Aritm (KL)= 		  =  0.460 +- 0.040, 0.516 +- 0.006, 0.685 +- 0.009, 0.775 +- 0.011
Faith. Armon (KL)= 		  =  0.320 +- 0.047, 0.492 +- 0.030, 0.667 +- 0.011, 0.709 +- 0.019
Faith. GMean (KL)= 	  =  0.382 +- 0.026, 0.504 +- 0.018, 0.676 +- 0.010, 0.741 +- 0.016
Computed for split load_split = id



Completed in  2:00:21.066213  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 19:57:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 07:57:09 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 07:57:39 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 07:57:49 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 07:57:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:15 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 07:58:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ROC-AUC: 0.9389
Train Loss: 0.1959
ID Validation ROC-AUC: 0.9165
ID Validation Loss: 0.2359
ID Test ROC-AUC: 0.9179
ID Test Loss: 0.2384
OOD Validation ROC-AUC: 0.6619
OOD Validation Loss: 0.4043
OOD Test ROC-AUC: 0.7147
OOD Test Loss: 0.5509

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 23...
[0m[1;37mINFO[0m: [1mCheckpoint 23: 
-----------------------------------
Train ROC-AUC: 0.8751
Train Loss: 0.3409
ID Validation ROC-AUC: 0.8700
ID Validation Loss: 0.3462
ID Test ROC-AUC: 0.8715
ID Test Loss: 0.3524
OOD Validation ROC-AUC: 0.6889
OOD Validation Loss: 0.3356
OOD Test ROC-AUC: 0.7148
OOD Test Loss: 0.5877

[0m[1;37mINFO[0m: [1mChartInfo 0.9179 0.7147 0.8715 0.7148 0.8700 0.6889[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 07:58:32 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 07:58:37 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 07:58:41 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 07:58:45 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 778
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.666
SUFF++ for r=0.3 class 0.0 = 0.897 +- 0.070 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.3 class 1.0 = 0.955 +- 0.070 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.3 all KL = 0.964 +- 0.070 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.3 all L1 = 0.949 +- 0.075 (in-sample avg dev_std = 0.113)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.768
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.745
SUFF++ for r=0.6 class 0.0 = 0.938 +- 0.047 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 class 1.0 = 0.987 +- 0.047 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 all KL = 0.99 +- 0.047 (in-sample avg dev_std = 0.046)
SUFF++ for r=0.6 all L1 = 0.982 +- 0.055 (in-sample avg dev_std = 0.046)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.806
SUFF++ for r=0.9 class 0.0 = 0.972 +- 0.009 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 class 1.0 = 0.997 +- 0.009 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 all KL = 0.998 +- 0.009 (in-sample avg dev_std = 0.032)
SUFF++ for r=0.9 all L1 = 0.994 +- 0.024 (in-sample avg dev_std = 0.032)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.735
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 789
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.673
SUFF++ for r=0.3 class 0.0 = 0.874 +- 0.076 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.3 class 1.0 = 0.953 +- 0.076 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.3 all KL = 0.959 +- 0.076 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.3 all L1 = 0.944 +- 0.080 (in-sample avg dev_std = 0.127)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.781
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.774
SUFF++ for r=0.6 class 0.0 = 0.937 +- 0.045 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.6 class 1.0 = 0.989 +- 0.045 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.6 all KL = 0.991 +- 0.045 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.6 all L1 = 0.983 +- 0.055 (in-sample avg dev_std = 0.053)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.798
SUFF++ for r=0.9 class 0.0 = 0.982 +- 0.008 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.9 class 1.0 = 0.997 +- 0.008 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.9 all KL = 0.999 +- 0.008 (in-sample avg dev_std = 0.030)
SUFF++ for r=0.9 all L1 = 0.995 +- 0.019 (in-sample avg dev_std = 0.030)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.665
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 780
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.619
SUFF++ for r=0.3 class 0.0 = 0.889 +- 0.080 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.3 class 1.0 = 0.934 +- 0.080 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.3 all KL = 0.954 +- 0.080 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.088 (in-sample avg dev_std = 0.129)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.64
SUFF++ for r=0.6 class 0.0 = 0.952 +- 0.043 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 class 1.0 = 0.983 +- 0.043 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all KL = 0.989 +- 0.043 (in-sample avg dev_std = 0.048)
SUFF++ for r=0.6 all L1 = 0.981 +- 0.049 (in-sample avg dev_std = 0.048)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.673
SUFF++ for r=0.9 class 0.0 = 0.985 +- 0.012 (in-sample avg dev_std = 0.027)
SUFF++ for r=0.9 class 1.0 = 0.995 +- 0.012 (in-sample avg dev_std = 0.027)
SUFF++ for r=0.9 all KL = 0.998 +- 0.012 (in-sample avg dev_std = 0.027)
SUFF++ for r=0.9 all L1 = 0.994 +- 0.025 (in-sample avg dev_std = 0.027)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.611
SUFF++ for r=0.3 class 0.0 = 0.888 +- 0.086 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 1.0 = 0.93 +- 0.086 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 all KL = 0.949 +- 0.086 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 all L1 = 0.924 +- 0.093 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.668
SUFF++ for r=0.6 class 0.0 = 0.952 +- 0.044 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.6 class 1.0 = 0.979 +- 0.044 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.6 all KL = 0.987 +- 0.044 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.6 all L1 = 0.975 +- 0.061 (in-sample avg dev_std = 0.056)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0.0 = 0.978 +- 0.015 (in-sample avg dev_std = 0.041)
SUFF++ for r=0.9 class 1.0 = 0.993 +- 0.015 (in-sample avg dev_std = 0.041)
SUFF++ for r=0.9 all KL = 0.997 +- 0.015 (in-sample avg dev_std = 0.041)
SUFF++ for r=0.9 all L1 = 0.99 +- 0.033 (in-sample avg dev_std = 0.041)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.765
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.727
NEC for r=0.3 class 0.0 = 0.069 +- 0.025 (in-sample avg dev_std = 0.051)
NEC for r=0.3 class 1.0 = 0.025 +- 0.025 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all KL = 0.01 +- 0.025 (in-sample avg dev_std = 0.051)
NEC for r=0.3 all L1 = 0.03 +- 0.058 (in-sample avg dev_std = 0.051)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.768
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.745
NEC for r=0.6 class 0.0 = 0.047 +- 0.020 (in-sample avg dev_std = 0.037)
NEC for r=0.6 class 1.0 = 0.01 +- 0.020 (in-sample avg dev_std = 0.037)
NEC for r=0.6 all KL = 0.005 +- 0.020 (in-sample avg dev_std = 0.037)
NEC for r=0.6 all L1 = 0.014 +- 0.046 (in-sample avg dev_std = 0.037)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.772
NEC for r=0.9 class 0.0 = 0.06 +- 0.022 (in-sample avg dev_std = 0.033)
NEC for r=0.9 class 1.0 = 0.007 +- 0.022 (in-sample avg dev_std = 0.033)
NEC for r=0.9 all KL = 0.005 +- 0.022 (in-sample avg dev_std = 0.033)
NEC for r=0.9 all L1 = 0.013 +- 0.050 (in-sample avg dev_std = 0.033)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.777
NEC for r=1.0 class 0.0 = 0.084 +- 0.027 (in-sample avg dev_std = 0.041)
NEC for r=1.0 class 1.0 = 0.007 +- 0.027 (in-sample avg dev_std = 0.041)
NEC for r=1.0 all KL = 0.006 +- 0.027 (in-sample avg dev_std = 0.041)
NEC for r=1.0 all L1 = 0.016 +- 0.058 (in-sample avg dev_std = 0.041)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.717
NEC for r=0.3 class 0.0 = 0.088 +- 0.023 (in-sample avg dev_std = 0.047)
NEC for r=0.3 class 1.0 = 0.025 +- 0.023 (in-sample avg dev_std = 0.047)
NEC for r=0.3 all KL = 0.01 +- 0.023 (in-sample avg dev_std = 0.047)
NEC for r=0.3 all L1 = 0.032 +- 0.059 (in-sample avg dev_std = 0.047)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.781
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.768
NEC for r=0.6 class 0.0 = 0.05 +- 0.032 (in-sample avg dev_std = 0.040)
NEC for r=0.6 class 1.0 = 0.009 +- 0.032 (in-sample avg dev_std = 0.040)
NEC for r=0.6 all KL = 0.006 +- 0.032 (in-sample avg dev_std = 0.040)
NEC for r=0.6 all L1 = 0.014 +- 0.048 (in-sample avg dev_std = 0.040)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.777
NEC for r=0.9 class 0.0 = 0.059 +- 0.026 (in-sample avg dev_std = 0.043)
NEC for r=0.9 class 1.0 = 0.008 +- 0.026 (in-sample avg dev_std = 0.043)
NEC for r=0.9 all KL = 0.006 +- 0.026 (in-sample avg dev_std = 0.043)
NEC for r=0.9 all L1 = 0.014 +- 0.054 (in-sample avg dev_std = 0.043)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.811
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.773
NEC for r=1.0 class 0.0 = 0.067 +- 0.026 (in-sample avg dev_std = 0.041)
NEC for r=1.0 class 1.0 = 0.007 +- 0.026 (in-sample avg dev_std = 0.041)
NEC for r=1.0 all KL = 0.006 +- 0.026 (in-sample avg dev_std = 0.041)
NEC for r=1.0 all L1 = 0.014 +- 0.055 (in-sample avg dev_std = 0.041)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.671
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.664
NEC for r=0.3 class 0.0 = 0.085 +- 0.033 (in-sample avg dev_std = 0.053)
NEC for r=0.3 class 1.0 = 0.037 +- 0.033 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all KL = 0.014 +- 0.033 (in-sample avg dev_std = 0.053)
NEC for r=0.3 all L1 = 0.041 +- 0.069 (in-sample avg dev_std = 0.053)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.644
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.638
NEC for r=0.6 class 0.0 = 0.036 +- 0.020 (in-sample avg dev_std = 0.042)
NEC for r=0.6 class 1.0 = 0.013 +- 0.020 (in-sample avg dev_std = 0.042)
NEC for r=0.6 all KL = 0.006 +- 0.020 (in-sample avg dev_std = 0.042)
NEC for r=0.6 all L1 = 0.015 +- 0.042 (in-sample avg dev_std = 0.042)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.672
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.659
NEC for r=0.9 class 0.0 = 0.042 +- 0.043 (in-sample avg dev_std = 0.054)
NEC for r=0.9 class 1.0 = 0.015 +- 0.043 (in-sample avg dev_std = 0.054)
NEC for r=0.9 all KL = 0.009 +- 0.043 (in-sample avg dev_std = 0.054)
NEC for r=0.9 all L1 = 0.017 +- 0.061 (in-sample avg dev_std = 0.054)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.681
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.658
NEC for r=1.0 class 0.0 = 0.036 +- 0.034 (in-sample avg dev_std = 0.051)
NEC for r=1.0 class 1.0 = 0.015 +- 0.034 (in-sample avg dev_std = 0.051)
NEC for r=1.0 all KL = 0.008 +- 0.034 (in-sample avg dev_std = 0.051)
NEC for r=1.0 all L1 = 0.017 +- 0.057 (in-sample avg dev_std = 0.051)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.65
NEC for r=0.3 class 0.0 = 0.068 +- 0.034 (in-sample avg dev_std = 0.063)
NEC for r=0.3 class 1.0 = 0.041 +- 0.034 (in-sample avg dev_std = 0.063)
NEC for r=0.3 all KL = 0.015 +- 0.034 (in-sample avg dev_std = 0.063)
NEC for r=0.3 all L1 = 0.045 +- 0.075 (in-sample avg dev_std = 0.063)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.689
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.675
NEC for r=0.6 class 0.0 = 0.044 +- 0.035 (in-sample avg dev_std = 0.056)
NEC for r=0.6 class 1.0 = 0.018 +- 0.035 (in-sample avg dev_std = 0.056)
NEC for r=0.6 all KL = 0.01 +- 0.035 (in-sample avg dev_std = 0.056)
NEC for r=0.6 all L1 = 0.022 +- 0.058 (in-sample avg dev_std = 0.056)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.674
NEC for r=0.9 class 0.0 = 0.042 +- 0.037 (in-sample avg dev_std = 0.056)
NEC for r=0.9 class 1.0 = 0.018 +- 0.037 (in-sample avg dev_std = 0.056)
NEC for r=0.9 all KL = 0.009 +- 0.037 (in-sample avg dev_std = 0.056)
NEC for r=0.9 all L1 = 0.022 +- 0.066 (in-sample avg dev_std = 0.056)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.677
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.66
NEC for r=1.0 class 0.0 = 0.04 +- 0.029 (in-sample avg dev_std = 0.050)
NEC for r=1.0 class 1.0 = 0.017 +- 0.029 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all KL = 0.008 +- 0.029 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all L1 = 0.021 +- 0.061 (in-sample avg dev_std = 0.050)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:03:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:03:38 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:04:09 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:04:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:04:29 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:04:44 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ROC-AUC: 0.9514
Train Loss: 0.1805
ID Validation ROC-AUC: 0.9181
ID Validation Loss: 0.2360
ID Test ROC-AUC: 0.9211
ID Test Loss: 0.2370
OOD Validation ROC-AUC: 0.6322
OOD Validation Loss: 0.4502
OOD Test ROC-AUC: 0.7009
OOD Test Loss: 0.5649

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.8894
Train Loss: 0.3317
ID Validation ROC-AUC: 0.8818
ID Validation Loss: 0.3404
ID Test ROC-AUC: 0.8842
ID Test Loss: 0.3446
OOD Validation ROC-AUC: 0.6992
OOD Validation Loss: 0.3369
OOD Test ROC-AUC: 0.7225
OOD Test Loss: 0.5874

[0m[1;37mINFO[0m: [1mChartInfo 0.9211 0.7009 0.8842 0.7225 0.8818 0.6992[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:05:00 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:05:05 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:05:09 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:05:13 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.741
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 788
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.69
SUFF++ for r=0.3 class 0.0 = 0.808 +- 0.117 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 1.0 = 0.911 +- 0.117 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 all KL = 0.925 +- 0.117 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 all L1 = 0.899 +- 0.127 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.823
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.803
SUFF++ for r=0.6 class 0.0 = 0.873 +- 0.063 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.6 class 1.0 = 0.975 +- 0.063 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.6 all KL = 0.979 +- 0.063 (in-sample avg dev_std = 0.091)
SUFF++ for r=0.6 all L1 = 0.963 +- 0.090 (in-sample avg dev_std = 0.091)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.861
SUFF++ for r=0.9 class 0.0 = 0.935 +- 0.057 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.9 class 1.0 = 0.993 +- 0.057 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.9 all KL = 0.992 +- 0.057 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.9 all L1 = 0.987 +- 0.053 (in-sample avg dev_std = 0.073)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.756
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.665
SUFF++ for r=0.3 class 0.0 = 0.815 +- 0.133 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.3 class 1.0 = 0.903 +- 0.133 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.3 all KL = 0.915 +- 0.133 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.3 all L1 = 0.893 +- 0.132 (in-sample avg dev_std = 0.219)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.819
SUFF++ for r=0.6 class 0.0 = 0.896 +- 0.091 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 class 1.0 = 0.977 +- 0.091 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all KL = 0.974 +- 0.091 (in-sample avg dev_std = 0.095)
SUFF++ for r=0.6 all L1 = 0.968 +- 0.083 (in-sample avg dev_std = 0.095)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.851
SUFF++ for r=0.9 class 0.0 = 0.951 +- 0.051 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 class 1.0 = 0.992 +- 0.051 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 all KL = 0.993 +- 0.051 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 all L1 = 0.987 +- 0.049 (in-sample avg dev_std = 0.053)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 775
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0.0 = 0.839 +- 0.126 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.3 class 1.0 = 0.878 +- 0.126 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.3 all KL = 0.909 +- 0.126 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.3 all L1 = 0.875 +- 0.132 (in-sample avg dev_std = 0.222)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.677
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.64
SUFF++ for r=0.6 class 0.0 = 0.895 +- 0.093 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 class 1.0 = 0.961 +- 0.093 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all KL = 0.968 +- 0.093 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.6 all L1 = 0.956 +- 0.100 (in-sample avg dev_std = 0.100)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.668
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.023 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 class 1.0 = 0.987 +- 0.023 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all KL = 0.994 +- 0.023 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all L1 = 0.986 +- 0.044 (in-sample avg dev_std = 0.059)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.817 +- 0.115 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 1.0 = 0.879 +- 0.115 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all KL = 0.911 +- 0.115 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all L1 = 0.869 +- 0.133 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
SUFF++ for r=0.6 class 0.0 = 0.913 +- 0.084 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 class 1.0 = 0.957 +- 0.084 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 all KL = 0.967 +- 0.084 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 all L1 = 0.95 +- 0.097 (in-sample avg dev_std = 0.106)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.68
SUFF++ for r=0.9 class 0.0 = 0.974 +- 0.042 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.042 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all KL = 0.992 +- 0.042 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.058 (in-sample avg dev_std = 0.069)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.74
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.735
NEC for r=0.3 class 0.0 = 0.116 +- 0.057 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1.0 = 0.054 +- 0.057 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.027 +- 0.057 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.061 +- 0.097 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.823
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.799
NEC for r=0.6 class 0.0 = 0.11 +- 0.055 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 1.0 = 0.022 +- 0.055 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all KL = 0.017 +- 0.055 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all L1 = 0.032 +- 0.086 (in-sample avg dev_std = 0.086)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.815
NEC for r=0.9 class 0.0 = 0.141 +- 0.084 (in-sample avg dev_std = 0.095)
NEC for r=0.9 class 1.0 = 0.016 +- 0.084 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all KL = 0.02 +- 0.084 (in-sample avg dev_std = 0.095)
NEC for r=0.9 all L1 = 0.03 +- 0.092 (in-sample avg dev_std = 0.095)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.822
NEC for r=1.0 class 0.0 = 0.157 +- 0.085 (in-sample avg dev_std = 0.095)
NEC for r=1.0 class 1.0 = 0.017 +- 0.085 (in-sample avg dev_std = 0.095)
NEC for r=1.0 all KL = 0.022 +- 0.085 (in-sample avg dev_std = 0.095)
NEC for r=1.0 all L1 = 0.033 +- 0.095 (in-sample avg dev_std = 0.095)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.758
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.737
NEC for r=0.3 class 0.0 = 0.134 +- 0.072 (in-sample avg dev_std = 0.104)
NEC for r=0.3 class 1.0 = 0.054 +- 0.072 (in-sample avg dev_std = 0.104)
NEC for r=0.3 all KL = 0.03 +- 0.072 (in-sample avg dev_std = 0.104)
NEC for r=0.3 all L1 = 0.064 +- 0.104 (in-sample avg dev_std = 0.104)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.827
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.816
NEC for r=0.6 class 0.0 = 0.102 +- 0.054 (in-sample avg dev_std = 0.083)
NEC for r=0.6 class 1.0 = 0.016 +- 0.054 (in-sample avg dev_std = 0.083)
NEC for r=0.6 all KL = 0.015 +- 0.054 (in-sample avg dev_std = 0.083)
NEC for r=0.6 all L1 = 0.026 +- 0.076 (in-sample avg dev_std = 0.083)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.826
NEC for r=0.9 class 0.0 = 0.136 +- 0.067 (in-sample avg dev_std = 0.088)
NEC for r=0.9 class 1.0 = 0.015 +- 0.067 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all KL = 0.018 +- 0.067 (in-sample avg dev_std = 0.088)
NEC for r=0.9 all L1 = 0.029 +- 0.088 (in-sample avg dev_std = 0.088)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0.0 = 0.145 +- 0.057 (in-sample avg dev_std = 0.080)
NEC for r=1.0 class 1.0 = 0.015 +- 0.057 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all KL = 0.018 +- 0.057 (in-sample avg dev_std = 0.080)
NEC for r=1.0 all L1 = 0.03 +- 0.088 (in-sample avg dev_std = 0.080)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.619
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0.0 = 0.113 +- 0.059 (in-sample avg dev_std = 0.109)
NEC for r=0.3 class 1.0 = 0.075 +- 0.059 (in-sample avg dev_std = 0.109)
NEC for r=0.3 all KL = 0.032 +- 0.059 (in-sample avg dev_std = 0.109)
NEC for r=0.3 all L1 = 0.078 +- 0.110 (in-sample avg dev_std = 0.109)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.677
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.645
NEC for r=0.6 class 0.0 = 0.085 +- 0.061 (in-sample avg dev_std = 0.091)
NEC for r=0.6 class 1.0 = 0.029 +- 0.061 (in-sample avg dev_std = 0.091)
NEC for r=0.6 all KL = 0.019 +- 0.061 (in-sample avg dev_std = 0.091)
NEC for r=0.6 all L1 = 0.033 +- 0.084 (in-sample avg dev_std = 0.091)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.671
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.645
NEC for r=0.9 class 0.0 = 0.089 +- 0.069 (in-sample avg dev_std = 0.080)
NEC for r=0.9 class 1.0 = 0.028 +- 0.069 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all KL = 0.02 +- 0.069 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all L1 = 0.033 +- 0.089 (in-sample avg dev_std = 0.080)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.689
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.652
NEC for r=1.0 class 0.0 = 0.088 +- 0.081 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 1.0 = 0.033 +- 0.081 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all KL = 0.024 +- 0.081 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all L1 = 0.038 +- 0.102 (in-sample avg dev_std = 0.088)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.641
NEC for r=0.3 class 0.0 = 0.137 +- 0.069 (in-sample avg dev_std = 0.127)
NEC for r=0.3 class 1.0 = 0.08 +- 0.069 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all KL = 0.039 +- 0.069 (in-sample avg dev_std = 0.127)
NEC for r=0.3 all L1 = 0.09 +- 0.117 (in-sample avg dev_std = 0.127)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.691
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.672
NEC for r=0.6 class 0.0 = 0.08 +- 0.072 (in-sample avg dev_std = 0.105)
NEC for r=0.6 class 1.0 = 0.035 +- 0.072 (in-sample avg dev_std = 0.105)
NEC for r=0.6 all KL = 0.023 +- 0.072 (in-sample avg dev_std = 0.105)
NEC for r=0.6 all L1 = 0.042 +- 0.093 (in-sample avg dev_std = 0.105)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.666
NEC for r=0.9 class 0.0 = 0.066 +- 0.070 (in-sample avg dev_std = 0.097)
NEC for r=0.9 class 1.0 = 0.032 +- 0.070 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all KL = 0.022 +- 0.070 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all L1 = 0.038 +- 0.095 (in-sample avg dev_std = 0.097)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.697
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0.0 = 0.081 +- 0.076 (in-sample avg dev_std = 0.092)
NEC for r=1.0 class 1.0 = 0.033 +- 0.076 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all KL = 0.025 +- 0.076 (in-sample avg dev_std = 0.092)
NEC for r=1.0 all L1 = 0.041 +- 0.101 (in-sample avg dev_std = 0.092)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:10:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:10:04 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:10:35 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:10:45 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:10:55 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:10 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:11:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ROC-AUC: 0.9411
Train Loss: 0.2098
ID Validation ROC-AUC: 0.9161
ID Validation Loss: 0.2498
ID Test ROC-AUC: 0.9173
ID Test Loss: 0.2568
OOD Validation ROC-AUC: 0.6619
OOD Validation Loss: 0.3726
OOD Test ROC-AUC: 0.7052
OOD Test Loss: 0.5507

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ROC-AUC: 0.8652
Train Loss: 0.2878
ID Validation ROC-AUC: 0.8553
ID Validation Loss: 0.2994
ID Test ROC-AUC: 0.8620
ID Test Loss: 0.2958
OOD Validation ROC-AUC: 0.7065
OOD Validation Loss: 0.3072
OOD Test ROC-AUC: 0.7025
OOD Test Loss: 0.5179

[0m[1;37mINFO[0m: [1mChartInfo 0.9173 0.7052 0.8620 0.7025 0.8553 0.7065[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:11:27 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:11:31 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:11:35 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:11:39 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.677
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 788
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.638
SUFF++ for r=0.3 class 0.0 = 0.833 +- 0.083 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.3 class 1.0 = 0.914 +- 0.083 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.3 all KL = 0.943 +- 0.083 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.3 all L1 = 0.905 +- 0.100 (in-sample avg dev_std = 0.169)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.772
SUFF++ for r=0.6 class 0.0 = 0.877 +- 0.061 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 class 1.0 = 0.965 +- 0.061 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 all KL = 0.978 +- 0.061 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 all L1 = 0.955 +- 0.085 (in-sample avg dev_std = 0.084)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.882
SUFF++ for r=0.9 class 0.0 = 0.945 +- 0.015 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 class 1.0 = 0.989 +- 0.015 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all KL = 0.996 +- 0.015 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all L1 = 0.984 +- 0.039 (in-sample avg dev_std = 0.059)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.723
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.659
SUFF++ for r=0.3 class 0.0 = 0.845 +- 0.084 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.3 class 1.0 = 0.919 +- 0.084 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.3 all KL = 0.947 +- 0.084 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.3 all L1 = 0.91 +- 0.100 (in-sample avg dev_std = 0.163)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.79
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.787
SUFF++ for r=0.6 class 0.0 = 0.886 +- 0.057 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.6 class 1.0 = 0.966 +- 0.057 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.6 all KL = 0.979 +- 0.057 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.6 all L1 = 0.957 +- 0.088 (in-sample avg dev_std = 0.088)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0.0 = 0.945 +- 0.019 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 class 1.0 = 0.99 +- 0.019 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 all KL = 0.995 +- 0.019 (in-sample avg dev_std = 0.053)
SUFF++ for r=0.9 all L1 = 0.985 +- 0.039 (in-sample avg dev_std = 0.053)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.58
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.562
SUFF++ for r=0.3 class 0.0 = 0.861 +- 0.089 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 class 1.0 = 0.888 +- 0.089 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all KL = 0.935 +- 0.089 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.3 all L1 = 0.885 +- 0.108 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0.0 = 0.887 +- 0.055 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.6 class 1.0 = 0.94 +- 0.055 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.6 all KL = 0.973 +- 0.055 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.100 (in-sample avg dev_std = 0.093)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.622
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.617
SUFF++ for r=0.9 class 0.0 = 0.974 +- 0.024 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.024 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 all KL = 0.994 +- 0.024 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 all L1 = 0.98 +- 0.044 (in-sample avg dev_std = 0.056)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 776
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0.0 = 0.852 +- 0.091 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.3 class 1.0 = 0.886 +- 0.091 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.3 all KL = 0.932 +- 0.091 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.3 all L1 = 0.88 +- 0.110 (in-sample avg dev_std = 0.187)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.646
SUFF++ for r=0.6 class 0.0 = 0.898 +- 0.069 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 class 1.0 = 0.945 +- 0.069 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all KL = 0.97 +- 0.069 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.097 (in-sample avg dev_std = 0.099)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.71
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.706
SUFF++ for r=0.9 class 0.0 = 0.954 +- 0.027 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.027 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all KL = 0.992 +- 0.027 (in-sample avg dev_std = 0.069)
SUFF++ for r=0.9 all L1 = 0.974 +- 0.054 (in-sample avg dev_std = 0.069)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.677
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.684
NEC for r=0.3 class 0.0 = 0.135 +- 0.051 (in-sample avg dev_std = 0.092)
NEC for r=0.3 class 1.0 = 0.055 +- 0.051 (in-sample avg dev_std = 0.092)
NEC for r=0.3 all KL = 0.023 +- 0.051 (in-sample avg dev_std = 0.092)
NEC for r=0.3 all L1 = 0.064 +- 0.092 (in-sample avg dev_std = 0.092)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.761
NEC for r=0.6 class 0.0 = 0.123 +- 0.054 (in-sample avg dev_std = 0.088)
NEC for r=0.6 class 1.0 = 0.029 +- 0.054 (in-sample avg dev_std = 0.088)
NEC for r=0.6 all KL = 0.019 +- 0.054 (in-sample avg dev_std = 0.088)
NEC for r=0.6 all L1 = 0.04 +- 0.078 (in-sample avg dev_std = 0.088)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.835
NEC for r=0.9 class 0.0 = 0.167 +- 0.086 (in-sample avg dev_std = 0.113)
NEC for r=0.9 class 1.0 = 0.034 +- 0.086 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all KL = 0.031 +- 0.086 (in-sample avg dev_std = 0.113)
NEC for r=0.9 all L1 = 0.049 +- 0.104 (in-sample avg dev_std = 0.113)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.917
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.854
NEC for r=1.0 class 0.0 = 0.177 +- 0.072 (in-sample avg dev_std = 0.104)
NEC for r=1.0 class 1.0 = 0.029 +- 0.072 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all KL = 0.026 +- 0.072 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all L1 = 0.046 +- 0.098 (in-sample avg dev_std = 0.104)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.725
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.705
NEC for r=0.3 class 0.0 = 0.111 +- 0.046 (in-sample avg dev_std = 0.091)
NEC for r=0.3 class 1.0 = 0.052 +- 0.046 (in-sample avg dev_std = 0.091)
NEC for r=0.3 all KL = 0.021 +- 0.046 (in-sample avg dev_std = 0.091)
NEC for r=0.3 all L1 = 0.059 +- 0.083 (in-sample avg dev_std = 0.091)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.79
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.77
NEC for r=0.6 class 0.0 = 0.098 +- 0.041 (in-sample avg dev_std = 0.081)
NEC for r=0.6 class 1.0 = 0.028 +- 0.041 (in-sample avg dev_std = 0.081)
NEC for r=0.6 all KL = 0.015 +- 0.041 (in-sample avg dev_std = 0.081)
NEC for r=0.6 all L1 = 0.036 +- 0.074 (in-sample avg dev_std = 0.081)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.84
NEC for r=0.9 class 0.0 = 0.133 +- 0.077 (in-sample avg dev_std = 0.101)
NEC for r=0.9 class 1.0 = 0.031 +- 0.077 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all KL = 0.027 +- 0.077 (in-sample avg dev_std = 0.101)
NEC for r=0.9 all L1 = 0.043 +- 0.093 (in-sample avg dev_std = 0.101)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.904
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0.0 = 0.153 +- 0.071 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.029 +- 0.071 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.027 +- 0.071 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.043 +- 0.097 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.58
NEC for r=0.3 class 0.0 = 0.105 +- 0.049 (in-sample avg dev_std = 0.096)
NEC for r=0.3 class 1.0 = 0.072 +- 0.049 (in-sample avg dev_std = 0.096)
NEC for r=0.3 all KL = 0.026 +- 0.049 (in-sample avg dev_std = 0.096)
NEC for r=0.3 all L1 = 0.075 +- 0.097 (in-sample avg dev_std = 0.096)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
NEC for r=0.6 class 0.0 = 0.101 +- 0.044 (in-sample avg dev_std = 0.101)
NEC for r=0.6 class 1.0 = 0.048 +- 0.044 (in-sample avg dev_std = 0.101)
NEC for r=0.6 all KL = 0.021 +- 0.044 (in-sample avg dev_std = 0.101)
NEC for r=0.6 all L1 = 0.052 +- 0.084 (in-sample avg dev_std = 0.101)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.622
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.599
NEC for r=0.9 class 0.0 = 0.091 +- 0.058 (in-sample avg dev_std = 0.093)
NEC for r=0.9 class 1.0 = 0.05 +- 0.058 (in-sample avg dev_std = 0.093)
NEC for r=0.9 all KL = 0.027 +- 0.058 (in-sample avg dev_std = 0.093)
NEC for r=0.9 all L1 = 0.054 +- 0.092 (in-sample avg dev_std = 0.093)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.658
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.629
NEC for r=1.0 class 0.0 = 0.083 +- 0.064 (in-sample avg dev_std = 0.095)
NEC for r=1.0 class 1.0 = 0.05 +- 0.064 (in-sample avg dev_std = 0.095)
NEC for r=1.0 all KL = 0.027 +- 0.064 (in-sample avg dev_std = 0.095)
NEC for r=1.0 all L1 = 0.053 +- 0.096 (in-sample avg dev_std = 0.095)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.616
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.594
NEC for r=0.3 class 0.0 = 0.105 +- 0.056 (in-sample avg dev_std = 0.098)
NEC for r=0.3 class 1.0 = 0.075 +- 0.056 (in-sample avg dev_std = 0.098)
NEC for r=0.3 all KL = 0.029 +- 0.056 (in-sample avg dev_std = 0.098)
NEC for r=0.3 all L1 = 0.08 +- 0.096 (in-sample avg dev_std = 0.098)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.63
NEC for r=0.6 class 0.0 = 0.088 +- 0.059 (in-sample avg dev_std = 0.109)
NEC for r=0.6 class 1.0 = 0.05 +- 0.059 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all KL = 0.025 +- 0.059 (in-sample avg dev_std = 0.109)
NEC for r=0.6 all L1 = 0.056 +- 0.091 (in-sample avg dev_std = 0.109)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.71
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0.0 = 0.097 +- 0.072 (in-sample avg dev_std = 0.102)
NEC for r=0.9 class 1.0 = 0.052 +- 0.072 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all KL = 0.031 +- 0.072 (in-sample avg dev_std = 0.102)
NEC for r=0.9 all L1 = 0.059 +- 0.099 (in-sample avg dev_std = 0.102)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.719
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.688
NEC for r=1.0 class 0.0 = 0.114 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.052 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.03 +- 0.062 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.062 +- 0.103 (in-sample avg dev_std = 0.096)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:16:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:16:31 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:11 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:21 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:37 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:17:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ROC-AUC: 0.9467
Train Loss: 0.2039
ID Validation ROC-AUC: 0.9170
ID Validation Loss: 0.2477
ID Test ROC-AUC: 0.9174
ID Test Loss: 0.2595
OOD Validation ROC-AUC: 0.6627
OOD Validation Loss: 0.3794
OOD Test ROC-AUC: 0.7160
OOD Test Loss: 0.5292

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.8925
Train Loss: 0.2938
ID Validation ROC-AUC: 0.8833
ID Validation Loss: 0.3043
ID Test ROC-AUC: 0.8871
ID Test Loss: 0.3056
OOD Validation ROC-AUC: 0.6923
OOD Validation Loss: 0.3171
OOD Test ROC-AUC: 0.7131
OOD Test Loss: 0.5494

[0m[1;37mINFO[0m: [1mChartInfo 0.9174 0.7160 0.8871 0.7131 0.8833 0.6923[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:17:53 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:17:57 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:18:01 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:18:05 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.765
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 790
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.688
SUFF++ for r=0.3 class 0.0 = 0.798 +- 0.090 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 1.0 = 0.885 +- 0.090 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 all KL = 0.925 +- 0.090 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 all L1 = 0.875 +- 0.118 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.814
SUFF++ for r=0.6 class 0.0 = 0.846 +- 0.064 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 class 1.0 = 0.963 +- 0.064 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 all KL = 0.974 +- 0.064 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 all L1 = 0.949 +- 0.098 (in-sample avg dev_std = 0.106)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.875
SUFF++ for r=0.9 class 0.0 = 0.938 +- 0.023 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 class 1.0 = 0.994 +- 0.023 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 all KL = 0.995 +- 0.023 (in-sample avg dev_std = 0.060)
SUFF++ for r=0.9 all L1 = 0.987 +- 0.042 (in-sample avg dev_std = 0.060)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.735
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 784
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.684
SUFF++ for r=0.3 class 0.0 = 0.816 +- 0.091 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.3 class 1.0 = 0.892 +- 0.091 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.3 all KL = 0.93 +- 0.091 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.3 all L1 = 0.883 +- 0.113 (in-sample avg dev_std = 0.184)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.79
SUFF++ for r=0.6 class 0.0 = 0.871 +- 0.067 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 class 1.0 = 0.964 +- 0.067 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all KL = 0.974 +- 0.067 (in-sample avg dev_std = 0.099)
SUFF++ for r=0.6 all L1 = 0.953 +- 0.097 (in-sample avg dev_std = 0.099)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.853
SUFF++ for r=0.9 class 0.0 = 0.947 +- 0.023 (in-sample avg dev_std = 0.050)
SUFF++ for r=0.9 class 1.0 = 0.994 +- 0.023 (in-sample avg dev_std = 0.050)
SUFF++ for r=0.9 all KL = 0.996 +- 0.023 (in-sample avg dev_std = 0.050)
SUFF++ for r=0.9 all L1 = 0.988 +- 0.037 (in-sample avg dev_std = 0.050)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.603
SUFF++ for r=0.3 class 0.0 = 0.819 +- 0.097 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 1.0 = 0.865 +- 0.097 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all KL = 0.922 +- 0.097 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all L1 = 0.861 +- 0.120 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0.0 = 0.894 +- 0.082 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 class 1.0 = 0.944 +- 0.082 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 all KL = 0.966 +- 0.082 (in-sample avg dev_std = 0.106)
SUFF++ for r=0.6 all L1 = 0.94 +- 0.102 (in-sample avg dev_std = 0.106)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.633
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.626
SUFF++ for r=0.9 class 0.0 = 0.972 +- 0.015 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.9 class 1.0 = 0.987 +- 0.015 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.9 all KL = 0.995 +- 0.015 (in-sample avg dev_std = 0.047)
SUFF++ for r=0.9 all L1 = 0.986 +- 0.038 (in-sample avg dev_std = 0.047)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.653
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.605
SUFF++ for r=0.3 class 0.0 = 0.811 +- 0.088 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.3 class 1.0 = 0.862 +- 0.088 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.3 all KL = 0.918 +- 0.088 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.3 all L1 = 0.853 +- 0.118 (in-sample avg dev_std = 0.212)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0.0 = 0.884 +- 0.067 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 1.0 = 0.945 +- 0.067 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 all KL = 0.968 +- 0.067 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 all L1 = 0.935 +- 0.106 (in-sample avg dev_std = 0.107)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.704
SUFF++ for r=0.9 class 0.0 = 0.974 +- 0.035 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 class 1.0 = 0.985 +- 0.035 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all KL = 0.993 +- 0.035 (in-sample avg dev_std = 0.059)
SUFF++ for r=0.9 all L1 = 0.983 +- 0.041 (in-sample avg dev_std = 0.059)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.766
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.752
NEC for r=0.3 class 0.0 = 0.145 +- 0.060 (in-sample avg dev_std = 0.110)
NEC for r=0.3 class 1.0 = 0.073 +- 0.060 (in-sample avg dev_std = 0.110)
NEC for r=0.3 all KL = 0.03 +- 0.060 (in-sample avg dev_std = 0.110)
NEC for r=0.3 all L1 = 0.081 +- 0.101 (in-sample avg dev_std = 0.110)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.815
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.795
NEC for r=0.6 class 0.0 = 0.14 +- 0.055 (in-sample avg dev_std = 0.100)
NEC for r=0.6 class 1.0 = 0.032 +- 0.055 (in-sample avg dev_std = 0.100)
NEC for r=0.6 all KL = 0.021 +- 0.055 (in-sample avg dev_std = 0.100)
NEC for r=0.6 all L1 = 0.045 +- 0.093 (in-sample avg dev_std = 0.100)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.826
NEC for r=0.9 class 0.0 = 0.155 +- 0.101 (in-sample avg dev_std = 0.112)
NEC for r=0.9 class 1.0 = 0.022 +- 0.101 (in-sample avg dev_std = 0.112)
NEC for r=0.9 all KL = 0.029 +- 0.101 (in-sample avg dev_std = 0.112)
NEC for r=0.9 all L1 = 0.038 +- 0.095 (in-sample avg dev_std = 0.112)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.841
NEC for r=1.0 class 0.0 = 0.138 +- 0.081 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.019 +- 0.081 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.022 +- 0.081 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.033 +- 0.084 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.732
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.739
NEC for r=0.3 class 0.0 = 0.121 +- 0.059 (in-sample avg dev_std = 0.101)
NEC for r=0.3 class 1.0 = 0.071 +- 0.059 (in-sample avg dev_std = 0.101)
NEC for r=0.3 all KL = 0.029 +- 0.059 (in-sample avg dev_std = 0.101)
NEC for r=0.3 all L1 = 0.077 +- 0.095 (in-sample avg dev_std = 0.101)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.806
NEC for r=0.6 class 0.0 = 0.107 +- 0.050 (in-sample avg dev_std = 0.087)
NEC for r=0.6 class 1.0 = 0.028 +- 0.050 (in-sample avg dev_std = 0.087)
NEC for r=0.6 all KL = 0.018 +- 0.050 (in-sample avg dev_std = 0.087)
NEC for r=0.6 all L1 = 0.037 +- 0.081 (in-sample avg dev_std = 0.087)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.842
NEC for r=0.9 class 0.0 = 0.117 +- 0.070 (in-sample avg dev_std = 0.086)
NEC for r=0.9 class 1.0 = 0.02 +- 0.070 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all KL = 0.02 +- 0.070 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all L1 = 0.031 +- 0.079 (in-sample avg dev_std = 0.086)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.843
NEC for r=1.0 class 0.0 = 0.115 +- 0.054 (in-sample avg dev_std = 0.070)
NEC for r=1.0 class 1.0 = 0.018 +- 0.054 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all KL = 0.017 +- 0.054 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all L1 = 0.029 +- 0.078 (in-sample avg dev_std = 0.070)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.658
NEC for r=0.3 class 0.0 = 0.123 +- 0.060 (in-sample avg dev_std = 0.115)
NEC for r=0.3 class 1.0 = 0.09 +- 0.060 (in-sample avg dev_std = 0.115)
NEC for r=0.3 all KL = 0.035 +- 0.060 (in-sample avg dev_std = 0.115)
NEC for r=0.3 all L1 = 0.093 +- 0.103 (in-sample avg dev_std = 0.115)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.638
NEC for r=0.6 class 0.0 = 0.1 +- 0.067 (in-sample avg dev_std = 0.104)
NEC for r=0.6 class 1.0 = 0.05 +- 0.067 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all KL = 0.027 +- 0.067 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all L1 = 0.054 +- 0.097 (in-sample avg dev_std = 0.104)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.633
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.615
NEC for r=0.9 class 0.0 = 0.07 +- 0.064 (in-sample avg dev_std = 0.081)
NEC for r=0.9 class 1.0 = 0.033 +- 0.064 (in-sample avg dev_std = 0.081)
NEC for r=0.9 all KL = 0.023 +- 0.064 (in-sample avg dev_std = 0.081)
NEC for r=0.9 all L1 = 0.036 +- 0.078 (in-sample avg dev_std = 0.081)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.637
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.616
NEC for r=1.0 class 0.0 = 0.056 +- 0.065 (in-sample avg dev_std = 0.078)
NEC for r=1.0 class 1.0 = 0.037 +- 0.065 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all KL = 0.024 +- 0.065 (in-sample avg dev_std = 0.078)
NEC for r=1.0 all L1 = 0.039 +- 0.085 (in-sample avg dev_std = 0.078)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.648
NEC for r=0.3 class 0.0 = 0.12 +- 0.066 (in-sample avg dev_std = 0.118)
NEC for r=0.3 class 1.0 = 0.098 +- 0.066 (in-sample avg dev_std = 0.118)
NEC for r=0.3 all KL = 0.038 +- 0.066 (in-sample avg dev_std = 0.118)
NEC for r=0.3 all L1 = 0.102 +- 0.108 (in-sample avg dev_std = 0.118)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.668
NEC for r=0.6 class 0.0 = 0.095 +- 0.068 (in-sample avg dev_std = 0.108)
NEC for r=0.6 class 1.0 = 0.051 +- 0.068 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all KL = 0.03 +- 0.068 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all L1 = 0.058 +- 0.095 (in-sample avg dev_std = 0.108)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.685
NEC for r=0.9 class 0.0 = 0.07 +- 0.069 (in-sample avg dev_std = 0.094)
NEC for r=0.9 class 1.0 = 0.039 +- 0.069 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all KL = 0.024 +- 0.069 (in-sample avg dev_std = 0.094)
NEC for r=0.9 all L1 = 0.044 +- 0.087 (in-sample avg dev_std = 0.094)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.691
NEC for r=1.0 class 0.0 = 0.068 +- 0.078 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1.0 = 0.04 +- 0.078 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.027 +- 0.078 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.044 +- 0.090 (in-sample avg dev_std = 0.090)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:22:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:22:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:23:30 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:23:39 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:23:50 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ROC-AUC: 0.9500
Train Loss: 0.1823
ID Validation ROC-AUC: 0.9183
ID Validation Loss: 0.2329
ID Test ROC-AUC: 0.9199
ID Test Loss: 0.2360
OOD Validation ROC-AUC: 0.6503
OOD Validation Loss: 0.4194
OOD Test ROC-AUC: 0.7025
OOD Test Loss: 0.5496

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ROC-AUC: 0.8855
Train Loss: 0.2937
ID Validation ROC-AUC: 0.8794
ID Validation Loss: 0.3017
ID Test ROC-AUC: 0.8819
ID Test Loss: 0.3040
OOD Validation ROC-AUC: 0.6906
OOD Validation Loss: 0.3185
OOD Test ROC-AUC: 0.7146
OOD Test Loss: 0.5352

[0m[1;37mINFO[0m: [1mChartInfo 0.9199 0.7025 0.8819 0.7146 0.8794 0.6906[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:24:21 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:24:26 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:24:30 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:24:34 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.731
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.668
SUFF++ for r=0.3 class 0.0 = 0.797 +- 0.110 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 class 1.0 = 0.867 +- 0.110 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all KL = 0.911 +- 0.110 (in-sample avg dev_std = 0.232)
SUFF++ for r=0.3 all L1 = 0.859 +- 0.122 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.783
SUFF++ for r=0.6 class 0.0 = 0.861 +- 0.083 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 class 1.0 = 0.965 +- 0.083 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all KL = 0.971 +- 0.083 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.6 all L1 = 0.953 +- 0.098 (in-sample avg dev_std = 0.104)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.931 +- 0.050 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 class 1.0 = 0.989 +- 0.050 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all KL = 0.991 +- 0.050 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.059 (in-sample avg dev_std = 0.080)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.706
SUFF++ for r=0.3 class 0.0 = 0.783 +- 0.107 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 1.0 = 0.874 +- 0.107 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 all KL = 0.916 +- 0.107 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 all L1 = 0.864 +- 0.126 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.833
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.809
SUFF++ for r=0.6 class 0.0 = 0.849 +- 0.084 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 class 1.0 = 0.964 +- 0.084 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 all KL = 0.969 +- 0.084 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.6 all L1 = 0.95 +- 0.100 (in-sample avg dev_std = 0.107)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.017 (in-sample avg dev_std = 0.055)
SUFF++ for r=0.9 class 1.0 = 0.992 +- 0.017 (in-sample avg dev_std = 0.055)
SUFF++ for r=0.9 all KL = 0.996 +- 0.017 (in-sample avg dev_std = 0.055)
SUFF++ for r=0.9 all L1 = 0.986 +- 0.041 (in-sample avg dev_std = 0.055)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.637
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.802 +- 0.111 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 class 1.0 = 0.84 +- 0.111 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all KL = 0.905 +- 0.111 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.3 all L1 = 0.837 +- 0.131 (in-sample avg dev_std = 0.252)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.695
SUFF++ for r=0.6 class 0.0 = 0.854 +- 0.083 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 class 1.0 = 0.944 +- 0.083 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all KL = 0.962 +- 0.083 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all L1 = 0.937 +- 0.110 (in-sample avg dev_std = 0.111)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0.0 = 0.969 +- 0.019 (in-sample avg dev_std = 0.057)
SUFF++ for r=0.9 class 1.0 = 0.987 +- 0.019 (in-sample avg dev_std = 0.057)
SUFF++ for r=0.9 all KL = 0.995 +- 0.019 (in-sample avg dev_std = 0.057)
SUFF++ for r=0.9 all L1 = 0.985 +- 0.038 (in-sample avg dev_std = 0.057)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.596
SUFF++ for r=0.3 class 0.0 = 0.802 +- 0.105 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 class 1.0 = 0.84 +- 0.105 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all KL = 0.904 +- 0.105 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all L1 = 0.833 +- 0.131 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.66
SUFF++ for r=0.6 class 0.0 = 0.889 +- 0.103 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 class 1.0 = 0.933 +- 0.103 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all KL = 0.954 +- 0.103 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all L1 = 0.926 +- 0.117 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0.0 = 0.973 +- 0.031 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.031 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.9 all KL = 0.992 +- 0.031 (in-sample avg dev_std = 0.066)
SUFF++ for r=0.9 all L1 = 0.982 +- 0.045 (in-sample avg dev_std = 0.066)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.724
NEC for r=0.3 class 0.0 = 0.156 +- 0.061 (in-sample avg dev_std = 0.125)
NEC for r=0.3 class 1.0 = 0.084 +- 0.061 (in-sample avg dev_std = 0.125)
NEC for r=0.3 all KL = 0.037 +- 0.061 (in-sample avg dev_std = 0.125)
NEC for r=0.3 all L1 = 0.093 +- 0.105 (in-sample avg dev_std = 0.125)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.104 +- 0.065 (in-sample avg dev_std = 0.096)
NEC for r=0.6 class 1.0 = 0.031 +- 0.065 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all KL = 0.023 +- 0.065 (in-sample avg dev_std = 0.096)
NEC for r=0.6 all L1 = 0.04 +- 0.083 (in-sample avg dev_std = 0.096)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.835
NEC for r=0.9 class 0.0 = 0.149 +- 0.076 (in-sample avg dev_std = 0.097)
NEC for r=0.9 class 1.0 = 0.021 +- 0.076 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all KL = 0.022 +- 0.076 (in-sample avg dev_std = 0.097)
NEC for r=0.9 all L1 = 0.035 +- 0.097 (in-sample avg dev_std = 0.097)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.825
NEC for r=1.0 class 0.0 = 0.154 +- 0.077 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1.0 = 0.02 +- 0.077 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.021 +- 0.077 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.036 +- 0.096 (in-sample avg dev_std = 0.090)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.765
NEC for r=0.3 class 0.0 = 0.168 +- 0.063 (in-sample avg dev_std = 0.122)
NEC for r=0.3 class 1.0 = 0.08 +- 0.063 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all KL = 0.036 +- 0.063 (in-sample avg dev_std = 0.122)
NEC for r=0.3 all L1 = 0.091 +- 0.108 (in-sample avg dev_std = 0.122)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.833
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.814
NEC for r=0.6 class 0.0 = 0.118 +- 0.063 (in-sample avg dev_std = 0.097)
NEC for r=0.6 class 1.0 = 0.029 +- 0.063 (in-sample avg dev_std = 0.097)
NEC for r=0.6 all KL = 0.023 +- 0.063 (in-sample avg dev_std = 0.097)
NEC for r=0.6 all L1 = 0.039 +- 0.081 (in-sample avg dev_std = 0.097)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.873
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.842
NEC for r=0.9 class 0.0 = 0.12 +- 0.082 (in-sample avg dev_std = 0.092)
NEC for r=0.9 class 1.0 = 0.022 +- 0.082 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all KL = 0.022 +- 0.082 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all L1 = 0.033 +- 0.090 (in-sample avg dev_std = 0.092)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.841
NEC for r=1.0 class 0.0 = 0.118 +- 0.064 (in-sample avg dev_std = 0.072)
NEC for r=1.0 class 1.0 = 0.019 +- 0.064 (in-sample avg dev_std = 0.072)
NEC for r=1.0 all KL = 0.017 +- 0.064 (in-sample avg dev_std = 0.072)
NEC for r=1.0 all L1 = 0.03 +- 0.089 (in-sample avg dev_std = 0.072)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.627
NEC for r=0.3 class 0.0 = 0.141 +- 0.067 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1.0 = 0.11 +- 0.067 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.044 +- 0.067 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.113 +- 0.115 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
NEC for r=0.6 class 0.0 = 0.114 +- 0.068 (in-sample avg dev_std = 0.116)
NEC for r=0.6 class 1.0 = 0.046 +- 0.068 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all KL = 0.028 +- 0.068 (in-sample avg dev_std = 0.116)
NEC for r=0.6 all L1 = 0.051 +- 0.095 (in-sample avg dev_std = 0.116)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.684
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
NEC for r=0.9 class 0.0 = 0.084 +- 0.068 (in-sample avg dev_std = 0.096)
NEC for r=0.9 class 1.0 = 0.034 +- 0.068 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all KL = 0.023 +- 0.068 (in-sample avg dev_std = 0.096)
NEC for r=0.9 all L1 = 0.038 +- 0.088 (in-sample avg dev_std = 0.096)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.679
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.65
NEC for r=1.0 class 0.0 = 0.076 +- 0.069 (in-sample avg dev_std = 0.096)
NEC for r=1.0 class 1.0 = 0.033 +- 0.069 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all KL = 0.024 +- 0.069 (in-sample avg dev_std = 0.096)
NEC for r=1.0 all L1 = 0.037 +- 0.086 (in-sample avg dev_std = 0.096)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.638
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.624
NEC for r=0.3 class 0.0 = 0.144 +- 0.075 (in-sample avg dev_std = 0.150)
NEC for r=0.3 class 1.0 = 0.113 +- 0.075 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all KL = 0.048 +- 0.075 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all L1 = 0.118 +- 0.119 (in-sample avg dev_std = 0.150)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
NEC for r=0.6 class 0.0 = 0.091 +- 0.075 (in-sample avg dev_std = 0.121)
NEC for r=0.6 class 1.0 = 0.055 +- 0.075 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all KL = 0.034 +- 0.075 (in-sample avg dev_std = 0.121)
NEC for r=0.6 all L1 = 0.061 +- 0.104 (in-sample avg dev_std = 0.121)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.686
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.673
NEC for r=0.9 class 0.0 = 0.072 +- 0.087 (in-sample avg dev_std = 0.107)
NEC for r=0.9 class 1.0 = 0.038 +- 0.087 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all KL = 0.03 +- 0.087 (in-sample avg dev_std = 0.107)
NEC for r=0.9 all L1 = 0.044 +- 0.095 (in-sample avg dev_std = 0.107)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.716
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.682
NEC for r=1.0 class 0.0 = 0.066 +- 0.077 (in-sample avg dev_std = 0.098)
NEC for r=1.0 class 1.0 = 0.038 +- 0.077 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all KL = 0.026 +- 0.077 (in-sample avg dev_std = 0.098)
NEC for r=1.0 all L1 = 0.042 +- 0.093 (in-sample avg dev_std = 0.098)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.964, 0.99, 0.998, 1.0], 'all_L1': [0.949, 0.982, 0.994, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.925, 0.979, 0.992, 1.0], 'all_L1': [0.899, 0.963, 0.987, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.943, 0.978, 0.996, 1.0], 'all_L1': [0.905, 0.955, 0.984, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.925, 0.974, 0.995, 1.0], 'all_L1': [0.875, 0.949, 0.987, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.971, 0.991, 1.0], 'all_L1': [0.859, 0.953, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.01, 0.005, 0.005, 0.006], 'all_L1': [0.03, 0.014, 0.013, 0.016]}), defaultdict(<class 'list'>, {'all_KL': [0.027, 0.017, 0.02, 0.022], 'all_L1': [0.061, 0.032, 0.03, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.023, 0.019, 0.031, 0.026], 'all_L1': [0.064, 0.04, 0.049, 0.046]}), defaultdict(<class 'list'>, {'all_KL': [0.03, 0.021, 0.029, 0.022], 'all_L1': [0.081, 0.045, 0.038, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.023, 0.022, 0.021], 'all_L1': [0.093, 0.04, 0.035, 0.036]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.959, 0.991, 0.999, 1.0], 'all_L1': [0.944, 0.983, 0.995, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.915, 0.974, 0.993, 1.0], 'all_L1': [0.893, 0.968, 0.987, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.947, 0.979, 0.995, 1.0], 'all_L1': [0.91, 0.957, 0.985, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.93, 0.974, 0.996, 1.0], 'all_L1': [0.883, 0.953, 0.988, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.916, 0.969, 0.996, 1.0], 'all_L1': [0.864, 0.95, 0.986, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.01, 0.006, 0.006, 0.006], 'all_L1': [0.032, 0.014, 0.014, 0.014]}), defaultdict(<class 'list'>, {'all_KL': [0.03, 0.015, 0.018, 0.018], 'all_L1': [0.064, 0.026, 0.029, 0.03]}), defaultdict(<class 'list'>, {'all_KL': [0.021, 0.015, 0.027, 0.027], 'all_L1': [0.059, 0.036, 0.043, 0.043]}), defaultdict(<class 'list'>, {'all_KL': [0.029, 0.018, 0.02, 0.017], 'all_L1': [0.077, 0.037, 0.031, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.036, 0.023, 0.022, 0.017], 'all_L1': [0.091, 0.039, 0.033, 0.03]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.954, 0.989, 0.998, 1.0], 'all_L1': [0.931, 0.981, 0.994, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.909, 0.968, 0.994, 1.0], 'all_L1': [0.875, 0.956, 0.986, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.935, 0.973, 0.994, 1.0], 'all_L1': [0.885, 0.936, 0.98, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.966, 0.995, 1.0], 'all_L1': [0.861, 0.94, 0.986, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.905, 0.962, 0.995, 1.0], 'all_L1': [0.837, 0.937, 0.985, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.014, 0.006, 0.009, 0.008], 'all_L1': [0.041, 0.015, 0.017, 0.017]}), defaultdict(<class 'list'>, {'all_KL': [0.032, 0.019, 0.02, 0.024], 'all_L1': [0.078, 0.033, 0.033, 0.038]}), defaultdict(<class 'list'>, {'all_KL': [0.026, 0.021, 0.027, 0.027], 'all_L1': [0.075, 0.052, 0.054, 0.053]}), defaultdict(<class 'list'>, {'all_KL': [0.035, 0.027, 0.023, 0.024], 'all_L1': [0.093, 0.054, 0.036, 0.039]}), defaultdict(<class 'list'>, {'all_KL': [0.044, 0.028, 0.023, 0.024], 'all_L1': [0.113, 0.051, 0.038, 0.037]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.949, 0.987, 0.997, 1.0], 'all_L1': [0.924, 0.975, 0.99, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.967, 0.992, 1.0], 'all_L1': [0.869, 0.95, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.932, 0.97, 0.992, 1.0], 'all_L1': [0.88, 0.938, 0.974, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.918, 0.968, 0.993, 1.0], 'all_L1': [0.853, 0.935, 0.983, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.904, 0.954, 0.992, 1.0], 'all_L1': [0.833, 0.926, 0.982, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.015, 0.01, 0.009, 0.008], 'all_L1': [0.045, 0.022, 0.022, 0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.039, 0.023, 0.022, 0.025], 'all_L1': [0.09, 0.042, 0.038, 0.041]}), defaultdict(<class 'list'>, {'all_KL': [0.029, 0.025, 0.031, 0.03], 'all_L1': [0.08, 0.056, 0.059, 0.062]}), defaultdict(<class 'list'>, {'all_KL': [0.038, 0.03, 0.024, 0.027], 'all_L1': [0.102, 0.058, 0.044, 0.044]}), defaultdict(<class 'list'>, {'all_KL': [0.048, 0.034, 0.03, 0.026], 'all_L1': [0.118, 0.061, 0.044, 0.042]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.897 +- 0.031, 0.960 +- 0.012, 0.987 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.934 +- 0.018, 0.978 +- 0.006, 0.994 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.670 +- 0.019, 0.784 +- 0.024, 0.859 +- 0.027
nec class all_L1  =  0.066 +- 0.021, 0.034 +- 0.011, 0.033 +- 0.012, 0.033 +- 0.010
nec class all_KL  =  0.025 +- 0.009, 0.017 +- 0.006, 0.021 +- 0.009, 0.019 +- 0.007
nec_acc_int  =  0.725 +- 0.022, 0.774 +- 0.020, 0.817 +- 0.023, 0.824 +- 0.026

Eval split id_val
suff++ class all_L1  =  0.899 +- 0.027, 0.962 +- 0.012, 0.988 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.933 +- 0.017, 0.977 +- 0.007, 0.996 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.677 +- 0.017, 0.796 +- 0.016, 0.849 +- 0.028
nec class all_L1  =  0.065 +- 0.020, 0.030 +- 0.009, 0.030 +- 0.009, 0.029 +- 0.009
nec class all_KL  =  0.025 +- 0.009, 0.015 +- 0.006, 0.019 +- 0.007, 0.017 +- 0.007
nec_acc_int  =  0.733 +- 0.021, 0.795 +- 0.021, 0.825 +- 0.025, 0.829 +- 0.029

Eval split val
suff++ class all_L1  =  0.878 +- 0.031, 0.950 +- 0.017, 0.986 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.925 +- 0.018, 0.972 +- 0.009, 0.995 +- 0.001, 1.000 +- 0.000
suff++_acc_int  =  0.592 +- 0.021, 0.642 +- 0.029, 0.653 +- 0.026
nec class all_L1  =  0.080 +- 0.024, 0.041 +- 0.015, 0.036 +- 0.012, 0.037 +- 0.011
nec class all_KL  =  0.030 +- 0.010, 0.020 +- 0.008, 0.020 +- 0.006, 0.021 +- 0.007
nec_acc_int  =  0.627 +- 0.031, 0.643 +- 0.026, 0.637 +- 0.026, 0.641 +- 0.016

Eval split test
suff++ class all_L1  =  0.872 +- 0.031, 0.945 +- 0.017, 0.982 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.923 +- 0.016, 0.969 +- 0.011, 0.993 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.599 +- 0.010, 0.661 +- 0.012, 0.691 +- 0.011
nec class all_L1  =  0.087 +- 0.025, 0.048 +- 0.014, 0.041 +- 0.012, 0.042 +- 0.013
nec class all_KL  =  0.034 +- 0.011, 0.024 +- 0.008, 0.023 +- 0.008, 0.023 +- 0.008
nec_acc_int  =  0.631 +- 0.021, 0.659 +- 0.017, 0.676 +- 0.007, 0.677 +- 0.013


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.482 +- 0.005, 0.497 +- 0.001, 0.510 +- 0.004, 0.516 +- 0.005
Faith. Armon (L1)= 		  =  0.122 +- 0.037, 0.066 +- 0.021, 0.064 +- 0.022, 0.063 +- 0.018
Faith. GMean (L1)= 	  =  0.238 +- 0.039, 0.178 +- 0.032, 0.177 +- 0.035, 0.179 +- 0.029
Faith. Aritm (KL)= 		  =  0.479 +- 0.005, 0.498 +- 0.001, 0.508 +- 0.004, 0.510 +- 0.003
Faith. Armon (KL)= 		  =  0.049 +- 0.017, 0.033 +- 0.012, 0.042 +- 0.018, 0.038 +- 0.013
Faith. GMean (KL)= 	  =  0.151 +- 0.029, 0.126 +- 0.028, 0.141 +- 0.038, 0.136 +- 0.030

Eval split id_val
Faith. Aritm (L1)= 		  =  0.482 +- 0.004, 0.496 +- 0.001, 0.509 +- 0.003, 0.515 +- 0.005
Faith. Armon (L1)= 		  =  0.120 +- 0.034, 0.059 +- 0.018, 0.058 +- 0.018, 0.057 +- 0.017
Faith. GMean (L1)= 	  =  0.237 +- 0.036, 0.168 +- 0.028, 0.170 +- 0.029, 0.168 +- 0.029
Faith. Aritm (KL)= 		  =  0.479 +- 0.005, 0.496 +- 0.001, 0.507 +- 0.003, 0.508 +- 0.003
Faith. Armon (KL)= 		  =  0.049 +- 0.017, 0.030 +- 0.011, 0.036 +- 0.014, 0.033 +- 0.013
Faith. GMean (KL)= 	  =  0.150 +- 0.029, 0.120 +- 0.024, 0.133 +- 0.029, 0.127 +- 0.028

Eval split val
Faith. Aritm (L1)= 		  =  0.479 +- 0.004, 0.495 +- 0.002, 0.511 +- 0.004, 0.518 +- 0.006
Faith. Armon (L1)= 		  =  0.145 +- 0.040, 0.078 +- 0.028, 0.068 +- 0.022, 0.071 +- 0.022
Faith. GMean (L1)= 	  =  0.261 +- 0.037, 0.193 +- 0.040, 0.184 +- 0.032, 0.189 +- 0.032
Faith. Aritm (KL)= 		  =  0.478 +- 0.005, 0.496 +- 0.001, 0.508 +- 0.002, 0.511 +- 0.003
Faith. Armon (KL)= 		  =  0.058 +- 0.019, 0.039 +- 0.015, 0.040 +- 0.012, 0.042 +- 0.013
Faith. GMean (KL)= 	  =  0.164 +- 0.028, 0.136 +- 0.032, 0.140 +- 0.024, 0.144 +- 0.027

Eval split test
Faith. Aritm (L1)= 		  =  0.479 +- 0.003, 0.496 +- 0.002, 0.512 +- 0.004, 0.521 +- 0.007
Faith. Armon (L1)= 		  =  0.157 +- 0.041, 0.091 +- 0.026, 0.079 +- 0.022, 0.080 +- 0.024
Faith. GMean (L1)= 	  =  0.271 +- 0.037, 0.209 +- 0.034, 0.199 +- 0.030, 0.202 +- 0.033
Faith. Aritm (KL)= 		  =  0.478 +- 0.003, 0.497 +- 0.002, 0.508 +- 0.003, 0.512 +- 0.004
Faith. Armon (KL)= 		  =  0.065 +- 0.021, 0.047 +- 0.016, 0.045 +- 0.015, 0.045 +- 0.015
Faith. GMean (KL)= 	  =  0.173 +- 0.030, 0.151 +- 0.028, 0.149 +- 0.029, 0.149 +- 0.030
Computed for split load_split = id



Completed in  0:32:22.202385  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:30:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:30:05 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:30:37 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:30:48 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:30:58 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:15 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:31:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 89...
[0m[1;37mINFO[0m: [1mCheckpoint 89: 
-----------------------------------
Train ROC-AUC: 0.9464
Train Loss: 0.1872
ID Validation ROC-AUC: 0.9160
ID Validation Loss: 0.2460
ID Test ROC-AUC: 0.9187
ID Test Loss: 0.2462
OOD Validation ROC-AUC: 0.6716
OOD Validation Loss: 0.4065
OOD Test ROC-AUC: 0.7197
OOD Test Loss: 0.5629

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 64...
[0m[1;37mINFO[0m: [1mCheckpoint 64: 
-----------------------------------
Train ROC-AUC: 0.9330
Train Loss: 0.2258
ID Validation ROC-AUC: 0.9076
ID Validation Loss: 0.2632
ID Test ROC-AUC: 0.9096
ID Test Loss: 0.2658
OOD Validation ROC-AUC: 0.6846
OOD Validation Loss: 0.3469
OOD Test ROC-AUC: 0.7230
OOD Test Loss: 0.5378

[0m[1;37mINFO[0m: [1mChartInfo 0.9187 0.7197 0.9096 0.7230 0.9076 0.6846[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:31:32 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:31:38 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:31:42 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:31:46 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.718
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 798
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.645
SUFF++ for r=0.3 class 0.0 = 0.786 +- 0.115 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.3 class 1.0 = 0.759 +- 0.115 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.3 all KL = 0.907 +- 0.115 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.3 all L1 = 0.762 +- 0.112 (in-sample avg dev_std = 0.225)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.724
SUFF++ for r=0.6 class 0.0 = 0.76 +- 0.127 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 class 1.0 = 0.77 +- 0.127 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all KL = 0.883 +- 0.127 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.110 (in-sample avg dev_std = 0.246)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.88 +- 0.046 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 class 1.0 = 0.939 +- 0.046 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all KL = 0.973 +- 0.046 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.9 all L1 = 0.932 +- 0.078 (in-sample avg dev_std = 0.141)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.658
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 798
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.586
SUFF++ for r=0.3 class 0.0 = 0.794 +- 0.123 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 class 1.0 = 0.769 +- 0.123 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all KL = 0.909 +- 0.123 (in-sample avg dev_std = 0.211)
SUFF++ for r=0.3 all L1 = 0.772 +- 0.115 (in-sample avg dev_std = 0.211)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.738
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.692
SUFF++ for r=0.6 class 0.0 = 0.757 +- 0.109 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 class 1.0 = 0.766 +- 0.109 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all KL = 0.887 +- 0.109 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all L1 = 0.765 +- 0.107 (in-sample avg dev_std = 0.242)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0.0 = 0.864 +- 0.050 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.050 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.97 +- 0.050 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.926 +- 0.089 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.577
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 798
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.553
SUFF++ for r=0.3 class 0.0 = 0.81 +- 0.069 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 class 1.0 = 0.8 +- 0.069 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 all KL = 0.942 +- 0.069 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.3 all L1 = 0.801 +- 0.094 (in-sample avg dev_std = 0.186)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.538
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.585
SUFF++ for r=0.6 class 0.0 = 0.764 +- 0.101 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 1.0 = 0.766 +- 0.101 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all KL = 0.903 +- 0.101 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.107 (in-sample avg dev_std = 0.238)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.635
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.629
SUFF++ for r=0.9 class 0.0 = 0.884 +- 0.051 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1.0 = 0.9 +- 0.051 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.962 +- 0.051 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.899 +- 0.092 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.575
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 797
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.545
SUFF++ for r=0.3 class 0.0 = 0.817 +- 0.091 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 class 1.0 = 0.783 +- 0.091 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 all KL = 0.931 +- 0.091 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 all L1 = 0.788 +- 0.105 (in-sample avg dev_std = 0.191)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.583
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
SUFF++ for r=0.6 class 0.0 = 0.748 +- 0.116 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 class 1.0 = 0.758 +- 0.116 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 all KL = 0.887 +- 0.116 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.6 all L1 = 0.756 +- 0.112 (in-sample avg dev_std = 0.251)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.674
SUFF++ for r=0.9 class 0.0 = 0.887 +- 0.064 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1.0 = 0.902 +- 0.064 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.961 +- 0.064 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.899 +- 0.098 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.717
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.684
NEC for r=0.3 class 0.0 = 0.181 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 class 1.0 = 0.216 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all KL = 0.08 +- 0.121 (in-sample avg dev_std = 0.163)
NEC for r=0.3 all L1 = 0.212 +- 0.134 (in-sample avg dev_std = 0.163)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.745
NEC for r=0.6 class 0.0 = 0.184 +- 0.138 (in-sample avg dev_std = 0.193)
NEC for r=0.6 class 1.0 = 0.199 +- 0.138 (in-sample avg dev_std = 0.193)
NEC for r=0.6 all KL = 0.097 +- 0.138 (in-sample avg dev_std = 0.193)
NEC for r=0.6 all L1 = 0.197 +- 0.124 (in-sample avg dev_std = 0.193)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.885
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.836
NEC for r=0.9 class 0.0 = 0.167 +- 0.124 (in-sample avg dev_std = 0.185)
NEC for r=0.9 class 1.0 = 0.135 +- 0.124 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all KL = 0.083 +- 0.124 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all L1 = 0.139 +- 0.136 (in-sample avg dev_std = 0.185)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.849
NEC for r=1.0 class 0.0 = 0.17 +- 0.129 (in-sample avg dev_std = 0.188)
NEC for r=1.0 class 1.0 = 0.104 +- 0.129 (in-sample avg dev_std = 0.188)
NEC for r=1.0 all KL = 0.075 +- 0.129 (in-sample avg dev_std = 0.188)
NEC for r=1.0 all L1 = 0.112 +- 0.133 (in-sample avg dev_std = 0.188)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.645
NEC for r=0.3 class 0.0 = 0.199 +- 0.134 (in-sample avg dev_std = 0.156)
NEC for r=0.3 class 1.0 = 0.218 +- 0.134 (in-sample avg dev_std = 0.156)
NEC for r=0.3 all KL = 0.085 +- 0.134 (in-sample avg dev_std = 0.156)
NEC for r=0.3 all L1 = 0.215 +- 0.141 (in-sample avg dev_std = 0.156)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.738
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.721
NEC for r=0.6 class 0.0 = 0.187 +- 0.115 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 1.0 = 0.205 +- 0.115 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all KL = 0.094 +- 0.115 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all L1 = 0.203 +- 0.116 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.862
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.831
NEC for r=0.9 class 0.0 = 0.167 +- 0.123 (in-sample avg dev_std = 0.191)
NEC for r=0.9 class 1.0 = 0.139 +- 0.123 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all KL = 0.086 +- 0.123 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all L1 = 0.142 +- 0.134 (in-sample avg dev_std = 0.191)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0.0 = 0.192 +- 0.129 (in-sample avg dev_std = 0.182)
NEC for r=1.0 class 1.0 = 0.1 +- 0.129 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all KL = 0.073 +- 0.129 (in-sample avg dev_std = 0.182)
NEC for r=1.0 all L1 = 0.11 +- 0.132 (in-sample avg dev_std = 0.182)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.554
NEC for r=0.3 class 0.0 = 0.19 +- 0.092 (in-sample avg dev_std = 0.139)
NEC for r=0.3 class 1.0 = 0.186 +- 0.092 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all KL = 0.055 +- 0.092 (in-sample avg dev_std = 0.139)
NEC for r=0.3 all L1 = 0.186 +- 0.120 (in-sample avg dev_std = 0.139)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.538
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.543
NEC for r=0.6 class 0.0 = 0.23 +- 0.126 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1.0 = 0.194 +- 0.126 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.081 +- 0.126 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.197 +- 0.126 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.635
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.607
NEC for r=0.9 class 0.0 = 0.199 +- 0.109 (in-sample avg dev_std = 0.207)
NEC for r=0.9 class 1.0 = 0.174 +- 0.109 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all KL = 0.088 +- 0.109 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all L1 = 0.176 +- 0.125 (in-sample avg dev_std = 0.207)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.664
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.644
NEC for r=1.0 class 0.0 = 0.176 +- 0.106 (in-sample avg dev_std = 0.196)
NEC for r=1.0 class 1.0 = 0.144 +- 0.106 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all KL = 0.076 +- 0.106 (in-sample avg dev_std = 0.196)
NEC for r=1.0 all L1 = 0.147 +- 0.125 (in-sample avg dev_std = 0.196)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.573
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
NEC for r=0.3 class 0.0 = 0.183 +- 0.107 (in-sample avg dev_std = 0.150)
NEC for r=0.3 class 1.0 = 0.214 +- 0.107 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all KL = 0.069 +- 0.107 (in-sample avg dev_std = 0.150)
NEC for r=0.3 all L1 = 0.208 +- 0.128 (in-sample avg dev_std = 0.150)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.583
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.609
NEC for r=0.6 class 0.0 = 0.231 +- 0.145 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 1.0 = 0.216 +- 0.145 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all KL = 0.103 +- 0.145 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all L1 = 0.218 +- 0.137 (in-sample avg dev_std = 0.200)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.681
NEC for r=0.9 class 0.0 = 0.169 +- 0.121 (in-sample avg dev_std = 0.193)
NEC for r=0.9 class 1.0 = 0.168 +- 0.121 (in-sample avg dev_std = 0.193)
NEC for r=0.9 all KL = 0.083 +- 0.121 (in-sample avg dev_std = 0.193)
NEC for r=0.9 all L1 = 0.169 +- 0.128 (in-sample avg dev_std = 0.193)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.699
NEC for r=1.0 class 0.0 = 0.166 +- 0.112 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1.0 = 0.145 +- 0.112 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.075 +- 0.112 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.148 +- 0.133 (in-sample avg dev_std = 0.191)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:36:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:36:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:37:26 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:37:36 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:37:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:03 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:19 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:19 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:19 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:19 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ROC-AUC: 0.9666
Train Loss: 0.1624
ID Validation ROC-AUC: 0.9160
ID Validation Loss: 0.3137
ID Test ROC-AUC: 0.9213
ID Test Loss: 0.3047
OOD Validation ROC-AUC: 0.6610
OOD Validation Loss: 0.5328
OOD Test ROC-AUC: 0.7051
OOD Test Loss: 0.7594

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9059
Train Loss: 0.2695
ID Validation ROC-AUC: 0.8929
ID Validation Loss: 0.2843
ID Test ROC-AUC: 0.8985
ID Test Loss: 0.2854
OOD Validation ROC-AUC: 0.6846
OOD Validation Loss: 0.3103
OOD Test ROC-AUC: 0.7255
OOD Test Loss: 0.5013

[0m[1;37mINFO[0m: [1mChartInfo 0.9213 0.7051 0.8985 0.7255 0.8929 0.6846[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:38:20 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:38:24 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:38:28 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:38:32 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.621
SUFF++ for r=0.3 class 0.0 = 0.662 +- 0.144 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.3 class 1.0 = 0.701 +- 0.144 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.3 all KL = 0.822 +- 0.144 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.3 all L1 = 0.696 +- 0.127 (in-sample avg dev_std = 0.331)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.807
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.751
SUFF++ for r=0.6 class 0.0 = 0.616 +- 0.176 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.6 class 1.0 = 0.849 +- 0.176 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.6 all KL = 0.861 +- 0.176 (in-sample avg dev_std = 0.253)
SUFF++ for r=0.6 all L1 = 0.822 +- 0.199 (in-sample avg dev_std = 0.253)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0.0 = 0.721 +- 0.106 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.106 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.958 +- 0.106 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.138 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.62
SUFF++ for r=0.3 class 0.0 = 0.676 +- 0.136 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 class 1.0 = 0.71 +- 0.136 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all KL = 0.83 +- 0.136 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.3 all L1 = 0.706 +- 0.135 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.739
SUFF++ for r=0.6 class 0.0 = 0.668 +- 0.175 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 class 1.0 = 0.847 +- 0.175 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all KL = 0.864 +- 0.175 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all L1 = 0.826 +- 0.197 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.837
SUFF++ for r=0.9 class 0.0 = 0.774 +- 0.105 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.105 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all KL = 0.958 +- 0.105 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.136 (in-sample avg dev_std = 0.125)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.494
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.521
SUFF++ for r=0.3 class 0.0 = 0.674 +- 0.148 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 class 1.0 = 0.682 +- 0.148 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all KL = 0.813 +- 0.148 (in-sample avg dev_std = 0.344)
SUFF++ for r=0.3 all L1 = 0.681 +- 0.130 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.605
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.622
SUFF++ for r=0.6 class 0.0 = 0.696 +- 0.206 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 class 1.0 = 0.768 +- 0.206 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all KL = 0.809 +- 0.206 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.6 all L1 = 0.762 +- 0.209 (in-sample avg dev_std = 0.315)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0.0 = 0.816 +- 0.120 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 1.0 = 0.914 +- 0.120 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all KL = 0.942 +- 0.120 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all L1 = 0.906 +- 0.154 (in-sample avg dev_std = 0.160)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0.0 = 0.692 +- 0.150 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 class 1.0 = 0.682 +- 0.150 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all KL = 0.813 +- 0.150 (in-sample avg dev_std = 0.341)
SUFF++ for r=0.3 all L1 = 0.684 +- 0.130 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.642
SUFF++ for r=0.6 class 0.0 = 0.667 +- 0.186 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 class 1.0 = 0.765 +- 0.186 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 all KL = 0.808 +- 0.186 (in-sample avg dev_std = 0.322)
SUFF++ for r=0.6 all L1 = 0.749 +- 0.204 (in-sample avg dev_std = 0.322)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.7
SUFF++ for r=0.9 class 0.0 = 0.827 +- 0.133 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 class 1.0 = 0.903 +- 0.133 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all KL = 0.929 +- 0.133 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all L1 = 0.89 +- 0.168 (in-sample avg dev_std = 0.180)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
NEC for r=0.3 class 0.0 = 0.325 +- 0.152 (in-sample avg dev_std = 0.271)
NEC for r=0.3 class 1.0 = 0.281 +- 0.152 (in-sample avg dev_std = 0.271)
NEC for r=0.3 all KL = 0.157 +- 0.152 (in-sample avg dev_std = 0.271)
NEC for r=0.3 all L1 = 0.286 +- 0.155 (in-sample avg dev_std = 0.271)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.807
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.789
NEC for r=0.6 class 0.0 = 0.308 +- 0.178 (in-sample avg dev_std = 0.233)
NEC for r=0.6 class 1.0 = 0.146 +- 0.178 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all KL = 0.126 +- 0.178 (in-sample avg dev_std = 0.233)
NEC for r=0.6 all L1 = 0.165 +- 0.179 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.885
NEC for r=0.9 class 0.0 = 0.244 +- 0.138 (in-sample avg dev_std = 0.171)
NEC for r=0.9 class 1.0 = 0.051 +- 0.138 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all KL = 0.058 +- 0.138 (in-sample avg dev_std = 0.171)
NEC for r=0.9 all L1 = 0.074 +- 0.138 (in-sample avg dev_std = 0.171)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.927
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.882
NEC for r=1.0 class 0.0 = 0.24 +- 0.114 (in-sample avg dev_std = 0.147)
NEC for r=1.0 class 1.0 = 0.037 +- 0.114 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all KL = 0.044 +- 0.114 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all L1 = 0.061 +- 0.125 (in-sample avg dev_std = 0.147)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.642
NEC for r=0.3 class 0.0 = 0.342 +- 0.155 (in-sample avg dev_std = 0.261)
NEC for r=0.3 class 1.0 = 0.275 +- 0.155 (in-sample avg dev_std = 0.261)
NEC for r=0.3 all KL = 0.156 +- 0.155 (in-sample avg dev_std = 0.261)
NEC for r=0.3 all L1 = 0.283 +- 0.160 (in-sample avg dev_std = 0.261)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.787
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.814
NEC for r=0.6 class 0.0 = 0.316 +- 0.176 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 1.0 = 0.149 +- 0.176 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all KL = 0.129 +- 0.176 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all L1 = 0.169 +- 0.183 (in-sample avg dev_std = 0.235)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.866
NEC for r=0.9 class 0.0 = 0.227 +- 0.127 (in-sample avg dev_std = 0.154)
NEC for r=0.9 class 1.0 = 0.053 +- 0.127 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all KL = 0.055 +- 0.127 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all L1 = 0.073 +- 0.133 (in-sample avg dev_std = 0.154)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.893
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.192 +- 0.117 (in-sample avg dev_std = 0.149)
NEC for r=1.0 class 1.0 = 0.041 +- 0.117 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all KL = 0.044 +- 0.117 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all L1 = 0.059 +- 0.120 (in-sample avg dev_std = 0.149)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.494
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.525
NEC for r=0.3 class 0.0 = 0.309 +- 0.164 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 1.0 = 0.301 +- 0.164 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all KL = 0.168 +- 0.164 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all L1 = 0.302 +- 0.159 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.605
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
NEC for r=0.6 class 0.0 = 0.284 +- 0.190 (in-sample avg dev_std = 0.273)
NEC for r=0.6 class 1.0 = 0.209 +- 0.190 (in-sample avg dev_std = 0.273)
NEC for r=0.6 all KL = 0.162 +- 0.190 (in-sample avg dev_std = 0.273)
NEC for r=0.6 all L1 = 0.216 +- 0.185 (in-sample avg dev_std = 0.273)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.677
NEC for r=0.9 class 0.0 = 0.225 +- 0.159 (in-sample avg dev_std = 0.207)
NEC for r=0.9 class 1.0 = 0.103 +- 0.159 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all KL = 0.089 +- 0.159 (in-sample avg dev_std = 0.207)
NEC for r=0.9 all L1 = 0.113 +- 0.162 (in-sample avg dev_std = 0.207)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.684
NEC for r=1.0 class 0.0 = 0.195 +- 0.133 (in-sample avg dev_std = 0.177)
NEC for r=1.0 class 1.0 = 0.075 +- 0.133 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all KL = 0.062 +- 0.133 (in-sample avg dev_std = 0.177)
NEC for r=1.0 all L1 = 0.085 +- 0.142 (in-sample avg dev_std = 0.177)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
NEC for r=0.3 class 0.0 = 0.305 +- 0.169 (in-sample avg dev_std = 0.295)
NEC for r=0.3 class 1.0 = 0.313 +- 0.169 (in-sample avg dev_std = 0.295)
NEC for r=0.3 all KL = 0.18 +- 0.169 (in-sample avg dev_std = 0.295)
NEC for r=0.3 all L1 = 0.312 +- 0.158 (in-sample avg dev_std = 0.295)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.663
NEC for r=0.6 class 0.0 = 0.283 +- 0.184 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 1.0 = 0.221 +- 0.184 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all KL = 0.167 +- 0.184 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all L1 = 0.231 +- 0.184 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.711
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.701
NEC for r=0.9 class 0.0 = 0.192 +- 0.164 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 1.0 = 0.109 +- 0.164 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all KL = 0.096 +- 0.164 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all L1 = 0.123 +- 0.165 (in-sample avg dev_std = 0.212)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.719
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.705
NEC for r=1.0 class 0.0 = 0.159 +- 0.141 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 1.0 = 0.082 +- 0.141 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all KL = 0.068 +- 0.141 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all L1 = 0.095 +- 0.150 (in-sample avg dev_std = 0.175)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:44:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:44:05 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:44:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:44:48 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:44:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:15 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ROC-AUC: 0.9448
Train Loss: 0.1884
ID Validation ROC-AUC: 0.9180
ID Validation Loss: 0.2347
ID Test ROC-AUC: 0.9184
ID Test Loss: 0.2386
OOD Validation ROC-AUC: 0.6600
OOD Validation Loss: 0.3835
OOD Test ROC-AUC: 0.7111
OOD Test Loss: 0.5336

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 31...
[0m[1;37mINFO[0m: [1mCheckpoint 31: 
-----------------------------------
Train ROC-AUC: 0.9149
Train Loss: 0.2364
ID Validation ROC-AUC: 0.8999
ID Validation Loss: 0.2568
ID Test ROC-AUC: 0.9020
ID Test Loss: 0.2587
OOD Validation ROC-AUC: 0.6854
OOD Validation Loss: 0.3297
OOD Test ROC-AUC: 0.7162
OOD Test Loss: 0.5067

[0m[1;37mINFO[0m: [1mChartInfo 0.9184 0.7111 0.9020 0.7162 0.8999 0.6854[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:45:32 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:45:36 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:45:40 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:45:44 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.622
SUFF++ for r=0.3 class 0.0 = 0.812 +- 0.072 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 class 1.0 = 0.786 +- 0.072 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 all KL = 0.934 +- 0.072 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 all L1 = 0.789 +- 0.079 (in-sample avg dev_std = 0.204)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.744
SUFF++ for r=0.6 class 0.0 = 0.77 +- 0.101 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 1.0 = 0.802 +- 0.101 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all KL = 0.901 +- 0.101 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.118 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.834
SUFF++ for r=0.9 class 0.0 = 0.823 +- 0.072 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 class 1.0 = 0.946 +- 0.072 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all KL = 0.966 +- 0.072 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.9 all L1 = 0.931 +- 0.102 (in-sample avg dev_std = 0.124)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.664
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.629
SUFF++ for r=0.3 class 0.0 = 0.799 +- 0.072 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 class 1.0 = 0.783 +- 0.072 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all KL = 0.932 +- 0.072 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.3 all L1 = 0.784 +- 0.082 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.828
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.748
SUFF++ for r=0.6 class 0.0 = 0.765 +- 0.092 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 class 1.0 = 0.808 +- 0.092 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all KL = 0.904 +- 0.092 (in-sample avg dev_std = 0.209)
SUFF++ for r=0.6 all L1 = 0.803 +- 0.116 (in-sample avg dev_std = 0.209)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.844
SUFF++ for r=0.9 class 0.0 = 0.838 +- 0.051 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.051 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all KL = 0.975 +- 0.051 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.093 (in-sample avg dev_std = 0.103)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.551
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.51
SUFF++ for r=0.3 class 0.0 = 0.781 +- 0.059 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 class 1.0 = 0.799 +- 0.059 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 all KL = 0.945 +- 0.059 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.3 all L1 = 0.797 +- 0.079 (in-sample avg dev_std = 0.191)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.593
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.593
SUFF++ for r=0.6 class 0.0 = 0.786 +- 0.093 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 class 1.0 = 0.773 +- 0.093 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all KL = 0.899 +- 0.093 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all L1 = 0.774 +- 0.103 (in-sample avg dev_std = 0.225)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.667
SUFF++ for r=0.9 class 0.0 = 0.879 +- 0.053 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 class 1.0 = 0.915 +- 0.053 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all KL = 0.964 +- 0.053 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all L1 = 0.912 +- 0.100 (in-sample avg dev_std = 0.119)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.592
SUFF++ for r=0.3 class 0.0 = 0.812 +- 0.060 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.3 class 1.0 = 0.789 +- 0.060 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.3 all KL = 0.94 +- 0.060 (in-sample avg dev_std = 0.195)
SUFF++ for r=0.3 all L1 = 0.793 +- 0.077 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.657
SUFF++ for r=0.6 class 0.0 = 0.763 +- 0.095 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 1.0 = 0.787 +- 0.095 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all KL = 0.902 +- 0.095 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all L1 = 0.783 +- 0.107 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.696
SUFF++ for r=0.9 class 0.0 = 0.87 +- 0.076 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 1.0 = 0.912 +- 0.076 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all KL = 0.956 +- 0.076 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all L1 = 0.905 +- 0.111 (in-sample avg dev_std = 0.133)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.641
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.608
NEC for r=0.3 class 0.0 = 0.173 +- 0.091 (in-sample avg dev_std = 0.157)
NEC for r=0.3 class 1.0 = 0.201 +- 0.091 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all KL = 0.059 +- 0.091 (in-sample avg dev_std = 0.157)
NEC for r=0.3 all L1 = 0.198 +- 0.102 (in-sample avg dev_std = 0.157)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.758
NEC for r=0.6 class 0.0 = 0.195 +- 0.126 (in-sample avg dev_std = 0.188)
NEC for r=0.6 class 1.0 = 0.184 +- 0.126 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all KL = 0.095 +- 0.126 (in-sample avg dev_std = 0.188)
NEC for r=0.6 all L1 = 0.186 +- 0.114 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.829
NEC for r=0.9 class 0.0 = 0.173 +- 0.119 (in-sample avg dev_std = 0.146)
NEC for r=0.9 class 1.0 = 0.083 +- 0.119 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all KL = 0.068 +- 0.119 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all L1 = 0.093 +- 0.119 (in-sample avg dev_std = 0.146)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.845
NEC for r=1.0 class 0.0 = 0.156 +- 0.100 (in-sample avg dev_std = 0.133)
NEC for r=1.0 class 1.0 = 0.061 +- 0.100 (in-sample avg dev_std = 0.133)
NEC for r=1.0 all KL = 0.049 +- 0.100 (in-sample avg dev_std = 0.133)
NEC for r=1.0 all L1 = 0.072 +- 0.110 (in-sample avg dev_std = 0.133)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.664
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0.0 = 0.167 +- 0.083 (in-sample avg dev_std = 0.152)
NEC for r=0.3 class 1.0 = 0.198 +- 0.083 (in-sample avg dev_std = 0.152)
NEC for r=0.3 all KL = 0.056 +- 0.083 (in-sample avg dev_std = 0.152)
NEC for r=0.3 all L1 = 0.194 +- 0.101 (in-sample avg dev_std = 0.152)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.828
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.793
NEC for r=0.6 class 0.0 = 0.183 +- 0.112 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 1.0 = 0.179 +- 0.112 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all KL = 0.086 +- 0.112 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all L1 = 0.18 +- 0.112 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.864
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.841
NEC for r=0.9 class 0.0 = 0.194 +- 0.104 (in-sample avg dev_std = 0.136)
NEC for r=0.9 class 1.0 = 0.074 +- 0.104 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all KL = 0.059 +- 0.104 (in-sample avg dev_std = 0.136)
NEC for r=0.9 all L1 = 0.088 +- 0.112 (in-sample avg dev_std = 0.136)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.883
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.85
NEC for r=1.0 class 0.0 = 0.158 +- 0.101 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1.0 = 0.055 +- 0.101 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.045 +- 0.101 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.067 +- 0.102 (in-sample avg dev_std = 0.123)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.551
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.545
NEC for r=0.3 class 0.0 = 0.195 +- 0.060 (in-sample avg dev_std = 0.143)
NEC for r=0.3 class 1.0 = 0.182 +- 0.060 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all KL = 0.043 +- 0.060 (in-sample avg dev_std = 0.143)
NEC for r=0.3 all L1 = 0.183 +- 0.093 (in-sample avg dev_std = 0.143)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.593
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
NEC for r=0.6 class 0.0 = 0.196 +- 0.101 (in-sample avg dev_std = 0.190)
NEC for r=0.6 class 1.0 = 0.206 +- 0.101 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all KL = 0.084 +- 0.101 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all L1 = 0.205 +- 0.111 (in-sample avg dev_std = 0.190)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.678
NEC for r=0.9 class 0.0 = 0.156 +- 0.113 (in-sample avg dev_std = 0.159)
NEC for r=0.9 class 1.0 = 0.117 +- 0.113 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all KL = 0.076 +- 0.113 (in-sample avg dev_std = 0.159)
NEC for r=0.9 all L1 = 0.121 +- 0.121 (in-sample avg dev_std = 0.159)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.698
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0.0 = 0.138 +- 0.085 (in-sample avg dev_std = 0.138)
NEC for r=1.0 class 1.0 = 0.09 +- 0.085 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all KL = 0.055 +- 0.085 (in-sample avg dev_std = 0.138)
NEC for r=1.0 all L1 = 0.094 +- 0.105 (in-sample avg dev_std = 0.138)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.648
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.573
NEC for r=0.3 class 0.0 = 0.17 +- 0.087 (in-sample avg dev_std = 0.156)
NEC for r=0.3 class 1.0 = 0.202 +- 0.087 (in-sample avg dev_std = 0.156)
NEC for r=0.3 all KL = 0.056 +- 0.087 (in-sample avg dev_std = 0.156)
NEC for r=0.3 all L1 = 0.197 +- 0.101 (in-sample avg dev_std = 0.156)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.705
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.652
NEC for r=0.6 class 0.0 = 0.204 +- 0.112 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 1.0 = 0.197 +- 0.112 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all KL = 0.086 +- 0.112 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all L1 = 0.198 +- 0.115 (in-sample avg dev_std = 0.191)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
NEC for r=0.9 class 0.0 = 0.159 +- 0.122 (in-sample avg dev_std = 0.153)
NEC for r=0.9 class 1.0 = 0.115 +- 0.122 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all KL = 0.076 +- 0.122 (in-sample avg dev_std = 0.153)
NEC for r=0.9 all L1 = 0.123 +- 0.127 (in-sample avg dev_std = 0.153)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.723
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.696
NEC for r=1.0 class 0.0 = 0.138 +- 0.107 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 1.0 = 0.093 +- 0.107 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all KL = 0.063 +- 0.107 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all L1 = 0.101 +- 0.123 (in-sample avg dev_std = 0.148)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:51:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:51:08 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:51:40 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:51:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:01 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:18 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 76...
[0m[1;37mINFO[0m: [1mCheckpoint 76: 
-----------------------------------
Train ROC-AUC: 0.9447
Train Loss: 0.1981
ID Validation ROC-AUC: 0.9176
ID Validation Loss: 0.2462
ID Test ROC-AUC: 0.9184
ID Test Loss: 0.2510
OOD Validation ROC-AUC: 0.6540
OOD Validation Loss: 0.3805
OOD Test ROC-AUC: 0.7143
OOD Test Loss: 0.5437

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.9016
Train Loss: 0.2361
ID Validation ROC-AUC: 0.8892
ID Validation Loss: 0.2496
ID Test ROC-AUC: 0.8921
ID Test Loss: 0.2503
OOD Validation ROC-AUC: 0.6837
OOD Validation Loss: 0.3108
OOD Test ROC-AUC: 0.7208
OOD Test Loss: 0.4574

[0m[1;37mINFO[0m: [1mChartInfo 0.9184 0.7143 0.8921 0.7208 0.8892 0.6837[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:52:34 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:52:39 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:52:43 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:52:47 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.672
SUFF++ for r=0.3 class 0.0 = 0.839 +- 0.060 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.3 class 1.0 = 0.817 +- 0.060 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.3 all KL = 0.945 +- 0.060 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.3 all L1 = 0.82 +- 0.081 (in-sample avg dev_std = 0.214)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.747
SUFF++ for r=0.6 class 0.0 = 0.759 +- 0.102 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 class 1.0 = 0.836 +- 0.102 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all KL = 0.914 +- 0.102 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.6 all L1 = 0.827 +- 0.110 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.898
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.868
SUFF++ for r=0.9 class 0.0 = 0.844 +- 0.064 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.963 +- 0.064 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.973 +- 0.064 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.086 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.689
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.642
SUFF++ for r=0.3 class 0.0 = 0.841 +- 0.075 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 class 1.0 = 0.811 +- 0.075 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 all KL = 0.938 +- 0.075 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.3 all L1 = 0.814 +- 0.090 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.808
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.783 +- 0.100 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 1.0 = 0.837 +- 0.100 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 all KL = 0.914 +- 0.100 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.110 (in-sample avg dev_std = 0.197)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.845 +- 0.060 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.9 class 1.0 = 0.964 +- 0.060 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.9 all KL = 0.976 +- 0.060 (in-sample avg dev_std = 0.092)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.089 (in-sample avg dev_std = 0.092)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.584
SUFF++ for r=0.3 class 0.0 = 0.834 +- 0.062 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.3 class 1.0 = 0.815 +- 0.062 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.3 all KL = 0.944 +- 0.062 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.3 all L1 = 0.817 +- 0.089 (in-sample avg dev_std = 0.208)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.647
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.642
SUFF++ for r=0.6 class 0.0 = 0.777 +- 0.112 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 class 1.0 = 0.786 +- 0.112 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all KL = 0.892 +- 0.112 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all L1 = 0.785 +- 0.111 (in-sample avg dev_std = 0.225)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0.0 = 0.89 +- 0.054 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.054 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.971 +- 0.054 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.93 +- 0.095 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.578
SUFF++ for r=0.3 class 0.0 = 0.83 +- 0.059 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 class 1.0 = 0.828 +- 0.059 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 all KL = 0.949 +- 0.059 (in-sample avg dev_std = 0.207)
SUFF++ for r=0.3 all L1 = 0.828 +- 0.083 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
SUFF++ for r=0.6 class 0.0 = 0.781 +- 0.111 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 class 1.0 = 0.803 +- 0.111 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all KL = 0.903 +- 0.111 (in-sample avg dev_std = 0.219)
SUFF++ for r=0.6 all L1 = 0.799 +- 0.109 (in-sample avg dev_std = 0.219)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.727
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.724
SUFF++ for r=0.9 class 0.0 = 0.874 +- 0.065 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.065 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all KL = 0.966 +- 0.065 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all L1 = 0.924 +- 0.098 (in-sample avg dev_std = 0.122)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.694
NEC for r=0.3 class 0.0 = 0.086 +- 0.055 (in-sample avg dev_std = 0.100)
NEC for r=0.3 class 1.0 = 0.098 +- 0.055 (in-sample avg dev_std = 0.100)
NEC for r=0.3 all KL = 0.021 +- 0.055 (in-sample avg dev_std = 0.100)
NEC for r=0.3 all L1 = 0.097 +- 0.093 (in-sample avg dev_std = 0.100)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.798
NEC for r=0.6 class 0.0 = 0.143 +- 0.094 (in-sample avg dev_std = 0.130)
NEC for r=0.6 class 1.0 = 0.116 +- 0.094 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all KL = 0.053 +- 0.094 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all L1 = 0.119 +- 0.093 (in-sample avg dev_std = 0.130)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.898
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.863
NEC for r=0.9 class 0.0 = 0.153 +- 0.075 (in-sample avg dev_std = 0.108)
NEC for r=0.9 class 1.0 = 0.049 +- 0.075 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all KL = 0.037 +- 0.075 (in-sample avg dev_std = 0.108)
NEC for r=0.9 all L1 = 0.061 +- 0.089 (in-sample avg dev_std = 0.108)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.914
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.876
NEC for r=1.0 class 0.0 = 0.149 +- 0.080 (in-sample avg dev_std = 0.104)
NEC for r=1.0 class 1.0 = 0.036 +- 0.080 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all KL = 0.031 +- 0.080 (in-sample avg dev_std = 0.104)
NEC for r=1.0 all L1 = 0.049 +- 0.088 (in-sample avg dev_std = 0.104)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.689
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.661
NEC for r=0.3 class 0.0 = 0.096 +- 0.073 (in-sample avg dev_std = 0.104)
NEC for r=0.3 class 1.0 = 0.102 +- 0.073 (in-sample avg dev_std = 0.104)
NEC for r=0.3 all KL = 0.027 +- 0.073 (in-sample avg dev_std = 0.104)
NEC for r=0.3 all L1 = 0.101 +- 0.101 (in-sample avg dev_std = 0.104)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.808
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.801
NEC for r=0.6 class 0.0 = 0.136 +- 0.099 (in-sample avg dev_std = 0.134)
NEC for r=0.6 class 1.0 = 0.12 +- 0.099 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all KL = 0.059 +- 0.099 (in-sample avg dev_std = 0.134)
NEC for r=0.6 all L1 = 0.122 +- 0.099 (in-sample avg dev_std = 0.134)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.172 +- 0.089 (in-sample avg dev_std = 0.115)
NEC for r=0.9 class 1.0 = 0.049 +- 0.089 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all KL = 0.039 +- 0.089 (in-sample avg dev_std = 0.115)
NEC for r=0.9 all L1 = 0.063 +- 0.097 (in-sample avg dev_std = 0.115)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.865
NEC for r=1.0 class 0.0 = 0.162 +- 0.079 (in-sample avg dev_std = 0.108)
NEC for r=1.0 class 1.0 = 0.035 +- 0.079 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all KL = 0.033 +- 0.079 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all L1 = 0.05 +- 0.090 (in-sample avg dev_std = 0.108)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.599
NEC for r=0.3 class 0.0 = 0.079 +- 0.053 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 1.0 = 0.106 +- 0.053 (in-sample avg dev_std = 0.095)
NEC for r=0.3 all KL = 0.023 +- 0.053 (in-sample avg dev_std = 0.095)
NEC for r=0.3 all L1 = 0.104 +- 0.097 (in-sample avg dev_std = 0.095)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.647
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0.0 = 0.133 +- 0.116 (in-sample avg dev_std = 0.139)
NEC for r=0.6 class 1.0 = 0.142 +- 0.116 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all KL = 0.065 +- 0.116 (in-sample avg dev_std = 0.139)
NEC for r=0.6 all L1 = 0.142 +- 0.108 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0.0 = 0.141 +- 0.095 (in-sample avg dev_std = 0.140)
NEC for r=0.9 class 1.0 = 0.087 +- 0.095 (in-sample avg dev_std = 0.140)
NEC for r=0.9 all KL = 0.053 +- 0.095 (in-sample avg dev_std = 0.140)
NEC for r=0.9 all L1 = 0.092 +- 0.107 (in-sample avg dev_std = 0.140)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.687
NEC for r=1.0 class 0.0 = 0.124 +- 0.092 (in-sample avg dev_std = 0.127)
NEC for r=1.0 class 1.0 = 0.063 +- 0.092 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all KL = 0.045 +- 0.092 (in-sample avg dev_std = 0.127)
NEC for r=1.0 all L1 = 0.068 +- 0.098 (in-sample avg dev_std = 0.127)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.577
NEC for r=0.3 class 0.0 = 0.1 +- 0.048 (in-sample avg dev_std = 0.093)
NEC for r=0.3 class 1.0 = 0.09 +- 0.048 (in-sample avg dev_std = 0.093)
NEC for r=0.3 all KL = 0.019 +- 0.048 (in-sample avg dev_std = 0.093)
NEC for r=0.3 all L1 = 0.092 +- 0.088 (in-sample avg dev_std = 0.093)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.664
NEC for r=0.6 class 0.0 = 0.136 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.133 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.058 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.134 +- 0.102 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.727
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.713
NEC for r=0.9 class 0.0 = 0.138 +- 0.087 (in-sample avg dev_std = 0.130)
NEC for r=0.9 class 1.0 = 0.084 +- 0.087 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all KL = 0.05 +- 0.087 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all L1 = 0.093 +- 0.110 (in-sample avg dev_std = 0.130)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.729
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.709
NEC for r=1.0 class 0.0 = 0.117 +- 0.091 (in-sample avg dev_std = 0.130)
NEC for r=1.0 class 1.0 = 0.067 +- 0.091 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all KL = 0.046 +- 0.091 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all L1 = 0.075 +- 0.109 (in-sample avg dev_std = 0.130)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue Apr 23 20:58:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 04/23/2024 08:58:15 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 04/23/2024 08:58:47 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 04/23/2024 08:58:57 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  weighted
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 113...
[0m[1;37mINFO[0m: [1mCheckpoint 113: 
-----------------------------------
Train ROC-AUC: 0.9523
Train Loss: 0.1941
ID Validation ROC-AUC: 0.9167
ID Validation Loss: 0.2770
ID Test ROC-AUC: 0.9188
ID Test Loss: 0.2782
OOD Validation ROC-AUC: 0.6697
OOD Validation Loss: 0.4367
OOD Test ROC-AUC: 0.7174
OOD Test Loss: 0.6357

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ROC-AUC: 0.9039
Train Loss: 0.2683
ID Validation ROC-AUC: 0.8913
ID Validation Loss: 0.2825
ID Test ROC-AUC: 0.8924
ID Test Loss: 0.2889
OOD Validation ROC-AUC: 0.6869
OOD Validation Loss: 0.3201
OOD Test ROC-AUC: 0.7328
OOD Test Loss: 0.5061

[0m[1;37mINFO[0m: [1mChartInfo 0.9188 0.7174 0.8924 0.7328 0.8913 0.6869[0mLBAPcore(34179)
Data example from train: Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
Label distribution from train: (tensor([0., 1.]), tensor([ 3960, 30219]))
[1;34mDEBUG[0m: 04/23/2024 08:59:41 PM : [1mUnbalanced warning for LBAPcore (train)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 04/23/2024 08:59:46 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19028)
Data example from val: Data(x=[23, 39], edge_index=[2, 50], edge_attr=[50, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 50], node_perm=[23])
Label distribution from val: (tensor([0., 1.]), tensor([ 1602, 17426]))
[1;34mDEBUG[0m: 04/23/2024 08:59:50 PM : [1mUnbalanced warning for LBAPcore (val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 04/23/2024 08:59:54 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.591
SUFF++ for r=0.3 class 0.0 = 0.695 +- 0.104 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 class 1.0 = 0.71 +- 0.104 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all KL = 0.854 +- 0.104 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all L1 = 0.708 +- 0.100 (in-sample avg dev_std = 0.265)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.828
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.709
SUFF++ for r=0.6 class 0.0 = 0.703 +- 0.141 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 class 1.0 = 0.867 +- 0.141 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all KL = 0.863 +- 0.141 (in-sample avg dev_std = 0.216)
SUFF++ for r=0.6 all L1 = 0.848 +- 0.142 (in-sample avg dev_std = 0.216)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.903
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0.0 = 0.772 +- 0.074 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.074 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.966 +- 0.074 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.121 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.658
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.607
SUFF++ for r=0.3 class 0.0 = 0.696 +- 0.102 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 class 1.0 = 0.71 +- 0.102 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all KL = 0.857 +- 0.102 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.3 all L1 = 0.708 +- 0.102 (in-sample avg dev_std = 0.265)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.751
SUFF++ for r=0.6 class 0.0 = 0.674 +- 0.142 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.6 class 1.0 = 0.874 +- 0.142 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.6 all KL = 0.866 +- 0.142 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.6 all L1 = 0.851 +- 0.145 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.866
SUFF++ for r=0.9 class 0.0 = 0.774 +- 0.086 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.952 +- 0.086 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.962 +- 0.086 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.931 +- 0.124 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
SUFF++ for r=0.3 class 0.0 = 0.71 +- 0.097 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 1.0 = 0.707 +- 0.097 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all KL = 0.866 +- 0.097 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all L1 = 0.708 +- 0.099 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.641
SUFF++ for r=0.6 class 0.0 = 0.74 +- 0.135 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1.0 = 0.81 +- 0.135 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.847 +- 0.135 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.804 +- 0.142 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
SUFF++ for r=0.9 class 0.0 = 0.829 +- 0.077 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 class 1.0 = 0.915 +- 0.077 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all KL = 0.955 +- 0.077 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.9 all L1 = 0.908 +- 0.127 (in-sample avg dev_std = 0.119)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.501
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.54
SUFF++ for r=0.3 class 0.0 = 0.708 +- 0.092 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 class 1.0 = 0.706 +- 0.092 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 all KL = 0.867 +- 0.092 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.3 all L1 = 0.706 +- 0.101 (in-sample avg dev_std = 0.271)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0.0 = 0.74 +- 0.148 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 class 1.0 = 0.807 +- 0.148 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all KL = 0.838 +- 0.148 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.6 all L1 = 0.796 +- 0.148 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.722
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.714
SUFF++ for r=0.9 class 0.0 = 0.856 +- 0.074 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 class 1.0 = 0.92 +- 0.074 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all KL = 0.956 +- 0.074 (in-sample avg dev_std = 0.120)
SUFF++ for r=0.9 all L1 = 0.91 +- 0.123 (in-sample avg dev_std = 0.120)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over train across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.654
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.687
NEC for r=0.3 class 0.0 = 0.212 +- 0.078 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 1.0 = 0.203 +- 0.078 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all KL = 0.073 +- 0.078 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all L1 = 0.204 +- 0.107 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.828
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.82
NEC for r=0.6 class 0.0 = 0.216 +- 0.116 (in-sample avg dev_std = 0.160)
NEC for r=0.6 class 1.0 = 0.103 +- 0.116 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all KL = 0.077 +- 0.116 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all L1 = 0.116 +- 0.130 (in-sample avg dev_std = 0.160)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.903
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.867
NEC for r=0.9 class 0.0 = 0.205 +- 0.081 (in-sample avg dev_std = 0.131)
NEC for r=0.9 class 1.0 = 0.049 +- 0.081 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all KL = 0.038 +- 0.081 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all L1 = 0.067 +- 0.114 (in-sample avg dev_std = 0.131)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.915
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.878
NEC for r=1.0 class 0.0 = 0.21 +- 0.089 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.037 +- 0.089 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.032 +- 0.089 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.058 +- 0.115 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.658
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.696
NEC for r=0.3 class 0.0 = 0.213 +- 0.087 (in-sample avg dev_std = 0.201)
NEC for r=0.3 class 1.0 = 0.203 +- 0.087 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all KL = 0.076 +- 0.087 (in-sample avg dev_std = 0.201)
NEC for r=0.3 all L1 = 0.204 +- 0.112 (in-sample avg dev_std = 0.201)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.873
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.852
NEC for r=0.6 class 0.0 = 0.246 +- 0.117 (in-sample avg dev_std = 0.165)
NEC for r=0.6 class 1.0 = 0.099 +- 0.117 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all KL = 0.079 +- 0.117 (in-sample avg dev_std = 0.165)
NEC for r=0.6 all L1 = 0.116 +- 0.131 (in-sample avg dev_std = 0.165)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.881
NEC for r=0.9 class 0.0 = 0.21 +- 0.084 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1.0 = 0.051 +- 0.084 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.041 +- 0.084 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.069 +- 0.115 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.883
NEC for r=1.0 class 0.0 = 0.201 +- 0.073 (in-sample avg dev_std = 0.115)
NEC for r=1.0 class 1.0 = 0.037 +- 0.073 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all KL = 0.031 +- 0.073 (in-sample avg dev_std = 0.115)
NEC for r=1.0 all L1 = 0.056 +- 0.106 (in-sample avg dev_std = 0.115)



--------------------------------------------------


#D#Computing NEC over val across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.544
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.552
NEC for r=0.3 class 0.0 = 0.232 +- 0.083 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1.0 = 0.204 +- 0.083 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.071 +- 0.083 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.207 +- 0.110 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.688
NEC for r=0.6 class 0.0 = 0.222 +- 0.129 (in-sample avg dev_std = 0.198)
NEC for r=0.6 class 1.0 = 0.158 +- 0.129 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all KL = 0.104 +- 0.129 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all L1 = 0.163 +- 0.140 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.709
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.693
NEC for r=0.9 class 0.0 = 0.17 +- 0.097 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1.0 = 0.092 +- 0.097 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.056 +- 0.097 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.099 +- 0.127 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.686
NEC for r=1.0 class 0.0 = 0.152 +- 0.079 (in-sample avg dev_std = 0.134)
NEC for r=1.0 class 1.0 = 0.069 +- 0.079 (in-sample avg dev_std = 0.134)
NEC for r=1.0 all KL = 0.041 +- 0.079 (in-sample avg dev_std = 0.134)
NEC for r=1.0 all L1 = 0.076 +- 0.112 (in-sample avg dev_std = 0.134)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.501
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.515
NEC for r=0.3 class 0.0 = 0.2 +- 0.078 (in-sample avg dev_std = 0.203)
NEC for r=0.3 class 1.0 = 0.216 +- 0.078 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all KL = 0.074 +- 0.078 (in-sample avg dev_std = 0.203)
NEC for r=0.3 all L1 = 0.214 +- 0.109 (in-sample avg dev_std = 0.203)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.641
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.666
NEC for r=0.6 class 0.0 = 0.221 +- 0.135 (in-sample avg dev_std = 0.192)
NEC for r=0.6 class 1.0 = 0.157 +- 0.135 (in-sample avg dev_std = 0.192)
NEC for r=0.6 all KL = 0.107 +- 0.135 (in-sample avg dev_std = 0.192)
NEC for r=0.6 all L1 = 0.167 +- 0.145 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.722
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.699
NEC for r=0.9 class 0.0 = 0.167 +- 0.109 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1.0 = 0.093 +- 0.109 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.064 +- 0.109 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.106 +- 0.133 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.746
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.714
NEC for r=1.0 class 0.0 = 0.143 +- 0.095 (in-sample avg dev_std = 0.134)
NEC for r=1.0 class 1.0 = 0.07 +- 0.095 (in-sample avg dev_std = 0.134)
NEC for r=1.0 all KL = 0.045 +- 0.095 (in-sample avg dev_std = 0.134)
NEC for r=1.0 all L1 = 0.082 +- 0.123 (in-sample avg dev_std = 0.134)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split train
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.907, 0.883, 0.973, 1.0], 'all_L1': [0.762, 0.769, 0.932, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.822, 0.861, 0.958, 1.0], 'all_L1': [0.696, 0.822, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.934, 0.901, 0.966, 1.0], 'all_L1': [0.789, 0.798, 0.931, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.945, 0.914, 0.973, 1.0], 'all_L1': [0.82, 0.827, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.854, 0.863, 0.966, 1.0], 'all_L1': [0.708, 0.848, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.08, 0.097, 0.083, 0.075], 'all_L1': [0.212, 0.197, 0.139, 0.112]}), defaultdict(<class 'list'>, {'all_KL': [0.157, 0.126, 0.058, 0.044], 'all_L1': [0.286, 0.165, 0.074, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.059, 0.095, 0.068, 0.049], 'all_L1': [0.198, 0.186, 0.093, 0.072]}), defaultdict(<class 'list'>, {'all_KL': [0.021, 0.053, 0.037, 0.031], 'all_L1': [0.097, 0.119, 0.061, 0.049]}), defaultdict(<class 'list'>, {'all_KL': [0.073, 0.077, 0.038, 0.032], 'all_L1': [0.204, 0.116, 0.067, 0.058]})]

Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.909, 0.887, 0.97, 1.0], 'all_L1': [0.772, 0.765, 0.926, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.83, 0.864, 0.958, 1.0], 'all_L1': [0.706, 0.826, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.932, 0.904, 0.975, 1.0], 'all_L1': [0.784, 0.803, 0.94, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.938, 0.914, 0.976, 1.0], 'all_L1': [0.814, 0.83, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.857, 0.866, 0.962, 1.0], 'all_L1': [0.708, 0.851, 0.931, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.085, 0.094, 0.086, 0.073], 'all_L1': [0.215, 0.203, 0.142, 0.11]}), defaultdict(<class 'list'>, {'all_KL': [0.156, 0.129, 0.055, 0.044], 'all_L1': [0.283, 0.169, 0.073, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.056, 0.086, 0.059, 0.045], 'all_L1': [0.194, 0.18, 0.088, 0.067]}), defaultdict(<class 'list'>, {'all_KL': [0.027, 0.059, 0.039, 0.033], 'all_L1': [0.101, 0.122, 0.063, 0.05]}), defaultdict(<class 'list'>, {'all_KL': [0.076, 0.079, 0.041, 0.031], 'all_L1': [0.204, 0.116, 0.069, 0.056]})]

Eval split val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.942, 0.903, 0.962, 1.0], 'all_L1': [0.801, 0.766, 0.899, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.813, 0.809, 0.942, 1.0], 'all_L1': [0.681, 0.762, 0.906, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.945, 0.899, 0.964, 1.0], 'all_L1': [0.797, 0.774, 0.912, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.944, 0.892, 0.971, 1.0], 'all_L1': [0.817, 0.785, 0.93, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.866, 0.847, 0.955, 1.0], 'all_L1': [0.708, 0.804, 0.908, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.055, 0.081, 0.088, 0.076], 'all_L1': [0.186, 0.197, 0.176, 0.147]}), defaultdict(<class 'list'>, {'all_KL': [0.168, 0.162, 0.089, 0.062], 'all_L1': [0.302, 0.216, 0.113, 0.085]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.084, 0.076, 0.055], 'all_L1': [0.183, 0.205, 0.121, 0.094]}), defaultdict(<class 'list'>, {'all_KL': [0.023, 0.065, 0.053, 0.045], 'all_L1': [0.104, 0.142, 0.092, 0.068]}), defaultdict(<class 'list'>, {'all_KL': [0.071, 0.104, 0.056, 0.041], 'all_L1': [0.207, 0.163, 0.099, 0.076]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.931, 0.887, 0.961, 1.0], 'all_L1': [0.788, 0.756, 0.899, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.813, 0.808, 0.929, 1.0], 'all_L1': [0.684, 0.749, 0.89, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.94, 0.902, 0.956, 1.0], 'all_L1': [0.793, 0.783, 0.905, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.949, 0.903, 0.966, 1.0], 'all_L1': [0.828, 0.799, 0.924, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.867, 0.838, 0.956, 1.0], 'all_L1': [0.706, 0.796, 0.91, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.069, 0.103, 0.083, 0.075], 'all_L1': [0.208, 0.218, 0.169, 0.148]}), defaultdict(<class 'list'>, {'all_KL': [0.18, 0.167, 0.096, 0.068], 'all_L1': [0.312, 0.231, 0.123, 0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.056, 0.086, 0.076, 0.063], 'all_L1': [0.197, 0.198, 0.123, 0.101]}), defaultdict(<class 'list'>, {'all_KL': [0.019, 0.058, 0.05, 0.046], 'all_L1': [0.092, 0.134, 0.093, 0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.074, 0.107, 0.064, 0.045], 'all_L1': [0.214, 0.167, 0.106, 0.082]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split train
suff++ class all_L1  =  0.755 +- 0.047, 0.813 +- 0.027, 0.936 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.892 +- 0.047, 0.884 +- 0.021, 0.967 +- 0.006, 1.000 +- 0.000
suff++_acc_int  =  0.630 +- 0.027, 0.735 +- 0.016, 0.854 +- 0.014
nec class all_L1  =  0.199 +- 0.060, 0.157 +- 0.034, 0.087 +- 0.028, 0.070 +- 0.022
nec class all_KL  =  0.078 +- 0.044, 0.090 +- 0.024, 0.057 +- 0.018, 0.046 +- 0.016
nec_acc_int  =  0.656 +- 0.039, 0.782 +- 0.027, 0.856 +- 0.021, 0.866 +- 0.016

Eval split id_val
suff++ class all_L1  =  0.757 +- 0.043, 0.815 +- 0.029, 0.936 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.893 +- 0.043, 0.887 +- 0.020, 0.968 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.617 +- 0.019, 0.740 +- 0.026, 0.851 +- 0.013
nec class all_L1  =  0.199 +- 0.058, 0.158 +- 0.034, 0.087 +- 0.029, 0.068 +- 0.022
nec class all_KL  =  0.080 +- 0.043, 0.089 +- 0.023, 0.056 +- 0.017, 0.045 +- 0.015
nec_acc_int  =  0.656 +- 0.022, 0.796 +- 0.043, 0.856 +- 0.018, 0.866 +- 0.011

Eval split val
suff++ class all_L1  =  0.761 +- 0.055, 0.778 +- 0.015, 0.911 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.902 +- 0.054, 0.870 +- 0.037, 0.959 +- 0.010, 1.000 +- 0.000
suff++_acc_int  =  0.547 +- 0.027, 0.617 +- 0.024, 0.671 +- 0.023
nec class all_L1  =  0.196 +- 0.063, 0.185 +- 0.028, 0.120 +- 0.030, 0.094 +- 0.028
nec class all_KL  =  0.072 +- 0.050, 0.099 +- 0.034, 0.072 +- 0.015, 0.056 +- 0.013
nec_acc_int  =  0.555 +- 0.024, 0.618 +- 0.049, 0.669 +- 0.031, 0.678 +- 0.017

Eval split test
suff++ class all_L1  =  0.760 +- 0.055, 0.777 +- 0.021, 0.906 +- 0.011, 1.000 +- 0.000
suff++ class all_KL  =  0.900 +- 0.052, 0.868 +- 0.038, 0.954 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.566 +- 0.020, 0.638 +- 0.023, 0.702 +- 0.017
nec class all_L1  =  0.205 +- 0.070, 0.190 +- 0.035, 0.123 +- 0.026, 0.100 +- 0.026
nec class all_KL  =  0.080 +- 0.054, 0.104 +- 0.036, 0.074 +- 0.016, 0.059 +- 0.012
nec_acc_int  =  0.562 +- 0.024, 0.651 +- 0.021, 0.698 +- 0.010, 0.704 +- 0.006


 -------------------------------------------------- 
Computing faithfulness

Eval split train
Faith. Aritm (L1)= 		  =  0.477 +- 0.016, 0.485 +- 0.007, 0.511 +- 0.013, 0.535 +- 0.011
Faith. Armon (L1)= 		  =  0.309 +- 0.075, 0.260 +- 0.046, 0.158 +- 0.046, 0.131 +- 0.038
Faith. GMean (L1)= 	  =  0.381 +- 0.054, 0.354 +- 0.034, 0.282 +- 0.043, 0.262 +- 0.039
Faith. Aritm (KL)= 		  =  0.485 +- 0.012, 0.487 +- 0.010, 0.512 +- 0.009, 0.523 +- 0.008
Faith. Armon (KL)= 		  =  0.139 +- 0.072, 0.162 +- 0.040, 0.107 +- 0.031, 0.088 +- 0.029
Faith. GMean (KL)= 	  =  0.251 +- 0.070, 0.278 +- 0.037, 0.232 +- 0.037, 0.212 +- 0.036

Eval split id_val
Faith. Aritm (L1)= 		  =  0.478 +- 0.018, 0.486 +- 0.007, 0.512 +- 0.012, 0.534 +- 0.011
Faith. Armon (L1)= 		  =  0.310 +- 0.073, 0.262 +- 0.046, 0.158 +- 0.046, 0.127 +- 0.037
Faith. GMean (L1)= 	  =  0.382 +- 0.053, 0.356 +- 0.033, 0.282 +- 0.043, 0.259 +- 0.038
Faith. Aritm (KL)= 		  =  0.487 +- 0.011, 0.488 +- 0.009, 0.512 +- 0.009, 0.523 +- 0.007
Faith. Armon (KL)= 		  =  0.143 +- 0.069, 0.161 +- 0.037, 0.105 +- 0.030, 0.086 +- 0.027
Faith. GMean (KL)= 	  =  0.256 +- 0.065, 0.279 +- 0.033, 0.230 +- 0.034, 0.210 +- 0.033

Eval split val
Faith. Aritm (L1)= 		  =  0.479 +- 0.016, 0.481 +- 0.009, 0.516 +- 0.012, 0.547 +- 0.014
Faith. Armon (L1)= 		  =  0.305 +- 0.074, 0.297 +- 0.036, 0.211 +- 0.045, 0.171 +- 0.045
Faith. GMean (L1)= 	  =  0.379 +- 0.052, 0.378 +- 0.026, 0.328 +- 0.037, 0.304 +- 0.043
Faith. Aritm (KL)= 		  =  0.487 +- 0.010, 0.485 +- 0.007, 0.516 +- 0.007, 0.528 +- 0.006
Faith. Armon (KL)= 		  =  0.128 +- 0.080, 0.176 +- 0.051, 0.134 +- 0.027, 0.105 +- 0.022
Faith. GMean (KL)= 	  =  0.239 +- 0.074, 0.289 +- 0.041, 0.262 +- 0.028, 0.235 +- 0.026

Eval split test
Faith. Aritm (L1)= 		  =  0.482 +- 0.018, 0.483 +- 0.009, 0.514 +- 0.010, 0.550 +- 0.013
Faith. Armon (L1)= 		  =  0.313 +- 0.084, 0.303 +- 0.045, 0.215 +- 0.039, 0.181 +- 0.041
Faith. GMean (L1)= 	  =  0.385 +- 0.061, 0.381 +- 0.032, 0.332 +- 0.033, 0.314 +- 0.039
Faith. Aritm (KL)= 		  =  0.490 +- 0.011, 0.486 +- 0.008, 0.514 +- 0.005, 0.530 +- 0.006
Faith. Armon (KL)= 		  =  0.141 +- 0.085, 0.183 +- 0.055, 0.137 +- 0.027, 0.112 +- 0.021
Faith. GMean (KL)= 	  =  0.251 +- 0.079, 0.295 +- 0.045, 0.264 +- 0.028, 0.242 +- 0.025
Computed for split load_split = id



Completed in  0:35:20.505637  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay
DONE all :)
