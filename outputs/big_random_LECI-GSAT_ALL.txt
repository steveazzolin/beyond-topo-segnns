nohup: ignoring input
Time to compute metrics for random explanations!
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:50:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:50:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.8598
Train Loss: 0.5235
ID Validation ACCURACY: 0.8683
ID Validation Loss: 0.5030
ID Test ACCURACY: 0.8607
ID Test Loss: 0.5282
OOD Validation ACCURACY: 0.8537
OOD Validation Loss: 0.6475
OOD Test ACCURACY: 0.5690
OOD Test Loss: 1.2550

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.8449
Train Loss: 0.5037
ID Validation ACCURACY: 0.8490
ID Validation Loss: 0.4950
ID Test ACCURACY: 0.8447
ID Test Loss: 0.5158
OOD Validation ACCURACY: 0.8813
OOD Validation Loss: 0.5724
OOD Test ACCURACY: 0.8553
OOD Test Loss: 0.5144

[0m[1;37mINFO[0m: [1mChartInfo 0.8607 0.5690 0.8447 0.8553 0.8490 0.8813[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.126
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.241
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.276
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.281
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.102
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.146
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.232
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.253


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.12630625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.339
SUFF++ for r=0.3 class 0 = 0.594 +- 0.309 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 1 = 0.464 +- 0.309 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 2 = 0.437 +- 0.309 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 all KL = 0.53 +- 0.309 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 all L1 = 0.498 +- 0.209 (in-sample avg dev_std = 0.454)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.757
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24122
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.378
SUFF++ for r=0.6 class 0 = 0.451 +- 0.270 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 1 = 0.488 +- 0.270 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 2 = 0.421 +- 0.270 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all KL = 0.485 +- 0.270 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all L1 = 0.454 +- 0.159 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.27585125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.513
SUFF++ for r=0.9 class 0 = 0.671 +- 0.318 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 1 = 0.614 +- 0.318 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 2 = 0.425 +- 0.318 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all KL = 0.611 +- 0.318 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all L1 = 0.571 +- 0.242 (in-sample avg dev_std = 0.411)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.216
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.10222375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.326
SUFF++ for r=0.3 class 0 = 0.403 +- 0.243 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 1 = 0.507 +- 0.243 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 2 = 0.418 +- 0.243 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all KL = 0.422 +- 0.243 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all L1 = 0.444 +- 0.153 (in-sample avg dev_std = 0.576)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.14633749999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.372
SUFF++ for r=0.6 class 0 = 0.459 +- 0.250 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 1 = 0.526 +- 0.250 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 class 2 = 0.505 +- 0.250 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all KL = 0.43 +- 0.250 (in-sample avg dev_std = 0.568)
SUFF++ for r=0.6 all L1 = 0.497 +- 0.166 (in-sample avg dev_std = 0.568)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.571
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.23237750000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.435
SUFF++ for r=0.9 class 0 = 0.682 +- 0.208 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 1 = 0.63 +- 0.208 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 class 2 = 0.664 +- 0.208 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all KL = 0.736 +- 0.208 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.9 all L1 = 0.658 +- 0.176 (in-sample avg dev_std = 0.319)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.12630625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.358 +- 0.327 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 1 = 0.47 +- 0.327 (in-sample avg dev_std = 0.429)
NEC for r=0.3 class 2 = 0.484 +- 0.327 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all KL = 0.398 +- 0.327 (in-sample avg dev_std = 0.429)
NEC for r=0.3 all L1 = 0.437 +- 0.241 (in-sample avg dev_std = 0.429)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.757
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24122
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.501
NEC for r=0.6 class 0 = 0.473 +- 0.287 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 1 = 0.462 +- 0.287 (in-sample avg dev_std = 0.541)
NEC for r=0.6 class 2 = 0.48 +- 0.287 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all KL = 0.447 +- 0.287 (in-sample avg dev_std = 0.541)
NEC for r=0.6 all L1 = 0.471 +- 0.176 (in-sample avg dev_std = 0.541)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.27585125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.47 +- 0.306 (in-sample avg dev_std = 0.535)
NEC for r=0.9 class 1 = 0.48 +- 0.306 (in-sample avg dev_std = 0.535)
NEC for r=0.9 class 2 = 0.531 +- 0.306 (in-sample avg dev_std = 0.535)
NEC for r=0.9 all KL = 0.475 +- 0.306 (in-sample avg dev_std = 0.535)
NEC for r=0.9 all L1 = 0.493 +- 0.187 (in-sample avg dev_std = 0.535)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.28069625000000004
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.501
NEC for r=1.0 class 0 = 0.466 +- 0.298 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 1 = 0.491 +- 0.298 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 2 = 0.552 +- 0.298 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all KL = 0.482 +- 0.298 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all L1 = 0.503 +- 0.173 (in-sample avg dev_std = 0.555)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.216
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.10222375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.299
NEC for r=0.3 class 0 = 0.556 +- 0.241 (in-sample avg dev_std = 0.593)
NEC for r=0.3 class 1 = 0.494 +- 0.241 (in-sample avg dev_std = 0.593)
NEC for r=0.3 class 2 = 0.563 +- 0.241 (in-sample avg dev_std = 0.593)
NEC for r=0.3 all KL = 0.568 +- 0.241 (in-sample avg dev_std = 0.593)
NEC for r=0.3 all L1 = 0.537 +- 0.148 (in-sample avg dev_std = 0.593)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.14633749999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.492
NEC for r=0.6 class 0 = 0.442 +- 0.293 (in-sample avg dev_std = 0.614)
NEC for r=0.6 class 1 = 0.459 +- 0.293 (in-sample avg dev_std = 0.614)
NEC for r=0.6 class 2 = 0.376 +- 0.293 (in-sample avg dev_std = 0.614)
NEC for r=0.6 all KL = 0.493 +- 0.293 (in-sample avg dev_std = 0.614)
NEC for r=0.6 all L1 = 0.426 +- 0.163 (in-sample avg dev_std = 0.614)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.571
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.23237750000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.493
NEC for r=0.9 class 0 = 0.382 +- 0.226 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 1 = 0.422 +- 0.226 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 2 = 0.362 +- 0.226 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all KL = 0.341 +- 0.226 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all L1 = 0.389 +- 0.129 (in-sample avg dev_std = 0.463)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.576
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25317875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.488
NEC for r=1.0 class 0 = 0.378 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 1 = 0.416 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 2 = 0.322 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all KL = 0.351 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all L1 = 0.372 +- 0.137 (in-sample avg dev_std = 0.456)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:53:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:53:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9087
Train Loss: 0.4218
ID Validation ACCURACY: 0.9113
ID Validation Loss: 0.4062
ID Test ACCURACY: 0.9043
ID Test Loss: 0.4406
OOD Validation ACCURACY: 0.9257
OOD Validation Loss: 0.4153
OOD Test ACCURACY: 0.9043
OOD Test Loss: 0.4070

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.8882
Train Loss: 0.4551
ID Validation ACCURACY: 0.8927
ID Validation Loss: 0.4382
ID Test ACCURACY: 0.8887
ID Test Loss: 0.4541
OOD Validation ACCURACY: 0.9283
OOD Validation Loss: 0.4551
OOD Test ACCURACY: 0.9143
OOD Test Loss: 0.3807

[0m[1;37mINFO[0m: [1mChartInfo 0.9043 0.9043 0.8887 0.9143 0.8927 0.9283[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.082
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.220
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.294
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.308
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.141
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.237
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.252
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.255


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.482
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.08194000000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.349
SUFF++ for r=0.3 class 0 = 0.568 +- 0.332 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 1 = 0.532 +- 0.332 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 class 2 = 0.49 +- 0.332 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all KL = 0.569 +- 0.332 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.3 all L1 = 0.53 +- 0.224 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22008625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.366
SUFF++ for r=0.6 class 0 = 0.458 +- 0.270 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 1 = 0.468 +- 0.270 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 class 2 = 0.394 +- 0.270 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all KL = 0.482 +- 0.270 (in-sample avg dev_std = 0.457)
SUFF++ for r=0.6 all L1 = 0.44 +- 0.145 (in-sample avg dev_std = 0.457)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29420375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.472
SUFF++ for r=0.9 class 0 = 0.495 +- 0.298 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 1 = 0.586 +- 0.298 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 2 = 0.438 +- 0.298 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 all KL = 0.507 +- 0.298 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 all L1 = 0.507 +- 0.224 (in-sample avg dev_std = 0.437)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.14103125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.405
SUFF++ for r=0.3 class 0 = 0.514 +- 0.267 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 1 = 0.43 +- 0.267 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 class 2 = 0.329 +- 0.267 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 all KL = 0.403 +- 0.267 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.3 all L1 = 0.423 +- 0.157 (in-sample avg dev_std = 0.554)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23661374999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.354
SUFF++ for r=0.6 class 0 = 0.409 +- 0.262 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 1 = 0.367 +- 0.262 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 class 2 = 0.313 +- 0.262 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 all KL = 0.319 +- 0.262 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.6 all L1 = 0.363 +- 0.134 (in-sample avg dev_std = 0.507)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25179
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.393
SUFF++ for r=0.9 class 0 = 0.433 +- 0.256 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.9 class 1 = 0.419 +- 0.256 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.9 class 2 = 0.362 +- 0.256 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.9 all KL = 0.366 +- 0.256 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.9 all L1 = 0.405 +- 0.153 (in-sample avg dev_std = 0.467)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.482
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.08194000000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.388
NEC for r=0.3 class 0 = 0.395 +- 0.313 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 1 = 0.408 +- 0.313 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 2 = 0.473 +- 0.313 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all KL = 0.378 +- 0.313 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all L1 = 0.425 +- 0.220 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.68
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22008625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.483
NEC for r=0.6 class 0 = 0.478 +- 0.277 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 1 = 0.485 +- 0.277 (in-sample avg dev_std = 0.487)
NEC for r=0.6 class 2 = 0.515 +- 0.277 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all KL = 0.452 +- 0.277 (in-sample avg dev_std = 0.487)
NEC for r=0.6 all L1 = 0.493 +- 0.180 (in-sample avg dev_std = 0.487)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29420375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.494 +- 0.290 (in-sample avg dev_std = 0.562)
NEC for r=0.9 class 1 = 0.519 +- 0.290 (in-sample avg dev_std = 0.562)
NEC for r=0.9 class 2 = 0.524 +- 0.290 (in-sample avg dev_std = 0.562)
NEC for r=0.9 all KL = 0.546 +- 0.290 (in-sample avg dev_std = 0.562)
NEC for r=0.9 all L1 = 0.512 +- 0.172 (in-sample avg dev_std = 0.562)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30767500000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.557
NEC for r=1.0 class 0 = 0.496 +- 0.281 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 1 = 0.507 +- 0.281 (in-sample avg dev_std = 0.574)
NEC for r=1.0 class 2 = 0.53 +- 0.281 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all KL = 0.551 +- 0.281 (in-sample avg dev_std = 0.574)
NEC for r=1.0 all L1 = 0.511 +- 0.155 (in-sample avg dev_std = 0.574)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.14103125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.521
NEC for r=0.3 class 0 = 0.399 +- 0.310 (in-sample avg dev_std = 0.500)
NEC for r=0.3 class 1 = 0.4 +- 0.310 (in-sample avg dev_std = 0.500)
NEC for r=0.3 class 2 = 0.498 +- 0.310 (in-sample avg dev_std = 0.500)
NEC for r=0.3 all KL = 0.431 +- 0.310 (in-sample avg dev_std = 0.500)
NEC for r=0.3 all L1 = 0.432 +- 0.251 (in-sample avg dev_std = 0.500)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23661374999999998
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.576
NEC for r=0.6 class 0 = 0.395 +- 0.394 (in-sample avg dev_std = 0.498)
NEC for r=0.6 class 1 = 0.443 +- 0.394 (in-sample avg dev_std = 0.498)
NEC for r=0.6 class 2 = 0.413 +- 0.394 (in-sample avg dev_std = 0.498)
NEC for r=0.6 all KL = 0.472 +- 0.394 (in-sample avg dev_std = 0.498)
NEC for r=0.6 all L1 = 0.417 +- 0.285 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25179
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.581
NEC for r=0.9 class 0 = 0.425 +- 0.390 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 1 = 0.412 +- 0.390 (in-sample avg dev_std = 0.506)
NEC for r=0.9 class 2 = 0.447 +- 0.390 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all KL = 0.487 +- 0.390 (in-sample avg dev_std = 0.506)
NEC for r=0.9 all L1 = 0.428 +- 0.270 (in-sample avg dev_std = 0.506)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25509875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.627
NEC for r=1.0 class 0 = 0.422 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 class 1 = 0.399 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 class 2 = 0.413 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 all KL = 0.469 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 all L1 = 0.411 +- 0.188 (in-sample avg dev_std = 0.602)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:55:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:55:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.8349
Train Loss: 0.5629
ID Validation ACCURACY: 0.8427
ID Validation Loss: 0.5385
ID Test ACCURACY: 0.8290
ID Test Loss: 0.5847
OOD Validation ACCURACY: 0.7613
OOD Validation Loss: 0.7380
OOD Test ACCURACY: 0.7983
OOD Test Loss: 0.5704

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.8374
Train Loss: 0.5193
ID Validation ACCURACY: 0.8337
ID Validation Loss: 0.5058
ID Test ACCURACY: 0.8260
ID Test Loss: 0.5460
OOD Validation ACCURACY: 0.8300
OOD Validation Loss: 0.6757
OOD Test ACCURACY: 0.8513
OOD Test Loss: 0.4627

[0m[1;37mINFO[0m: [1mChartInfo 0.8290 0.7983 0.8260 0.8513 0.8337 0.8300[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.171
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.274
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.310
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.311
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.159
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.239
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.252
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.616
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17080874999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.368
SUFF++ for r=0.3 class 0 = 0.428 +- 0.297 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 class 1 = 0.609 +- 0.297 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 class 2 = 0.462 +- 0.297 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all KL = 0.413 +- 0.297 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all L1 = 0.5 +- 0.206 (in-sample avg dev_std = 0.553)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.27364625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.411
SUFF++ for r=0.6 class 0 = 0.453 +- 0.300 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 1 = 0.535 +- 0.300 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 2 = 0.385 +- 0.300 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all KL = 0.471 +- 0.300 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all L1 = 0.458 +- 0.166 (in-sample avg dev_std = 0.482)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30970625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.464
SUFF++ for r=0.9 class 0 = 0.591 +- 0.300 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 1 = 0.6 +- 0.300 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 class 2 = 0.443 +- 0.300 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all KL = 0.603 +- 0.300 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.9 all L1 = 0.545 +- 0.215 (in-sample avg dev_std = 0.375)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.15909625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.421
SUFF++ for r=0.3 class 0 = 0.435 +- 0.306 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.622 +- 0.306 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.486 +- 0.306 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.477 +- 0.306 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.516 +- 0.170 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23944624999999997
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.412
SUFF++ for r=0.6 class 0 = 0.514 +- 0.307 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1 = 0.58 +- 0.307 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 2 = 0.357 +- 0.307 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.534 +- 0.307 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.484 +- 0.178 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.78
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25210625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.407
SUFF++ for r=0.9 class 0 = 0.614 +- 0.295 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 1 = 0.479 +- 0.295 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 2 = 0.378 +- 0.295 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all KL = 0.56 +- 0.295 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all L1 = 0.489 +- 0.193 (in-sample avg dev_std = 0.368)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.616
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17080874999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.442
NEC for r=0.3 class 0 = 0.505 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 1 = 0.288 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 2 = 0.42 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all KL = 0.45 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all L1 = 0.404 +- 0.245 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.27364625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.561
NEC for r=0.6 class 0 = 0.466 +- 0.306 (in-sample avg dev_std = 0.508)
NEC for r=0.6 class 1 = 0.377 +- 0.306 (in-sample avg dev_std = 0.508)
NEC for r=0.6 class 2 = 0.481 +- 0.306 (in-sample avg dev_std = 0.508)
NEC for r=0.6 all KL = 0.424 +- 0.306 (in-sample avg dev_std = 0.508)
NEC for r=0.6 all L1 = 0.441 +- 0.184 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30970625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.573
NEC for r=0.9 class 0 = 0.424 +- 0.294 (in-sample avg dev_std = 0.490)
NEC for r=0.9 class 1 = 0.402 +- 0.294 (in-sample avg dev_std = 0.490)
NEC for r=0.9 class 2 = 0.465 +- 0.294 (in-sample avg dev_std = 0.490)
NEC for r=0.9 all KL = 0.394 +- 0.294 (in-sample avg dev_std = 0.490)
NEC for r=0.9 all L1 = 0.43 +- 0.178 (in-sample avg dev_std = 0.490)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.853
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31105
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.549
NEC for r=1.0 class 0 = 0.408 +- 0.290 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 1 = 0.435 +- 0.290 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 2 = 0.482 +- 0.290 (in-sample avg dev_std = 0.472)
NEC for r=1.0 all KL = 0.388 +- 0.290 (in-sample avg dev_std = 0.472)
NEC for r=1.0 all L1 = 0.441 +- 0.173 (in-sample avg dev_std = 0.472)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.15909625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.541
NEC for r=0.3 class 0 = 0.362 +- 0.291 (in-sample avg dev_std = 0.454)
NEC for r=0.3 class 1 = 0.227 +- 0.291 (in-sample avg dev_std = 0.454)
NEC for r=0.3 class 2 = 0.283 +- 0.291 (in-sample avg dev_std = 0.454)
NEC for r=0.3 all KL = 0.292 +- 0.291 (in-sample avg dev_std = 0.454)
NEC for r=0.3 all L1 = 0.289 +- 0.206 (in-sample avg dev_std = 0.454)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23944624999999997
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.635
NEC for r=0.6 class 0 = 0.296 +- 0.320 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 1 = 0.262 +- 0.320 (in-sample avg dev_std = 0.485)
NEC for r=0.6 class 2 = 0.392 +- 0.320 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all KL = 0.311 +- 0.320 (in-sample avg dev_std = 0.485)
NEC for r=0.6 all L1 = 0.317 +- 0.234 (in-sample avg dev_std = 0.485)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.78
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.25210625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0 = 0.318 +- 0.285 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 1 = 0.276 +- 0.285 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 2 = 0.402 +- 0.285 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all KL = 0.308 +- 0.285 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all L1 = 0.332 +- 0.197 (in-sample avg dev_std = 0.492)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.789
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25210625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.618
NEC for r=1.0 class 0 = 0.312 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 class 1 = 0.339 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 class 2 = 0.424 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 all KL = 0.316 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 all L1 = 0.358 +- 0.185 (in-sample avg dev_std = 0.496)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 13:58:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 01:58:36 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 0.8396
Train Loss: 0.5054
ID Validation ACCURACY: 0.8567
ID Validation Loss: 0.4677
ID Test ACCURACY: 0.8283
ID Test Loss: 0.5320
OOD Validation ACCURACY: 0.7540
OOD Validation Loss: 0.7147
OOD Test ACCURACY: 0.8567
OOD Test Loss: 0.4681

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 0.8396
Train Loss: 0.5054
ID Validation ACCURACY: 0.8567
ID Validation Loss: 0.4677
ID Test ACCURACY: 0.8283
ID Test Loss: 0.5320
OOD Validation ACCURACY: 0.7540
OOD Validation Loss: 0.7147
OOD Test ACCURACY: 0.8567
OOD Test Loss: 0.4681

[0m[1;37mINFO[0m: [1mChartInfo 0.8283 0.8567 0.8283 0.8567 0.8567 0.7540[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.083
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.228
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.290
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.308
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.139
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.241
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.249
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.249


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.08314375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.357
SUFF++ for r=0.3 class 0 = 0.473 +- 0.248 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 1 = 0.516 +- 0.248 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.248 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all KL = 0.401 +- 0.248 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.3 all L1 = 0.487 +- 0.169 (in-sample avg dev_std = 0.589)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22802
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.385
SUFF++ for r=0.6 class 0 = 0.447 +- 0.278 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 1 = 0.537 +- 0.278 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 2 = 0.416 +- 0.278 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all KL = 0.431 +- 0.278 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all L1 = 0.467 +- 0.180 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.837
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29028625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.534
SUFF++ for r=0.9 class 0 = 0.53 +- 0.320 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 class 1 = 0.691 +- 0.320 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 class 2 = 0.489 +- 0.320 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 all KL = 0.583 +- 0.320 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 all L1 = 0.571 +- 0.240 (in-sample avg dev_std = 0.416)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1386725
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.426
SUFF++ for r=0.3 class 0 = 0.492 +- 0.281 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 class 1 = 0.542 +- 0.281 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 class 2 = 0.488 +- 0.281 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 all KL = 0.315 +- 0.281 (in-sample avg dev_std = 0.659)
SUFF++ for r=0.3 all L1 = 0.508 +- 0.136 (in-sample avg dev_std = 0.659)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24096625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.41
SUFF++ for r=0.6 class 0 = 0.402 +- 0.294 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 1 = 0.535 +- 0.294 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 2 = 0.354 +- 0.294 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all KL = 0.408 +- 0.294 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all L1 = 0.432 +- 0.183 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.869
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24873874999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.432
SUFF++ for r=0.9 class 0 = 0.418 +- 0.302 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 1 = 0.565 +- 0.302 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 class 2 = 0.374 +- 0.302 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all KL = 0.445 +- 0.302 (in-sample avg dev_std = 0.388)
SUFF++ for r=0.9 all L1 = 0.454 +- 0.206 (in-sample avg dev_std = 0.388)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.505
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.08314375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.451
NEC for r=0.3 class 0 = 0.437 +- 0.322 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 1 = 0.383 +- 0.322 (in-sample avg dev_std = 0.432)
NEC for r=0.3 class 2 = 0.382 +- 0.322 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all KL = 0.438 +- 0.322 (in-sample avg dev_std = 0.432)
NEC for r=0.3 all L1 = 0.401 +- 0.269 (in-sample avg dev_std = 0.432)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22802
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.471
NEC for r=0.6 class 0 = 0.489 +- 0.301 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 1 = 0.433 +- 0.301 (in-sample avg dev_std = 0.562)
NEC for r=0.6 class 2 = 0.5 +- 0.301 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all KL = 0.526 +- 0.301 (in-sample avg dev_std = 0.562)
NEC for r=0.6 all L1 = 0.474 +- 0.220 (in-sample avg dev_std = 0.562)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.837
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29028625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.546
NEC for r=0.9 class 0 = 0.492 +- 0.310 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 1 = 0.377 +- 0.310 (in-sample avg dev_std = 0.567)
NEC for r=0.9 class 2 = 0.508 +- 0.310 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all KL = 0.479 +- 0.310 (in-sample avg dev_std = 0.567)
NEC for r=0.9 all L1 = 0.458 +- 0.206 (in-sample avg dev_std = 0.567)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.864
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30800875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.543
NEC for r=1.0 class 0 = 0.508 +- 0.311 (in-sample avg dev_std = 0.557)
NEC for r=1.0 class 1 = 0.376 +- 0.311 (in-sample avg dev_std = 0.557)
NEC for r=1.0 class 2 = 0.496 +- 0.311 (in-sample avg dev_std = 0.557)
NEC for r=1.0 all KL = 0.476 +- 0.311 (in-sample avg dev_std = 0.557)
NEC for r=1.0 all L1 = 0.459 +- 0.201 (in-sample avg dev_std = 0.557)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.1386725
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.532
NEC for r=0.3 class 0 = 0.293 +- 0.368 (in-sample avg dev_std = 0.531)
NEC for r=0.3 class 1 = 0.264 +- 0.368 (in-sample avg dev_std = 0.531)
NEC for r=0.3 class 2 = 0.268 +- 0.368 (in-sample avg dev_std = 0.531)
NEC for r=0.3 all KL = 0.443 +- 0.368 (in-sample avg dev_std = 0.531)
NEC for r=0.3 all L1 = 0.275 +- 0.202 (in-sample avg dev_std = 0.531)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.24096625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.619
NEC for r=0.6 class 0 = 0.407 +- 0.389 (in-sample avg dev_std = 0.512)
NEC for r=0.6 class 1 = 0.24 +- 0.389 (in-sample avg dev_std = 0.512)
NEC for r=0.6 class 2 = 0.395 +- 0.389 (in-sample avg dev_std = 0.512)
NEC for r=0.6 all KL = 0.403 +- 0.389 (in-sample avg dev_std = 0.512)
NEC for r=0.6 all L1 = 0.346 +- 0.276 (in-sample avg dev_std = 0.512)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.869
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24873874999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.642
NEC for r=0.9 class 0 = 0.409 +- 0.349 (in-sample avg dev_std = 0.529)
NEC for r=0.9 class 1 = 0.236 +- 0.349 (in-sample avg dev_std = 0.529)
NEC for r=0.9 class 2 = 0.384 +- 0.349 (in-sample avg dev_std = 0.529)
NEC for r=0.9 all KL = 0.392 +- 0.349 (in-sample avg dev_std = 0.529)
NEC for r=0.9 all L1 = 0.341 +- 0.234 (in-sample avg dev_std = 0.529)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.873
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.24873874999999998
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.626
NEC for r=1.0 class 0 = 0.431 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 class 1 = 0.282 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 class 2 = 0.426 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 all KL = 0.42 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 all L1 = 0.378 +- 0.217 (in-sample avg dev_std = 0.547)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:01:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:01:10 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.8734
Train Loss: 0.4599
ID Validation ACCURACY: 0.8810
ID Validation Loss: 0.4475
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4786
OOD Validation ACCURACY: 0.8663
OOD Validation Loss: 0.5284
OOD Test ACCURACY: 0.8430
OOD Test Loss: 0.5743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ACCURACY: 0.8522
Train Loss: 0.4709
ID Validation ACCURACY: 0.8573
ID Validation Loss: 0.4632
ID Test ACCURACY: 0.8450
ID Test Loss: 0.4949
OOD Validation ACCURACY: 0.9020
OOD Validation Loss: 0.5173
OOD Test ACCURACY: 0.8550
OOD Test Loss: 0.5385

[0m[1;37mINFO[0m: [1mChartInfo 0.8727 0.8430 0.8450 0.8550 0.8573 0.9020[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.066
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.156
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.282
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.054
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.126
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.219
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.06593125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
SUFF++ for r=0.3 class 0 = 0.521 +- 0.331 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 1 = 0.499 +- 0.331 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 2 = 0.49 +- 0.331 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all KL = 0.474 +- 0.331 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all L1 = 0.503 +- 0.194 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.15583
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.356
SUFF++ for r=0.6 class 0 = 0.576 +- 0.316 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1 = 0.53 +- 0.316 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 2 = 0.514 +- 0.316 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.554 +- 0.316 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.54 +- 0.207 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.281675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.44
SUFF++ for r=0.9 class 0 = 0.568 +- 0.278 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.9 class 1 = 0.591 +- 0.278 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.9 class 2 = 0.509 +- 0.278 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.9 all KL = 0.596 +- 0.278 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.9 all L1 = 0.556 +- 0.185 (in-sample avg dev_std = 0.443)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.365
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.054102500000000005
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.296
SUFF++ for r=0.3 class 0 = 0.406 +- 0.272 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.3 class 1 = 0.453 +- 0.272 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.3 class 2 = 0.414 +- 0.272 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.3 all KL = 0.433 +- 0.272 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.3 all L1 = 0.425 +- 0.155 (in-sample avg dev_std = 0.474)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.125525
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.39
SUFF++ for r=0.6 class 0 = 0.506 +- 0.271 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.572 +- 0.271 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.522 +- 0.271 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.516 +- 0.271 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.534 +- 0.196 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.21876250000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.407
SUFF++ for r=0.9 class 0 = 0.455 +- 0.258 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 1 = 0.482 +- 0.258 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 class 2 = 0.558 +- 0.258 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all KL = 0.546 +- 0.258 (in-sample avg dev_std = 0.352)
SUFF++ for r=0.9 all L1 = 0.499 +- 0.186 (in-sample avg dev_std = 0.352)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.493
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.06593125000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.404
NEC for r=0.3 class 0 = 0.414 +- 0.312 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 1 = 0.437 +- 0.312 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 2 = 0.455 +- 0.312 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all KL = 0.427 +- 0.312 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all L1 = 0.435 +- 0.197 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.15583
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.461
NEC for r=0.6 class 0 = 0.463 +- 0.297 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 1 = 0.453 +- 0.297 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 2 = 0.493 +- 0.297 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all KL = 0.458 +- 0.297 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all L1 = 0.47 +- 0.206 (in-sample avg dev_std = 0.521)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.281675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.493
NEC for r=0.9 class 0 = 0.472 +- 0.258 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 1 = 0.466 +- 0.258 (in-sample avg dev_std = 0.491)
NEC for r=0.9 class 2 = 0.492 +- 0.258 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all KL = 0.441 +- 0.258 (in-sample avg dev_std = 0.491)
NEC for r=0.9 all L1 = 0.477 +- 0.173 (in-sample avg dev_std = 0.491)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31046625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.589
NEC for r=1.0 class 0 = 0.477 +- 0.270 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 1 = 0.392 +- 0.270 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 2 = 0.522 +- 0.270 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all KL = 0.478 +- 0.270 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all L1 = 0.463 +- 0.176 (in-sample avg dev_std = 0.545)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.365
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.054102500000000005
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.33
NEC for r=0.3 class 0 = 0.594 +- 0.256 (in-sample avg dev_std = 0.550)
NEC for r=0.3 class 1 = 0.571 +- 0.256 (in-sample avg dev_std = 0.550)
NEC for r=0.3 class 2 = 0.58 +- 0.256 (in-sample avg dev_std = 0.550)
NEC for r=0.3 all KL = 0.58 +- 0.256 (in-sample avg dev_std = 0.550)
NEC for r=0.3 all L1 = 0.581 +- 0.138 (in-sample avg dev_std = 0.550)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.125525
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.427
NEC for r=0.6 class 0 = 0.445 +- 0.256 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 1 = 0.53 +- 0.256 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 2 = 0.429 +- 0.256 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all KL = 0.499 +- 0.256 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all L1 = 0.469 +- 0.171 (in-sample avg dev_std = 0.528)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.21876250000000003
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.542
NEC for r=0.9 class 0 = 0.519 +- 0.232 (in-sample avg dev_std = 0.424)
NEC for r=0.9 class 1 = 0.494 +- 0.232 (in-sample avg dev_std = 0.424)
NEC for r=0.9 class 2 = 0.412 +- 0.232 (in-sample avg dev_std = 0.424)
NEC for r=0.9 all KL = 0.439 +- 0.232 (in-sample avg dev_std = 0.424)
NEC for r=0.9 all L1 = 0.475 +- 0.143 (in-sample avg dev_std = 0.424)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25216125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.606
NEC for r=1.0 class 0 = 0.527 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 1 = 0.507 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 2 = 0.359 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all KL = 0.485 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all L1 = 0.464 +- 0.159 (in-sample avg dev_std = 0.511)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.53, 0.485, 0.611, 1.0], 'all_L1': [0.498, 0.454, 0.571, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.569, 0.482, 0.507, 1.0], 'all_L1': [0.53, 0.44, 0.507, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.413, 0.471, 0.603, 1.0], 'all_L1': [0.5, 0.458, 0.545, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.401, 0.431, 0.583, 1.0], 'all_L1': [0.487, 0.467, 0.571, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.474, 0.554, 0.596, 1.0], 'all_L1': [0.503, 0.54, 0.556, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.398, 0.447, 0.475, 0.482], 'all_L1': [0.437, 0.471, 0.493, 0.503]}), defaultdict(<class 'list'>, {'all_KL': [0.378, 0.452, 0.546, 0.551], 'all_L1': [0.425, 0.493, 0.512, 0.511]}), defaultdict(<class 'list'>, {'all_KL': [0.45, 0.424, 0.394, 0.388], 'all_L1': [0.404, 0.441, 0.43, 0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.438, 0.526, 0.479, 0.476], 'all_L1': [0.401, 0.474, 0.458, 0.459]}), defaultdict(<class 'list'>, {'all_KL': [0.427, 0.458, 0.441, 0.478], 'all_L1': [0.435, 0.47, 0.477, 0.463]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.422, 0.43, 0.736, 1.0], 'all_L1': [0.444, 0.497, 0.658, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.403, 0.319, 0.366, 1.0], 'all_L1': [0.423, 0.363, 0.405, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.477, 0.534, 0.56, 1.0], 'all_L1': [0.516, 0.484, 0.489, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.315, 0.408, 0.445, 1.0], 'all_L1': [0.508, 0.432, 0.454, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.433, 0.516, 0.546, 1.0], 'all_L1': [0.425, 0.534, 0.499, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.568, 0.493, 0.341, 0.351], 'all_L1': [0.537, 0.426, 0.389, 0.372]}), defaultdict(<class 'list'>, {'all_KL': [0.431, 0.472, 0.487, 0.469], 'all_L1': [0.432, 0.417, 0.428, 0.411]}), defaultdict(<class 'list'>, {'all_KL': [0.292, 0.311, 0.308, 0.316], 'all_L1': [0.289, 0.317, 0.332, 0.358]}), defaultdict(<class 'list'>, {'all_KL': [0.443, 0.403, 0.392, 0.42], 'all_L1': [0.275, 0.346, 0.341, 0.378]}), defaultdict(<class 'list'>, {'all_KL': [0.58, 0.499, 0.439, 0.485], 'all_L1': [0.581, 0.469, 0.475, 0.464]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.504 +- 0.014, 0.472 +- 0.035, 0.550 +- 0.024, 1.000 +- 0.000
suff++ class all_KL  =  0.477 +- 0.065, 0.485 +- 0.040, 0.580 +- 0.038, 1.000 +- 0.000
suff++_acc_int  =  0.355 +- 0.010, 0.379 +- 0.019, 0.484 +- 0.034
nec class all_L1  =  0.420 +- 0.015, 0.470 +- 0.017, 0.474 +- 0.028, 0.475 +- 0.027
nec class all_KL  =  0.418 +- 0.026, 0.461 +- 0.034, 0.467 +- 0.050, 0.475 +- 0.052
nec_acc_int  =  0.413 +- 0.028, 0.495 +- 0.035, 0.535 +- 0.027, 0.548 +- 0.028

Eval split test
suff++ class all_L1  =  0.463 +- 0.041, 0.462 +- 0.059, 0.501 +- 0.085, 1.000 +- 0.000
suff++ class all_KL  =  0.410 +- 0.053, 0.441 +- 0.078, 0.531 +- 0.125, 1.000 +- 0.000
suff++_acc_int  =  0.375 +- 0.053, 0.387 +- 0.022, 0.415 +- 0.016
nec class all_L1  =  0.423 +- 0.125, 0.395 +- 0.056, 0.393 +- 0.054, 0.397 +- 0.038
nec class all_KL  =  0.463 +- 0.105, 0.436 +- 0.071, 0.393 +- 0.065, 0.408 +- 0.066
nec_acc_int  =  0.445 +- 0.107, 0.550 +- 0.079, 0.582 +- 0.060, 0.593 +- 0.053


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.462 +- 0.012, 0.471 +- 0.018, 0.512 +- 0.014, 0.738 +- 0.013
Faith. Armon (L1)= 		  =  0.458 +- 0.012, 0.470 +- 0.018, 0.508 +- 0.016, 0.644 +- 0.025
Faith. GMean (L1)= 	  =  0.460 +- 0.012, 0.470 +- 0.018, 0.510 +- 0.015, 0.689 +- 0.020
Faith. Aritm (KL)= 		  =  0.448 +- 0.020, 0.473 +- 0.019, 0.524 +- 0.015, 0.738 +- 0.026
Faith. Armon (KL)= 		  =  0.442 +- 0.014, 0.471 +- 0.018, 0.514 +- 0.021, 0.642 +- 0.048
Faith. GMean (KL)= 	  =  0.445 +- 0.017, 0.472 +- 0.019, 0.519 +- 0.018, 0.688 +- 0.038

Eval split test
Faith. Aritm (L1)= 		  =  0.443 +- 0.046, 0.428 +- 0.045, 0.447 +- 0.049, 0.698 +- 0.019
Faith. Armon (L1)= 		  =  0.426 +- 0.056, 0.423 +- 0.048, 0.435 +- 0.044, 0.567 +- 0.038
Faith. GMean (L1)= 	  =  0.435 +- 0.051, 0.426 +- 0.046, 0.441 +- 0.046, 0.629 +- 0.030
Faith. Aritm (KL)= 		  =  0.436 +- 0.054, 0.438 +- 0.041, 0.462 +- 0.046, 0.704 +- 0.033
Faith. Armon (KL)= 		  =  0.425 +- 0.056, 0.429 +- 0.047, 0.437 +- 0.034, 0.577 +- 0.067
Faith. GMean (KL)= 	  =  0.431 +- 0.055, 0.434 +- 0.044, 0.449 +- 0.038, 0.637 +- 0.052
Computed for split load_split = id



Completed in  0:13:20.855222  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:04:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:04:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 18...
[0m[1;37mINFO[0m: [1mCheckpoint 18: 
-----------------------------------
Train ACCURACY: 0.6871
Train Loss: 0.8504
ID Validation ACCURACY: 0.6993
ID Validation Loss: 0.8351
ID Test ACCURACY: 0.6983
ID Test Loss: 0.8449
OOD Validation ACCURACY: 0.5330
OOD Validation Loss: 1.1042
OOD Test ACCURACY: 0.5190
OOD Test Loss: 1.0268

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ACCURACY: 0.5497
Train Loss: 1.1856
ID Validation ACCURACY: 0.5620
ID Validation Loss: 1.1989
ID Test ACCURACY: 0.5707
ID Test Loss: 1.1955
OOD Validation ACCURACY: 0.6903
OOD Validation Loss: 0.7487
OOD Test ACCURACY: 0.6773
OOD Test Loss: 0.7183

[0m[1;37mINFO[0m: [1mChartInfo 0.6983 0.5190 0.5707 0.6773 0.5620 0.6903[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.029
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.100
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.261
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.309
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.054
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.121
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.224
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.344
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.028933749999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.344
SUFF++ for r=0.3 class 0 = 0.689 +- 0.140 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 1 = 0.702 +- 0.140 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 2 = 0.693 +- 0.140 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all KL = 0.847 +- 0.140 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all L1 = 0.695 +- 0.111 (in-sample avg dev_std = 0.249)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.416
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.09975875000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.33
SUFF++ for r=0.6 class 0 = 0.722 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 1 = 0.739 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 2 = 0.72 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all KL = 0.881 +- 0.141 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all L1 = 0.727 +- 0.147 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.445
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.261175
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.389
SUFF++ for r=0.9 class 0 = 0.773 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1 = 0.822 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 2 = 0.752 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.91 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.782 +- 0.136 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.248
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.053795
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.384
SUFF++ for r=0.3 class 0 = 0.568 +- 0.224 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 1 = 0.627 +- 0.224 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 class 2 = 0.579 +- 0.224 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all KL = 0.723 +- 0.224 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.3 all L1 = 0.592 +- 0.123 (in-sample avg dev_std = 0.249)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.417
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.12070375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.286
SUFF++ for r=0.6 class 0 = 0.669 +- 0.105 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 class 1 = 0.654 +- 0.105 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 class 2 = 0.609 +- 0.105 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all KL = 0.826 +- 0.105 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all L1 = 0.644 +- 0.095 (in-sample avg dev_std = 0.252)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.374
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.22354
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.461
SUFF++ for r=0.9 class 0 = 0.734 +- 0.158 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 1 = 0.779 +- 0.158 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 class 2 = 0.663 +- 0.158 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all KL = 0.878 +- 0.158 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.9 all L1 = 0.726 +- 0.140 (in-sample avg dev_std = 0.184)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.344
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.028933749999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.368
NEC for r=0.3 class 0 = 0.325 +- 0.133 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 1 = 0.325 +- 0.133 (in-sample avg dev_std = 0.241)
NEC for r=0.3 class 2 = 0.333 +- 0.133 (in-sample avg dev_std = 0.241)
NEC for r=0.3 all KL = 0.169 +- 0.133 (in-sample avg dev_std = 0.241)
NEC for r=0.3 all L1 = 0.327 +- 0.115 (in-sample avg dev_std = 0.241)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.416
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.09975875000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.34
NEC for r=0.6 class 0 = 0.341 +- 0.141 (in-sample avg dev_std = 0.208)
NEC for r=0.6 class 1 = 0.291 +- 0.141 (in-sample avg dev_std = 0.208)
NEC for r=0.6 class 2 = 0.333 +- 0.141 (in-sample avg dev_std = 0.208)
NEC for r=0.6 all KL = 0.149 +- 0.141 (in-sample avg dev_std = 0.208)
NEC for r=0.6 all L1 = 0.321 +- 0.141 (in-sample avg dev_std = 0.208)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.445
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.261175
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.388
NEC for r=0.9 class 0 = 0.32 +- 0.117 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 1 = 0.265 +- 0.117 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 2 = 0.35 +- 0.117 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all KL = 0.143 +- 0.117 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all L1 = 0.311 +- 0.120 (in-sample avg dev_std = 0.210)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.72
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3092375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.48
NEC for r=1.0 class 0 = 0.316 +- 0.136 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 1 = 0.243 +- 0.136 (in-sample avg dev_std = 0.208)
NEC for r=1.0 class 2 = 0.355 +- 0.136 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all KL = 0.147 +- 0.136 (in-sample avg dev_std = 0.208)
NEC for r=1.0 all L1 = 0.304 +- 0.134 (in-sample avg dev_std = 0.208)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.248
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.053795
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.364
NEC for r=0.3 class 0 = 0.414 +- 0.196 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 1 = 0.393 +- 0.196 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 2 = 0.4 +- 0.196 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all KL = 0.278 +- 0.196 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all L1 = 0.402 +- 0.118 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.417
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.12070375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.345
NEC for r=0.6 class 0 = 0.344 +- 0.128 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 1 = 0.375 +- 0.128 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 2 = 0.364 +- 0.128 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all KL = 0.187 +- 0.128 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all L1 = 0.361 +- 0.100 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.374
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.22354
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.498
NEC for r=0.9 class 0 = 0.274 +- 0.137 (in-sample avg dev_std = 0.208)
NEC for r=0.9 class 1 = 0.244 +- 0.137 (in-sample avg dev_std = 0.208)
NEC for r=0.9 class 2 = 0.339 +- 0.137 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all KL = 0.126 +- 0.137 (in-sample avg dev_std = 0.208)
NEC for r=0.9 all L1 = 0.286 +- 0.123 (in-sample avg dev_std = 0.208)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.531
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.252145
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.571
NEC for r=1.0 class 0 = 0.249 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 1 = 0.231 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 2 = 0.34 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all KL = 0.121 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all L1 = 0.273 +- 0.134 (in-sample avg dev_std = 0.203)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:06:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:06:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 70...
[0m[1;37mINFO[0m: [1mCheckpoint 70: 
-----------------------------------
Train ACCURACY: 0.6884
Train Loss: 0.7575
ID Validation ACCURACY: 0.7133
ID Validation Loss: 0.7174
ID Test ACCURACY: 0.6943
ID Test Loss: 0.7583
OOD Validation ACCURACY: 0.5157
OOD Validation Loss: 1.1036
OOD Test ACCURACY: 0.7193
OOD Test Loss: 0.7663

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 75...
[0m[1;37mINFO[0m: [1mCheckpoint 75: 
-----------------------------------
Train ACCURACY: 0.5467
Train Loss: 0.9902
ID Validation ACCURACY: 0.5517
ID Validation Loss: 0.9905
ID Test ACCURACY: 0.5537
ID Test Loss: 0.9969
OOD Validation ACCURACY: 0.7237
OOD Validation Loss: 0.7625
OOD Test ACCURACY: 0.6420
OOD Test Loss: 0.7160

[0m[1;37mINFO[0m: [1mChartInfo 0.6943 0.7193 0.5537 0.6420 0.5517 0.7237[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.102
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.231
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.299
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.311
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.060
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.186
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.236
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.4
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.10150749999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.352
SUFF++ for r=0.3 class 0 = 0.433 +- 0.214 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 1 = 0.438 +- 0.214 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 class 2 = 0.483 +- 0.214 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all KL = 0.415 +- 0.214 (in-sample avg dev_std = 0.507)
SUFF++ for r=0.3 all L1 = 0.451 +- 0.125 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.488
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23065624999999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.354
SUFF++ for r=0.6 class 0 = 0.416 +- 0.232 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 1 = 0.419 +- 0.232 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 class 2 = 0.434 +- 0.232 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all KL = 0.437 +- 0.232 (in-sample avg dev_std = 0.481)
SUFF++ for r=0.6 all L1 = 0.423 +- 0.116 (in-sample avg dev_std = 0.481)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.702
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.299085
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.537
SUFF++ for r=0.9 class 0 = 0.548 +- 0.264 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.9 class 1 = 0.535 +- 0.264 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.9 class 2 = 0.511 +- 0.264 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.9 all KL = 0.571 +- 0.264 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.9 all L1 = 0.531 +- 0.176 (in-sample avg dev_std = 0.433)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.347
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.060143749999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.334
SUFF++ for r=0.3 class 0 = 0.472 +- 0.225 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 1 = 0.488 +- 0.225 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 2 = 0.467 +- 0.225 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all KL = 0.489 +- 0.225 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all L1 = 0.476 +- 0.105 (in-sample avg dev_std = 0.436)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.246
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.18632375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.386
SUFF++ for r=0.6 class 0 = 0.484 +- 0.178 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 1 = 0.495 +- 0.178 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 2 = 0.478 +- 0.178 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all KL = 0.578 +- 0.178 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all L1 = 0.486 +- 0.098 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.23625749999999995
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.527
SUFF++ for r=0.9 class 0 = 0.58 +- 0.280 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.9 class 1 = 0.592 +- 0.280 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.9 class 2 = 0.5 +- 0.280 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.9 all KL = 0.597 +- 0.280 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.9 all L1 = 0.557 +- 0.191 (in-sample avg dev_std = 0.417)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.4
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.10150749999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.549 +- 0.253 (in-sample avg dev_std = 0.461)
NEC for r=0.3 class 1 = 0.509 +- 0.253 (in-sample avg dev_std = 0.461)
NEC for r=0.3 class 2 = 0.502 +- 0.253 (in-sample avg dev_std = 0.461)
NEC for r=0.3 all KL = 0.55 +- 0.253 (in-sample avg dev_std = 0.461)
NEC for r=0.3 all L1 = 0.52 +- 0.183 (in-sample avg dev_std = 0.461)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.488
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.23065624999999998
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.397
NEC for r=0.6 class 0 = 0.561 +- 0.219 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 1 = 0.528 +- 0.219 (in-sample avg dev_std = 0.489)
NEC for r=0.6 class 2 = 0.526 +- 0.219 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all KL = 0.52 +- 0.219 (in-sample avg dev_std = 0.489)
NEC for r=0.6 all L1 = 0.538 +- 0.133 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.702
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.299085
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.48
NEC for r=0.9 class 0 = 0.535 +- 0.227 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 1 = 0.563 +- 0.227 (in-sample avg dev_std = 0.476)
NEC for r=0.9 class 2 = 0.5 +- 0.227 (in-sample avg dev_std = 0.476)
NEC for r=0.9 all KL = 0.517 +- 0.227 (in-sample avg dev_std = 0.476)
NEC for r=0.9 all L1 = 0.533 +- 0.139 (in-sample avg dev_std = 0.476)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.724
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31105499999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.506
NEC for r=1.0 class 0 = 0.511 +- 0.224 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 1 = 0.551 +- 0.224 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 2 = 0.457 +- 0.224 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all KL = 0.472 +- 0.224 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all L1 = 0.507 +- 0.136 (in-sample avg dev_std = 0.458)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.347
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.060143749999999996
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.533 +- 0.209 (in-sample avg dev_std = 0.418)
NEC for r=0.3 class 1 = 0.485 +- 0.209 (in-sample avg dev_std = 0.418)
NEC for r=0.3 class 2 = 0.517 +- 0.209 (in-sample avg dev_std = 0.418)
NEC for r=0.3 all KL = 0.49 +- 0.209 (in-sample avg dev_std = 0.418)
NEC for r=0.3 all L1 = 0.511 +- 0.125 (in-sample avg dev_std = 0.418)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.246
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.18632375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.45
NEC for r=0.6 class 0 = 0.495 +- 0.194 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 1 = 0.494 +- 0.194 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 2 = 0.535 +- 0.194 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all KL = 0.407 +- 0.194 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all L1 = 0.508 +- 0.117 (in-sample avg dev_std = 0.388)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.23625749999999995
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.587
NEC for r=0.9 class 0 = 0.446 +- 0.309 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 1 = 0.447 +- 0.309 (in-sample avg dev_std = 0.462)
NEC for r=0.9 class 2 = 0.495 +- 0.309 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all KL = 0.435 +- 0.309 (in-sample avg dev_std = 0.462)
NEC for r=0.9 all L1 = 0.463 +- 0.190 (in-sample avg dev_std = 0.462)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25226624999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.593
NEC for r=1.0 class 0 = 0.433 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 1 = 0.427 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 2 = 0.478 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all KL = 0.416 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all L1 = 0.446 +- 0.193 (in-sample avg dev_std = 0.458)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:09:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:09:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ACCURACY: 0.6692
Train Loss: 0.8985
ID Validation ACCURACY: 0.6720
ID Validation Loss: 0.8802
ID Test ACCURACY: 0.6757
ID Test Loss: 0.8848
OOD Validation ACCURACY: 0.3387
OOD Validation Loss: 1.1799
OOD Test ACCURACY: 0.5467
OOD Test Loss: 0.8602

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ACCURACY: 0.5163
Train Loss: 1.2847
ID Validation ACCURACY: 0.5163
ID Validation Loss: 1.3363
ID Test ACCURACY: 0.5163
ID Test Loss: 1.3361
OOD Validation ACCURACY: 0.6937
OOD Validation Loss: 0.7726
OOD Test ACCURACY: 0.6027
OOD Test Loss: 0.9304

[0m[1;37mINFO[0m: [1mChartInfo 0.6757 0.5467 0.5163 0.6027 0.5163 0.6937[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.003
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.060
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.250
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.002
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.049
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.208
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.352
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.00256875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.338
SUFF++ for r=0.3 class 0 = 0.714 +- 0.149 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 1 = 0.728 +- 0.149 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 class 2 = 0.722 +- 0.149 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all KL = 0.867 +- 0.149 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.3 all L1 = 0.721 +- 0.146 (in-sample avg dev_std = 0.233)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.24
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0599625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.331
SUFF++ for r=0.6 class 0 = 0.76 +- 0.076 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 1 = 0.759 +- 0.076 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 class 2 = 0.766 +- 0.076 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all KL = 0.911 +- 0.076 (in-sample avg dev_std = 0.205)
SUFF++ for r=0.6 all L1 = 0.762 +- 0.104 (in-sample avg dev_std = 0.205)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.379
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2503
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.416
SUFF++ for r=0.9 class 0 = 0.797 +- 0.076 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 class 1 = 0.858 +- 0.076 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 class 2 = 0.814 +- 0.076 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all KL = 0.94 +- 0.076 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.112 (in-sample avg dev_std = 0.171)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.256
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.00183
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.399
SUFF++ for r=0.3 class 0 = 0.562 +- 0.147 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 class 1 = 0.617 +- 0.147 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 class 2 = 0.571 +- 0.147 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 all KL = 0.719 +- 0.147 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 all L1 = 0.584 +- 0.114 (in-sample avg dev_std = 0.334)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.275
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.04886625000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.305
SUFF++ for r=0.6 class 0 = 0.688 +- 0.087 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 class 1 = 0.724 +- 0.087 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 class 2 = 0.705 +- 0.087 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all KL = 0.883 +- 0.087 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.6 all L1 = 0.706 +- 0.114 (in-sample avg dev_std = 0.221)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.389
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.20823
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.424
SUFF++ for r=0.9 class 0 = 0.778 +- 0.060 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 class 1 = 0.8 +- 0.060 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 class 2 = 0.72 +- 0.060 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 all KL = 0.928 +- 0.060 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.9 all L1 = 0.766 +- 0.104 (in-sample avg dev_std = 0.177)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.352
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.00256875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.289 +- 0.123 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 1 = 0.271 +- 0.123 (in-sample avg dev_std = 0.232)
NEC for r=0.3 class 2 = 0.307 +- 0.123 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all KL = 0.133 +- 0.123 (in-sample avg dev_std = 0.232)
NEC for r=0.3 all L1 = 0.289 +- 0.134 (in-sample avg dev_std = 0.232)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.24
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0599625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.351
NEC for r=0.6 class 0 = 0.239 +- 0.105 (in-sample avg dev_std = 0.190)
NEC for r=0.6 class 1 = 0.294 +- 0.105 (in-sample avg dev_std = 0.190)
NEC for r=0.6 class 2 = 0.265 +- 0.105 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all KL = 0.107 +- 0.105 (in-sample avg dev_std = 0.190)
NEC for r=0.6 all L1 = 0.266 +- 0.137 (in-sample avg dev_std = 0.190)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.379
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2503
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.358
NEC for r=0.9 class 0 = 0.272 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 1 = 0.211 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.9 class 2 = 0.247 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all KL = 0.1 +- 0.127 (in-sample avg dev_std = 0.184)
NEC for r=0.9 all L1 = 0.243 +- 0.147 (in-sample avg dev_std = 0.184)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.696
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3101725
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.487
NEC for r=1.0 class 0 = 0.24 +- 0.144 (in-sample avg dev_std = 0.202)
NEC for r=1.0 class 1 = 0.205 +- 0.144 (in-sample avg dev_std = 0.202)
NEC for r=1.0 class 2 = 0.279 +- 0.144 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all KL = 0.108 +- 0.144 (in-sample avg dev_std = 0.202)
NEC for r=1.0 all L1 = 0.241 +- 0.144 (in-sample avg dev_std = 0.202)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.256
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.00183
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.352
NEC for r=0.3 class 0 = 0.404 +- 0.145 (in-sample avg dev_std = 0.313)
NEC for r=0.3 class 1 = 0.359 +- 0.145 (in-sample avg dev_std = 0.313)
NEC for r=0.3 class 2 = 0.371 +- 0.145 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all KL = 0.243 +- 0.145 (in-sample avg dev_std = 0.313)
NEC for r=0.3 all L1 = 0.377 +- 0.134 (in-sample avg dev_std = 0.313)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.275
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.04886625000000001
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.305
NEC for r=0.6 class 0 = 0.287 +- 0.085 (in-sample avg dev_std = 0.194)
NEC for r=0.6 class 1 = 0.252 +- 0.085 (in-sample avg dev_std = 0.194)
NEC for r=0.6 class 2 = 0.305 +- 0.085 (in-sample avg dev_std = 0.194)
NEC for r=0.6 all KL = 0.106 +- 0.085 (in-sample avg dev_std = 0.194)
NEC for r=0.6 all L1 = 0.281 +- 0.115 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.389
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.20823
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.413
NEC for r=0.9 class 0 = 0.299 +- 0.059 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1 = 0.212 +- 0.059 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 2 = 0.319 +- 0.059 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.096 +- 0.059 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.276 +- 0.099 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.544
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25144
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.452
NEC for r=1.0 class 0 = 0.215 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 1 = 0.18 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 2 = 0.231 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all KL = 0.076 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all L1 = 0.208 +- 0.098 (in-sample avg dev_std = 0.198)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:11:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:11:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 49...
[0m[1;37mINFO[0m: [1mCheckpoint 49: 
-----------------------------------
Train ACCURACY: 0.7740
Train Loss: 0.6713
ID Validation ACCURACY: 0.7883
ID Validation Loss: 0.6566
ID Test ACCURACY: 0.7730
ID Test Loss: 0.7012
OOD Validation ACCURACY: 0.4643
OOD Validation Loss: 1.2859
OOD Test ACCURACY: 0.7057
OOD Test Loss: 0.6370

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 68...
[0m[1;37mINFO[0m: [1mCheckpoint 68: 
-----------------------------------
Train ACCURACY: 0.6974
Train Loss: 0.7951
ID Validation ACCURACY: 0.7197
ID Validation Loss: 0.7468
ID Test ACCURACY: 0.7103
ID Test Loss: 0.8074
OOD Validation ACCURACY: 0.6740
OOD Validation Loss: 0.8290
OOD Test ACCURACY: 0.6273
OOD Test Loss: 0.9364

[0m[1;37mINFO[0m: [1mChartInfo 0.7730 0.7057 0.7103 0.6273 0.7197 0.6740[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.050
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.208
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.286
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.309
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.028
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.169
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.236
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.287
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.05001250000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.469 +- 0.244 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 class 1 = 0.493 +- 0.244 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 class 2 = 0.47 +- 0.244 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 all KL = 0.504 +- 0.244 (in-sample avg dev_std = 0.487)
SUFF++ for r=0.3 all L1 = 0.477 +- 0.126 (in-sample avg dev_std = 0.487)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.482
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.20775125000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.356
SUFF++ for r=0.6 class 0 = 0.454 +- 0.281 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 class 1 = 0.478 +- 0.281 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 class 2 = 0.474 +- 0.281 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 all KL = 0.493 +- 0.281 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.6 all L1 = 0.469 +- 0.129 (in-sample avg dev_std = 0.437)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.7
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.28617875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.551
SUFF++ for r=0.9 class 0 = 0.572 +- 0.287 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.9 class 1 = 0.549 +- 0.287 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.9 class 2 = 0.6 +- 0.287 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.9 all KL = 0.578 +- 0.287 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.9 all L1 = 0.574 +- 0.179 (in-sample avg dev_std = 0.434)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.387
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.027622499999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.334
SUFF++ for r=0.3 class 0 = 0.452 +- 0.243 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 1 = 0.474 +- 0.243 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 2 = 0.522 +- 0.243 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all KL = 0.549 +- 0.243 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all L1 = 0.483 +- 0.135 (in-sample avg dev_std = 0.455)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.305
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.16866
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.336
SUFF++ for r=0.6 class 0 = 0.415 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 1 = 0.442 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 2 = 0.438 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all KL = 0.463 +- 0.259 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all L1 = 0.432 +- 0.124 (in-sample avg dev_std = 0.409)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2361575
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.537
SUFF++ for r=0.9 class 0 = 0.531 +- 0.275 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 1 = 0.543 +- 0.275 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 class 2 = 0.567 +- 0.275 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all KL = 0.593 +- 0.275 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.9 all L1 = 0.547 +- 0.180 (in-sample avg dev_std = 0.368)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.287
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.05001250000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.331
NEC for r=0.3 class 0 = 0.513 +- 0.265 (in-sample avg dev_std = 0.460)
NEC for r=0.3 class 1 = 0.506 +- 0.265 (in-sample avg dev_std = 0.460)
NEC for r=0.3 class 2 = 0.492 +- 0.265 (in-sample avg dev_std = 0.460)
NEC for r=0.3 all KL = 0.479 +- 0.265 (in-sample avg dev_std = 0.460)
NEC for r=0.3 all L1 = 0.504 +- 0.169 (in-sample avg dev_std = 0.460)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.482
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.20775125000000003
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.351
NEC for r=0.6 class 0 = 0.56 +- 0.264 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 1 = 0.554 +- 0.264 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 2 = 0.51 +- 0.264 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all KL = 0.527 +- 0.264 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all L1 = 0.542 +- 0.127 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.7
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.28617875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.502
NEC for r=0.9 class 0 = 0.515 +- 0.261 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 1 = 0.553 +- 0.261 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 2 = 0.396 +- 0.261 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all KL = 0.495 +- 0.261 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all L1 = 0.488 +- 0.154 (in-sample avg dev_std = 0.472)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.806
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30925125000000003
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.573
NEC for r=1.0 class 0 = 0.489 +- 0.250 (in-sample avg dev_std = 0.432)
NEC for r=1.0 class 1 = 0.494 +- 0.250 (in-sample avg dev_std = 0.432)
NEC for r=1.0 class 2 = 0.337 +- 0.250 (in-sample avg dev_std = 0.432)
NEC for r=1.0 all KL = 0.441 +- 0.250 (in-sample avg dev_std = 0.432)
NEC for r=1.0 all L1 = 0.441 +- 0.158 (in-sample avg dev_std = 0.432)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.387
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.027622499999999998
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.323
NEC for r=0.3 class 0 = 0.544 +- 0.244 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 1 = 0.529 +- 0.244 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 2 = 0.462 +- 0.244 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all KL = 0.45 +- 0.244 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all L1 = 0.511 +- 0.142 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.305
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.16866
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.304
NEC for r=0.6 class 0 = 0.598 +- 0.268 (in-sample avg dev_std = 0.436)
NEC for r=0.6 class 1 = 0.566 +- 0.268 (in-sample avg dev_std = 0.436)
NEC for r=0.6 class 2 = 0.552 +- 0.268 (in-sample avg dev_std = 0.436)
NEC for r=0.6 all KL = 0.532 +- 0.268 (in-sample avg dev_std = 0.436)
NEC for r=0.6 all L1 = 0.572 +- 0.129 (in-sample avg dev_std = 0.436)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2361575
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.581
NEC for r=0.9 class 0 = 0.5 +- 0.273 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 1 = 0.469 +- 0.273 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 2 = 0.401 +- 0.273 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all KL = 0.433 +- 0.273 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all L1 = 0.456 +- 0.153 (in-sample avg dev_std = 0.443)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.707
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25176
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.609
NEC for r=1.0 class 0 = 0.491 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 1 = 0.429 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 2 = 0.404 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all KL = 0.389 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all L1 = 0.441 +- 0.143 (in-sample avg dev_std = 0.415)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:14:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:14:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ACCURACY: 0.6885
Train Loss: 0.8644
ID Validation ACCURACY: 0.6977
ID Validation Loss: 0.8397
ID Test ACCURACY: 0.6903
ID Test Loss: 0.8483
OOD Validation ACCURACY: 0.5057
OOD Validation Loss: 1.1208
OOD Test ACCURACY: 0.6890
OOD Test Loss: 0.8000

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ACCURACY: 0.4692
Train Loss: 1.2687
ID Validation ACCURACY: 0.4743
ID Validation Loss: 1.2830
ID Test ACCURACY: 0.4663
ID Test Loss: 1.2951
OOD Validation ACCURACY: 0.6260
OOD Validation Loss: 0.8764
OOD Test ACCURACY: 0.3913
OOD Test Loss: 1.4173

[0m[1;37mINFO[0m: [1mChartInfo 0.6903 0.6890 0.4663 0.3913 0.4743 0.6260[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.044
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.227
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.000
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.157
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.366
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.326
SUFF++ for r=0.3 class 0 = 0.69 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 class 1 = 0.697 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 class 2 = 0.702 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 all KL = 0.825 +- 0.193 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.3 all L1 = 0.696 +- 0.175 (in-sample avg dev_std = 0.304)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.334
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.04424375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.339
SUFF++ for r=0.6 class 0 = 0.81 +- 0.088 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 class 1 = 0.759 +- 0.088 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 class 2 = 0.792 +- 0.088 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all KL = 0.924 +- 0.088 (in-sample avg dev_std = 0.225)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.110 (in-sample avg dev_std = 0.225)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.365
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.22728625000000002
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.369
SUFF++ for r=0.9 class 0 = 0.856 +- 0.046 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 1 = 0.877 +- 0.046 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 class 2 = 0.848 +- 0.046 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all KL = 0.965 +- 0.046 (in-sample avg dev_std = 0.163)
SUFF++ for r=0.9 all L1 = 0.86 +- 0.078 (in-sample avg dev_std = 0.163)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.299
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.381
SUFF++ for r=0.3 class 0 = 0.623 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 class 2 = 0.617 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 all KL = 0.721 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 all L1 = 0.636 +- 0.204 (in-sample avg dev_std = 0.395)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.344
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.322
SUFF++ for r=0.6 class 0 = 0.823 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 1 = 0.808 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 2 = 0.819 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all KL = 0.944 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all L1 = 0.816 +- 0.089 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.341
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.346
SUFF++ for r=0.9 class 0 = 0.882 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all KL = 0.97 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.084 (in-sample avg dev_std = 0.133)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.366
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.371
NEC for r=0.3 class 0 = 0.349 +- 0.178 (in-sample avg dev_std = 0.270)
NEC for r=0.3 class 1 = 0.314 +- 0.178 (in-sample avg dev_std = 0.270)
NEC for r=0.3 class 2 = 0.356 +- 0.178 (in-sample avg dev_std = 0.270)
NEC for r=0.3 all KL = 0.189 +- 0.178 (in-sample avg dev_std = 0.270)
NEC for r=0.3 all L1 = 0.339 +- 0.164 (in-sample avg dev_std = 0.270)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.334
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.04424375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.336
NEC for r=0.6 class 0 = 0.265 +- 0.113 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 1 = 0.274 +- 0.113 (in-sample avg dev_std = 0.210)
NEC for r=0.6 class 2 = 0.261 +- 0.113 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all KL = 0.11 +- 0.113 (in-sample avg dev_std = 0.210)
NEC for r=0.6 all L1 = 0.267 +- 0.143 (in-sample avg dev_std = 0.210)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.365
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.22728625000000002
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.343
NEC for r=0.9 class 0 = 0.202 +- 0.106 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1 = 0.22 +- 0.106 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 2 = 0.243 +- 0.106 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.076 +- 0.106 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.222 +- 0.126 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.716
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30988124999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.467
NEC for r=1.0 class 0 = 0.278 +- 0.180 (in-sample avg dev_std = 0.216)
NEC for r=1.0 class 1 = 0.219 +- 0.180 (in-sample avg dev_std = 0.216)
NEC for r=1.0 class 2 = 0.324 +- 0.180 (in-sample avg dev_std = 0.216)
NEC for r=1.0 all KL = 0.138 +- 0.180 (in-sample avg dev_std = 0.216)
NEC for r=1.0 all L1 = 0.273 +- 0.159 (in-sample avg dev_std = 0.216)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.299
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.287 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 1 = 0.339 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 2 = 0.314 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all KL = 0.214 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all L1 = 0.314 +- 0.206 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.344
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.319
NEC for r=0.6 class 0 = 0.179 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 class 1 = 0.199 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 class 2 = 0.184 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all KL = 0.065 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all L1 = 0.187 +- 0.127 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.341
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.379
NEC for r=0.9 class 0 = 0.185 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1 = 0.166 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 2 = 0.197 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.061 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.183 +- 0.137 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.694
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25132374999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.52
NEC for r=1.0 class 0 = 0.211 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 class 1 = 0.183 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 class 2 = 0.255 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 all KL = 0.09 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 all L1 = 0.216 +- 0.119 (in-sample avg dev_std = 0.201)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.847, 0.881, 0.91, 1.0], 'all_L1': [0.695, 0.727, 0.782, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.415, 0.437, 0.571, 1.0], 'all_L1': [0.451, 0.423, 0.531, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.867, 0.911, 0.94, 1.0], 'all_L1': [0.721, 0.762, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.504, 0.493, 0.578, 1.0], 'all_L1': [0.477, 0.469, 0.574, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.825, 0.924, 0.965, 1.0], 'all_L1': [0.696, 0.787, 0.86, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.169, 0.149, 0.143, 0.147], 'all_L1': [0.327, 0.321, 0.311, 0.304]}), defaultdict(<class 'list'>, {'all_KL': [0.55, 0.52, 0.517, 0.472], 'all_L1': [0.52, 0.538, 0.533, 0.507]}), defaultdict(<class 'list'>, {'all_KL': [0.133, 0.107, 0.1, 0.108], 'all_L1': [0.289, 0.266, 0.243, 0.241]}), defaultdict(<class 'list'>, {'all_KL': [0.479, 0.527, 0.495, 0.441], 'all_L1': [0.504, 0.542, 0.488, 0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.189, 0.11, 0.076, 0.138], 'all_L1': [0.339, 0.267, 0.222, 0.273]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.723, 0.826, 0.878, 1.0], 'all_L1': [0.592, 0.644, 0.726, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.489, 0.578, 0.597, 1.0], 'all_L1': [0.476, 0.486, 0.557, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.719, 0.883, 0.928, 1.0], 'all_L1': [0.584, 0.706, 0.766, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.549, 0.463, 0.593, 1.0], 'all_L1': [0.483, 0.432, 0.547, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.721, 0.944, 0.97, 1.0], 'all_L1': [0.636, 0.816, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.278, 0.187, 0.126, 0.121], 'all_L1': [0.402, 0.361, 0.286, 0.273]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.407, 0.435, 0.416], 'all_L1': [0.511, 0.508, 0.463, 0.446]}), defaultdict(<class 'list'>, {'all_KL': [0.243, 0.106, 0.096, 0.076], 'all_L1': [0.377, 0.281, 0.276, 0.208]}), defaultdict(<class 'list'>, {'all_KL': [0.45, 0.532, 0.433, 0.389], 'all_L1': [0.511, 0.572, 0.456, 0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.214, 0.065, 0.061, 0.09], 'all_L1': [0.314, 0.187, 0.183, 0.216]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.608 +- 0.118, 0.634 +- 0.155, 0.714 +- 0.135, 1.000 +- 0.000
suff++ class all_KL  =  0.692 +- 0.192, 0.729 +- 0.217, 0.793 +- 0.179, 1.000 +- 0.000
suff++_acc_int  =  0.340 +- 0.009, 0.342 +- 0.011, 0.452 +- 0.077
nec class all_L1  =  0.396 +- 0.096, 0.387 +- 0.127, 0.359 +- 0.128, 0.353 +- 0.103
nec class all_KL  =  0.304 +- 0.174, 0.283 +- 0.197, 0.266 +- 0.197, 0.261 +- 0.160
nec_acc_int  =  0.357 +- 0.015, 0.355 +- 0.022, 0.414 +- 0.065, 0.502 +- 0.037

Eval split test
suff++ class all_L1  =  0.554 +- 0.064, 0.617 +- 0.141, 0.692 +- 0.122, 1.000 +- 0.000
suff++ class all_KL  =  0.640 +- 0.101, 0.739 +- 0.186, 0.793 +- 0.164, 1.000 +- 0.000
suff++_acc_int  =  0.366 +- 0.027, 0.327 +- 0.034, 0.459 +- 0.070
nec class all_L1  =  0.423 +- 0.077, 0.382 +- 0.142, 0.333 +- 0.110, 0.317 +- 0.106
nec class all_KL  =  0.335 +- 0.113, 0.259 +- 0.180, 0.230 +- 0.168, 0.218 +- 0.151
nec_acc_int  =  0.349 +- 0.016, 0.345 +- 0.055, 0.492 +- 0.085, 0.549 +- 0.057


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.502 +- 0.012, 0.510 +- 0.017, 0.537 +- 0.006, 0.677 +- 0.051
Faith. Armon (L1)= 		  =  0.457 +- 0.028, 0.443 +- 0.042, 0.447 +- 0.074, 0.514 +- 0.110
Faith. GMean (L1)= 	  =  0.479 +- 0.012, 0.475 +- 0.019, 0.488 +- 0.040, 0.588 +- 0.085
Faith. Aritm (KL)= 		  =  0.498 +- 0.010, 0.506 +- 0.014, 0.529 +- 0.009, 0.631 +- 0.080
Faith. Armon (KL)= 		  =  0.357 +- 0.105, 0.325 +- 0.138, 0.329 +- 0.174, 0.389 +- 0.195
Faith. GMean (KL)= 	  =  0.416 +- 0.059, 0.396 +- 0.082, 0.403 +- 0.115, 0.487 +- 0.155

Eval split test
Faith. Aritm (L1)= 		  =  0.489 +- 0.009, 0.499 +- 0.004, 0.512 +- 0.008, 0.658 +- 0.053
Faith. Armon (L1)= 		  =  0.469 +- 0.028, 0.432 +- 0.072, 0.424 +- 0.074, 0.471 +- 0.120
Faith. GMean (L1)= 	  =  0.479 +- 0.019, 0.462 +- 0.041, 0.464 +- 0.039, 0.555 +- 0.093
Faith. Aritm (KL)= 		  =  0.488 +- 0.012, 0.499 +- 0.005, 0.512 +- 0.005, 0.609 +- 0.076
Faith. Armon (KL)= 		  =  0.416 +- 0.066, 0.318 +- 0.150, 0.303 +- 0.166, 0.334 +- 0.198
Faith. GMean (KL)= 	  =  0.449 +- 0.040, 0.386 +- 0.098, 0.378 +- 0.110, 0.438 +- 0.162
Computed for split load_split = id



Completed in  0:13:09.950931  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:17:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:17:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8721
ID Validation Loss: 0.5525
ID Test ACCURACY: 0.8738
ID Test Loss: 0.6177
OOD Validation ACCURACY: 0.8730
OOD Validation Loss: 0.7070
OOD Test ACCURACY: 0.8114
OOD Test Loss: 1.1250

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8698
ID Validation Loss: 0.5684
ID Test ACCURACY: 0.8749
ID Test Loss: 0.6247
OOD Validation ACCURACY: 0.8748
OOD Validation Loss: 0.7016
OOD Test ACCURACY: 0.8157
OOD Test Loss: 1.0466

[0m[1;37mINFO[0m: [1mChartInfo 0.8738 0.8114 0.8749 0.8157 0.8698 0.8748[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:17:25 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.855
SUFF++ for r=0.6 class 0.0 = 0.922 +- 0.146 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.146 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 all KL = 0.947 +- 0.146 (in-sample avg dev_std = 0.177)
SUFF++ for r=0.6 all L1 = 0.945 +- 0.115 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0.0 = 0.948 +- 0.127 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 class 1.0 = 0.947 +- 0.127 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all KL = 0.96 +- 0.127 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all L1 = 0.947 +- 0.133 (in-sample avg dev_std = 0.138)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.745
SUFF++ for r=0.3 class 0.0 = 0.901 +- 0.101 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 class 1.0 = 0.959 +- 0.101 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 all KL = 0.951 +- 0.101 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.106 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.909 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all KL = 0.951 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.114 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0.0 = 0.962 +- 0.043 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 class 1.0 = 0.985 +- 0.043 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all KL = 0.988 +- 0.043 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all L1 = 0.974 +- 0.066 (in-sample avg dev_std = 0.096)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.856
NEC for r=0.6 class 0.0 = 0.09 +- 0.163 (in-sample avg dev_std = 0.132)
NEC for r=0.6 class 1.0 = 0.05 +- 0.163 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all KL = 0.058 +- 0.163 (in-sample avg dev_std = 0.132)
NEC for r=0.6 all L1 = 0.067 +- 0.146 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.051 +- 0.118 (in-sample avg dev_std = 0.105)
NEC for r=0.9 class 1.0 = 0.038 +- 0.118 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all KL = 0.034 +- 0.118 (in-sample avg dev_std = 0.105)
NEC for r=0.9 all L1 = 0.044 +- 0.124 (in-sample avg dev_std = 0.105)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.868
NEC for r=1.0 class 0.0 = 0.041 +- 0.100 (in-sample avg dev_std = 0.081)
NEC for r=1.0 class 1.0 = 0.034 +- 0.100 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all KL = 0.029 +- 0.100 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all L1 = 0.037 +- 0.109 (in-sample avg dev_std = 0.081)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.765
NEC for r=0.3 class 0.0 = 0.114 +- 0.094 (in-sample avg dev_std = 0.106)
NEC for r=0.3 class 1.0 = 0.05 +- 0.094 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all KL = 0.044 +- 0.094 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all L1 = 0.081 +- 0.133 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.793
NEC for r=0.6 class 0.0 = 0.098 +- 0.088 (in-sample avg dev_std = 0.119)
NEC for r=0.6 class 1.0 = 0.042 +- 0.088 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all KL = 0.038 +- 0.088 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all L1 = 0.069 +- 0.123 (in-sample avg dev_std = 0.119)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.818
NEC for r=0.9 class 0.0 = 0.076 +- 0.100 (in-sample avg dev_std = 0.103)
NEC for r=0.9 class 1.0 = 0.036 +- 0.100 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all KL = 0.033 +- 0.100 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all L1 = 0.055 +- 0.122 (in-sample avg dev_std = 0.103)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.834
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.823
NEC for r=1.0 class 0.0 = 0.072 +- 0.100 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 1.0 = 0.034 +- 0.100 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all KL = 0.033 +- 0.100 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all L1 = 0.052 +- 0.118 (in-sample avg dev_std = 0.116)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:19:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:19:43 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9485
Train Loss: 0.0766
ID Validation ACCURACY: 0.8749
ID Validation Loss: 0.5049
ID Test ACCURACY: 0.8668
ID Test Loss: 0.5615
OOD Validation ACCURACY: 0.8653
OOD Validation Loss: 0.6072
OOD Test ACCURACY: 0.7872
OOD Test Loss: 0.9617

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0757
ID Validation ACCURACY: 0.8723
ID Validation Loss: 0.5268
ID Test ACCURACY: 0.8719
ID Test Loss: 0.6128
OOD Validation ACCURACY: 0.8778
OOD Validation Loss: 0.6058
OOD Test ACCURACY: 0.8173
OOD Test Loss: 0.8048

[0m[1;37mINFO[0m: [1mChartInfo 0.8668 0.7872 0.8719 0.8173 0.8723 0.8778[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:19:43 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.87
SUFF++ for r=0.6 class 0.0 = 0.928 +- 0.136 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 1.0 = 0.949 +- 0.136 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all KL = 0.946 +- 0.136 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all L1 = 0.94 +- 0.107 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.872
SUFF++ for r=0.9 class 0.0 = 0.936 +- 0.111 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 class 1.0 = 0.952 +- 0.111 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all KL = 0.964 +- 0.111 (in-sample avg dev_std = 0.089)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.135 (in-sample avg dev_std = 0.089)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.724
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.715
SUFF++ for r=0.3 class 0.0 = 0.908 +- 0.089 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.3 class 1.0 = 0.96 +- 0.089 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.3 all KL = 0.961 +- 0.089 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.3 all L1 = 0.935 +- 0.093 (in-sample avg dev_std = 0.159)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.737
SUFF++ for r=0.6 class 0.0 = 0.898 +- 0.084 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 1.0 = 0.973 +- 0.084 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all KL = 0.965 +- 0.084 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.108 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.786
SUFF++ for r=0.9 class 0.0 = 0.951 +- 0.043 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 class 1.0 = 0.986 +- 0.043 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all KL = 0.988 +- 0.043 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.066 (in-sample avg dev_std = 0.093)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.871
NEC for r=0.6 class 0.0 = 0.091 +- 0.159 (in-sample avg dev_std = 0.108)
NEC for r=0.6 class 1.0 = 0.061 +- 0.159 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all KL = 0.063 +- 0.159 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all L1 = 0.074 +- 0.132 (in-sample avg dev_std = 0.108)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.873
NEC for r=0.9 class 0.0 = 0.066 +- 0.115 (in-sample avg dev_std = 0.086)
NEC for r=0.9 class 1.0 = 0.039 +- 0.115 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all KL = 0.034 +- 0.115 (in-sample avg dev_std = 0.086)
NEC for r=0.9 all L1 = 0.05 +- 0.130 (in-sample avg dev_std = 0.086)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.874
NEC for r=1.0 class 0.0 = 0.059 +- 0.106 (in-sample avg dev_std = 0.073)
NEC for r=1.0 class 1.0 = 0.033 +- 0.106 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all KL = 0.028 +- 0.106 (in-sample avg dev_std = 0.073)
NEC for r=1.0 all L1 = 0.044 +- 0.122 (in-sample avg dev_std = 0.073)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.724
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.719
NEC for r=0.3 class 0.0 = 0.122 +- 0.090 (in-sample avg dev_std = 0.113)
NEC for r=0.3 class 1.0 = 0.049 +- 0.090 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all KL = 0.042 +- 0.090 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all L1 = 0.084 +- 0.117 (in-sample avg dev_std = 0.113)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.739
NEC for r=0.6 class 0.0 = 0.112 +- 0.065 (in-sample avg dev_std = 0.108)
NEC for r=0.6 class 1.0 = 0.035 +- 0.065 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all KL = 0.032 +- 0.065 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all L1 = 0.072 +- 0.107 (in-sample avg dev_std = 0.108)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.78
NEC for r=0.9 class 0.0 = 0.119 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.9 class 1.0 = 0.041 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all KL = 0.045 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all L1 = 0.079 +- 0.135 (in-sample avg dev_std = 0.131)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.8
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.789
NEC for r=1.0 class 0.0 = 0.106 +- 0.092 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.037 +- 0.092 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.039 +- 0.092 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.07 +- 0.125 (in-sample avg dev_std = 0.125)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:21:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:21:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:22:00 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8755
ID Validation Loss: 0.5193
ID Test ACCURACY: 0.8710
ID Test Loss: 0.6143
OOD Validation ACCURACY: 0.8741
OOD Validation Loss: 0.6579
OOD Test ACCURACY: 0.7991
OOD Test Loss: 1.0166

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0757
ID Validation ACCURACY: 0.8713
ID Validation Loss: 0.4845
ID Test ACCURACY: 0.8713
ID Test Loss: 0.5534
OOD Validation ACCURACY: 0.8785
OOD Validation Loss: 0.6028
OOD Test ACCURACY: 0.8218
OOD Test Loss: 0.7450

[0m[1;37mINFO[0m: [1mChartInfo 0.8710 0.7991 0.8713 0.8218 0.8713 0.8785[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:22:00 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.877
SUFF++ for r=0.6 class 0.0 = 0.931 +- 0.157 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 1.0 = 0.963 +- 0.157 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all KL = 0.938 +- 0.157 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all L1 = 0.95 +- 0.092 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.902
SUFF++ for r=0.9 class 0.0 = 0.935 +- 0.132 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.977 +- 0.132 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.966 +- 0.132 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.130 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.71
SUFF++ for r=0.3 class 0.0 = 0.909 +- 0.117 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.3 class 1.0 = 0.95 +- 0.117 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.3 all KL = 0.948 +- 0.117 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.3 all L1 = 0.93 +- 0.096 (in-sample avg dev_std = 0.172)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.755
SUFF++ for r=0.6 class 0.0 = 0.901 +- 0.111 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 1.0 = 0.959 +- 0.111 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all KL = 0.953 +- 0.111 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all L1 = 0.931 +- 0.118 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.803
SUFF++ for r=0.9 class 0.0 = 0.942 +- 0.084 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 class 1.0 = 0.977 +- 0.084 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all KL = 0.973 +- 0.084 (in-sample avg dev_std = 0.148)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.089 (in-sample avg dev_std = 0.148)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.888
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.889
NEC for r=0.6 class 0.0 = 0.067 +- 0.147 (in-sample avg dev_std = 0.104)
NEC for r=0.6 class 1.0 = 0.045 +- 0.147 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all KL = 0.054 +- 0.147 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all L1 = 0.054 +- 0.105 (in-sample avg dev_std = 0.104)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.891
NEC for r=0.9 class 0.0 = 0.045 +- 0.105 (in-sample avg dev_std = 0.092)
NEC for r=0.9 class 1.0 = 0.025 +- 0.105 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all KL = 0.025 +- 0.105 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all L1 = 0.033 +- 0.110 (in-sample avg dev_std = 0.092)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.898
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.887
NEC for r=1.0 class 0.0 = 0.039 +- 0.101 (in-sample avg dev_std = 0.090)
NEC for r=1.0 class 1.0 = 0.025 +- 0.101 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all KL = 0.023 +- 0.101 (in-sample avg dev_std = 0.090)
NEC for r=1.0 all L1 = 0.031 +- 0.102 (in-sample avg dev_std = 0.090)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.72
NEC for r=0.3 class 0.0 = 0.131 +- 0.127 (in-sample avg dev_std = 0.131)
NEC for r=0.3 class 1.0 = 0.065 +- 0.127 (in-sample avg dev_std = 0.131)
NEC for r=0.3 all KL = 0.062 +- 0.127 (in-sample avg dev_std = 0.131)
NEC for r=0.3 all L1 = 0.097 +- 0.134 (in-sample avg dev_std = 0.131)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.755
NEC for r=0.6 class 0.0 = 0.122 +- 0.099 (in-sample avg dev_std = 0.126)
NEC for r=0.6 class 1.0 = 0.044 +- 0.099 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all KL = 0.046 +- 0.099 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all L1 = 0.082 +- 0.132 (in-sample avg dev_std = 0.126)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.798
NEC for r=0.9 class 0.0 = 0.115 +- 0.124 (in-sample avg dev_std = 0.146)
NEC for r=0.9 class 1.0 = 0.04 +- 0.124 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all KL = 0.052 +- 0.124 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all L1 = 0.076 +- 0.136 (in-sample avg dev_std = 0.146)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.814
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.808
NEC for r=1.0 class 0.0 = 0.108 +- 0.120 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 1.0 = 0.032 +- 0.120 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all KL = 0.047 +- 0.120 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all L1 = 0.069 +- 0.133 (in-sample avg dev_std = 0.142)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:24:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0765
ID Validation ACCURACY: 0.8764
ID Validation Loss: 0.4270
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4723
OOD Validation ACCURACY: 0.8786
OOD Validation Loss: 0.5089
OOD Test ACCURACY: 0.8355
OOD Test Loss: 0.5859

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0765
ID Validation ACCURACY: 0.8764
ID Validation Loss: 0.4270
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4723
OOD Validation ACCURACY: 0.8786
OOD Validation Loss: 0.5089
OOD Test ACCURACY: 0.8355
OOD Test Loss: 0.5859

[0m[1;37mINFO[0m: [1mChartInfo 0.8727 0.8355 0.8727 0.8355 0.8764 0.8786[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:24:17 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.858
SUFF++ for r=0.6 class 0.0 = 0.926 +- 0.091 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 1.0 = 0.956 +- 0.091 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 all KL = 0.963 +- 0.091 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.098 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.946 +- 0.074 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.074 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all KL = 0.976 +- 0.074 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.111 (in-sample avg dev_std = 0.079)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.748
SUFF++ for r=0.3 class 0.0 = 0.911 +- 0.074 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.3 class 1.0 = 0.951 +- 0.074 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.3 all KL = 0.964 +- 0.074 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.3 all L1 = 0.932 +- 0.086 (in-sample avg dev_std = 0.152)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.808
SUFF++ for r=0.6 class 0.0 = 0.92 +- 0.076 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 class 1.0 = 0.955 +- 0.076 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all KL = 0.968 +- 0.076 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.098 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.85
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.036 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1.0 = 0.975 +- 0.036 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.989 +- 0.036 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.065 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.861
NEC for r=0.6 class 0.0 = 0.092 +- 0.114 (in-sample avg dev_std = 0.076)
NEC for r=0.6 class 1.0 = 0.046 +- 0.114 (in-sample avg dev_std = 0.076)
NEC for r=0.6 all KL = 0.043 +- 0.114 (in-sample avg dev_std = 0.076)
NEC for r=0.6 all L1 = 0.065 +- 0.115 (in-sample avg dev_std = 0.076)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.895
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.881
NEC for r=0.9 class 0.0 = 0.045 +- 0.095 (in-sample avg dev_std = 0.082)
NEC for r=0.9 class 1.0 = 0.038 +- 0.095 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all KL = 0.026 +- 0.095 (in-sample avg dev_std = 0.082)
NEC for r=0.9 all L1 = 0.041 +- 0.107 (in-sample avg dev_std = 0.082)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.895
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.885
NEC for r=1.0 class 0.0 = 0.047 +- 0.105 (in-sample avg dev_std = 0.077)
NEC for r=1.0 class 1.0 = 0.031 +- 0.105 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all KL = 0.026 +- 0.105 (in-sample avg dev_std = 0.077)
NEC for r=1.0 all L1 = 0.038 +- 0.109 (in-sample avg dev_std = 0.077)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.757
NEC for r=0.3 class 0.0 = 0.116 +- 0.087 (in-sample avg dev_std = 0.113)
NEC for r=0.3 class 1.0 = 0.066 +- 0.087 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all KL = 0.045 +- 0.087 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all L1 = 0.09 +- 0.114 (in-sample avg dev_std = 0.113)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.812
NEC for r=0.6 class 0.0 = 0.1 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=0.6 class 1.0 = 0.056 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=0.6 all KL = 0.033 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=0.6 all L1 = 0.078 +- 0.114 (in-sample avg dev_std = 0.100)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.852
NEC for r=0.9 class 0.0 = 0.084 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 class 1.0 = 0.059 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all KL = 0.037 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all L1 = 0.071 +- 0.118 (in-sample avg dev_std = 0.106)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.86
NEC for r=1.0 class 0.0 = 0.072 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=1.0 class 1.0 = 0.049 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all KL = 0.029 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all L1 = 0.06 +- 0.106 (in-sample avg dev_std = 0.100)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:26:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9487
Train Loss: 0.0764
ID Validation ACCURACY: 0.8762
ID Validation Loss: 0.4746
ID Test ACCURACY: 0.8687
ID Test Loss: 0.5282
OOD Validation ACCURACY: 0.8716
OOD Validation Loss: 0.5888
OOD Test ACCURACY: 0.8079
OOD Test Loss: 0.8214

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0760
ID Validation ACCURACY: 0.8732
ID Validation Loss: 0.4817
ID Test ACCURACY: 0.8685
ID Test Loss: 0.5451
OOD Validation ACCURACY: 0.8787
OOD Validation Loss: 0.5826
OOD Test ACCURACY: 0.8277
OOD Test Loss: 0.6909

[0m[1;37mINFO[0m: [1mChartInfo 0.8687 0.8079 0.8685 0.8277 0.8732 0.8787[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:26:35 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.847
SUFF++ for r=0.6 class 0.0 = 0.925 +- 0.104 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 class 1.0 = 0.952 +- 0.104 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 all KL = 0.957 +- 0.104 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.6 all L1 = 0.941 +- 0.108 (in-sample avg dev_std = 0.151)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0.0 = 0.922 +- 0.132 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.132 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.958 +- 0.132 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.943 +- 0.138 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.741
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.731
SUFF++ for r=0.3 class 0.0 = 0.908 +- 0.084 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 class 1.0 = 0.953 +- 0.084 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 all KL = 0.961 +- 0.084 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.094 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.765
SUFF++ for r=0.6 class 0.0 = 0.91 +- 0.077 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 class 1.0 = 0.961 +- 0.077 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all KL = 0.967 +- 0.077 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.101 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.030 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 1.0 = 0.979 +- 0.030 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all KL = 0.99 +- 0.030 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.058 (in-sample avg dev_std = 0.079)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.854
NEC for r=0.6 class 0.0 = 0.093 +- 0.128 (in-sample avg dev_std = 0.118)
NEC for r=0.6 class 1.0 = 0.055 +- 0.128 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all KL = 0.052 +- 0.128 (in-sample avg dev_std = 0.118)
NEC for r=0.6 all L1 = 0.071 +- 0.129 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.86
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.855
NEC for r=0.9 class 0.0 = 0.056 +- 0.116 (in-sample avg dev_std = 0.098)
NEC for r=0.9 class 1.0 = 0.04 +- 0.116 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all KL = 0.033 +- 0.116 (in-sample avg dev_std = 0.098)
NEC for r=0.9 all L1 = 0.047 +- 0.124 (in-sample avg dev_std = 0.098)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.852
NEC for r=1.0 class 0.0 = 0.05 +- 0.123 (in-sample avg dev_std = 0.088)
NEC for r=1.0 class 1.0 = 0.038 +- 0.123 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all KL = 0.034 +- 0.123 (in-sample avg dev_std = 0.088)
NEC for r=1.0 all L1 = 0.043 +- 0.120 (in-sample avg dev_std = 0.088)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.741
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.739
NEC for r=0.3 class 0.0 = 0.118 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1.0 = 0.059 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.041 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.087 +- 0.116 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.769
NEC for r=0.6 class 0.0 = 0.101 +- 0.075 (in-sample avg dev_std = 0.112)
NEC for r=0.6 class 1.0 = 0.049 +- 0.075 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all KL = 0.034 +- 0.075 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all L1 = 0.074 +- 0.111 (in-sample avg dev_std = 0.112)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.816
NEC for r=0.9 class 0.0 = 0.098 +- 0.094 (in-sample avg dev_std = 0.119)
NEC for r=0.9 class 1.0 = 0.05 +- 0.094 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all KL = 0.039 +- 0.094 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all L1 = 0.073 +- 0.118 (in-sample avg dev_std = 0.119)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.834
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.088 +- 0.082 (in-sample avg dev_std = 0.109)
NEC for r=1.0 class 1.0 = 0.042 +- 0.082 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all KL = 0.034 +- 0.082 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all L1 = 0.065 +- 0.111 (in-sample avg dev_std = 0.109)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.947, 0.96, 1.0], 'all_L1': [0.945, 0.947, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.946, 0.964, 1.0], 'all_L1': [0.94, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.938, 0.966, 1.0], 'all_L1': [0.95, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.963, 0.976, 1.0], 'all_L1': [0.943, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.957, 0.958, 1.0], 'all_L1': [0.941, 0.943, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.058, 0.034, 0.029], 'all_L1': [0.067, 0.044, 0.037]}), defaultdict(<class 'list'>, {'all_KL': [0.063, 0.034, 0.028], 'all_L1': [0.074, 0.05, 0.044]}), defaultdict(<class 'list'>, {'all_KL': [0.054, 0.025, 0.023], 'all_L1': [0.054, 0.033, 0.031]}), defaultdict(<class 'list'>, {'all_KL': [0.043, 0.026, 0.026], 'all_L1': [0.065, 0.041, 0.038]}), defaultdict(<class 'list'>, {'all_KL': [0.052, 0.033, 0.034], 'all_L1': [0.071, 0.047, 0.043]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.951, 0.951, 0.988, 1.0], 'all_L1': [0.931, 0.936, 0.974, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.961, 0.965, 0.988, 1.0], 'all_L1': [0.935, 0.936, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.948, 0.953, 0.973, 1.0], 'all_L1': [0.93, 0.931, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.964, 0.968, 0.989, 1.0], 'all_L1': [0.932, 0.938, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.961, 0.967, 0.99, 1.0], 'all_L1': [0.931, 0.936, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.044, 0.038, 0.033, 0.033], 'all_L1': [0.081, 0.069, 0.055, 0.052]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.032, 0.045, 0.039], 'all_L1': [0.084, 0.072, 0.079, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.062, 0.046, 0.052, 0.047], 'all_L1': [0.097, 0.082, 0.076, 0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.045, 0.033, 0.037, 0.029], 'all_L1': [0.09, 0.078, 0.071, 0.06]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.034, 0.039, 0.034], 'all_L1': [0.087, 0.074, 0.073, 0.065]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.944 +- 0.004, 0.949 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.950 +- 0.009, 0.965 +- 0.006, 1.000 +- 0.000
suff++_acc_int  =  0.861 +- 0.011, 0.876 +- 0.019
nec class all_L1  =  0.066 +- 0.007, 0.043 +- 0.006, 0.039 +- 0.005
nec class all_KL  =  0.054 +- 0.007, 0.030 +- 0.004, 0.028 +- 0.004
nec_acc_int  =  0.866 +- 0.013, 0.875 +- 0.012, 0.873 +- 0.013

Eval split test
suff++ class all_L1  =  0.932 +- 0.002, 0.935 +- 0.002, 0.969 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.957 +- 0.006, 0.961 +- 0.007, 0.986 +- 0.006, 1.000 +- 0.000
suff++_acc_int  =  0.730 +- 0.015, 0.769 +- 0.024, 0.817 +- 0.022
nec class all_L1  =  0.088 +- 0.005, 0.075 +- 0.005, 0.071 +- 0.008, 0.063 +- 0.007
nec class all_KL  =  0.047 +- 0.008, 0.037 +- 0.005, 0.041 +- 0.007, 0.036 +- 0.006
nec_acc_int  =  0.740 +- 0.019, 0.773 +- 0.026, 0.813 +- 0.024, 0.821 +- 0.024


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.505 +- 0.002, 0.496 +- 0.001, 0.519 +- 0.002
Faith. Armon (L1)= 		  =  0.124 +- 0.012, 0.082 +- 0.011, 0.074 +- 0.009
Faith. GMean (L1)= 	  =  0.250 +- 0.013, 0.202 +- 0.014, 0.196 +- 0.012
Faith. Aritm (KL)= 		  =  0.502 +- 0.003, 0.498 +- 0.002, 0.514 +- 0.002
Faith. Armon (KL)= 		  =  0.102 +- 0.012, 0.059 +- 0.008, 0.054 +- 0.007
Faith. GMean (KL)= 	  =  0.226 +- 0.014, 0.171 +- 0.011, 0.167 +- 0.011

Eval split test
Faith. Aritm (L1)= 		  =  0.510 +- 0.002, 0.505 +- 0.002, 0.520 +- 0.003, 0.532 +- 0.003
Faith. Armon (L1)= 		  =  0.160 +- 0.009, 0.139 +- 0.008, 0.132 +- 0.015, 0.119 +- 0.012
Faith. GMean (L1)= 	  =  0.286 +- 0.009, 0.265 +- 0.008, 0.261 +- 0.016, 0.251 +- 0.013
Faith. Aritm (KL)= 		  =  0.502 +- 0.003, 0.499 +- 0.002, 0.513 +- 0.002, 0.518 +- 0.003
Faith. Armon (KL)= 		  =  0.089 +- 0.014, 0.070 +- 0.009, 0.079 +- 0.012, 0.070 +- 0.011
Faith. GMean (KL)= 	  =  0.211 +- 0.016, 0.187 +- 0.012, 0.201 +- 0.016, 0.190 +- 0.016
Computed for split load_split = id



Completed in  0:11:24.977709  for LECIGIN GOODSST2/length



DONE LECI GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:29:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:29:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.8946
Train Loss: 0.2294
ID Validation ACCURACY: 0.8451
ID Validation Loss: 0.4596
ID Test ACCURACY: 0.8359
ID Test Loss: 0.4928
OOD Validation ACCURACY: 0.8442
OOD Validation Loss: 0.7055
OOD Test ACCURACY: 0.7909
OOD Test Loss: 1.2081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 150...
[0m[1;37mINFO[0m: [1mCheckpoint 150: 
-----------------------------------
Train ACCURACY: 0.8613
Train Loss: 0.3029
ID Validation ACCURACY: 0.8268
ID Validation Loss: 0.4327
ID Test ACCURACY: 0.8231
ID Test Loss: 0.4451
OOD Validation ACCURACY: 0.8502
OOD Validation Loss: 0.5097
OOD Test ACCURACY: 0.8121
OOD Test Loss: 0.6943

[0m[1;37mINFO[0m: [1mChartInfo 0.8359 0.7909 0.8231 0.8121 0.8268 0.8502[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:29:04 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.842
SUFF++ for r=0.6 class 0.0 = 0.944 +- 0.104 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 class 1.0 = 0.957 +- 0.104 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 all KL = 0.962 +- 0.104 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 all L1 = 0.952 +- 0.102 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.84
SUFF++ for r=0.9 class 0.0 = 0.91 +- 0.135 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 1.0 = 0.948 +- 0.135 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all KL = 0.952 +- 0.135 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all L1 = 0.931 +- 0.142 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.739
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.731
SUFF++ for r=0.3 class 0.0 = 0.881 +- 0.151 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 class 1.0 = 0.954 +- 0.151 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 all KL = 0.923 +- 0.151 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 all L1 = 0.919 +- 0.133 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.757
SUFF++ for r=0.6 class 0.0 = 0.914 +- 0.110 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.110 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.6 all KL = 0.954 +- 0.110 (in-sample avg dev_std = 0.167)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.120 (in-sample avg dev_std = 0.167)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.792
SUFF++ for r=0.9 class 0.0 = 0.965 +- 0.035 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.035 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 all KL = 0.99 +- 0.035 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.9 all L1 = 0.974 +- 0.065 (in-sample avg dev_std = 0.084)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.86
NEC for r=0.6 class 0.0 = 0.079 +- 0.116 (in-sample avg dev_std = 0.110)
NEC for r=0.6 class 1.0 = 0.053 +- 0.116 (in-sample avg dev_std = 0.110)
NEC for r=0.6 all KL = 0.045 +- 0.116 (in-sample avg dev_std = 0.110)
NEC for r=0.6 all L1 = 0.064 +- 0.125 (in-sample avg dev_std = 0.110)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.87
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.845
NEC for r=0.9 class 0.0 = 0.092 +- 0.132 (in-sample avg dev_std = 0.139)
NEC for r=0.9 class 1.0 = 0.042 +- 0.132 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all KL = 0.045 +- 0.132 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all L1 = 0.063 +- 0.139 (in-sample avg dev_std = 0.139)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.87
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.844
NEC for r=1.0 class 0.0 = 0.109 +- 0.148 (in-sample avg dev_std = 0.136)
NEC for r=1.0 class 1.0 = 0.041 +- 0.148 (in-sample avg dev_std = 0.136)
NEC for r=1.0 all KL = 0.053 +- 0.148 (in-sample avg dev_std = 0.136)
NEC for r=1.0 all L1 = 0.07 +- 0.159 (in-sample avg dev_std = 0.136)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.739
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.745
NEC for r=0.3 class 0.0 = 0.138 +- 0.164 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 1.0 = 0.061 +- 0.164 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all KL = 0.078 +- 0.164 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all L1 = 0.098 +- 0.169 (in-sample avg dev_std = 0.179)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.768
NEC for r=0.6 class 0.0 = 0.108 +- 0.145 (in-sample avg dev_std = 0.163)
NEC for r=0.6 class 1.0 = 0.048 +- 0.145 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all KL = 0.059 +- 0.145 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all L1 = 0.077 +- 0.151 (in-sample avg dev_std = 0.163)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.798
NEC for r=0.9 class 0.0 = 0.093 +- 0.118 (in-sample avg dev_std = 0.144)
NEC for r=0.9 class 1.0 = 0.038 +- 0.118 (in-sample avg dev_std = 0.144)
NEC for r=0.9 all KL = 0.044 +- 0.118 (in-sample avg dev_std = 0.144)
NEC for r=0.9 all L1 = 0.065 +- 0.136 (in-sample avg dev_std = 0.144)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.795
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.798
NEC for r=1.0 class 0.0 = 0.088 +- 0.125 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 1.0 = 0.037 +- 0.125 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all KL = 0.045 +- 0.125 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all L1 = 0.062 +- 0.136 (in-sample avg dev_std = 0.151)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:31:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9069
Train Loss: 0.1959
ID Validation ACCURACY: 0.8449
ID Validation Loss: 0.5034
ID Test ACCURACY: 0.8380
ID Test Loss: 0.5283
OOD Validation ACCURACY: 0.8458
OOD Validation Loss: 0.8693
OOD Test ACCURACY: 0.8026
OOD Test Loss: 1.3095

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 35...
[0m[1;37mINFO[0m: [1mCheckpoint 35: 
-----------------------------------
Train ACCURACY: 0.8494
Train Loss: 0.3303
ID Validation ACCURACY: 0.8246
ID Validation Loss: 0.3965
ID Test ACCURACY: 0.8274
ID Test Loss: 0.4033
OOD Validation ACCURACY: 0.8494
OOD Validation Loss: 0.3884
OOD Test ACCURACY: 0.8215
OOD Test Loss: 0.4617

[0m[1;37mINFO[0m: [1mChartInfo 0.8380 0.8026 0.8274 0.8215 0.8246 0.8494[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:31:33 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.842
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.837
SUFF++ for r=0.6 class 0.0 = 0.94 +- 0.143 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 class 1.0 = 0.951 +- 0.143 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all KL = 0.943 +- 0.143 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.6 all L1 = 0.946 +- 0.112 (in-sample avg dev_std = 0.188)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0.0 = 0.934 +- 0.110 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1.0 = 0.95 +- 0.110 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.961 +- 0.110 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.943 +- 0.139 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.774
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.765
SUFF++ for r=0.3 class 0.0 = 0.898 +- 0.203 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 class 1.0 = 0.927 +- 0.203 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all KL = 0.887 +- 0.203 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all L1 = 0.913 +- 0.147 (in-sample avg dev_std = 0.262)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.802
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 class 1.0 = 0.957 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 all KL = 0.942 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.135 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.827
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.056 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1.0 = 0.981 +- 0.056 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.986 +- 0.056 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.081 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.842
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.852
NEC for r=0.6 class 0.0 = 0.073 +- 0.146 (in-sample avg dev_std = 0.157)
NEC for r=0.6 class 1.0 = 0.051 +- 0.146 (in-sample avg dev_std = 0.157)
NEC for r=0.6 all KL = 0.055 +- 0.146 (in-sample avg dev_std = 0.157)
NEC for r=0.6 all L1 = 0.06 +- 0.134 (in-sample avg dev_std = 0.157)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.853
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.871
NEC for r=0.9 class 0.0 = 0.072 +- 0.119 (in-sample avg dev_std = 0.124)
NEC for r=0.9 class 1.0 = 0.047 +- 0.119 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all KL = 0.039 +- 0.119 (in-sample avg dev_std = 0.124)
NEC for r=0.9 all L1 = 0.058 +- 0.140 (in-sample avg dev_std = 0.124)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.083 +- 0.130 (in-sample avg dev_std = 0.128)
NEC for r=1.0 class 1.0 = 0.047 +- 0.130 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all KL = 0.044 +- 0.130 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all L1 = 0.062 +- 0.150 (in-sample avg dev_std = 0.128)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.774
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.785
NEC for r=0.3 class 0.0 = 0.107 +- 0.200 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1.0 = 0.077 +- 0.200 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.093 +- 0.200 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.091 +- 0.178 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.809
NEC for r=0.6 class 0.0 = 0.096 +- 0.165 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1.0 = 0.053 +- 0.165 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.065 +- 0.165 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.074 +- 0.163 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.83
NEC for r=0.9 class 0.0 = 0.07 +- 0.130 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1.0 = 0.042 +- 0.130 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.046 +- 0.130 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.056 +- 0.132 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.839
NEC for r=1.0 class 0.0 = 0.073 +- 0.145 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 1.0 = 0.041 +- 0.145 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all KL = 0.05 +- 0.145 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all L1 = 0.057 +- 0.141 (in-sample avg dev_std = 0.156)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:33:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9232
Train Loss: 0.1496
ID Validation ACCURACY: 0.8449
ID Validation Loss: 0.5913
ID Test ACCURACY: 0.8447
ID Test Loss: 0.5983
OOD Validation ACCURACY: 0.8434
OOD Validation Loss: 0.9268
OOD Test ACCURACY: 0.7956
OOD Test Loss: 1.1860

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ACCURACY: 0.8865
Train Loss: 0.2502
ID Validation ACCURACY: 0.8387
ID Validation Loss: 0.4508
ID Test ACCURACY: 0.8359
ID Test Loss: 0.4682
OOD Validation ACCURACY: 0.8523
OOD Validation Loss: 0.5568
OOD Test ACCURACY: 0.8184
OOD Test Loss: 0.7482

[0m[1;37mINFO[0m: [1mChartInfo 0.8447 0.7956 0.8359 0.8184 0.8387 0.8523[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:33:59 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.856
SUFF++ for r=0.6 class 0.0 = 0.947 +- 0.145 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 class 1.0 = 0.953 +- 0.145 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all KL = 0.951 +- 0.145 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.6 all L1 = 0.951 +- 0.121 (in-sample avg dev_std = 0.194)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.873
SUFF++ for r=0.9 class 0.0 = 0.931 +- 0.144 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 class 1.0 = 0.951 +- 0.144 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all KL = 0.949 +- 0.144 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.9 all L1 = 0.942 +- 0.132 (in-sample avg dev_std = 0.171)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.746
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.735
SUFF++ for r=0.3 class 0.0 = 0.901 +- 0.171 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 class 1.0 = 0.947 +- 0.171 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 all KL = 0.911 +- 0.171 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 all L1 = 0.925 +- 0.130 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.917 +- 0.121 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1.0 = 0.949 +- 0.121 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.945 +- 0.121 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.934 +- 0.129 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.961 +- 0.046 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.046 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all KL = 0.986 +- 0.046 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.072 (in-sample avg dev_std = 0.094)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.856
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.866
NEC for r=0.6 class 0.0 = 0.087 +- 0.189 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1.0 = 0.063 +- 0.189 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.072 +- 0.189 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.073 +- 0.169 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.874
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
NEC for r=0.9 class 0.0 = 0.075 +- 0.135 (in-sample avg dev_std = 0.145)
NEC for r=0.9 class 1.0 = 0.04 +- 0.135 (in-sample avg dev_std = 0.145)
NEC for r=0.9 all KL = 0.046 +- 0.135 (in-sample avg dev_std = 0.145)
NEC for r=0.9 all L1 = 0.055 +- 0.139 (in-sample avg dev_std = 0.145)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.867
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.866
NEC for r=1.0 class 0.0 = 0.082 +- 0.139 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.037 +- 0.139 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.046 +- 0.139 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.056 +- 0.145 (in-sample avg dev_std = 0.145)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.746
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.763
NEC for r=0.3 class 0.0 = 0.141 +- 0.229 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1.0 = 0.071 +- 0.229 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.109 +- 0.229 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.105 +- 0.196 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.796
NEC for r=0.6 class 0.0 = 0.121 +- 0.174 (in-sample avg dev_std = 0.196)
NEC for r=0.6 class 1.0 = 0.058 +- 0.174 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all KL = 0.075 +- 0.174 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all L1 = 0.088 +- 0.173 (in-sample avg dev_std = 0.196)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.821
NEC for r=0.9 class 0.0 = 0.092 +- 0.140 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1.0 = 0.05 +- 0.140 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.055 +- 0.140 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.07 +- 0.147 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.817
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.089 +- 0.138 (in-sample avg dev_std = 0.163)
NEC for r=1.0 class 1.0 = 0.05 +- 0.138 (in-sample avg dev_std = 0.163)
NEC for r=1.0 all KL = 0.057 +- 0.138 (in-sample avg dev_std = 0.163)
NEC for r=1.0 all L1 = 0.069 +- 0.147 (in-sample avg dev_std = 0.163)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:36:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.8962
Train Loss: 0.2153
ID Validation ACCURACY: 0.8427
ID Validation Loss: 0.4803
ID Test ACCURACY: 0.8374
ID Test Loss: 0.4933
OOD Validation ACCURACY: 0.8439
OOD Validation Loss: 0.7998
OOD Test ACCURACY: 0.7991
OOD Test Loss: 1.0971

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 82...
[0m[1;37mINFO[0m: [1mCheckpoint 82: 
-----------------------------------
Train ACCURACY: 0.8763
Train Loss: 0.2680
ID Validation ACCURACY: 0.8308
ID Validation Loss: 0.4440
ID Test ACCURACY: 0.8295
ID Test Loss: 0.4615
OOD Validation ACCURACY: 0.8541
OOD Validation Loss: 0.6125
OOD Test ACCURACY: 0.8222
OOD Test Loss: 0.7056

[0m[1;37mINFO[0m: [1mChartInfo 0.8374 0.7991 0.8295 0.8222 0.8308 0.8541[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:36:18 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.849
SUFF++ for r=0.6 class 0.0 = 0.919 +- 0.151 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 class 1.0 = 0.954 +- 0.151 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all KL = 0.943 +- 0.151 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.6 all L1 = 0.94 +- 0.119 (in-sample avg dev_std = 0.192)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0.0 = 0.925 +- 0.127 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 1.0 = 0.935 +- 0.127 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all KL = 0.955 +- 0.127 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all L1 = 0.93 +- 0.146 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.752
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.748
SUFF++ for r=0.3 class 0.0 = 0.896 +- 0.164 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 1.0 = 0.949 +- 0.164 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all KL = 0.919 +- 0.164 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all L1 = 0.924 +- 0.131 (in-sample avg dev_std = 0.226)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.788
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.129 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 1.0 = 0.966 +- 0.129 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all KL = 0.949 +- 0.129 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.114 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0.0 = 0.968 +- 0.036 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.036 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all KL = 0.991 +- 0.036 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all L1 = 0.976 +- 0.065 (in-sample avg dev_std = 0.081)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.842
NEC for r=0.6 class 0.0 = 0.092 +- 0.154 (in-sample avg dev_std = 0.153)
NEC for r=0.6 class 1.0 = 0.055 +- 0.154 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all KL = 0.056 +- 0.154 (in-sample avg dev_std = 0.153)
NEC for r=0.6 all L1 = 0.07 +- 0.147 (in-sample avg dev_std = 0.153)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.859
NEC for r=0.9 class 0.0 = 0.071 +- 0.114 (in-sample avg dev_std = 0.128)
NEC for r=0.9 class 1.0 = 0.061 +- 0.114 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all KL = 0.04 +- 0.114 (in-sample avg dev_std = 0.128)
NEC for r=0.9 all L1 = 0.065 +- 0.141 (in-sample avg dev_std = 0.128)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.867
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.861
NEC for r=1.0 class 0.0 = 0.07 +- 0.109 (in-sample avg dev_std = 0.117)
NEC for r=1.0 class 1.0 = 0.05 +- 0.109 (in-sample avg dev_std = 0.117)
NEC for r=1.0 all KL = 0.037 +- 0.109 (in-sample avg dev_std = 0.117)
NEC for r=1.0 all L1 = 0.059 +- 0.136 (in-sample avg dev_std = 0.117)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.752
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.772
NEC for r=0.3 class 0.0 = 0.116 +- 0.176 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 1.0 = 0.077 +- 0.176 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all KL = 0.081 +- 0.176 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all L1 = 0.096 +- 0.176 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.803
NEC for r=0.6 class 0.0 = 0.098 +- 0.123 (in-sample avg dev_std = 0.150)
NEC for r=0.6 class 1.0 = 0.043 +- 0.123 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all KL = 0.052 +- 0.123 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all L1 = 0.07 +- 0.139 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
NEC for r=0.9 class 0.0 = 0.086 +- 0.123 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.04 +- 0.123 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.045 +- 0.123 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.063 +- 0.137 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.823
NEC for r=1.0 class 0.0 = 0.082 +- 0.124 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.038 +- 0.124 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.043 +- 0.124 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.059 +- 0.137 (in-sample avg dev_std = 0.145)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:38:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9018
Train Loss: 0.2011
ID Validation ACCURACY: 0.8468
ID Validation Loss: 0.5144
ID Test ACCURACY: 0.8415
ID Test Loss: 0.5419
OOD Validation ACCURACY: 0.8424
OOD Validation Loss: 0.9462
OOD Test ACCURACY: 0.7918
OOD Test Loss: 1.4711

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.8617
Train Loss: 0.3062
ID Validation ACCURACY: 0.8221
ID Validation Loss: 0.4222
ID Test ACCURACY: 0.8200
ID Test Loss: 0.4485
OOD Validation ACCURACY: 0.8539
OOD Validation Loss: 0.4468
OOD Test ACCURACY: 0.8237
OOD Test Loss: 0.5712

[0m[1;37mINFO[0m: [1mChartInfo 0.8415 0.7918 0.8200 0.8237 0.8221 0.8539[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/29/2024 02:38:42 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.832
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.84
SUFF++ for r=0.6 class 0.0 = 0.921 +- 0.171 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 class 1.0 = 0.931 +- 0.171 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 all KL = 0.926 +- 0.171 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.6 all L1 = 0.927 +- 0.144 (in-sample avg dev_std = 0.206)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.844
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.837
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.138 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 class 1.0 = 0.92 +- 0.138 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all KL = 0.938 +- 0.138 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all L1 = 0.918 +- 0.162 (in-sample avg dev_std = 0.169)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.751
SUFF++ for r=0.3 class 0.0 = 0.887 +- 0.214 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 1.0 = 0.934 +- 0.214 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all KL = 0.887 +- 0.214 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all L1 = 0.911 +- 0.159 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.779
SUFF++ for r=0.6 class 0.0 = 0.914 +- 0.137 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1.0 = 0.957 +- 0.137 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.943 +- 0.137 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.138 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.81
SUFF++ for r=0.9 class 0.0 = 0.961 +- 0.064 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.064 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all KL = 0.983 +- 0.064 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.080 (in-sample avg dev_std = 0.109)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.832
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.829
NEC for r=0.6 class 0.0 = 0.092 +- 0.172 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 1.0 = 0.08 +- 0.172 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all KL = 0.077 +- 0.172 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all L1 = 0.085 +- 0.160 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.839
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.836
NEC for r=0.9 class 0.0 = 0.095 +- 0.143 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1.0 = 0.064 +- 0.143 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.059 +- 0.143 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.077 +- 0.162 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.843
NEC for r=1.0 class 0.0 = 0.087 +- 0.136 (in-sample avg dev_std = 0.136)
NEC for r=1.0 class 1.0 = 0.051 +- 0.136 (in-sample avg dev_std = 0.136)
NEC for r=1.0 all KL = 0.049 +- 0.136 (in-sample avg dev_std = 0.136)
NEC for r=1.0 all L1 = 0.066 +- 0.151 (in-sample avg dev_std = 0.136)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.771
NEC for r=0.3 class 0.0 = 0.117 +- 0.203 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1.0 = 0.068 +- 0.203 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.094 +- 0.203 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.092 +- 0.180 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.798
NEC for r=0.6 class 0.0 = 0.1 +- 0.162 (in-sample avg dev_std = 0.180)
NEC for r=0.6 class 1.0 = 0.054 +- 0.162 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all KL = 0.069 +- 0.162 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all L1 = 0.076 +- 0.158 (in-sample avg dev_std = 0.180)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.816
NEC for r=0.9 class 0.0 = 0.089 +- 0.155 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1.0 = 0.047 +- 0.155 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.058 +- 0.155 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.067 +- 0.153 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.812
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.816
NEC for r=1.0 class 0.0 = 0.092 +- 0.168 (in-sample avg dev_std = 0.178)
NEC for r=1.0 class 1.0 = 0.047 +- 0.168 (in-sample avg dev_std = 0.178)
NEC for r=1.0 all KL = 0.062 +- 0.168 (in-sample avg dev_std = 0.178)
NEC for r=1.0 all L1 = 0.068 +- 0.158 (in-sample avg dev_std = 0.178)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.962, 0.952, 1.0], 'all_L1': [0.952, 0.931, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.943, 0.961, 1.0], 'all_L1': [0.946, 0.943, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.951, 0.949, 1.0], 'all_L1': [0.951, 0.942, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.943, 0.955, 1.0], 'all_L1': [0.94, 0.93, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.926, 0.938, 1.0], 'all_L1': [0.927, 0.918, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.045, 0.045, 0.053], 'all_L1': [0.064, 0.063, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.055, 0.039, 0.044], 'all_L1': [0.06, 0.058, 0.062]}), defaultdict(<class 'list'>, {'all_KL': [0.072, 0.046, 0.046], 'all_L1': [0.073, 0.055, 0.056]}), defaultdict(<class 'list'>, {'all_KL': [0.056, 0.04, 0.037], 'all_L1': [0.07, 0.065, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.077, 0.059, 0.049], 'all_L1': [0.085, 0.077, 0.066]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.923, 0.954, 0.99, 1.0], 'all_L1': [0.919, 0.939, 0.974, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.887, 0.942, 0.986, 1.0], 'all_L1': [0.913, 0.938, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.945, 0.986, 1.0], 'all_L1': [0.925, 0.934, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.919, 0.949, 0.991, 1.0], 'all_L1': [0.924, 0.943, 0.976, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.887, 0.943, 0.983, 1.0], 'all_L1': [0.911, 0.936, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.078, 0.059, 0.044, 0.045], 'all_L1': [0.098, 0.077, 0.065, 0.062]}), defaultdict(<class 'list'>, {'all_KL': [0.093, 0.065, 0.046, 0.05], 'all_L1': [0.091, 0.074, 0.056, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.109, 0.075, 0.055, 0.057], 'all_L1': [0.105, 0.088, 0.07, 0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.081, 0.052, 0.045, 0.043], 'all_L1': [0.096, 0.07, 0.063, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.094, 0.069, 0.058, 0.062], 'all_L1': [0.092, 0.076, 0.067, 0.068]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.943 +- 0.009, 0.933 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.945 +- 0.012, 0.951 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.845 +- 0.007, 0.857 +- 0.016
nec class all_L1  =  0.070 +- 0.009, 0.064 +- 0.008, 0.063 +- 0.005
nec class all_KL  =  0.061 +- 0.012, 0.046 +- 0.007, 0.046 +- 0.005
nec_acc_int  =  0.850 +- 0.013, 0.856 +- 0.013, 0.858 +- 0.012

Eval split test
suff++ class all_L1  =  0.918 +- 0.006, 0.938 +- 0.003, 0.973 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.905 +- 0.016, 0.947 +- 0.004, 0.987 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.746 +- 0.012, 0.779 +- 0.015, 0.812 +- 0.012
nec class all_L1  =  0.096 +- 0.005, 0.077 +- 0.006, 0.064 +- 0.005, 0.063 +- 0.005
nec class all_KL  =  0.091 +- 0.011, 0.064 +- 0.008, 0.050 +- 0.006, 0.051 +- 0.007
nec_acc_int  =  0.767 +- 0.013, 0.795 +- 0.014, 0.818 +- 0.011, 0.820 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.507 +- 0.003, 0.498 +- 0.001, 0.531 +- 0.002
Faith. Armon (L1)= 		  =  0.131 +- 0.015, 0.119 +- 0.013, 0.118 +- 0.009
Faith. GMean (L1)= 	  =  0.257 +- 0.015, 0.243 +- 0.013, 0.250 +- 0.010
Faith. Aritm (KL)= 		  =  0.503 +- 0.005, 0.498 +- 0.001, 0.523 +- 0.003
Faith. Armon (KL)= 		  =  0.114 +- 0.021, 0.087 +- 0.013, 0.088 +- 0.010
Faith. GMean (KL)= 	  =  0.239 +- 0.022, 0.208 +- 0.015, 0.214 +- 0.013

Eval split test
Faith. Aritm (L1)= 		  =  0.507 +- 0.005, 0.508 +- 0.002, 0.519 +- 0.002, 0.531 +- 0.002
Faith. Armon (L1)= 		  =  0.174 +- 0.008, 0.142 +- 0.010, 0.120 +- 0.008, 0.118 +- 0.008
Faith. GMean (L1)= 	  =  0.297 +- 0.008, 0.269 +- 0.010, 0.250 +- 0.009, 0.251 +- 0.010
Faith. Aritm (KL)= 		  =  0.498 +- 0.007, 0.505 +- 0.003, 0.518 +- 0.002, 0.526 +- 0.004
Faith. Armon (KL)= 		  =  0.165 +- 0.018, 0.120 +- 0.014, 0.094 +- 0.010, 0.098 +- 0.013
Faith. GMean (KL)= 	  =  0.286 +- 0.016, 0.246 +- 0.015, 0.221 +- 0.012, 0.226 +- 0.016
Computed for split load_split = id



Completed in  0:11:59.020735  for GSATGIN GOODSST2/length



DONE GSAT GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:41:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:41:14 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:41:50 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:11 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:28 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:42:44 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.9169
Train Loss: 0.2213
ID Validation ROC-AUC: 0.8917
ID Validation Loss: 0.2544
ID Test ROC-AUC: 0.8970
ID Test Loss: 0.2524
OOD Validation ROC-AUC: 0.6382
OOD Validation Loss: 0.3929
OOD Test ROC-AUC: 0.6940
OOD Test Loss: 0.5070

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ROC-AUC: 0.8609
Train Loss: 0.2974
ID Validation ROC-AUC: 0.8471
ID Validation Loss: 0.3106
ID Test ROC-AUC: 0.8565
ID Test Loss: 0.3081
OOD Validation ROC-AUC: 0.6770
OOD Validation Loss: 0.3063
OOD Test ROC-AUC: 0.6903
OOD Test Loss: 0.5439

[0m[1;37mINFO[0m: [1mChartInfo 0.8970 0.6940 0.8565 0.6903 0.8471 0.6770[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:42:46 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:42:50 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.679
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 789
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.638
SUFF++ for r=0.3 class 0.0 = 0.731 +- 0.134 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 class 1.0 = 0.859 +- 0.134 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all KL = 0.904 +- 0.134 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.3 all L1 = 0.844 +- 0.154 (in-sample avg dev_std = 0.259)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.768
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.729
SUFF++ for r=0.6 class 0.0 = 0.822 +- 0.072 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.6 class 1.0 = 0.927 +- 0.072 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.6 all KL = 0.965 +- 0.072 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.6 all L1 = 0.915 +- 0.114 (in-sample avg dev_std = 0.121)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0.0 = 0.905 +- 0.020 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.020 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 all KL = 0.991 +- 0.020 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.054 (in-sample avg dev_std = 0.087)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.622
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.59
SUFF++ for r=0.3 class 0.0 = 0.756 +- 0.138 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.3 class 1.0 = 0.819 +- 0.138 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.3 all KL = 0.883 +- 0.138 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.3 all L1 = 0.809 +- 0.160 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0.0 = 0.841 +- 0.084 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 1.0 = 0.883 +- 0.084 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all KL = 0.948 +- 0.084 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all L1 = 0.876 +- 0.136 (in-sample avg dev_std = 0.149)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.678
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0.0 = 0.928 +- 0.035 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.035 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.986 +- 0.035 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.069 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.671
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.676
NEC for r=0.3 class 0.0 = 0.169 +- 0.088 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 1.0 = 0.111 +- 0.088 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all KL = 0.054 +- 0.088 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all L1 = 0.118 +- 0.132 (in-sample avg dev_std = 0.165)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.768
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.745
NEC for r=0.6 class 0.0 = 0.188 +- 0.085 (in-sample avg dev_std = 0.152)
NEC for r=0.6 class 1.0 = 0.074 +- 0.085 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all KL = 0.043 +- 0.085 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all L1 = 0.088 +- 0.116 (in-sample avg dev_std = 0.152)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.855
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.798
NEC for r=0.9 class 0.0 = 0.248 +- 0.080 (in-sample avg dev_std = 0.134)
NEC for r=0.9 class 1.0 = 0.057 +- 0.080 (in-sample avg dev_std = 0.134)
NEC for r=0.9 all KL = 0.038 +- 0.080 (in-sample avg dev_std = 0.134)
NEC for r=0.9 all L1 = 0.079 +- 0.122 (in-sample avg dev_std = 0.134)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.876
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.816
NEC for r=1.0 class 0.0 = 0.267 +- 0.085 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.059 +- 0.085 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.042 +- 0.085 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.083 +- 0.129 (in-sample avg dev_std = 0.145)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.627
NEC for r=0.3 class 0.0 = 0.175 +- 0.107 (in-sample avg dev_std = 0.185)
NEC for r=0.3 class 1.0 = 0.134 +- 0.107 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all KL = 0.066 +- 0.107 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all L1 = 0.141 +- 0.132 (in-sample avg dev_std = 0.185)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.632
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.631
NEC for r=0.6 class 0.0 = 0.162 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.6 class 1.0 = 0.108 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.6 all KL = 0.054 +- 0.093 (in-sample avg dev_std = 0.174)
NEC for r=0.6 all L1 = 0.117 +- 0.128 (in-sample avg dev_std = 0.174)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.678
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.662
NEC for r=0.9 class 0.0 = 0.166 +- 0.082 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 1.0 = 0.11 +- 0.082 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all KL = 0.053 +- 0.082 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all L1 = 0.119 +- 0.133 (in-sample avg dev_std = 0.157)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.668
NEC for r=1.0 class 0.0 = 0.199 +- 0.095 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 1.0 = 0.112 +- 0.095 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all KL = 0.057 +- 0.095 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all L1 = 0.126 +- 0.142 (in-sample avg dev_std = 0.155)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:45:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:45:52 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:46:27 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:46:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:46:48 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:04 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ROC-AUC: 0.9177
Train Loss: 0.2213
ID Validation ROC-AUC: 0.8918
ID Validation Loss: 0.2573
ID Test ROC-AUC: 0.8984
ID Test Loss: 0.2518
OOD Validation ROC-AUC: 0.6468
OOD Validation Loss: 0.3762
OOD Test ROC-AUC: 0.6919
OOD Test Loss: 0.5107

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 74...
[0m[1;37mINFO[0m: [1mCheckpoint 74: 
-----------------------------------
Train ROC-AUC: 0.8920
Train Loss: 0.2449
ID Validation ROC-AUC: 0.8753
ID Validation Loss: 0.2636
ID Test ROC-AUC: 0.8793
ID Test Loss: 0.2613
OOD Validation ROC-AUC: 0.6705
OOD Validation Loss: 0.3458
OOD Test ROC-AUC: 0.7046
OOD Test Loss: 0.4816

[0m[1;37mINFO[0m: [1mChartInfo 0.8984 0.6919 0.8793 0.7046 0.8753 0.6705[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:47:20 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:47:25 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.698
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 786
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.63
SUFF++ for r=0.3 class 0.0 = 0.76 +- 0.119 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 class 1.0 = 0.864 +- 0.119 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 all KL = 0.914 +- 0.119 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.3 all L1 = 0.852 +- 0.142 (in-sample avg dev_std = 0.236)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.778
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.746
SUFF++ for r=0.6 class 0.0 = 0.822 +- 0.060 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 class 1.0 = 0.933 +- 0.060 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all KL = 0.968 +- 0.060 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.109 (in-sample avg dev_std = 0.103)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0.0 = 0.909 +- 0.026 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.026 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 all KL = 0.991 +- 0.026 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.9 all L1 = 0.97 +- 0.056 (in-sample avg dev_std = 0.078)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
SUFF++ for r=0.3 class 0.0 = 0.794 +- 0.119 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 class 1.0 = 0.833 +- 0.119 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all KL = 0.905 +- 0.119 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.3 all L1 = 0.827 +- 0.156 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0.0 = 0.827 +- 0.082 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.6 class 1.0 = 0.896 +- 0.082 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.6 all KL = 0.952 +- 0.082 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.6 all L1 = 0.885 +- 0.135 (in-sample avg dev_std = 0.138)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.669
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.664
SUFF++ for r=0.9 class 0.0 = 0.934 +- 0.035 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.035 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all KL = 0.987 +- 0.035 (in-sample avg dev_std = 0.100)
SUFF++ for r=0.9 all L1 = 0.956 +- 0.063 (in-sample avg dev_std = 0.100)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.694
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.686
NEC for r=0.3 class 0.0 = 0.19 +- 0.079 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 1.0 = 0.099 +- 0.079 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all KL = 0.047 +- 0.079 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all L1 = 0.11 +- 0.117 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.778
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.758
NEC for r=0.6 class 0.0 = 0.199 +- 0.093 (in-sample avg dev_std = 0.161)
NEC for r=0.6 class 1.0 = 0.069 +- 0.093 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all KL = 0.045 +- 0.093 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all L1 = 0.084 +- 0.118 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.808
NEC for r=0.9 class 0.0 = 0.246 +- 0.099 (in-sample avg dev_std = 0.139)
NEC for r=0.9 class 1.0 = 0.06 +- 0.099 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all KL = 0.046 +- 0.099 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all L1 = 0.081 +- 0.126 (in-sample avg dev_std = 0.139)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.869
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.804
NEC for r=1.0 class 0.0 = 0.254 +- 0.105 (in-sample avg dev_std = 0.147)
NEC for r=1.0 class 1.0 = 0.06 +- 0.105 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all KL = 0.05 +- 0.105 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all L1 = 0.083 +- 0.128 (in-sample avg dev_std = 0.147)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.603
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0.0 = 0.168 +- 0.095 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1.0 = 0.132 +- 0.095 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.062 +- 0.095 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.138 +- 0.141 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
NEC for r=0.6 class 0.0 = 0.17 +- 0.096 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 1.0 = 0.101 +- 0.096 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all KL = 0.056 +- 0.096 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all L1 = 0.113 +- 0.131 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.669
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.651
NEC for r=0.9 class 0.0 = 0.187 +- 0.099 (in-sample avg dev_std = 0.160)
NEC for r=0.9 class 1.0 = 0.102 +- 0.099 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all KL = 0.058 +- 0.099 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all L1 = 0.116 +- 0.139 (in-sample avg dev_std = 0.160)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.677
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.659
NEC for r=1.0 class 0.0 = 0.191 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=1.0 class 1.0 = 0.117 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all KL = 0.064 +- 0.103 (in-sample avg dev_std = 0.161)
NEC for r=1.0 all L1 = 0.129 +- 0.145 (in-sample avg dev_std = 0.161)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:50:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:50:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:50:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:09 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:20 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:36 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:51:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ROC-AUC: 0.9167
Train Loss: 0.2199
ID Validation ROC-AUC: 0.8927
ID Validation Loss: 0.2531
ID Test ROC-AUC: 0.8965
ID Test Loss: 0.2508
OOD Validation ROC-AUC: 0.6401
OOD Validation Loss: 0.3915
OOD Test ROC-AUC: 0.6865
OOD Test Loss: 0.5100

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 36...
[0m[1;37mINFO[0m: [1mCheckpoint 36: 
-----------------------------------
Train ROC-AUC: 0.8702
Train Loss: 0.2826
ID Validation ROC-AUC: 0.8547
ID Validation Loss: 0.2953
ID Test ROC-AUC: 0.8658
ID Test Loss: 0.2920
OOD Validation ROC-AUC: 0.6717
OOD Validation Loss: 0.3020
OOD Test ROC-AUC: 0.6881
OOD Test Loss: 0.5174

[0m[1;37mINFO[0m: [1mChartInfo 0.8965 0.6865 0.8658 0.6881 0.8547 0.6717[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:51:52 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:51:56 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.664
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.62
SUFF++ for r=0.3 class 0.0 = 0.775 +- 0.109 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 class 1.0 = 0.873 +- 0.109 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 all KL = 0.922 +- 0.109 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 all L1 = 0.862 +- 0.144 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.757
SUFF++ for r=0.6 class 0.0 = 0.809 +- 0.076 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 class 1.0 = 0.931 +- 0.076 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all KL = 0.965 +- 0.076 (in-sample avg dev_std = 0.118)
SUFF++ for r=0.6 all L1 = 0.917 +- 0.123 (in-sample avg dev_std = 0.118)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.848
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.841
SUFF++ for r=0.9 class 0.0 = 0.899 +- 0.026 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.026 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 all KL = 0.99 +- 0.026 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.059 (in-sample avg dev_std = 0.087)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 776
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
SUFF++ for r=0.3 class 0.0 = 0.781 +- 0.125 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 1.0 = 0.84 +- 0.125 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all KL = 0.899 +- 0.125 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all L1 = 0.83 +- 0.154 (in-sample avg dev_std = 0.255)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.624
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.614
SUFF++ for r=0.6 class 0.0 = 0.85 +- 0.078 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 class 1.0 = 0.902 +- 0.078 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 all KL = 0.956 +- 0.078 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.6 all L1 = 0.893 +- 0.124 (in-sample avg dev_std = 0.132)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.698
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.687
SUFF++ for r=0.9 class 0.0 = 0.922 +- 0.039 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.039 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.985 +- 0.039 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.070 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.668
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.644
NEC for r=0.3 class 0.0 = 0.184 +- 0.088 (in-sample avg dev_std = 0.162)
NEC for r=0.3 class 1.0 = 0.103 +- 0.088 (in-sample avg dev_std = 0.162)
NEC for r=0.3 all KL = 0.052 +- 0.088 (in-sample avg dev_std = 0.162)
NEC for r=0.3 all L1 = 0.113 +- 0.128 (in-sample avg dev_std = 0.162)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.744
NEC for r=0.6 class 0.0 = 0.19 +- 0.098 (in-sample avg dev_std = 0.154)
NEC for r=0.6 class 1.0 = 0.072 +- 0.098 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all KL = 0.046 +- 0.098 (in-sample avg dev_std = 0.154)
NEC for r=0.6 all L1 = 0.085 +- 0.121 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.848
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.787
NEC for r=0.9 class 0.0 = 0.269 +- 0.107 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 1.0 = 0.07 +- 0.107 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all KL = 0.058 +- 0.107 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all L1 = 0.093 +- 0.137 (in-sample avg dev_std = 0.166)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.796
NEC for r=1.0 class 0.0 = 0.281 +- 0.122 (in-sample avg dev_std = 0.172)
NEC for r=1.0 class 1.0 = 0.077 +- 0.122 (in-sample avg dev_std = 0.172)
NEC for r=1.0 all KL = 0.065 +- 0.122 (in-sample avg dev_std = 0.172)
NEC for r=1.0 all L1 = 0.1 +- 0.147 (in-sample avg dev_std = 0.172)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.578
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.587
NEC for r=0.3 class 0.0 = 0.16 +- 0.104 (in-sample avg dev_std = 0.184)
NEC for r=0.3 class 1.0 = 0.135 +- 0.104 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all KL = 0.066 +- 0.104 (in-sample avg dev_std = 0.184)
NEC for r=0.3 all L1 = 0.139 +- 0.140 (in-sample avg dev_std = 0.184)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.624
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0.0 = 0.152 +- 0.092 (in-sample avg dev_std = 0.164)
NEC for r=0.6 class 1.0 = 0.102 +- 0.092 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all KL = 0.054 +- 0.092 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all L1 = 0.11 +- 0.128 (in-sample avg dev_std = 0.164)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.698
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
NEC for r=0.9 class 0.0 = 0.2 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1.0 = 0.109 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.066 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.124 +- 0.147 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.709
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0.0 = 0.211 +- 0.118 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 1.0 = 0.123 +- 0.118 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all KL = 0.074 +- 0.118 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all L1 = 0.137 +- 0.157 (in-sample avg dev_std = 0.174)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:54:55 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:54:55 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:55:30 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 02:55:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 02:55:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.9170
Train Loss: 0.2226
ID Validation ROC-AUC: 0.8917
ID Validation Loss: 0.2557
ID Test ROC-AUC: 0.8960
ID Test Loss: 0.2545
OOD Validation ROC-AUC: 0.6425
OOD Validation Loss: 0.4071
OOD Test ROC-AUC: 0.6986
OOD Test Loss: 0.5143

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 34...
[0m[1;37mINFO[0m: [1mCheckpoint 34: 
-----------------------------------
Train ROC-AUC: 0.8702
Train Loss: 0.2691
ID Validation ROC-AUC: 0.8562
ID Validation Loss: 0.2805
ID Test ROC-AUC: 0.8672
ID Test Loss: 0.2773
OOD Validation ROC-AUC: 0.6673
OOD Validation Loss: 0.3080
OOD Test ROC-AUC: 0.6889
OOD Test Loss: 0.4959

[0m[1;37mINFO[0m: [1mChartInfo 0.8960 0.6986 0.8672 0.6889 0.8562 0.6673[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 02:56:22 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 02:56:27 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.663
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 784
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.641
SUFF++ for r=0.3 class 0.0 = 0.804 +- 0.104 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 class 1.0 = 0.873 +- 0.104 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 all KL = 0.927 +- 0.104 (in-sample avg dev_std = 0.204)
SUFF++ for r=0.3 all L1 = 0.865 +- 0.140 (in-sample avg dev_std = 0.204)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.75
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0.0 = 0.828 +- 0.067 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 class 1.0 = 0.933 +- 0.067 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 all KL = 0.967 +- 0.067 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 all L1 = 0.921 +- 0.115 (in-sample avg dev_std = 0.115)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0.0 = 0.899 +- 0.037 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1.0 = 0.978 +- 0.037 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.99 +- 0.037 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.060 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0.0 = 0.79 +- 0.118 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 class 1.0 = 0.847 +- 0.118 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all KL = 0.908 +- 0.118 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.3 all L1 = 0.837 +- 0.147 (in-sample avg dev_std = 0.241)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0.0 = 0.844 +- 0.082 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 class 1.0 = 0.904 +- 0.082 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all KL = 0.955 +- 0.082 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all L1 = 0.894 +- 0.127 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.682
SUFF++ for r=0.9 class 0.0 = 0.92 +- 0.044 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.044 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all KL = 0.983 +- 0.044 (in-sample avg dev_std = 0.121)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.073 (in-sample avg dev_std = 0.121)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.657
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.654
NEC for r=0.3 class 0.0 = 0.179 +- 0.090 (in-sample avg dev_std = 0.165)
NEC for r=0.3 class 1.0 = 0.106 +- 0.090 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all KL = 0.056 +- 0.090 (in-sample avg dev_std = 0.165)
NEC for r=0.3 all L1 = 0.115 +- 0.127 (in-sample avg dev_std = 0.165)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.75
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.727
NEC for r=0.6 class 0.0 = 0.181 +- 0.100 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 1.0 = 0.072 +- 0.100 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all KL = 0.047 +- 0.100 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all L1 = 0.085 +- 0.120 (in-sample avg dev_std = 0.159)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.849
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.797
NEC for r=0.9 class 0.0 = 0.262 +- 0.103 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 1.0 = 0.064 +- 0.103 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all KL = 0.051 +- 0.103 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all L1 = 0.087 +- 0.138 (in-sample avg dev_std = 0.157)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.875
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.799
NEC for r=1.0 class 0.0 = 0.305 +- 0.115 (in-sample avg dev_std = 0.175)
NEC for r=1.0 class 1.0 = 0.07 +- 0.115 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all KL = 0.062 +- 0.115 (in-sample avg dev_std = 0.175)
NEC for r=1.0 all L1 = 0.098 +- 0.146 (in-sample avg dev_std = 0.175)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.596
NEC for r=0.3 class 0.0 = 0.151 +- 0.113 (in-sample avg dev_std = 0.192)
NEC for r=0.3 class 1.0 = 0.135 +- 0.113 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all KL = 0.07 +- 0.113 (in-sample avg dev_std = 0.192)
NEC for r=0.3 all L1 = 0.138 +- 0.137 (in-sample avg dev_std = 0.192)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0.0 = 0.154 +- 0.098 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 1.0 = 0.102 +- 0.098 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all KL = 0.057 +- 0.098 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all L1 = 0.111 +- 0.130 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.652
NEC for r=0.9 class 0.0 = 0.191 +- 0.116 (in-sample avg dev_std = 0.190)
NEC for r=0.9 class 1.0 = 0.117 +- 0.116 (in-sample avg dev_std = 0.190)
NEC for r=0.9 all KL = 0.072 +- 0.116 (in-sample avg dev_std = 0.190)
NEC for r=0.9 all L1 = 0.13 +- 0.146 (in-sample avg dev_std = 0.190)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.692
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0.0 = 0.219 +- 0.121 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 1.0 = 0.128 +- 0.121 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all KL = 0.079 +- 0.121 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all L1 = 0.143 +- 0.155 (in-sample avg dev_std = 0.194)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 14:59:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 02:59:24 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 02:59:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:08 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:19 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:35 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ROC-AUC: 0.9165
Train Loss: 0.2206
ID Validation ROC-AUC: 0.8913
ID Validation Loss: 0.2538
ID Test ROC-AUC: 0.8969
ID Test Loss: 0.2504
OOD Validation ROC-AUC: 0.6290
OOD Validation Loss: 0.3879
OOD Test ROC-AUC: 0.6928
OOD Test Loss: 0.5115

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 34...
[0m[1;37mINFO[0m: [1mCheckpoint 34: 
-----------------------------------
Train ROC-AUC: 0.8628
Train Loss: 0.2911
ID Validation ROC-AUC: 0.8493
ID Validation Loss: 0.3012
ID Test ROC-AUC: 0.8611
ID Test Loss: 0.2996
OOD Validation ROC-AUC: 0.6659
OOD Validation Loss: 0.3055
OOD Test ROC-AUC: 0.6840
OOD Test Loss: 0.5249

[0m[1;37mINFO[0m: [1mChartInfo 0.8969 0.6928 0.8611 0.6840 0.8493 0.6659[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:00:51 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:00:55 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.721
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.664
SUFF++ for r=0.3 class 0.0 = 0.766 +- 0.122 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 class 1.0 = 0.887 +- 0.122 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 all KL = 0.923 +- 0.122 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.3 all L1 = 0.874 +- 0.151 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.765
SUFF++ for r=0.6 class 0.0 = 0.839 +- 0.057 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.6 class 1.0 = 0.955 +- 0.057 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.6 all KL = 0.975 +- 0.057 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.6 all L1 = 0.941 +- 0.105 (in-sample avg dev_std = 0.087)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.848
SUFF++ for r=0.9 class 0.0 = 0.928 +- 0.017 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.9 class 1.0 = 0.989 +- 0.017 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.9 all KL = 0.995 +- 0.017 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.9 all L1 = 0.981 +- 0.043 (in-sample avg dev_std = 0.063)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.605
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.802 +- 0.136 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.3 class 1.0 = 0.848 +- 0.136 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.3 all KL = 0.9 +- 0.136 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.3 all L1 = 0.84 +- 0.155 (in-sample avg dev_std = 0.257)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.619
SUFF++ for r=0.6 class 0.0 = 0.882 +- 0.074 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 class 1.0 = 0.927 +- 0.074 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all KL = 0.964 +- 0.074 (in-sample avg dev_std = 0.111)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.115 (in-sample avg dev_std = 0.111)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.694
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.682
SUFF++ for r=0.9 class 0.0 = 0.957 +- 0.018 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 class 1.0 = 0.981 +- 0.018 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 all KL = 0.993 +- 0.018 (in-sample avg dev_std = 0.064)
SUFF++ for r=0.9 all L1 = 0.977 +- 0.043 (in-sample avg dev_std = 0.064)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.719
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.706
NEC for r=0.3 class 0.0 = 0.191 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 1.0 = 0.091 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all KL = 0.05 +- 0.087 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all L1 = 0.103 +- 0.122 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.172 +- 0.072 (in-sample avg dev_std = 0.127)
NEC for r=0.6 class 1.0 = 0.047 +- 0.072 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all KL = 0.033 +- 0.072 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all L1 = 0.062 +- 0.106 (in-sample avg dev_std = 0.127)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.858
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.825
NEC for r=0.9 class 0.0 = 0.19 +- 0.065 (in-sample avg dev_std = 0.099)
NEC for r=0.9 class 1.0 = 0.032 +- 0.065 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all KL = 0.027 +- 0.065 (in-sample avg dev_std = 0.099)
NEC for r=0.9 all L1 = 0.05 +- 0.100 (in-sample avg dev_std = 0.099)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.873
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.832
NEC for r=1.0 class 0.0 = 0.188 +- 0.076 (in-sample avg dev_std = 0.110)
NEC for r=1.0 class 1.0 = 0.033 +- 0.076 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all KL = 0.03 +- 0.076 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all L1 = 0.051 +- 0.106 (in-sample avg dev_std = 0.110)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.609
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.577
NEC for r=0.3 class 0.0 = 0.168 +- 0.112 (in-sample avg dev_std = 0.183)
NEC for r=0.3 class 1.0 = 0.122 +- 0.112 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all KL = 0.065 +- 0.112 (in-sample avg dev_std = 0.183)
NEC for r=0.3 all L1 = 0.129 +- 0.137 (in-sample avg dev_std = 0.183)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.652
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.624
NEC for r=0.6 class 0.0 = 0.139 +- 0.100 (in-sample avg dev_std = 0.160)
NEC for r=0.6 class 1.0 = 0.077 +- 0.100 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all KL = 0.05 +- 0.100 (in-sample avg dev_std = 0.160)
NEC for r=0.6 all L1 = 0.088 +- 0.120 (in-sample avg dev_std = 0.160)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.694
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.664
NEC for r=0.9 class 0.0 = 0.115 +- 0.087 (in-sample avg dev_std = 0.126)
NEC for r=0.9 class 1.0 = 0.058 +- 0.087 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all KL = 0.041 +- 0.087 (in-sample avg dev_std = 0.126)
NEC for r=0.9 all L1 = 0.068 +- 0.110 (in-sample avg dev_std = 0.126)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.712
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.683
NEC for r=1.0 class 0.0 = 0.115 +- 0.078 (in-sample avg dev_std = 0.114)
NEC for r=1.0 class 1.0 = 0.056 +- 0.078 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all KL = 0.035 +- 0.078 (in-sample avg dev_std = 0.114)
NEC for r=1.0 all L1 = 0.066 +- 0.107 (in-sample avg dev_std = 0.114)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.904, 0.965, 0.991, 1.0], 'all_L1': [0.844, 0.915, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.914, 0.968, 0.991, 1.0], 'all_L1': [0.852, 0.92, 0.97, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.922, 0.965, 0.99, 1.0], 'all_L1': [0.862, 0.917, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.927, 0.967, 0.99, 1.0], 'all_L1': [0.865, 0.921, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.923, 0.975, 0.995, 1.0], 'all_L1': [0.874, 0.941, 0.981, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.054, 0.043, 0.038, 0.042], 'all_L1': [0.118, 0.088, 0.079, 0.083]}), defaultdict(<class 'list'>, {'all_KL': [0.047, 0.045, 0.046, 0.05], 'all_L1': [0.11, 0.084, 0.081, 0.083]}), defaultdict(<class 'list'>, {'all_KL': [0.052, 0.046, 0.058, 0.065], 'all_L1': [0.113, 0.085, 0.093, 0.1]}), defaultdict(<class 'list'>, {'all_KL': [0.056, 0.047, 0.051, 0.062], 'all_L1': [0.115, 0.085, 0.087, 0.098]}), defaultdict(<class 'list'>, {'all_KL': [0.05, 0.033, 0.027, 0.03], 'all_L1': [0.103, 0.062, 0.05, 0.051]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.883, 0.948, 0.986, 1.0], 'all_L1': [0.809, 0.876, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.905, 0.952, 0.987, 1.0], 'all_L1': [0.827, 0.885, 0.956, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.899, 0.956, 0.985, 1.0], 'all_L1': [0.83, 0.893, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.908, 0.955, 0.983, 1.0], 'all_L1': [0.837, 0.894, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.9, 0.964, 0.993, 1.0], 'all_L1': [0.84, 0.92, 0.977, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.066, 0.054, 0.053, 0.057], 'all_L1': [0.141, 0.117, 0.119, 0.126]}), defaultdict(<class 'list'>, {'all_KL': [0.062, 0.056, 0.058, 0.064], 'all_L1': [0.138, 0.113, 0.116, 0.129]}), defaultdict(<class 'list'>, {'all_KL': [0.066, 0.054, 0.066, 0.074], 'all_L1': [0.139, 0.11, 0.124, 0.137]}), defaultdict(<class 'list'>, {'all_KL': [0.07, 0.057, 0.072, 0.079], 'all_L1': [0.138, 0.111, 0.13, 0.143]}), defaultdict(<class 'list'>, {'all_KL': [0.065, 0.05, 0.041, 0.035], 'all_L1': [0.129, 0.088, 0.068, 0.066]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.859 +- 0.010, 0.923 +- 0.009, 0.971 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.918 +- 0.008, 0.968 +- 0.004, 0.991 +- 0.002, 1.000 +- 0.000
suff++_acc_int  =  0.639 +- 0.015, 0.743 +- 0.018, 0.847 +- 0.005
nec class all_L1  =  0.112 +- 0.005, 0.081 +- 0.009, 0.078 +- 0.015, 0.083 +- 0.018
nec class all_KL  =  0.052 +- 0.003, 0.043 +- 0.005, 0.044 +- 0.011, 0.050 +- 0.013
nec_acc_int  =  0.673 +- 0.022, 0.749 +- 0.015, 0.803 +- 0.013, 0.809 +- 0.013

Eval split test
suff++ class all_L1  =  0.829 +- 0.011, 0.894 +- 0.015, 0.957 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.899 +- 0.009, 0.955 +- 0.005, 0.987 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.578 +- 0.011, 0.626 +- 0.009, 0.679 +- 0.008
nec class all_L1  =  0.137 +- 0.004, 0.108 +- 0.010, 0.111 +- 0.022, 0.120 +- 0.028
nec class all_KL  =  0.066 +- 0.003, 0.054 +- 0.002, 0.058 +- 0.011, 0.062 +- 0.015
nec_acc_int  =  0.598 +- 0.017, 0.629 +- 0.006, 0.659 +- 0.006, 0.670 +- 0.009


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.486 +- 0.004, 0.502 +- 0.001, 0.525 +- 0.005, 0.541 +- 0.009
Faith. Armon (L1)= 		  =  0.198 +- 0.008, 0.148 +- 0.016, 0.144 +- 0.026, 0.153 +- 0.030
Faith. GMean (L1)= 	  =  0.310 +- 0.006, 0.272 +- 0.016, 0.274 +- 0.027, 0.286 +- 0.032
Faith. Aritm (KL)= 		  =  0.485 +- 0.005, 0.505 +- 0.001, 0.518 +- 0.005, 0.525 +- 0.006
Faith. Armon (KL)= 		  =  0.098 +- 0.006, 0.082 +- 0.009, 0.084 +- 0.020, 0.095 +- 0.024
Faith. GMean (KL)= 	  =  0.218 +- 0.007, 0.203 +- 0.012, 0.207 +- 0.026, 0.221 +- 0.030

Eval split test
Faith. Aritm (L1)= 		  =  0.483 +- 0.004, 0.501 +- 0.003, 0.534 +- 0.006, 0.560 +- 0.014
Faith. Armon (L1)= 		  =  0.235 +- 0.006, 0.192 +- 0.016, 0.199 +- 0.037, 0.213 +- 0.046
Faith. GMean (L1)= 	  =  0.337 +- 0.004, 0.310 +- 0.013, 0.324 +- 0.034, 0.344 +- 0.044
Faith. Aritm (KL)= 		  =  0.482 +- 0.005, 0.505 +- 0.002, 0.522 +- 0.004, 0.531 +- 0.008
Faith. Armon (KL)= 		  =  0.123 +- 0.004, 0.103 +- 0.004, 0.109 +- 0.019, 0.116 +- 0.028
Faith. GMean (KL)= 	  =  0.243 +- 0.005, 0.227 +- 0.005, 0.238 +- 0.022, 0.246 +- 0.033
Computed for split load_split = id



Completed in  0:22:42.168330  for LECIGIN LBAPcore/assay



DONE LECI LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:04:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:04:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:04:44 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:04:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:20 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:05:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ROC-AUC: 0.9219
Train Loss: 0.2433
ID Validation ROC-AUC: 0.9005
ID Validation Loss: 0.2836
ID Test ROC-AUC: 0.9006
ID Test Loss: 0.2830
OOD Validation ROC-AUC: 0.6415
OOD Validation Loss: 0.5290
OOD Test ROC-AUC: 0.6998
OOD Test Loss: 0.6406

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ROC-AUC: 0.8862
Train Loss: 0.2825
ID Validation ROC-AUC: 0.8721
ID Validation Loss: 0.3043
ID Test ROC-AUC: 0.8739
ID Test Loss: 0.3017
OOD Validation ROC-AUC: 0.6708
OOD Validation Loss: 0.4663
OOD Test ROC-AUC: 0.6892
OOD Test Loss: 0.5869

[0m[1;37mINFO[0m: [1mChartInfo 0.9006 0.6998 0.8739 0.6892 0.8721 0.6708[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:05:36 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:05:41 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.68
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 793
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.671
SUFF++ for r=0.3 class 0.0 = 0.699 +- 0.198 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 class 1.0 = 0.814 +- 0.198 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all KL = 0.835 +- 0.198 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all L1 = 0.801 +- 0.191 (in-sample avg dev_std = 0.346)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.744
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.737
SUFF++ for r=0.6 class 0.0 = 0.731 +- 0.201 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 class 1.0 = 0.894 +- 0.201 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all KL = 0.893 +- 0.201 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.6 all L1 = 0.875 +- 0.189 (in-sample avg dev_std = 0.250)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.774
SUFF++ for r=0.9 class 0.0 = 0.838 +- 0.140 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 1.0 = 0.952 +- 0.140 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all KL = 0.949 +- 0.140 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all L1 = 0.939 +- 0.137 (in-sample avg dev_std = 0.185)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.63
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 784
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.608
SUFF++ for r=0.3 class 0.0 = 0.711 +- 0.218 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 class 1.0 = 0.78 +- 0.218 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 all KL = 0.803 +- 0.218 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.3 all L1 = 0.769 +- 0.203 (in-sample avg dev_std = 0.375)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.667
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
SUFF++ for r=0.6 class 0.0 = 0.769 +- 0.202 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 class 1.0 = 0.853 +- 0.202 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all KL = 0.869 +- 0.202 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all L1 = 0.839 +- 0.203 (in-sample avg dev_std = 0.272)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.667
SUFF++ for r=0.9 class 0.0 = 0.885 +- 0.159 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 class 1.0 = 0.919 +- 0.159 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all KL = 0.925 +- 0.159 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.9 all L1 = 0.913 +- 0.151 (in-sample avg dev_std = 0.227)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.678
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.676
NEC for r=0.3 class 0.0 = 0.187 +- 0.198 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 1.0 = 0.183 +- 0.198 (in-sample avg dev_std = 0.311)
NEC for r=0.3 all KL = 0.155 +- 0.198 (in-sample avg dev_std = 0.311)
NEC for r=0.3 all L1 = 0.183 +- 0.174 (in-sample avg dev_std = 0.311)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.744
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.744
NEC for r=0.6 class 0.0 = 0.235 +- 0.207 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 1.0 = 0.119 +- 0.207 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all KL = 0.129 +- 0.207 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all L1 = 0.132 +- 0.178 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.775
NEC for r=0.9 class 0.0 = 0.215 +- 0.186 (in-sample avg dev_std = 0.242)
NEC for r=0.9 class 1.0 = 0.078 +- 0.186 (in-sample avg dev_std = 0.242)
NEC for r=0.9 all KL = 0.096 +- 0.186 (in-sample avg dev_std = 0.242)
NEC for r=0.9 all L1 = 0.094 +- 0.170 (in-sample avg dev_std = 0.242)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.785
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.793
NEC for r=1.0 class 0.0 = 0.207 +- 0.192 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 1.0 = 0.071 +- 0.192 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all KL = 0.09 +- 0.192 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all L1 = 0.087 +- 0.165 (in-sample avg dev_std = 0.239)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.627
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.628
NEC for r=0.3 class 0.0 = 0.256 +- 0.226 (in-sample avg dev_std = 0.344)
NEC for r=0.3 class 1.0 = 0.214 +- 0.226 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all KL = 0.19 +- 0.226 (in-sample avg dev_std = 0.344)
NEC for r=0.3 all L1 = 0.221 +- 0.194 (in-sample avg dev_std = 0.344)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.667
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.654
NEC for r=0.6 class 0.0 = 0.235 +- 0.232 (in-sample avg dev_std = 0.337)
NEC for r=0.6 class 1.0 = 0.169 +- 0.232 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all KL = 0.171 +- 0.232 (in-sample avg dev_std = 0.337)
NEC for r=0.6 all L1 = 0.18 +- 0.198 (in-sample avg dev_std = 0.337)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.658
NEC for r=0.9 class 0.0 = 0.175 +- 0.224 (in-sample avg dev_std = 0.309)
NEC for r=0.9 class 1.0 = 0.136 +- 0.224 (in-sample avg dev_std = 0.309)
NEC for r=0.9 all KL = 0.149 +- 0.224 (in-sample avg dev_std = 0.309)
NEC for r=0.9 all L1 = 0.143 +- 0.195 (in-sample avg dev_std = 0.309)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.684
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.677
NEC for r=1.0 class 0.0 = 0.159 +- 0.223 (in-sample avg dev_std = 0.296)
NEC for r=1.0 class 1.0 = 0.122 +- 0.223 (in-sample avg dev_std = 0.296)
NEC for r=1.0 all KL = 0.136 +- 0.223 (in-sample avg dev_std = 0.296)
NEC for r=1.0 all L1 = 0.128 +- 0.185 (in-sample avg dev_std = 0.296)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:08:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:08:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:08:55 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:05 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:16 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:32 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ROC-AUC: 0.9224
Train Loss: 0.2417
ID Validation ROC-AUC: 0.9030
ID Validation Loss: 0.2771
ID Test ROC-AUC: 0.9024
ID Test Loss: 0.2775
OOD Validation ROC-AUC: 0.6469
OOD Validation Loss: 0.5210
OOD Test ROC-AUC: 0.6993
OOD Test Loss: 0.6134

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ROC-AUC: 0.8995
Train Loss: 0.2912
ID Validation ROC-AUC: 0.8814
ID Validation Loss: 0.3229
ID Test ROC-AUC: 0.8856
ID Test Loss: 0.3231
OOD Validation ROC-AUC: 0.6688
OOD Validation Loss: 0.3630
OOD Test ROC-AUC: 0.6979
OOD Test Loss: 0.6124

[0m[1;37mINFO[0m: [1mChartInfo 0.9024 0.6993 0.8856 0.6979 0.8814 0.6688[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:09:47 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:09:52 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.643
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 791
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.629
SUFF++ for r=0.3 class 0.0 = 0.748 +- 0.213 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.3 class 1.0 = 0.822 +- 0.213 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.3 all KL = 0.839 +- 0.213 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.3 all L1 = 0.814 +- 0.199 (in-sample avg dev_std = 0.348)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.74
SUFF++ for r=0.6 class 0.0 = 0.798 +- 0.182 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 class 1.0 = 0.936 +- 0.182 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all KL = 0.923 +- 0.182 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.6 all L1 = 0.92 +- 0.165 (in-sample avg dev_std = 0.213)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.836 +- 0.148 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1.0 = 0.973 +- 0.148 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.954 +- 0.148 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.957 +- 0.123 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 784
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.594
SUFF++ for r=0.3 class 0.0 = 0.772 +- 0.215 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.3 class 1.0 = 0.801 +- 0.215 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.3 all KL = 0.819 +- 0.215 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.3 all L1 = 0.796 +- 0.205 (in-sample avg dev_std = 0.367)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0.0 = 0.816 +- 0.185 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.6 class 1.0 = 0.903 +- 0.185 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.6 all KL = 0.903 +- 0.185 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.6 all L1 = 0.888 +- 0.188 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.694
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0.0 = 0.903 +- 0.179 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1.0 = 0.942 +- 0.179 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.927 +- 0.179 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.144 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.643
NEC for r=0.3 class 0.0 = 0.24 +- 0.222 (in-sample avg dev_std = 0.353)
NEC for r=0.3 class 1.0 = 0.19 +- 0.222 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all KL = 0.184 +- 0.222 (in-sample avg dev_std = 0.353)
NEC for r=0.3 all L1 = 0.196 +- 0.192 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.76
NEC for r=0.6 class 0.0 = 0.217 +- 0.208 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 1.0 = 0.077 +- 0.208 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all KL = 0.11 +- 0.208 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all L1 = 0.093 +- 0.165 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.788
NEC for r=0.9 class 0.0 = 0.235 +- 0.216 (in-sample avg dev_std = 0.232)
NEC for r=0.9 class 1.0 = 0.05 +- 0.216 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all KL = 0.095 +- 0.216 (in-sample avg dev_std = 0.232)
NEC for r=0.9 all L1 = 0.072 +- 0.164 (in-sample avg dev_std = 0.232)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.833
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.798
NEC for r=1.0 class 0.0 = 0.282 +- 0.243 (in-sample avg dev_std = 0.249)
NEC for r=1.0 class 1.0 = 0.057 +- 0.243 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all KL = 0.108 +- 0.243 (in-sample avg dev_std = 0.249)
NEC for r=1.0 all L1 = 0.083 +- 0.183 (in-sample avg dev_std = 0.249)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.603
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.614
NEC for r=0.3 class 0.0 = 0.254 +- 0.250 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 1.0 = 0.224 +- 0.250 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all KL = 0.223 +- 0.250 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all L1 = 0.229 +- 0.208 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
NEC for r=0.6 class 0.0 = 0.214 +- 0.222 (in-sample avg dev_std = 0.304)
NEC for r=0.6 class 1.0 = 0.117 +- 0.222 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all KL = 0.144 +- 0.222 (in-sample avg dev_std = 0.304)
NEC for r=0.6 all L1 = 0.133 +- 0.189 (in-sample avg dev_std = 0.304)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.694
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0.0 = 0.211 +- 0.282 (in-sample avg dev_std = 0.315)
NEC for r=0.9 class 1.0 = 0.104 +- 0.282 (in-sample avg dev_std = 0.315)
NEC for r=0.9 all KL = 0.162 +- 0.282 (in-sample avg dev_std = 0.315)
NEC for r=0.9 all L1 = 0.122 +- 0.210 (in-sample avg dev_std = 0.315)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.687
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.692
NEC for r=1.0 class 0.0 = 0.191 +- 0.293 (in-sample avg dev_std = 0.318)
NEC for r=1.0 class 1.0 = 0.113 +- 0.293 (in-sample avg dev_std = 0.318)
NEC for r=1.0 all KL = 0.168 +- 0.293 (in-sample avg dev_std = 0.318)
NEC for r=1.0 all L1 = 0.126 +- 0.216 (in-sample avg dev_std = 0.318)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:12:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:12:34 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:14 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ROC-AUC: 0.9160
Train Loss: 0.2563
ID Validation ROC-AUC: 0.8983
ID Validation Loss: 0.2916
ID Test ROC-AUC: 0.8976
ID Test Loss: 0.2924
OOD Validation ROC-AUC: 0.6457
OOD Validation Loss: 0.5279
OOD Test ROC-AUC: 0.7031
OOD Test Loss: 0.6410

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ROC-AUC: 0.8843
Train Loss: 0.2917
ID Validation ROC-AUC: 0.8698
ID Validation Loss: 0.3179
ID Test ROC-AUC: 0.8731
ID Test Loss: 0.3116
OOD Validation ROC-AUC: 0.6741
OOD Validation Loss: 0.4275
OOD Test ROC-AUC: 0.6836
OOD Test Loss: 0.6310

[0m[1;37mINFO[0m: [1mChartInfo 0.8976 0.7031 0.8731 0.6836 0.8698 0.6741[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:13:56 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:14:00 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 793
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.615
SUFF++ for r=0.3 class 0.0 = 0.733 +- 0.275 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 class 1.0 = 0.651 +- 0.275 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all KL = 0.594 +- 0.275 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all L1 = 0.66 +- 0.202 (in-sample avg dev_std = 0.562)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.662
SUFF++ for r=0.6 class 0.0 = 0.723 +- 0.262 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 1.0 = 0.657 +- 0.262 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all KL = 0.65 +- 0.262 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all L1 = 0.665 +- 0.200 (in-sample avg dev_std = 0.490)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.731
SUFF++ for r=0.9 class 0.0 = 0.874 +- 0.192 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 class 1.0 = 0.781 +- 0.192 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 all KL = 0.836 +- 0.192 (in-sample avg dev_std = 0.324)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.179 (in-sample avg dev_std = 0.324)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.555
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 782
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.565
SUFF++ for r=0.3 class 0.0 = 0.737 +- 0.279 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.3 class 1.0 = 0.691 +- 0.279 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.3 all KL = 0.634 +- 0.279 (in-sample avg dev_std = 0.538)
SUFF++ for r=0.3 all L1 = 0.698 +- 0.204 (in-sample avg dev_std = 0.538)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.596
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.581
SUFF++ for r=0.6 class 0.0 = 0.707 +- 0.255 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 class 1.0 = 0.684 +- 0.255 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all KL = 0.677 +- 0.255 (in-sample avg dev_std = 0.466)
SUFF++ for r=0.6 all L1 = 0.688 +- 0.202 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.666
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.632
SUFF++ for r=0.9 class 0.0 = 0.854 +- 0.200 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 class 1.0 = 0.825 +- 0.200 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all KL = 0.85 +- 0.200 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.9 all L1 = 0.83 +- 0.170 (in-sample avg dev_std = 0.317)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.624
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.613
NEC for r=0.3 class 0.0 = 0.148 +- 0.216 (in-sample avg dev_std = 0.345)
NEC for r=0.3 class 1.0 = 0.2 +- 0.216 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all KL = 0.176 +- 0.216 (in-sample avg dev_std = 0.345)
NEC for r=0.3 all L1 = 0.194 +- 0.201 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.682
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.684
NEC for r=0.6 class 0.0 = 0.173 +- 0.221 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 1.0 = 0.257 +- 0.221 (in-sample avg dev_std = 0.389)
NEC for r=0.6 all KL = 0.221 +- 0.221 (in-sample avg dev_std = 0.389)
NEC for r=0.6 all L1 = 0.247 +- 0.189 (in-sample avg dev_std = 0.389)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.767
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.733
NEC for r=0.9 class 0.0 = 0.136 +- 0.203 (in-sample avg dev_std = 0.370)
NEC for r=0.9 class 1.0 = 0.264 +- 0.203 (in-sample avg dev_std = 0.370)
NEC for r=0.9 all KL = 0.207 +- 0.203 (in-sample avg dev_std = 0.370)
NEC for r=0.9 all L1 = 0.249 +- 0.188 (in-sample avg dev_std = 0.370)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.766
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.73
NEC for r=1.0 class 0.0 = 0.133 +- 0.203 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 1.0 = 0.249 +- 0.203 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all KL = 0.189 +- 0.203 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all L1 = 0.235 +- 0.185 (in-sample avg dev_std = 0.357)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.598
NEC for r=0.3 class 0.0 = 0.142 +- 0.226 (in-sample avg dev_std = 0.336)
NEC for r=0.3 class 1.0 = 0.189 +- 0.226 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all KL = 0.174 +- 0.226 (in-sample avg dev_std = 0.336)
NEC for r=0.3 all L1 = 0.181 +- 0.201 (in-sample avg dev_std = 0.336)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.596
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
NEC for r=0.6 class 0.0 = 0.206 +- 0.219 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 1.0 = 0.245 +- 0.219 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all KL = 0.21 +- 0.219 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all L1 = 0.239 +- 0.199 (in-sample avg dev_std = 0.374)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.666
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.651
NEC for r=0.9 class 0.0 = 0.159 +- 0.207 (in-sample avg dev_std = 0.357)
NEC for r=0.9 class 1.0 = 0.234 +- 0.207 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all KL = 0.195 +- 0.207 (in-sample avg dev_std = 0.357)
NEC for r=0.9 all L1 = 0.222 +- 0.188 (in-sample avg dev_std = 0.357)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.672
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.638
NEC for r=1.0 class 0.0 = 0.151 +- 0.205 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 1.0 = 0.217 +- 0.205 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all KL = 0.179 +- 0.205 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all L1 = 0.206 +- 0.185 (in-sample avg dev_std = 0.345)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:16:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:16:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:17:17 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:17:27 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:17:37 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:17:53 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ROC-AUC: 0.9203
Train Loss: 0.2616
ID Validation ROC-AUC: 0.8992
ID Validation Loss: 0.3023
ID Test ROC-AUC: 0.8991
ID Test Loss: 0.3012
OOD Validation ROC-AUC: 0.6438
OOD Validation Loss: 0.5717
OOD Test ROC-AUC: 0.7015
OOD Test Loss: 0.6695

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 19...
[0m[1;37mINFO[0m: [1mCheckpoint 19: 
-----------------------------------
Train ROC-AUC: 0.8698
Train Loss: 0.3086
ID Validation ROC-AUC: 0.8607
ID Validation Loss: 0.3199
ID Test ROC-AUC: 0.8667
ID Test Loss: 0.3140
OOD Validation ROC-AUC: 0.6746
OOD Validation Loss: 0.4525
OOD Test ROC-AUC: 0.6941
OOD Test Loss: 0.5667

[0m[1;37mINFO[0m: [1mChartInfo 0.8991 0.7015 0.8667 0.6941 0.8607 0.6746[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:18:08 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:18:12 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.635
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 791
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.643 +- 0.283 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 1.0 = 0.639 +- 0.283 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all KL = 0.601 +- 0.283 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all L1 = 0.639 +- 0.211 (in-sample avg dev_std = 0.559)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.666
SUFF++ for r=0.6 class 0.0 = 0.664 +- 0.300 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 class 1.0 = 0.666 +- 0.300 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all KL = 0.634 +- 0.300 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.6 all L1 = 0.666 +- 0.236 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.744
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.718
SUFF++ for r=0.9 class 0.0 = 0.802 +- 0.209 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.9 class 1.0 = 0.79 +- 0.209 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.9 all KL = 0.815 +- 0.209 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.188 (in-sample avg dev_std = 0.362)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.555
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 791
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.549
SUFF++ for r=0.3 class 0.0 = 0.622 +- 0.291 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 1.0 = 0.626 +- 0.291 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 all KL = 0.554 +- 0.291 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 all L1 = 0.626 +- 0.213 (in-sample avg dev_std = 0.595)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.591
SUFF++ for r=0.6 class 0.0 = 0.644 +- 0.297 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 1.0 = 0.665 +- 0.297 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all KL = 0.615 +- 0.297 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all L1 = 0.661 +- 0.228 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.658
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.641
SUFF++ for r=0.9 class 0.0 = 0.842 +- 0.236 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.9 class 1.0 = 0.786 +- 0.236 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.9 all KL = 0.803 +- 0.236 (in-sample avg dev_std = 0.373)
SUFF++ for r=0.9 all L1 = 0.795 +- 0.195 (in-sample avg dev_std = 0.373)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.629
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.623
NEC for r=0.3 class 0.0 = 0.274 +- 0.264 (in-sample avg dev_std = 0.434)
NEC for r=0.3 class 1.0 = 0.29 +- 0.264 (in-sample avg dev_std = 0.434)
NEC for r=0.3 all KL = 0.28 +- 0.264 (in-sample avg dev_std = 0.434)
NEC for r=0.3 all L1 = 0.288 +- 0.218 (in-sample avg dev_std = 0.434)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.74
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.709
NEC for r=0.6 class 0.0 = 0.25 +- 0.278 (in-sample avg dev_std = 0.445)
NEC for r=0.6 class 1.0 = 0.287 +- 0.278 (in-sample avg dev_std = 0.445)
NEC for r=0.6 all KL = 0.292 +- 0.278 (in-sample avg dev_std = 0.445)
NEC for r=0.6 all L1 = 0.283 +- 0.219 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.744
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.732
NEC for r=0.9 class 0.0 = 0.222 +- 0.246 (in-sample avg dev_std = 0.407)
NEC for r=0.9 class 1.0 = 0.28 +- 0.246 (in-sample avg dev_std = 0.407)
NEC for r=0.9 all KL = 0.257 +- 0.246 (in-sample avg dev_std = 0.407)
NEC for r=0.9 all L1 = 0.273 +- 0.213 (in-sample avg dev_std = 0.407)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.741
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.72
NEC for r=1.0 class 0.0 = 0.214 +- 0.223 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1.0 = 0.264 +- 0.223 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.226 +- 0.223 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.258 +- 0.197 (in-sample avg dev_std = 0.397)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.551
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
NEC for r=0.3 class 0.0 = 0.257 +- 0.272 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 1.0 = 0.257 +- 0.272 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all KL = 0.265 +- 0.272 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all L1 = 0.257 +- 0.220 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.634
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.62
NEC for r=0.6 class 0.0 = 0.23 +- 0.265 (in-sample avg dev_std = 0.435)
NEC for r=0.6 class 1.0 = 0.28 +- 0.265 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all KL = 0.28 +- 0.265 (in-sample avg dev_std = 0.435)
NEC for r=0.6 all L1 = 0.271 +- 0.214 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.658
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.653
NEC for r=0.9 class 0.0 = 0.22 +- 0.242 (in-sample avg dev_std = 0.415)
NEC for r=0.9 class 1.0 = 0.274 +- 0.242 (in-sample avg dev_std = 0.415)
NEC for r=0.9 all KL = 0.257 +- 0.242 (in-sample avg dev_std = 0.415)
NEC for r=0.9 all L1 = 0.265 +- 0.210 (in-sample avg dev_std = 0.415)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.648
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.643
NEC for r=1.0 class 0.0 = 0.215 +- 0.247 (in-sample avg dev_std = 0.403)
NEC for r=1.0 class 1.0 = 0.256 +- 0.247 (in-sample avg dev_std = 0.403)
NEC for r=1.0 all KL = 0.236 +- 0.247 (in-sample avg dev_std = 0.403)
NEC for r=1.0 all L1 = 0.249 +- 0.203 (in-sample avg dev_std = 0.403)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:20:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/29/2024 03:20:59 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/29/2024 03:21:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/29/2024 03:21:39 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/29/2024 03:21:49 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ROC-AUC: 0.9212
Train Loss: 0.2580
ID Validation ROC-AUC: 0.9021
ID Validation Loss: 0.2945
ID Test ROC-AUC: 0.9029
ID Test Loss: 0.2921
OOD Validation ROC-AUC: 0.6499
OOD Validation Loss: 0.5617
OOD Test ROC-AUC: 0.7014
OOD Test Loss: 0.6597

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ROC-AUC: 0.8981
Train Loss: 0.2656
ID Validation ROC-AUC: 0.8784
ID Validation Loss: 0.3013
ID Test ROC-AUC: 0.8854
ID Test Loss: 0.2911
OOD Validation ROC-AUC: 0.6706
OOD Validation Loss: 0.3957
OOD Test ROC-AUC: 0.6942
OOD Test Loss: 0.5938

[0m[1;37mINFO[0m: [1mChartInfo 0.9029 0.7014 0.8854 0.6942 0.8784 0.6706[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/29/2024 03:22:20 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/29/2024 03:22:24 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 782
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.598
SUFF++ for r=0.3 class 0.0 = 0.717 +- 0.232 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 class 1.0 = 0.691 +- 0.232 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all KL = 0.699 +- 0.232 (in-sample avg dev_std = 0.485)
SUFF++ for r=0.3 all L1 = 0.694 +- 0.192 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.668
SUFF++ for r=0.6 class 0.0 = 0.762 +- 0.213 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 1.0 = 0.712 +- 0.213 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all KL = 0.77 +- 0.213 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all L1 = 0.718 +- 0.196 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.657
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.637
SUFF++ for r=0.9 class 0.0 = 0.912 +- 0.106 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 1.0 = 0.896 +- 0.106 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all KL = 0.941 +- 0.106 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all L1 = 0.898 +- 0.114 (in-sample avg dev_std = 0.228)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.582
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
SUFF++ for r=0.3 class 0.0 = 0.743 +- 0.244 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 class 1.0 = 0.708 +- 0.244 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all KL = 0.693 +- 0.244 (in-sample avg dev_std = 0.499)
SUFF++ for r=0.3 all L1 = 0.714 +- 0.186 (in-sample avg dev_std = 0.499)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.597
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.587
SUFF++ for r=0.6 class 0.0 = 0.754 +- 0.214 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 class 1.0 = 0.721 +- 0.214 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all KL = 0.765 +- 0.214 (in-sample avg dev_std = 0.383)
SUFF++ for r=0.6 all L1 = 0.726 +- 0.191 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.614
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0.0 = 0.907 +- 0.130 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1.0 = 0.891 +- 0.130 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.927 +- 0.130 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.894 +- 0.122 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.646
NEC for r=0.3 class 0.0 = 0.169 +- 0.196 (in-sample avg dev_std = 0.329)
NEC for r=0.3 class 1.0 = 0.21 +- 0.196 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all KL = 0.159 +- 0.196 (in-sample avg dev_std = 0.329)
NEC for r=0.3 all L1 = 0.205 +- 0.185 (in-sample avg dev_std = 0.329)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.678
NEC for r=0.6 class 0.0 = 0.144 +- 0.176 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 1.0 = 0.228 +- 0.176 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all KL = 0.157 +- 0.176 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all L1 = 0.218 +- 0.169 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.657
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.658
NEC for r=0.9 class 0.0 = 0.17 +- 0.176 (in-sample avg dev_std = 0.339)
NEC for r=0.9 class 1.0 = 0.235 +- 0.176 (in-sample avg dev_std = 0.339)
NEC for r=0.9 all KL = 0.165 +- 0.176 (in-sample avg dev_std = 0.339)
NEC for r=0.9 all L1 = 0.228 +- 0.177 (in-sample avg dev_std = 0.339)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.644
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.647
NEC for r=1.0 class 0.0 = 0.144 +- 0.177 (in-sample avg dev_std = 0.330)
NEC for r=1.0 class 1.0 = 0.22 +- 0.177 (in-sample avg dev_std = 0.330)
NEC for r=1.0 all KL = 0.152 +- 0.177 (in-sample avg dev_std = 0.330)
NEC for r=1.0 all L1 = 0.211 +- 0.175 (in-sample avg dev_std = 0.330)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.584
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.57
NEC for r=0.3 class 0.0 = 0.16 +- 0.203 (in-sample avg dev_std = 0.309)
NEC for r=0.3 class 1.0 = 0.195 +- 0.203 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all KL = 0.153 +- 0.203 (in-sample avg dev_std = 0.309)
NEC for r=0.3 all L1 = 0.189 +- 0.190 (in-sample avg dev_std = 0.309)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.597
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.605
NEC for r=0.6 class 0.0 = 0.177 +- 0.180 (in-sample avg dev_std = 0.340)
NEC for r=0.6 class 1.0 = 0.218 +- 0.180 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all KL = 0.16 +- 0.180 (in-sample avg dev_std = 0.340)
NEC for r=0.6 all L1 = 0.211 +- 0.172 (in-sample avg dev_std = 0.340)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.614
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.605
NEC for r=0.9 class 0.0 = 0.164 +- 0.191 (in-sample avg dev_std = 0.334)
NEC for r=0.9 class 1.0 = 0.222 +- 0.191 (in-sample avg dev_std = 0.334)
NEC for r=0.9 all KL = 0.165 +- 0.191 (in-sample avg dev_std = 0.334)
NEC for r=0.9 all L1 = 0.212 +- 0.179 (in-sample avg dev_std = 0.334)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.595
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.594
NEC for r=1.0 class 0.0 = 0.149 +- 0.179 (in-sample avg dev_std = 0.323)
NEC for r=1.0 class 1.0 = 0.21 +- 0.179 (in-sample avg dev_std = 0.323)
NEC for r=1.0 all KL = 0.151 +- 0.179 (in-sample avg dev_std = 0.323)
NEC for r=1.0 all L1 = 0.199 +- 0.179 (in-sample avg dev_std = 0.323)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.835, 0.893, 0.949, 1.0], 'all_L1': [0.801, 0.875, 0.939, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.839, 0.923, 0.954, 1.0], 'all_L1': [0.814, 0.92, 0.957, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.594, 0.65, 0.836, 1.0], 'all_L1': [0.66, 0.665, 0.792, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.601, 0.634, 0.815, 1.0], 'all_L1': [0.639, 0.666, 0.792, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.699, 0.77, 0.941, 1.0], 'all_L1': [0.694, 0.718, 0.898, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.155, 0.129, 0.096, 0.09], 'all_L1': [0.183, 0.132, 0.094, 0.087]}), defaultdict(<class 'list'>, {'all_KL': [0.184, 0.11, 0.095, 0.108], 'all_L1': [0.196, 0.093, 0.072, 0.083]}), defaultdict(<class 'list'>, {'all_KL': [0.176, 0.221, 0.207, 0.189], 'all_L1': [0.194, 0.247, 0.249, 0.235]}), defaultdict(<class 'list'>, {'all_KL': [0.28, 0.292, 0.257, 0.226], 'all_L1': [0.288, 0.283, 0.273, 0.258]}), defaultdict(<class 'list'>, {'all_KL': [0.159, 0.157, 0.165, 0.152], 'all_L1': [0.205, 0.218, 0.228, 0.211]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.803, 0.869, 0.925, 1.0], 'all_L1': [0.769, 0.839, 0.913, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.819, 0.903, 0.927, 1.0], 'all_L1': [0.796, 0.888, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.634, 0.677, 0.85, 1.0], 'all_L1': [0.698, 0.688, 0.83, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.554, 0.615, 0.803, 1.0], 'all_L1': [0.626, 0.661, 0.795, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.693, 0.765, 0.927, 1.0], 'all_L1': [0.714, 0.726, 0.894, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.19, 0.171, 0.149, 0.136], 'all_L1': [0.221, 0.18, 0.143, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.223, 0.144, 0.162, 0.168], 'all_L1': [0.229, 0.133, 0.122, 0.126]}), defaultdict(<class 'list'>, {'all_KL': [0.174, 0.21, 0.195, 0.179], 'all_L1': [0.181, 0.239, 0.222, 0.206]}), defaultdict(<class 'list'>, {'all_KL': [0.265, 0.28, 0.257, 0.236], 'all_L1': [0.257, 0.271, 0.265, 0.249]}), defaultdict(<class 'list'>, {'all_KL': [0.153, 0.16, 0.165, 0.151], 'all_L1': [0.189, 0.211, 0.212, 0.199]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.722 +- 0.072, 0.769 +- 0.108, 0.876 +- 0.071, 1.000 +- 0.000
suff++ class all_KL  =  0.714 +- 0.107, 0.774 +- 0.119, 0.899 +- 0.061, 1.000 +- 0.000
suff++_acc_int  =  0.623 +- 0.026, 0.695 +- 0.036, 0.734 +- 0.058
nec class all_L1  =  0.213 +- 0.038, 0.195 +- 0.071, 0.183 +- 0.083, 0.175 +- 0.075
nec class all_KL  =  0.191 +- 0.046, 0.182 +- 0.067, 0.164 +- 0.063, 0.153 +- 0.050
nec_acc_int  =  0.640 +- 0.022, 0.715 +- 0.032, 0.737 +- 0.046, 0.738 +- 0.055

Eval split test
suff++ class all_L1  =  0.721 +- 0.059, 0.760 +- 0.088, 0.873 +- 0.053, 1.000 +- 0.000
suff++ class all_KL  =  0.701 +- 0.100, 0.766 +- 0.110, 0.886 +- 0.051, 1.000 +- 0.000
suff++_acc_int  =  0.575 +- 0.023, 0.612 +- 0.031, 0.646 +- 0.030
nec class all_L1  =  0.215 +- 0.028, 0.207 +- 0.048, 0.193 +- 0.053, 0.182 +- 0.048
nec class all_KL  =  0.201 +- 0.039, 0.193 +- 0.049, 0.186 +- 0.039, 0.174 +- 0.034
nec_acc_int  =  0.599 +- 0.021, 0.629 +- 0.019, 0.651 +- 0.027, 0.649 +- 0.034


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.467 +- 0.028, 0.482 +- 0.020, 0.529 +- 0.018, 0.587 +- 0.037
Faith. Armon (L1)= 		  =  0.325 +- 0.037, 0.298 +- 0.085, 0.291 +- 0.114, 0.291 +- 0.111
Faith. GMean (L1)= 	  =  0.389 +- 0.024, 0.373 +- 0.051, 0.384 +- 0.086, 0.407 +- 0.096
Faith. Aritm (KL)= 		  =  0.452 +- 0.046, 0.478 +- 0.031, 0.531 +- 0.012, 0.576 +- 0.025
Faith. Armon (KL)= 		  =  0.295 +- 0.046, 0.283 +- 0.074, 0.270 +- 0.086, 0.262 +- 0.075
Faith. GMean (KL)= 	  =  0.364 +- 0.033, 0.363 +- 0.039, 0.374 +- 0.063, 0.386 +- 0.065

Eval split test
Faith. Aritm (L1)= 		  =  0.468 +- 0.030, 0.484 +- 0.022, 0.533 +- 0.010, 0.591 +- 0.024
Faith. Armon (L1)= 		  =  0.330 +- 0.031, 0.319 +- 0.053, 0.311 +- 0.068, 0.305 +- 0.069
Faith. GMean (L1)= 	  =  0.393 +- 0.027, 0.390 +- 0.026, 0.405 +- 0.047, 0.422 +- 0.057
Faith. Aritm (KL)= 		  =  0.451 +- 0.048, 0.479 +- 0.035, 0.536 +- 0.009, 0.587 +- 0.017
Faith. Armon (KL)= 		  =  0.308 +- 0.042, 0.301 +- 0.048, 0.304 +- 0.047, 0.295 +- 0.049
Faith. GMean (KL)= 	  =  0.372 +- 0.038, 0.378 +- 0.022, 0.402 +- 0.028, 0.415 +- 0.040
Computed for split load_split = id



Completed in  0:20:57.963157  for GSATGIN LBAPcore/assay



DONE GSAT LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:25:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:25:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9989
Train Loss: 0.0081
ID Validation ACCURACY: 0.8799
ID Validation Loss: 0.4755
ID Test ACCURACY: 0.8819
ID Test Loss: 0.4854
OOD Validation ACCURACY: 0.8617
OOD Validation Loss: 0.5669
OOD Test ACCURACY: 0.7476
OOD Test Loss: 1.1971

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 81...
[0m[1;37mINFO[0m: [1mCheckpoint 81: 
-----------------------------------
Train ACCURACY: 0.9611
Train Loss: 0.1229
ID Validation ACCURACY: 0.8749
ID Validation Loss: 0.4002
ID Test ACCURACY: 0.8791
ID Test Loss: 0.3989
OOD Validation ACCURACY: 0.8756
OOD Validation Loss: 0.4110
OOD Test ACCURACY: 0.7587
OOD Test Loss: 0.8224

[0m[1;37mINFO[0m: [1mChartInfo 0.8819 0.7476 0.8791 0.7587 0.8749 0.8756[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.783 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 1 = 0.71 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 2 = 0.729 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 3 = 0.783 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 4 = 0.767 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 5 = 0.782 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 6 = 0.754 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 7 = 0.794 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 8 = 0.87 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 class 9 = 0.772 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 all KL = 0.855 +- 0.176 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.3 all L1 = 0.773 +- 0.222 (in-sample avg dev_std = 0.174)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
SUFF++ for r=0.6 class 0 = 0.445 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 1 = 0.485 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 2 = 0.486 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 3 = 0.501 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 4 = 0.514 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 5 = 0.514 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 6 = 0.491 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 7 = 0.469 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 8 = 0.535 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 class 9 = 0.445 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 all KL = 0.476 +- 0.320 (in-sample avg dev_std = 0.197)
SUFF++ for r=0.6 all L1 = 0.488 +- 0.243 (in-sample avg dev_std = 0.197)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.775
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.717
SUFF++ for r=0.9 class 0 = 0.933 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 1 = 0.904 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 2 = 0.748 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 3 = 0.707 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 4 = 0.789 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 5 = 0.692 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 6 = 0.724 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 7 = 0.764 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 8 = 0.822 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 class 9 = 0.719 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all KL = 0.776 +- 0.289 (in-sample avg dev_std = 0.315)
SUFF++ for r=0.9 all L1 = 0.783 +- 0.238 (in-sample avg dev_std = 0.315)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
SUFF++ for r=0.3 class 0 = 0.867 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 1 = 0.844 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 2 = 0.872 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 3 = 0.885 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 4 = 0.812 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 5 = 0.851 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 6 = 0.842 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 7 = 0.86 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 8 = 0.875 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 class 9 = 0.842 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 all KL = 0.919 +- 0.126 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.3 all L1 = 0.855 +- 0.179 (in-sample avg dev_std = 0.125)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.196
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
SUFF++ for r=0.6 class 0 = 0.434 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 1 = 0.515 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 2 = 0.443 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 3 = 0.448 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 4 = 0.463 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 5 = 0.39 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 6 = 0.502 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 7 = 0.517 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 8 = 0.423 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 9 = 0.486 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all KL = 0.444 +- 0.307 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all L1 = 0.463 +- 0.235 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.597
SUFF++ for r=0.9 class 0 = 0.812 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 1 = 0.829 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 2 = 0.708 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 3 = 0.65 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 4 = 0.719 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 5 = 0.672 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 6 = 0.745 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 7 = 0.775 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 8 = 0.72 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 class 9 = 0.64 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 all KL = 0.748 +- 0.265 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.9 all L1 = 0.729 +- 0.234 (in-sample avg dev_std = 0.311)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.225 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 1 = 0.291 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 2 = 0.272 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 3 = 0.225 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 4 = 0.25 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 5 = 0.223 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 6 = 0.261 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 7 = 0.217 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 8 = 0.142 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 class 9 = 0.235 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all KL = 0.155 +- 0.192 (in-sample avg dev_std = 0.151)
NEC for r=0.3 all L1 = 0.235 +- 0.227 (in-sample avg dev_std = 0.151)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
NEC for r=0.6 class 0 = 0.573 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 1 = 0.525 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 2 = 0.536 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 3 = 0.523 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 4 = 0.499 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 5 = 0.491 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 6 = 0.514 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 7 = 0.547 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 8 = 0.477 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 class 9 = 0.567 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 all KL = 0.578 +- 0.277 (in-sample avg dev_std = 0.405)
NEC for r=0.6 all L1 = 0.526 +- 0.202 (in-sample avg dev_std = 0.405)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.775
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.54
NEC for r=0.9 class 0 = 0.218 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 1 = 0.268 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 2 = 0.559 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 3 = 0.561 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 4 = 0.459 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 5 = 0.647 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 6 = 0.556 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 7 = 0.463 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 8 = 0.339 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 class 9 = 0.589 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all KL = 0.663 +- 0.342 (in-sample avg dev_std = 0.504)
NEC for r=0.9 all L1 = 0.461 +- 0.281 (in-sample avg dev_std = 0.504)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.796
NEC for r=1.0 class 0 = 0.089 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 1 = 0.054 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 2 = 0.319 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 3 = 0.391 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 4 = 0.241 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 5 = 0.421 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 6 = 0.399 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 7 = 0.268 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 8 = 0.204 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 class 9 = 0.408 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 all KL = 0.476 +- 0.387 (in-sample avg dev_std = 0.451)
NEC for r=1.0 all L1 = 0.275 +- 0.275 (in-sample avg dev_std = 0.451)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.109
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.13 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1 = 0.159 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 2 = 0.137 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 3 = 0.119 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 4 = 0.201 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 5 = 0.153 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 6 = 0.156 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 7 = 0.151 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 8 = 0.132 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 9 = 0.163 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.087 +- 0.144 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.15 +- 0.189 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.196
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.168
NEC for r=0.6 class 0 = 0.571 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 1 = 0.51 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 2 = 0.574 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 3 = 0.587 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 4 = 0.551 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 5 = 0.593 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 6 = 0.562 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 7 = 0.5 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 8 = 0.568 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 9 = 0.562 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 all KL = 0.627 +- 0.249 (in-sample avg dev_std = 0.438)
NEC for r=0.6 all L1 = 0.557 +- 0.181 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.674
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.423
NEC for r=0.9 class 0 = 0.518 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 1 = 0.419 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 2 = 0.531 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 3 = 0.592 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 4 = 0.533 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 5 = 0.675 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 6 = 0.605 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 7 = 0.384 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 8 = 0.523 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 9 = 0.632 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all KL = 0.708 +- 0.282 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all L1 = 0.537 +- 0.241 (in-sample avg dev_std = 0.509)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.777
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.639
NEC for r=1.0 class 0 = 0.381 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 1 = 0.1 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 2 = 0.484 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 3 = 0.485 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 4 = 0.339 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 5 = 0.526 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 6 = 0.545 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 7 = 0.276 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 8 = 0.464 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 class 9 = 0.517 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 all KL = 0.594 +- 0.351 (in-sample avg dev_std = 0.500)
NEC for r=1.0 all L1 = 0.407 +- 0.279 (in-sample avg dev_std = 0.500)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:38:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:16 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:38:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ACCURACY: 0.9985
Train Loss: 0.0098
ID Validation ACCURACY: 0.8837
ID Validation Loss: 0.5031
ID Test ACCURACY: 0.8831
ID Test Loss: 0.4930
OOD Validation ACCURACY: 0.8623
OOD Validation Loss: 0.5645
OOD Test ACCURACY: 0.6190
OOD Test Loss: 2.3743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.9724
Train Loss: 0.0901
ID Validation ACCURACY: 0.8793
ID Validation Loss: 0.4008
ID Test ACCURACY: 0.8846
ID Test Loss: 0.3936
OOD Validation ACCURACY: 0.8716
OOD Validation Loss: 0.4173
OOD Test ACCURACY: 0.7290
OOD Test Loss: 0.9761

[0m[1;37mINFO[0m: [1mChartInfo 0.8831 0.6190 0.8846 0.7290 0.8793 0.8716[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
SUFF++ for r=0.3 class 0 = 0.652 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 1 = 0.639 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 2 = 0.646 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 3 = 0.653 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 4 = 0.627 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 5 = 0.636 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 6 = 0.646 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 7 = 0.642 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 8 = 0.694 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 class 9 = 0.655 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 all KL = 0.775 +- 0.197 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.3 all L1 = 0.649 +- 0.184 (in-sample avg dev_std = 0.229)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.137
SUFF++ for r=0.6 class 0 = 0.417 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 1 = 0.404 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 2 = 0.439 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 3 = 0.493 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 4 = 0.453 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 5 = 0.477 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 6 = 0.465 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 7 = 0.407 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 8 = 0.507 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 9 = 0.424 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all KL = 0.404 +- 0.323 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all L1 = 0.447 +- 0.241 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.719
SUFF++ for r=0.9 class 0 = 0.927 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 1 = 0.85 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 2 = 0.754 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 3 = 0.692 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 4 = 0.742 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 5 = 0.676 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 6 = 0.712 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 7 = 0.766 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 8 = 0.789 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 class 9 = 0.769 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all KL = 0.753 +- 0.295 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.9 all L1 = 0.77 +- 0.234 (in-sample avg dev_std = 0.334)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.129
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.139
SUFF++ for r=0.3 class 0 = 0.717 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 1 = 0.695 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 2 = 0.751 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 3 = 0.745 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 4 = 0.693 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 5 = 0.698 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 6 = 0.735 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 7 = 0.702 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 8 = 0.728 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 class 9 = 0.729 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 all KL = 0.864 +- 0.143 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.3 all L1 = 0.719 +- 0.151 (in-sample avg dev_std = 0.161)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.141
SUFF++ for r=0.6 class 0 = 0.436 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 1 = 0.437 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 2 = 0.448 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 3 = 0.483 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 4 = 0.444 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 5 = 0.441 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 6 = 0.449 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 7 = 0.484 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 8 = 0.46 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 9 = 0.443 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all KL = 0.444 +- 0.317 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all L1 = 0.452 +- 0.232 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.553
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.523
SUFF++ for r=0.9 class 0 = 0.743 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 1 = 0.838 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 2 = 0.671 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 3 = 0.712 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 4 = 0.72 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 5 = 0.635 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 6 = 0.676 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 7 = 0.762 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 8 = 0.692 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 class 9 = 0.682 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 all KL = 0.742 +- 0.268 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.9 all L1 = 0.715 +- 0.235 (in-sample avg dev_std = 0.320)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
NEC for r=0.3 class 0 = 0.394 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 1 = 0.439 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 2 = 0.424 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 3 = 0.439 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 4 = 0.459 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 5 = 0.428 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 6 = 0.466 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 7 = 0.434 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 8 = 0.371 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 9 = 0.414 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all KL = 0.338 +- 0.254 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all L1 = 0.427 +- 0.195 (in-sample avg dev_std = 0.301)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.124
NEC for r=0.6 class 0 = 0.607 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 1 = 0.582 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 2 = 0.589 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 3 = 0.551 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 4 = 0.548 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 5 = 0.601 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 6 = 0.527 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 7 = 0.567 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 8 = 0.569 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 class 9 = 0.595 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 all KL = 0.674 +- 0.245 (in-sample avg dev_std = 0.480)
NEC for r=0.6 all L1 = 0.573 +- 0.180 (in-sample avg dev_std = 0.480)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.312 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 1 = 0.459 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 2 = 0.496 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 3 = 0.588 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 4 = 0.504 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 5 = 0.602 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 6 = 0.567 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 7 = 0.466 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 8 = 0.433 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 9 = 0.549 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 all KL = 0.718 +- 0.298 (in-sample avg dev_std = 0.536)
NEC for r=0.9 all L1 = 0.496 +- 0.260 (in-sample avg dev_std = 0.536)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0 = 0.099 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 1 = 0.102 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 2 = 0.298 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 3 = 0.366 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 4 = 0.228 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 5 = 0.429 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 6 = 0.382 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 7 = 0.248 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 8 = 0.22 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 class 9 = 0.358 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 all KL = 0.468 +- 0.380 (in-sample avg dev_std = 0.461)
NEC for r=1.0 all L1 = 0.268 +- 0.266 (in-sample avg dev_std = 0.461)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.129
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.139
NEC for r=0.3 class 0 = 0.319 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 1 = 0.388 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 2 = 0.326 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 3 = 0.317 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 4 = 0.399 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 5 = 0.351 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 6 = 0.337 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 7 = 0.354 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 8 = 0.351 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 class 9 = 0.343 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all KL = 0.218 +- 0.205 (in-sample avg dev_std = 0.199)
NEC for r=0.3 all L1 = 0.348 +- 0.179 (in-sample avg dev_std = 0.199)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.156
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.15
NEC for r=0.6 class 0 = 0.58 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 1 = 0.56 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 2 = 0.583 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 3 = 0.568 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 4 = 0.579 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 5 = 0.589 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 6 = 0.561 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 7 = 0.535 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 8 = 0.508 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 9 = 0.583 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all KL = 0.625 +- 0.240 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all L1 = 0.564 +- 0.174 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.553
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.411
NEC for r=0.9 class 0 = 0.615 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 1 = 0.386 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 2 = 0.569 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 3 = 0.528 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 4 = 0.527 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 5 = 0.59 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 6 = 0.636 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 7 = 0.475 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 8 = 0.613 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 class 9 = 0.615 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all KL = 0.706 +- 0.272 (in-sample avg dev_std = 0.472)
NEC for r=0.9 all L1 = 0.553 +- 0.234 (in-sample avg dev_std = 0.472)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.626
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.558
NEC for r=1.0 class 0 = 0.479 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 1 = 0.205 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 2 = 0.563 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 3 = 0.433 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 4 = 0.447 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 5 = 0.53 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 6 = 0.529 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 7 = 0.366 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 8 = 0.47 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 9 = 0.579 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all KL = 0.616 +- 0.333 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all L1 = 0.457 +- 0.273 (in-sample avg dev_std = 0.478)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 15:51:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 03:51:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.9771
Train Loss: 0.0788
ID Validation ACCURACY: 0.8796
ID Validation Loss: 0.4118
ID Test ACCURACY: 0.8799
ID Test Loss: 0.4099
OOD Validation ACCURACY: 0.8694
OOD Validation Loss: 0.4406
OOD Test ACCURACY: 0.7794
OOD Test Loss: 0.8262

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 151...
[0m[1;37mINFO[0m: [1mCheckpoint 151: 
-----------------------------------
Train ACCURACY: 0.9966
Train Loss: 0.0192
ID Validation ACCURACY: 0.8714
ID Validation Loss: 0.4738
ID Test ACCURACY: 0.8740
ID Test Loss: 0.4719
OOD Validation ACCURACY: 0.8739
OOD Validation Loss: 0.4821
OOD Test ACCURACY: 0.8027
OOD Test Loss: 0.8199

[0m[1;37mINFO[0m: [1mChartInfo 0.8799 0.7794 0.8740 0.8027 0.8714 0.8739[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
SUFF++ for r=0.3 class 0 = 0.829 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 1 = 0.787 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 2 = 0.786 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 3 = 0.831 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 4 = 0.805 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 5 = 0.806 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 6 = 0.781 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 7 = 0.832 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 8 = 0.878 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 class 9 = 0.792 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 all KL = 0.895 +- 0.144 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.3 all L1 = 0.813 +- 0.189 (in-sample avg dev_std = 0.147)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.14
SUFF++ for r=0.6 class 0 = 0.443 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 1 = 0.468 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 2 = 0.487 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 3 = 0.553 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 4 = 0.513 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 5 = 0.524 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 6 = 0.539 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 7 = 0.489 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 8 = 0.583 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 class 9 = 0.521 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all KL = 0.594 +- 0.250 (in-sample avg dev_std = 0.149)
SUFF++ for r=0.6 all L1 = 0.511 +- 0.182 (in-sample avg dev_std = 0.149)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.775
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.729
SUFF++ for r=0.9 class 0 = 0.944 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1 = 0.928 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 2 = 0.751 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 3 = 0.725 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 4 = 0.782 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 5 = 0.709 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 6 = 0.788 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 7 = 0.78 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 8 = 0.804 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 9 = 0.751 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.837 +- 0.213 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.199 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
SUFF++ for r=0.3 class 0 = 0.875 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 1 = 0.859 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 2 = 0.858 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 3 = 0.868 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 4 = 0.821 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 5 = 0.874 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 6 = 0.846 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 7 = 0.87 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 8 = 0.867 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 class 9 = 0.844 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 all KL = 0.926 +- 0.110 (in-sample avg dev_std = 0.119)
SUFF++ for r=0.3 all L1 = 0.858 +- 0.165 (in-sample avg dev_std = 0.119)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.211
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
SUFF++ for r=0.6 class 0 = 0.494 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 1 = 0.523 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 2 = 0.54 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 3 = 0.503 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 4 = 0.504 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 5 = 0.515 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 6 = 0.496 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 7 = 0.524 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 8 = 0.501 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 class 9 = 0.485 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 all KL = 0.591 +- 0.243 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.6 all L1 = 0.509 +- 0.172 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.665
SUFF++ for r=0.9 class 0 = 0.832 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 1 = 0.965 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 2 = 0.741 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 3 = 0.72 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 4 = 0.752 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 5 = 0.684 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 6 = 0.718 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 7 = 0.835 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 8 = 0.759 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 class 9 = 0.688 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all KL = 0.831 +- 0.207 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.9 all L1 = 0.773 +- 0.205 (in-sample avg dev_std = 0.248)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.19 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 1 = 0.206 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 2 = 0.219 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 3 = 0.172 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 4 = 0.191 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 5 = 0.199 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 6 = 0.229 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 7 = 0.182 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 8 = 0.127 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 class 9 = 0.205 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 all KL = 0.107 +- 0.159 (in-sample avg dev_std = 0.111)
NEC for r=0.3 all L1 = 0.192 +- 0.200 (in-sample avg dev_std = 0.111)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.18
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
NEC for r=0.6 class 0 = 0.564 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 1 = 0.533 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 2 = 0.504 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 3 = 0.51 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 4 = 0.506 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 5 = 0.483 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 6 = 0.487 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 7 = 0.534 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 8 = 0.449 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 9 = 0.528 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all KL = 0.459 +- 0.206 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all L1 = 0.511 +- 0.142 (in-sample avg dev_std = 0.326)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.775
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.587
NEC for r=0.9 class 0 = 0.253 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 1 = 0.21 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 2 = 0.527 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 3 = 0.515 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 4 = 0.467 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 5 = 0.595 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 6 = 0.471 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 7 = 0.445 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 8 = 0.402 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 class 9 = 0.526 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all KL = 0.56 +- 0.296 (in-sample avg dev_std = 0.432)
NEC for r=0.9 all L1 = 0.436 +- 0.243 (in-sample avg dev_std = 0.432)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.939
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0 = 0.117 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 1 = 0.039 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 2 = 0.325 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 3 = 0.339 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 4 = 0.28 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 5 = 0.417 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 6 = 0.325 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 7 = 0.295 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 8 = 0.277 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 class 9 = 0.378 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all KL = 0.388 +- 0.318 (in-sample avg dev_std = 0.393)
NEC for r=1.0 all L1 = 0.274 +- 0.245 (in-sample avg dev_std = 0.393)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.115
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.126 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 1 = 0.141 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 2 = 0.144 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 3 = 0.135 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 4 = 0.183 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 5 = 0.123 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 6 = 0.156 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 7 = 0.126 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 8 = 0.135 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 class 9 = 0.163 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 all KL = 0.075 +- 0.128 (in-sample avg dev_std = 0.082)
NEC for r=0.3 all L1 = 0.143 +- 0.178 (in-sample avg dev_std = 0.082)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.211
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.168
NEC for r=0.6 class 0 = 0.544 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 1 = 0.456 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 2 = 0.509 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 3 = 0.519 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 4 = 0.504 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 5 = 0.522 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 6 = 0.511 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 7 = 0.485 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 8 = 0.487 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 class 9 = 0.506 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 all KL = 0.433 +- 0.190 (in-sample avg dev_std = 0.325)
NEC for r=0.6 all L1 = 0.503 +- 0.129 (in-sample avg dev_std = 0.325)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.701
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.501
NEC for r=0.9 class 0 = 0.556 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1 = 0.113 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 2 = 0.522 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 3 = 0.608 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 4 = 0.455 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 5 = 0.619 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 6 = 0.533 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 7 = 0.384 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 8 = 0.5 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 9 = 0.608 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.578 +- 0.286 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.484 +- 0.240 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.801
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.683
NEC for r=1.0 class 0 = 0.429 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 1 = 0.043 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 2 = 0.412 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 3 = 0.446 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 4 = 0.345 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 5 = 0.434 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 6 = 0.51 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 7 = 0.226 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 8 = 0.442 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 class 9 = 0.479 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 all KL = 0.495 +- 0.326 (in-sample avg dev_std = 0.439)
NEC for r=1.0 all L1 = 0.372 +- 0.257 (in-sample avg dev_std = 0.439)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:04:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:17 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:04:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 169...
[0m[1;37mINFO[0m: [1mCheckpoint 169: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0075
ID Validation ACCURACY: 0.8839
ID Validation Loss: 0.4781
ID Test ACCURACY: 0.8827
ID Test Loss: 0.5041
OOD Validation ACCURACY: 0.8734
OOD Validation Loss: 0.5221
OOD Test ACCURACY: 0.7557
OOD Test Loss: 1.1829

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.9862
Train Loss: 0.0531
ID Validation ACCURACY: 0.8741
ID Validation Loss: 0.4244
ID Test ACCURACY: 0.8776
ID Test Loss: 0.4244
OOD Validation ACCURACY: 0.8810
OOD Validation Loss: 0.4194
OOD Test ACCURACY: 0.7921
OOD Test Loss: 0.8078

[0m[1;37mINFO[0m: [1mChartInfo 0.8827 0.7557 0.8776 0.7921 0.8741 0.8810[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
SUFF++ for r=0.3 class 0 = 0.687 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 1 = 0.683 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 2 = 0.674 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 3 = 0.67 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 4 = 0.676 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 5 = 0.692 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 6 = 0.649 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 7 = 0.653 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 8 = 0.773 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 class 9 = 0.674 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all KL = 0.806 +- 0.166 (in-sample avg dev_std = 0.227)
SUFF++ for r=0.3 all L1 = 0.682 +- 0.205 (in-sample avg dev_std = 0.227)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.201
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.176
SUFF++ for r=0.6 class 0 = 0.521 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 1 = 0.439 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 2 = 0.525 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 3 = 0.499 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 4 = 0.52 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 5 = 0.469 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 6 = 0.478 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 7 = 0.465 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 8 = 0.516 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 class 9 = 0.452 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 all KL = 0.508 +- 0.286 (in-sample avg dev_std = 0.170)
SUFF++ for r=0.6 all L1 = 0.488 +- 0.207 (in-sample avg dev_std = 0.170)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.777
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.728
SUFF++ for r=0.9 class 0 = 0.906 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 1 = 0.949 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 2 = 0.785 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 3 = 0.664 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 4 = 0.769 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 5 = 0.715 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 6 = 0.73 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 7 = 0.786 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 8 = 0.865 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 class 9 = 0.745 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all KL = 0.789 +- 0.283 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.232 (in-sample avg dev_std = 0.303)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.121
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.113
SUFF++ for r=0.3 class 0 = 0.713 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 1 = 0.738 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 2 = 0.703 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 3 = 0.68 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 4 = 0.681 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 5 = 0.703 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 6 = 0.728 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 7 = 0.716 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 8 = 0.756 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 class 9 = 0.736 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 all KL = 0.842 +- 0.135 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.3 all L1 = 0.716 +- 0.182 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.22
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.183
SUFF++ for r=0.6 class 0 = 0.466 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 1 = 0.555 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 2 = 0.434 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 3 = 0.49 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 4 = 0.415 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 5 = 0.411 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 6 = 0.439 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 7 = 0.441 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 8 = 0.41 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 9 = 0.412 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all KL = 0.477 +- 0.269 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all L1 = 0.449 +- 0.189 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.648
SUFF++ for r=0.9 class 0 = 0.842 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 1 = 0.963 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 2 = 0.713 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 3 = 0.67 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 4 = 0.762 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 5 = 0.692 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 6 = 0.741 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 7 = 0.805 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 8 = 0.78 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 9 = 0.701 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all KL = 0.792 +- 0.247 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all L1 = 0.77 +- 0.223 (in-sample avg dev_std = 0.277)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.304 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 1 = 0.3 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 2 = 0.304 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 3 = 0.336 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 4 = 0.311 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 5 = 0.301 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 6 = 0.357 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 7 = 0.34 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 8 = 0.239 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 class 9 = 0.322 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all KL = 0.191 +- 0.171 (in-sample avg dev_std = 0.179)
NEC for r=0.3 all L1 = 0.312 +- 0.198 (in-sample avg dev_std = 0.179)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.201
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.194
NEC for r=0.6 class 0 = 0.441 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 1 = 0.519 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 2 = 0.492 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 3 = 0.508 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 4 = 0.501 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 5 = 0.506 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 6 = 0.506 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 7 = 0.53 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 8 = 0.486 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 9 = 0.528 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all KL = 0.504 +- 0.228 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all L1 = 0.502 +- 0.161 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.777
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.568
NEC for r=0.9 class 0 = 0.292 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 1 = 0.149 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 2 = 0.456 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 3 = 0.617 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 4 = 0.513 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 5 = 0.582 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 6 = 0.606 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 7 = 0.464 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 8 = 0.32 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 class 9 = 0.503 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 all KL = 0.635 +- 0.337 (in-sample avg dev_std = 0.486)
NEC for r=0.9 all L1 = 0.445 +- 0.274 (in-sample avg dev_std = 0.486)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0 = 0.115 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 1 = 0.02 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 2 = 0.255 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 3 = 0.455 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 4 = 0.277 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 5 = 0.418 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 6 = 0.359 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 7 = 0.235 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 8 = 0.179 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 class 9 = 0.381 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all KL = 0.463 +- 0.378 (in-sample avg dev_std = 0.455)
NEC for r=1.0 all L1 = 0.264 +- 0.263 (in-sample avg dev_std = 0.455)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.121
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
NEC for r=0.3 class 0 = 0.256 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 1 = 0.232 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 2 = 0.28 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 3 = 0.313 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 4 = 0.312 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 5 = 0.285 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 6 = 0.288 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 7 = 0.272 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 8 = 0.246 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 class 9 = 0.277 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all KL = 0.151 +- 0.151 (in-sample avg dev_std = 0.145)
NEC for r=0.3 all L1 = 0.275 +- 0.186 (in-sample avg dev_std = 0.145)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.22
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.191
NEC for r=0.6 class 0 = 0.539 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 1 = 0.44 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 2 = 0.6 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 3 = 0.565 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 4 = 0.591 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 5 = 0.561 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 6 = 0.576 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 7 = 0.545 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 8 = 0.596 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 class 9 = 0.576 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all KL = 0.554 +- 0.218 (in-sample avg dev_std = 0.353)
NEC for r=0.6 all L1 = 0.558 +- 0.147 (in-sample avg dev_std = 0.353)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.692
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.475
NEC for r=0.9 class 0 = 0.581 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 1 = 0.123 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 2 = 0.514 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 3 = 0.636 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 4 = 0.475 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 5 = 0.585 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 6 = 0.611 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 7 = 0.404 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 8 = 0.516 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 class 9 = 0.612 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 all KL = 0.658 +- 0.305 (in-sample avg dev_std = 0.480)
NEC for r=0.9 all L1 = 0.5 +- 0.259 (in-sample avg dev_std = 0.480)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.815
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.683
NEC for r=1.0 class 0 = 0.359 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 1 = 0.06 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 2 = 0.384 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 3 = 0.526 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 4 = 0.33 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 5 = 0.454 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 6 = 0.498 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 7 = 0.232 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 8 = 0.418 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 class 9 = 0.503 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 all KL = 0.547 +- 0.358 (in-sample avg dev_std = 0.472)
NEC for r=1.0 all L1 = 0.371 +- 0.278 (in-sample avg dev_std = 0.472)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:17:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:17:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.9837
Train Loss: 0.0597
ID Validation ACCURACY: 0.8830
ID Validation Loss: 0.4132
ID Test ACCURACY: 0.8796
ID Test Loss: 0.4055
OOD Validation ACCURACY: 0.8721
OOD Validation Loss: 0.4230
OOD Test ACCURACY: 0.7870
OOD Test Loss: 0.8251

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.9769
Train Loss: 0.0782
ID Validation ACCURACY: 0.8811
ID Validation Loss: 0.4010
ID Test ACCURACY: 0.8799
ID Test Loss: 0.4049
OOD Validation ACCURACY: 0.8813
OOD Validation Loss: 0.4007
OOD Test ACCURACY: 0.7771
OOD Test Loss: 0.8287

[0m[1;37mINFO[0m: [1mChartInfo 0.8796 0.7870 0.8799 0.7771 0.8811 0.8813[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.666 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 1 = 0.708 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 2 = 0.638 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 3 = 0.688 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 4 = 0.645 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 5 = 0.681 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 6 = 0.678 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 7 = 0.663 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 8 = 0.729 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 class 9 = 0.685 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all KL = 0.836 +- 0.121 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.3 all L1 = 0.678 +- 0.140 (in-sample avg dev_std = 0.223)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.151
SUFF++ for r=0.6 class 0 = 0.522 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 1 = 0.491 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 2 = 0.487 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 3 = 0.514 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 4 = 0.525 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 5 = 0.508 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 6 = 0.498 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 7 = 0.487 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 8 = 0.559 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 class 9 = 0.519 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all KL = 0.595 +- 0.245 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.6 all L1 = 0.51 +- 0.173 (in-sample avg dev_std = 0.155)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.708
SUFF++ for r=0.9 class 0 = 0.891 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 1 = 0.896 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 2 = 0.783 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 3 = 0.675 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 4 = 0.749 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 5 = 0.647 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 6 = 0.779 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 7 = 0.744 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 8 = 0.871 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 class 9 = 0.746 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 all KL = 0.811 +- 0.239 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.9 all L1 = 0.781 +- 0.214 (in-sample avg dev_std = 0.287)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.12
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.723 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 1 = 0.778 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 2 = 0.74 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 3 = 0.734 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 4 = 0.731 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 5 = 0.751 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 6 = 0.76 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 7 = 0.748 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 8 = 0.763 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 9 = 0.754 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all KL = 0.892 +- 0.090 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all L1 = 0.749 +- 0.121 (in-sample avg dev_std = 0.176)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.228
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.177
SUFF++ for r=0.6 class 0 = 0.526 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 1 = 0.504 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 2 = 0.482 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 3 = 0.498 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 4 = 0.495 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 5 = 0.464 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 6 = 0.491 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 7 = 0.502 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 8 = 0.477 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 9 = 0.5 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 all KL = 0.576 +- 0.254 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 all L1 = 0.494 +- 0.179 (in-sample avg dev_std = 0.160)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.673
SUFF++ for r=0.9 class 0 = 0.79 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 1 = 0.962 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 2 = 0.775 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 3 = 0.709 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 4 = 0.767 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 5 = 0.737 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 6 = 0.807 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 7 = 0.795 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 8 = 0.77 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 9 = 0.727 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all KL = 0.84 +- 0.194 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all L1 = 0.787 +- 0.190 (in-sample avg dev_std = 0.238)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.117
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
NEC for r=0.3 class 0 = 0.311 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 1 = 0.254 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 2 = 0.328 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 3 = 0.277 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 4 = 0.302 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 5 = 0.299 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 6 = 0.329 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 7 = 0.307 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 8 = 0.237 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 class 9 = 0.3 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all KL = 0.145 +- 0.145 (in-sample avg dev_std = 0.164)
NEC for r=0.3 all L1 = 0.294 +- 0.167 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.158
NEC for r=0.6 class 0 = 0.503 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 1 = 0.482 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 2 = 0.496 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 3 = 0.494 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 4 = 0.473 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 5 = 0.482 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 6 = 0.484 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 7 = 0.514 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 8 = 0.484 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 9 = 0.491 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all KL = 0.419 +- 0.200 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all L1 = 0.491 +- 0.129 (in-sample avg dev_std = 0.293)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.42 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.245 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.434 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 3 = 0.557 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 4 = 0.546 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 5 = 0.656 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 6 = 0.541 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 7 = 0.547 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 8 = 0.333 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 9 = 0.518 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.619 +- 0.296 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.475 +- 0.250 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.941
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.796
NEC for r=1.0 class 0 = 0.225 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 1 = 0.061 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 2 = 0.224 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 3 = 0.448 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 4 = 0.294 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 5 = 0.459 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 6 = 0.311 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 7 = 0.332 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 8 = 0.2 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 class 9 = 0.321 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 all KL = 0.428 +- 0.326 (in-sample avg dev_std = 0.413)
NEC for r=1.0 all L1 = 0.283 +- 0.252 (in-sample avg dev_std = 0.413)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.12
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
NEC for r=0.3 class 0 = 0.238 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1 = 0.179 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 2 = 0.232 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 3 = 0.241 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 4 = 0.238 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 5 = 0.205 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 6 = 0.206 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 7 = 0.211 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 8 = 0.207 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 9 = 0.215 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.086 +- 0.112 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.217 +- 0.149 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.228
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.193
NEC for r=0.6 class 0 = 0.506 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 1 = 0.504 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 2 = 0.557 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 3 = 0.544 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 4 = 0.521 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 5 = 0.549 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 6 = 0.517 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 7 = 0.514 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 8 = 0.511 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 class 9 = 0.525 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 all KL = 0.463 +- 0.202 (in-sample avg dev_std = 0.309)
NEC for r=0.6 all L1 = 0.524 +- 0.132 (in-sample avg dev_std = 0.309)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.726
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.513
NEC for r=0.9 class 0 = 0.548 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 1 = 0.149 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 2 = 0.403 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 3 = 0.617 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 4 = 0.48 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 5 = 0.561 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 6 = 0.499 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 7 = 0.517 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 8 = 0.547 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 class 9 = 0.512 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all KL = 0.578 +- 0.291 (in-sample avg dev_std = 0.433)
NEC for r=0.9 all L1 = 0.478 +- 0.237 (in-sample avg dev_std = 0.433)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.812
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.714
NEC for r=1.0 class 0 = 0.446 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 1 = 0.056 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 2 = 0.314 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 3 = 0.473 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 4 = 0.317 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 5 = 0.414 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 6 = 0.323 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 7 = 0.315 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 8 = 0.422 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 9 = 0.406 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all KL = 0.452 +- 0.316 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all L1 = 0.345 +- 0.254 (in-sample avg dev_std = 0.410)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.855, 0.476, 0.776, 1.0], 'all_L1': [0.773, 0.488, 0.783, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.775, 0.404, 0.753, 1.0], 'all_L1': [0.649, 0.447, 0.77, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.895, 0.594, 0.837, 1.0], 'all_L1': [0.813, 0.511, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.806, 0.508, 0.789, 1.0], 'all_L1': [0.682, 0.488, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.836, 0.595, 0.811, 1.0], 'all_L1': [0.678, 0.51, 0.781, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.155, 0.578, 0.663, 0.476], 'all_L1': [0.235, 0.526, 0.461, 0.275]}), defaultdict(<class 'list'>, {'all_KL': [0.338, 0.674, 0.718, 0.468], 'all_L1': [0.427, 0.573, 0.496, 0.268]}), defaultdict(<class 'list'>, {'all_KL': [0.107, 0.459, 0.56, 0.388], 'all_L1': [0.192, 0.511, 0.436, 0.274]}), defaultdict(<class 'list'>, {'all_KL': [0.191, 0.504, 0.635, 0.463], 'all_L1': [0.312, 0.502, 0.445, 0.264]}), defaultdict(<class 'list'>, {'all_KL': [0.145, 0.419, 0.619, 0.428], 'all_L1': [0.294, 0.491, 0.475, 0.283]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.919, 0.444, 0.748, 1.0], 'all_L1': [0.855, 0.463, 0.729, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.864, 0.444, 0.742, 1.0], 'all_L1': [0.719, 0.452, 0.715, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.926, 0.591, 0.831, 1.0], 'all_L1': [0.858, 0.509, 0.773, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.842, 0.477, 0.792, 1.0], 'all_L1': [0.716, 0.449, 0.77, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.892, 0.576, 0.84, 1.0], 'all_L1': [0.749, 0.494, 0.787, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.087, 0.627, 0.708, 0.594], 'all_L1': [0.15, 0.557, 0.537, 0.407]}), defaultdict(<class 'list'>, {'all_KL': [0.218, 0.625, 0.706, 0.616], 'all_L1': [0.348, 0.564, 0.553, 0.457]}), defaultdict(<class 'list'>, {'all_KL': [0.075, 0.433, 0.578, 0.495], 'all_L1': [0.143, 0.503, 0.484, 0.372]}), defaultdict(<class 'list'>, {'all_KL': [0.151, 0.554, 0.658, 0.547], 'all_L1': [0.275, 0.558, 0.5, 0.371]}), defaultdict(<class 'list'>, {'all_KL': [0.086, 0.463, 0.578, 0.452], 'all_L1': [0.217, 0.524, 0.478, 0.345]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.719 +- 0.063, 0.489 +- 0.023, 0.785 +- 0.010, 1.000 +- 0.000
suff++ class all_KL  =  0.833 +- 0.041, 0.515 +- 0.073, 0.793 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.111 +- 0.004, 0.149 +- 0.014, 0.720 +- 0.008
nec class all_L1  =  0.292 +- 0.080, 0.521 +- 0.029, 0.463 +- 0.021, 0.273 +- 0.006
nec class all_KL  =  0.187 +- 0.080, 0.527 +- 0.091, 0.639 +- 0.052, 0.445 +- 0.033
nec_acc_int  =  0.112 +- 0.003, 0.153 +- 0.024, 0.552 +- 0.022, 0.802 +- 0.005

Eval split test
suff++ class all_L1  =  0.779 +- 0.064, 0.473 +- 0.024, 0.755 +- 0.028, 1.000 +- 0.000
suff++ class all_KL  =  0.889 +- 0.032, 0.506 +- 0.064, 0.791 +- 0.041, 1.000 +- 0.000
suff++_acc_int  =  0.118 +- 0.011, 0.161 +- 0.016, 0.621 +- 0.056
nec class all_L1  =  0.227 +- 0.077, 0.541 +- 0.024, 0.510 +- 0.030, 0.390 +- 0.039
nec class all_KL  =  0.123 +- 0.054, 0.540 +- 0.080, 0.646 +- 0.058, 0.541 +- 0.061
nec_acc_int  =  0.118 +- 0.011, 0.174 +- 0.016, 0.465 +- 0.041, 0.655 +- 0.054


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.506 +- 0.017, 0.505 +- 0.006, 0.624 +- 0.006, 0.636 +- 0.003
Faith. Armon (L1)= 		  =  0.405 +- 0.069, 0.503 +- 0.005, 0.582 +- 0.014, 0.429 +- 0.008
Faith. GMean (L1)= 	  =  0.451 +- 0.044, 0.504 +- 0.006, 0.603 +- 0.010, 0.522 +- 0.006
Faith. Aritm (KL)= 		  =  0.510 +- 0.024, 0.521 +- 0.013, 0.716 +- 0.012, 0.722 +- 0.016
Faith. Armon (KL)= 		  =  0.296 +- 0.095, 0.509 +- 0.011, 0.705 +- 0.021, 0.615 +- 0.032
Faith. GMean (KL)= 	  =  0.385 +- 0.069, 0.515 +- 0.010, 0.711 +- 0.016, 0.666 +- 0.025

Eval split test
Faith. Aritm (L1)= 		  =  0.503 +- 0.017, 0.507 +- 0.002, 0.633 +- 0.002, 0.695 +- 0.019
Faith. Armon (L1)= 		  =  0.341 +- 0.085, 0.504 +- 0.004, 0.608 +- 0.012, 0.560 +- 0.039
Faith. GMean (L1)= 	  =  0.411 +- 0.056, 0.506 +- 0.003, 0.620 +- 0.007, 0.624 +- 0.031
Faith. Aritm (KL)= 		  =  0.506 +- 0.018, 0.523 +- 0.010, 0.718 +- 0.009, 0.770 +- 0.030
Faith. Armon (KL)= 		  =  0.212 +- 0.080, 0.513 +- 0.007, 0.707 +- 0.020, 0.700 +- 0.052
Faith. GMean (KL)= 	  =  0.323 +- 0.064, 0.518 +- 0.008, 0.713 +- 0.015, 0.734 +- 0.042
Computed for split load_split = id



Completed in  1:05:05.377101  for LECIGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:30:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:38 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 04:30:39 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.3520
Train Loss: 4.1012
ID Validation ACCURACY: 0.3500
ID Validation Loss: 4.1593
ID Test ACCURACY: 0.3524
ID Test Loss: 4.1588
OOD Validation ACCURACY: 0.3167
OOD Validation Loss: 6.5550
OOD Test ACCURACY: 0.1637
OOD Test Loss: 33.3198

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.3520
Train Loss: 4.1012
ID Validation ACCURACY: 0.3500
ID Validation Loss: 4.1593
ID Test ACCURACY: 0.3524
ID Test Loss: 4.1588
OOD Validation ACCURACY: 0.3167
OOD Validation Loss: 6.5550
OOD Test ACCURACY: 0.1637
OOD Test Loss: 33.3198

[0m[1;37mINFO[0m: [1mChartInfo 0.3524 0.1637 0.3524 0.1637 0.3500 0.3167[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.113
SUFF++ for r=0.3 class 0 = 0.346 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 1 = 0.402 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 2 = 0.33 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 3 = 0.323 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 4 = 0.334 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 5 = 0.338 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 6 = 0.301 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 7 = 0.355 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 8 = 0.322 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 9 = 0.313 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all KL = 0.231 +- 0.181 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all L1 = 0.338 +- 0.105 (in-sample avg dev_std = 0.617)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.29
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.2
SUFF++ for r=0.6 class 0 = 0.297 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 1 = 0.355 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 2 = 0.288 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 3 = 0.305 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 4 = 0.322 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 5 = 0.304 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 6 = 0.31 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 7 = 0.442 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 8 = 0.29 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 class 9 = 0.304 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 all KL = 0.129 +- 0.169 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.6 all L1 = 0.323 +- 0.141 (in-sample avg dev_std = 0.618)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.345
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.251
SUFF++ for r=0.9 class 0 = 0.288 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 1 = 0.404 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 2 = 0.305 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 3 = 0.303 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 4 = 0.399 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 5 = 0.35 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 6 = 0.377 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 7 = 0.506 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 8 = 0.285 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 class 9 = 0.338 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 all KL = 0.119 +- 0.180 (in-sample avg dev_std = 0.665)
SUFF++ for r=0.9 all L1 = 0.357 +- 0.164 (in-sample avg dev_std = 0.665)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
SUFF++ for r=0.3 class 0 = 0.431 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 1 = 0.439 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 2 = 0.43 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 3 = 0.417 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 4 = 0.435 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 5 = 0.433 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 6 = 0.453 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 7 = 0.434 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 8 = 0.415 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 9 = 0.432 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 all KL = 0.471 +- 0.216 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 all L1 = 0.432 +- 0.123 (in-sample avg dev_std = 0.506)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.245
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.185
SUFF++ for r=0.6 class 0 = 0.248 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 1 = 0.348 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 2 = 0.265 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 3 = 0.267 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 4 = 0.289 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 5 = 0.266 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 6 = 0.275 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 7 = 0.328 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 8 = 0.267 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 9 = 0.288 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all KL = 0.141 +- 0.138 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all L1 = 0.285 +- 0.112 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.176
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.172
SUFF++ for r=0.9 class 0 = 0.27 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 1 = 0.544 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 2 = 0.255 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 3 = 0.262 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 4 = 0.304 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 5 = 0.265 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 6 = 0.332 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 7 = 0.272 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 8 = 0.281 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 class 9 = 0.345 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 all KL = 0.086 +- 0.202 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.9 all L1 = 0.316 +- 0.194 (in-sample avg dev_std = 0.624)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.136
NEC for r=0.3 class 0 = 0.487 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 1 = 0.422 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 2 = 0.499 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 3 = 0.57 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 4 = 0.537 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 5 = 0.536 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 6 = 0.58 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 7 = 0.497 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 8 = 0.496 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 class 9 = 0.584 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 all KL = 0.542 +- 0.288 (in-sample avg dev_std = 0.452)
NEC for r=0.3 all L1 = 0.519 +- 0.209 (in-sample avg dev_std = 0.452)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.29
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.278
NEC for r=0.6 class 0 = 0.657 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 1 = 0.262 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 2 = 0.594 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 3 = 0.597 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 4 = 0.595 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 5 = 0.616 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 6 = 0.644 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 7 = 0.454 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 8 = 0.515 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 9 = 0.635 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all KL = 0.683 +- 0.326 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all L1 = 0.551 +- 0.264 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.345
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.37
NEC for r=0.9 class 0 = 0.643 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 1 = 0.039 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 2 = 0.626 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 3 = 0.654 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 4 = 0.471 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 5 = 0.628 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 6 = 0.608 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 7 = 0.39 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 8 = 0.581 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 class 9 = 0.612 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all KL = 0.672 +- 0.366 (in-sample avg dev_std = 0.492)
NEC for r=0.9 all L1 = 0.517 +- 0.298 (in-sample avg dev_std = 0.492)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.351
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.384
NEC for r=1.0 class 0 = 0.652 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 1 = 0.055 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 2 = 0.608 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 3 = 0.658 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 4 = 0.467 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 5 = 0.626 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 6 = 0.626 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 7 = 0.405 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 8 = 0.615 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 9 = 0.612 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all KL = 0.662 +- 0.353 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all L1 = 0.524 +- 0.288 (in-sample avg dev_std = 0.475)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.124
NEC for r=0.3 class 0 = 0.429 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 1 = 0.449 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 2 = 0.413 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 3 = 0.425 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 4 = 0.441 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 5 = 0.407 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 6 = 0.448 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 7 = 0.423 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 8 = 0.461 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 9 = 0.441 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all KL = 0.348 +- 0.241 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all L1 = 0.434 +- 0.164 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.245
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.229
NEC for r=0.6 class 0 = 0.659 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 1 = 0.494 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 2 = 0.638 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 3 = 0.656 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 4 = 0.603 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 5 = 0.608 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 6 = 0.615 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 7 = 0.487 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 8 = 0.641 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 9 = 0.627 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all KL = 0.668 +- 0.282 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all L1 = 0.602 +- 0.214 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.176
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.206
NEC for r=0.9 class 0 = 0.641 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 1 = 0.386 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 2 = 0.683 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 3 = 0.652 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 4 = 0.687 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 5 = 0.689 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 6 = 0.681 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 7 = 0.748 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 8 = 0.691 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 class 9 = 0.631 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 all KL = 0.789 +- 0.302 (in-sample avg dev_std = 0.394)
NEC for r=0.9 all L1 = 0.646 +- 0.254 (in-sample avg dev_std = 0.394)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.164
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.195
NEC for r=1.0 class 0 = 0.698 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 1 = 0.336 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 2 = 0.695 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 3 = 0.69 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 4 = 0.664 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 5 = 0.73 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 6 = 0.698 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 7 = 0.776 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 8 = 0.722 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 9 = 0.61 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 all KL = 0.839 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 all L1 = 0.658 +- 0.267 (in-sample avg dev_std = 0.329)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:44:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 04:44:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 65...
[0m[1;37mINFO[0m: [1mCheckpoint 65: 
-----------------------------------
Train ACCURACY: 0.4144
Train Loss: 2.4823
ID Validation ACCURACY: 0.4157
ID Validation Loss: 2.5162
ID Test ACCURACY: 0.4114
ID Test Loss: 2.4803
OOD Validation ACCURACY: 0.3104
OOD Validation Loss: 6.7585
OOD Test ACCURACY: 0.1446
OOD Test Loss: 41.0285

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.2914
Train Loss: 3.5159
ID Validation ACCURACY: 0.2877
ID Validation Loss: 3.5219
ID Test ACCURACY: 0.2904
ID Test Loss: 3.4864
OOD Validation ACCURACY: 0.3116
OOD Validation Loss: 9.4187
OOD Test ACCURACY: 0.1699
OOD Test Loss: 50.5791

[0m[1;37mINFO[0m: [1mChartInfo 0.4114 0.1446 0.2904 0.1699 0.2877 0.3116[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.453 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 1 = 0.42 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 2 = 0.427 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 3 = 0.404 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 4 = 0.373 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 5 = 0.446 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 6 = 0.417 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 7 = 0.41 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 8 = 0.437 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 class 9 = 0.397 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all KL = 0.313 +- 0.203 (in-sample avg dev_std = 0.559)
SUFF++ for r=0.3 all L1 = 0.418 +- 0.140 (in-sample avg dev_std = 0.559)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.22
SUFF++ for r=0.6 class 0 = 0.237 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 1 = 0.426 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 2 = 0.27 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 3 = 0.26 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 4 = 0.29 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 5 = 0.273 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 6 = 0.322 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 7 = 0.42 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 8 = 0.259 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 9 = 0.33 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all KL = 0.147 +- 0.173 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all L1 = 0.311 +- 0.144 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.421
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.268
SUFF++ for r=0.9 class 0 = 0.26 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 1 = 0.352 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 2 = 0.267 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 3 = 0.253 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 4 = 0.3 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 5 = 0.276 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 6 = 0.306 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 7 = 0.425 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 8 = 0.242 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 class 9 = 0.341 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 all KL = 0.122 +- 0.176 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.9 all L1 = 0.304 +- 0.138 (in-sample avg dev_std = 0.609)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.449 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 1 = 0.489 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 2 = 0.467 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 3 = 0.455 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 4 = 0.441 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 5 = 0.492 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 6 = 0.47 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 7 = 0.467 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 8 = 0.459 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 class 9 = 0.472 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 all KL = 0.46 +- 0.216 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.3 all L1 = 0.466 +- 0.136 (in-sample avg dev_std = 0.510)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.257
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.181
SUFF++ for r=0.6 class 0 = 0.214 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 1 = 0.442 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 2 = 0.234 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 3 = 0.224 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 4 = 0.267 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 5 = 0.227 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 6 = 0.262 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 7 = 0.272 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 8 = 0.233 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 9 = 0.276 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all KL = 0.105 +- 0.136 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all L1 = 0.267 +- 0.123 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.164
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.161
SUFF++ for r=0.9 class 0 = 0.225 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 1 = 0.499 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 2 = 0.236 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 3 = 0.248 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 4 = 0.291 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 5 = 0.247 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 6 = 0.296 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 7 = 0.252 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 8 = 0.264 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 class 9 = 0.343 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 all KL = 0.079 +- 0.204 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.9 all L1 = 0.292 +- 0.176 (in-sample avg dev_std = 0.608)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
NEC for r=0.3 class 0 = 0.459 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 1 = 0.416 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 2 = 0.442 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 3 = 0.459 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 4 = 0.514 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 5 = 0.397 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 6 = 0.451 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 7 = 0.465 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 8 = 0.348 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 class 9 = 0.541 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all KL = 0.442 +- 0.275 (in-sample avg dev_std = 0.375)
NEC for r=0.3 all L1 = 0.449 +- 0.231 (in-sample avg dev_std = 0.375)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.326
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.282
NEC for r=0.6 class 0 = 0.696 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 1 = 0.363 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 2 = 0.63 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 3 = 0.661 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 4 = 0.669 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 5 = 0.694 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 6 = 0.673 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 7 = 0.541 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 8 = 0.624 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 9 = 0.64 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all KL = 0.737 +- 0.269 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all L1 = 0.614 +- 0.209 (in-sample avg dev_std = 0.486)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.421
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.435
NEC for r=0.9 class 0 = 0.657 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 1 = 0.194 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 2 = 0.597 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 3 = 0.671 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 4 = 0.624 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 5 = 0.676 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 6 = 0.649 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 7 = 0.436 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 8 = 0.665 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 9 = 0.636 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all KL = 0.694 +- 0.303 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all L1 = 0.572 +- 0.246 (in-sample avg dev_std = 0.461)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.417
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.443
NEC for r=1.0 class 0 = 0.649 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 1 = 0.187 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 2 = 0.577 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 3 = 0.666 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 4 = 0.587 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 5 = 0.662 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 6 = 0.639 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 7 = 0.455 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 8 = 0.661 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 class 9 = 0.624 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 all KL = 0.668 +- 0.292 (in-sample avg dev_std = 0.445)
NEC for r=1.0 all L1 = 0.563 +- 0.238 (in-sample avg dev_std = 0.445)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.115
NEC for r=0.3 class 0 = 0.459 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1 = 0.407 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 2 = 0.478 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 3 = 0.499 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 4 = 0.521 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 5 = 0.466 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 6 = 0.504 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 7 = 0.494 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 8 = 0.476 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 9 = 0.46 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.436 +- 0.272 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.475 +- 0.205 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.257
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.251
NEC for r=0.6 class 0 = 0.706 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 1 = 0.339 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 2 = 0.679 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 3 = 0.715 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 4 = 0.684 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 5 = 0.708 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 6 = 0.699 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 7 = 0.641 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 8 = 0.726 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 9 = 0.688 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all KL = 0.766 +- 0.255 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all L1 = 0.654 +- 0.206 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.164
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.219
NEC for r=0.9 class 0 = 0.671 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 1 = 0.567 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 2 = 0.685 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 3 = 0.656 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 4 = 0.653 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 5 = 0.667 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 6 = 0.664 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 7 = 0.67 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 8 = 0.699 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 class 9 = 0.636 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 all KL = 0.84 +- 0.234 (in-sample avg dev_std = 0.416)
NEC for r=0.9 all L1 = 0.656 +- 0.194 (in-sample avg dev_std = 0.416)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.166
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.204
NEC for r=1.0 class 0 = 0.665 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 1 = 0.527 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 2 = 0.679 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 3 = 0.645 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 4 = 0.617 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 5 = 0.644 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 6 = 0.662 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 7 = 0.663 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 8 = 0.666 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 9 = 0.605 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 all KL = 0.829 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 all L1 = 0.636 +- 0.222 (in-sample avg dev_std = 0.412)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 16:58:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:18 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 04:58:19 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 66...
[0m[1;37mINFO[0m: [1mCheckpoint 66: 
-----------------------------------
Train ACCURACY: 0.3567
Train Loss: 3.2947
ID Validation ACCURACY: 0.3594
ID Validation Loss: 3.2787
ID Test ACCURACY: 0.3510
ID Test Loss: 3.2852
OOD Validation ACCURACY: 0.3019
OOD Validation Loss: 3.8731
OOD Test ACCURACY: 0.1820
OOD Test Loss: 4.9479

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 39...
[0m[1;37mINFO[0m: [1mCheckpoint 39: 
-----------------------------------
Train ACCURACY: 0.3426
Train Loss: 2.6924
ID Validation ACCURACY: 0.3353
ID Validation Loss: 2.7255
ID Test ACCURACY: 0.3387
ID Test Loss: 2.7041
OOD Validation ACCURACY: 0.3136
OOD Validation Loss: 2.9546
OOD Test ACCURACY: 0.1916
OOD Test Loss: 4.1809

[0m[1;37mINFO[0m: [1mChartInfo 0.3510 0.1820 0.3387 0.1916 0.3353 0.3136[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.319 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 1 = 0.328 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 2 = 0.349 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 3 = 0.283 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 4 = 0.285 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 5 = 0.321 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 6 = 0.312 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 7 = 0.313 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 8 = 0.32 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 class 9 = 0.288 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 all KL = 0.201 +- 0.162 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.3 all L1 = 0.312 +- 0.099 (in-sample avg dev_std = 0.595)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.27
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.199
SUFF++ for r=0.6 class 0 = 0.265 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 1 = 0.339 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 2 = 0.268 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 3 = 0.263 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 4 = 0.276 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 5 = 0.265 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 6 = 0.266 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 7 = 0.387 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 8 = 0.214 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 class 9 = 0.269 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 all KL = 0.086 +- 0.142 (in-sample avg dev_std = 0.557)
SUFF++ for r=0.6 all L1 = 0.283 +- 0.120 (in-sample avg dev_std = 0.557)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.347
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.256
SUFF++ for r=0.9 class 0 = 0.26 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 1 = 0.393 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 2 = 0.282 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 3 = 0.251 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 4 = 0.348 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 5 = 0.264 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 6 = 0.271 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 7 = 0.326 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 8 = 0.238 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 class 9 = 0.294 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 all KL = 0.085 +- 0.164 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.9 all L1 = 0.294 +- 0.139 (in-sample avg dev_std = 0.604)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.131
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.124
SUFF++ for r=0.3 class 0 = 0.436 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 1 = 0.409 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 2 = 0.409 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 3 = 0.41 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 4 = 0.441 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 5 = 0.414 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 6 = 0.446 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 7 = 0.41 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 8 = 0.379 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 9 = 0.39 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all KL = 0.367 +- 0.246 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all L1 = 0.414 +- 0.160 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.229
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.178
SUFF++ for r=0.6 class 0 = 0.234 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 1 = 0.43 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 2 = 0.223 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 3 = 0.218 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 4 = 0.248 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 5 = 0.24 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 6 = 0.241 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 7 = 0.257 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 8 = 0.236 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 class 9 = 0.255 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 all KL = 0.062 +- 0.096 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.6 all L1 = 0.26 +- 0.111 (in-sample avg dev_std = 0.579)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.165
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.161
SUFF++ for r=0.9 class 0 = 0.242 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 1 = 0.315 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 2 = 0.249 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 3 = 0.24 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 4 = 0.246 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 5 = 0.239 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 6 = 0.251 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 7 = 0.249 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 8 = 0.247 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 class 9 = 0.26 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 all KL = 0.039 +- 0.063 (in-sample avg dev_std = 0.566)
SUFF++ for r=0.9 all L1 = 0.255 +- 0.088 (in-sample avg dev_std = 0.566)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.541 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 1 = 0.45 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 2 = 0.525 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 3 = 0.599 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 4 = 0.574 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 5 = 0.554 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 6 = 0.545 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 7 = 0.513 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 8 = 0.511 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 9 = 0.602 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all KL = 0.563 +- 0.268 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all L1 = 0.54 +- 0.203 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.27
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.259
NEC for r=0.6 class 0 = 0.668 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 1 = 0.36 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 2 = 0.672 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 3 = 0.666 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 4 = 0.647 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 5 = 0.696 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 6 = 0.665 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 7 = 0.489 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 8 = 0.698 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 9 = 0.699 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all KL = 0.76 +- 0.272 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all L1 = 0.62 +- 0.215 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.347
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.393
NEC for r=0.9 class 0 = 0.668 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 1 = 0.163 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 2 = 0.615 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 3 = 0.667 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 4 = 0.593 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 5 = 0.69 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 6 = 0.68 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 7 = 0.475 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 8 = 0.693 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 9 = 0.69 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all KL = 0.711 +- 0.307 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all L1 = 0.585 +- 0.249 (in-sample avg dev_std = 0.445)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.359
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.407
NEC for r=1.0 class 0 = 0.675 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 1 = 0.15 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 2 = 0.594 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 3 = 0.674 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 4 = 0.598 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 5 = 0.683 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 6 = 0.679 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 7 = 0.485 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 8 = 0.684 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 class 9 = 0.68 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 all KL = 0.695 +- 0.302 (in-sample avg dev_std = 0.433)
NEC for r=1.0 all L1 = 0.582 +- 0.240 (in-sample avg dev_std = 0.433)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.131
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.136
NEC for r=0.3 class 0 = 0.473 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 1 = 0.455 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 2 = 0.512 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 3 = 0.492 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 4 = 0.514 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 5 = 0.496 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 6 = 0.448 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 7 = 0.474 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 8 = 0.511 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 class 9 = 0.488 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all KL = 0.487 +- 0.276 (in-sample avg dev_std = 0.395)
NEC for r=0.3 all L1 = 0.486 +- 0.204 (in-sample avg dev_std = 0.395)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.229
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.23
NEC for r=0.6 class 0 = 0.681 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 1 = 0.296 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 2 = 0.691 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 3 = 0.686 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 4 = 0.586 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 5 = 0.634 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 6 = 0.628 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 7 = 0.596 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 8 = 0.652 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 class 9 = 0.643 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 all KL = 0.765 +- 0.282 (in-sample avg dev_std = 0.464)
NEC for r=0.6 all L1 = 0.606 +- 0.246 (in-sample avg dev_std = 0.464)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.165
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.219
NEC for r=0.9 class 0 = 0.673 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 1 = 0.479 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 2 = 0.654 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 3 = 0.639 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 4 = 0.65 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 5 = 0.652 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 6 = 0.651 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 7 = 0.654 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 8 = 0.654 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 9 = 0.663 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all KL = 0.762 +- 0.221 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all L1 = 0.635 +- 0.181 (in-sample avg dev_std = 0.446)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.162
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.221
NEC for r=1.0 class 0 = 0.656 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 1 = 0.479 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 2 = 0.628 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 3 = 0.639 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 4 = 0.636 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 5 = 0.628 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 6 = 0.649 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 7 = 0.642 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 8 = 0.659 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 9 = 0.637 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all KL = 0.73 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all L1 = 0.624 +- 0.179 (in-sample avg dev_std = 0.417)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 17:13:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 05:13:13 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.3909
Train Loss: 2.8134
ID Validation ACCURACY: 0.4021
ID Validation Loss: 2.7741
ID Test ACCURACY: 0.3860
ID Test Loss: 2.8356
OOD Validation ACCURACY: 0.3126
OOD Validation Loss: 4.1696
OOD Test ACCURACY: 0.2140
OOD Test Loss: 12.2054

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.3350
Train Loss: 4.2162
ID Validation ACCURACY: 0.3359
ID Validation Loss: 4.3002
ID Test ACCURACY: 0.3386
ID Test Loss: 4.2674
OOD Validation ACCURACY: 0.3293
OOD Validation Loss: 8.2922
OOD Test ACCURACY: 0.1864
OOD Test Loss: 53.4631

[0m[1;37mINFO[0m: [1mChartInfo 0.3860 0.2140 0.3386 0.1864 0.3359 0.3293[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.368 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 1 = 0.358 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 2 = 0.352 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 3 = 0.333 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 4 = 0.337 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 5 = 0.373 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 6 = 0.33 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 7 = 0.338 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 8 = 0.341 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 class 9 = 0.294 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 all KL = 0.303 +- 0.197 (in-sample avg dev_std = 0.506)
SUFF++ for r=0.3 all L1 = 0.342 +- 0.113 (in-sample avg dev_std = 0.506)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.285
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.201
SUFF++ for r=0.6 class 0 = 0.223 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 1 = 0.325 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 2 = 0.267 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 3 = 0.259 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 4 = 0.264 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 5 = 0.288 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 6 = 0.273 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 7 = 0.33 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 8 = 0.243 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 class 9 = 0.293 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 all KL = 0.093 +- 0.139 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.6 all L1 = 0.277 +- 0.108 (in-sample avg dev_std = 0.582)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.379
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.279
SUFF++ for r=0.9 class 0 = 0.264 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 1 = 0.328 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 2 = 0.283 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 3 = 0.262 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 4 = 0.317 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 5 = 0.327 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 6 = 0.279 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 7 = 0.321 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 8 = 0.248 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 9 = 0.362 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 all KL = 0.128 +- 0.187 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 all L1 = 0.299 +- 0.131 (in-sample avg dev_std = 0.618)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.493 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 1 = 0.447 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 2 = 0.466 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 3 = 0.486 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 4 = 0.452 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 5 = 0.462 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 6 = 0.511 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 7 = 0.462 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 8 = 0.477 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 class 9 = 0.473 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 all KL = 0.531 +- 0.219 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.3 all L1 = 0.473 +- 0.158 (in-sample avg dev_std = 0.426)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.31
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.193
SUFF++ for r=0.6 class 0 = 0.283 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 1 = 0.47 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 2 = 0.262 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 3 = 0.261 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 4 = 0.278 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 5 = 0.277 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 6 = 0.292 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 7 = 0.319 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 8 = 0.278 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 class 9 = 0.324 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all KL = 0.168 +- 0.158 (in-sample avg dev_std = 0.532)
SUFF++ for r=0.6 all L1 = 0.306 +- 0.126 (in-sample avg dev_std = 0.532)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.21
SUFF++ for r=0.9 class 0 = 0.296 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 1 = 0.809 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 2 = 0.254 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 3 = 0.293 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 4 = 0.309 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 5 = 0.284 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 6 = 0.35 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 7 = 0.281 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 8 = 0.286 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 class 9 = 0.455 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 all KL = 0.172 +- 0.302 (in-sample avg dev_std = 0.550)
SUFF++ for r=0.9 all L1 = 0.367 +- 0.259 (in-sample avg dev_std = 0.550)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
NEC for r=0.3 class 0 = 0.546 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 1 = 0.452 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 2 = 0.512 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 3 = 0.565 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 4 = 0.565 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 5 = 0.514 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 6 = 0.542 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 7 = 0.534 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 8 = 0.547 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 class 9 = 0.595 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 all KL = 0.512 +- 0.258 (in-sample avg dev_std = 0.396)
NEC for r=0.3 all L1 = 0.536 +- 0.175 (in-sample avg dev_std = 0.396)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.285
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.275
NEC for r=0.6 class 0 = 0.729 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 1 = 0.378 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 2 = 0.631 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 3 = 0.619 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 4 = 0.654 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 5 = 0.666 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 6 = 0.645 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 7 = 0.48 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 8 = 0.657 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 9 = 0.657 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all KL = 0.736 +- 0.277 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all L1 = 0.606 +- 0.221 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.379
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.447
NEC for r=0.9 class 0 = 0.663 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 1 = 0.178 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 2 = 0.645 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 3 = 0.658 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 4 = 0.612 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 5 = 0.656 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 6 = 0.637 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 7 = 0.516 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 8 = 0.683 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 class 9 = 0.632 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 all KL = 0.71 +- 0.308 (in-sample avg dev_std = 0.466)
NEC for r=0.9 all L1 = 0.581 +- 0.255 (in-sample avg dev_std = 0.466)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.382
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.458
NEC for r=1.0 class 0 = 0.674 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 1 = 0.21 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 2 = 0.619 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 3 = 0.643 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 4 = 0.622 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 5 = 0.651 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 6 = 0.632 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 7 = 0.525 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 8 = 0.679 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 class 9 = 0.637 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 all KL = 0.692 +- 0.298 (in-sample avg dev_std = 0.450)
NEC for r=1.0 all L1 = 0.582 +- 0.246 (in-sample avg dev_std = 0.450)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
NEC for r=0.3 class 0 = 0.402 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 1 = 0.381 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 2 = 0.429 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 3 = 0.41 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 4 = 0.463 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 5 = 0.428 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 6 = 0.419 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 7 = 0.397 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 8 = 0.439 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 9 = 0.461 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all KL = 0.313 +- 0.204 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all L1 = 0.422 +- 0.153 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.31
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.251
NEC for r=0.6 class 0 = 0.627 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 1 = 0.159 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 2 = 0.636 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 3 = 0.663 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 4 = 0.608 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 5 = 0.628 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 6 = 0.611 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 7 = 0.51 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 8 = 0.622 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 class 9 = 0.562 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 all KL = 0.615 +- 0.297 (in-sample avg dev_std = 0.371)
NEC for r=0.6 all L1 = 0.558 +- 0.242 (in-sample avg dev_std = 0.371)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.285
NEC for r=0.9 class 0 = 0.644 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 1 = 0.079 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 2 = 0.706 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 3 = 0.694 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 4 = 0.668 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 5 = 0.687 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 6 = 0.622 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 7 = 0.657 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 8 = 0.66 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 9 = 0.558 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 all KL = 0.731 +- 0.318 (in-sample avg dev_std = 0.397)
NEC for r=0.9 all L1 = 0.591 +- 0.274 (in-sample avg dev_std = 0.397)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.209
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.275
NEC for r=1.0 class 0 = 0.655 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 1 = 0.058 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 2 = 0.699 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 3 = 0.648 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 4 = 0.575 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 5 = 0.656 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 6 = 0.608 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 7 = 0.64 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 8 = 0.632 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 9 = 0.422 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all KL = 0.7 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all L1 = 0.554 +- 0.316 (in-sample avg dev_std = 0.387)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedmitig_explscoreshardavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sun Sep 29 17:27:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 09/29/2024 05:27:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 0.3832
Train Loss: 3.2781
ID Validation ACCURACY: 0.3854
ID Validation Loss: 3.3077
ID Test ACCURACY: 0.3756
ID Test Loss: 3.3515
OOD Validation ACCURACY: 0.2441
OOD Validation Loss: 6.2321
OOD Test ACCURACY: 0.1736
OOD Test Loss: 8.2136

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.3804
Train Loss: 3.3525
ID Validation ACCURACY: 0.3771
ID Validation Loss: 3.3880
ID Test ACCURACY: 0.3827
ID Test Loss: 3.3628
OOD Validation ACCURACY: 0.3297
OOD Validation Loss: 4.5238
OOD Test ACCURACY: 0.2149
OOD Test Loss: 6.5520

[0m[1;37mINFO[0m: [1mChartInfo 0.3756 0.1736 0.3827 0.2149 0.3771 0.3297[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.083
SUFF++ for r=0.3 class 0 = 0.35 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 1 = 0.37 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 2 = 0.322 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 3 = 0.317 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 4 = 0.335 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 5 = 0.314 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 6 = 0.332 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 7 = 0.351 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 8 = 0.363 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 9 = 0.319 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all KL = 0.266 +- 0.191 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all L1 = 0.338 +- 0.111 (in-sample avg dev_std = 0.570)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.268
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.211
SUFF++ for r=0.6 class 0 = 0.239 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 1 = 0.392 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 2 = 0.267 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 3 = 0.266 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 4 = 0.285 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 5 = 0.242 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 6 = 0.266 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 7 = 0.393 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 8 = 0.285 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 9 = 0.276 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all KL = 0.09 +- 0.137 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all L1 = 0.294 +- 0.138 (in-sample avg dev_std = 0.576)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.404
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.286
SUFF++ for r=0.9 class 0 = 0.276 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 1 = 0.403 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 2 = 0.259 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 3 = 0.271 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 4 = 0.306 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 5 = 0.272 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 6 = 0.285 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 7 = 0.43 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 8 = 0.26 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 class 9 = 0.302 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 all KL = 0.09 +- 0.155 (in-sample avg dev_std = 0.640)
SUFF++ for r=0.9 all L1 = 0.309 +- 0.147 (in-sample avg dev_std = 0.640)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.407 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 1 = 0.328 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 2 = 0.336 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 3 = 0.364 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 4 = 0.317 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 5 = 0.343 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 6 = 0.373 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 7 = 0.327 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 8 = 0.349 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 class 9 = 0.333 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all KL = 0.319 +- 0.221 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.3 all L1 = 0.348 +- 0.127 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.151
SUFF++ for r=0.6 class 0 = 0.234 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 1 = 0.362 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 2 = 0.25 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 3 = 0.254 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 4 = 0.302 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 5 = 0.252 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 6 = 0.277 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 7 = 0.339 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 8 = 0.27 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 9 = 0.332 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 all KL = 0.027 +- 0.066 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 all L1 = 0.288 +- 0.110 (in-sample avg dev_std = 0.656)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.16
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.135
SUFF++ for r=0.9 class 0 = 0.248 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 1 = 0.611 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 2 = 0.31 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 3 = 0.325 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 4 = 0.526 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 5 = 0.337 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 6 = 0.433 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 7 = 0.423 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 8 = 0.381 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 class 9 = 0.617 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 all KL = 0.182 +- 0.303 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.9 all L1 = 0.422 +- 0.274 (in-sample avg dev_std = 0.562)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.097
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.092
NEC for r=0.3 class 0 = 0.535 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.453 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.526 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 3 = 0.537 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 4 = 0.548 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 5 = 0.497 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 6 = 0.508 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 7 = 0.538 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 8 = 0.375 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 9 = 0.59 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.508 +- 0.279 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.51 +- 0.216 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.268
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.24
NEC for r=0.6 class 0 = 0.718 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 1 = 0.425 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 2 = 0.676 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 3 = 0.631 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 4 = 0.654 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 5 = 0.684 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 6 = 0.683 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 7 = 0.52 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 8 = 0.543 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 class 9 = 0.68 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 all KL = 0.78 +- 0.271 (in-sample avg dev_std = 0.524)
NEC for r=0.6 all L1 = 0.617 +- 0.225 (in-sample avg dev_std = 0.524)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.404
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.435
NEC for r=0.9 class 0 = 0.572 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 1 = 0.209 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 2 = 0.658 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 3 = 0.666 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 4 = 0.633 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 5 = 0.711 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 6 = 0.707 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 7 = 0.529 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 8 = 0.594 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 class 9 = 0.672 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all KL = 0.754 +- 0.319 (in-sample avg dev_std = 0.496)
NEC for r=0.9 all L1 = 0.587 +- 0.268 (in-sample avg dev_std = 0.496)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.401
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.449
NEC for r=1.0 class 0 = 0.561 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 1 = 0.236 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 2 = 0.658 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 3 = 0.662 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 4 = 0.617 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 5 = 0.702 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 6 = 0.682 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 7 = 0.556 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 8 = 0.587 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 class 9 = 0.646 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 all KL = 0.735 +- 0.311 (in-sample avg dev_std = 0.477)
NEC for r=1.0 all L1 = 0.584 +- 0.260 (in-sample avg dev_std = 0.477)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.497 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 1 = 0.458 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 2 = 0.59 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 3 = 0.521 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 4 = 0.545 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 5 = 0.525 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 6 = 0.498 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 7 = 0.562 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 8 = 0.562 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 9 = 0.519 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 all KL = 0.49 +- 0.254 (in-sample avg dev_std = 0.311)
NEC for r=0.3 all L1 = 0.527 +- 0.175 (in-sample avg dev_std = 0.311)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.176
NEC for r=0.6 class 0 = 0.697 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 1 = 0.386 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 2 = 0.656 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 3 = 0.607 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 4 = 0.448 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 5 = 0.617 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 6 = 0.534 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 7 = 0.468 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 8 = 0.58 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 class 9 = 0.355 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all KL = 0.741 +- 0.338 (in-sample avg dev_std = 0.469)
NEC for r=0.6 all L1 = 0.534 +- 0.282 (in-sample avg dev_std = 0.469)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.16
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.183
NEC for r=0.9 class 0 = 0.695 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 1 = 0.412 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 2 = 0.649 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 3 = 0.628 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 4 = 0.436 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 5 = 0.642 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 6 = 0.592 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 7 = 0.581 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 8 = 0.633 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 9 = 0.38 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all KL = 0.737 +- 0.342 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all L1 = 0.564 +- 0.280 (in-sample avg dev_std = 0.487)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.161
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.187
NEC for r=1.0 class 0 = 0.692 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 1 = 0.387 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 2 = 0.661 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 3 = 0.627 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 4 = 0.454 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 5 = 0.642 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 6 = 0.577 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 7 = 0.578 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 8 = 0.628 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 9 = 0.399 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 all KL = 0.722 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 all L1 = 0.563 +- 0.276 (in-sample avg dev_std = 0.464)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.231, 0.129, 0.119, 1.0], 'all_L1': [0.338, 0.323, 0.357, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.313, 0.147, 0.122, 1.0], 'all_L1': [0.418, 0.311, 0.304, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.201, 0.086, 0.085, 1.0], 'all_L1': [0.312, 0.283, 0.294, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.303, 0.093, 0.128, 1.0], 'all_L1': [0.342, 0.277, 0.299, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.266, 0.09, 0.09, 1.0], 'all_L1': [0.338, 0.294, 0.309, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.542, 0.683, 0.672, 0.662], 'all_L1': [0.519, 0.551, 0.517, 0.524]}), defaultdict(<class 'list'>, {'all_KL': [0.442, 0.737, 0.694, 0.668], 'all_L1': [0.449, 0.614, 0.572, 0.563]}), defaultdict(<class 'list'>, {'all_KL': [0.563, 0.76, 0.711, 0.695], 'all_L1': [0.54, 0.62, 0.585, 0.582]}), defaultdict(<class 'list'>, {'all_KL': [0.512, 0.736, 0.71, 0.692], 'all_L1': [0.536, 0.606, 0.581, 0.582]}), defaultdict(<class 'list'>, {'all_KL': [0.508, 0.78, 0.754, 0.735], 'all_L1': [0.51, 0.617, 0.587, 0.584]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.471, 0.141, 0.086, 1.0], 'all_L1': [0.432, 0.285, 0.316, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.46, 0.105, 0.079, 1.0], 'all_L1': [0.466, 0.267, 0.292, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.367, 0.062, 0.039, 1.0], 'all_L1': [0.414, 0.26, 0.255, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.531, 0.168, 0.172, 1.0], 'all_L1': [0.473, 0.306, 0.367, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.319, 0.027, 0.182, 1.0], 'all_L1': [0.348, 0.288, 0.422, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.348, 0.668, 0.789, 0.839], 'all_L1': [0.434, 0.602, 0.646, 0.658]}), defaultdict(<class 'list'>, {'all_KL': [0.436, 0.766, 0.84, 0.829], 'all_L1': [0.475, 0.654, 0.656, 0.636]}), defaultdict(<class 'list'>, {'all_KL': [0.487, 0.765, 0.762, 0.73], 'all_L1': [0.486, 0.606, 0.635, 0.624]}), defaultdict(<class 'list'>, {'all_KL': [0.313, 0.615, 0.731, 0.7], 'all_L1': [0.422, 0.558, 0.591, 0.554]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.741, 0.737, 0.722], 'all_L1': [0.527, 0.534, 0.564, 0.563]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.350 +- 0.036, 0.298 +- 0.017, 0.313 +- 0.023, 1.000 +- 0.000
suff++ class all_KL  =  0.263 +- 0.042, 0.109 +- 0.024, 0.109 +- 0.018, 1.000 +- 0.000
suff++_acc_int  =  0.100 +- 0.010, 0.206 +- 0.008, 0.268 +- 0.013
nec class all_L1  =  0.511 +- 0.033, 0.602 +- 0.026, 0.568 +- 0.026, 0.567 +- 0.023
nec class all_KL  =  0.513 +- 0.041, 0.739 +- 0.032, 0.708 +- 0.027, 0.690 +- 0.026
nec_acc_int  =  0.111 +- 0.014, 0.267 +- 0.016, 0.416 +- 0.029, 0.428 +- 0.028

Eval split test
suff++ class all_L1  =  0.427 +- 0.045, 0.281 +- 0.016, 0.330 +- 0.058, 1.000 +- 0.000
suff++ class all_KL  =  0.430 +- 0.076, 0.101 +- 0.051, 0.112 +- 0.056, 1.000 +- 0.000
suff++_acc_int  =  0.110 +- 0.009, 0.177 +- 0.014, 0.168 +- 0.025
nec class all_L1  =  0.469 +- 0.038, 0.591 +- 0.042, 0.618 +- 0.035, 0.607 +- 0.041
nec class all_KL  =  0.415 +- 0.072, 0.711 +- 0.060, 0.772 +- 0.040, 0.764 +- 0.058
nec_acc_int  =  0.118 +- 0.010, 0.227 +- 0.027, 0.223 +- 0.034, 0.216 +- 0.032


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.430 +- 0.005, 0.450 +- 0.009, 0.440 +- 0.004, 0.783 +- 0.011
Faith. Armon (L1)= 		  =  0.412 +- 0.012, 0.397 +- 0.012, 0.402 +- 0.011, 0.723 +- 0.019
Faith. GMean (L1)= 	  =  0.421 +- 0.008, 0.423 +- 0.009, 0.421 +- 0.006, 0.753 +- 0.015
Faith. Aritm (KL)= 		  =  0.388 +- 0.010, 0.424 +- 0.013, 0.409 +- 0.011, 0.845 +- 0.013
Faith. Armon (KL)= 		  =  0.343 +- 0.030, 0.189 +- 0.036, 0.188 +- 0.026, 0.817 +- 0.018
Faith. GMean (KL)= 	  =  0.365 +- 0.019, 0.282 +- 0.028, 0.276 +- 0.020, 0.831 +- 0.015

Eval split test
Faith. Aritm (L1)= 		  =  0.448 +- 0.013, 0.436 +- 0.016, 0.474 +- 0.016, 0.803 +- 0.021
Faith. Armon (L1)= 		  =  0.443 +- 0.017, 0.380 +- 0.011, 0.426 +- 0.041, 0.755 +- 0.032
Faith. GMean (L1)= 	  =  0.445 +- 0.015, 0.407 +- 0.010, 0.449 +- 0.029, 0.779 +- 0.027
Faith. Aritm (KL)= 		  =  0.422 +- 0.015, 0.406 +- 0.018, 0.442 +- 0.022, 0.882 +- 0.029
Faith. Armon (KL)= 		  =  0.409 +- 0.022, 0.170 +- 0.077, 0.189 +- 0.084, 0.865 +- 0.037
Faith. GMean (KL)= 	  =  0.416 +- 0.018, 0.254 +- 0.067, 0.282 +- 0.071, 0.873 +- 0.033
Computed for split load_split = id



Completed in  1:11:01.011503  for GSATGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color
big_random.sh: line 55: --mitigation_expl_scores: command not found
