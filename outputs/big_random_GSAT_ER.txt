Time to compute metrics for random explanations!
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:15:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:15:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.9301
Train Loss: 0.3224
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.3055
ID Test ACCURACY: 0.9257
ID Test Loss: 0.3402
OOD Validation ACCURACY: 0.7387
OOD Validation Loss: 0.6602
OOD Test ACCURACY: 0.6417
OOD Test Loss: 1.1222

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 28...
[0m[1;37mINFO[0m: [1mCheckpoint 28: 
-----------------------------------
Train ACCURACY: 0.9281
Train Loss: 0.3370
ID Validation ACCURACY: 0.9327
ID Validation Loss: 0.3225
ID Test ACCURACY: 0.9240
ID Test Loss: 0.3558
OOD Validation ACCURACY: 0.9200
OOD Validation Loss: 0.4528
OOD Test ACCURACY: 0.6980
OOD Test Loss: 1.4036

[0m[1;37mINFO[0m: [1mChartInfo 0.9257 0.6417 0.9240 0.6980 0.9327 0.9200[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.178
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.254
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.303
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.167
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.221
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.247
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.425
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17824500000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.356
SUFF++ for r=0.3 class 0 = 0.407 +- 0.258 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 1 = 0.467 +- 0.258 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 class 2 = 0.384 +- 0.258 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all KL = 0.318 +- 0.258 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.3 all L1 = 0.42 +- 0.159 (in-sample avg dev_std = 0.567)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.709
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.253535
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.418
SUFF++ for r=0.6 class 0 = 0.392 +- 0.297 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 1 = 0.653 +- 0.297 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 2 = 0.349 +- 0.297 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all KL = 0.375 +- 0.297 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all L1 = 0.466 +- 0.218 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30298875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.724
SUFF++ for r=0.9 class 0 = 0.576 +- 0.314 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.9 class 1 = 0.749 +- 0.314 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.9 class 2 = 0.603 +- 0.314 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.9 all KL = 0.643 +- 0.314 (in-sample avg dev_std = 0.426)
SUFF++ for r=0.9 all L1 = 0.643 +- 0.245 (in-sample avg dev_std = 0.426)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.496
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16659875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.421
SUFF++ for r=0.3 class 0 = 0.402 +- 0.252 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 class 1 = 0.551 +- 0.252 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 class 2 = 0.424 +- 0.252 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all KL = 0.342 +- 0.252 (in-sample avg dev_std = 0.588)
SUFF++ for r=0.3 all L1 = 0.46 +- 0.162 (in-sample avg dev_std = 0.588)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.755
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22086750000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.472
SUFF++ for r=0.6 class 0 = 0.441 +- 0.282 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 class 1 = 0.67 +- 0.282 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 class 2 = 0.383 +- 0.282 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 all KL = 0.462 +- 0.282 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 all L1 = 0.5 +- 0.212 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24707374999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.621
SUFF++ for r=0.9 class 0 = 0.451 +- 0.315 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.9 class 1 = 0.68 +- 0.315 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.9 class 2 = 0.644 +- 0.315 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.9 all KL = 0.593 +- 0.315 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.9 all L1 = 0.594 +- 0.226 (in-sample avg dev_std = 0.414)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.424
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17824500000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.394
NEC for r=0.3 class 0 = 0.597 +- 0.312 (in-sample avg dev_std = 0.514)
NEC for r=0.3 class 1 = 0.501 +- 0.312 (in-sample avg dev_std = 0.514)
NEC for r=0.3 class 2 = 0.538 +- 0.312 (in-sample avg dev_std = 0.514)
NEC for r=0.3 all KL = 0.629 +- 0.312 (in-sample avg dev_std = 0.514)
NEC for r=0.3 all L1 = 0.545 +- 0.213 (in-sample avg dev_std = 0.514)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.253535
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.467
NEC for r=0.6 class 0 = 0.564 +- 0.308 (in-sample avg dev_std = 0.567)
NEC for r=0.6 class 1 = 0.39 +- 0.308 (in-sample avg dev_std = 0.567)
NEC for r=0.6 class 2 = 0.612 +- 0.308 (in-sample avg dev_std = 0.567)
NEC for r=0.6 all KL = 0.604 +- 0.308 (in-sample avg dev_std = 0.567)
NEC for r=0.6 all L1 = 0.521 +- 0.211 (in-sample avg dev_std = 0.567)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30298875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.524
NEC for r=0.9 class 0 = 0.611 +- 0.242 (in-sample avg dev_std = 0.615)
NEC for r=0.9 class 1 = 0.448 +- 0.242 (in-sample avg dev_std = 0.615)
NEC for r=0.9 class 2 = 0.571 +- 0.242 (in-sample avg dev_std = 0.615)
NEC for r=0.9 all KL = 0.624 +- 0.242 (in-sample avg dev_std = 0.615)
NEC for r=0.9 all L1 = 0.543 +- 0.173 (in-sample avg dev_std = 0.615)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30962
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.559
NEC for r=1.0 class 0 = 0.553 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 1 = 0.407 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 2 = 0.591 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all KL = 0.598 +- 0.244 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all L1 = 0.516 +- 0.181 (in-sample avg dev_std = 0.655)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.495
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16659875
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.494
NEC for r=0.3 class 0 = 0.576 +- 0.286 (in-sample avg dev_std = 0.581)
NEC for r=0.3 class 1 = 0.399 +- 0.286 (in-sample avg dev_std = 0.581)
NEC for r=0.3 class 2 = 0.494 +- 0.286 (in-sample avg dev_std = 0.581)
NEC for r=0.3 all KL = 0.581 +- 0.286 (in-sample avg dev_std = 0.581)
NEC for r=0.3 all L1 = 0.488 +- 0.208 (in-sample avg dev_std = 0.581)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.755
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22086750000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.551
NEC for r=0.6 class 0 = 0.562 +- 0.282 (in-sample avg dev_std = 0.573)
NEC for r=0.6 class 1 = 0.336 +- 0.282 (in-sample avg dev_std = 0.573)
NEC for r=0.6 class 2 = 0.563 +- 0.282 (in-sample avg dev_std = 0.573)
NEC for r=0.6 all KL = 0.546 +- 0.282 (in-sample avg dev_std = 0.573)
NEC for r=0.6 all L1 = 0.485 +- 0.199 (in-sample avg dev_std = 0.573)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24707374999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.552
NEC for r=0.9 class 0 = 0.624 +- 0.317 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 1 = 0.415 +- 0.317 (in-sample avg dev_std = 0.573)
NEC for r=0.9 class 2 = 0.477 +- 0.317 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all KL = 0.577 +- 0.317 (in-sample avg dev_std = 0.573)
NEC for r=0.9 all L1 = 0.503 +- 0.193 (in-sample avg dev_std = 0.573)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.665
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.2517125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.566
NEC for r=1.0 class 0 = 0.528 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 1 = 0.407 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 class 2 = 0.377 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all KL = 0.463 +- 0.272 (in-sample avg dev_std = 0.531)
NEC for r=1.0 all L1 = 0.436 +- 0.166 (in-sample avg dev_std = 0.531)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:18:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:18:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9294
Train Loss: 0.3188
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3050
ID Test ACCURACY: 0.9253
ID Test Loss: 0.3427
OOD Validation ACCURACY: 0.9233
OOD Validation Loss: 0.3537
OOD Test ACCURACY: 0.5027
OOD Test Loss: 1.2959

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ACCURACY: 0.9271
Train Loss: 0.3300
ID Validation ACCURACY: 0.9323
ID Validation Loss: 0.3113
ID Test ACCURACY: 0.9240
ID Test Loss: 0.3472
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.3600
OOD Test ACCURACY: 0.5900
OOD Test Loss: 1.4067

[0m[1;37mINFO[0m: [1mChartInfo 0.9253 0.5027 0.9240 0.5900 0.9323 0.9297[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.181
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.256
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.301
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.168
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.217
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.244
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.424
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18138625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.353
SUFF++ for r=0.3 class 0 = 0.398 +- 0.283 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.387 +- 0.283 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.417 +- 0.283 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.339 +- 0.283 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.401 +- 0.136 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.671
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.255525
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.413
SUFF++ for r=0.6 class 0 = 0.423 +- 0.276 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 class 1 = 0.537 +- 0.276 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 class 2 = 0.356 +- 0.276 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 all KL = 0.361 +- 0.276 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.6 all L1 = 0.439 +- 0.158 (in-sample avg dev_std = 0.552)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30062625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.707
SUFF++ for r=0.9 class 0 = 0.563 +- 0.315 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 class 1 = 0.687 +- 0.315 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 class 2 = 0.628 +- 0.315 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 all KL = 0.63 +- 0.315 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.9 all L1 = 0.626 +- 0.242 (in-sample avg dev_std = 0.416)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16801375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.391
SUFF++ for r=0.3 class 0 = 0.422 +- 0.282 (in-sample avg dev_std = 0.561)
SUFF++ for r=0.3 class 1 = 0.505 +- 0.282 (in-sample avg dev_std = 0.561)
SUFF++ for r=0.3 class 2 = 0.351 +- 0.282 (in-sample avg dev_std = 0.561)
SUFF++ for r=0.3 all KL = 0.397 +- 0.282 (in-sample avg dev_std = 0.561)
SUFF++ for r=0.3 all L1 = 0.427 +- 0.131 (in-sample avg dev_std = 0.561)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21686875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.453
SUFF++ for r=0.6 class 0 = 0.464 +- 0.273 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.592 +- 0.273 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.393 +- 0.273 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.489 +- 0.273 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.484 +- 0.168 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.645
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24409124999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.613
SUFF++ for r=0.9 class 0 = 0.479 +- 0.310 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 1 = 0.628 +- 0.310 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 class 2 = 0.643 +- 0.310 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all KL = 0.602 +- 0.310 (in-sample avg dev_std = 0.411)
SUFF++ for r=0.9 all L1 = 0.585 +- 0.222 (in-sample avg dev_std = 0.411)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.42
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18138625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.364
NEC for r=0.3 class 0 = 0.597 +- 0.311 (in-sample avg dev_std = 0.523)
NEC for r=0.3 class 1 = 0.568 +- 0.311 (in-sample avg dev_std = 0.523)
NEC for r=0.3 class 2 = 0.492 +- 0.311 (in-sample avg dev_std = 0.523)
NEC for r=0.3 all KL = 0.607 +- 0.311 (in-sample avg dev_std = 0.523)
NEC for r=0.3 all L1 = 0.553 +- 0.197 (in-sample avg dev_std = 0.523)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.255525
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.439
NEC for r=0.6 class 0 = 0.564 +- 0.275 (in-sample avg dev_std = 0.575)
NEC for r=0.6 class 1 = 0.516 +- 0.275 (in-sample avg dev_std = 0.575)
NEC for r=0.6 class 2 = 0.577 +- 0.275 (in-sample avg dev_std = 0.575)
NEC for r=0.6 all KL = 0.627 +- 0.275 (in-sample avg dev_std = 0.575)
NEC for r=0.6 all L1 = 0.552 +- 0.173 (in-sample avg dev_std = 0.575)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.928
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30062625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.517
NEC for r=0.9 class 0 = 0.588 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 class 1 = 0.502 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 class 2 = 0.544 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 all KL = 0.62 +- 0.242 (in-sample avg dev_std = 0.633)
NEC for r=0.9 all L1 = 0.544 +- 0.162 (in-sample avg dev_std = 0.633)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.3097075
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.539
NEC for r=1.0 class 0 = 0.553 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 class 1 = 0.475 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 class 2 = 0.562 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 all KL = 0.598 +- 0.237 (in-sample avg dev_std = 0.658)
NEC for r=1.0 all L1 = 0.53 +- 0.167 (in-sample avg dev_std = 0.658)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16801375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.425
NEC for r=0.3 class 0 = 0.549 +- 0.305 (in-sample avg dev_std = 0.540)
NEC for r=0.3 class 1 = 0.407 +- 0.305 (in-sample avg dev_std = 0.540)
NEC for r=0.3 class 2 = 0.547 +- 0.305 (in-sample avg dev_std = 0.540)
NEC for r=0.3 all KL = 0.523 +- 0.305 (in-sample avg dev_std = 0.540)
NEC for r=0.3 all L1 = 0.5 +- 0.192 (in-sample avg dev_std = 0.540)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.688
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21686875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.504
NEC for r=0.6 class 0 = 0.556 +- 0.268 (in-sample avg dev_std = 0.546)
NEC for r=0.6 class 1 = 0.379 +- 0.268 (in-sample avg dev_std = 0.546)
NEC for r=0.6 class 2 = 0.516 +- 0.268 (in-sample avg dev_std = 0.546)
NEC for r=0.6 all KL = 0.484 +- 0.268 (in-sample avg dev_std = 0.546)
NEC for r=0.6 all L1 = 0.482 +- 0.173 (in-sample avg dev_std = 0.546)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.645
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24409124999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.547
NEC for r=0.9 class 0 = 0.57 +- 0.303 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 1 = 0.453 +- 0.303 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 2 = 0.472 +- 0.303 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all KL = 0.536 +- 0.303 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all L1 = 0.497 +- 0.170 (in-sample avg dev_std = 0.550)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.526
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25152499999999994
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.504
NEC for r=1.0 class 0 = 0.464 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 1 = 0.465 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 class 2 = 0.312 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all KL = 0.44 +- 0.242 (in-sample avg dev_std = 0.478)
NEC for r=1.0 all L1 = 0.414 +- 0.166 (in-sample avg dev_std = 0.478)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:21:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:21:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9308
Train Loss: 0.3191
ID Validation ACCURACY: 0.9370
ID Validation Loss: 0.3044
ID Test ACCURACY: 0.9263
ID Test Loss: 0.3380
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.3803
OOD Test ACCURACY: 0.6390
OOD Test Loss: 1.0273

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 41...
[0m[1;37mINFO[0m: [1mCheckpoint 41: 
-----------------------------------
Train ACCURACY: 0.9197
Train Loss: 0.3431
ID Validation ACCURACY: 0.9267
ID Validation Loss: 0.3258
ID Test ACCURACY: 0.9177
ID Test Loss: 0.3707
OOD Validation ACCURACY: 0.9290
OOD Validation Loss: 0.3668
OOD Test ACCURACY: 0.7483
OOD Test Loss: 1.8033

[0m[1;37mINFO[0m: [1mChartInfo 0.9263 0.6390 0.9177 0.7483 0.9267 0.9290[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.194
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.261
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.304
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.164
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.218
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.245
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.442
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19406500000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.362 +- 0.245 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 1 = 0.403 +- 0.245 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 class 2 = 0.397 +- 0.245 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all KL = 0.341 +- 0.245 (in-sample avg dev_std = 0.555)
SUFF++ for r=0.3 all L1 = 0.387 +- 0.120 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26057625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.419
SUFF++ for r=0.6 class 0 = 0.394 +- 0.269 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 1 = 0.51 +- 0.269 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 2 = 0.365 +- 0.269 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all KL = 0.364 +- 0.269 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all L1 = 0.424 +- 0.160 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.712
SUFF++ for r=0.9 class 0 = 0.559 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 class 1 = 0.695 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 class 2 = 0.597 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 all KL = 0.625 +- 0.297 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 all L1 = 0.617 +- 0.227 (in-sample avg dev_std = 0.441)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.477
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16373625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.409
SUFF++ for r=0.3 class 0 = 0.424 +- 0.229 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 1 = 0.39 +- 0.229 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 2 = 0.354 +- 0.229 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all KL = 0.296 +- 0.229 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all L1 = 0.389 +- 0.115 (in-sample avg dev_std = 0.617)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21842750000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.461
SUFF++ for r=0.6 class 0 = 0.432 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 class 1 = 0.563 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 class 2 = 0.373 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 all KL = 0.419 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 all L1 = 0.457 +- 0.162 (in-sample avg dev_std = 0.535)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.724
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24538374999999996
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.623
SUFF++ for r=0.9 class 0 = 0.443 +- 0.283 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 class 1 = 0.681 +- 0.283 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 class 2 = 0.661 +- 0.283 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 all KL = 0.643 +- 0.283 (in-sample avg dev_std = 0.377)
SUFF++ for r=0.9 all L1 = 0.597 +- 0.209 (in-sample avg dev_std = 0.377)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.44
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.19406500000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.658 +- 0.302 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 1 = 0.518 +- 0.302 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 2 = 0.525 +- 0.302 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all KL = 0.601 +- 0.302 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all L1 = 0.567 +- 0.205 (in-sample avg dev_std = 0.496)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26057625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.432
NEC for r=0.6 class 0 = 0.578 +- 0.266 (in-sample avg dev_std = 0.568)
NEC for r=0.6 class 1 = 0.511 +- 0.266 (in-sample avg dev_std = 0.568)
NEC for r=0.6 class 2 = 0.598 +- 0.266 (in-sample avg dev_std = 0.568)
NEC for r=0.6 all KL = 0.622 +- 0.266 (in-sample avg dev_std = 0.568)
NEC for r=0.6 all L1 = 0.562 +- 0.155 (in-sample avg dev_std = 0.568)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.934
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.30375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.52
NEC for r=0.9 class 0 = 0.598 +- 0.232 (in-sample avg dev_std = 0.638)
NEC for r=0.9 class 1 = 0.504 +- 0.232 (in-sample avg dev_std = 0.638)
NEC for r=0.9 class 2 = 0.567 +- 0.232 (in-sample avg dev_std = 0.638)
NEC for r=0.9 all KL = 0.621 +- 0.232 (in-sample avg dev_std = 0.638)
NEC for r=0.9 all L1 = 0.556 +- 0.157 (in-sample avg dev_std = 0.638)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31012875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.553 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 class 1 = 0.459 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 class 2 = 0.559 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 all KL = 0.567 +- 0.225 (in-sample avg dev_std = 0.641)
NEC for r=1.0 all L1 = 0.523 +- 0.163 (in-sample avg dev_std = 0.641)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.48
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16373625
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.483
NEC for r=0.3 class 0 = 0.599 +- 0.285 (in-sample avg dev_std = 0.591)
NEC for r=0.3 class 1 = 0.525 +- 0.285 (in-sample avg dev_std = 0.591)
NEC for r=0.3 class 2 = 0.55 +- 0.285 (in-sample avg dev_std = 0.591)
NEC for r=0.3 all KL = 0.638 +- 0.285 (in-sample avg dev_std = 0.591)
NEC for r=0.3 all L1 = 0.557 +- 0.203 (in-sample avg dev_std = 0.591)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.775
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21842750000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.52
NEC for r=0.6 class 0 = 0.561 +- 0.285 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 1 = 0.448 +- 0.285 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 2 = 0.549 +- 0.285 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all KL = 0.567 +- 0.285 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all L1 = 0.518 +- 0.165 (in-sample avg dev_std = 0.593)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.724
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24538374999999996
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.551
NEC for r=0.9 class 0 = 0.592 +- 0.301 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 1 = 0.427 +- 0.301 (in-sample avg dev_std = 0.526)
NEC for r=0.9 class 2 = 0.457 +- 0.301 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all KL = 0.494 +- 0.301 (in-sample avg dev_std = 0.526)
NEC for r=0.9 all L1 = 0.491 +- 0.176 (in-sample avg dev_std = 0.526)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.66
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25159624999999997
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.488 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 1 = 0.411 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 class 2 = 0.384 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all KL = 0.404 +- 0.259 (in-sample avg dev_std = 0.475)
NEC for r=1.0 all L1 = 0.427 +- 0.151 (in-sample avg dev_std = 0.475)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:24:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:24:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9309
Train Loss: 0.3182
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.3060
ID Test ACCURACY: 0.9263
ID Test Loss: 0.3404
OOD Validation ACCURACY: 0.9267
OOD Validation Loss: 0.3565
OOD Test ACCURACY: 0.7483
OOD Test Loss: 0.8473

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 44...
[0m[1;37mINFO[0m: [1mCheckpoint 44: 
-----------------------------------
Train ACCURACY: 0.9266
Train Loss: 0.3333
ID Validation ACCURACY: 0.9320
ID Validation Loss: 0.3169
ID Test ACCURACY: 0.9243
ID Test Loss: 0.3533
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.3816
OOD Test ACCURACY: 0.7223
OOD Test Loss: 1.4805

[0m[1;37mINFO[0m: [1mChartInfo 0.9263 0.7483 0.9243 0.7223 0.9320 0.9297[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.182
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.252
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.298
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.309
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.172
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.221
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.246
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.412
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18218125000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.356
SUFF++ for r=0.3 class 0 = 0.395 +- 0.263 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 1 = 0.365 +- 0.263 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 class 2 = 0.412 +- 0.263 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all KL = 0.375 +- 0.263 (in-sample avg dev_std = 0.503)
SUFF++ for r=0.3 all L1 = 0.391 +- 0.121 (in-sample avg dev_std = 0.503)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.735
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25161625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.415
SUFF++ for r=0.6 class 0 = 0.418 +- 0.247 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 1 = 0.507 +- 0.247 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 2 = 0.363 +- 0.247 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all KL = 0.363 +- 0.247 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all L1 = 0.43 +- 0.155 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.926
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29760875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0 = 0.556 +- 0.283 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 class 1 = 0.683 +- 0.283 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 class 2 = 0.575 +- 0.283 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 all KL = 0.634 +- 0.283 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.9 all L1 = 0.605 +- 0.226 (in-sample avg dev_std = 0.430)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.415
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17188375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.386
SUFF++ for r=0.3 class 0 = 0.393 +- 0.268 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 class 1 = 0.446 +- 0.268 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 class 2 = 0.36 +- 0.268 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 all KL = 0.374 +- 0.268 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.3 all L1 = 0.4 +- 0.138 (in-sample avg dev_std = 0.544)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.686
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22082125000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.437
SUFF++ for r=0.6 class 0 = 0.461 +- 0.245 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 class 1 = 0.539 +- 0.245 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 class 2 = 0.392 +- 0.245 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all KL = 0.5 +- 0.245 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all L1 = 0.465 +- 0.153 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.636
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2461025
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.587
SUFF++ for r=0.9 class 0 = 0.519 +- 0.267 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 class 1 = 0.643 +- 0.267 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 class 2 = 0.634 +- 0.267 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 all KL = 0.636 +- 0.267 (in-sample avg dev_std = 0.404)
SUFF++ for r=0.9 all L1 = 0.6 +- 0.188 (in-sample avg dev_std = 0.404)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.411
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18218125000000002
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.373
NEC for r=0.3 class 0 = 0.63 +- 0.282 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 1 = 0.59 +- 0.282 (in-sample avg dev_std = 0.482)
NEC for r=0.3 class 2 = 0.511 +- 0.282 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all KL = 0.595 +- 0.282 (in-sample avg dev_std = 0.482)
NEC for r=0.3 all L1 = 0.577 +- 0.177 (in-sample avg dev_std = 0.482)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.735
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.25161625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.456
NEC for r=0.6 class 0 = 0.558 +- 0.267 (in-sample avg dev_std = 0.563)
NEC for r=0.6 class 1 = 0.493 +- 0.267 (in-sample avg dev_std = 0.563)
NEC for r=0.6 class 2 = 0.586 +- 0.267 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all KL = 0.599 +- 0.267 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all L1 = 0.546 +- 0.176 (in-sample avg dev_std = 0.563)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.929
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29760875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.546
NEC for r=0.9 class 0 = 0.554 +- 0.224 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 1 = 0.488 +- 0.224 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 2 = 0.549 +- 0.224 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all KL = 0.551 +- 0.224 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all L1 = 0.53 +- 0.151 (in-sample avg dev_std = 0.588)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.30948
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.542
NEC for r=1.0 class 0 = 0.549 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 class 1 = 0.468 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 class 2 = 0.565 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 all KL = 0.575 +- 0.234 (in-sample avg dev_std = 0.646)
NEC for r=1.0 all L1 = 0.527 +- 0.167 (in-sample avg dev_std = 0.646)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.425
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.17188375
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.442
NEC for r=0.3 class 0 = 0.61 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.3 class 1 = 0.49 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.3 class 2 = 0.561 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.3 all KL = 0.589 +- 0.292 (in-sample avg dev_std = 0.557)
NEC for r=0.3 all L1 = 0.553 +- 0.184 (in-sample avg dev_std = 0.557)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.686
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.22082125000000002
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.522
NEC for r=0.6 class 0 = 0.525 +- 0.255 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 1 = 0.415 +- 0.255 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 2 = 0.541 +- 0.255 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all KL = 0.457 +- 0.255 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all L1 = 0.493 +- 0.167 (in-sample avg dev_std = 0.521)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.636
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.2461025
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.571 +- 0.284 (in-sample avg dev_std = 0.539)
NEC for r=0.9 class 1 = 0.433 +- 0.284 (in-sample avg dev_std = 0.539)
NEC for r=0.9 class 2 = 0.498 +- 0.284 (in-sample avg dev_std = 0.539)
NEC for r=0.9 all KL = 0.52 +- 0.284 (in-sample avg dev_std = 0.539)
NEC for r=0.9 all L1 = 0.499 +- 0.170 (in-sample avg dev_std = 0.539)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.751
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25167125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0 = 0.504 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 class 1 = 0.405 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 class 2 = 0.419 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 all KL = 0.431 +- 0.269 (in-sample avg dev_std = 0.494)
NEC for r=1.0 all L1 = 0.441 +- 0.155 (in-sample avg dev_std = 0.494)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:27:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:27:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9288
Train Loss: 0.3202
ID Validation ACCURACY: 0.9347
ID Validation Loss: 0.3069
ID Test ACCURACY: 0.9253
ID Test Loss: 0.3425
OOD Validation ACCURACY: 0.9070
OOD Validation Loss: 0.4360
OOD Test ACCURACY: 0.6230
OOD Test Loss: 1.1103

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 61...
[0m[1;37mINFO[0m: [1mCheckpoint 61: 
-----------------------------------
Train ACCURACY: 0.9275
Train Loss: 0.3347
ID Validation ACCURACY: 0.9320
ID Validation Loss: 0.3170
ID Test ACCURACY: 0.9240
ID Test Loss: 0.3484
OOD Validation ACCURACY: 0.9283
OOD Validation Loss: 0.3823
OOD Test ACCURACY: 0.6687
OOD Test Loss: 1.1273

[0m[1;37mINFO[0m: [1mChartInfo 0.9253 0.6230 0.9240 0.6687 0.9320 0.9283[0mGOODMotif2(3000)
Data example from id_val: Data(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
Label distribution from id_val: (tensor([0, 1, 2]), tensor([1002, 1009,  989]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument lr_filternod in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.188
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.264
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.300
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.310
GOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.167
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.218
F1 for r=0.9 = 0.000
WIoU for r=0.9 = 0.245
F1 for r=1.0 = 0.000
WIoU for r=1.0 = 0.252


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.436
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18769249999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
SUFF++ for r=0.3 class 0 = 0.363 +- 0.235 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 1 = 0.409 +- 0.235 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 2 = 0.381 +- 0.235 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all KL = 0.336 +- 0.235 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all L1 = 0.384 +- 0.115 (in-sample avg dev_std = 0.586)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.694
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26386625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.426
SUFF++ for r=0.6 class 0 = 0.403 +- 0.277 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 1 = 0.559 +- 0.277 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 2 = 0.372 +- 0.277 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all KL = 0.391 +- 0.277 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all L1 = 0.445 +- 0.174 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29982624999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.694
SUFF++ for r=0.9 class 0 = 0.548 +- 0.300 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 class 1 = 0.652 +- 0.300 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 class 2 = 0.618 +- 0.300 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 all KL = 0.611 +- 0.300 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.9 all L1 = 0.606 +- 0.224 (in-sample avg dev_std = 0.441)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16737125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.408
SUFF++ for r=0.3 class 0 = 0.382 +- 0.226 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 class 1 = 0.431 +- 0.226 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 class 2 = 0.335 +- 0.226 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all KL = 0.285 +- 0.226 (in-sample avg dev_std = 0.602)
SUFF++ for r=0.3 all L1 = 0.383 +- 0.114 (in-sample avg dev_std = 0.602)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21843625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.474
SUFF++ for r=0.6 class 0 = 0.408 +- 0.263 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.6 class 1 = 0.604 +- 0.263 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.6 class 2 = 0.367 +- 0.263 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.6 all KL = 0.428 +- 0.263 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.6 all L1 = 0.461 +- 0.179 (in-sample avg dev_std = 0.521)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24522624999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.668
SUFF++ for r=0.9 class 0 = 0.464 +- 0.309 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 1 = 0.659 +- 0.309 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 2 = 0.657 +- 0.309 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all KL = 0.6 +- 0.309 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all L1 = 0.595 +- 0.226 (in-sample avg dev_std = 0.421)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.439
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.18769249999999998
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.377
NEC for r=0.3 class 0 = 0.608 +- 0.304 (in-sample avg dev_std = 0.517)
NEC for r=0.3 class 1 = 0.499 +- 0.304 (in-sample avg dev_std = 0.517)
NEC for r=0.3 class 2 = 0.524 +- 0.304 (in-sample avg dev_std = 0.517)
NEC for r=0.3 all KL = 0.571 +- 0.304 (in-sample avg dev_std = 0.517)
NEC for r=0.3 all L1 = 0.544 +- 0.208 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.692
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.26386625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.457
NEC for r=0.6 class 0 = 0.58 +- 0.277 (in-sample avg dev_std = 0.555)
NEC for r=0.6 class 1 = 0.462 +- 0.277 (in-sample avg dev_std = 0.555)
NEC for r=0.6 class 2 = 0.594 +- 0.277 (in-sample avg dev_std = 0.555)
NEC for r=0.6 all KL = 0.599 +- 0.277 (in-sample avg dev_std = 0.555)
NEC for r=0.6 all L1 = 0.545 +- 0.168 (in-sample avg dev_std = 0.555)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.918
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.29982624999999996
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.525
NEC for r=0.9 class 0 = 0.588 +- 0.224 (in-sample avg dev_std = 0.634)
NEC for r=0.9 class 1 = 0.509 +- 0.224 (in-sample avg dev_std = 0.634)
NEC for r=0.9 class 2 = 0.564 +- 0.224 (in-sample avg dev_std = 0.634)
NEC for r=0.9 all KL = 0.618 +- 0.224 (in-sample avg dev_std = 0.634)
NEC for r=0.9 all L1 = 0.553 +- 0.145 (in-sample avg dev_std = 0.634)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.942
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.31004625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.553 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 1 = 0.464 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 class 2 = 0.564 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all KL = 0.597 +- 0.243 (in-sample avg dev_std = 0.655)
NEC for r=1.0 all L1 = 0.527 +- 0.174 (in-sample avg dev_std = 0.655)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.567
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.16737125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.466
NEC for r=0.3 class 0 = 0.617 +- 0.284 (in-sample avg dev_std = 0.565)
NEC for r=0.3 class 1 = 0.464 +- 0.284 (in-sample avg dev_std = 0.565)
NEC for r=0.3 class 2 = 0.552 +- 0.284 (in-sample avg dev_std = 0.565)
NEC for r=0.3 all KL = 0.632 +- 0.284 (in-sample avg dev_std = 0.565)
NEC for r=0.3 all L1 = 0.543 +- 0.208 (in-sample avg dev_std = 0.565)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.795
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.21843625
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.548
NEC for r=0.6 class 0 = 0.549 +- 0.256 (in-sample avg dev_std = 0.591)
NEC for r=0.6 class 1 = 0.402 +- 0.256 (in-sample avg dev_std = 0.591)
NEC for r=0.6 class 2 = 0.55 +- 0.256 (in-sample avg dev_std = 0.591)
NEC for r=0.6 all KL = 0.54 +- 0.256 (in-sample avg dev_std = 0.591)
NEC for r=0.6 all L1 = 0.499 +- 0.168 (in-sample avg dev_std = 0.591)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  0.0
Model XAI WIoU of binarized graphs for r=0.9 =  0.24522624999999998
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.559
NEC for r=0.9 class 0 = 0.597 +- 0.300 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 1 = 0.421 +- 0.300 (in-sample avg dev_std = 0.592)
NEC for r=0.9 class 2 = 0.505 +- 0.300 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all KL = 0.567 +- 0.300 (in-sample avg dev_std = 0.592)
NEC for r=0.9 all L1 = 0.506 +- 0.186 (in-sample avg dev_std = 0.592)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.634
Model XAI F1 of binarized graphs for r=1.0 =  0.0
Model XAI WIoU of binarized graphs for r=1.0 =  0.25165375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.533
NEC for r=1.0 class 0 = 0.469 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 1 = 0.443 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 2 = 0.344 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all KL = 0.417 +- 0.237 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all L1 = 0.418 +- 0.154 (in-sample avg dev_std = 0.458)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.318, 0.375, 0.643, 1.0], 'all_L1': [0.42, 0.466, 0.643, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.339, 0.361, 0.63, 1.0], 'all_L1': [0.401, 0.439, 0.626, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.341, 0.364, 0.625, 1.0], 'all_L1': [0.387, 0.424, 0.617, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.375, 0.363, 0.634, 1.0], 'all_L1': [0.391, 0.43, 0.605, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.336, 0.391, 0.611, 1.0], 'all_L1': [0.384, 0.445, 0.606, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.629, 0.604, 0.624, 0.598], 'all_L1': [0.545, 0.521, 0.543, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.607, 0.627, 0.62, 0.598], 'all_L1': [0.553, 0.552, 0.544, 0.53]}), defaultdict(<class 'list'>, {'all_KL': [0.601, 0.622, 0.621, 0.567], 'all_L1': [0.567, 0.562, 0.556, 0.523]}), defaultdict(<class 'list'>, {'all_KL': [0.595, 0.599, 0.551, 0.575], 'all_L1': [0.577, 0.546, 0.53, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.571, 0.599, 0.618, 0.597], 'all_L1': [0.544, 0.545, 0.553, 0.527]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.342, 0.462, 0.593, 1.0], 'all_L1': [0.46, 0.5, 0.594, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.397, 0.489, 0.602, 1.0], 'all_L1': [0.427, 0.484, 0.585, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.296, 0.419, 0.643, 1.0], 'all_L1': [0.389, 0.457, 0.597, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.374, 0.5, 0.636, 1.0], 'all_L1': [0.4, 0.465, 0.6, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.285, 0.428, 0.6, 1.0], 'all_L1': [0.383, 0.461, 0.595, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.581, 0.546, 0.577, 0.463], 'all_L1': [0.488, 0.485, 0.503, 0.436]}), defaultdict(<class 'list'>, {'all_KL': [0.523, 0.484, 0.536, 0.44], 'all_L1': [0.5, 0.482, 0.497, 0.414]}), defaultdict(<class 'list'>, {'all_KL': [0.638, 0.567, 0.494, 0.404], 'all_L1': [0.557, 0.518, 0.491, 0.427]}), defaultdict(<class 'list'>, {'all_KL': [0.589, 0.457, 0.52, 0.431], 'all_L1': [0.553, 0.493, 0.499, 0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.632, 0.54, 0.567, 0.417], 'all_L1': [0.543, 0.499, 0.506, 0.418]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.397 +- 0.013, 0.441 +- 0.015, 0.619 +- 0.014, 1.000 +- 0.000
suff++ class all_KL  =  0.342 +- 0.018, 0.371 +- 0.011, 0.629 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.354 +- 0.007, 0.418 +- 0.005, 0.703 +- 0.015
nec class all_L1  =  0.557 +- 0.013, 0.545 +- 0.014, 0.545 +- 0.009, 0.525 +- 0.005
nec class all_KL  =  0.601 +- 0.019, 0.610 +- 0.012, 0.607 +- 0.028, 0.587 +- 0.013
nec_acc_int  =  0.374 +- 0.011, 0.450 +- 0.013, 0.527 +- 0.010, 0.545 +- 0.008

Eval split test
suff++ class all_L1  =  0.412 +- 0.028, 0.473 +- 0.016, 0.594 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.339 +- 0.043, 0.460 +- 0.032, 0.615 +- 0.021, 1.000 +- 0.000
suff++_acc_int  =  0.403 +- 0.013, 0.459 +- 0.014, 0.622 +- 0.026
nec class all_L1  =  0.528 +- 0.029, 0.495 +- 0.013, 0.499 +- 0.005, 0.427 +- 0.010
nec class all_KL  =  0.593 +- 0.041, 0.519 +- 0.041, 0.539 +- 0.030, 0.431 +- 0.020
nec_acc_int  =  0.462 +- 0.026, 0.529 +- 0.018, 0.549 +- 0.008, 0.545 +- 0.025


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.477 +- 0.007, 0.493 +- 0.003, 0.582 +- 0.009, 0.762 +- 0.002
Faith. Armon (L1)= 		  =  0.463 +- 0.008, 0.487 +- 0.004, 0.580 +- 0.008, 0.688 +- 0.004
Faith. GMean (L1)= 	  =  0.470 +- 0.007, 0.490 +- 0.003, 0.581 +- 0.008, 0.724 +- 0.003
Faith. Aritm (KL)= 		  =  0.471 +- 0.010, 0.490 +- 0.005, 0.618 +- 0.014, 0.794 +- 0.007
Faith. Armon (KL)= 		  =  0.435 +- 0.014, 0.461 +- 0.007, 0.617 +- 0.015, 0.740 +- 0.011
Faith. GMean (KL)= 	  =  0.453 +- 0.011, 0.476 +- 0.006, 0.617 +- 0.014, 0.766 +- 0.009

Eval split test
Faith. Aritm (L1)= 		  =  0.470 +- 0.006, 0.484 +- 0.005, 0.547 +- 0.004, 0.714 +- 0.005
Faith. Armon (L1)= 		  =  0.461 +- 0.008, 0.484 +- 0.005, 0.543 +- 0.004, 0.599 +- 0.010
Faith. GMean (L1)= 	  =  0.466 +- 0.006, 0.484 +- 0.005, 0.545 +- 0.004, 0.654 +- 0.008
Faith. Aritm (KL)= 		  =  0.466 +- 0.008, 0.489 +- 0.009, 0.577 +- 0.007, 0.715 +- 0.010
Faith. Armon (KL)= 		  =  0.427 +- 0.025, 0.485 +- 0.009, 0.573 +- 0.010, 0.602 +- 0.020
Faith. GMean (KL)= 	  =  0.446 +- 0.016, 0.487 +- 0.008, 0.575 +- 0.008, 0.656 +- 0.015
Computed for split load_split = id



Completed in  0:14:36.374858  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:30:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:30:27 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9472
Train Loss: 0.0807
ID Validation ACCURACY: 0.8638
ID Validation Loss: 0.5569
ID Test ACCURACY: 0.8542
ID Test Loss: 0.6640
OOD Validation ACCURACY: 0.8582
OOD Validation Loss: 1.2856
OOD Test ACCURACY: 0.8136
OOD Test Loss: 3.3019

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ACCURACY: 0.9439
Train Loss: 0.0928
ID Validation ACCURACY: 0.8502
ID Validation Loss: 0.4924
ID Test ACCURACY: 0.8523
ID Test Loss: 0.5678
OOD Validation ACCURACY: 0.8595
OOD Validation Loss: 0.9019
OOD Test ACCURACY: 0.8168
OOD Test Loss: 2.0206

[0m[1;37mINFO[0m: [1mChartInfo 0.8542 0.8136 0.8523 0.8168 0.8502 0.8595[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:30:29 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.803
SUFF++ for r=0.6 class 0.0 = 0.801 +- 0.364 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 1.0 = 0.799 +- 0.364 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all KL = 0.601 +- 0.364 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all L1 = 0.8 +- 0.219 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.853
SUFF++ for r=0.9 class 0.0 = 0.916 +- 0.175 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.175 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all KL = 0.933 +- 0.175 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.9 all L1 = 0.926 +- 0.168 (in-sample avg dev_std = 0.182)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.707
SUFF++ for r=0.3 class 0.0 = 0.712 +- 0.358 (in-sample avg dev_std = 0.716)
SUFF++ for r=0.3 class 1.0 = 0.654 +- 0.358 (in-sample avg dev_std = 0.716)
SUFF++ for r=0.3 all KL = 0.307 +- 0.358 (in-sample avg dev_std = 0.716)
SUFF++ for r=0.3 all L1 = 0.682 +- 0.200 (in-sample avg dev_std = 0.716)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.843 +- 0.418 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 class 1.0 = 0.766 +- 0.418 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all KL = 0.534 +- 0.418 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.6 all L1 = 0.803 +- 0.203 (in-sample avg dev_std = 0.534)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
SUFF++ for r=0.9 class 0.0 = 0.929 +- 0.219 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1.0 = 0.922 +- 0.219 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.888 +- 0.219 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.925 +- 0.147 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.859
NEC for r=0.6 class 0.0 = 0.119 +- 0.277 (in-sample avg dev_std = 0.239)
NEC for r=0.6 class 1.0 = 0.101 +- 0.277 (in-sample avg dev_std = 0.239)
NEC for r=0.6 all KL = 0.134 +- 0.277 (in-sample avg dev_std = 0.239)
NEC for r=0.6 all L1 = 0.108 +- 0.222 (in-sample avg dev_std = 0.239)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.856
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.068 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1.0 = 0.049 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.055 +- 0.160 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.057 +- 0.146 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.867
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.864
NEC for r=1.0 class 0.0 = 0.074 +- 0.162 (in-sample avg dev_std = 0.170)
NEC for r=1.0 class 1.0 = 0.046 +- 0.162 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all KL = 0.057 +- 0.162 (in-sample avg dev_std = 0.170)
NEC for r=1.0 all L1 = 0.057 +- 0.150 (in-sample avg dev_std = 0.170)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.812
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.805
NEC for r=0.3 class 0.0 = 0.11 +- 0.298 (in-sample avg dev_std = 0.279)
NEC for r=0.3 class 1.0 = 0.111 +- 0.298 (in-sample avg dev_std = 0.279)
NEC for r=0.3 all KL = 0.163 +- 0.298 (in-sample avg dev_std = 0.279)
NEC for r=0.3 all L1 = 0.11 +- 0.211 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.817
NEC for r=0.6 class 0.0 = 0.08 +- 0.274 (in-sample avg dev_std = 0.241)
NEC for r=0.6 class 1.0 = 0.094 +- 0.274 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all KL = 0.139 +- 0.274 (in-sample avg dev_std = 0.241)
NEC for r=0.6 all L1 = 0.087 +- 0.175 (in-sample avg dev_std = 0.241)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.83
NEC for r=0.9 class 0.0 = 0.07 +- 0.203 (in-sample avg dev_std = 0.181)
NEC for r=0.9 class 1.0 = 0.068 +- 0.203 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all KL = 0.085 +- 0.203 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all L1 = 0.069 +- 0.154 (in-sample avg dev_std = 0.181)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0.0 = 0.069 +- 0.189 (in-sample avg dev_std = 0.180)
NEC for r=1.0 class 1.0 = 0.066 +- 0.189 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all KL = 0.077 +- 0.189 (in-sample avg dev_std = 0.180)
NEC for r=1.0 all L1 = 0.067 +- 0.158 (in-sample avg dev_std = 0.180)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:32:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 174...
[0m[1;37mINFO[0m: [1mCheckpoint 174: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0755
ID Validation ACCURACY: 0.8640
ID Validation Loss: 0.6847
ID Test ACCURACY: 0.8623
ID Test Loss: 0.7604
OOD Validation ACCURACY: 0.8614
OOD Validation Loss: 1.0820
OOD Test ACCURACY: 0.8157
OOD Test Loss: 2.1369

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0754
ID Validation ACCURACY: 0.8619
ID Validation Loss: 0.7617
ID Test ACCURACY: 0.8598
ID Test Loss: 0.8515
OOD Validation ACCURACY: 0.8642
OOD Validation Loss: 1.0488
OOD Test ACCURACY: 0.8181
OOD Test Loss: 2.0109

[0m[1;37mINFO[0m: [1mChartInfo 0.8623 0.8157 0.8598 0.8181 0.8619 0.8642[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:32:53 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.803
SUFF++ for r=0.6 class 0.0 = 0.727 +- 0.389 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 1.0 = 0.879 +- 0.389 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all KL = 0.653 +- 0.389 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all L1 = 0.816 +- 0.226 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.867
SUFF++ for r=0.9 class 0.0 = 0.94 +- 0.186 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 class 1.0 = 0.937 +- 0.186 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 all KL = 0.932 +- 0.186 (in-sample avg dev_std = 0.187)
SUFF++ for r=0.9 all L1 = 0.938 +- 0.158 (in-sample avg dev_std = 0.187)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.794
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.681
SUFF++ for r=0.3 class 0.0 = 0.559 +- 0.342 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 class 1.0 = 0.735 +- 0.342 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 all KL = 0.304 +- 0.342 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 all L1 = 0.65 +- 0.218 (in-sample avg dev_std = 0.728)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.805
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.76
SUFF++ for r=0.6 class 0.0 = 0.702 +- 0.380 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1.0 = 0.859 +- 0.380 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.56 +- 0.380 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.783 +- 0.220 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.816
SUFF++ for r=0.9 class 0.0 = 0.882 +- 0.207 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.207 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.891 +- 0.207 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.912 +- 0.164 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.826
NEC for r=0.6 class 0.0 = 0.146 +- 0.274 (in-sample avg dev_std = 0.254)
NEC for r=0.6 class 1.0 = 0.076 +- 0.274 (in-sample avg dev_std = 0.254)
NEC for r=0.6 all KL = 0.129 +- 0.274 (in-sample avg dev_std = 0.254)
NEC for r=0.6 all L1 = 0.105 +- 0.212 (in-sample avg dev_std = 0.254)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.863
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.056 +- 0.178 (in-sample avg dev_std = 0.173)
NEC for r=0.9 class 1.0 = 0.055 +- 0.178 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all KL = 0.063 +- 0.178 (in-sample avg dev_std = 0.173)
NEC for r=0.9 all L1 = 0.056 +- 0.151 (in-sample avg dev_std = 0.173)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.86
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0.0 = 0.047 +- 0.183 (in-sample avg dev_std = 0.176)
NEC for r=1.0 class 1.0 = 0.053 +- 0.183 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all KL = 0.06 +- 0.183 (in-sample avg dev_std = 0.176)
NEC for r=1.0 all L1 = 0.051 +- 0.149 (in-sample avg dev_std = 0.176)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.794
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.771
NEC for r=0.3 class 0.0 = 0.25 +- 0.342 (in-sample avg dev_std = 0.371)
NEC for r=0.3 class 1.0 = 0.075 +- 0.342 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all KL = 0.228 +- 0.342 (in-sample avg dev_std = 0.371)
NEC for r=0.3 all L1 = 0.16 +- 0.250 (in-sample avg dev_std = 0.371)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.805
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.795
NEC for r=0.6 class 0.0 = 0.19 +- 0.266 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 1.0 = 0.06 +- 0.266 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all KL = 0.15 +- 0.266 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all L1 = 0.123 +- 0.214 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.827
NEC for r=0.9 class 0.0 = 0.098 +- 0.173 (in-sample avg dev_std = 0.188)
NEC for r=0.9 class 1.0 = 0.054 +- 0.173 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all KL = 0.075 +- 0.173 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all L1 = 0.075 +- 0.159 (in-sample avg dev_std = 0.188)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.841
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.837
NEC for r=1.0 class 0.0 = 0.081 +- 0.141 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 1.0 = 0.049 +- 0.141 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all KL = 0.051 +- 0.141 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all L1 = 0.065 +- 0.148 (in-sample avg dev_std = 0.148)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:35:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.8408
ID Test ACCURACY: 0.8625
ID Test Loss: 0.9711
OOD Validation ACCURACY: 0.8587
OOD Validation Loss: 1.3017
OOD Test ACCURACY: 0.7962
OOD Test Loss: 2.1004

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9474
Train Loss: 0.0804
ID Validation ACCURACY: 0.8585
ID Validation Loss: 0.5789
ID Test ACCURACY: 0.8617
ID Test Loss: 0.6702
OOD Validation ACCURACY: 0.8607
OOD Validation Loss: 0.9609
OOD Test ACCURACY: 0.8074
OOD Test Loss: 1.7859

[0m[1;37mINFO[0m: [1mChartInfo 0.8625 0.7962 0.8617 0.8074 0.8585 0.8607[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:35:17 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.823
SUFF++ for r=0.6 class 0.0 = 0.798 +- 0.411 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 class 1.0 = 0.857 +- 0.411 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all KL = 0.59 +- 0.411 (in-sample avg dev_std = 0.502)
SUFF++ for r=0.6 all L1 = 0.832 +- 0.210 (in-sample avg dev_std = 0.502)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.883
SUFF++ for r=0.9 class 0.0 = 0.93 +- 0.202 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 1.0 = 0.936 +- 0.202 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all KL = 0.928 +- 0.202 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all L1 = 0.933 +- 0.175 (in-sample avg dev_std = 0.174)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.81
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.712
SUFF++ for r=0.3 class 0.0 = 0.626 +- 0.359 (in-sample avg dev_std = 0.704)
SUFF++ for r=0.3 class 1.0 = 0.739 +- 0.359 (in-sample avg dev_std = 0.704)
SUFF++ for r=0.3 all KL = 0.33 +- 0.359 (in-sample avg dev_std = 0.704)
SUFF++ for r=0.3 all L1 = 0.685 +- 0.213 (in-sample avg dev_std = 0.704)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.749
SUFF++ for r=0.6 class 0.0 = 0.708 +- 0.402 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 1.0 = 0.866 +- 0.402 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all KL = 0.573 +- 0.402 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all L1 = 0.79 +- 0.226 (in-sample avg dev_std = 0.525)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.799
SUFF++ for r=0.9 class 0.0 = 0.884 +- 0.228 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.228 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.889 +- 0.228 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.92 +- 0.167 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.861
NEC for r=0.6 class 0.0 = 0.107 +- 0.276 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 1.0 = 0.05 +- 0.276 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all KL = 0.115 +- 0.276 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all L1 = 0.074 +- 0.185 (in-sample avg dev_std = 0.259)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.082 +- 0.204 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1.0 = 0.049 +- 0.204 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.072 +- 0.204 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.063 +- 0.174 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.869
NEC for r=1.0 class 0.0 = 0.078 +- 0.195 (in-sample avg dev_std = 0.168)
NEC for r=1.0 class 1.0 = 0.045 +- 0.195 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all KL = 0.064 +- 0.195 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all L1 = 0.059 +- 0.171 (in-sample avg dev_std = 0.168)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.81
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.804
NEC for r=0.3 class 0.0 = 0.166 +- 0.305 (in-sample avg dev_std = 0.322)
NEC for r=0.3 class 1.0 = 0.093 +- 0.305 (in-sample avg dev_std = 0.322)
NEC for r=0.3 all KL = 0.178 +- 0.305 (in-sample avg dev_std = 0.322)
NEC for r=0.3 all L1 = 0.128 +- 0.227 (in-sample avg dev_std = 0.322)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.793
NEC for r=0.6 class 0.0 = 0.14 +- 0.271 (in-sample avg dev_std = 0.277)
NEC for r=0.6 class 1.0 = 0.075 +- 0.271 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all KL = 0.138 +- 0.271 (in-sample avg dev_std = 0.277)
NEC for r=0.6 all L1 = 0.106 +- 0.207 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.8
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.808
NEC for r=0.9 class 0.0 = 0.099 +- 0.214 (in-sample avg dev_std = 0.229)
NEC for r=0.9 class 1.0 = 0.055 +- 0.214 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all KL = 0.092 +- 0.214 (in-sample avg dev_std = 0.229)
NEC for r=0.9 all L1 = 0.076 +- 0.172 (in-sample avg dev_std = 0.229)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.809
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.809
NEC for r=1.0 class 0.0 = 0.09 +- 0.187 (in-sample avg dev_std = 0.195)
NEC for r=1.0 class 1.0 = 0.047 +- 0.187 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all KL = 0.071 +- 0.187 (in-sample avg dev_std = 0.195)
NEC for r=1.0 all L1 = 0.068 +- 0.164 (in-sample avg dev_std = 0.195)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:37:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:37:41 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8664
ID Validation Loss: 0.7891
ID Test ACCURACY: 0.8602
ID Test Loss: 0.8571
OOD Validation ACCURACY: 0.8539
OOD Validation Loss: 1.3496
OOD Test ACCURACY: 0.7823
OOD Test Loss: 3.4741

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 96...
[0m[1;37mINFO[0m: [1mCheckpoint 96: 
-----------------------------------
Train ACCURACY: 0.9474
Train Loss: 0.0816
ID Validation ACCURACY: 0.8564
ID Validation Loss: 0.6260
ID Test ACCURACY: 0.8576
ID Test Loss: 0.7197
OOD Validation ACCURACY: 0.8616
OOD Validation Loss: 1.2995
OOD Test ACCURACY: 0.8121
OOD Test Loss: 2.8311

[0m[1;37mINFO[0m: [1mChartInfo 0.8602 0.7823 0.8576 0.8121 0.8564 0.8616[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:37:42 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.819
SUFF++ for r=0.6 class 0.0 = 0.755 +- 0.423 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 class 1.0 = 0.885 +- 0.423 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all KL = 0.632 +- 0.423 (in-sample avg dev_std = 0.495)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.233 (in-sample avg dev_std = 0.495)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.838
SUFF++ for r=0.9 class 0.0 = 0.891 +- 0.246 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.246 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all KL = 0.903 +- 0.246 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.9 all L1 = 0.914 +- 0.217 (in-sample avg dev_std = 0.208)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.803
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.698
SUFF++ for r=0.3 class 0.0 = 0.592 +- 0.395 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 class 1.0 = 0.787 +- 0.395 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 all KL = 0.311 +- 0.395 (in-sample avg dev_std = 0.728)
SUFF++ for r=0.3 all L1 = 0.692 +- 0.227 (in-sample avg dev_std = 0.728)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.738
SUFF++ for r=0.6 class 0.0 = 0.695 +- 0.434 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.6 class 1.0 = 0.912 +- 0.434 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.6 all KL = 0.576 +- 0.434 (in-sample avg dev_std = 0.549)
SUFF++ for r=0.6 all L1 = 0.807 +- 0.227 (in-sample avg dev_std = 0.549)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.778
SUFF++ for r=0.9 class 0.0 = 0.868 +- 0.259 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.259 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all KL = 0.871 +- 0.259 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all L1 = 0.919 +- 0.166 (in-sample avg dev_std = 0.277)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.858
NEC for r=0.6 class 0.0 = 0.117 +- 0.270 (in-sample avg dev_std = 0.231)
NEC for r=0.6 class 1.0 = 0.047 +- 0.270 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all KL = 0.103 +- 0.270 (in-sample avg dev_std = 0.231)
NEC for r=0.6 all L1 = 0.076 +- 0.203 (in-sample avg dev_std = 0.231)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.867
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.86
NEC for r=0.9 class 0.0 = 0.094 +- 0.220 (in-sample avg dev_std = 0.186)
NEC for r=0.9 class 1.0 = 0.043 +- 0.220 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all KL = 0.072 +- 0.220 (in-sample avg dev_std = 0.186)
NEC for r=0.9 all L1 = 0.064 +- 0.190 (in-sample avg dev_std = 0.186)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.874
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.867
NEC for r=1.0 class 0.0 = 0.083 +- 0.199 (in-sample avg dev_std = 0.192)
NEC for r=1.0 class 1.0 = 0.036 +- 0.199 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all KL = 0.061 +- 0.199 (in-sample avg dev_std = 0.192)
NEC for r=1.0 all L1 = 0.056 +- 0.167 (in-sample avg dev_std = 0.192)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.803
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.798
NEC for r=0.3 class 0.0 = 0.156 +- 0.338 (in-sample avg dev_std = 0.333)
NEC for r=0.3 class 1.0 = 0.065 +- 0.338 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all KL = 0.18 +- 0.338 (in-sample avg dev_std = 0.333)
NEC for r=0.3 all L1 = 0.109 +- 0.221 (in-sample avg dev_std = 0.333)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.779
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.799
NEC for r=0.6 class 0.0 = 0.136 +- 0.289 (in-sample avg dev_std = 0.274)
NEC for r=0.6 class 1.0 = 0.038 +- 0.289 (in-sample avg dev_std = 0.274)
NEC for r=0.6 all KL = 0.135 +- 0.289 (in-sample avg dev_std = 0.274)
NEC for r=0.6 all L1 = 0.086 +- 0.192 (in-sample avg dev_std = 0.274)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.791
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.788
NEC for r=0.9 class 0.0 = 0.112 +- 0.212 (in-sample avg dev_std = 0.219)
NEC for r=0.9 class 1.0 = 0.026 +- 0.212 (in-sample avg dev_std = 0.219)
NEC for r=0.9 all KL = 0.087 +- 0.212 (in-sample avg dev_std = 0.219)
NEC for r=0.9 all L1 = 0.068 +- 0.160 (in-sample avg dev_std = 0.219)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.799
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.806
NEC for r=1.0 class 0.0 = 0.091 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 1.0 = 0.027 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all KL = 0.066 +- 0.174 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all L1 = 0.058 +- 0.143 (in-sample avg dev_std = 0.183)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:40:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 160...
[0m[1;37mINFO[0m: [1mCheckpoint 160: 
-----------------------------------
Train ACCURACY: 0.9483
Train Loss: 0.0767
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.7098
ID Test ACCURACY: 0.8564
ID Test Loss: 0.8617
OOD Validation ACCURACY: 0.8566
OOD Validation Loss: 1.3829
OOD Test ACCURACY: 0.8027
OOD Test Loss: 3.1845

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.7238
ID Test ACCURACY: 0.8580
ID Test Loss: 0.8646
OOD Validation ACCURACY: 0.8584
OOD Validation Loss: 1.4575
OOD Test ACCURACY: 0.8023
OOD Test Loss: 3.6392

[0m[1;37mINFO[0m: [1mChartInfo 0.8564 0.8027 0.8580 0.8023 0.8630 0.8584[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 02:40:05 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.817
SUFF++ for r=0.6 class 0.0 = 0.835 +- 0.396 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.6 class 1.0 = 0.797 +- 0.396 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.6 all KL = 0.571 +- 0.396 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.6 all L1 = 0.813 +- 0.210 (in-sample avg dev_std = 0.523)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.915 +- 0.210 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 class 1.0 = 0.95 +- 0.210 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all KL = 0.922 +- 0.210 (in-sample avg dev_std = 0.165)
SUFF++ for r=0.9 all L1 = 0.935 +- 0.178 (in-sample avg dev_std = 0.165)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.702
SUFF++ for r=0.3 class 0.0 = 0.619 +- 0.353 (in-sample avg dev_std = 0.761)
SUFF++ for r=0.3 class 1.0 = 0.703 +- 0.353 (in-sample avg dev_std = 0.761)
SUFF++ for r=0.3 all KL = 0.248 +- 0.353 (in-sample avg dev_std = 0.761)
SUFF++ for r=0.3 all L1 = 0.663 +- 0.213 (in-sample avg dev_std = 0.761)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.775
SUFF++ for r=0.6 class 0.0 = 0.768 +- 0.422 (in-sample avg dev_std = 0.573)
SUFF++ for r=0.6 class 1.0 = 0.794 +- 0.422 (in-sample avg dev_std = 0.573)
SUFF++ for r=0.6 all KL = 0.499 +- 0.422 (in-sample avg dev_std = 0.573)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.224 (in-sample avg dev_std = 0.573)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.817
SUFF++ for r=0.9 class 0.0 = 0.904 +- 0.276 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 class 1.0 = 0.927 +- 0.276 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all KL = 0.859 +- 0.276 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.9 all L1 = 0.916 +- 0.173 (in-sample avg dev_std = 0.295)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.862
NEC for r=0.6 class 0.0 = 0.088 +- 0.235 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 1.0 = 0.054 +- 0.235 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all KL = 0.092 +- 0.235 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all L1 = 0.068 +- 0.177 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.87
NEC for r=0.9 class 0.0 = 0.065 +- 0.199 (in-sample avg dev_std = 0.178)
NEC for r=0.9 class 1.0 = 0.048 +- 0.199 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all KL = 0.069 +- 0.199 (in-sample avg dev_std = 0.178)
NEC for r=0.9 all L1 = 0.055 +- 0.162 (in-sample avg dev_std = 0.178)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.872
NEC for r=1.0 class 0.0 = 0.063 +- 0.169 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1.0 = 0.042 +- 0.169 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.055 +- 0.169 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.051 +- 0.152 (in-sample avg dev_std = 0.159)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.8
NEC for r=0.3 class 0.0 = 0.15 +- 0.370 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1.0 = 0.125 +- 0.370 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.236 +- 0.370 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.137 +- 0.240 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.817
NEC for r=0.6 class 0.0 = 0.109 +- 0.299 (in-sample avg dev_std = 0.281)
NEC for r=0.6 class 1.0 = 0.085 +- 0.299 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all KL = 0.156 +- 0.299 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all L1 = 0.097 +- 0.198 (in-sample avg dev_std = 0.281)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.818
NEC for r=0.9 class 0.0 = 0.094 +- 0.263 (in-sample avg dev_std = 0.234)
NEC for r=0.9 class 1.0 = 0.069 +- 0.263 (in-sample avg dev_std = 0.234)
NEC for r=0.9 all KL = 0.113 +- 0.263 (in-sample avg dev_std = 0.234)
NEC for r=0.9 all L1 = 0.081 +- 0.192 (in-sample avg dev_std = 0.234)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.815
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.817
NEC for r=1.0 class 0.0 = 0.087 +- 0.236 (in-sample avg dev_std = 0.222)
NEC for r=1.0 class 1.0 = 0.058 +- 0.236 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all KL = 0.094 +- 0.236 (in-sample avg dev_std = 0.222)
NEC for r=1.0 all L1 = 0.072 +- 0.177 (in-sample avg dev_std = 0.222)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.601, 0.933, 1.0], 'all_L1': [0.8, 0.926, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.653, 0.932, 1.0], 'all_L1': [0.816, 0.938, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.59, 0.928, 1.0], 'all_L1': [0.832, 0.933, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.632, 0.903, 1.0], 'all_L1': [0.83, 0.914, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.571, 0.922, 1.0], 'all_L1': [0.813, 0.935, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.134, 0.055, 0.057], 'all_L1': [0.108, 0.057, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.129, 0.063, 0.06], 'all_L1': [0.105, 0.056, 0.051]}), defaultdict(<class 'list'>, {'all_KL': [0.115, 0.072, 0.064], 'all_L1': [0.074, 0.063, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.103, 0.072, 0.061], 'all_L1': [0.076, 0.064, 0.056]}), defaultdict(<class 'list'>, {'all_KL': [0.092, 0.069, 0.055], 'all_L1': [0.068, 0.055, 0.051]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.307, 0.534, 0.888, 1.0], 'all_L1': [0.682, 0.803, 0.925, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.304, 0.56, 0.891, 1.0], 'all_L1': [0.65, 0.783, 0.912, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.33, 0.573, 0.889, 1.0], 'all_L1': [0.685, 0.79, 0.92, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.311, 0.576, 0.871, 1.0], 'all_L1': [0.692, 0.807, 0.919, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.248, 0.499, 0.859, 1.0], 'all_L1': [0.663, 0.782, 0.916, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.163, 0.139, 0.085, 0.077], 'all_L1': [0.11, 0.087, 0.069, 0.067]}), defaultdict(<class 'list'>, {'all_KL': [0.228, 0.15, 0.075, 0.051], 'all_L1': [0.16, 0.123, 0.075, 0.065]}), defaultdict(<class 'list'>, {'all_KL': [0.178, 0.138, 0.092, 0.071], 'all_L1': [0.128, 0.106, 0.076, 0.068]}), defaultdict(<class 'list'>, {'all_KL': [0.18, 0.135, 0.087, 0.066], 'all_L1': [0.109, 0.086, 0.068, 0.058]}), defaultdict(<class 'list'>, {'all_KL': [0.236, 0.156, 0.113, 0.094], 'all_L1': [0.137, 0.097, 0.081, 0.072]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.818 +- 0.012, 0.929 +- 0.009, 1.000 +- 0.000
suff++ class all_KL  =  0.609 +- 0.029, 0.924 +- 0.011, 1.000 +- 0.000
suff++_acc_int  =  0.813 +- 0.008, 0.863 +- 0.016
nec class all_L1  =  0.086 +- 0.017, 0.059 +- 0.004, 0.055 +- 0.003
nec class all_KL  =  0.115 +- 0.016, 0.066 +- 0.006, 0.059 +- 0.003
nec_acc_int  =  0.853 +- 0.014, 0.865 +- 0.004, 0.866 +- 0.006

Eval split test
suff++ class all_L1  =  0.674 +- 0.016, 0.793 +- 0.010, 0.918 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.300 +- 0.028, 0.548 +- 0.029, 0.880 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.700 +- 0.011, 0.758 +- 0.013, 0.807 +- 0.017
nec class all_L1  =  0.129 +- 0.019, 0.100 +- 0.014, 0.074 +- 0.005, 0.066 +- 0.005
nec class all_KL  =  0.197 +- 0.029, 0.144 +- 0.008, 0.090 +- 0.013, 0.072 +- 0.014
nec_acc_int  =  0.796 +- 0.013, 0.804 +- 0.011, 0.814 +- 0.015, 0.820 +- 0.012


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.452 +- 0.006, 0.494 +- 0.003, 0.527 +- 0.002
Faith. Armon (L1)= 		  =  0.155 +- 0.027, 0.111 +- 0.007, 0.104 +- 0.006
Faith. GMean (L1)= 	  =  0.264 +- 0.024, 0.234 +- 0.007, 0.234 +- 0.007
Faith. Aritm (KL)= 		  =  0.362 +- 0.020, 0.495 +- 0.004, 0.530 +- 0.002
Faith. Armon (KL)= 		  =  0.193 +- 0.023, 0.123 +- 0.011, 0.112 +- 0.006
Faith. GMean (KL)= 	  =  0.264 +- 0.022, 0.247 +- 0.012, 0.244 +- 0.006

Eval split test
Faith. Aritm (L1)= 		  =  0.402 +- 0.004, 0.446 +- 0.004, 0.496 +- 0.002, 0.533 +- 0.002
Faith. Armon (L1)= 		  =  0.215 +- 0.026, 0.177 +- 0.021, 0.137 +- 0.008, 0.124 +- 0.008
Faith. GMean (L1)= 	  =  0.294 +- 0.018, 0.281 +- 0.018, 0.260 +- 0.008, 0.257 +- 0.009
Faith. Aritm (KL)= 		  =  0.249 +- 0.011, 0.346 +- 0.012, 0.485 +- 0.004, 0.536 +- 0.007
Faith. Armon (KL)= 		  =  0.235 +- 0.016, 0.227 +- 0.008, 0.164 +- 0.020, 0.134 +- 0.024
Faith. GMean (KL)= 	  =  0.242 +- 0.013, 0.280 +- 0.006, 0.281 +- 0.018, 0.267 +- 0.026
Computed for split load_split = id



Completed in  0:12:11.601497  for GSATvGIN GOODSST2/length



DONE GSAT GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:42:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:42:46 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:29 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:43:57 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:44:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ROC-AUC: 0.9790
Train Loss: 0.1210
ID Validation ROC-AUC: 0.9202
ID Validation Loss: 0.2663
ID Test ROC-AUC: 0.9191
ID Test Loss: 0.2695
OOD Validation ROC-AUC: 0.6372
OOD Validation Loss: 0.5165
OOD Test ROC-AUC: 0.6873
OOD Test Loss: 0.6912

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 1...
[0m[1;37mINFO[0m: [1mCheckpoint 1: 
-----------------------------------
Train ROC-AUC: 0.8266
Train Loss: 0.7015
ID Validation ROC-AUC: 0.8256
ID Validation Loss: 0.7089
ID Test ROC-AUC: 0.8216
ID Test Loss: 0.7167
OOD Validation ROC-AUC: 0.7019
OOD Validation Loss: 0.4065
OOD Test ROC-AUC: 0.7079
OOD Test Loss: 0.4708

[0m[1;37mINFO[0m: [1mChartInfo 0.9191 0.6873 0.8216 0.7079 0.8256 0.7019[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:44:15 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:44:20 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.668
SUFF++ for r=0.3 class 0.0 = 0.6 +- 0.157 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 class 1.0 = 0.771 +- 0.157 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all KL = 0.817 +- 0.157 (in-sample avg dev_std = 0.321)
SUFF++ for r=0.3 all L1 = 0.751 +- 0.170 (in-sample avg dev_std = 0.321)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.857
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.759
SUFF++ for r=0.6 class 0.0 = 0.613 +- 0.175 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 class 1.0 = 0.862 +- 0.175 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all KL = 0.863 +- 0.175 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.6 all L1 = 0.833 +- 0.193 (in-sample avg dev_std = 0.279)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.841
SUFF++ for r=0.9 class 0.0 = 0.729 +- 0.120 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 class 1.0 = 0.921 +- 0.120 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all KL = 0.939 +- 0.120 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all L1 = 0.899 +- 0.145 (in-sample avg dev_std = 0.186)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
SUFF++ for r=0.3 class 0.0 = 0.615 +- 0.185 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 class 1.0 = 0.691 +- 0.185 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all KL = 0.758 +- 0.185 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.3 all L1 = 0.679 +- 0.164 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.634
SUFF++ for r=0.6 class 0.0 = 0.655 +- 0.182 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 class 1.0 = 0.76 +- 0.182 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all KL = 0.807 +- 0.182 (in-sample avg dev_std = 0.336)
SUFF++ for r=0.6 all L1 = 0.743 +- 0.198 (in-sample avg dev_std = 0.336)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.713
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.684
SUFF++ for r=0.9 class 0.0 = 0.783 +- 0.130 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 class 1.0 = 0.854 +- 0.130 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all KL = 0.913 +- 0.130 (in-sample avg dev_std = 0.222)
SUFF++ for r=0.9 all L1 = 0.842 +- 0.168 (in-sample avg dev_std = 0.222)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.763
NEC for r=0.3 class 0.0 = 0.299 +- 0.170 (in-sample avg dev_std = 0.263)
NEC for r=0.3 class 1.0 = 0.189 +- 0.170 (in-sample avg dev_std = 0.263)
NEC for r=0.3 all KL = 0.131 +- 0.170 (in-sample avg dev_std = 0.263)
NEC for r=0.3 all L1 = 0.201 +- 0.159 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.857
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.83
NEC for r=0.6 class 0.0 = 0.275 +- 0.176 (in-sample avg dev_std = 0.252)
NEC for r=0.6 class 1.0 = 0.125 +- 0.176 (in-sample avg dev_std = 0.252)
NEC for r=0.6 all KL = 0.114 +- 0.176 (in-sample avg dev_std = 0.252)
NEC for r=0.6 all L1 = 0.143 +- 0.163 (in-sample avg dev_std = 0.252)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.854
NEC for r=0.9 class 0.0 = 0.24 +- 0.139 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 1.0 = 0.096 +- 0.139 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all KL = 0.082 +- 0.139 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all L1 = 0.112 +- 0.143 (in-sample avg dev_std = 0.221)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0.0 = 0.233 +- 0.126 (in-sample avg dev_std = 0.205)
NEC for r=1.0 class 1.0 = 0.084 +- 0.126 (in-sample avg dev_std = 0.205)
NEC for r=1.0 all KL = 0.069 +- 0.126 (in-sample avg dev_std = 0.205)
NEC for r=1.0 all L1 = 0.101 +- 0.135 (in-sample avg dev_std = 0.205)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.642
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.622
NEC for r=0.3 class 0.0 = 0.293 +- 0.173 (in-sample avg dev_std = 0.270)
NEC for r=0.3 class 1.0 = 0.23 +- 0.173 (in-sample avg dev_std = 0.270)
NEC for r=0.3 all KL = 0.142 +- 0.173 (in-sample avg dev_std = 0.270)
NEC for r=0.3 all L1 = 0.24 +- 0.165 (in-sample avg dev_std = 0.270)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.697
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.665
NEC for r=0.6 class 0.0 = 0.267 +- 0.169 (in-sample avg dev_std = 0.281)
NEC for r=0.6 class 1.0 = 0.196 +- 0.169 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all KL = 0.137 +- 0.169 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all L1 = 0.207 +- 0.171 (in-sample avg dev_std = 0.281)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.713
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.677
NEC for r=0.9 class 0.0 = 0.232 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.9 class 1.0 = 0.157 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.9 all KL = 0.103 +- 0.145 (in-sample avg dev_std = 0.239)
NEC for r=0.9 all L1 = 0.17 +- 0.161 (in-sample avg dev_std = 0.239)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.717
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.691
NEC for r=1.0 class 0.0 = 0.201 +- 0.134 (in-sample avg dev_std = 0.224)
NEC for r=1.0 class 1.0 = 0.142 +- 0.134 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all KL = 0.09 +- 0.134 (in-sample avg dev_std = 0.224)
NEC for r=1.0 all L1 = 0.152 +- 0.153 (in-sample avg dev_std = 0.224)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:47:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:47:45 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:17 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:28 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:39 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:48:55 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:49:11 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:49:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9730
Train Loss: 0.1349
ID Validation ROC-AUC: 0.9206
ID Validation Loss: 0.2729
ID Test ROC-AUC: 0.9183
ID Test Loss: 0.2776
OOD Validation ROC-AUC: 0.6535
OOD Validation Loss: 0.5572
OOD Test ROC-AUC: 0.7044
OOD Test Loss: 0.7172

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ROC-AUC: 0.8666
Train Loss: 0.3770
ID Validation ROC-AUC: 0.8640
ID Validation Loss: 0.3811
ID Test ROC-AUC: 0.8657
ID Test Loss: 0.3851
OOD Validation ROC-AUC: 0.6952
OOD Validation Loss: 0.3144
OOD Test ROC-AUC: 0.7141
OOD Test Loss: 0.5763

[0m[1;37mINFO[0m: [1mChartInfo 0.9183 0.7044 0.8657 0.7141 0.8640 0.6952[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:49:12 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:49:16 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.782
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.627
SUFF++ for r=0.3 class 0.0 = 0.598 +- 0.143 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 class 1.0 = 0.757 +- 0.143 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all KL = 0.827 +- 0.143 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all L1 = 0.739 +- 0.163 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.708
SUFF++ for r=0.6 class 0.0 = 0.669 +- 0.162 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 class 1.0 = 0.929 +- 0.162 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 all KL = 0.917 +- 0.162 (in-sample avg dev_std = 0.208)
SUFF++ for r=0.6 all L1 = 0.899 +- 0.179 (in-sample avg dev_std = 0.208)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0.0 = 0.772 +- 0.108 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 1.0 = 0.963 +- 0.108 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all KL = 0.962 +- 0.108 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all L1 = 0.941 +- 0.137 (in-sample avg dev_std = 0.142)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.586
SUFF++ for r=0.3 class 0.0 = 0.626 +- 0.158 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 class 1.0 = 0.691 +- 0.158 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all KL = 0.791 +- 0.158 (in-sample avg dev_std = 0.345)
SUFF++ for r=0.3 all L1 = 0.68 +- 0.159 (in-sample avg dev_std = 0.345)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.698
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.617
SUFF++ for r=0.6 class 0.0 = 0.73 +- 0.185 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.185 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all KL = 0.866 +- 0.185 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.6 all L1 = 0.83 +- 0.208 (in-sample avg dev_std = 0.277)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
SUFF++ for r=0.9 class 0.0 = 0.849 +- 0.119 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1.0 = 0.919 +- 0.119 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.941 +- 0.119 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.907 +- 0.154 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.782
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.761
NEC for r=0.3 class 0.0 = 0.263 +- 0.131 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 1.0 = 0.201 +- 0.131 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all KL = 0.116 +- 0.131 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all L1 = 0.208 +- 0.127 (in-sample avg dev_std = 0.219)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.827
NEC for r=0.6 class 0.0 = 0.226 +- 0.135 (in-sample avg dev_std = 0.183)
NEC for r=0.6 class 1.0 = 0.068 +- 0.135 (in-sample avg dev_std = 0.183)
NEC for r=0.6 all KL = 0.067 +- 0.135 (in-sample avg dev_std = 0.183)
NEC for r=0.6 all L1 = 0.086 +- 0.139 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.879
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.862
NEC for r=0.9 class 0.0 = 0.195 +- 0.104 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.04 +- 0.104 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.042 +- 0.104 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.058 +- 0.123 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.168 +- 0.096 (in-sample avg dev_std = 0.137)
NEC for r=1.0 class 1.0 = 0.037 +- 0.096 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all KL = 0.036 +- 0.096 (in-sample avg dev_std = 0.137)
NEC for r=1.0 all L1 = 0.052 +- 0.114 (in-sample avg dev_std = 0.137)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
NEC for r=0.3 class 0.0 = 0.246 +- 0.147 (in-sample avg dev_std = 0.246)
NEC for r=0.3 class 1.0 = 0.238 +- 0.147 (in-sample avg dev_std = 0.246)
NEC for r=0.3 all KL = 0.125 +- 0.147 (in-sample avg dev_std = 0.246)
NEC for r=0.3 all L1 = 0.239 +- 0.139 (in-sample avg dev_std = 0.246)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.699
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.687
NEC for r=0.6 class 0.0 = 0.195 +- 0.164 (in-sample avg dev_std = 0.223)
NEC for r=0.6 class 1.0 = 0.129 +- 0.164 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all KL = 0.098 +- 0.164 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all L1 = 0.14 +- 0.169 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.714
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.705
NEC for r=0.9 class 0.0 = 0.168 +- 0.142 (in-sample avg dev_std = 0.196)
NEC for r=0.9 class 1.0 = 0.086 +- 0.142 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all KL = 0.072 +- 0.142 (in-sample avg dev_std = 0.196)
NEC for r=0.9 all L1 = 0.1 +- 0.152 (in-sample avg dev_std = 0.196)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.724
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.705
NEC for r=1.0 class 0.0 = 0.155 +- 0.133 (in-sample avg dev_std = 0.184)
NEC for r=1.0 class 1.0 = 0.077 +- 0.133 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all KL = 0.063 +- 0.133 (in-sample avg dev_std = 0.184)
NEC for r=1.0 all L1 = 0.09 +- 0.146 (in-sample avg dev_std = 0.184)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:52:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:52:40 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:13 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:23 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:34 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:53:51 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ROC-AUC: 0.9708
Train Loss: 0.1435
ID Validation ROC-AUC: 0.9211
ID Validation Loss: 0.2689
ID Test ROC-AUC: 0.9165
ID Test Loss: 0.2816
OOD Validation ROC-AUC: 0.6552
OOD Validation Loss: 0.4851
OOD Test ROC-AUC: 0.6967
OOD Test Loss: 0.6916

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 2...
[0m[1;37mINFO[0m: [1mCheckpoint 2: 
-----------------------------------
Train ROC-AUC: 0.8500
Train Loss: 0.3423
ID Validation ROC-AUC: 0.8488
ID Validation Loss: 0.3452
ID Test ROC-AUC: 0.8482
ID Test Loss: 0.3500
OOD Validation ROC-AUC: 0.7007
OOD Validation Loss: 0.2847
OOD Test ROC-AUC: 0.7132
OOD Test Loss: 0.5090

[0m[1;37mINFO[0m: [1mChartInfo 0.9165 0.6967 0.8482 0.7132 0.8488 0.7007[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:54:09 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:54:13 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.707
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.616
SUFF++ for r=0.3 class 0.0 = 0.662 +- 0.118 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 class 1.0 = 0.758 +- 0.118 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all KL = 0.852 +- 0.118 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all L1 = 0.747 +- 0.137 (in-sample avg dev_std = 0.262)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.743
SUFF++ for r=0.6 class 0.0 = 0.61 +- 0.152 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 class 1.0 = 0.879 +- 0.152 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all KL = 0.894 +- 0.152 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.6 all L1 = 0.848 +- 0.194 (in-sample avg dev_std = 0.234)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0.0 = 0.758 +- 0.107 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.107 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all KL = 0.953 +- 0.107 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.9 all L1 = 0.918 +- 0.147 (in-sample avg dev_std = 0.161)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.582
SUFF++ for r=0.3 class 0.0 = 0.695 +- 0.115 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 class 1.0 = 0.737 +- 0.115 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all KL = 0.849 +- 0.115 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.3 all L1 = 0.73 +- 0.129 (in-sample avg dev_std = 0.278)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.72
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.665
SUFF++ for r=0.6 class 0.0 = 0.656 +- 0.157 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 class 1.0 = 0.795 +- 0.157 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 all KL = 0.849 +- 0.157 (in-sample avg dev_std = 0.287)
SUFF++ for r=0.6 all L1 = 0.772 +- 0.201 (in-sample avg dev_std = 0.287)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.739
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.733
SUFF++ for r=0.9 class 0.0 = 0.808 +- 0.109 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 class 1.0 = 0.891 +- 0.109 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all KL = 0.935 +- 0.109 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.9 all L1 = 0.878 +- 0.155 (in-sample avg dev_std = 0.196)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.707
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.678
NEC for r=0.3 class 0.0 = 0.277 +- 0.104 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 1.0 = 0.19 +- 0.104 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all KL = 0.093 +- 0.104 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all L1 = 0.2 +- 0.133 (in-sample avg dev_std = 0.196)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.835
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.813
NEC for r=0.6 class 0.0 = 0.281 +- 0.114 (in-sample avg dev_std = 0.187)
NEC for r=0.6 class 1.0 = 0.105 +- 0.114 (in-sample avg dev_std = 0.187)
NEC for r=0.6 all KL = 0.075 +- 0.114 (in-sample avg dev_std = 0.187)
NEC for r=0.6 all L1 = 0.125 +- 0.149 (in-sample avg dev_std = 0.187)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.868
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.864
NEC for r=0.9 class 0.0 = 0.227 +- 0.103 (in-sample avg dev_std = 0.166)
NEC for r=0.9 class 1.0 = 0.062 +- 0.103 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all KL = 0.048 +- 0.103 (in-sample avg dev_std = 0.166)
NEC for r=0.9 all L1 = 0.081 +- 0.135 (in-sample avg dev_std = 0.166)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.87
NEC for r=1.0 class 0.0 = 0.199 +- 0.082 (in-sample avg dev_std = 0.149)
NEC for r=1.0 class 1.0 = 0.05 +- 0.082 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all KL = 0.036 +- 0.082 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all L1 = 0.067 +- 0.120 (in-sample avg dev_std = 0.149)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.614
NEC for r=0.3 class 0.0 = 0.218 +- 0.105 (in-sample avg dev_std = 0.197)
NEC for r=0.3 class 1.0 = 0.205 +- 0.105 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all KL = 0.089 +- 0.105 (in-sample avg dev_std = 0.197)
NEC for r=0.3 all L1 = 0.207 +- 0.132 (in-sample avg dev_std = 0.197)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.72
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.712
NEC for r=0.6 class 0.0 = 0.247 +- 0.117 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 1.0 = 0.161 +- 0.117 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all KL = 0.093 +- 0.117 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all L1 = 0.175 +- 0.155 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.727
NEC for r=0.9 class 0.0 = 0.18 +- 0.113 (in-sample avg dev_std = 0.185)
NEC for r=0.9 class 1.0 = 0.115 +- 0.113 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all KL = 0.068 +- 0.113 (in-sample avg dev_std = 0.185)
NEC for r=0.9 all L1 = 0.125 +- 0.149 (in-sample avg dev_std = 0.185)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.742
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.73
NEC for r=1.0 class 0.0 = 0.169 +- 0.100 (in-sample avg dev_std = 0.168)
NEC for r=1.0 class 1.0 = 0.091 +- 0.100 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all KL = 0.052 +- 0.100 (in-sample avg dev_std = 0.168)
NEC for r=1.0 all L1 = 0.104 +- 0.136 (in-sample avg dev_std = 0.168)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 14:57:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 02:57:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:17 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:27 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:38 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 02:58:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ROC-AUC: 0.9711
Train Loss: 0.1374
ID Validation ROC-AUC: 0.9175
ID Validation Loss: 0.2514
ID Test ROC-AUC: 0.9200
ID Test Loss: 0.2482
OOD Validation ROC-AUC: 0.6432
OOD Validation Loss: 0.4802
OOD Test ROC-AUC: 0.6930
OOD Test Loss: 0.6345

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ROC-AUC: 0.8717
Train Loss: 0.3270
ID Validation ROC-AUC: 0.8702
ID Validation Loss: 0.3310
ID Test ROC-AUC: 0.8707
ID Test Loss: 0.3340
OOD Validation ROC-AUC: 0.6958
OOD Validation Loss: 0.3030
OOD Test ROC-AUC: 0.7249
OOD Test Loss: 0.5231

[0m[1;37mINFO[0m: [1mChartInfo 0.9200 0.6930 0.8707 0.7249 0.8702 0.6958[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 02:59:11 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 02:59:15 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.825
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.679
SUFF++ for r=0.3 class 0.0 = 0.585 +- 0.140 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 class 1.0 = 0.768 +- 0.140 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all KL = 0.844 +- 0.140 (in-sample avg dev_std = 0.327)
SUFF++ for r=0.3 all L1 = 0.747 +- 0.152 (in-sample avg dev_std = 0.327)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.757
SUFF++ for r=0.6 class 0.0 = 0.589 +- 0.163 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 class 1.0 = 0.853 +- 0.163 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all KL = 0.868 +- 0.163 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.6 all L1 = 0.823 +- 0.188 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.848
SUFF++ for r=0.9 class 0.0 = 0.734 +- 0.114 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 class 1.0 = 0.927 +- 0.114 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all KL = 0.944 +- 0.114 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.9 all L1 = 0.904 +- 0.149 (in-sample avg dev_std = 0.186)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.681
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.627 +- 0.172 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.3 class 1.0 = 0.7 +- 0.172 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.3 all KL = 0.794 +- 0.172 (in-sample avg dev_std = 0.389)
SUFF++ for r=0.3 all L1 = 0.688 +- 0.160 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.704
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0.0 = 0.637 +- 0.179 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 class 1.0 = 0.749 +- 0.179 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 all KL = 0.808 +- 0.179 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.6 all L1 = 0.73 +- 0.197 (in-sample avg dev_std = 0.361)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.695
SUFF++ for r=0.9 class 0.0 = 0.755 +- 0.133 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 class 1.0 = 0.856 +- 0.133 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all KL = 0.911 +- 0.133 (in-sample avg dev_std = 0.230)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.176 (in-sample avg dev_std = 0.230)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.825
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.805
NEC for r=0.3 class 0.0 = 0.256 +- 0.116 (in-sample avg dev_std = 0.219)
NEC for r=0.3 class 1.0 = 0.166 +- 0.116 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all KL = 0.082 +- 0.116 (in-sample avg dev_std = 0.219)
NEC for r=0.3 all L1 = 0.176 +- 0.131 (in-sample avg dev_std = 0.219)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.871
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.849
NEC for r=0.6 class 0.0 = 0.255 +- 0.140 (in-sample avg dev_std = 0.220)
NEC for r=0.6 class 1.0 = 0.119 +- 0.140 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all KL = 0.086 +- 0.140 (in-sample avg dev_std = 0.220)
NEC for r=0.6 all L1 = 0.135 +- 0.148 (in-sample avg dev_std = 0.220)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.887
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.872
NEC for r=0.9 class 0.0 = 0.227 +- 0.119 (in-sample avg dev_std = 0.188)
NEC for r=0.9 class 1.0 = 0.078 +- 0.119 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all KL = 0.062 +- 0.119 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all L1 = 0.095 +- 0.135 (in-sample avg dev_std = 0.188)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.886
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.873
NEC for r=1.0 class 0.0 = 0.226 +- 0.110 (in-sample avg dev_std = 0.183)
NEC for r=1.0 class 1.0 = 0.067 +- 0.110 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all KL = 0.055 +- 0.110 (in-sample avg dev_std = 0.183)
NEC for r=1.0 all L1 = 0.085 +- 0.131 (in-sample avg dev_std = 0.183)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.681
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.647
NEC for r=0.3 class 0.0 = 0.24 +- 0.143 (in-sample avg dev_std = 0.260)
NEC for r=0.3 class 1.0 = 0.217 +- 0.143 (in-sample avg dev_std = 0.260)
NEC for r=0.3 all KL = 0.111 +- 0.143 (in-sample avg dev_std = 0.260)
NEC for r=0.3 all L1 = 0.221 +- 0.154 (in-sample avg dev_std = 0.260)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.704
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.682
NEC for r=0.6 class 0.0 = 0.237 +- 0.140 (in-sample avg dev_std = 0.259)
NEC for r=0.6 class 1.0 = 0.184 +- 0.140 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all KL = 0.108 +- 0.140 (in-sample avg dev_std = 0.259)
NEC for r=0.6 all L1 = 0.193 +- 0.159 (in-sample avg dev_std = 0.259)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.715
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.698
NEC for r=0.9 class 0.0 = 0.213 +- 0.136 (in-sample avg dev_std = 0.238)
NEC for r=0.9 class 1.0 = 0.145 +- 0.136 (in-sample avg dev_std = 0.238)
NEC for r=0.9 all KL = 0.092 +- 0.136 (in-sample avg dev_std = 0.238)
NEC for r=0.9 all L1 = 0.157 +- 0.160 (in-sample avg dev_std = 0.238)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.715
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.706
NEC for r=1.0 class 0.0 = 0.199 +- 0.128 (in-sample avg dev_std = 0.231)
NEC for r=1.0 class 1.0 = 0.131 +- 0.128 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all KL = 0.083 +- 0.128 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all L1 = 0.143 +- 0.157 (in-sample avg dev_std = 0.231)
model_dirname= repr_GSATvGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:02:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 03:02:37 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:10 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 03:03:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ROC-AUC: 0.9717
Train Loss: 0.1380
ID Validation ROC-AUC: 0.9197
ID Validation Loss: 0.2550
ID Test ROC-AUC: 0.9210
ID Test Loss: 0.2563
OOD Validation ROC-AUC: 0.6324
OOD Validation Loss: 0.4871
OOD Test ROC-AUC: 0.6937
OOD Test Loss: 0.6380

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 2...
[0m[1;37mINFO[0m: [1mCheckpoint 2: 
-----------------------------------
Train ROC-AUC: 0.8312
Train Loss: 1.4697
ID Validation ROC-AUC: 0.8322
ID Validation Loss: 1.4867
ID Test ROC-AUC: 0.8295
ID Test Loss: 1.4988
OOD Validation ROC-AUC: 0.6988
OOD Validation Loss: 0.6555
OOD Test ROC-AUC: 0.7116
OOD Test Loss: 0.5724

[0m[1;37mINFO[0m: [1mChartInfo 0.9210 0.6937 0.8295 0.7116 0.8322 0.6988[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 03:04:08 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 03:04:13 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.747
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.643
SUFF++ for r=0.3 class 0.0 = 0.609 +- 0.125 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.3 class 1.0 = 0.708 +- 0.125 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.3 all KL = 0.823 +- 0.125 (in-sample avg dev_std = 0.340)
SUFF++ for r=0.3 all L1 = 0.697 +- 0.130 (in-sample avg dev_std = 0.340)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.741
SUFF++ for r=0.6 class 0.0 = 0.642 +- 0.167 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 class 1.0 = 0.84 +- 0.167 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 all KL = 0.862 +- 0.167 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.187 (in-sample avg dev_std = 0.308)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.847
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0.0 = 0.791 +- 0.107 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 class 1.0 = 0.905 +- 0.107 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all KL = 0.945 +- 0.107 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.9 all L1 = 0.892 +- 0.145 (in-sample avg dev_std = 0.179)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.64
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.58
SUFF++ for r=0.3 class 0.0 = 0.65 +- 0.145 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 1.0 = 0.663 +- 0.145 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all KL = 0.796 +- 0.145 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.128 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.687
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0.0 = 0.674 +- 0.180 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 class 1.0 = 0.752 +- 0.180 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all KL = 0.808 +- 0.180 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.6 all L1 = 0.739 +- 0.191 (in-sample avg dev_std = 0.380)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.687
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.66
SUFF++ for r=0.9 class 0.0 = 0.801 +- 0.139 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 class 1.0 = 0.837 +- 0.139 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all KL = 0.908 +- 0.139 (in-sample avg dev_std = 0.241)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.163 (in-sample avg dev_std = 0.241)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.747
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.732
NEC for r=0.3 class 0.0 = 0.227 +- 0.115 (in-sample avg dev_std = 0.233)
NEC for r=0.3 class 1.0 = 0.219 +- 0.115 (in-sample avg dev_std = 0.233)
NEC for r=0.3 all KL = 0.098 +- 0.115 (in-sample avg dev_std = 0.233)
NEC for r=0.3 all L1 = 0.22 +- 0.125 (in-sample avg dev_std = 0.233)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.826
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.804
NEC for r=0.6 class 0.0 = 0.234 +- 0.156 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 1.0 = 0.149 +- 0.156 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all KL = 0.11 +- 0.156 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all L1 = 0.159 +- 0.161 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.847
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.833
NEC for r=0.9 class 0.0 = 0.205 +- 0.133 (in-sample avg dev_std = 0.224)
NEC for r=0.9 class 1.0 = 0.114 +- 0.133 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all KL = 0.079 +- 0.133 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all L1 = 0.125 +- 0.147 (in-sample avg dev_std = 0.224)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.846
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.182 +- 0.121 (in-sample avg dev_std = 0.206)
NEC for r=1.0 class 1.0 = 0.107 +- 0.121 (in-sample avg dev_std = 0.206)
NEC for r=1.0 all KL = 0.069 +- 0.121 (in-sample avg dev_std = 0.206)
NEC for r=1.0 all L1 = 0.116 +- 0.139 (in-sample avg dev_std = 0.206)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.64
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0.0 = 0.244 +- 0.143 (in-sample avg dev_std = 0.258)
NEC for r=0.3 class 1.0 = 0.251 +- 0.143 (in-sample avg dev_std = 0.258)
NEC for r=0.3 all KL = 0.119 +- 0.143 (in-sample avg dev_std = 0.258)
NEC for r=0.3 all L1 = 0.25 +- 0.142 (in-sample avg dev_std = 0.258)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.687
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.649
NEC for r=0.6 class 0.0 = 0.229 +- 0.174 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 1.0 = 0.209 +- 0.174 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all KL = 0.135 +- 0.174 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all L1 = 0.212 +- 0.174 (in-sample avg dev_std = 0.282)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.687
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.656
NEC for r=0.9 class 0.0 = 0.198 +- 0.159 (in-sample avg dev_std = 0.254)
NEC for r=0.9 class 1.0 = 0.177 +- 0.159 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all KL = 0.107 +- 0.159 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all L1 = 0.18 +- 0.167 (in-sample avg dev_std = 0.254)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.687
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.662
NEC for r=1.0 class 0.0 = 0.188 +- 0.145 (in-sample avg dev_std = 0.236)
NEC for r=1.0 class 1.0 = 0.167 +- 0.145 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all KL = 0.093 +- 0.145 (in-sample avg dev_std = 0.236)
NEC for r=1.0 all L1 = 0.17 +- 0.156 (in-sample avg dev_std = 0.236)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.817, 0.863, 0.939, 1.0], 'all_L1': [0.751, 0.833, 0.899, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.827, 0.917, 0.962, 1.0], 'all_L1': [0.739, 0.899, 0.941, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.852, 0.894, 0.953, 1.0], 'all_L1': [0.747, 0.848, 0.918, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.844, 0.868, 0.944, 1.0], 'all_L1': [0.747, 0.823, 0.904, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.823, 0.862, 0.945, 1.0], 'all_L1': [0.697, 0.817, 0.892, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.131, 0.114, 0.082, 0.069], 'all_L1': [0.201, 0.143, 0.112, 0.101]}), defaultdict(<class 'list'>, {'all_KL': [0.116, 0.067, 0.042, 0.036], 'all_L1': [0.208, 0.086, 0.058, 0.052]}), defaultdict(<class 'list'>, {'all_KL': [0.093, 0.075, 0.048, 0.036], 'all_L1': [0.2, 0.125, 0.081, 0.067]}), defaultdict(<class 'list'>, {'all_KL': [0.082, 0.086, 0.062, 0.055], 'all_L1': [0.176, 0.135, 0.095, 0.085]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.11, 0.079, 0.069], 'all_L1': [0.22, 0.159, 0.125, 0.116]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.758, 0.807, 0.913, 1.0], 'all_L1': [0.679, 0.743, 0.842, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.791, 0.866, 0.941, 1.0], 'all_L1': [0.68, 0.83, 0.907, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.849, 0.849, 0.935, 1.0], 'all_L1': [0.73, 0.772, 0.878, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.794, 0.808, 0.911, 1.0], 'all_L1': [0.688, 0.73, 0.839, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.796, 0.808, 0.908, 1.0], 'all_L1': [0.661, 0.739, 0.831, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.142, 0.137, 0.103, 0.09], 'all_L1': [0.24, 0.207, 0.17, 0.152]}), defaultdict(<class 'list'>, {'all_KL': [0.125, 0.098, 0.072, 0.063], 'all_L1': [0.239, 0.14, 0.1, 0.09]}), defaultdict(<class 'list'>, {'all_KL': [0.089, 0.093, 0.068, 0.052], 'all_L1': [0.207, 0.175, 0.125, 0.104]}), defaultdict(<class 'list'>, {'all_KL': [0.111, 0.108, 0.092, 0.083], 'all_L1': [0.221, 0.193, 0.157, 0.143]}), defaultdict(<class 'list'>, {'all_KL': [0.119, 0.135, 0.107, 0.093], 'all_L1': [0.25, 0.212, 0.18, 0.17]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.736 +- 0.020, 0.844 +- 0.029, 0.911 +- 0.017, 1.000 +- 0.000
suff++ class all_KL  =  0.833 +- 0.013, 0.881 +- 0.022, 0.949 +- 0.008, 1.000 +- 0.000
suff++_acc_int  =  0.647 +- 0.024, 0.741 +- 0.018, 0.843 +- 0.010
nec class all_L1  =  0.201 +- 0.014, 0.130 +- 0.024, 0.094 +- 0.023, 0.084 +- 0.023
nec class all_KL  =  0.104 +- 0.017, 0.090 +- 0.019, 0.063 +- 0.016, 0.053 +- 0.015
nec_acc_int  =  0.748 +- 0.042, 0.824 +- 0.015, 0.857 +- 0.013, 0.859 +- 0.017

Eval split test
suff++ class all_L1  =  0.688 +- 0.023, 0.763 +- 0.036, 0.859 +- 0.029, 1.000 +- 0.000
suff++ class all_KL  =  0.798 +- 0.029, 0.828 +- 0.025, 0.922 +- 0.014, 1.000 +- 0.000
suff++_acc_int  =  0.588 +- 0.008, 0.638 +- 0.017, 0.692 +- 0.024
nec class all_L1  =  0.231 +- 0.015, 0.185 +- 0.026, 0.146 +- 0.030, 0.132 +- 0.030
nec class all_KL  =  0.117 +- 0.017, 0.114 +- 0.018, 0.088 +- 0.016, 0.076 +- 0.016
nec_acc_int  =  0.625 +- 0.016, 0.679 +- 0.021, 0.692 +- 0.024, 0.699 +- 0.022


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.469 +- 0.007, 0.487 +- 0.004, 0.502 +- 0.004, 0.542 +- 0.011
Faith. Armon (L1)= 		  =  0.315 +- 0.017, 0.223 +- 0.037, 0.170 +- 0.039, 0.154 +- 0.039
Faith. GMean (L1)= 	  =  0.384 +- 0.011, 0.329 +- 0.028, 0.290 +- 0.035, 0.287 +- 0.040
Faith. Aritm (KL)= 		  =  0.468 +- 0.005, 0.486 +- 0.005, 0.506 +- 0.005, 0.527 +- 0.007
Faith. Armon (KL)= 		  =  0.184 +- 0.027, 0.163 +- 0.030, 0.117 +- 0.028, 0.100 +- 0.027
Faith. GMean (KL)= 	  =  0.293 +- 0.023, 0.280 +- 0.026, 0.242 +- 0.031, 0.228 +- 0.033

Eval split test
Faith. Aritm (L1)= 		  =  0.460 +- 0.005, 0.474 +- 0.007, 0.503 +- 0.003, 0.566 +- 0.015
Faith. Armon (L1)= 		  =  0.346 +- 0.015, 0.297 +- 0.032, 0.248 +- 0.043, 0.232 +- 0.047
Faith. GMean (L1)= 	  =  0.398 +- 0.008, 0.374 +- 0.020, 0.352 +- 0.032, 0.361 +- 0.042
Faith. Aritm (KL)= 		  =  0.457 +- 0.007, 0.471 +- 0.008, 0.505 +- 0.003, 0.538 +- 0.008
Faith. Armon (KL)= 		  =  0.204 +- 0.026, 0.200 +- 0.028, 0.161 +- 0.026, 0.141 +- 0.028
Faith. GMean (KL)= 	  =  0.304 +- 0.018, 0.306 +- 0.021, 0.284 +- 0.024, 0.274 +- 0.030
Computed for split load_split = id



Completed in  0:24:49.105562  for GSATvGIN LBAPcore/assay



DONE GSAT LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:07:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:07:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9577
Train Loss: 0.1191
ID Validation ACCURACY: 0.8961
ID Validation Loss: 0.3648
ID Test ACCURACY: 0.8907
ID Test Loss: 0.3804
OOD Validation ACCURACY: 0.7797
OOD Validation Loss: 0.8828
OOD Test ACCURACY: 0.2677
OOD Test Loss: 6.4566

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9471
Train Loss: 0.1505
ID Validation ACCURACY: 0.8906
ID Validation Loss: 0.3662
ID Test ACCURACY: 0.8890
ID Test Loss: 0.3755
OOD Validation ACCURACY: 0.8057
OOD Validation Loss: 0.7317
OOD Test ACCURACY: 0.3631
OOD Test Loss: 4.0084

[0m[1;37mINFO[0m: [1mChartInfo 0.8907 0.2677 0.8890 0.3631 0.8906 0.8057[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.093
SUFF++ for r=0.3 class 0 = 0.433 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 1 = 0.525 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 2 = 0.388 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 3 = 0.483 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 4 = 0.473 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 5 = 0.399 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 6 = 0.49 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 7 = 0.531 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 8 = 0.502 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 9 = 0.52 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all KL = 0.438 +- 0.252 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all L1 = 0.476 +- 0.178 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.177
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
SUFF++ for r=0.6 class 0 = 0.297 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 1 = 0.291 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 2 = 0.362 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 3 = 0.393 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 4 = 0.274 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 5 = 0.301 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 6 = 0.315 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 7 = 0.289 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 8 = 0.303 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 class 9 = 0.298 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all KL = 0.229 +- 0.203 (in-sample avg dev_std = 0.407)
SUFF++ for r=0.6 all L1 = 0.313 +- 0.131 (in-sample avg dev_std = 0.407)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.397
SUFF++ for r=0.9 class 0 = 0.271 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 1 = 0.314 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 2 = 0.294 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 3 = 0.285 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 4 = 0.324 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 5 = 0.284 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 6 = 0.29 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 7 = 0.666 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 8 = 0.3 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 class 9 = 0.286 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 all KL = 0.108 +- 0.214 (in-sample avg dev_std = 0.748)
SUFF++ for r=0.9 all L1 = 0.335 +- 0.164 (in-sample avg dev_std = 0.748)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.474 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 1 = 0.498 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 2 = 0.382 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 3 = 0.396 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 4 = 0.407 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 5 = 0.446 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 6 = 0.423 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 7 = 0.479 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 8 = 0.432 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 class 9 = 0.45 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 all KL = 0.386 +- 0.266 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.3 all L1 = 0.439 +- 0.186 (in-sample avg dev_std = 0.478)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.1
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.1
SUFF++ for r=0.6 class 0 = 0.272 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 1 = 0.243 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 2 = 0.253 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 3 = 0.244 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 4 = 0.238 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 5 = 0.26 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 6 = 0.242 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 7 = 0.266 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 8 = 0.241 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 class 9 = 0.223 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all KL = 0.113 +- 0.145 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.6 all L1 = 0.248 +- 0.085 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.159
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.157
SUFF++ for r=0.9 class 0 = 0.227 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 1 = 0.257 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 2 = 0.237 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 3 = 0.247 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 4 = 0.212 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 5 = 0.218 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 6 = 0.22 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 7 = 0.204 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 8 = 0.213 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 class 9 = 0.213 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 all KL = 0.028 +- 0.060 (in-sample avg dev_std = 0.529)
SUFF++ for r=0.9 all L1 = 0.225 +- 0.079 (in-sample avg dev_std = 0.529)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.54 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 1 = 0.485 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 2 = 0.538 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 3 = 0.494 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 4 = 0.489 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 5 = 0.527 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 6 = 0.491 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 7 = 0.481 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 8 = 0.457 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 class 9 = 0.437 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all KL = 0.508 +- 0.269 (in-sample avg dev_std = 0.415)
NEC for r=0.3 all L1 = 0.494 +- 0.193 (in-sample avg dev_std = 0.415)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.177
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
NEC for r=0.6 class 0 = 0.659 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 1 = 0.7 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 2 = 0.602 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 3 = 0.587 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 4 = 0.655 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 5 = 0.627 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 6 = 0.634 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 7 = 0.626 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 8 = 0.65 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 class 9 = 0.645 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all KL = 0.704 +- 0.203 (in-sample avg dev_std = 0.384)
NEC for r=0.6 all L1 = 0.639 +- 0.129 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.684
NEC for r=0.9 class 0 = 0.497 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 1 = 0.386 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 2 = 0.378 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 3 = 0.412 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 4 = 0.388 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 5 = 0.445 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 6 = 0.508 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 7 = 0.363 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 8 = 0.285 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 9 = 0.507 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all KL = 0.556 +- 0.298 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all L1 = 0.415 +- 0.245 (in-sample avg dev_std = 0.449)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.928
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.842
NEC for r=1.0 class 0 = 0.098 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 1 = 0.061 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 2 = 0.301 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 3 = 0.252 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 4 = 0.175 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 5 = 0.308 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 6 = 0.282 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 7 = 0.2 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 8 = 0.214 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 9 = 0.266 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 all KL = 0.296 +- 0.301 (in-sample avg dev_std = 0.342)
NEC for r=1.0 all L1 = 0.212 +- 0.231 (in-sample avg dev_std = 0.342)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.11
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
NEC for r=0.3 class 0 = 0.519 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 1 = 0.52 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 2 = 0.608 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 3 = 0.591 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 4 = 0.633 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 5 = 0.573 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 6 = 0.615 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 7 = 0.556 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 8 = 0.593 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 class 9 = 0.614 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all KL = 0.635 +- 0.289 (in-sample avg dev_std = 0.388)
NEC for r=0.3 all L1 = 0.581 +- 0.187 (in-sample avg dev_std = 0.388)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.1
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.102
NEC for r=0.6 class 0 = 0.694 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 1 = 0.659 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 2 = 0.659 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 3 = 0.694 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 4 = 0.661 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 5 = 0.686 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 6 = 0.681 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 7 = 0.661 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 8 = 0.729 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 class 9 = 0.68 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 all KL = 0.806 +- 0.197 (in-sample avg dev_std = 0.383)
NEC for r=0.6 all L1 = 0.68 +- 0.148 (in-sample avg dev_std = 0.383)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.159
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.23
NEC for r=0.9 class 0 = 0.671 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 1 = 0.547 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 2 = 0.597 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 3 = 0.611 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 4 = 0.737 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 5 = 0.666 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 6 = 0.717 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 7 = 0.72 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 8 = 0.699 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 class 9 = 0.746 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 all KL = 0.785 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=0.9 all L1 = 0.669 +- 0.202 (in-sample avg dev_std = 0.397)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.273
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.327
NEC for r=1.0 class 0 = 0.474 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 1 = 0.459 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 2 = 0.601 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 3 = 0.589 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 4 = 0.652 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 5 = 0.644 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 6 = 0.683 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 7 = 0.667 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 8 = 0.649 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 class 9 = 0.71 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 all KL = 0.692 +- 0.310 (in-sample avg dev_std = 0.325)
NEC for r=1.0 all L1 = 0.61 +- 0.241 (in-sample avg dev_std = 0.325)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:24:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:24:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 195...
[0m[1;37mINFO[0m: [1mCheckpoint 195: 
-----------------------------------
Train ACCURACY: 0.9525
Train Loss: 0.1347
ID Validation ACCURACY: 0.8934
ID Validation Loss: 0.3753
ID Test ACCURACY: 0.8850
ID Test Loss: 0.4006
OOD Validation ACCURACY: 0.7796
OOD Validation Loss: 0.9275
OOD Test ACCURACY: 0.2351
OOD Test Loss: 6.0508

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9504
Train Loss: 0.1404
ID Validation ACCURACY: 0.8880
ID Validation Loss: 0.3623
ID Test ACCURACY: 0.8880
ID Test Loss: 0.3744
OOD Validation ACCURACY: 0.8044
OOD Validation Loss: 0.7478
OOD Test ACCURACY: 0.2784
OOD Test Loss: 5.7807

[0m[1;37mINFO[0m: [1mChartInfo 0.8850 0.2351 0.8880 0.2784 0.8880 0.8044[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
SUFF++ for r=0.3 class 0 = 0.635 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 1 = 0.559 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 2 = 0.732 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 3 = 0.654 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 4 = 0.618 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 5 = 0.671 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 6 = 0.636 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 7 = 0.685 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 8 = 0.542 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 class 9 = 0.582 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 all KL = 0.693 +- 0.264 (in-sample avg dev_std = 0.303)
SUFF++ for r=0.3 all L1 = 0.631 +- 0.245 (in-sample avg dev_std = 0.303)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.21
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.142
SUFF++ for r=0.6 class 0 = 0.312 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1 = 0.316 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 2 = 0.439 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 3 = 0.394 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 4 = 0.434 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 5 = 0.46 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 6 = 0.368 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 7 = 0.505 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 8 = 0.313 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 9 = 0.401 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.328 +- 0.250 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.393 +- 0.175 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.411
SUFF++ for r=0.9 class 0 = 0.29 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 1 = 0.351 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 2 = 0.298 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 3 = 0.31 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 4 = 0.315 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 5 = 0.28 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 6 = 0.304 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 7 = 0.697 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 8 = 0.304 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 class 9 = 0.383 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 all KL = 0.133 +- 0.218 (in-sample avg dev_std = 0.741)
SUFF++ for r=0.9 all L1 = 0.358 +- 0.171 (in-sample avg dev_std = 0.741)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.118
SUFF++ for r=0.3 class 0 = 0.378 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 1 = 0.472 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 2 = 0.391 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 3 = 0.377 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 4 = 0.311 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 5 = 0.383 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 6 = 0.347 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 7 = 0.373 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 8 = 0.392 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 9 = 0.341 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all KL = 0.321 +- 0.293 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all L1 = 0.378 +- 0.185 (in-sample avg dev_std = 0.445)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
SUFF++ for r=0.6 class 0 = 0.28 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 1 = 0.293 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 2 = 0.269 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 3 = 0.252 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 4 = 0.214 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 5 = 0.275 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 6 = 0.248 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 7 = 0.267 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 8 = 0.259 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 9 = 0.228 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all KL = 0.117 +- 0.186 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all L1 = 0.259 +- 0.133 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.228
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.176
SUFF++ for r=0.9 class 0 = 0.214 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 1 = 0.333 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 2 = 0.256 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 3 = 0.235 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 4 = 0.289 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 5 = 0.234 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 6 = 0.256 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 7 = 0.251 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 8 = 0.241 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 class 9 = 0.259 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 all KL = 0.031 +- 0.055 (in-sample avg dev_std = 0.618)
SUFF++ for r=0.9 all L1 = 0.258 +- 0.083 (in-sample avg dev_std = 0.618)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.377 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 1 = 0.392 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 2 = 0.266 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 3 = 0.315 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 4 = 0.369 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 5 = 0.299 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 6 = 0.361 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 7 = 0.309 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 8 = 0.408 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 class 9 = 0.41 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all KL = 0.29 +- 0.263 (in-sample avg dev_std = 0.293)
NEC for r=0.3 all L1 = 0.35 +- 0.228 (in-sample avg dev_std = 0.293)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.21
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.17
NEC for r=0.6 class 0 = 0.632 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 1 = 0.65 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 2 = 0.51 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 3 = 0.519 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 4 = 0.51 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 5 = 0.469 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 6 = 0.562 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 7 = 0.445 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 8 = 0.643 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 class 9 = 0.561 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 all KL = 0.604 +- 0.278 (in-sample avg dev_std = 0.419)
NEC for r=0.6 all L1 = 0.551 +- 0.205 (in-sample avg dev_std = 0.419)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.789
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.693
NEC for r=0.9 class 0 = 0.419 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 1 = 0.164 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 2 = 0.472 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 3 = 0.357 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 4 = 0.429 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 5 = 0.534 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 6 = 0.495 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 7 = 0.24 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 8 = 0.277 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 class 9 = 0.513 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 all KL = 0.5 +- 0.327 (in-sample avg dev_std = 0.435)
NEC for r=0.9 all L1 = 0.382 +- 0.261 (in-sample avg dev_std = 0.435)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0 = 0.098 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 1 = 0.019 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 2 = 0.317 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 3 = 0.333 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 4 = 0.174 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 5 = 0.384 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 6 = 0.255 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 7 = 0.181 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 8 = 0.182 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 class 9 = 0.342 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all KL = 0.311 +- 0.320 (in-sample avg dev_std = 0.345)
NEC for r=1.0 all L1 = 0.224 +- 0.248 (in-sample avg dev_std = 0.345)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.1
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.131
NEC for r=0.3 class 0 = 0.612 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 1 = 0.478 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 2 = 0.59 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 3 = 0.591 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 4 = 0.665 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 5 = 0.581 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 6 = 0.622 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 7 = 0.585 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 8 = 0.565 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 class 9 = 0.632 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 all KL = 0.655 +- 0.306 (in-sample avg dev_std = 0.411)
NEC for r=0.3 all L1 = 0.591 +- 0.210 (in-sample avg dev_std = 0.411)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.157
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.162
NEC for r=0.6 class 0 = 0.715 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 1 = 0.367 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 2 = 0.719 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 3 = 0.733 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 4 = 0.752 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 5 = 0.688 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 6 = 0.68 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 7 = 0.698 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 8 = 0.714 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 class 9 = 0.716 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all KL = 0.83 +- 0.244 (in-sample avg dev_std = 0.473)
NEC for r=0.6 all L1 = 0.675 +- 0.210 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.228
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.272
NEC for r=0.9 class 0 = 0.704 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.278 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.564 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 3 = 0.638 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 4 = 0.5 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 5 = 0.613 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 6 = 0.642 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 7 = 0.62 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 8 = 0.618 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 9 = 0.627 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.75 +- 0.291 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.577 +- 0.240 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.237
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.326
NEC for r=1.0 class 0 = 0.598 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 1 = 0.463 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 2 = 0.539 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 3 = 0.605 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 4 = 0.494 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 5 = 0.515 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 6 = 0.588 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 7 = 0.6 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 8 = 0.592 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 class 9 = 0.561 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 all KL = 0.685 +- 0.288 (in-sample avg dev_std = 0.381)
NEC for r=1.0 all L1 = 0.555 +- 0.216 (in-sample avg dev_std = 0.381)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:41:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:41:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.9563
Train Loss: 0.1251
ID Validation ACCURACY: 0.8953
ID Validation Loss: 0.3825
ID Test ACCURACY: 0.8890
ID Test Loss: 0.4034
OOD Validation ACCURACY: 0.7610
OOD Validation Loss: 1.0349
OOD Test ACCURACY: 0.3757
OOD Test Loss: 4.5211

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 165...
[0m[1;37mINFO[0m: [1mCheckpoint 165: 
-----------------------------------
Train ACCURACY: 0.9359
Train Loss: 0.1833
ID Validation ACCURACY: 0.8829
ID Validation Loss: 0.4135
ID Test ACCURACY: 0.8829
ID Test Loss: 0.4120
OOD Validation ACCURACY: 0.8049
OOD Validation Loss: 0.7120
OOD Test ACCURACY: 0.3070
OOD Test Loss: 5.3571

[0m[1;37mINFO[0m: [1mChartInfo 0.8890 0.3757 0.8829 0.3070 0.8829 0.8049[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.114
SUFF++ for r=0.3 class 0 = 0.47 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 1 = 0.491 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 2 = 0.489 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 3 = 0.541 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 4 = 0.466 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 5 = 0.588 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 6 = 0.47 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 7 = 0.567 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 8 = 0.49 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 class 9 = 0.554 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 all KL = 0.45 +- 0.282 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.3 all L1 = 0.512 +- 0.204 (in-sample avg dev_std = 0.461)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.112
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
SUFF++ for r=0.6 class 0 = 0.358 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 1 = 0.521 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 2 = 0.425 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 3 = 0.506 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 4 = 0.386 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 5 = 0.571 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 6 = 0.403 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 7 = 0.471 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 8 = 0.424 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 class 9 = 0.466 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all KL = 0.359 +- 0.282 (in-sample avg dev_std = 0.433)
SUFF++ for r=0.6 all L1 = 0.453 +- 0.232 (in-sample avg dev_std = 0.433)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.399
SUFF++ for r=0.9 class 0 = 0.285 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 1 = 0.34 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 2 = 0.329 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 3 = 0.281 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 4 = 0.313 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 5 = 0.26 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 6 = 0.292 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 7 = 0.61 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 8 = 0.306 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 class 9 = 0.356 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 all KL = 0.093 +- 0.167 (in-sample avg dev_std = 0.743)
SUFF++ for r=0.9 all L1 = 0.341 +- 0.153 (in-sample avg dev_std = 0.743)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.481 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 1 = 0.392 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 2 = 0.489 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 3 = 0.473 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 4 = 0.463 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 5 = 0.457 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 6 = 0.488 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 7 = 0.491 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 8 = 0.492 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 class 9 = 0.438 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 all KL = 0.481 +- 0.278 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.3 all L1 = 0.466 +- 0.149 (in-sample avg dev_std = 0.446)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.146
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
SUFF++ for r=0.6 class 0 = 0.374 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 1 = 0.263 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 2 = 0.306 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 3 = 0.331 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 4 = 0.288 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 5 = 0.334 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 6 = 0.338 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 7 = 0.327 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 8 = 0.372 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 9 = 0.334 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 all KL = 0.197 +- 0.231 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 all L1 = 0.326 +- 0.180 (in-sample avg dev_std = 0.510)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.235
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.18
SUFF++ for r=0.9 class 0 = 0.251 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 1 = 0.379 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 2 = 0.276 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 3 = 0.255 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 4 = 0.252 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 5 = 0.255 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 6 = 0.261 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 7 = 0.257 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 8 = 0.259 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 class 9 = 0.258 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 all KL = 0.046 +- 0.076 (in-sample avg dev_std = 0.664)
SUFF++ for r=0.9 all L1 = 0.272 +- 0.091 (in-sample avg dev_std = 0.664)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.126
NEC for r=0.3 class 0 = 0.484 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 1 = 0.478 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 2 = 0.476 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 3 = 0.436 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 4 = 0.511 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 5 = 0.291 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 6 = 0.47 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 7 = 0.385 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 8 = 0.48 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 class 9 = 0.433 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all KL = 0.483 +- 0.315 (in-sample avg dev_std = 0.414)
NEC for r=0.3 all L1 = 0.446 +- 0.244 (in-sample avg dev_std = 0.414)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.112
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.136
NEC for r=0.6 class 0 = 0.58 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 1 = 0.493 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 2 = 0.461 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 3 = 0.477 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 4 = 0.605 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 5 = 0.394 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 6 = 0.548 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 7 = 0.496 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 8 = 0.568 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 class 9 = 0.52 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all KL = 0.585 +- 0.310 (in-sample avg dev_std = 0.412)
NEC for r=0.6 all L1 = 0.514 +- 0.244 (in-sample avg dev_std = 0.412)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.786
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.665
NEC for r=0.9 class 0 = 0.459 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 1 = 0.233 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 2 = 0.311 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 3 = 0.475 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 4 = 0.457 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 5 = 0.555 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 6 = 0.477 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 7 = 0.283 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 8 = 0.363 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 9 = 0.558 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 all KL = 0.559 +- 0.313 (in-sample avg dev_std = 0.470)
NEC for r=0.9 all L1 = 0.41 +- 0.254 (in-sample avg dev_std = 0.470)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.855
NEC for r=1.0 class 0 = 0.063 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 1 = 0.008 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 2 = 0.235 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 3 = 0.282 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 4 = 0.224 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 5 = 0.365 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 6 = 0.206 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 7 = 0.161 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 8 = 0.169 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 class 9 = 0.298 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 all KL = 0.285 +- 0.309 (in-sample avg dev_std = 0.331)
NEC for r=1.0 all L1 = 0.196 +- 0.232 (in-sample avg dev_std = 0.331)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.493 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 1 = 0.561 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 2 = 0.514 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 3 = 0.497 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 4 = 0.509 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 5 = 0.504 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 6 = 0.494 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 7 = 0.471 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 8 = 0.479 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 class 9 = 0.539 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 all KL = 0.495 +- 0.293 (in-sample avg dev_std = 0.409)
NEC for r=0.3 all L1 = 0.507 +- 0.196 (in-sample avg dev_std = 0.409)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.146
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.148
NEC for r=0.6 class 0 = 0.656 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 1 = 0.534 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 2 = 0.673 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 3 = 0.659 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 4 = 0.678 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 5 = 0.677 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 6 = 0.637 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 7 = 0.633 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 8 = 0.625 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 class 9 = 0.603 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all KL = 0.769 +- 0.241 (in-sample avg dev_std = 0.458)
NEC for r=0.6 all L1 = 0.636 +- 0.192 (in-sample avg dev_std = 0.458)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.235
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.263
NEC for r=0.9 class 0 = 0.661 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 1 = 0.186 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 2 = 0.481 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 3 = 0.548 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 4 = 0.506 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 5 = 0.572 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 6 = 0.566 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 7 = 0.592 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 8 = 0.574 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 9 = 0.612 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 all KL = 0.653 +- 0.334 (in-sample avg dev_std = 0.420)
NEC for r=0.9 all L1 = 0.525 +- 0.266 (in-sample avg dev_std = 0.420)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.382
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.386
NEC for r=1.0 class 0 = 0.522 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 1 = 0.057 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 2 = 0.299 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 3 = 0.472 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 4 = 0.505 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 5 = 0.518 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 6 = 0.51 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 7 = 0.421 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 8 = 0.485 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 class 9 = 0.508 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all KL = 0.504 +- 0.355 (in-sample avg dev_std = 0.380)
NEC for r=1.0 all L1 = 0.423 +- 0.284 (in-sample avg dev_std = 0.380)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 15:58:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 03:58:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 195...
[0m[1;37mINFO[0m: [1mCheckpoint 195: 
-----------------------------------
Train ACCURACY: 0.9530
Train Loss: 0.1347
ID Validation ACCURACY: 0.8939
ID Validation Loss: 0.3805
ID Test ACCURACY: 0.8906
ID Test Loss: 0.3916
OOD Validation ACCURACY: 0.7736
OOD Validation Loss: 0.8778
OOD Test ACCURACY: 0.2604
OOD Test Loss: 5.6625

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 173...
[0m[1;37mINFO[0m: [1mCheckpoint 173: 
-----------------------------------
Train ACCURACY: 0.9409
Train Loss: 0.1679
ID Validation ACCURACY: 0.8884
ID Validation Loss: 0.3795
ID Test ACCURACY: 0.8903
ID Test Loss: 0.3857
OOD Validation ACCURACY: 0.8063
OOD Validation Loss: 0.7133
OOD Test ACCURACY: 0.2663
OOD Test Loss: 4.7473

[0m[1;37mINFO[0m: [1mChartInfo 0.8906 0.2604 0.8903 0.2663 0.8884 0.8063[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
SUFF++ for r=0.3 class 0 = 0.566 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 1 = 0.763 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 2 = 0.734 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 3 = 0.766 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 4 = 0.755 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 5 = 0.709 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 6 = 0.756 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 7 = 0.776 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 8 = 0.678 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 class 9 = 0.723 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all KL = 0.69 +- 0.291 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.3 all L1 = 0.724 +- 0.259 (in-sample avg dev_std = 0.272)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
SUFF++ for r=0.6 class 0 = 0.264 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 1 = 0.758 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 2 = 0.322 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 3 = 0.34 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 4 = 0.333 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 5 = 0.373 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 6 = 0.354 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 7 = 0.426 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 8 = 0.266 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 class 9 = 0.331 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all KL = 0.293 +- 0.278 (in-sample avg dev_std = 0.482)
SUFF++ for r=0.6 all L1 = 0.382 +- 0.224 (in-sample avg dev_std = 0.482)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.804
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.429
SUFF++ for r=0.9 class 0 = 0.29 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 1 = 0.636 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 2 = 0.316 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 3 = 0.308 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 4 = 0.33 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 5 = 0.266 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 6 = 0.296 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 7 = 0.737 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 8 = 0.297 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 class 9 = 0.274 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 all KL = 0.164 +- 0.269 (in-sample avg dev_std = 0.709)
SUFF++ for r=0.9 all L1 = 0.384 +- 0.219 (in-sample avg dev_std = 0.709)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.139
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.447 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 1 = 0.384 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 2 = 0.523 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 3 = 0.508 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 4 = 0.496 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 5 = 0.503 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 6 = 0.56 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 7 = 0.6 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 8 = 0.585 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 9 = 0.513 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all KL = 0.425 +- 0.314 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all L1 = 0.51 +- 0.250 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.132
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.119
SUFF++ for r=0.6 class 0 = 0.282 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 1 = 0.27 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 2 = 0.266 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 3 = 0.283 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 4 = 0.263 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 5 = 0.296 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 6 = 0.288 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 7 = 0.302 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 8 = 0.329 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 class 9 = 0.29 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 all KL = 0.117 +- 0.202 (in-sample avg dev_std = 0.629)
SUFF++ for r=0.6 all L1 = 0.287 +- 0.141 (in-sample avg dev_std = 0.629)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.18
SUFF++ for r=0.9 class 0 = 0.292 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 1 = 0.298 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 2 = 0.273 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 3 = 0.258 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 4 = 0.275 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 5 = 0.238 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 6 = 0.313 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 7 = 0.274 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 8 = 0.264 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 class 9 = 0.307 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 all KL = 0.092 +- 0.152 (in-sample avg dev_std = 0.548)
SUFF++ for r=0.9 all L1 = 0.28 +- 0.131 (in-sample avg dev_std = 0.548)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.456 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 1 = 0.242 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 2 = 0.274 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 3 = 0.257 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 4 = 0.297 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 5 = 0.282 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 6 = 0.267 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 7 = 0.234 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 8 = 0.356 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 class 9 = 0.278 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 all KL = 0.339 +- 0.312 (in-sample avg dev_std = 0.311)
NEC for r=0.3 all L1 = 0.293 +- 0.260 (in-sample avg dev_std = 0.311)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.145
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
NEC for r=0.6 class 0 = 0.628 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 1 = 0.288 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 2 = 0.622 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 3 = 0.63 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 4 = 0.623 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 5 = 0.603 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 6 = 0.603 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 7 = 0.519 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 8 = 0.655 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 class 9 = 0.633 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all KL = 0.669 +- 0.255 (in-sample avg dev_std = 0.444)
NEC for r=0.6 all L1 = 0.576 +- 0.199 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.804
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.691
NEC for r=0.9 class 0 = 0.487 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.258 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.391 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 3 = 0.324 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 4 = 0.393 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 5 = 0.552 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 6 = 0.487 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 7 = 0.288 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 8 = 0.324 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 9 = 0.544 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.539 +- 0.320 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.398 +- 0.261 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.919
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.845
NEC for r=1.0 class 0 = 0.093 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 1 = 0.019 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 2 = 0.248 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 3 = 0.269 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 4 = 0.193 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 5 = 0.349 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 6 = 0.246 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 7 = 0.185 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 8 = 0.199 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 class 9 = 0.355 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all KL = 0.311 +- 0.313 (in-sample avg dev_std = 0.357)
NEC for r=1.0 all L1 = 0.21 +- 0.233 (in-sample avg dev_std = 0.357)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.139
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.117
NEC for r=0.3 class 0 = 0.55 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 1 = 0.619 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 2 = 0.49 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 3 = 0.526 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 4 = 0.508 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 5 = 0.504 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 6 = 0.437 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 7 = 0.43 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 8 = 0.446 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 class 9 = 0.513 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all KL = 0.601 +- 0.316 (in-sample avg dev_std = 0.394)
NEC for r=0.3 all L1 = 0.504 +- 0.247 (in-sample avg dev_std = 0.394)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.132
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.144
NEC for r=0.6 class 0 = 0.55 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 1 = 0.739 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 2 = 0.568 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 3 = 0.549 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 4 = 0.642 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 5 = 0.586 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 6 = 0.655 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 7 = 0.562 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 8 = 0.603 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 9 = 0.634 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all KL = 0.731 +- 0.262 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all L1 = 0.61 +- 0.194 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.172
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.205
NEC for r=0.9 class 0 = 0.611 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 1 = 0.669 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 2 = 0.55 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 3 = 0.644 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 4 = 0.694 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 5 = 0.665 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 6 = 0.668 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 7 = 0.661 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 8 = 0.718 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 class 9 = 0.721 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 all KL = 0.779 +- 0.240 (in-sample avg dev_std = 0.402)
NEC for r=0.9 all L1 = 0.659 +- 0.191 (in-sample avg dev_std = 0.402)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.261
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.295
NEC for r=1.0 class 0 = 0.568 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 1 = 0.547 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 2 = 0.574 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 3 = 0.538 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 4 = 0.622 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 5 = 0.587 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 6 = 0.591 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 7 = 0.61 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 8 = 0.65 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 class 9 = 0.646 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all KL = 0.688 +- 0.296 (in-sample avg dev_std = 0.364)
NEC for r=1.0 all L1 = 0.592 +- 0.228 (in-sample avg dev_std = 0.364)
model_dirname= repr_GSATvGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatmitig_readoutweightedavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 16:14:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:41 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:41 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mInit vGINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  weighted
[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 09/28/2024 04:14:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.9564
Train Loss: 0.1236
ID Validation ACCURACY: 0.8974
ID Validation Loss: 0.3664
ID Test ACCURACY: 0.8890
ID Test Loss: 0.3872
OOD Validation ACCURACY: 0.7263
OOD Validation Loss: 1.3274
OOD Test ACCURACY: 0.2876
OOD Test Loss: 7.4089

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 170...
[0m[1;37mINFO[0m: [1mCheckpoint 170: 
-----------------------------------
Train ACCURACY: 0.9481
Train Loss: 0.1490
ID Validation ACCURACY: 0.8914
ID Validation Loss: 0.3625
ID Test ACCURACY: 0.8883
ID Test Loss: 0.3817
OOD Validation ACCURACY: 0.8150
OOD Validation Loss: 0.7224
OOD Test ACCURACY: 0.3173
OOD Test Loss: 4.4169

[0m[1;37mINFO[0m: [1mChartInfo 0.8890 0.2876 0.8883 0.3173 0.8914 0.8150[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.127
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.118
SUFF++ for r=0.3 class 0 = 0.641 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 1 = 0.77 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 2 = 0.628 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 3 = 0.723 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 4 = 0.766 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 5 = 0.751 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 6 = 0.775 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 7 = 0.857 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 8 = 0.582 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 class 9 = 0.75 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 all KL = 0.647 +- 0.353 (in-sample avg dev_std = 0.353)
SUFF++ for r=0.3 all L1 = 0.725 +- 0.288 (in-sample avg dev_std = 0.353)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.262
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.164
SUFF++ for r=0.6 class 0 = 0.334 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 1 = 0.317 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 2 = 0.409 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 3 = 0.402 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 4 = 0.451 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 5 = 0.415 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 6 = 0.446 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 7 = 0.614 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 8 = 0.243 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 9 = 0.476 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all KL = 0.28 +- 0.262 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all L1 = 0.411 +- 0.228 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.442
SUFF++ for r=0.9 class 0 = 0.294 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 1 = 0.824 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 2 = 0.305 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 3 = 0.296 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 4 = 0.317 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 5 = 0.281 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 6 = 0.323 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 7 = 0.595 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 8 = 0.306 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 class 9 = 0.276 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 all KL = 0.12 +- 0.226 (in-sample avg dev_std = 0.715)
SUFF++ for r=0.9 all L1 = 0.391 +- 0.217 (in-sample avg dev_std = 0.715)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.879 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 1 = 0.792 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 2 = 0.87 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 3 = 0.837 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 4 = 0.907 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 5 = 0.825 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 6 = 0.82 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 7 = 0.802 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 8 = 0.847 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 class 9 = 0.789 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 all KL = 0.801 +- 0.302 (in-sample avg dev_std = 0.221)
SUFF++ for r=0.3 all L1 = 0.837 +- 0.255 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.149
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
SUFF++ for r=0.6 class 0 = 0.425 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 1 = 0.277 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 2 = 0.348 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 3 = 0.363 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 4 = 0.302 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 5 = 0.344 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 6 = 0.327 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 7 = 0.364 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 8 = 0.446 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 class 9 = 0.299 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all KL = 0.224 +- 0.257 (in-sample avg dev_std = 0.479)
SUFF++ for r=0.6 all L1 = 0.349 +- 0.203 (in-sample avg dev_std = 0.479)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.174
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.195
SUFF++ for r=0.9 class 0 = 0.325 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 1 = 0.361 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 2 = 0.275 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 3 = 0.326 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 4 = 0.276 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 5 = 0.311 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 6 = 0.33 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 7 = 0.342 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 8 = 0.331 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 class 9 = 0.364 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 all KL = 0.152 +- 0.226 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.9 all L1 = 0.324 +- 0.186 (in-sample avg dev_std = 0.516)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.127
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.127
NEC for r=0.3 class 0 = 0.396 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 1 = 0.278 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 2 = 0.395 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 3 = 0.308 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 4 = 0.26 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 5 = 0.277 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 6 = 0.251 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 7 = 0.162 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 8 = 0.468 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 class 9 = 0.269 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 all KL = 0.407 +- 0.366 (in-sample avg dev_std = 0.398)
NEC for r=0.3 all L1 = 0.306 +- 0.287 (in-sample avg dev_std = 0.398)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.262
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.215
NEC for r=0.6 class 0 = 0.678 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 1 = 0.521 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 2 = 0.578 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 3 = 0.589 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 4 = 0.565 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 5 = 0.581 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 6 = 0.553 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 7 = 0.399 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 8 = 0.704 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 class 9 = 0.529 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 all KL = 0.69 +- 0.276 (in-sample avg dev_std = 0.434)
NEC for r=0.6 all L1 = 0.567 +- 0.225 (in-sample avg dev_std = 0.434)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.695
NEC for r=0.9 class 0 = 0.44 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.096 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.372 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 3 = 0.355 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 4 = 0.465 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 5 = 0.46 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 6 = 0.538 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 7 = 0.201 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 8 = 0.313 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 9 = 0.589 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.506 +- 0.328 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.374 +- 0.262 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.931
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.854
NEC for r=1.0 class 0 = 0.088 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 1 = 0.024 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 2 = 0.246 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 3 = 0.215 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 4 = 0.186 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 5 = 0.347 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 6 = 0.268 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 7 = 0.14 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 8 = 0.206 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 class 9 = 0.342 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 all KL = 0.287 +- 0.309 (in-sample avg dev_std = 0.336)
NEC for r=1.0 all L1 = 0.2 +- 0.234 (in-sample avg dev_std = 0.336)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.132 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 1 = 0.246 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 2 = 0.135 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 3 = 0.176 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 4 = 0.11 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 5 = 0.188 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 6 = 0.185 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 7 = 0.192 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 8 = 0.163 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 class 9 = 0.232 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 all KL = 0.235 +- 0.314 (in-sample avg dev_std = 0.248)
NEC for r=0.3 all L1 = 0.176 +- 0.251 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.149
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.183
NEC for r=0.6 class 0 = 0.551 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 1 = 0.552 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 2 = 0.611 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 3 = 0.597 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 4 = 0.652 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 5 = 0.658 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 6 = 0.639 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 7 = 0.59 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 8 = 0.546 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 9 = 0.657 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all KL = 0.712 +- 0.293 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all L1 = 0.604 +- 0.238 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.174
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.26
NEC for r=0.9 class 0 = 0.663 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 1 = 0.566 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 2 = 0.632 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 3 = 0.643 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 4 = 0.687 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 5 = 0.638 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 6 = 0.724 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 7 = 0.665 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 8 = 0.696 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 9 = 0.68 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all KL = 0.794 +- 0.251 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all L1 = 0.658 +- 0.206 (in-sample avg dev_std = 0.393)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.289
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.38
NEC for r=1.0 class 0 = 0.453 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 1 = 0.501 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 2 = 0.501 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 3 = 0.551 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 4 = 0.616 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 5 = 0.589 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 6 = 0.631 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 7 = 0.518 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 8 = 0.641 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 9 = 0.62 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all KL = 0.647 +- 0.310 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all L1 = 0.56 +- 0.247 (in-sample avg dev_std = 0.354)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.438, 0.229, 0.108, 1.0], 'all_L1': [0.476, 0.313, 0.335, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.693, 0.328, 0.133, 1.0], 'all_L1': [0.631, 0.393, 0.358, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.45, 0.359, 0.093, 1.0], 'all_L1': [0.512, 0.453, 0.341, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.69, 0.293, 0.164, 1.0], 'all_L1': [0.724, 0.382, 0.384, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.647, 0.28, 0.12, 1.0], 'all_L1': [0.725, 0.411, 0.391, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.508, 0.704, 0.556, 0.296], 'all_L1': [0.494, 0.639, 0.415, 0.212]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.604, 0.5, 0.311], 'all_L1': [0.35, 0.551, 0.382, 0.224]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.585, 0.559, 0.285], 'all_L1': [0.446, 0.514, 0.41, 0.196]}), defaultdict(<class 'list'>, {'all_KL': [0.339, 0.669, 0.539, 0.311], 'all_L1': [0.293, 0.576, 0.398, 0.21]}), defaultdict(<class 'list'>, {'all_KL': [0.407, 0.69, 0.506, 0.287], 'all_L1': [0.306, 0.567, 0.374, 0.2]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.386, 0.113, 0.028, 1.0], 'all_L1': [0.439, 0.248, 0.225, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.321, 0.117, 0.031, 1.0], 'all_L1': [0.378, 0.259, 0.258, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.481, 0.197, 0.046, 1.0], 'all_L1': [0.466, 0.326, 0.272, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.425, 0.117, 0.092, 1.0], 'all_L1': [0.51, 0.287, 0.28, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.801, 0.224, 0.152, 1.0], 'all_L1': [0.837, 0.349, 0.324, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.635, 0.806, 0.785, 0.692], 'all_L1': [0.581, 0.68, 0.669, 0.61]}), defaultdict(<class 'list'>, {'all_KL': [0.655, 0.83, 0.75, 0.685], 'all_L1': [0.591, 0.675, 0.577, 0.555]}), defaultdict(<class 'list'>, {'all_KL': [0.495, 0.769, 0.653, 0.504], 'all_L1': [0.507, 0.636, 0.525, 0.423]}), defaultdict(<class 'list'>, {'all_KL': [0.601, 0.731, 0.779, 0.688], 'all_L1': [0.504, 0.61, 0.659, 0.592]}), defaultdict(<class 'list'>, {'all_KL': [0.235, 0.712, 0.794, 0.647], 'all_L1': [0.176, 0.604, 0.658, 0.56]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.614 +- 0.104, 0.390 +- 0.046, 0.362 +- 0.022, 1.000 +- 0.000
suff++ class all_KL  =  0.584 +- 0.115, 0.298 +- 0.044, 0.124 +- 0.024, 1.000 +- 0.000
suff++_acc_int  =  0.110 +- 0.009, 0.132 +- 0.019, 0.415 +- 0.017
nec class all_L1  =  0.378 +- 0.079, 0.569 +- 0.041, 0.396 +- 0.016, 0.208 +- 0.010
nec class all_KL  =  0.405 +- 0.083, 0.650 +- 0.047, 0.532 +- 0.025, 0.298 +- 0.011
nec_acc_int  =  0.116 +- 0.011, 0.157 +- 0.032, 0.686 +- 0.011, 0.845 +- 0.009

Eval split test
suff++ class all_L1  =  0.526 +- 0.161, 0.294 +- 0.039, 0.272 +- 0.032, 1.000 +- 0.000
suff++ class all_KL  =  0.483 +- 0.167, 0.154 +- 0.047, 0.070 +- 0.047, 1.000 +- 0.000
suff++_acc_int  =  0.106 +- 0.006, 0.125 +- 0.016, 0.178 +- 0.012
nec class all_L1  =  0.472 +- 0.152, 0.641 +- 0.032, 0.618 +- 0.057, 0.548 +- 0.066
nec class all_KL  =  0.524 +- 0.155, 0.770 +- 0.044, 0.752 +- 0.052, 0.643 +- 0.071
nec_acc_int  =  0.114 +- 0.009, 0.148 +- 0.027, 0.246 +- 0.025, 0.343 +- 0.035


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.496 +- 0.014, 0.480 +- 0.006, 0.379 +- 0.007, 0.604 +- 0.005
Faith. Armon (L1)= 		  =  0.452 +- 0.026, 0.459 +- 0.022, 0.377 +- 0.008, 0.345 +- 0.013
Faith. GMean (L1)= 	  =  0.473 +- 0.008, 0.469 +- 0.013, 0.378 +- 0.008, 0.456 +- 0.011
Faith. Aritm (KL)= 		  =  0.495 +- 0.023, 0.474 +- 0.008, 0.328 +- 0.014, 0.649 +- 0.006
Faith. Armon (KL)= 		  =  0.460 +- 0.030, 0.404 +- 0.033, 0.199 +- 0.031, 0.459 +- 0.013
Faith. GMean (KL)= 	  =  0.477 +- 0.022, 0.437 +- 0.019, 0.255 +- 0.023, 0.546 +- 0.010

Eval split test
Faith. Aritm (L1)= 		  =  0.499 +- 0.011, 0.467 +- 0.011, 0.445 +- 0.034, 0.774 +- 0.033
Faith. Armon (L1)= 		  =  0.449 +- 0.081, 0.400 +- 0.031, 0.376 +- 0.034, 0.706 +- 0.058
Faith. GMean (L1)= 	  =  0.471 +- 0.045, 0.432 +- 0.021, 0.409 +- 0.032, 0.739 +- 0.046
Faith. Aritm (KL)= 		  =  0.503 +- 0.013, 0.462 +- 0.020, 0.411 +- 0.042, 0.822 +- 0.036
Faith. Armon (KL)= 		  =  0.452 +- 0.050, 0.252 +- 0.062, 0.124 +- 0.077, 0.780 +- 0.056
Faith. GMean (KL)= 	  =  0.476 +- 0.026, 0.339 +- 0.046, 0.218 +- 0.078, 0.801 +- 0.046
Computed for split load_split = id



Completed in  1:23:00.019058  for GSATvGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color
DONE all :)
