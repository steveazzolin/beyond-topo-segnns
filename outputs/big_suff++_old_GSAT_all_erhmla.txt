Time to compute metrics!
The PID of this script is: 2264812

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 10:53:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 10:53:25 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 18...
[0m[1;37mINFO[0m: [1mCheckpoint 18: 
-----------------------------------
Train ACCURACY: 0.6871
Train Loss: 0.8504
ID Validation ACCURACY: 0.6993
ID Validation Loss: 0.8351
ID Test ACCURACY: 0.6983
ID Test Loss: 0.8449
OOD Validation ACCURACY: 0.5330
OOD Validation Loss: 1.1042
OOD Test ACCURACY: 0.5190
OOD Test Loss: 1.0268

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ACCURACY: 0.5497
Train Loss: 1.1856
ID Validation ACCURACY: 0.5620
ID Validation Loss: 1.1989
ID Test ACCURACY: 0.5707
ID Test Loss: 1.1955
OOD Validation ACCURACY: 0.6903
OOD Validation Loss: 0.7487
OOD Test ACCURACY: 0.6773
OOD Test Loss: 0.7183

[0m[1;37mINFO[0m: [1mChartInfo 0.6983 0.5190 0.5707 0.6773 0.5620 0.6903[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.003
WIoU for r=0.3 = 0.002
F1 for r=0.6 = 0.258
WIoU for r=0.6 = 0.173
F1 for r=0.9 = 0.369
WIoU for r=0.9 = 0.291
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.314


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.248
Model XAI F1 of binarized graphs for r=0.3 =  0.0034125
Model XAI WIoU of binarized graphs for r=0.3 =  0.0018
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.377
SUFF++ for r=0.3 class 0 = 0.583 +- 0.207 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 1 = 0.622 +- 0.207 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 class 2 = 0.583 +- 0.207 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all KL = 0.72 +- 0.207 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.3 all L1 = 0.596 +- 0.110 (in-sample avg dev_std = 0.316)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.417
Model XAI F1 of binarized graphs for r=0.6 =  0.25848999999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.17271375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.377
SUFF++ for r=0.6 class 0 = 0.72 +- 0.081 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 class 1 = 0.704 +- 0.081 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 class 2 = 0.662 +- 0.081 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all KL = 0.871 +- 0.081 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all L1 = 0.695 +- 0.085 (in-sample avg dev_std = 0.246)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.374
Model XAI F1 of binarized graphs for r=0.9 =  0.36900999999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.2905825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.535
SUFF++ for r=0.9 class 0 = 0.782 +- 0.118 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 1 = 0.849 +- 0.118 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 class 2 = 0.759 +- 0.118 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all KL = 0.913 +- 0.118 (in-sample avg dev_std = 0.181)
SUFF++ for r=0.9 all L1 = 0.797 +- 0.145 (in-sample avg dev_std = 0.181)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.248
Model XAI F1 of binarized graphs for r=0.3 =  0.0034125
Model XAI WIoU of binarized graphs for r=0.3 =  0.0018
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.32
NEC for r=0.3 class 0 = 0.425 +- 0.194 (in-sample avg dev_std = 0.273)
NEC for r=0.3 class 1 = 0.381 +- 0.194 (in-sample avg dev_std = 0.273)
NEC for r=0.3 class 2 = 0.4 +- 0.194 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all KL = 0.272 +- 0.194 (in-sample avg dev_std = 0.273)
NEC for r=0.3 all L1 = 0.401 +- 0.110 (in-sample avg dev_std = 0.273)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.417
Model XAI F1 of binarized graphs for r=0.6 =  0.25848999999999994
Model XAI WIoU of binarized graphs for r=0.6 =  0.17271375
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.303
NEC for r=0.6 class 0 = 0.363 +- 0.136 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 1 = 0.397 +- 0.136 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 2 = 0.382 +- 0.136 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all KL = 0.206 +- 0.136 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all L1 = 0.381 +- 0.098 (in-sample avg dev_std = 0.271)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.374
Model XAI F1 of binarized graphs for r=0.9 =  0.36900999999999995
Model XAI WIoU of binarized graphs for r=0.9 =  0.2905825
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.49
NEC for r=0.9 class 0 = 0.275 +- 0.134 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1 = 0.238 +- 0.134 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 2 = 0.349 +- 0.134 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.125 +- 0.134 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.287 +- 0.122 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.531
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.31427
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.571
NEC for r=1.0 class 0 = 0.249 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 1 = 0.231 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 2 = 0.34 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all KL = 0.121 +- 0.149 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all L1 = 0.273 +- 0.134 (in-sample avg dev_std = 0.203)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 10:54:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 10:54:37 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 70...
[0m[1;37mINFO[0m: [1mCheckpoint 70: 
-----------------------------------
Train ACCURACY: 0.6884
Train Loss: 0.7575
ID Validation ACCURACY: 0.7133
ID Validation Loss: 0.7174
ID Test ACCURACY: 0.6943
ID Test Loss: 0.7583
OOD Validation ACCURACY: 0.5157
OOD Validation Loss: 1.1036
OOD Test ACCURACY: 0.7193
OOD Test Loss: 0.7663

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 75...
[0m[1;37mINFO[0m: [1mCheckpoint 75: 
-----------------------------------
Train ACCURACY: 0.5467
Train Loss: 0.9902
ID Validation ACCURACY: 0.5517
ID Validation Loss: 0.9905
ID Test ACCURACY: 0.5537
ID Test Loss: 0.9969
OOD Validation ACCURACY: 0.7237
OOD Validation Loss: 0.7625
OOD Test ACCURACY: 0.6420
OOD Test Loss: 0.7160

[0m[1;37mINFO[0m: [1mChartInfo 0.6943 0.7193 0.5537 0.6420 0.5517 0.7237[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.354
WIoU for r=0.6 = 0.238
F1 for r=0.9 = 0.413
WIoU for r=0.9 = 0.310
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.310


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.347
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.347
SUFF++ for r=0.3 class 0 = 0.473 +- 0.211 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 1 = 0.512 +- 0.211 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 2 = 0.504 +- 0.211 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all KL = 0.509 +- 0.211 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all L1 = 0.497 +- 0.114 (in-sample avg dev_std = 0.445)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.246
Model XAI F1 of binarized graphs for r=0.6 =  0.35424
Model XAI WIoU of binarized graphs for r=0.6 =  0.2384425
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.438
SUFF++ for r=0.6 class 0 = 0.496 +- 0.172 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 1 = 0.495 +- 0.172 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 class 2 = 0.479 +- 0.172 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all KL = 0.588 +- 0.172 (in-sample avg dev_std = 0.391)
SUFF++ for r=0.6 all L1 = 0.49 +- 0.101 (in-sample avg dev_std = 0.391)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  0.41276625
Model XAI WIoU of binarized graphs for r=0.9 =  0.30991125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.662
SUFF++ for r=0.9 class 0 = 0.636 +- 0.236 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.774 +- 0.236 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.757 +- 0.236 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.785 +- 0.236 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.724 +- 0.197 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.347
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.366
NEC for r=0.3 class 0 = 0.538 +- 0.225 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 1 = 0.423 +- 0.225 (in-sample avg dev_std = 0.382)
NEC for r=0.3 class 2 = 0.517 +- 0.225 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all KL = 0.452 +- 0.225 (in-sample avg dev_std = 0.382)
NEC for r=0.3 all L1 = 0.491 +- 0.143 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.246
Model XAI F1 of binarized graphs for r=0.6 =  0.35424
Model XAI WIoU of binarized graphs for r=0.6 =  0.2384425
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.422
NEC for r=0.6 class 0 = 0.496 +- 0.192 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 1 = 0.49 +- 0.192 (in-sample avg dev_std = 0.393)
NEC for r=0.6 class 2 = 0.519 +- 0.192 (in-sample avg dev_std = 0.393)
NEC for r=0.6 all KL = 0.4 +- 0.192 (in-sample avg dev_std = 0.393)
NEC for r=0.6 all L1 = 0.502 +- 0.113 (in-sample avg dev_std = 0.393)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.707
Model XAI F1 of binarized graphs for r=0.9 =  0.41276625
Model XAI WIoU of binarized graphs for r=0.9 =  0.30991125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.577
NEC for r=0.9 class 0 = 0.443 +- 0.311 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 1 = 0.456 +- 0.311 (in-sample avg dev_std = 0.457)
NEC for r=0.9 class 2 = 0.507 +- 0.311 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all KL = 0.442 +- 0.311 (in-sample avg dev_std = 0.457)
NEC for r=0.9 all L1 = 0.469 +- 0.194 (in-sample avg dev_std = 0.457)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.704
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.31009125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.593
NEC for r=1.0 class 0 = 0.433 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 1 = 0.427 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 class 2 = 0.478 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all KL = 0.416 +- 0.306 (in-sample avg dev_std = 0.458)
NEC for r=1.0 all L1 = 0.446 +- 0.193 (in-sample avg dev_std = 0.458)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 10:55:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 10:55:48 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ACCURACY: 0.6692
Train Loss: 0.8985
ID Validation ACCURACY: 0.6720
ID Validation Loss: 0.8802
ID Test ACCURACY: 0.6757
ID Test Loss: 0.8848
OOD Validation ACCURACY: 0.3387
OOD Validation Loss: 1.1799
OOD Test ACCURACY: 0.5467
OOD Test Loss: 0.8602

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ACCURACY: 0.5163
Train Loss: 1.2847
ID Validation ACCURACY: 0.5163
ID Validation Loss: 1.3363
ID Test ACCURACY: 0.5163
ID Test Loss: 1.3361
OOD Validation ACCURACY: 0.6937
OOD Validation Loss: 0.7726
OOD Test ACCURACY: 0.6027
OOD Test Loss: 0.9304

[0m[1;37mINFO[0m: [1mChartInfo 0.6757 0.5467 0.5163 0.6027 0.5163 0.6937[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.053
WIoU for r=0.6 = 0.030
F1 for r=0.9 = 0.357
WIoU for r=0.9 = 0.229
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.264


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.256
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.389
SUFF++ for r=0.3 class 0 = 0.569 +- 0.157 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.3 class 1 = 0.641 +- 0.157 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.3 class 2 = 0.57 +- 0.157 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.3 all KL = 0.715 +- 0.157 (in-sample avg dev_std = 0.381)
SUFF++ for r=0.3 all L1 = 0.594 +- 0.113 (in-sample avg dev_std = 0.381)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.275
Model XAI F1 of binarized graphs for r=0.6 =  0.05330875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.0301525
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.316
SUFF++ for r=0.6 class 0 = 0.699 +- 0.087 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 1 = 0.731 +- 0.087 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 class 2 = 0.702 +- 0.087 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all KL = 0.886 +- 0.087 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.6 all L1 = 0.711 +- 0.117 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.389
Model XAI F1 of binarized graphs for r=0.9 =  0.35655375
Model XAI WIoU of binarized graphs for r=0.9 =  0.22912375000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.362
SUFF++ for r=0.9 class 0 = 0.863 +- 0.059 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.9 class 1 = 0.81 +- 0.059 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.9 class 2 = 0.744 +- 0.059 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.9 all KL = 0.939 +- 0.059 (in-sample avg dev_std = 0.166)
SUFF++ for r=0.9 all L1 = 0.806 +- 0.117 (in-sample avg dev_std = 0.166)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.256
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.411 +- 0.134 (in-sample avg dev_std = 0.304)
NEC for r=0.3 class 1 = 0.371 +- 0.134 (in-sample avg dev_std = 0.304)
NEC for r=0.3 class 2 = 0.37 +- 0.134 (in-sample avg dev_std = 0.304)
NEC for r=0.3 all KL = 0.241 +- 0.134 (in-sample avg dev_std = 0.304)
NEC for r=0.3 all L1 = 0.383 +- 0.125 (in-sample avg dev_std = 0.304)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.275
Model XAI F1 of binarized graphs for r=0.6 =  0.05330875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.0301525
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.317
NEC for r=0.6 class 0 = 0.283 +- 0.073 (in-sample avg dev_std = 0.184)
NEC for r=0.6 class 1 = 0.25 +- 0.073 (in-sample avg dev_std = 0.184)
NEC for r=0.6 class 2 = 0.289 +- 0.073 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all KL = 0.098 +- 0.073 (in-sample avg dev_std = 0.184)
NEC for r=0.6 all L1 = 0.274 +- 0.104 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.389
Model XAI F1 of binarized graphs for r=0.9 =  0.35655375
Model XAI WIoU of binarized graphs for r=0.9 =  0.22912375000000004
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.42
NEC for r=0.9 class 0 = 0.297 +- 0.057 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1 = 0.213 +- 0.057 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 2 = 0.304 +- 0.057 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.092 +- 0.057 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.27 +- 0.095 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.544
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.26379375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.452
NEC for r=1.0 class 0 = 0.215 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 1 = 0.18 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 2 = 0.231 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all KL = 0.076 +- 0.085 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all L1 = 0.208 +- 0.098 (in-sample avg dev_std = 0.198)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 10:56:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 10:56:57 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 49...
[0m[1;37mINFO[0m: [1mCheckpoint 49: 
-----------------------------------
Train ACCURACY: 0.7740
Train Loss: 0.6713
ID Validation ACCURACY: 0.7883
ID Validation Loss: 0.6566
ID Test ACCURACY: 0.7730
ID Test Loss: 0.7012
OOD Validation ACCURACY: 0.4643
OOD Validation Loss: 1.2859
OOD Test ACCURACY: 0.7057
OOD Test Loss: 0.6370

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 68...
[0m[1;37mINFO[0m: [1mCheckpoint 68: 
-----------------------------------
Train ACCURACY: 0.6974
Train Loss: 0.7951
ID Validation ACCURACY: 0.7197
ID Validation Loss: 0.7468
ID Test ACCURACY: 0.7103
ID Test Loss: 0.8074
OOD Validation ACCURACY: 0.6740
OOD Validation Loss: 0.8290
OOD Test ACCURACY: 0.6273
OOD Test Loss: 0.9364

[0m[1;37mINFO[0m: [1mChartInfo 0.7730 0.7057 0.7103 0.6273 0.7197 0.6740[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.015
WIoU for r=0.3 = 0.008
F1 for r=0.6 = 0.302
WIoU for r=0.6 = 0.204
F1 for r=0.9 = 0.420
WIoU for r=0.9 = 0.317
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.316


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.387
Model XAI F1 of binarized graphs for r=0.3 =  0.015014999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.00825
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.324
SUFF++ for r=0.3 class 0 = 0.48 +- 0.238 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 1 = 0.498 +- 0.238 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 class 2 = 0.545 +- 0.238 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all KL = 0.57 +- 0.238 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.3 all L1 = 0.508 +- 0.136 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.305
Model XAI F1 of binarized graphs for r=0.6 =  0.3017275
Model XAI WIoU of binarized graphs for r=0.6 =  0.20385
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.316
SUFF++ for r=0.6 class 0 = 0.461 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.461 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.496 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.501 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.473 +- 0.124 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.42045375000000007
Model XAI WIoU of binarized graphs for r=0.9 =  0.31724625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.62
SUFF++ for r=0.9 class 0 = 0.579 +- 0.306 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.9 class 1 = 0.601 +- 0.306 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.9 class 2 = 0.778 +- 0.306 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.9 all KL = 0.674 +- 0.306 (in-sample avg dev_std = 0.439)
SUFF++ for r=0.9 all L1 = 0.653 +- 0.213 (in-sample avg dev_std = 0.439)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.387
Model XAI F1 of binarized graphs for r=0.3 =  0.015014999999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.00825
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.528 +- 0.238 (in-sample avg dev_std = 0.478)
NEC for r=0.3 class 1 = 0.507 +- 0.238 (in-sample avg dev_std = 0.478)
NEC for r=0.3 class 2 = 0.451 +- 0.238 (in-sample avg dev_std = 0.478)
NEC for r=0.3 all KL = 0.438 +- 0.238 (in-sample avg dev_std = 0.478)
NEC for r=0.3 all L1 = 0.495 +- 0.134 (in-sample avg dev_std = 0.478)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.305
Model XAI F1 of binarized graphs for r=0.6 =  0.3017275
Model XAI WIoU of binarized graphs for r=0.6 =  0.20385
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.343
NEC for r=0.6 class 0 = 0.606 +- 0.247 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 1 = 0.551 +- 0.247 (in-sample avg dev_std = 0.385)
NEC for r=0.6 class 2 = 0.468 +- 0.247 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all KL = 0.499 +- 0.247 (in-sample avg dev_std = 0.385)
NEC for r=0.6 all L1 = 0.541 +- 0.155 (in-sample avg dev_std = 0.385)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.754
Model XAI F1 of binarized graphs for r=0.9 =  0.42045375000000007
Model XAI WIoU of binarized graphs for r=0.9 =  0.31724625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.563
NEC for r=0.9 class 0 = 0.501 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 1 = 0.472 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.9 class 2 = 0.428 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.9 all KL = 0.442 +- 0.277 (in-sample avg dev_std = 0.444)
NEC for r=0.9 all L1 = 0.467 +- 0.151 (in-sample avg dev_std = 0.444)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.707
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.3155275
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.609
NEC for r=1.0 class 0 = 0.491 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 1 = 0.429 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 2 = 0.404 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all KL = 0.389 +- 0.243 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all L1 = 0.441 +- 0.143 (in-sample avg dev_std = 0.415)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 10:58:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 10:58:07 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ACCURACY: 0.6885
Train Loss: 0.8644
ID Validation ACCURACY: 0.6977
ID Validation Loss: 0.8397
ID Test ACCURACY: 0.6903
ID Test Loss: 0.8483
OOD Validation ACCURACY: 0.5057
OOD Validation Loss: 1.1208
OOD Test ACCURACY: 0.6890
OOD Test Loss: 0.8000

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ACCURACY: 0.4692
Train Loss: 1.2687
ID Validation ACCURACY: 0.4743
ID Validation Loss: 1.2830
ID Test ACCURACY: 0.4663
ID Test Loss: 1.2951
OOD Validation ACCURACY: 0.6260
OOD Validation Loss: 0.8764
OOD Test ACCURACY: 0.3913
OOD Test Loss: 1.4173

[0m[1;37mINFO[0m: [1mChartInfo 0.6903 0.6890 0.4663 0.3913 0.4743 0.6260[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.000
WIoU for r=0.3 = 0.000
F1 for r=0.6 = 0.000
WIoU for r=0.6 = 0.000
F1 for r=0.9 = 0.259
WIoU for r=0.9 = 0.157
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.251


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.299
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.381
SUFF++ for r=0.3 class 0 = 0.623 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 class 1 = 0.666 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 class 2 = 0.617 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 all KL = 0.721 +- 0.259 (in-sample avg dev_std = 0.395)
SUFF++ for r=0.3 all L1 = 0.636 +- 0.204 (in-sample avg dev_std = 0.395)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.344
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.322
SUFF++ for r=0.6 class 0 = 0.823 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 1 = 0.808 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 class 2 = 0.819 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all KL = 0.944 +- 0.054 (in-sample avg dev_std = 0.179)
SUFF++ for r=0.6 all L1 = 0.816 +- 0.089 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.341
Model XAI F1 of binarized graphs for r=0.9 =  0.25916875
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.346
SUFF++ for r=0.9 class 0 = 0.882 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 1 = 0.857 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all KL = 0.97 +- 0.037 (in-sample avg dev_std = 0.133)
SUFF++ for r=0.9 all L1 = 0.862 +- 0.084 (in-sample avg dev_std = 0.133)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.299
Model XAI F1 of binarized graphs for r=0.3 =  0.0
Model XAI WIoU of binarized graphs for r=0.3 =  0.0
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.287 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 1 = 0.339 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 2 = 0.314 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all KL = 0.214 +- 0.214 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all L1 = 0.314 +- 0.206 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.344
Model XAI F1 of binarized graphs for r=0.6 =  0.0
Model XAI WIoU of binarized graphs for r=0.6 =  0.0
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.319
NEC for r=0.6 class 0 = 0.179 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 class 1 = 0.199 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 class 2 = 0.184 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all KL = 0.065 +- 0.086 (in-sample avg dev_std = 0.156)
NEC for r=0.6 all L1 = 0.187 +- 0.127 (in-sample avg dev_std = 0.156)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.341
Model XAI F1 of binarized graphs for r=0.9 =  0.25916875
Model XAI WIoU of binarized graphs for r=0.9 =  0.15704875000000001
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.379
NEC for r=0.9 class 0 = 0.185 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1 = 0.166 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 2 = 0.197 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.061 +- 0.072 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.183 +- 0.137 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.694
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.25132374999999996
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.52
NEC for r=1.0 class 0 = 0.211 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 class 1 = 0.183 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 class 2 = 0.255 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 all KL = 0.09 +- 0.100 (in-sample avg dev_std = 0.201)
NEC for r=1.0 all L1 = 0.216 +- 0.119 (in-sample avg dev_std = 0.201)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.72, 0.871, 0.913, 1.0], 'all_L1': [0.596, 0.695, 0.797, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.509, 0.588, 0.785, 1.0], 'all_L1': [0.497, 0.49, 0.724, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.715, 0.886, 0.939, 1.0], 'all_L1': [0.594, 0.711, 0.806, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.57, 0.501, 0.674, 1.0], 'all_L1': [0.508, 0.473, 0.653, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.721, 0.944, 0.97, 1.0], 'all_L1': [0.636, 0.816, 0.862, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.272, 0.206, 0.125, 0.121], 'all_L1': [0.401, 0.381, 0.287, 0.273]}), defaultdict(<class 'list'>, {'all_KL': [0.452, 0.4, 0.442, 0.416], 'all_L1': [0.491, 0.502, 0.469, 0.446]}), defaultdict(<class 'list'>, {'all_KL': [0.241, 0.098, 0.092, 0.076], 'all_L1': [0.383, 0.274, 0.27, 0.208]}), defaultdict(<class 'list'>, {'all_KL': [0.438, 0.499, 0.442, 0.389], 'all_L1': [0.495, 0.541, 0.467, 0.441]}), defaultdict(<class 'list'>, {'all_KL': [0.214, 0.065, 0.061, 0.09], 'all_L1': [0.314, 0.187, 0.183, 0.216]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.566 +- 0.054, 0.637 +- 0.134, 0.768 +- 0.072, 1.000 +- 0.000
suff++ class all_KL  =  0.647 +- 0.090, 0.758 +- 0.178, 0.856 +- 0.111, 1.000 +- 0.000
suff++_acc_int  =  0.364 +- 0.025, 0.354 +- 0.048, 0.505 +- 0.130
nec class all_L1  =  0.417 +- 0.069, 0.377 +- 0.134, 0.335 +- 0.114, 0.317 +- 0.106
nec class all_KL  =  0.323 +- 0.101, 0.254 +- 0.170, 0.232 +- 0.172, 0.218 +- 0.151
nec_acc_int  =  0.342 +- 0.015, 0.341 +- 0.043, 0.486 +- 0.078, 0.549 +- 0.057


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.491 +- 0.009, 0.507 +- 0.016, 0.552 +- 0.025, 0.658 +- 0.053
Faith. Armon (L1)= 		  =  0.472 +- 0.029, 0.439 +- 0.078, 0.448 +- 0.098, 0.471 +- 0.120
Faith. GMean (L1)= 	  =  0.482 +- 0.019, 0.470 +- 0.047, 0.495 +- 0.066, 0.555 +- 0.093
Faith. Aritm (KL)= 		  =  0.485 +- 0.013, 0.506 +- 0.017, 0.544 +- 0.038, 0.609 +- 0.076
Faith. Armon (KL)= 		  =  0.412 +- 0.065, 0.321 +- 0.153, 0.320 +- 0.190, 0.334 +- 0.198
Faith. GMean (KL)= 	  =  0.446 +- 0.040, 0.390 +- 0.102, 0.402 +- 0.139, 0.438 +- 0.162
Computed for split load_split = id



Completed in  0:05:55.382297  for GSATGIN GOODMotif2/basis



DONE GSAT GOODMotif2/basis all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 10:59:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:32 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:32 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:32 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 10:59:33 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.3520
Train Loss: 4.1012
ID Validation ACCURACY: 0.3500
ID Validation Loss: 4.1593
ID Test ACCURACY: 0.3524
ID Test Loss: 4.1588
OOD Validation ACCURACY: 0.3167
OOD Validation Loss: 6.5550
OOD Test ACCURACY: 0.1637
OOD Test Loss: 33.3198

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.3520
Train Loss: 4.1012
ID Validation ACCURACY: 0.3500
ID Validation Loss: 4.1593
ID Test ACCURACY: 0.3524
ID Test Loss: 4.1588
OOD Validation ACCURACY: 0.3167
OOD Validation Loss: 6.5550
OOD Test ACCURACY: 0.1637
OOD Test Loss: 33.3198

[0m[1;37mINFO[0m: [1mChartInfo 0.3524 0.1637 0.3524 0.1637 0.3500 0.3167[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
[1;31mERROR[0m: 05/17/2024 10:59:37 AM - utils.py - line 52 : [1mCUDA out of memory. Tried to allocate 1.59 GiB. GPU 0 has a total capacty of 11.77 GiB of which 926.25 MiB is free. Process 2265408 has 1.88 GiB memory in use. Including non-PyTorch memory, this process has 8.99 GiB memory in use. Of the allocated memory 6.43 GiB is allocated by PyTorch, and 1.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[0m
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 639, in goodtg
    print(f'#E#{e}')
Time to compute metrics!
The PID of this script is: 2266127

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:02:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:47 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:02:48 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.3520
Train Loss: 4.1012
ID Validation ACCURACY: 0.3500
ID Validation Loss: 4.1593
ID Test ACCURACY: 0.3524
ID Test Loss: 4.1588
OOD Validation ACCURACY: 0.3167
OOD Validation Loss: 6.5550
OOD Test ACCURACY: 0.1637
OOD Test Loss: 33.3198

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.3520
Train Loss: 4.1012
ID Validation ACCURACY: 0.3500
ID Validation Loss: 4.1593
ID Test ACCURACY: 0.3524
ID Test Loss: 4.1588
OOD Validation ACCURACY: 0.3167
OOD Validation Loss: 6.5550
OOD Test ACCURACY: 0.1637
OOD Test Loss: 33.3198

[0m[1;37mINFO[0m: [1mChartInfo 0.3524 0.1637 0.3524 0.1637 0.3500 0.3167[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
SUFF++ for r=0.3 class 0 = 0.458 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 1 = 0.479 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 2 = 0.459 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 3 = 0.459 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 4 = 0.471 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 5 = 0.462 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 6 = 0.485 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 7 = 0.476 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 8 = 0.449 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 class 9 = 0.48 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all KL = 0.505 +- 0.211 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.3 all L1 = 0.468 +- 0.122 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.245
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.191
SUFF++ for r=0.6 class 0 = 0.298 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1 = 0.491 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 2 = 0.305 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 3 = 0.32 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 4 = 0.363 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 5 = 0.316 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 6 = 0.347 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 7 = 0.409 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 8 = 0.334 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 9 = 0.377 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.231 +- 0.209 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.357 +- 0.170 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.176
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.145
SUFF++ for r=0.9 class 0 = 0.316 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 1 = 0.89 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 2 = 0.442 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 3 = 0.446 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 4 = 0.578 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 5 = 0.435 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 6 = 0.567 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 7 = 0.487 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 8 = 0.513 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 class 9 = 0.656 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 all KL = 0.402 +- 0.386 (in-sample avg dev_std = 0.493)
SUFF++ for r=0.9 all L1 = 0.536 +- 0.296 (in-sample avg dev_std = 0.493)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.129
NEC for r=0.3 class 0 = 0.462 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 1 = 0.488 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 2 = 0.43 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 3 = 0.437 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 4 = 0.472 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 5 = 0.427 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 6 = 0.46 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 7 = 0.435 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 8 = 0.474 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 9 = 0.46 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all KL = 0.384 +- 0.257 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all L1 = 0.455 +- 0.171 (in-sample avg dev_std = 0.314)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.245
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.233
NEC for r=0.6 class 0 = 0.681 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 1 = 0.514 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 2 = 0.651 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 3 = 0.666 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 4 = 0.602 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 5 = 0.625 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 6 = 0.627 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 7 = 0.51 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 8 = 0.65 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 class 9 = 0.638 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all KL = 0.69 +- 0.278 (in-sample avg dev_std = 0.388)
NEC for r=0.6 all L1 = 0.616 +- 0.210 (in-sample avg dev_std = 0.388)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.176
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.209
NEC for r=0.9 class 0 = 0.637 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 1 = 0.408 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 2 = 0.699 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 3 = 0.662 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 4 = 0.691 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 5 = 0.689 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 6 = 0.68 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 7 = 0.753 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 8 = 0.672 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 class 9 = 0.641 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 all KL = 0.799 +- 0.291 (in-sample avg dev_std = 0.379)
NEC for r=0.9 all L1 = 0.65 +- 0.251 (in-sample avg dev_std = 0.379)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.164
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.195
NEC for r=1.0 class 0 = 0.698 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 1 = 0.336 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 2 = 0.695 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 3 = 0.69 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 4 = 0.664 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 5 = 0.73 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 6 = 0.698 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 7 = 0.776 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 8 = 0.722 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 class 9 = 0.61 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 all KL = 0.839 +- 0.290 (in-sample avg dev_std = 0.329)
NEC for r=1.0 all L1 = 0.658 +- 0.267 (in-sample avg dev_std = 0.329)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:09:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:34 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:34 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:09:35 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 65...
[0m[1;37mINFO[0m: [1mCheckpoint 65: 
-----------------------------------
Train ACCURACY: 0.4144
Train Loss: 2.4823
ID Validation ACCURACY: 0.4157
ID Validation Loss: 2.5162
ID Test ACCURACY: 0.4114
ID Test Loss: 2.4803
OOD Validation ACCURACY: 0.3104
OOD Validation Loss: 6.7585
OOD Test ACCURACY: 0.1446
OOD Test Loss: 41.0285

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.2914
Train Loss: 3.5159
ID Validation ACCURACY: 0.2877
ID Validation Loss: 3.5219
ID Test ACCURACY: 0.2904
ID Test Loss: 3.4864
OOD Validation ACCURACY: 0.3116
OOD Validation Loss: 9.4187
OOD Test ACCURACY: 0.1699
OOD Test Loss: 50.5791

[0m[1;37mINFO[0m: [1mChartInfo 0.4114 0.1446 0.2904 0.1699 0.2877 0.3116[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.122
SUFF++ for r=0.3 class 0 = 0.488 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 1 = 0.534 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 2 = 0.514 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 3 = 0.498 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 4 = 0.49 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 5 = 0.512 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 6 = 0.497 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 7 = 0.505 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 8 = 0.507 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 class 9 = 0.52 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 all KL = 0.52 +- 0.218 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.3 all L1 = 0.507 +- 0.154 (in-sample avg dev_std = 0.469)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.257
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.185
SUFF++ for r=0.6 class 0 = 0.23 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 1 = 0.557 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 2 = 0.24 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 3 = 0.248 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 4 = 0.29 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 5 = 0.238 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 6 = 0.282 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 7 = 0.306 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 8 = 0.242 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 9 = 0.338 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all KL = 0.155 +- 0.196 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all L1 = 0.3 +- 0.169 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.164
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.163
SUFF++ for r=0.9 class 0 = 0.27 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 1 = 0.685 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 2 = 0.315 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 3 = 0.337 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 4 = 0.44 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 5 = 0.34 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 6 = 0.448 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 7 = 0.389 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 8 = 0.356 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 class 9 = 0.461 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 all KL = 0.19 +- 0.301 (in-sample avg dev_std = 0.554)
SUFF++ for r=0.9 all L1 = 0.407 +- 0.256 (in-sample avg dev_std = 0.554)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.483 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1 = 0.421 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 2 = 0.491 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 3 = 0.524 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 4 = 0.528 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 5 = 0.465 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 6 = 0.495 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 7 = 0.491 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 8 = 0.46 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 9 = 0.483 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.448 +- 0.269 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.484 +- 0.205 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.257
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.236
NEC for r=0.6 class 0 = 0.704 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 1 = 0.361 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 2 = 0.678 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 3 = 0.723 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 4 = 0.698 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 5 = 0.721 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 6 = 0.717 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 7 = 0.65 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 8 = 0.738 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 class 9 = 0.68 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 all KL = 0.771 +- 0.257 (in-sample avg dev_std = 0.392)
NEC for r=0.6 all L1 = 0.663 +- 0.206 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.164
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.225
NEC for r=0.9 class 0 = 0.701 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 1 = 0.584 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 2 = 0.695 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 3 = 0.654 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 4 = 0.649 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 5 = 0.653 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 6 = 0.668 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 7 = 0.674 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 8 = 0.687 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 class 9 = 0.653 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 all KL = 0.845 +- 0.227 (in-sample avg dev_std = 0.421)
NEC for r=0.9 all L1 = 0.662 +- 0.192 (in-sample avg dev_std = 0.421)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.166
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.204
NEC for r=1.0 class 0 = 0.665 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 1 = 0.527 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 2 = 0.679 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 3 = 0.645 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 4 = 0.617 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 5 = 0.644 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 6 = 0.662 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 7 = 0.663 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 8 = 0.666 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 class 9 = 0.605 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 all KL = 0.829 +- 0.260 (in-sample avg dev_std = 0.412)
NEC for r=1.0 all L1 = 0.636 +- 0.222 (in-sample avg dev_std = 0.412)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:16:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:31 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:31 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:31 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:31 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:16:32 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 66...
[0m[1;37mINFO[0m: [1mCheckpoint 66: 
-----------------------------------
Train ACCURACY: 0.3567
Train Loss: 3.2947
ID Validation ACCURACY: 0.3594
ID Validation Loss: 3.2787
ID Test ACCURACY: 0.3510
ID Test Loss: 3.2852
OOD Validation ACCURACY: 0.3019
OOD Validation Loss: 3.8731
OOD Test ACCURACY: 0.1820
OOD Test Loss: 4.9479

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 39...
[0m[1;37mINFO[0m: [1mCheckpoint 39: 
-----------------------------------
Train ACCURACY: 0.3426
Train Loss: 2.6924
ID Validation ACCURACY: 0.3353
ID Validation Loss: 2.7255
ID Test ACCURACY: 0.3387
ID Test Loss: 2.7041
OOD Validation ACCURACY: 0.3136
OOD Validation Loss: 2.9546
OOD Test ACCURACY: 0.1916
OOD Test Loss: 4.1809

[0m[1;37mINFO[0m: [1mChartInfo 0.3510 0.1820 0.3387 0.1916 0.3353 0.3136[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.131
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
SUFF++ for r=0.3 class 0 = 0.438 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 1 = 0.41 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 2 = 0.398 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 3 = 0.405 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 4 = 0.422 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 5 = 0.408 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 6 = 0.464 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 7 = 0.413 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 8 = 0.415 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 class 9 = 0.401 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all KL = 0.37 +- 0.252 (in-sample avg dev_std = 0.517)
SUFF++ for r=0.3 all L1 = 0.417 +- 0.167 (in-sample avg dev_std = 0.517)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.229
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.193
SUFF++ for r=0.6 class 0 = 0.244 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 1 = 0.435 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 2 = 0.236 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 3 = 0.259 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 4 = 0.275 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 5 = 0.281 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 6 = 0.284 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 7 = 0.332 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 8 = 0.254 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 9 = 0.271 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all KL = 0.086 +- 0.120 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all L1 = 0.288 +- 0.145 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.165
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.158
SUFF++ for r=0.9 class 0 = 0.325 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 1 = 0.347 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 2 = 0.352 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 3 = 0.334 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 4 = 0.339 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 5 = 0.338 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 6 = 0.336 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 7 = 0.346 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 8 = 0.334 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 class 9 = 0.339 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 all KL = 0.147 +- 0.146 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.9 all L1 = 0.339 +- 0.132 (in-sample avg dev_std = 0.542)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.131
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.139
NEC for r=0.3 class 0 = 0.475 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 1 = 0.442 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 2 = 0.511 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 3 = 0.513 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 4 = 0.501 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 5 = 0.509 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 6 = 0.462 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 7 = 0.476 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 8 = 0.513 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 class 9 = 0.493 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 all KL = 0.49 +- 0.263 (in-sample avg dev_std = 0.412)
NEC for r=0.3 all L1 = 0.489 +- 0.195 (in-sample avg dev_std = 0.412)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.229
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.226
NEC for r=0.6 class 0 = 0.669 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 1 = 0.3 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 2 = 0.675 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 3 = 0.688 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 4 = 0.568 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 5 = 0.627 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 6 = 0.605 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 7 = 0.571 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 8 = 0.645 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 9 = 0.628 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 all KL = 0.753 +- 0.282 (in-sample avg dev_std = 0.462)
NEC for r=0.6 all L1 = 0.595 +- 0.247 (in-sample avg dev_std = 0.462)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.165
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.216
NEC for r=0.9 class 0 = 0.677 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 1 = 0.489 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 2 = 0.651 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 3 = 0.655 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 4 = 0.644 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 5 = 0.656 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 6 = 0.658 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 7 = 0.638 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 8 = 0.643 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 class 9 = 0.656 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 all KL = 0.759 +- 0.229 (in-sample avg dev_std = 0.430)
NEC for r=0.9 all L1 = 0.635 +- 0.184 (in-sample avg dev_std = 0.430)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.162
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.221
NEC for r=1.0 class 0 = 0.656 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 1 = 0.479 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 2 = 0.628 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 3 = 0.639 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 4 = 0.636 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 5 = 0.628 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 6 = 0.649 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 7 = 0.642 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 8 = 0.659 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 class 9 = 0.637 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all KL = 0.73 +- 0.230 (in-sample avg dev_std = 0.417)
NEC for r=1.0 all L1 = 0.624 +- 0.179 (in-sample avg dev_std = 0.417)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:23:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:23:50 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:23:51 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.3909
Train Loss: 2.8134
ID Validation ACCURACY: 0.4021
ID Validation Loss: 2.7741
ID Test ACCURACY: 0.3860
ID Test Loss: 2.8356
OOD Validation ACCURACY: 0.3126
OOD Validation Loss: 4.1696
OOD Test ACCURACY: 0.2140
OOD Test Loss: 12.2054

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.3350
Train Loss: 4.2162
ID Validation ACCURACY: 0.3359
ID Validation Loss: 4.3002
ID Test ACCURACY: 0.3386
ID Test Loss: 4.2674
OOD Validation ACCURACY: 0.3293
OOD Validation Loss: 8.2922
OOD Test ACCURACY: 0.1864
OOD Test Loss: 53.4631

[0m[1;37mINFO[0m: [1mChartInfo 0.3860 0.2140 0.3386 0.1864 0.3359 0.3293[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
SUFF++ for r=0.3 class 0 = 0.487 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 1 = 0.459 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 2 = 0.48 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 3 = 0.486 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 4 = 0.459 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 5 = 0.469 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 6 = 0.513 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 7 = 0.476 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 8 = 0.48 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 9 = 0.472 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all KL = 0.544 +- 0.216 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all L1 = 0.478 +- 0.154 (in-sample avg dev_std = 0.423)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.31
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.191
SUFF++ for r=0.6 class 0 = 0.286 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 1 = 0.491 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 2 = 0.286 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 3 = 0.275 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 4 = 0.32 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 5 = 0.293 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 6 = 0.316 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 7 = 0.353 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 8 = 0.307 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 class 9 = 0.36 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all KL = 0.198 +- 0.182 (in-sample avg dev_std = 0.536)
SUFF++ for r=0.6 all L1 = 0.331 +- 0.138 (in-sample avg dev_std = 0.536)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.195
SUFF++ for r=0.9 class 0 = 0.322 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 1 = 0.885 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 2 = 0.295 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 3 = 0.358 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 4 = 0.502 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 5 = 0.342 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 6 = 0.455 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 7 = 0.441 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 8 = 0.412 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 class 9 = 0.624 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 all KL = 0.298 +- 0.370 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.9 all L1 = 0.468 +- 0.297 (in-sample avg dev_std = 0.544)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
NEC for r=0.3 class 0 = 0.424 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 1 = 0.396 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 2 = 0.464 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 3 = 0.428 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 4 = 0.478 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 5 = 0.436 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 6 = 0.412 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 7 = 0.402 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 8 = 0.464 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 class 9 = 0.474 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all KL = 0.334 +- 0.215 (in-sample avg dev_std = 0.298)
NEC for r=0.3 all L1 = 0.437 +- 0.159 (in-sample avg dev_std = 0.298)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.31
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.252
NEC for r=0.6 class 0 = 0.646 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 1 = 0.157 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 2 = 0.651 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 3 = 0.667 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 4 = 0.621 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 5 = 0.651 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 6 = 0.616 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 7 = 0.522 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 8 = 0.622 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 class 9 = 0.567 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all KL = 0.624 +- 0.299 (in-sample avg dev_std = 0.359)
NEC for r=0.6 all L1 = 0.567 +- 0.243 (in-sample avg dev_std = 0.359)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.229
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.294
NEC for r=0.9 class 0 = 0.653 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 1 = 0.082 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 2 = 0.704 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 3 = 0.688 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 4 = 0.662 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 5 = 0.672 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 6 = 0.639 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 7 = 0.649 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 8 = 0.672 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 class 9 = 0.566 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 all KL = 0.732 +- 0.318 (in-sample avg dev_std = 0.392)
NEC for r=0.9 all L1 = 0.593 +- 0.273 (in-sample avg dev_std = 0.392)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.209
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.275
NEC for r=1.0 class 0 = 0.655 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 1 = 0.058 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 2 = 0.699 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 3 = 0.648 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 4 = 0.575 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 5 = 0.656 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 6 = 0.608 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 7 = 0.64 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 8 = 0.632 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 class 9 = 0.422 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all KL = 0.7 +- 0.373 (in-sample avg dev_std = 0.387)
NEC for r=1.0 all L1 = 0.554 +- 0.316 (in-sample avg dev_std = 0.387)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:30:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:30:41 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:30:42 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 0.3832
Train Loss: 3.2781
ID Validation ACCURACY: 0.3854
ID Validation Loss: 3.3077
ID Test ACCURACY: 0.3756
ID Test Loss: 3.3515
OOD Validation ACCURACY: 0.2441
OOD Validation Loss: 6.2321
OOD Test ACCURACY: 0.1736
OOD Test Loss: 8.2136

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.3804
Train Loss: 3.3525
ID Validation ACCURACY: 0.3771
ID Validation Loss: 3.3880
ID Test ACCURACY: 0.3827
ID Test Loss: 3.3628
OOD Validation ACCURACY: 0.3297
OOD Validation Loss: 4.5238
OOD Test ACCURACY: 0.2149
OOD Test Loss: 6.5520

[0m[1;37mINFO[0m: [1mChartInfo 0.3756 0.1736 0.3827 0.2149 0.3771 0.3297[0mGOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
SUFF++ for r=0.3 class 0 = 0.436 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 1 = 0.392 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 2 = 0.372 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 3 = 0.404 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 4 = 0.363 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 5 = 0.387 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 6 = 0.435 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 7 = 0.383 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 8 = 0.393 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 class 9 = 0.361 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 all KL = 0.378 +- 0.223 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.3 all L1 = 0.393 +- 0.137 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
SUFF++ for r=0.6 class 0 = 0.275 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 1 = 0.516 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 2 = 0.341 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 3 = 0.338 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 4 = 0.443 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 5 = 0.329 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 6 = 0.434 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 7 = 0.488 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 8 = 0.385 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 class 9 = 0.509 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 all KL = 0.119 +- 0.199 (in-sample avg dev_std = 0.656)
SUFF++ for r=0.6 all L1 = 0.407 +- 0.199 (in-sample avg dev_std = 0.656)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.16
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.141
SUFF++ for r=0.9 class 0 = 0.305 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 1 = 0.626 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 2 = 0.385 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 3 = 0.388 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 4 = 0.599 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 5 = 0.376 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 6 = 0.49 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 7 = 0.481 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 8 = 0.474 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 class 9 = 0.623 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 all KL = 0.248 +- 0.317 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.9 all L1 = 0.475 +- 0.259 (in-sample avg dev_std = 0.582)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.124
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.499 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 1 = 0.423 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 2 = 0.567 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 3 = 0.523 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 4 = 0.493 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 5 = 0.482 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 6 = 0.478 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 7 = 0.493 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 8 = 0.497 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 class 9 = 0.494 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all KL = 0.44 +- 0.238 (in-sample avg dev_std = 0.332)
NEC for r=0.3 all L1 = 0.495 +- 0.175 (in-sample avg dev_std = 0.332)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.157
NEC for r=0.6 class 0 = 0.644 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 1 = 0.317 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 2 = 0.57 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 3 = 0.516 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 4 = 0.291 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 5 = 0.522 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 6 = 0.374 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 7 = 0.332 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 8 = 0.38 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 class 9 = 0.176 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 all KL = 0.556 +- 0.387 (in-sample avg dev_std = 0.411)
NEC for r=0.6 all L1 = 0.413 +- 0.309 (in-sample avg dev_std = 0.411)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.16
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.179
NEC for r=0.9 class 0 = 0.695 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 1 = 0.379 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 2 = 0.64 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 3 = 0.622 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 4 = 0.438 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 5 = 0.646 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 6 = 0.575 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 7 = 0.578 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 8 = 0.609 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 class 9 = 0.384 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all KL = 0.728 +- 0.345 (in-sample avg dev_std = 0.482)
NEC for r=0.9 all L1 = 0.555 +- 0.283 (in-sample avg dev_std = 0.482)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.161
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.187
NEC for r=1.0 class 0 = 0.692 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 1 = 0.387 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 2 = 0.661 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 3 = 0.627 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 4 = 0.454 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 5 = 0.642 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 6 = 0.577 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 7 = 0.578 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 8 = 0.628 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 class 9 = 0.399 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 all KL = 0.722 +- 0.338 (in-sample avg dev_std = 0.464)
NEC for r=1.0 all L1 = 0.563 +- 0.276 (in-sample avg dev_std = 0.464)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.505, 0.231, 0.402, 1.0], 'all_L1': [0.468, 0.357, 0.536, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.52, 0.155, 0.19, 1.0], 'all_L1': [0.507, 0.3, 0.407, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.37, 0.086, 0.147, 1.0], 'all_L1': [0.417, 0.288, 0.339, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.544, 0.198, 0.298, 1.0], 'all_L1': [0.478, 0.331, 0.468, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.378, 0.119, 0.248, 1.0], 'all_L1': [0.393, 0.407, 0.475, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.384, 0.69, 0.799, 0.839], 'all_L1': [0.455, 0.616, 0.65, 0.658]}), defaultdict(<class 'list'>, {'all_KL': [0.448, 0.771, 0.845, 0.829], 'all_L1': [0.484, 0.663, 0.662, 0.636]}), defaultdict(<class 'list'>, {'all_KL': [0.49, 0.753, 0.759, 0.73], 'all_L1': [0.489, 0.595, 0.635, 0.624]}), defaultdict(<class 'list'>, {'all_KL': [0.334, 0.624, 0.732, 0.7], 'all_L1': [0.437, 0.567, 0.593, 0.554]}), defaultdict(<class 'list'>, {'all_KL': [0.44, 0.556, 0.728, 0.722], 'all_L1': [0.495, 0.413, 0.555, 0.563]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.453 +- 0.042, 0.337 +- 0.043, 0.445 +- 0.067, 1.000 +- 0.000
suff++ class all_KL  =  0.463 +- 0.074, 0.158 +- 0.052, 0.257 +- 0.089, 1.000 +- 0.000
suff++_acc_int  =  0.112 +- 0.006, 0.183 +- 0.013, 0.161 +- 0.019
nec class all_L1  =  0.472 +- 0.022, 0.571 +- 0.085, 0.619 +- 0.040, 0.607 +- 0.041
nec class all_KL  =  0.419 +- 0.054, 0.679 +- 0.080, 0.773 +- 0.044, 0.764 +- 0.058
nec_acc_int  =  0.123 +- 0.010, 0.221 +- 0.033, 0.225 +- 0.038, 0.216 +- 0.032


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.462 +- 0.018, 0.454 +- 0.028, 0.532 +- 0.035, 0.803 +- 0.021
Faith. Armon (L1)= 		  =  0.460 +- 0.019, 0.416 +- 0.021, 0.514 +- 0.046, 0.755 +- 0.032
Faith. GMean (L1)= 	  =  0.461 +- 0.018, 0.434 +- 0.022, 0.523 +- 0.040, 0.779 +- 0.027
Faith. Aritm (KL)= 		  =  0.441 +- 0.025, 0.418 +- 0.046, 0.515 +- 0.049, 0.882 +- 0.029
Faith. Armon (KL)= 		  =  0.432 +- 0.027, 0.251 +- 0.069, 0.377 +- 0.099, 0.865 +- 0.037
Faith. GMean (KL)= 	  =  0.437 +- 0.025, 0.322 +- 0.057, 0.439 +- 0.077, 0.873 +- 0.033
Computed for split load_split = id



Completed in  0:35:12.283308  for GSATGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:38:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/17/2024 11:38:15 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 11:38:46 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 11:38:57 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:08 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:24 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:39:39 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ROC-AUC: 0.9219
Train Loss: 0.2433
ID Validation ROC-AUC: 0.9005
ID Validation Loss: 0.2836
ID Test ROC-AUC: 0.9006
ID Test Loss: 0.2830
OOD Validation ROC-AUC: 0.6415
OOD Validation Loss: 0.5290
OOD Test ROC-AUC: 0.6998
OOD Test Loss: 0.6406

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 100...
[0m[1;37mINFO[0m: [1mCheckpoint 100: 
-----------------------------------
Train ROC-AUC: 0.8862
Train Loss: 0.2825
ID Validation ROC-AUC: 0.8721
ID Validation Loss: 0.3043
ID Test ROC-AUC: 0.8739
ID Test Loss: 0.3017
OOD Validation ROC-AUC: 0.6708
OOD Validation Loss: 0.4663
OOD Test ROC-AUC: 0.6892
OOD Test Loss: 0.5869

[0m[1;37mINFO[0m: [1mChartInfo 0.9006 0.6998 0.8739 0.6892 0.8721 0.6708[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/17/2024 11:39:40 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.631
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 784
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
SUFF++ for r=0.3 class 0.0 = 0.713 +- 0.217 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 1.0 = 0.778 +- 0.217 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all KL = 0.802 +- 0.217 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all L1 = 0.768 +- 0.200 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.65
SUFF++ for r=0.6 class 0.0 = 0.763 +- 0.203 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.203 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all KL = 0.868 +- 0.203 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.6 all L1 = 0.836 +- 0.204 (in-sample avg dev_std = 0.274)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.665
SUFF++ for r=0.9 class 0.0 = 0.882 +- 0.150 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 class 1.0 = 0.917 +- 0.150 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all KL = 0.927 +- 0.150 (in-sample avg dev_std = 0.220)
SUFF++ for r=0.9 all L1 = 0.911 +- 0.153 (in-sample avg dev_std = 0.220)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.628
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.64
NEC for r=0.3 class 0.0 = 0.262 +- 0.223 (in-sample avg dev_std = 0.355)
NEC for r=0.3 class 1.0 = 0.222 +- 0.223 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all KL = 0.196 +- 0.223 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all L1 = 0.229 +- 0.195 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.668
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.659
NEC for r=0.6 class 0.0 = 0.232 +- 0.218 (in-sample avg dev_std = 0.326)
NEC for r=0.6 class 1.0 = 0.165 +- 0.218 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all KL = 0.159 +- 0.218 (in-sample avg dev_std = 0.326)
NEC for r=0.6 all L1 = 0.176 +- 0.194 (in-sample avg dev_std = 0.326)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0.0 = 0.176 +- 0.220 (in-sample avg dev_std = 0.298)
NEC for r=0.9 class 1.0 = 0.132 +- 0.220 (in-sample avg dev_std = 0.298)
NEC for r=0.9 all KL = 0.142 +- 0.220 (in-sample avg dev_std = 0.298)
NEC for r=0.9 all L1 = 0.139 +- 0.191 (in-sample avg dev_std = 0.298)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.683
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.676
NEC for r=1.0 class 0.0 = 0.158 +- 0.222 (in-sample avg dev_std = 0.298)
NEC for r=1.0 class 1.0 = 0.124 +- 0.222 (in-sample avg dev_std = 0.298)
NEC for r=1.0 all KL = 0.137 +- 0.222 (in-sample avg dev_std = 0.298)
NEC for r=1.0 all L1 = 0.13 +- 0.185 (in-sample avg dev_std = 0.298)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:40:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/17/2024 11:41:00 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 11:41:31 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 11:41:41 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 11:41:52 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:09 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ROC-AUC: 0.9224
Train Loss: 0.2417
ID Validation ROC-AUC: 0.9030
ID Validation Loss: 0.2771
ID Test ROC-AUC: 0.9024
ID Test Loss: 0.2775
OOD Validation ROC-AUC: 0.6469
OOD Validation Loss: 0.5210
OOD Test ROC-AUC: 0.6993
OOD Test Loss: 0.6134

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ROC-AUC: 0.8995
Train Loss: 0.2912
ID Validation ROC-AUC: 0.8814
ID Validation Loss: 0.3229
ID Test ROC-AUC: 0.8856
ID Test Loss: 0.3231
OOD Validation ROC-AUC: 0.6688
OOD Validation Loss: 0.3630
OOD Test ROC-AUC: 0.6979
OOD Test Loss: 0.6124

[0m[1;37mINFO[0m: [1mChartInfo 0.9024 0.6993 0.8856 0.6979 0.8814 0.6688[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/17/2024 11:42:25 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.592
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 784
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.59
SUFF++ for r=0.3 class 0.0 = 0.777 +- 0.203 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 class 1.0 = 0.801 +- 0.203 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all KL = 0.827 +- 0.203 (in-sample avg dev_std = 0.355)
SUFF++ for r=0.3 all L1 = 0.797 +- 0.200 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.654
SUFF++ for r=0.6 class 0.0 = 0.802 +- 0.196 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 1.0 = 0.893 +- 0.196 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all KL = 0.895 +- 0.196 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all L1 = 0.878 +- 0.195 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.698
SUFF++ for r=0.9 class 0.0 = 0.895 +- 0.177 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1.0 = 0.939 +- 0.177 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.927 +- 0.177 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.932 +- 0.148 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.608
NEC for r=0.3 class 0.0 = 0.243 +- 0.238 (in-sample avg dev_std = 0.383)
NEC for r=0.3 class 1.0 = 0.222 +- 0.238 (in-sample avg dev_std = 0.383)
NEC for r=0.3 all KL = 0.214 +- 0.238 (in-sample avg dev_std = 0.383)
NEC for r=0.3 all L1 = 0.225 +- 0.200 (in-sample avg dev_std = 0.383)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.669
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.655
NEC for r=0.6 class 0.0 = 0.221 +- 0.214 (in-sample avg dev_std = 0.293)
NEC for r=0.6 class 1.0 = 0.121 +- 0.214 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all KL = 0.138 +- 0.214 (in-sample avg dev_std = 0.293)
NEC for r=0.6 all L1 = 0.137 +- 0.194 (in-sample avg dev_std = 0.293)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.68
NEC for r=0.9 class 0.0 = 0.214 +- 0.276 (in-sample avg dev_std = 0.318)
NEC for r=0.9 class 1.0 = 0.111 +- 0.276 (in-sample avg dev_std = 0.318)
NEC for r=0.9 all KL = 0.166 +- 0.276 (in-sample avg dev_std = 0.318)
NEC for r=0.9 all L1 = 0.128 +- 0.209 (in-sample avg dev_std = 0.318)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.687
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.69
NEC for r=1.0 class 0.0 = 0.208 +- 0.303 (in-sample avg dev_std = 0.337)
NEC for r=1.0 class 1.0 = 0.132 +- 0.303 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all KL = 0.19 +- 0.303 (in-sample avg dev_std = 0.337)
NEC for r=1.0 all L1 = 0.144 +- 0.226 (in-sample avg dev_std = 0.337)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:43:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/17/2024 11:43:42 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 11:44:13 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 11:44:24 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 11:44:36 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 11:44:52 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ROC-AUC: 0.9160
Train Loss: 0.2563
ID Validation ROC-AUC: 0.8983
ID Validation Loss: 0.2916
ID Test ROC-AUC: 0.8976
ID Test Loss: 0.2924
OOD Validation ROC-AUC: 0.6457
OOD Validation Loss: 0.5279
OOD Test ROC-AUC: 0.7031
OOD Test Loss: 0.6410

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ROC-AUC: 0.8843
Train Loss: 0.2917
ID Validation ROC-AUC: 0.8698
ID Validation Loss: 0.3179
ID Test ROC-AUC: 0.8731
ID Test Loss: 0.3116
OOD Validation ROC-AUC: 0.6741
OOD Validation Loss: 0.4275
OOD Test ROC-AUC: 0.6836
OOD Test Loss: 0.6310

[0m[1;37mINFO[0m: [1mChartInfo 0.8976 0.7031 0.8731 0.6836 0.8698 0.6741[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/17/2024 11:45:08 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.56
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.561
SUFF++ for r=0.3 class 0.0 = 0.72 +- 0.271 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 class 1.0 = 0.702 +- 0.271 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 all KL = 0.637 +- 0.271 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 all L1 = 0.704 +- 0.205 (in-sample avg dev_std = 0.534)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.594
SUFF++ for r=0.6 class 0.0 = 0.731 +- 0.254 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 1.0 = 0.706 +- 0.254 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all KL = 0.711 +- 0.254 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all L1 = 0.71 +- 0.211 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.635
SUFF++ for r=0.9 class 0.0 = 0.886 +- 0.183 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 class 1.0 = 0.842 +- 0.183 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all KL = 0.878 +- 0.183 (in-sample avg dev_std = 0.273)
SUFF++ for r=0.9 all L1 = 0.849 +- 0.171 (in-sample avg dev_std = 0.273)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.562
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.596
NEC for r=0.3 class 0.0 = 0.152 +- 0.228 (in-sample avg dev_std = 0.328)
NEC for r=0.3 class 1.0 = 0.187 +- 0.228 (in-sample avg dev_std = 0.328)
NEC for r=0.3 all KL = 0.174 +- 0.228 (in-sample avg dev_std = 0.328)
NEC for r=0.3 all L1 = 0.181 +- 0.204 (in-sample avg dev_std = 0.328)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.604
NEC for r=0.6 class 0.0 = 0.208 +- 0.209 (in-sample avg dev_std = 0.363)
NEC for r=0.6 class 1.0 = 0.231 +- 0.209 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all KL = 0.201 +- 0.209 (in-sample avg dev_std = 0.363)
NEC for r=0.6 all L1 = 0.227 +- 0.192 (in-sample avg dev_std = 0.363)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.644
NEC for r=0.9 class 0.0 = 0.148 +- 0.201 (in-sample avg dev_std = 0.345)
NEC for r=0.9 class 1.0 = 0.221 +- 0.201 (in-sample avg dev_std = 0.345)
NEC for r=0.9 all KL = 0.186 +- 0.201 (in-sample avg dev_std = 0.345)
NEC for r=0.9 all L1 = 0.209 +- 0.186 (in-sample avg dev_std = 0.345)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.667
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.637
NEC for r=1.0 class 0.0 = 0.142 +- 0.207 (in-sample avg dev_std = 0.340)
NEC for r=1.0 class 1.0 = 0.209 +- 0.207 (in-sample avg dev_std = 0.340)
NEC for r=1.0 all KL = 0.177 +- 0.207 (in-sample avg dev_std = 0.340)
NEC for r=1.0 all L1 = 0.198 +- 0.184 (in-sample avg dev_std = 0.340)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:46:27 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/17/2024 11:46:27 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 11:46:58 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:08 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:19 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:35 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:47:51 AM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:47:52 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ROC-AUC: 0.9203
Train Loss: 0.2616
ID Validation ROC-AUC: 0.8992
ID Validation Loss: 0.3023
ID Test ROC-AUC: 0.8991
ID Test Loss: 0.3012
OOD Validation ROC-AUC: 0.6438
OOD Validation Loss: 0.5717
OOD Test ROC-AUC: 0.7015
OOD Test Loss: 0.6695

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 19...
[0m[1;37mINFO[0m: [1mCheckpoint 19: 
-----------------------------------
Train ROC-AUC: 0.8698
Train Loss: 0.3086
ID Validation ROC-AUC: 0.8607
ID Validation Loss: 0.3199
ID Test ROC-AUC: 0.8667
ID Test Loss: 0.3140
OOD Validation ROC-AUC: 0.6746
OOD Validation Loss: 0.4525
OOD Test ROC-AUC: 0.6941
OOD Test Loss: 0.5667

[0m[1;37mINFO[0m: [1mChartInfo 0.8991 0.7015 0.8667 0.6941 0.8607 0.6746[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/17/2024 11:47:52 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.547
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 788
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0.0 = 0.657 +- 0.285 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 class 1.0 = 0.639 +- 0.285 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 all KL = 0.568 +- 0.285 (in-sample avg dev_std = 0.579)
SUFF++ for r=0.3 all L1 = 0.642 +- 0.208 (in-sample avg dev_std = 0.579)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
SUFF++ for r=0.6 class 0.0 = 0.676 +- 0.286 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 class 1.0 = 0.676 +- 0.286 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all KL = 0.645 +- 0.286 (in-sample avg dev_std = 0.488)
SUFF++ for r=0.6 all L1 = 0.676 +- 0.230 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.66
SUFF++ for r=0.9 class 0.0 = 0.868 +- 0.210 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 class 1.0 = 0.809 +- 0.210 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all KL = 0.839 +- 0.210 (in-sample avg dev_std = 0.339)
SUFF++ for r=0.9 all L1 = 0.819 +- 0.183 (in-sample avg dev_std = 0.339)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.551
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.57
NEC for r=0.3 class 0.0 = 0.258 +- 0.264 (in-sample avg dev_std = 0.413)
NEC for r=0.3 class 1.0 = 0.257 +- 0.264 (in-sample avg dev_std = 0.413)
NEC for r=0.3 all KL = 0.265 +- 0.264 (in-sample avg dev_std = 0.413)
NEC for r=0.3 all L1 = 0.257 +- 0.217 (in-sample avg dev_std = 0.413)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.625
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.619
NEC for r=0.6 class 0.0 = 0.25 +- 0.266 (in-sample avg dev_std = 0.438)
NEC for r=0.6 class 1.0 = 0.279 +- 0.266 (in-sample avg dev_std = 0.438)
NEC for r=0.6 all KL = 0.281 +- 0.266 (in-sample avg dev_std = 0.438)
NEC for r=0.6 all L1 = 0.274 +- 0.217 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.653
NEC for r=0.9 class 0.0 = 0.21 +- 0.250 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1.0 = 0.279 +- 0.250 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.263 +- 0.250 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.267 +- 0.210 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.643
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.642
NEC for r=1.0 class 0.0 = 0.21 +- 0.245 (in-sample avg dev_std = 0.401)
NEC for r=1.0 class 1.0 = 0.255 +- 0.245 (in-sample avg dev_std = 0.401)
NEC for r=1.0 all KL = 0.233 +- 0.245 (in-sample avg dev_std = 0.401)
NEC for r=1.0 all L1 = 0.247 +- 0.202 (in-sample avg dev_std = 0.401)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:49:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/17/2024 11:49:09 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 11:49:41 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 11:49:51 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:02 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:18 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ROC-AUC: 0.9212
Train Loss: 0.2580
ID Validation ROC-AUC: 0.9021
ID Validation Loss: 0.2945
ID Test ROC-AUC: 0.9029
ID Test Loss: 0.2921
OOD Validation ROC-AUC: 0.6499
OOD Validation Loss: 0.5617
OOD Test ROC-AUC: 0.7014
OOD Test Loss: 0.6597

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ROC-AUC: 0.8981
Train Loss: 0.2656
ID Validation ROC-AUC: 0.8784
ID Validation Loss: 0.3013
ID Test ROC-AUC: 0.8854
ID Test Loss: 0.2911
OOD Validation ROC-AUC: 0.6706
OOD Validation Loss: 0.3957
OOD Test ROC-AUC: 0.6942
OOD Test Loss: 0.5938

[0m[1;37mINFO[0m: [1mChartInfo 0.9029 0.7014 0.8854 0.6942 0.8784 0.6706[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/17/2024 11:50:34 AM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.583
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.554
SUFF++ for r=0.3 class 0.0 = 0.743 +- 0.247 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.3 class 1.0 = 0.719 +- 0.247 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.3 all KL = 0.703 +- 0.247 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.3 all L1 = 0.723 +- 0.189 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.592
SUFF++ for r=0.6 class 0.0 = 0.762 +- 0.211 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.6 class 1.0 = 0.735 +- 0.211 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.6 all KL = 0.782 +- 0.211 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.6 all L1 = 0.739 +- 0.192 (in-sample avg dev_std = 0.354)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.611
SUFF++ for r=0.9 class 0.0 = 0.927 +- 0.123 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 class 1.0 = 0.903 +- 0.123 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all KL = 0.94 +- 0.123 (in-sample avg dev_std = 0.217)
SUFF++ for r=0.9 all L1 = 0.907 +- 0.118 (in-sample avg dev_std = 0.217)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.571
NEC for r=0.3 class 0.0 = 0.155 +- 0.189 (in-sample avg dev_std = 0.297)
NEC for r=0.3 class 1.0 = 0.181 +- 0.189 (in-sample avg dev_std = 0.297)
NEC for r=0.3 all KL = 0.143 +- 0.189 (in-sample avg dev_std = 0.297)
NEC for r=0.3 all L1 = 0.177 +- 0.182 (in-sample avg dev_std = 0.297)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.6
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.607
NEC for r=0.6 class 0.0 = 0.172 +- 0.183 (in-sample avg dev_std = 0.342)
NEC for r=0.6 class 1.0 = 0.212 +- 0.183 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all KL = 0.157 +- 0.183 (in-sample avg dev_std = 0.342)
NEC for r=0.6 all L1 = 0.205 +- 0.169 (in-sample avg dev_std = 0.342)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.611
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.616
NEC for r=0.9 class 0.0 = 0.156 +- 0.189 (in-sample avg dev_std = 0.338)
NEC for r=0.9 class 1.0 = 0.22 +- 0.189 (in-sample avg dev_std = 0.338)
NEC for r=0.9 all KL = 0.167 +- 0.189 (in-sample avg dev_std = 0.338)
NEC for r=0.9 all L1 = 0.21 +- 0.175 (in-sample avg dev_std = 0.338)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.591
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.593
NEC for r=1.0 class 0.0 = 0.146 +- 0.178 (in-sample avg dev_std = 0.319)
NEC for r=1.0 class 1.0 = 0.201 +- 0.178 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all KL = 0.147 +- 0.178 (in-sample avg dev_std = 0.319)
NEC for r=1.0 all L1 = 0.192 +- 0.177 (in-sample avg dev_std = 0.319)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.802, 0.868, 0.927, 1.0], 'all_L1': [0.768, 0.836, 0.911, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.827, 0.895, 0.927, 1.0], 'all_L1': [0.797, 0.878, 0.932, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.637, 0.711, 0.878, 1.0], 'all_L1': [0.704, 0.71, 0.849, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.568, 0.645, 0.839, 1.0], 'all_L1': [0.642, 0.676, 0.819, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.703, 0.782, 0.94, 1.0], 'all_L1': [0.723, 0.739, 0.907, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.196, 0.159, 0.142, 0.137], 'all_L1': [0.229, 0.176, 0.139, 0.13]}), defaultdict(<class 'list'>, {'all_KL': [0.214, 0.138, 0.166, 0.19], 'all_L1': [0.225, 0.137, 0.128, 0.144]}), defaultdict(<class 'list'>, {'all_KL': [0.174, 0.201, 0.186, 0.177], 'all_L1': [0.181, 0.227, 0.209, 0.198]}), defaultdict(<class 'list'>, {'all_KL': [0.265, 0.281, 0.263, 0.233], 'all_L1': [0.257, 0.274, 0.267, 0.247]}), defaultdict(<class 'list'>, {'all_KL': [0.143, 0.157, 0.167, 0.147], 'all_L1': [0.177, 0.205, 0.21, 0.192]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.727 +- 0.054, 0.768 +- 0.077, 0.884 +- 0.042, 1.000 +- 0.000
suff++ class all_KL  =  0.707 +- 0.098, 0.780 +- 0.094, 0.902 +- 0.038, 1.000 +- 0.000
suff++_acc_int  =  0.576 +- 0.020, 0.619 +- 0.027, 0.654 +- 0.029
nec class all_L1  =  0.214 +- 0.031, 0.204 +- 0.046, 0.191 +- 0.051, 0.182 +- 0.042
nec class all_KL  =  0.198 +- 0.041, 0.187 +- 0.051, 0.185 +- 0.042, 0.177 +- 0.034
nec_acc_int  =  0.597 +- 0.026, 0.629 +- 0.024, 0.651 +- 0.021, 0.647 +- 0.034


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.470 +- 0.029, 0.486 +- 0.017, 0.537 +- 0.012, 0.591 +- 0.021
Faith. Armon (L1)= 		  =  0.329 +- 0.035, 0.317 +- 0.051, 0.309 +- 0.067, 0.306 +- 0.059
Faith. GMean (L1)= 	  =  0.393 +- 0.029, 0.390 +- 0.027, 0.405 +- 0.047, 0.424 +- 0.049
Faith. Aritm (KL)= 		  =  0.453 +- 0.047, 0.484 +- 0.026, 0.544 +- 0.009, 0.588 +- 0.017
Faith. Armon (KL)= 		  =  0.305 +- 0.045, 0.295 +- 0.054, 0.304 +- 0.052, 0.299 +- 0.049
Faith. GMean (KL)= 	  =  0.371 +- 0.039, 0.375 +- 0.027, 0.405 +- 0.035, 0.419 +- 0.040
Computed for split load_split = id



Completed in  0:13:39.220828  for GSATGIN LBAPcore/assay



DONE GSAT LBAPcore/assay all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:52:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:52:06 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ACCURACY: 0.8946
Train Loss: 0.2294
ID Validation ACCURACY: 0.8451
ID Validation Loss: 0.4596
ID Test ACCURACY: 0.8359
ID Test Loss: 0.4928
OOD Validation ACCURACY: 0.8442
OOD Validation Loss: 0.7055
OOD Test ACCURACY: 0.7909
OOD Test Loss: 1.2081

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 150...
[0m[1;37mINFO[0m: [1mCheckpoint 150: 
-----------------------------------
Train ACCURACY: 0.8613
Train Loss: 0.3029
ID Validation ACCURACY: 0.8268
ID Validation Loss: 0.4327
ID Test ACCURACY: 0.8231
ID Test Loss: 0.4451
OOD Validation ACCURACY: 0.8502
OOD Validation Loss: 0.5097
OOD Test ACCURACY: 0.8121
OOD Test Loss: 0.6943

[0m[1;37mINFO[0m: [1mChartInfo 0.8359 0.7909 0.8231 0.8121 0.8268 0.8502[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.739
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.73
SUFF++ for r=0.3 class 0.0 = 0.881 +- 0.151 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 class 1.0 = 0.954 +- 0.151 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 all KL = 0.923 +- 0.151 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.3 all L1 = 0.919 +- 0.133 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.757
SUFF++ for r=0.6 class 0.0 = 0.915 +- 0.113 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 class 1.0 = 0.961 +- 0.113 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all KL = 0.954 +- 0.113 (in-sample avg dev_std = 0.168)
SUFF++ for r=0.6 all L1 = 0.939 +- 0.120 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.792
SUFF++ for r=0.9 class 0.0 = 0.966 +- 0.035 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.035 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.99 +- 0.035 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.975 +- 0.064 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.739
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.745
NEC for r=0.3 class 0.0 = 0.138 +- 0.164 (in-sample avg dev_std = 0.180)
NEC for r=0.3 class 1.0 = 0.06 +- 0.164 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all KL = 0.077 +- 0.164 (in-sample avg dev_std = 0.180)
NEC for r=0.3 all L1 = 0.098 +- 0.168 (in-sample avg dev_std = 0.180)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.774
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.109 +- 0.143 (in-sample avg dev_std = 0.170)
NEC for r=0.6 class 1.0 = 0.046 +- 0.143 (in-sample avg dev_std = 0.170)
NEC for r=0.6 all KL = 0.058 +- 0.143 (in-sample avg dev_std = 0.170)
NEC for r=0.6 all L1 = 0.077 +- 0.149 (in-sample avg dev_std = 0.170)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.794
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.798
NEC for r=0.9 class 0.0 = 0.093 +- 0.118 (in-sample avg dev_std = 0.144)
NEC for r=0.9 class 1.0 = 0.038 +- 0.118 (in-sample avg dev_std = 0.144)
NEC for r=0.9 all KL = 0.044 +- 0.118 (in-sample avg dev_std = 0.144)
NEC for r=0.9 all L1 = 0.065 +- 0.136 (in-sample avg dev_std = 0.144)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.795
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.798
NEC for r=1.0 class 0.0 = 0.088 +- 0.125 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 1.0 = 0.037 +- 0.125 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all KL = 0.045 +- 0.125 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all L1 = 0.062 +- 0.136 (in-sample avg dev_std = 0.151)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:53:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:53:43 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9069
Train Loss: 0.1959
ID Validation ACCURACY: 0.8449
ID Validation Loss: 0.5034
ID Test ACCURACY: 0.8380
ID Test Loss: 0.5283
OOD Validation ACCURACY: 0.8458
OOD Validation Loss: 0.8693
OOD Test ACCURACY: 0.8026
OOD Test Loss: 1.3095

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 35...
[0m[1;37mINFO[0m: [1mCheckpoint 35: 
-----------------------------------
Train ACCURACY: 0.8494
Train Loss: 0.3303
ID Validation ACCURACY: 0.8246
ID Validation Loss: 0.3965
ID Test ACCURACY: 0.8274
ID Test Loss: 0.4033
OOD Validation ACCURACY: 0.8494
OOD Validation Loss: 0.3884
OOD Test ACCURACY: 0.8215
OOD Test Loss: 0.4617

[0m[1;37mINFO[0m: [1mChartInfo 0.8380 0.8026 0.8274 0.8215 0.8246 0.8494[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.774
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.765
SUFF++ for r=0.3 class 0.0 = 0.898 +- 0.203 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 class 1.0 = 0.927 +- 0.203 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all KL = 0.887 +- 0.203 (in-sample avg dev_std = 0.262)
SUFF++ for r=0.3 all L1 = 0.913 +- 0.147 (in-sample avg dev_std = 0.262)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.802
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 class 1.0 = 0.957 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 all KL = 0.942 +- 0.132 (in-sample avg dev_std = 0.171)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.135 (in-sample avg dev_std = 0.171)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.827
SUFF++ for r=0.9 class 0.0 = 0.964 +- 0.056 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 class 1.0 = 0.981 +- 0.056 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all KL = 0.986 +- 0.056 (in-sample avg dev_std = 0.088)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.081 (in-sample avg dev_std = 0.088)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.774
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.785
NEC for r=0.3 class 0.0 = 0.107 +- 0.200 (in-sample avg dev_std = 0.207)
NEC for r=0.3 class 1.0 = 0.077 +- 0.200 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all KL = 0.093 +- 0.200 (in-sample avg dev_std = 0.207)
NEC for r=0.3 all L1 = 0.091 +- 0.178 (in-sample avg dev_std = 0.207)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.811
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.809
NEC for r=0.6 class 0.0 = 0.096 +- 0.165 (in-sample avg dev_std = 0.172)
NEC for r=0.6 class 1.0 = 0.053 +- 0.165 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all KL = 0.065 +- 0.165 (in-sample avg dev_std = 0.172)
NEC for r=0.6 all L1 = 0.074 +- 0.163 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.83
NEC for r=0.9 class 0.0 = 0.07 +- 0.130 (in-sample avg dev_std = 0.148)
NEC for r=0.9 class 1.0 = 0.042 +- 0.130 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all KL = 0.046 +- 0.130 (in-sample avg dev_std = 0.148)
NEC for r=0.9 all L1 = 0.056 +- 0.132 (in-sample avg dev_std = 0.148)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.836
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.839
NEC for r=1.0 class 0.0 = 0.073 +- 0.145 (in-sample avg dev_std = 0.156)
NEC for r=1.0 class 1.0 = 0.041 +- 0.145 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all KL = 0.05 +- 0.145 (in-sample avg dev_std = 0.156)
NEC for r=1.0 all L1 = 0.057 +- 0.141 (in-sample avg dev_std = 0.156)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:55:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:55:18 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9232
Train Loss: 0.1496
ID Validation ACCURACY: 0.8449
ID Validation Loss: 0.5913
ID Test ACCURACY: 0.8447
ID Test Loss: 0.5983
OOD Validation ACCURACY: 0.8434
OOD Validation Loss: 0.9268
OOD Test ACCURACY: 0.7956
OOD Test Loss: 1.1860

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ACCURACY: 0.8865
Train Loss: 0.2502
ID Validation ACCURACY: 0.8387
ID Validation Loss: 0.4508
ID Test ACCURACY: 0.8359
ID Test Loss: 0.4682
OOD Validation ACCURACY: 0.8523
OOD Validation Loss: 0.5568
OOD Test ACCURACY: 0.8184
OOD Test Loss: 0.7482

[0m[1;37mINFO[0m: [1mChartInfo 0.8447 0.7956 0.8359 0.8184 0.8387 0.8523[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.746
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.735
SUFF++ for r=0.3 class 0.0 = 0.901 +- 0.171 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 class 1.0 = 0.947 +- 0.171 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 all KL = 0.911 +- 0.171 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.3 all L1 = 0.925 +- 0.130 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.769
SUFF++ for r=0.6 class 0.0 = 0.917 +- 0.121 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1.0 = 0.949 +- 0.121 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.945 +- 0.121 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.934 +- 0.129 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.808
SUFF++ for r=0.9 class 0.0 = 0.961 +- 0.046 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.046 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all KL = 0.986 +- 0.046 (in-sample avg dev_std = 0.094)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.072 (in-sample avg dev_std = 0.094)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.746
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.763
NEC for r=0.3 class 0.0 = 0.141 +- 0.229 (in-sample avg dev_std = 0.220)
NEC for r=0.3 class 1.0 = 0.071 +- 0.229 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all KL = 0.109 +- 0.229 (in-sample avg dev_std = 0.220)
NEC for r=0.3 all L1 = 0.105 +- 0.196 (in-sample avg dev_std = 0.220)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.786
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.796
NEC for r=0.6 class 0.0 = 0.121 +- 0.174 (in-sample avg dev_std = 0.196)
NEC for r=0.6 class 1.0 = 0.058 +- 0.174 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all KL = 0.075 +- 0.174 (in-sample avg dev_std = 0.196)
NEC for r=0.6 all L1 = 0.088 +- 0.173 (in-sample avg dev_std = 0.196)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.821
NEC for r=0.9 class 0.0 = 0.092 +- 0.140 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1.0 = 0.05 +- 0.140 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.055 +- 0.140 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.07 +- 0.147 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.817
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.089 +- 0.138 (in-sample avg dev_std = 0.163)
NEC for r=1.0 class 1.0 = 0.05 +- 0.138 (in-sample avg dev_std = 0.163)
NEC for r=1.0 all KL = 0.057 +- 0.138 (in-sample avg dev_std = 0.163)
NEC for r=1.0 all L1 = 0.069 +- 0.147 (in-sample avg dev_std = 0.163)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:56:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:56:55 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.8962
Train Loss: 0.2153
ID Validation ACCURACY: 0.8427
ID Validation Loss: 0.4803
ID Test ACCURACY: 0.8374
ID Test Loss: 0.4933
OOD Validation ACCURACY: 0.8439
OOD Validation Loss: 0.7998
OOD Test ACCURACY: 0.7991
OOD Test Loss: 1.0971

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 82...
[0m[1;37mINFO[0m: [1mCheckpoint 82: 
-----------------------------------
Train ACCURACY: 0.8763
Train Loss: 0.2680
ID Validation ACCURACY: 0.8308
ID Validation Loss: 0.4440
ID Test ACCURACY: 0.8295
ID Test Loss: 0.4615
OOD Validation ACCURACY: 0.8541
OOD Validation Loss: 0.6125
OOD Test ACCURACY: 0.8222
OOD Test Loss: 0.7056

[0m[1;37mINFO[0m: [1mChartInfo 0.8374 0.7991 0.8295 0.8222 0.8308 0.8541[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.752
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.748
SUFF++ for r=0.3 class 0.0 = 0.896 +- 0.164 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 class 1.0 = 0.949 +- 0.164 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all KL = 0.919 +- 0.164 (in-sample avg dev_std = 0.226)
SUFF++ for r=0.3 all L1 = 0.924 +- 0.131 (in-sample avg dev_std = 0.226)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.788
SUFF++ for r=0.6 class 0.0 = 0.918 +- 0.129 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 class 1.0 = 0.966 +- 0.129 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all KL = 0.949 +- 0.129 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.6 all L1 = 0.943 +- 0.114 (in-sample avg dev_std = 0.172)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.821
SUFF++ for r=0.9 class 0.0 = 0.968 +- 0.036 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.036 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all KL = 0.991 +- 0.036 (in-sample avg dev_std = 0.081)
SUFF++ for r=0.9 all L1 = 0.976 +- 0.065 (in-sample avg dev_std = 0.081)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.752
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.772
NEC for r=0.3 class 0.0 = 0.116 +- 0.176 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 1.0 = 0.077 +- 0.176 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all KL = 0.081 +- 0.176 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all L1 = 0.096 +- 0.176 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.801
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.803
NEC for r=0.6 class 0.0 = 0.098 +- 0.123 (in-sample avg dev_std = 0.150)
NEC for r=0.6 class 1.0 = 0.043 +- 0.123 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all KL = 0.052 +- 0.123 (in-sample avg dev_std = 0.150)
NEC for r=0.6 all L1 = 0.07 +- 0.139 (in-sample avg dev_std = 0.150)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.821
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
NEC for r=0.9 class 0.0 = 0.086 +- 0.123 (in-sample avg dev_std = 0.149)
NEC for r=0.9 class 1.0 = 0.04 +- 0.123 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all KL = 0.045 +- 0.123 (in-sample avg dev_std = 0.149)
NEC for r=0.9 all L1 = 0.063 +- 0.137 (in-sample avg dev_std = 0.149)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.823
NEC for r=1.0 class 0.0 = 0.082 +- 0.124 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.038 +- 0.124 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.043 +- 0.124 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.059 +- 0.137 (in-sample avg dev_std = 0.145)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 11:58:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 11:58:31 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ACCURACY: 0.9018
Train Loss: 0.2011
ID Validation ACCURACY: 0.8468
ID Validation Loss: 0.5144
ID Test ACCURACY: 0.8415
ID Test Loss: 0.5419
OOD Validation ACCURACY: 0.8424
OOD Validation Loss: 0.9462
OOD Test ACCURACY: 0.7918
OOD Test Loss: 1.4711

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.8617
Train Loss: 0.3062
ID Validation ACCURACY: 0.8221
ID Validation Loss: 0.4222
ID Test ACCURACY: 0.8200
ID Test Loss: 0.4485
OOD Validation ACCURACY: 0.8539
OOD Validation Loss: 0.4468
OOD Test ACCURACY: 0.8237
OOD Test Loss: 0.5712

[0m[1;37mINFO[0m: [1mChartInfo 0.8415 0.7918 0.8200 0.8237 0.8221 0.8539[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.751
SUFF++ for r=0.3 class 0.0 = 0.887 +- 0.214 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 class 1.0 = 0.934 +- 0.214 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all KL = 0.887 +- 0.214 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.3 all L1 = 0.911 +- 0.159 (in-sample avg dev_std = 0.268)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.779
SUFF++ for r=0.6 class 0.0 = 0.914 +- 0.137 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 class 1.0 = 0.957 +- 0.137 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all KL = 0.943 +- 0.137 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.138 (in-sample avg dev_std = 0.176)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.81
SUFF++ for r=0.9 class 0.0 = 0.961 +- 0.064 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.064 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all KL = 0.983 +- 0.064 (in-sample avg dev_std = 0.109)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.080 (in-sample avg dev_std = 0.109)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.771
NEC for r=0.3 class 0.0 = 0.117 +- 0.203 (in-sample avg dev_std = 0.202)
NEC for r=0.3 class 1.0 = 0.068 +- 0.203 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all KL = 0.094 +- 0.203 (in-sample avg dev_std = 0.202)
NEC for r=0.3 all L1 = 0.092 +- 0.180 (in-sample avg dev_std = 0.202)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.794
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.798
NEC for r=0.6 class 0.0 = 0.1 +- 0.162 (in-sample avg dev_std = 0.180)
NEC for r=0.6 class 1.0 = 0.054 +- 0.162 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all KL = 0.069 +- 0.162 (in-sample avg dev_std = 0.180)
NEC for r=0.6 all L1 = 0.076 +- 0.158 (in-sample avg dev_std = 0.180)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.816
NEC for r=0.9 class 0.0 = 0.089 +- 0.155 (in-sample avg dev_std = 0.161)
NEC for r=0.9 class 1.0 = 0.047 +- 0.155 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all KL = 0.058 +- 0.155 (in-sample avg dev_std = 0.161)
NEC for r=0.9 all L1 = 0.067 +- 0.153 (in-sample avg dev_std = 0.161)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.812
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.816
NEC for r=1.0 class 0.0 = 0.092 +- 0.168 (in-sample avg dev_std = 0.178)
NEC for r=1.0 class 1.0 = 0.047 +- 0.168 (in-sample avg dev_std = 0.178)
NEC for r=1.0 all KL = 0.062 +- 0.168 (in-sample avg dev_std = 0.178)
NEC for r=1.0 all L1 = 0.068 +- 0.158 (in-sample avg dev_std = 0.178)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.923, 0.954, 0.99, 1.0], 'all_L1': [0.919, 0.939, 0.975, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.887, 0.942, 0.986, 1.0], 'all_L1': [0.913, 0.938, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.945, 0.986, 1.0], 'all_L1': [0.925, 0.934, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.919, 0.949, 0.991, 1.0], 'all_L1': [0.924, 0.943, 0.976, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.887, 0.943, 0.983, 1.0], 'all_L1': [0.911, 0.936, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.077, 0.058, 0.044, 0.045], 'all_L1': [0.098, 0.077, 0.065, 0.062]}), defaultdict(<class 'list'>, {'all_KL': [0.093, 0.065, 0.046, 0.05], 'all_L1': [0.091, 0.074, 0.056, 0.057]}), defaultdict(<class 'list'>, {'all_KL': [0.109, 0.075, 0.055, 0.057], 'all_L1': [0.105, 0.088, 0.07, 0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.081, 0.052, 0.045, 0.043], 'all_L1': [0.096, 0.07, 0.063, 0.059]}), defaultdict(<class 'list'>, {'all_KL': [0.094, 0.069, 0.058, 0.062], 'all_L1': [0.092, 0.076, 0.067, 0.068]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.918 +- 0.006, 0.938 +- 0.003, 0.973 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.905 +- 0.016, 0.947 +- 0.004, 0.987 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.746 +- 0.012, 0.779 +- 0.015, 0.812 +- 0.012
nec class all_L1  =  0.096 +- 0.005, 0.077 +- 0.006, 0.064 +- 0.005, 0.063 +- 0.005
nec class all_KL  =  0.091 +- 0.011, 0.064 +- 0.008, 0.050 +- 0.006, 0.051 +- 0.007
nec_acc_int  =  0.767 +- 0.013, 0.796 +- 0.012, 0.818 +- 0.011, 0.820 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.507 +- 0.005, 0.508 +- 0.002, 0.519 +- 0.002, 0.531 +- 0.002
Faith. Armon (L1)= 		  =  0.174 +- 0.008, 0.142 +- 0.010, 0.120 +- 0.008, 0.118 +- 0.008
Faith. GMean (L1)= 	  =  0.297 +- 0.008, 0.269 +- 0.010, 0.250 +- 0.009, 0.251 +- 0.010
Faith. Aritm (KL)= 		  =  0.498 +- 0.007, 0.505 +- 0.003, 0.518 +- 0.002, 0.526 +- 0.004
Faith. Armon (KL)= 		  =  0.165 +- 0.018, 0.119 +- 0.014, 0.094 +- 0.010, 0.098 +- 0.013
Faith. GMean (KL)= 	  =  0.286 +- 0.017, 0.245 +- 0.015, 0.221 +- 0.012, 0.226 +- 0.016
Computed for split load_split = id



Completed in  0:08:01.935356  for GSATGIN GOODSST2/length



DONE GSAT GOODSST2/length all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:00:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:18 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:20 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:21 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:23 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:00:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 89...
[0m[1;37mINFO[0m: [1mCheckpoint 89: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6877
ID Validation Loss: 3.0407
ID Test ACCURACY: 0.6661
ID Test Loss: 3.2248
OOD Validation ACCURACY: 0.5972
OOD Validation Loss: 3.5529
OOD Test ACCURACY: 0.5367
OOD Test Loss: 4.2839

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.9992
Train Loss: 0.0041
ID Validation ACCURACY: 0.6697
ID Validation Loss: 3.3240
ID Test ACCURACY: 0.6679
ID Test Loss: 3.3535
OOD Validation ACCURACY: 0.6101
OOD Validation Loss: 3.3846
OOD Test ACCURACY: 0.5642
OOD Test Loss: 3.7116

[0m[1;37mINFO[0m: [1mChartInfo 0.6661 0.5367 0.6679 0.5642 0.6697 0.6101[0mGOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.389
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.409
SUFF++ for r=0.3 class 0 = 0.843 +- 0.239 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.3 class 1 = 0.76 +- 0.239 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.3 class 2 = 0.767 +- 0.239 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.3 all KL = 0.781 +- 0.239 (in-sample avg dev_std = 0.406)
SUFF++ for r=0.3 all L1 = 0.783 +- 0.190 (in-sample avg dev_std = 0.406)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.501
SUFF++ for r=0.6 class 0 = 0.903 +- 0.202 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 1 = 0.795 +- 0.202 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 2 = 0.842 +- 0.202 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all KL = 0.867 +- 0.202 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all L1 = 0.835 +- 0.202 (in-sample avg dev_std = 0.285)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.521
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.528
SUFF++ for r=0.9 class 0 = 0.962 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 1 = 0.939 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 class 2 = 0.943 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all KL = 0.976 +- 0.058 (in-sample avg dev_std = 0.132)
SUFF++ for r=0.9 all L1 = 0.946 +- 0.094 (in-sample avg dev_std = 0.132)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.396
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.394
NEC for r=0.3 class 0 = 0.102 +- 0.158 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 1 = 0.188 +- 0.158 (in-sample avg dev_std = 0.242)
NEC for r=0.3 class 2 = 0.183 +- 0.158 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all KL = 0.11 +- 0.158 (in-sample avg dev_std = 0.242)
NEC for r=0.3 all L1 = 0.164 +- 0.174 (in-sample avg dev_std = 0.242)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.481
NEC for r=0.6 class 0 = 0.085 +- 0.201 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 1 = 0.202 +- 0.201 (in-sample avg dev_std = 0.286)
NEC for r=0.6 class 2 = 0.172 +- 0.201 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all KL = 0.134 +- 0.201 (in-sample avg dev_std = 0.286)
NEC for r=0.6 all L1 = 0.164 +- 0.194 (in-sample avg dev_std = 0.286)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.521
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.522
NEC for r=0.9 class 0 = 0.096 +- 0.216 (in-sample avg dev_std = 0.275)
NEC for r=0.9 class 1 = 0.192 +- 0.216 (in-sample avg dev_std = 0.275)
NEC for r=0.9 class 2 = 0.169 +- 0.216 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all KL = 0.143 +- 0.216 (in-sample avg dev_std = 0.275)
NEC for r=0.9 all L1 = 0.161 +- 0.210 (in-sample avg dev_std = 0.275)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.533
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.53
NEC for r=1.0 class 0 = 0.088 +- 0.236 (in-sample avg dev_std = 0.284)
NEC for r=1.0 class 1 = 0.185 +- 0.236 (in-sample avg dev_std = 0.284)
NEC for r=1.0 class 2 = 0.179 +- 0.236 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all KL = 0.148 +- 0.236 (in-sample avg dev_std = 0.284)
NEC for r=1.0 all L1 = 0.158 +- 0.219 (in-sample avg dev_std = 0.284)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:02:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:11 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:13 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:14 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:14 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:02:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 157...
[0m[1;37mINFO[0m: [1mCheckpoint 157: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6895
ID Validation Loss: 4.0211
ID Test ACCURACY: 0.6300
ID Test Loss: 3.9427
OOD Validation ACCURACY: 0.5832
OOD Validation Loss: 3.7787
OOD Test ACCURACY: 0.5635
OOD Test Loss: 4.3822

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6787
ID Validation Loss: 3.5222
ID Test ACCURACY: 0.6534
ID Test Loss: 3.4855
OOD Validation ACCURACY: 0.6230
OOD Validation Loss: 3.2861
OOD Test ACCURACY: 0.5477
OOD Test Loss: 3.9053

[0m[1;37mINFO[0m: [1mChartInfo 0.6300 0.5635 0.6534 0.5477 0.6787 0.6230[0mGOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.415
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 778
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.428
SUFF++ for r=0.3 class 0 = 0.838 +- 0.250 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 class 1 = 0.765 +- 0.250 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 class 2 = 0.766 +- 0.250 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 all KL = 0.773 +- 0.250 (in-sample avg dev_std = 0.417)
SUFF++ for r=0.3 all L1 = 0.784 +- 0.197 (in-sample avg dev_std = 0.417)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.482
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.494
SUFF++ for r=0.6 class 0 = 0.878 +- 0.216 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 class 1 = 0.806 +- 0.216 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 class 2 = 0.861 +- 0.216 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 all KL = 0.862 +- 0.216 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.6 all L1 = 0.839 +- 0.210 (in-sample avg dev_std = 0.286)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.55
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.552
SUFF++ for r=0.9 class 0 = 0.959 +- 0.075 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 1 = 0.946 +- 0.075 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 2 = 0.95 +- 0.075 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all KL = 0.974 +- 0.075 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.101 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.409
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.418
NEC for r=0.3 class 0 = 0.148 +- 0.203 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 1 = 0.204 +- 0.203 (in-sample avg dev_std = 0.292)
NEC for r=0.3 class 2 = 0.195 +- 0.203 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all KL = 0.15 +- 0.203 (in-sample avg dev_std = 0.292)
NEC for r=0.3 all L1 = 0.187 +- 0.195 (in-sample avg dev_std = 0.292)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.482
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.482
NEC for r=0.6 class 0 = 0.124 +- 0.204 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 1 = 0.187 +- 0.204 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 2 = 0.144 +- 0.204 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all KL = 0.138 +- 0.204 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all L1 = 0.16 +- 0.199 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.55
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.536
NEC for r=0.9 class 0 = 0.099 +- 0.227 (in-sample avg dev_std = 0.277)
NEC for r=0.9 class 1 = 0.168 +- 0.227 (in-sample avg dev_std = 0.277)
NEC for r=0.9 class 2 = 0.152 +- 0.227 (in-sample avg dev_std = 0.277)
NEC for r=0.9 all KL = 0.139 +- 0.227 (in-sample avg dev_std = 0.277)
NEC for r=0.9 all L1 = 0.146 +- 0.210 (in-sample avg dev_std = 0.277)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.569
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.556
NEC for r=1.0 class 0 = 0.113 +- 0.245 (in-sample avg dev_std = 0.283)
NEC for r=1.0 class 1 = 0.156 +- 0.245 (in-sample avg dev_std = 0.283)
NEC for r=1.0 class 2 = 0.164 +- 0.245 (in-sample avg dev_std = 0.283)
NEC for r=1.0 all KL = 0.145 +- 0.245 (in-sample avg dev_std = 0.283)
NEC for r=1.0 all L1 = 0.147 +- 0.224 (in-sample avg dev_std = 0.283)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:04:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:04:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6751
ID Validation Loss: 3.4008
ID Test ACCURACY: 0.6498
ID Test Loss: 3.5024
OOD Validation ACCURACY: 0.5882
OOD Validation Loss: 3.5451
OOD Test ACCURACY: 0.5669
OOD Test Loss: 3.8004

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 69...
[0m[1;37mINFO[0m: [1mCheckpoint 69: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6606
ID Validation Loss: 2.9431
ID Test ACCURACY: 0.6480
ID Test Loss: 3.2333
OOD Validation ACCURACY: 0.6056
OOD Validation Loss: 2.9688
OOD Test ACCURACY: 0.5607
OOD Test Loss: 3.3583

[0m[1;37mINFO[0m: [1mChartInfo 0.6498 0.5669 0.6480 0.5607 0.6606 0.6056[0mGOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.449
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 779
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.448
SUFF++ for r=0.3 class 0 = 0.791 +- 0.262 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 1 = 0.735 +- 0.262 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 2 = 0.776 +- 0.262 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all KL = 0.739 +- 0.262 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all L1 = 0.76 +- 0.199 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.524
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.538
SUFF++ for r=0.6 class 0 = 0.869 +- 0.218 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 class 1 = 0.792 +- 0.218 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 class 2 = 0.825 +- 0.218 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 all KL = 0.849 +- 0.218 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.211 (in-sample avg dev_std = 0.305)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.565
SUFF++ for r=0.9 class 0 = 0.953 +- 0.069 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 class 1 = 0.951 +- 0.069 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 class 2 = 0.943 +- 0.069 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all KL = 0.974 +- 0.069 (in-sample avg dev_std = 0.138)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.094 (in-sample avg dev_std = 0.138)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.446
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.443
NEC for r=0.3 class 0 = 0.152 +- 0.206 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1 = 0.223 +- 0.206 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 2 = 0.18 +- 0.206 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.153 +- 0.206 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.194 +- 0.190 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.524
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.537
NEC for r=0.6 class 0 = 0.13 +- 0.222 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1 = 0.205 +- 0.222 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 2 = 0.193 +- 0.222 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.165 +- 0.222 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.183 +- 0.198 (in-sample avg dev_std = 0.317)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.564
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.567
NEC for r=0.9 class 0 = 0.147 +- 0.240 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 1 = 0.146 +- 0.240 (in-sample avg dev_std = 0.284)
NEC for r=0.9 class 2 = 0.18 +- 0.240 (in-sample avg dev_std = 0.284)
NEC for r=0.9 all KL = 0.148 +- 0.240 (in-sample avg dev_std = 0.284)
NEC for r=0.9 all L1 = 0.155 +- 0.217 (in-sample avg dev_std = 0.284)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.572
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.58
NEC for r=1.0 class 0 = 0.145 +- 0.242 (in-sample avg dev_std = 0.278)
NEC for r=1.0 class 1 = 0.132 +- 0.242 (in-sample avg dev_std = 0.278)
NEC for r=1.0 class 2 = 0.17 +- 0.242 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all KL = 0.144 +- 0.242 (in-sample avg dev_std = 0.278)
NEC for r=1.0 all L1 = 0.145 +- 0.219 (in-sample avg dev_std = 0.278)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:05:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/17/2024 12:05:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:05:56 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:05:56 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:05:57 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:05:59 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:06:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6841
ID Validation Loss: 3.9650
ID Test ACCURACY: 0.6480
ID Test Loss: 4.0392
OOD Validation ACCURACY: 0.5955
OOD Validation Loss: 4.0912
OOD Test ACCURACY: 0.5422
OOD Test Loss: 4.6949

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6588
ID Validation Loss: 3.7182
ID Test ACCURACY: 0.6787
ID Test Loss: 3.3927
OOD Validation ACCURACY: 0.6174
OOD Validation Loss: 3.7005
OOD Test ACCURACY: 0.5546
OOD Test Loss: 4.1786

[0m[1;37mINFO[0m: [1mChartInfo 0.6480 0.5422 0.6787 0.5546 0.6588 0.6174[0mGOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.454
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 787
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.451
SUFF++ for r=0.3 class 0 = 0.802 +- 0.260 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 1 = 0.741 +- 0.260 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 class 2 = 0.76 +- 0.260 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all KL = 0.739 +- 0.260 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.3 all L1 = 0.762 +- 0.201 (in-sample avg dev_std = 0.455)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.527
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.54
SUFF++ for r=0.6 class 0 = 0.883 +- 0.184 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 class 1 = 0.852 +- 0.184 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 class 2 = 0.862 +- 0.184 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 all KL = 0.891 +- 0.184 (in-sample avg dev_std = 0.249)
SUFF++ for r=0.6 all L1 = 0.863 +- 0.187 (in-sample avg dev_std = 0.249)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.559
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.554
SUFF++ for r=0.9 class 0 = 0.96 +- 0.053 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 class 1 = 0.959 +- 0.053 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 class 2 = 0.96 +- 0.053 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 all KL = 0.981 +- 0.053 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.084 (in-sample avg dev_std = 0.115)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.449
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.456
NEC for r=0.3 class 0 = 0.134 +- 0.210 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 1 = 0.218 +- 0.210 (in-sample avg dev_std = 0.299)
NEC for r=0.3 class 2 = 0.171 +- 0.210 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all KL = 0.153 +- 0.210 (in-sample avg dev_std = 0.299)
NEC for r=0.3 all L1 = 0.184 +- 0.190 (in-sample avg dev_std = 0.299)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.527
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.531
NEC for r=0.6 class 0 = 0.128 +- 0.218 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 1 = 0.172 +- 0.218 (in-sample avg dev_std = 0.302)
NEC for r=0.6 class 2 = 0.162 +- 0.218 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all KL = 0.148 +- 0.218 (in-sample avg dev_std = 0.302)
NEC for r=0.6 all L1 = 0.158 +- 0.201 (in-sample avg dev_std = 0.302)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.559
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.562
NEC for r=0.9 class 0 = 0.127 +- 0.229 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 1 = 0.127 +- 0.229 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 2 = 0.154 +- 0.229 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all KL = 0.132 +- 0.229 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all L1 = 0.133 +- 0.206 (in-sample avg dev_std = 0.273)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.564
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.569
NEC for r=1.0 class 0 = 0.116 +- 0.239 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 1 = 0.124 +- 0.239 (in-sample avg dev_std = 0.280)
NEC for r=1.0 class 2 = 0.144 +- 0.239 (in-sample avg dev_std = 0.280)
NEC for r=1.0 all KL = 0.131 +- 0.239 (in-sample avg dev_std = 0.280)
NEC for r=1.0 all L1 = 0.127 +- 0.207 (in-sample avg dev_std = 0.280)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:07:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:45 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:47 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:48 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:48 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:50 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:07:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6841
ID Validation Loss: 3.3700
ID Test ACCURACY: 0.6408
ID Test Loss: 3.6060
OOD Validation ACCURACY: 0.6106
OOD Validation Loss: 3.5388
OOD Test ACCURACY: 0.5456
OOD Test Loss: 4.0838

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0005
ID Validation ACCURACY: 0.6552
ID Validation Loss: 2.6488
ID Test ACCURACY: 0.6444
ID Test Loss: 2.8878
OOD Validation ACCURACY: 0.6162
OOD Validation Loss: 2.8389
OOD Test ACCURACY: 0.5340
OOD Test Loss: 3.5982

[0m[1;37mINFO[0m: [1mChartInfo 0.6408 0.5456 0.6444 0.5340 0.6552 0.6162[0mGOODTwitter(1457)
Data example from test: Data(x=[28, 768], edge_index=[2, 54], y=[1], idx=[1], sentence_tokens=[28], length=[1], domain_id=[1], ori_edge_index=[2, 54], node_perm=[28])
Label distribution from test: (tensor([0, 1, 2]), tensor([379, 719, 359]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.404
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 782
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.407
SUFF++ for r=0.3 class 0 = 0.798 +- 0.271 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 1 = 0.755 +- 0.271 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 class 2 = 0.787 +- 0.271 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all KL = 0.742 +- 0.271 (in-sample avg dev_std = 0.436)
SUFF++ for r=0.3 all L1 = 0.774 +- 0.202 (in-sample avg dev_std = 0.436)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.495
SUFF++ for r=0.6 class 0 = 0.857 +- 0.246 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.246 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 2 = 0.827 +- 0.246 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all KL = 0.827 +- 0.246 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all L1 = 0.818 +- 0.217 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.527
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.537
SUFF++ for r=0.9 class 0 = 0.952 +- 0.085 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1 = 0.941 +- 0.085 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 2 = 0.943 +- 0.085 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.968 +- 0.085 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.944 +- 0.108 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.403
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.005
Model Accuracy over intervened graphs for r=0.3 =  0.407
NEC for r=0.3 class 0 = 0.131 +- 0.189 (in-sample avg dev_std = 0.279)
NEC for r=0.3 class 1 = 0.191 +- 0.189 (in-sample avg dev_std = 0.279)
NEC for r=0.3 class 2 = 0.179 +- 0.189 (in-sample avg dev_std = 0.279)
NEC for r=0.3 all KL = 0.134 +- 0.189 (in-sample avg dev_std = 0.279)
NEC for r=0.3 all L1 = 0.173 +- 0.183 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.004
Model Accuracy over intervened graphs for r=0.6 =  0.487
NEC for r=0.6 class 0 = 0.128 +- 0.215 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 1 = 0.196 +- 0.215 (in-sample avg dev_std = 0.307)
NEC for r=0.6 class 2 = 0.171 +- 0.215 (in-sample avg dev_std = 0.307)
NEC for r=0.6 all KL = 0.155 +- 0.215 (in-sample avg dev_std = 0.307)
NEC for r=0.6 all L1 = 0.172 +- 0.200 (in-sample avg dev_std = 0.307)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.527
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.908 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.539
NEC for r=0.9 class 0 = 0.114 +- 0.241 (in-sample avg dev_std = 0.292)
NEC for r=0.9 class 1 = 0.169 +- 0.241 (in-sample avg dev_std = 0.292)
NEC for r=0.9 class 2 = 0.168 +- 0.241 (in-sample avg dev_std = 0.292)
NEC for r=0.9 all KL = 0.153 +- 0.241 (in-sample avg dev_std = 0.292)
NEC for r=0.9 all L1 = 0.154 +- 0.217 (in-sample avg dev_std = 0.292)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.543
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.547
NEC for r=1.0 class 0 = 0.125 +- 0.244 (in-sample avg dev_std = 0.281)
NEC for r=1.0 class 1 = 0.149 +- 0.244 (in-sample avg dev_std = 0.281)
NEC for r=1.0 class 2 = 0.147 +- 0.244 (in-sample avg dev_std = 0.281)
NEC for r=1.0 all KL = 0.143 +- 0.244 (in-sample avg dev_std = 0.281)
NEC for r=1.0 all L1 = 0.142 +- 0.215 (in-sample avg dev_std = 0.281)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.781, 0.867, 0.976, 1.0], 'all_L1': [0.783, 0.835, 0.946, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.773, 0.862, 0.974, 1.0], 'all_L1': [0.784, 0.839, 0.95, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.739, 0.849, 0.974, 1.0], 'all_L1': [0.76, 0.82, 0.949, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.739, 0.891, 0.981, 1.0], 'all_L1': [0.762, 0.863, 0.96, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.742, 0.827, 0.968, 1.0], 'all_L1': [0.774, 0.818, 0.944, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.11, 0.134, 0.143, 0.148], 'all_L1': [0.164, 0.164, 0.161, 0.158]}), defaultdict(<class 'list'>, {'all_KL': [0.15, 0.138, 0.139, 0.145], 'all_L1': [0.187, 0.16, 0.146, 0.147]}), defaultdict(<class 'list'>, {'all_KL': [0.153, 0.165, 0.148, 0.144], 'all_L1': [0.194, 0.183, 0.155, 0.145]}), defaultdict(<class 'list'>, {'all_KL': [0.153, 0.148, 0.132, 0.131], 'all_L1': [0.184, 0.158, 0.133, 0.127]}), defaultdict(<class 'list'>, {'all_KL': [0.134, 0.155, 0.153, 0.143], 'all_L1': [0.173, 0.172, 0.154, 0.142]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.773 +- 0.010, 0.835 +- 0.016, 0.950 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.755 +- 0.018, 0.859 +- 0.021, 0.975 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.429 +- 0.019, 0.514 +- 0.021, 0.547 +- 0.013
nec class all_L1  =  0.180 +- 0.011, 0.167 +- 0.009, 0.150 +- 0.010, 0.144 +- 0.010
nec class all_KL  =  0.140 +- 0.017, 0.148 +- 0.011, 0.143 +- 0.007, 0.142 +- 0.006
nec_acc_int  =  0.424 +- 0.023, 0.504 +- 0.025, 0.545 +- 0.017, 0.557 +- 0.017


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.476 +- 0.005, 0.501 +- 0.005, 0.550 +- 0.003, 0.572 +- 0.005
Faith. Armon (L1)= 		  =  0.292 +- 0.014, 0.279 +- 0.012, 0.259 +- 0.014, 0.251 +- 0.015
Faith. GMean (L1)= 	  =  0.373 +- 0.010, 0.374 +- 0.007, 0.377 +- 0.011, 0.379 +- 0.013
Faith. Aritm (KL)= 		  =  0.447 +- 0.008, 0.504 +- 0.009, 0.559 +- 0.002, 0.571 +- 0.003
Faith. Armon (KL)= 		  =  0.236 +- 0.024, 0.252 +- 0.016, 0.249 +- 0.011, 0.249 +- 0.009
Faith. GMean (KL)= 	  =  0.324 +- 0.018, 0.356 +- 0.012, 0.373 +- 0.009, 0.377 +- 0.008
Computed for split load_split = id



Completed in  0:09:18.628007  for GSATGIN GOODTwitter/length



DONE GSAT GOODTwitter/length all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:09:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/17/2024 12:09:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:03 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:05 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:10:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 83...
[0m[1;37mINFO[0m: [1mCheckpoint 83: 
-----------------------------------
Train ACCURACY: 0.7197
Train Loss: 0.7820
ID Validation ACCURACY: 0.7167
ID Validation Loss: 0.7473
ID Test ACCURACY: 0.7263
ID Test Loss: 0.7804
OOD Validation ACCURACY: 0.4943
OOD Validation Loss: 1.4449
OOD Test ACCURACY: 0.3717
OOD Test Loss: 6.8538

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 52...
[0m[1;37mINFO[0m: [1mCheckpoint 52: 
-----------------------------------
Train ACCURACY: 0.6988
Train Loss: 0.9173
ID Validation ACCURACY: 0.7097
ID Validation Loss: 0.8609
ID Test ACCURACY: 0.7137
ID Test Loss: 0.8967
OOD Validation ACCURACY: 0.6590
OOD Validation Loss: 1.0066
OOD Test ACCURACY: 0.4037
OOD Test Loss: 1.9222

[0m[1;37mINFO[0m: [1mChartInfo 0.7263 0.3717 0.7137 0.4037 0.7097 0.6590[0mGOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.091
WIoU for r=0.3 = 0.050
F1 for r=0.6 = 0.094
WIoU for r=0.6 = 0.050
F1 for r=0.9 = 0.097
WIoU for r=0.9 = 0.052
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.055


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.328
Model XAI F1 of binarized graphs for r=0.3 =  0.0911475
Model XAI WIoU of binarized graphs for r=0.3 =  0.05028375
len(reference) = 777
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.321
SUFF++ for r=0.3 class 0 = 0.762 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 1 = 0.778 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 class 2 = 0.778 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all KL = 0.843 +- 0.206 (in-sample avg dev_std = 0.279)
SUFF++ for r=0.3 all L1 = 0.773 +- 0.095 (in-sample avg dev_std = 0.279)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.339
Model XAI F1 of binarized graphs for r=0.6 =  0.09352124999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.050337500000000014
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.331
SUFF++ for r=0.6 class 0 = 0.731 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 1 = 0.718 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 class 2 = 0.723 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all KL = 0.823 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.6 all L1 = 0.724 +- 0.137 (in-sample avg dev_std = 0.291)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.352
Model XAI F1 of binarized graphs for r=0.9 =  0.09728375
Model XAI WIoU of binarized graphs for r=0.9 =  0.05183375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.347
SUFF++ for r=0.9 class 0 = 0.907 +- 0.036 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 1 = 0.912 +- 0.036 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 class 2 = 0.898 +- 0.036 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all KL = 0.973 +- 0.036 (in-sample avg dev_std = 0.112)
SUFF++ for r=0.9 all L1 = 0.906 +- 0.095 (in-sample avg dev_std = 0.112)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.326
Model XAI F1 of binarized graphs for r=0.3 =  0.0911475
Model XAI WIoU of binarized graphs for r=0.3 =  0.05028375
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.325
NEC for r=0.3 class 0 = 0.134 +- 0.129 (in-sample avg dev_std = 0.101)
NEC for r=0.3 class 1 = 0.131 +- 0.129 (in-sample avg dev_std = 0.101)
NEC for r=0.3 class 2 = 0.132 +- 0.129 (in-sample avg dev_std = 0.101)
NEC for r=0.3 all KL = 0.041 +- 0.129 (in-sample avg dev_std = 0.101)
NEC for r=0.3 all L1 = 0.132 +- 0.110 (in-sample avg dev_std = 0.101)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.339
Model XAI F1 of binarized graphs for r=0.6 =  0.09352124999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.050337500000000014
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.344
NEC for r=0.6 class 0 = 0.214 +- 0.145 (in-sample avg dev_std = 0.152)
NEC for r=0.6 class 1 = 0.224 +- 0.145 (in-sample avg dev_std = 0.152)
NEC for r=0.6 class 2 = 0.212 +- 0.145 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all KL = 0.091 +- 0.145 (in-sample avg dev_std = 0.152)
NEC for r=0.6 all L1 = 0.217 +- 0.137 (in-sample avg dev_std = 0.152)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.352
Model XAI F1 of binarized graphs for r=0.9 =  0.09728375
Model XAI WIoU of binarized graphs for r=0.9 =  0.05183375
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.355
NEC for r=0.9 class 0 = 0.163 +- 0.089 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 1 = 0.165 +- 0.089 (in-sample avg dev_std = 0.156)
NEC for r=0.9 class 2 = 0.165 +- 0.089 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all KL = 0.082 +- 0.089 (in-sample avg dev_std = 0.156)
NEC for r=0.9 all L1 = 0.164 +- 0.152 (in-sample avg dev_std = 0.156)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.377
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.05522875000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.349
NEC for r=1.0 class 0 = 0.191 +- 0.111 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 1 = 0.19 +- 0.111 (in-sample avg dev_std = 0.153)
NEC for r=1.0 class 2 = 0.188 +- 0.111 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all KL = 0.102 +- 0.111 (in-sample avg dev_std = 0.153)
NEC for r=1.0 all L1 = 0.19 +- 0.180 (in-sample avg dev_std = 0.153)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:13:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:07 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:20 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:22 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:13:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 47...
[0m[1;37mINFO[0m: [1mCheckpoint 47: 
-----------------------------------
Train ACCURACY: 0.7800
Train Loss: 0.6829
ID Validation ACCURACY: 0.7807
ID Validation Loss: 0.6494
ID Test ACCURACY: 0.7813
ID Test Loss: 0.6898
OOD Validation ACCURACY: 0.5450
OOD Validation Loss: 1.2229
OOD Test ACCURACY: 0.3953
OOD Test Loss: 2.7475

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.7662
Train Loss: 0.7588
ID Validation ACCURACY: 0.7690
ID Validation Loss: 0.7299
ID Test ACCURACY: 0.7800
ID Test Loss: 0.7629
OOD Validation ACCURACY: 0.5940
OOD Validation Loss: 1.1164
OOD Test ACCURACY: 0.3670
OOD Test Loss: 4.3641

[0m[1;37mINFO[0m: [1mChartInfo 0.7813 0.3953 0.7800 0.3670 0.7690 0.5940[0mGOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.106
WIoU for r=0.3 = 0.058
F1 for r=0.6 = 0.101
WIoU for r=0.6 = 0.054
F1 for r=0.9 = 0.109
WIoU for r=0.9 = 0.058
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.061


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.32
Model XAI F1 of binarized graphs for r=0.3 =  0.10574124999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.05831250000000001
len(reference) = 785
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.313
SUFF++ for r=0.3 class 0 = 0.723 +- 0.199 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.3 class 1 = 0.729 +- 0.199 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.3 class 2 = 0.722 +- 0.199 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.3 all KL = 0.814 +- 0.199 (in-sample avg dev_std = 0.331)
SUFF++ for r=0.3 all L1 = 0.725 +- 0.092 (in-sample avg dev_std = 0.331)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.359
Model XAI F1 of binarized graphs for r=0.6 =  0.10091625
Model XAI WIoU of binarized graphs for r=0.6 =  0.054253749999999996
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.343
SUFF++ for r=0.6 class 0 = 0.743 +- 0.197 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 class 1 = 0.755 +- 0.197 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 class 2 = 0.744 +- 0.197 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all KL = 0.867 +- 0.197 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.6 all L1 = 0.747 +- 0.120 (in-sample avg dev_std = 0.246)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.359
Model XAI F1 of binarized graphs for r=0.9 =  0.10859500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.058023750000000006
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.363
SUFF++ for r=0.9 class 0 = 0.904 +- 0.034 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 1 = 0.915 +- 0.034 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 2 = 0.904 +- 0.034 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all KL = 0.98 +- 0.034 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all L1 = 0.908 +- 0.083 (in-sample avg dev_std = 0.103)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.321
Model XAI F1 of binarized graphs for r=0.3 =  0.10574124999999998
Model XAI WIoU of binarized graphs for r=0.3 =  0.05831250000000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.329
NEC for r=0.3 class 0 = 0.165 +- 0.130 (in-sample avg dev_std = 0.116)
NEC for r=0.3 class 1 = 0.152 +- 0.130 (in-sample avg dev_std = 0.116)
NEC for r=0.3 class 2 = 0.164 +- 0.130 (in-sample avg dev_std = 0.116)
NEC for r=0.3 all KL = 0.053 +- 0.130 (in-sample avg dev_std = 0.116)
NEC for r=0.3 all L1 = 0.16 +- 0.123 (in-sample avg dev_std = 0.116)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.359
Model XAI F1 of binarized graphs for r=0.6 =  0.10091625
Model XAI WIoU of binarized graphs for r=0.6 =  0.054253749999999996
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.339
NEC for r=0.6 class 0 = 0.192 +- 0.073 (in-sample avg dev_std = 0.130)
NEC for r=0.6 class 1 = 0.175 +- 0.073 (in-sample avg dev_std = 0.130)
NEC for r=0.6 class 2 = 0.186 +- 0.073 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all KL = 0.051 +- 0.073 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all L1 = 0.184 +- 0.102 (in-sample avg dev_std = 0.130)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.359
Model XAI F1 of binarized graphs for r=0.9 =  0.10859500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.058023750000000006
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.348
NEC for r=0.9 class 0 = 0.192 +- 0.072 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 1 = 0.197 +- 0.072 (in-sample avg dev_std = 0.151)
NEC for r=0.9 class 2 = 0.194 +- 0.072 (in-sample avg dev_std = 0.151)
NEC for r=0.9 all KL = 0.077 +- 0.072 (in-sample avg dev_std = 0.151)
NEC for r=0.9 all L1 = 0.194 +- 0.123 (in-sample avg dev_std = 0.151)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.399
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.060579999999999995
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.352
NEC for r=1.0 class 0 = 0.197 +- 0.068 (in-sample avg dev_std = 0.140)
NEC for r=1.0 class 1 = 0.21 +- 0.068 (in-sample avg dev_std = 0.140)
NEC for r=1.0 class 2 = 0.209 +- 0.068 (in-sample avg dev_std = 0.140)
NEC for r=1.0 all KL = 0.079 +- 0.068 (in-sample avg dev_std = 0.140)
NEC for r=1.0 all L1 = 0.206 +- 0.141 (in-sample avg dev_std = 0.140)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:16:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:21 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:33 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:35 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:37 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:16:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ACCURACY: 0.7691
Train Loss: 0.7874
ID Validation ACCURACY: 0.7797
ID Validation Loss: 0.7486
ID Test ACCURACY: 0.7787
ID Test Loss: 0.7782
OOD Validation ACCURACY: 0.6203
OOD Validation Loss: 1.0268
OOD Test ACCURACY: 0.3957
OOD Test Loss: 2.4402

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 71...
[0m[1;37mINFO[0m: [1mCheckpoint 71: 
-----------------------------------
Train ACCURACY: 0.7691
Train Loss: 0.7874
ID Validation ACCURACY: 0.7797
ID Validation Loss: 0.7486
ID Test ACCURACY: 0.7787
ID Test Loss: 0.7782
OOD Validation ACCURACY: 0.6203
OOD Validation Loss: 1.0268
OOD Test ACCURACY: 0.3957
OOD Test Loss: 2.4402

[0m[1;37mINFO[0m: [1mChartInfo 0.7787 0.3957 0.7787 0.3957 0.7797 0.6203[0mGOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.163
WIoU for r=0.3 = 0.102
F1 for r=0.6 = 0.147
WIoU for r=0.6 = 0.091
F1 for r=0.9 = 0.116
WIoU for r=0.9 = 0.086
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.086


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.1630475
Model XAI WIoU of binarized graphs for r=0.3 =  0.10161250000000001
len(reference) = 787
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.723 +- 0.227 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 class 1 = 0.701 +- 0.227 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 class 2 = 0.729 +- 0.227 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 all KL = 0.803 +- 0.227 (in-sample avg dev_std = 0.284)
SUFF++ for r=0.3 all L1 = 0.718 +- 0.099 (in-sample avg dev_std = 0.284)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.366
Model XAI F1 of binarized graphs for r=0.6 =  0.14672875000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.0908175
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.39
SUFF++ for r=0.6 class 0 = 0.586 +- 0.243 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1 = 0.564 +- 0.243 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 2 = 0.596 +- 0.243 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.676 +- 0.243 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.582 +- 0.125 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.347
Model XAI F1 of binarized graphs for r=0.9 =  0.11618
Model XAI WIoU of binarized graphs for r=0.9 =  0.08619
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.373
SUFF++ for r=0.9 class 0 = 0.7 +- 0.219 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 class 1 = 0.672 +- 0.219 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 class 2 = 0.698 +- 0.219 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 all KL = 0.785 +- 0.219 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.9 all L1 = 0.69 +- 0.185 (in-sample avg dev_std = 0.384)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.343
Model XAI F1 of binarized graphs for r=0.3 =  0.1630475
Model XAI WIoU of binarized graphs for r=0.3 =  0.10161250000000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.321
NEC for r=0.3 class 0 = 0.216 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 1 = 0.215 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 2 = 0.208 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all KL = 0.084 +- 0.120 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all L1 = 0.213 +- 0.132 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.366
Model XAI F1 of binarized graphs for r=0.6 =  0.14672875000000002
Model XAI WIoU of binarized graphs for r=0.6 =  0.0908175
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.362
NEC for r=0.6 class 0 = 0.332 +- 0.177 (in-sample avg dev_std = 0.229)
NEC for r=0.6 class 1 = 0.369 +- 0.177 (in-sample avg dev_std = 0.229)
NEC for r=0.6 class 2 = 0.333 +- 0.177 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all KL = 0.208 +- 0.177 (in-sample avg dev_std = 0.229)
NEC for r=0.6 all L1 = 0.345 +- 0.177 (in-sample avg dev_std = 0.229)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.347
Model XAI F1 of binarized graphs for r=0.9 =  0.11618
Model XAI WIoU of binarized graphs for r=0.9 =  0.08619
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.396
NEC for r=0.9 class 0 = 0.332 +- 0.148 (in-sample avg dev_std = 0.254)
NEC for r=0.9 class 1 = 0.374 +- 0.148 (in-sample avg dev_std = 0.254)
NEC for r=0.9 class 2 = 0.337 +- 0.148 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all KL = 0.189 +- 0.148 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all L1 = 0.348 +- 0.140 (in-sample avg dev_std = 0.254)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.394
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.08624499999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.396
NEC for r=1.0 class 0 = 0.295 +- 0.194 (in-sample avg dev_std = 0.240)
NEC for r=1.0 class 1 = 0.386 +- 0.194 (in-sample avg dev_std = 0.240)
NEC for r=1.0 class 2 = 0.309 +- 0.194 (in-sample avg dev_std = 0.240)
NEC for r=1.0 all KL = 0.192 +- 0.194 (in-sample avg dev_std = 0.240)
NEC for r=1.0 all L1 = 0.33 +- 0.177 (in-sample avg dev_std = 0.240)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:19:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/17/2024 12:19:46 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:19:58 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:00 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:20:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 28...
[0m[1;37mINFO[0m: [1mCheckpoint 28: 
-----------------------------------
Train ACCURACY: 0.7937
Train Loss: 0.7235
ID Validation ACCURACY: 0.7980
ID Validation Loss: 0.6911
ID Test ACCURACY: 0.8007
ID Test Loss: 0.7069
OOD Validation ACCURACY: 0.5993
OOD Validation Loss: 0.9847
OOD Test ACCURACY: 0.3377
OOD Test Loss: 1.5111

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ACCURACY: 0.6588
Train Loss: 1.0386
ID Validation ACCURACY: 0.6667
ID Validation Loss: 1.0173
ID Test ACCURACY: 0.6580
ID Test Loss: 1.0129
OOD Validation ACCURACY: 0.6160
OOD Validation Loss: 1.5710
OOD Test ACCURACY: 0.4370
OOD Test Loss: 2.5924

[0m[1;37mINFO[0m: [1mChartInfo 0.8007 0.3377 0.6580 0.4370 0.6667 0.6160[0mGOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.126
WIoU for r=0.3 = 0.070
F1 for r=0.6 = 0.122
WIoU for r=0.6 = 0.068
F1 for r=0.9 = 0.115
WIoU for r=0.9 = 0.066
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.067


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.317
Model XAI F1 of binarized graphs for r=0.3 =  0.12581375
Model XAI WIoU of binarized graphs for r=0.3 =  0.07045375000000001
len(reference) = 789
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.32
SUFF++ for r=0.3 class 0 = 0.779 +- 0.093 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.3 class 1 = 0.783 +- 0.093 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.3 class 2 = 0.787 +- 0.093 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.3 all KL = 0.906 +- 0.093 (in-sample avg dev_std = 0.234)
SUFF++ for r=0.3 all L1 = 0.783 +- 0.070 (in-sample avg dev_std = 0.234)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.32
Model XAI F1 of binarized graphs for r=0.6 =  0.12154375
Model XAI WIoU of binarized graphs for r=0.6 =  0.06769875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.337
SUFF++ for r=0.6 class 0 = 0.805 +- 0.089 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 1 = 0.795 +- 0.089 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 class 2 = 0.816 +- 0.089 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all KL = 0.93 +- 0.089 (in-sample avg dev_std = 0.184)
SUFF++ for r=0.6 all L1 = 0.805 +- 0.098 (in-sample avg dev_std = 0.184)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.343
Model XAI F1 of binarized graphs for r=0.9 =  0.11472500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.06619125000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.338
SUFF++ for r=0.9 class 0 = 0.889 +- 0.031 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.031 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 class 2 = 0.89 +- 0.031 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all KL = 0.978 +- 0.031 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.9 all L1 = 0.889 +- 0.081 (in-sample avg dev_std = 0.113)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.319
Model XAI F1 of binarized graphs for r=0.3 =  0.12581375
Model XAI WIoU of binarized graphs for r=0.3 =  0.07045375000000001
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.315
NEC for r=0.3 class 0 = 0.146 +- 0.060 (in-sample avg dev_std = 0.090)
NEC for r=0.3 class 1 = 0.143 +- 0.060 (in-sample avg dev_std = 0.090)
NEC for r=0.3 class 2 = 0.136 +- 0.060 (in-sample avg dev_std = 0.090)
NEC for r=0.3 all KL = 0.037 +- 0.060 (in-sample avg dev_std = 0.090)
NEC for r=0.3 all L1 = 0.142 +- 0.100 (in-sample avg dev_std = 0.090)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.32
Model XAI F1 of binarized graphs for r=0.6 =  0.12154375
Model XAI WIoU of binarized graphs for r=0.6 =  0.06769875
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.318
NEC for r=0.6 class 0 = 0.181 +- 0.108 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 1 = 0.182 +- 0.108 (in-sample avg dev_std = 0.117)
NEC for r=0.6 class 2 = 0.185 +- 0.108 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all KL = 0.069 +- 0.108 (in-sample avg dev_std = 0.117)
NEC for r=0.6 all L1 = 0.183 +- 0.136 (in-sample avg dev_std = 0.117)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.343
Model XAI F1 of binarized graphs for r=0.9 =  0.11472500000000001
Model XAI WIoU of binarized graphs for r=0.9 =  0.06619125000000001
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.361
NEC for r=0.9 class 0 = 0.203 +- 0.057 (in-sample avg dev_std = 0.125)
NEC for r=0.9 class 1 = 0.205 +- 0.057 (in-sample avg dev_std = 0.125)
NEC for r=0.9 class 2 = 0.209 +- 0.057 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all KL = 0.057 +- 0.057 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all L1 = 0.205 +- 0.096 (in-sample avg dev_std = 0.125)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.329
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06707
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.356
NEC for r=1.0 class 0 = 0.245 +- 0.097 (in-sample avg dev_std = 0.128)
NEC for r=1.0 class 1 = 0.241 +- 0.097 (in-sample avg dev_std = 0.128)
NEC for r=1.0 class 2 = 0.261 +- 0.097 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all KL = 0.103 +- 0.097 (in-sample avg dev_std = 0.128)
NEC for r=1.0 all L1 = 0.249 +- 0.116 (in-sample avg dev_std = 0.128)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:23:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:16 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:18 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:20 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:23:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ACCURACY: 0.7828
Train Loss: 0.7860
ID Validation ACCURACY: 0.7877
ID Validation Loss: 0.7713
ID Test ACCURACY: 0.7937
ID Test Loss: 0.7787
OOD Validation ACCURACY: 0.4320
OOD Validation Loss: 1.0457
OOD Test ACCURACY: 0.3123
OOD Test Loss: 2.1943

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ACCURACY: 0.7738
Train Loss: 0.6598
ID Validation ACCURACY: 0.7807
ID Validation Loss: 0.6297
ID Test ACCURACY: 0.7767
ID Test Loss: 0.6571
OOD Validation ACCURACY: 0.6107
OOD Validation Loss: 0.9966
OOD Test ACCURACY: 0.3437
OOD Test Loss: 2.6551

[0m[1;37mINFO[0m: [1mChartInfo 0.7937 0.3123 0.7767 0.3437 0.7807 0.6107[0mGOODMotif(3000)
Data example from test: Data(edge_index=[2, 462], x=[149, 1], node_gt=[149], edge_gt=[462], y=[1], env_id=[1], ori_edge_index=[2, 462], node_perm=[149], num_nodes=149)
Label distribution from test: (tensor([0, 1, 2]), tensor([1019, 1029,  952]))

Gold ratio (test) =  tensor(0.0605) +- tensor(0.0246)
F1 for r=0.3 = 0.106
WIoU for r=0.3 = 0.058
F1 for r=0.6 = 0.105
WIoU for r=0.6 = 0.057
F1 for r=0.9 = 0.111
WIoU for r=0.9 = 0.059
F1 for r=1.0 = 0.113
WIoU for r=1.0 = 0.061


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.328
Model XAI F1 of binarized graphs for r=0.3 =  0.1058825
Model XAI WIoU of binarized graphs for r=0.3 =  0.058301250000000006
len(reference) = 781
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.329
SUFF++ for r=0.3 class 0 = 0.836 +- 0.051 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 1 = 0.837 +- 0.051 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 class 2 = 0.837 +- 0.051 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all KL = 0.954 +- 0.051 (in-sample avg dev_std = 0.176)
SUFF++ for r=0.3 all L1 = 0.837 +- 0.063 (in-sample avg dev_std = 0.176)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.324
Model XAI F1 of binarized graphs for r=0.6 =  0.105155
Model XAI WIoU of binarized graphs for r=0.6 =  0.05668
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.33
SUFF++ for r=0.6 class 0 = 0.857 +- 0.070 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 1 = 0.865 +- 0.070 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 class 2 = 0.861 +- 0.070 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all KL = 0.965 +- 0.070 (in-sample avg dev_std = 0.136)
SUFF++ for r=0.6 all L1 = 0.861 +- 0.082 (in-sample avg dev_std = 0.136)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.325
Model XAI F1 of binarized graphs for r=0.9 =  0.11056875
Model XAI WIoU of binarized graphs for r=0.9 =  0.059175000000000005
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.329
SUFF++ for r=0.9 class 0 = 0.942 +- 0.010 (in-sample avg dev_std = 0.049)
SUFF++ for r=0.9 class 1 = 0.938 +- 0.010 (in-sample avg dev_std = 0.049)
SUFF++ for r=0.9 class 2 = 0.938 +- 0.010 (in-sample avg dev_std = 0.049)
SUFF++ for r=0.9 all KL = 0.994 +- 0.010 (in-sample avg dev_std = 0.049)
SUFF++ for r=0.9 all L1 = 0.94 +- 0.038 (in-sample avg dev_std = 0.049)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.327
Model XAI F1 of binarized graphs for r=0.3 =  0.1058825
Model XAI WIoU of binarized graphs for r=0.3 =  0.058301250000000006
len(reference) = 800
Effective ratio: 0.303 +- 0.002
Model Accuracy over intervened graphs for r=0.3 =  0.326
NEC for r=0.3 class 0 = 0.1 +- 0.042 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 1 = 0.092 +- 0.042 (in-sample avg dev_std = 0.060)
NEC for r=0.3 class 2 = 0.092 +- 0.042 (in-sample avg dev_std = 0.060)
NEC for r=0.3 all KL = 0.017 +- 0.042 (in-sample avg dev_std = 0.060)
NEC for r=0.3 all L1 = 0.095 +- 0.077 (in-sample avg dev_std = 0.060)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.324
Model XAI F1 of binarized graphs for r=0.6 =  0.105155
Model XAI WIoU of binarized graphs for r=0.6 =  0.05668
len(reference) = 800
Effective ratio: 0.602 +- 0.002
Model Accuracy over intervened graphs for r=0.6 =  0.325
NEC for r=0.6 class 0 = 0.102 +- 0.019 (in-sample avg dev_std = 0.061)
NEC for r=0.6 class 1 = 0.102 +- 0.019 (in-sample avg dev_std = 0.061)
NEC for r=0.6 class 2 = 0.098 +- 0.019 (in-sample avg dev_std = 0.061)
NEC for r=0.6 all KL = 0.013 +- 0.019 (in-sample avg dev_std = 0.061)
NEC for r=0.6 all L1 = 0.101 +- 0.060 (in-sample avg dev_std = 0.061)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.325
Model XAI F1 of binarized graphs for r=0.9 =  0.11056875
Model XAI WIoU of binarized graphs for r=0.9 =  0.059175000000000005
len(reference) = 800
Effective ratio: 0.902 +- 0.002
Model Accuracy over intervened graphs for r=0.9 =  0.34
NEC for r=0.9 class 0 = 0.188 +- 0.031 (in-sample avg dev_std = 0.080)
NEC for r=0.9 class 1 = 0.191 +- 0.031 (in-sample avg dev_std = 0.080)
NEC for r=0.9 class 2 = 0.193 +- 0.031 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all KL = 0.045 +- 0.031 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all L1 = 0.19 +- 0.060 (in-sample avg dev_std = 0.080)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.311
Model XAI F1 of binarized graphs for r=1.0 =  0.11317499999999998
Model XAI WIoU of binarized graphs for r=1.0 =  0.06105625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.347
NEC for r=1.0 class 0 = 0.163 +- 0.025 (in-sample avg dev_std = 0.068)
NEC for r=1.0 class 1 = 0.164 +- 0.025 (in-sample avg dev_std = 0.068)
NEC for r=1.0 class 2 = 0.17 +- 0.025 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all KL = 0.046 +- 0.025 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all L1 = 0.165 +- 0.075 (in-sample avg dev_std = 0.068)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.843, 0.823, 0.973, 1.0], 'all_L1': [0.773, 0.724, 0.906, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.814, 0.867, 0.98, 1.0], 'all_L1': [0.725, 0.747, 0.908, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.803, 0.676, 0.785, 1.0], 'all_L1': [0.718, 0.582, 0.69, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.906, 0.93, 0.978, 1.0], 'all_L1': [0.783, 0.805, 0.889, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.954, 0.965, 0.994, 1.0], 'all_L1': [0.837, 0.861, 0.94, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.041, 0.091, 0.082, 0.102], 'all_L1': [0.132, 0.217, 0.164, 0.19]}), defaultdict(<class 'list'>, {'all_KL': [0.053, 0.051, 0.077, 0.079], 'all_L1': [0.16, 0.184, 0.194, 0.206]}), defaultdict(<class 'list'>, {'all_KL': [0.084, 0.208, 0.189, 0.192], 'all_L1': [0.213, 0.345, 0.348, 0.33]}), defaultdict(<class 'list'>, {'all_KL': [0.037, 0.069, 0.057, 0.103], 'all_L1': [0.142, 0.183, 0.205, 0.249]}), defaultdict(<class 'list'>, {'all_KL': [0.017, 0.013, 0.045, 0.046], 'all_L1': [0.095, 0.101, 0.19, 0.165]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.767 +- 0.043, 0.744 +- 0.094, 0.867 +- 0.090, 1.000 +- 0.000
suff++ class all_KL  =  0.864 +- 0.057, 0.852 +- 0.101, 0.942 +- 0.079, 1.000 +- 0.000
suff++_acc_int  =  0.325 +- 0.010, 0.346 +- 0.022, 0.350 +- 0.016
nec class all_L1  =  0.148 +- 0.039, 0.206 +- 0.079, 0.220 +- 0.065, 0.228 +- 0.058
nec class all_KL  =  0.046 +- 0.022, 0.086 +- 0.066, 0.090 +- 0.051, 0.104 +- 0.048
nec_acc_int  =  0.323 +- 0.005, 0.338 +- 0.015, 0.360 +- 0.019, 0.360 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.458 +- 0.009, 0.475 +- 0.011, 0.543 +- 0.016, 0.614 +- 0.029
Faith. Armon (L1)= 		  =  0.245 +- 0.051, 0.308 +- 0.081, 0.342 +- 0.063, 0.368 +- 0.074
Faith. GMean (L1)= 	  =  0.333 +- 0.035, 0.379 +- 0.049, 0.429 +- 0.034, 0.474 +- 0.059
Faith. Aritm (KL)= 		  =  0.455 +- 0.020, 0.469 +- 0.021, 0.516 +- 0.015, 0.552 +- 0.024
Faith. Armon (KL)= 		  =  0.087 +- 0.039, 0.146 +- 0.097, 0.159 +- 0.077, 0.186 +- 0.077
Faith. GMean (KL)= 	  =  0.193 +- 0.043, 0.245 +- 0.086, 0.278 +- 0.059, 0.315 +- 0.073
Computed for split load_split = id



Completed in  0:16:32.051214  for GSATGIN GOODMotif/size



DONE GSAT GOODMotif/size all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:26:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:33 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:36 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:41 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:44 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:26:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.8554
Train Loss: 0.4338
ID Validation ROC-AUC: 0.8168
ID Validation Loss: 0.4661
ID Test ROC-AUC: 0.8029
ID Test Loss: 0.4748
OOD Validation ROC-AUC: 0.7182
OOD Validation Loss: 0.7766
OOD Test ROC-AUC: 0.6901
OOD Test Loss: 0.4975

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.8166
Train Loss: 0.1397
ID Validation ROC-AUC: 0.7736
ID Validation Loss: 0.1728
ID Test ROC-AUC: 0.7581
ID Test Loss: 0.1493
OOD Validation ROC-AUC: 0.7639
OOD Validation Loss: 0.1526
OOD Test ROC-AUC: 0.6632
OOD Test Loss: 0.1138

[0m[1;37mINFO[0m: [1mChartInfo 0.8029 0.6901 0.7581 0.6632 0.7736 0.7639[0mGOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/17/2024 12:26:48 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.535
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 161
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.547
SUFF++ for r=0.3 class 0.0 = 0.561 +- 0.328 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.3 class 1.0 = 0.605 +- 0.328 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.3 all KL = 0.357 +- 0.328 (in-sample avg dev_std = 0.697)
SUFF++ for r=0.3 all L1 = 0.583 +- 0.226 (in-sample avg dev_std = 0.697)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.6
SUFF++ for r=0.6 class 0.0 = 0.541 +- 0.300 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.6 class 1.0 = 0.626 +- 0.300 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.6 all KL = 0.526 +- 0.300 (in-sample avg dev_std = 0.545)
SUFF++ for r=0.6 all L1 = 0.584 +- 0.227 (in-sample avg dev_std = 0.545)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.638
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.607
SUFF++ for r=0.9 class 0.0 = 0.73 +- 0.195 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.9 class 1.0 = 0.772 +- 0.195 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.9 all KL = 0.816 +- 0.195 (in-sample avg dev_std = 0.361)
SUFF++ for r=0.9 all L1 = 0.751 +- 0.188 (in-sample avg dev_std = 0.361)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.532
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.549
NEC for r=0.3 class 0.0 = 0.404 +- 0.368 (in-sample avg dev_std = 0.603)
NEC for r=0.3 class 1.0 = 0.324 +- 0.368 (in-sample avg dev_std = 0.603)
NEC for r=0.3 all KL = 0.525 +- 0.368 (in-sample avg dev_std = 0.603)
NEC for r=0.3 all L1 = 0.364 +- 0.268 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.645
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.589
NEC for r=0.6 class 0.0 = 0.468 +- 0.297 (in-sample avg dev_std = 0.563)
NEC for r=0.6 class 1.0 = 0.402 +- 0.297 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all KL = 0.493 +- 0.297 (in-sample avg dev_std = 0.563)
NEC for r=0.6 all L1 = 0.435 +- 0.226 (in-sample avg dev_std = 0.563)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.638
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.611
NEC for r=0.9 class 0.0 = 0.412 +- 0.245 (in-sample avg dev_std = 0.446)
NEC for r=0.9 class 1.0 = 0.331 +- 0.245 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all KL = 0.327 +- 0.245 (in-sample avg dev_std = 0.446)
NEC for r=0.9 all L1 = 0.372 +- 0.187 (in-sample avg dev_std = 0.446)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.644
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.599
NEC for r=1.0 class 0.0 = 0.422 +- 0.229 (in-sample avg dev_std = 0.441)
NEC for r=1.0 class 1.0 = 0.34 +- 0.229 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all KL = 0.328 +- 0.229 (in-sample avg dev_std = 0.441)
NEC for r=1.0 all L1 = 0.381 +- 0.193 (in-sample avg dev_std = 0.441)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:27:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:06 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:09 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:12 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ROC-AUC: 0.8823
Train Loss: 0.1330
ID Validation ROC-AUC: 0.8155
ID Validation Loss: 0.1790
ID Test ROC-AUC: 0.8073
ID Test Loss: 0.1630
OOD Validation ROC-AUC: 0.7386
OOD Validation Loss: 0.2770
OOD Test ROC-AUC: 0.6827
OOD Test Loss: 0.1716

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.8034
Train Loss: 0.1680
ID Validation ROC-AUC: 0.7835
ID Validation Loss: 0.1884
ID Test ROC-AUC: 0.7716
ID Test Loss: 0.1649
OOD Validation ROC-AUC: 0.7634
OOD Validation Loss: 0.2424
OOD Test ROC-AUC: 0.6550
OOD Test Loss: 0.1592

[0m[1;37mINFO[0m: [1mChartInfo 0.8073 0.6827 0.7716 0.6550 0.7835 0.7634[0mGOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/17/2024 12:27:15 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.553
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 154
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.542
SUFF++ for r=0.3 class 0.0 = 0.593 +- 0.312 (in-sample avg dev_std = 0.719)
SUFF++ for r=0.3 class 1.0 = 0.658 +- 0.312 (in-sample avg dev_std = 0.719)
SUFF++ for r=0.3 all KL = 0.354 +- 0.312 (in-sample avg dev_std = 0.719)
SUFF++ for r=0.3 all L1 = 0.625 +- 0.211 (in-sample avg dev_std = 0.719)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.526
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.536
SUFF++ for r=0.6 class 0.0 = 0.618 +- 0.341 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.6 class 1.0 = 0.606 +- 0.341 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.6 all KL = 0.534 +- 0.341 (in-sample avg dev_std = 0.560)
SUFF++ for r=0.6 all L1 = 0.612 +- 0.250 (in-sample avg dev_std = 0.560)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.592
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.599
SUFF++ for r=0.9 class 0.0 = 0.952 +- 0.206 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 class 1.0 = 0.916 +- 0.206 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all KL = 0.913 +- 0.206 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.9 all L1 = 0.934 +- 0.135 (in-sample avg dev_std = 0.228)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.561
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.538
NEC for r=0.3 class 0.0 = 0.279 +- 0.387 (in-sample avg dev_std = 0.497)
NEC for r=0.3 class 1.0 = 0.201 +- 0.387 (in-sample avg dev_std = 0.497)
NEC for r=0.3 all KL = 0.357 +- 0.387 (in-sample avg dev_std = 0.497)
NEC for r=0.3 all L1 = 0.24 +- 0.268 (in-sample avg dev_std = 0.497)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.526
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.507
NEC for r=0.6 class 0.0 = 0.394 +- 0.297 (in-sample avg dev_std = 0.571)
NEC for r=0.6 class 1.0 = 0.412 +- 0.297 (in-sample avg dev_std = 0.571)
NEC for r=0.6 all KL = 0.511 +- 0.297 (in-sample avg dev_std = 0.571)
NEC for r=0.6 all L1 = 0.403 +- 0.228 (in-sample avg dev_std = 0.571)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.592
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.548
NEC for r=0.9 class 0.0 = 0.054 +- 0.190 (in-sample avg dev_std = 0.214)
NEC for r=0.9 class 1.0 = 0.072 +- 0.190 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all KL = 0.088 +- 0.190 (in-sample avg dev_std = 0.214)
NEC for r=0.9 all L1 = 0.063 +- 0.118 (in-sample avg dev_std = 0.214)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.606
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.599
NEC for r=1.0 class 0.0 = 0.026 +- 0.134 (in-sample avg dev_std = 0.145)
NEC for r=1.0 class 1.0 = 0.054 +- 0.134 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all KL = 0.044 +- 0.134 (in-sample avg dev_std = 0.145)
NEC for r=1.0 all L1 = 0.04 +- 0.096 (in-sample avg dev_std = 0.145)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:27:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:29 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:32 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:35 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:39 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.8896
Train Loss: 0.1635
ID Validation ROC-AUC: 0.8154
ID Validation Loss: 0.2174
ID Test ROC-AUC: 0.7951
ID Test Loss: 0.2075
OOD Validation ROC-AUC: 0.7496
OOD Validation Loss: 0.3360
OOD Test ROC-AUC: 0.6662
OOD Test Loss: 0.2099

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 22...
[0m[1;37mINFO[0m: [1mCheckpoint 22: 
-----------------------------------
Train ROC-AUC: 0.7948
Train Loss: 0.1687
ID Validation ROC-AUC: 0.7578
ID Validation Loss: 0.1964
ID Test ROC-AUC: 0.7533
ID Test Loss: 0.1648
OOD Validation ROC-AUC: 0.7704
OOD Validation Loss: 0.2321
OOD Test ROC-AUC: 0.6840
OOD Test Loss: 0.1430

[0m[1;37mINFO[0m: [1mChartInfo 0.7951 0.6662 0.7533 0.6840 0.7578 0.7704[0mGOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/17/2024 12:27:42 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.538
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 159
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.531
SUFF++ for r=0.3 class 0.0 = 0.555 +- 0.276 (in-sample avg dev_std = 0.766)
SUFF++ for r=0.3 class 1.0 = 0.58 +- 0.276 (in-sample avg dev_std = 0.766)
SUFF++ for r=0.3 all KL = 0.228 +- 0.276 (in-sample avg dev_std = 0.766)
SUFF++ for r=0.3 all L1 = 0.567 +- 0.222 (in-sample avg dev_std = 0.766)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.582
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.584
SUFF++ for r=0.6 class 0.0 = 0.773 +- 0.389 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 class 1.0 = 0.684 +- 0.389 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all KL = 0.554 +- 0.389 (in-sample avg dev_std = 0.518)
SUFF++ for r=0.6 all L1 = 0.728 +- 0.270 (in-sample avg dev_std = 0.518)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.61
SUFF++ for r=0.9 class 0.0 = 0.944 +- 0.207 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 class 1.0 = 0.889 +- 0.207 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all KL = 0.897 +- 0.207 (in-sample avg dev_std = 0.251)
SUFF++ for r=0.9 all L1 = 0.916 +- 0.157 (in-sample avg dev_std = 0.251)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.536
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.561
NEC for r=0.3 class 0.0 = 0.311 +- 0.396 (in-sample avg dev_std = 0.620)
NEC for r=0.3 class 1.0 = 0.312 +- 0.396 (in-sample avg dev_std = 0.620)
NEC for r=0.3 all KL = 0.527 +- 0.396 (in-sample avg dev_std = 0.620)
NEC for r=0.3 all L1 = 0.312 +- 0.276 (in-sample avg dev_std = 0.620)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.582
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.574
NEC for r=0.6 class 0.0 = 0.257 +- 0.388 (in-sample avg dev_std = 0.578)
NEC for r=0.6 class 1.0 = 0.33 +- 0.388 (in-sample avg dev_std = 0.578)
NEC for r=0.6 all KL = 0.471 +- 0.388 (in-sample avg dev_std = 0.578)
NEC for r=0.6 all L1 = 0.293 +- 0.263 (in-sample avg dev_std = 0.578)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.608
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.621
NEC for r=0.9 class 0.0 = 0.091 +- 0.249 (in-sample avg dev_std = 0.279)
NEC for r=0.9 class 1.0 = 0.113 +- 0.249 (in-sample avg dev_std = 0.279)
NEC for r=0.9 all KL = 0.147 +- 0.249 (in-sample avg dev_std = 0.279)
NEC for r=0.9 all L1 = 0.102 +- 0.172 (in-sample avg dev_std = 0.279)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.654
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.612
NEC for r=1.0 class 0.0 = 0.035 +- 0.176 (in-sample avg dev_std = 0.220)
NEC for r=1.0 class 1.0 = 0.095 +- 0.176 (in-sample avg dev_std = 0.220)
NEC for r=1.0 all KL = 0.081 +- 0.176 (in-sample avg dev_std = 0.220)
NEC for r=1.0 all L1 = 0.065 +- 0.131 (in-sample avg dev_std = 0.220)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:27:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:56 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:27:59 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ROC-AUC: 0.8629
Train Loss: 0.3601
ID Validation ROC-AUC: 0.8071
ID Validation Loss: 0.3906
ID Test ROC-AUC: 0.8014
ID Test Loss: 0.3869
OOD Validation ROC-AUC: 0.7294
OOD Validation Loss: 0.6233
OOD Test ROC-AUC: 0.6772
OOD Test Loss: 0.4237

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 33...
[0m[1;37mINFO[0m: [1mCheckpoint 33: 
-----------------------------------
Train ROC-AUC: 0.8228
Train Loss: 0.1441
ID Validation ROC-AUC: 0.8016
ID Validation Loss: 0.1667
ID Test ROC-AUC: 0.7843
ID Test Loss: 0.1413
OOD Validation ROC-AUC: 0.7586
OOD Validation Loss: 0.1918
OOD Test ROC-AUC: 0.6593
OOD Test Loss: 0.1299

[0m[1;37mINFO[0m: [1mChartInfo 0.8014 0.6772 0.7843 0.6593 0.8016 0.7586[0mGOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/17/2024 12:28:09 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.542
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 160
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.476
SUFF++ for r=0.3 class 0.0 = 0.747 +- 0.351 (in-sample avg dev_std = 0.572)
SUFF++ for r=0.3 class 1.0 = 0.742 +- 0.351 (in-sample avg dev_std = 0.572)
SUFF++ for r=0.3 all KL = 0.501 +- 0.351 (in-sample avg dev_std = 0.572)
SUFF++ for r=0.3 all L1 = 0.745 +- 0.211 (in-sample avg dev_std = 0.572)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.589
SUFF++ for r=0.6 class 0.0 = 0.538 +- 0.289 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 1.0 = 0.665 +- 0.289 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all KL = 0.493 +- 0.289 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all L1 = 0.601 +- 0.225 (in-sample avg dev_std = 0.577)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.645
SUFF++ for r=0.9 class 0.0 = 0.764 +- 0.185 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 class 1.0 = 0.819 +- 0.185 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all KL = 0.845 +- 0.185 (in-sample avg dev_std = 0.338)
SUFF++ for r=0.9 all L1 = 0.792 +- 0.177 (in-sample avg dev_std = 0.338)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.542
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.51
NEC for r=0.3 class 0.0 = 0.195 +- 0.354 (in-sample avg dev_std = 0.439)
NEC for r=0.3 class 1.0 = 0.188 +- 0.354 (in-sample avg dev_std = 0.439)
NEC for r=0.3 all KL = 0.317 +- 0.354 (in-sample avg dev_std = 0.439)
NEC for r=0.3 all L1 = 0.192 +- 0.231 (in-sample avg dev_std = 0.439)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.583
NEC for r=0.6 class 0.0 = 0.441 +- 0.316 (in-sample avg dev_std = 0.573)
NEC for r=0.6 class 1.0 = 0.34 +- 0.316 (in-sample avg dev_std = 0.573)
NEC for r=0.6 all KL = 0.477 +- 0.316 (in-sample avg dev_std = 0.573)
NEC for r=0.6 all L1 = 0.39 +- 0.238 (in-sample avg dev_std = 0.573)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.594
NEC for r=0.9 class 0.0 = 0.358 +- 0.264 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1.0 = 0.316 +- 0.264 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.306 +- 0.264 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.337 +- 0.205 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.66
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.594
NEC for r=1.0 class 0.0 = 0.354 +- 0.241 (in-sample avg dev_std = 0.419)
NEC for r=1.0 class 1.0 = 0.297 +- 0.241 (in-sample avg dev_std = 0.419)
NEC for r=1.0 all KL = 0.279 +- 0.241 (in-sample avg dev_std = 0.419)
NEC for r=1.0 all L1 = 0.326 +- 0.194 (in-sample avg dev_std = 0.419)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Fri May 17 12:28:22 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:26 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:29 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:33 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: hard
[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ROC-AUC: 0.8839
Train Loss: 0.1354
ID Validation ROC-AUC: 0.8150
ID Validation Loss: 0.1913
ID Test ROC-AUC: 0.8209
ID Test Loss: 0.1571
OOD Validation ROC-AUC: 0.7443
OOD Validation Loss: 0.2553
OOD Test ROC-AUC: 0.6590
OOD Test Loss: 0.1739

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ROC-AUC: 0.8156
Train Loss: 0.1601
ID Validation ROC-AUC: 0.7807
ID Validation Loss: 0.1914
ID Test ROC-AUC: 0.7745
ID Test Loss: 0.1596
OOD Validation ROC-AUC: 0.7633
OOD Validation Loss: 0.1988
OOD Test ROC-AUC: 0.6787
OOD Test Loss: 0.1375

[0m[1;37mINFO[0m: [1mChartInfo 0.8209 0.6590 0.7745 0.6787 0.7807 0.7633[0mGOODHIV(4108)
Data example from test: Data(x=[19, 9], edge_index=[2, 40], edge_attr=[40, 3], y=[1, 1], smiles='Nc1ccc2nc3ccc(O)cc3nc2c1.[Na]S[Na]', idx=[1], scaffold='c1ccc2nc3ccccc3nc2c1', domain_id=[1], ori_edge_index=[2, 40], node_perm=[19])
Label distribution from test: (tensor([0., 1.]), tensor([4027,   81]))
[1;34mDEBUG[0m: 05/17/2024 12:28:35 PM : [1mUnbalanced warning for GOODHIV (test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([81, 81]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.509
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 151
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0.0 = 0.649 +- 0.354 (in-sample avg dev_std = 0.717)
SUFF++ for r=0.3 class 1.0 = 0.664 +- 0.354 (in-sample avg dev_std = 0.717)
SUFF++ for r=0.3 all KL = 0.356 +- 0.354 (in-sample avg dev_std = 0.717)
SUFF++ for r=0.3 all L1 = 0.656 +- 0.225 (in-sample avg dev_std = 0.717)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.559
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.601
SUFF++ for r=0.6 class 0.0 = 0.592 +- 0.335 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.6 class 1.0 = 0.624 +- 0.335 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.6 all KL = 0.497 +- 0.335 (in-sample avg dev_std = 0.589)
SUFF++ for r=0.6 all L1 = 0.608 +- 0.246 (in-sample avg dev_std = 0.589)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.642
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.64
SUFF++ for r=0.9 class 0.0 = 0.923 +- 0.250 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 1.0 = 0.848 +- 0.250 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all KL = 0.857 +- 0.250 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.195 (in-sample avg dev_std = 0.288)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.516
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 162
Effective ratio: 0.311 +- 0.010
Model ROC-AUC over intervened graphs for r=0.3 =  0.494
NEC for r=0.3 class 0.0 = 0.142 +- 0.333 (in-sample avg dev_std = 0.387)
NEC for r=0.3 class 1.0 = 0.157 +- 0.333 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all KL = 0.231 +- 0.333 (in-sample avg dev_std = 0.387)
NEC for r=0.3 all L1 = 0.15 +- 0.229 (in-sample avg dev_std = 0.387)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.559
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 162
Effective ratio: 0.611 +- 0.009
Model ROC-AUC over intervened graphs for r=0.6 =  0.554
NEC for r=0.6 class 0.0 = 0.394 +- 0.316 (in-sample avg dev_std = 0.597)
NEC for r=0.6 class 1.0 = 0.369 +- 0.316 (in-sample avg dev_std = 0.597)
NEC for r=0.6 all KL = 0.499 +- 0.316 (in-sample avg dev_std = 0.597)
NEC for r=0.6 all L1 = 0.381 +- 0.225 (in-sample avg dev_std = 0.597)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.642
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 162
Effective ratio: 0.909 +- 0.008
Model ROC-AUC over intervened graphs for r=0.9 =  0.598
NEC for r=0.9 class 0.0 = 0.111 +- 0.271 (in-sample avg dev_std = 0.299)
NEC for r=0.9 class 1.0 = 0.154 +- 0.271 (in-sample avg dev_std = 0.299)
NEC for r=0.9 all KL = 0.17 +- 0.271 (in-sample avg dev_std = 0.299)
NEC for r=0.9 all L1 = 0.133 +- 0.210 (in-sample avg dev_std = 0.299)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.652
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 162
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.606
NEC for r=1.0 class 0.0 = 0.047 +- 0.169 (in-sample avg dev_std = 0.210)
NEC for r=1.0 class 1.0 = 0.133 +- 0.169 (in-sample avg dev_std = 0.210)
NEC for r=1.0 all KL = 0.084 +- 0.169 (in-sample avg dev_std = 0.210)
NEC for r=1.0 all L1 = 0.09 +- 0.164 (in-sample avg dev_std = 0.210)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.357, 0.526, 0.816, 1.0], 'all_L1': [0.583, 0.584, 0.751, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.354, 0.534, 0.913, 1.0], 'all_L1': [0.625, 0.612, 0.934, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.228, 0.554, 0.897, 1.0], 'all_L1': [0.567, 0.728, 0.916, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.501, 0.493, 0.845, 1.0], 'all_L1': [0.745, 0.601, 0.792, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.356, 0.497, 0.857, 1.0], 'all_L1': [0.656, 0.608, 0.885, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.525, 0.493, 0.327, 0.328], 'all_L1': [0.364, 0.435, 0.372, 0.381]}), defaultdict(<class 'list'>, {'all_KL': [0.357, 0.511, 0.088, 0.044], 'all_L1': [0.24, 0.403, 0.063, 0.04]}), defaultdict(<class 'list'>, {'all_KL': [0.527, 0.471, 0.147, 0.081], 'all_L1': [0.312, 0.293, 0.102, 0.065]}), defaultdict(<class 'list'>, {'all_KL': [0.317, 0.477, 0.306, 0.279], 'all_L1': [0.192, 0.39, 0.337, 0.326]}), defaultdict(<class 'list'>, {'all_KL': [0.231, 0.499, 0.17, 0.084], 'all_L1': [0.15, 0.381, 0.133, 0.09]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.635 +- 0.063, 0.627 +- 0.052, 0.856 +- 0.072, 1.000 +- 0.000
suff++ class all_KL  =  0.359 +- 0.086, 0.521 +- 0.023, 0.866 +- 0.035, 1.000 +- 0.000
suff++_acc_int  =  0.525 +- 0.025, 0.582 +- 0.024, 0.620 +- 0.018
nec class all_L1  =  0.252 +- 0.078, 0.380 +- 0.047, 0.201 +- 0.127, 0.180 +- 0.143
nec class all_KL  =  0.391 +- 0.117, 0.490 +- 0.015, 0.208 +- 0.093, 0.163 +- 0.116
nec_acc_int  =  0.530 +- 0.025, 0.561 +- 0.030, 0.595 +- 0.025, 0.602 +- 0.006


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.443 +- 0.026, 0.503 +- 0.007, 0.529 +- 0.028, 0.590 +- 0.072
Faith. Armon (L1)= 		  =  0.349 +- 0.072, 0.469 +- 0.028, 0.301 +- 0.155, 0.282 +- 0.199
Faith. GMean (L1)= 	  =  0.392 +- 0.049, 0.486 +- 0.014, 0.387 +- 0.115, 0.389 +- 0.171
Faith. Aritm (KL)= 		  =  0.375 +- 0.050, 0.506 +- 0.013, 0.537 +- 0.031, 0.582 +- 0.058
Faith. Armon (KL)= 		  =  0.353 +- 0.051, 0.505 +- 0.013, 0.323 +- 0.118, 0.264 +- 0.167
Faith. GMean (KL)= 	  =  0.364 +- 0.050, 0.505 +- 0.013, 0.411 +- 0.090, 0.377 +- 0.145
Computed for split load_split = id



Completed in  0:02:17.670830  for GSATGIN GOODHIV/scaffold



DONE GSAT GOODHIV/scaffold all mitig
DONE all :)
