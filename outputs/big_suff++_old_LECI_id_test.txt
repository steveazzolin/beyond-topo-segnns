nohup: ignoring input

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:34:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:48 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:34:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9035
Train Loss: 0.4128
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.4270
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4215
OOD Validation ACCURACY: 0.8670
OOD Validation Loss: 0.4795
OOD Test ACCURACY: 0.6793
OOD Test Loss: 0.8040

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 124...
[0m[1;37mINFO[0m: [1mCheckpoint 124: 
-----------------------------------
Train ACCURACY: 0.8663
Train Loss: 0.4837
ID Validation ACCURACY: 0.8677
ID Validation Loss: 0.4913
ID Test ACCURACY: 0.8707
ID Test Loss: 0.4812
OOD Validation ACCURACY: 0.9310
OOD Validation Loss: 0.4154
OOD Test ACCURACY: 0.7697
OOD Test Loss: 0.6769

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.6793 0.8707 0.7697 0.8677 0.9310[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.722
WIoU for r=0.3 = 0.684
F1 for r=0.6 = 0.620
WIoU for r=0.6 = 0.781
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.791
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.791


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.638
Model XAI F1 of binarized graphs for r=0.3 =  0.7219125
Model XAI WIoU of binarized graphs for r=0.3 =  0.68417875
len(reference) = 791
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.463
SUFF++ for r=0.3 class 0 = 0.491 +- 0.295 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 1 = 0.524 +- 0.295 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 class 2 = 0.49 +- 0.295 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all KL = 0.427 +- 0.295 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.3 all L1 = 0.502 +- 0.166 (in-sample avg dev_std = 0.577)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.619795
Model XAI WIoU of binarized graphs for r=0.6 =  0.78074125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.72
SUFF++ for r=0.6 class 0 = 0.655 +- 0.259 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 class 1 = 0.634 +- 0.259 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 class 2 = 0.655 +- 0.259 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 all KL = 0.624 +- 0.259 (in-sample avg dev_std = 0.491)
SUFF++ for r=0.6 all L1 = 0.648 +- 0.184 (in-sample avg dev_std = 0.491)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.48923125
Model XAI WIoU of binarized graphs for r=0.9 =  0.79137
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.857
SUFF++ for r=0.9 class 0 = 0.86 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1 = 0.823 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.89 +- 0.171 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.848 +- 0.165 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  0.7219125
Model XAI WIoU of binarized graphs for r=0.3 =  0.68417875
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.381
NEC for r=0.3 class 0 = 0.58 +- 0.309 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 1 = 0.514 +- 0.309 (in-sample avg dev_std = 0.483)
NEC for r=0.3 class 2 = 0.606 +- 0.309 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all KL = 0.612 +- 0.309 (in-sample avg dev_std = 0.483)
NEC for r=0.3 all L1 = 0.566 +- 0.179 (in-sample avg dev_std = 0.483)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.619795
Model XAI WIoU of binarized graphs for r=0.6 =  0.78074125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.487
NEC for r=0.6 class 0 = 0.533 +- 0.303 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 1 = 0.477 +- 0.303 (in-sample avg dev_std = 0.540)
NEC for r=0.6 class 2 = 0.63 +- 0.303 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all KL = 0.589 +- 0.303 (in-sample avg dev_std = 0.540)
NEC for r=0.6 all L1 = 0.545 +- 0.177 (in-sample avg dev_std = 0.540)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.48923125
Model XAI WIoU of binarized graphs for r=0.9 =  0.79137
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.557
NEC for r=0.9 class 0 = 0.471 +- 0.285 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 1 = 0.449 +- 0.285 (in-sample avg dev_std = 0.578)
NEC for r=0.9 class 2 = 0.581 +- 0.285 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all KL = 0.531 +- 0.285 (in-sample avg dev_std = 0.578)
NEC for r=0.9 all L1 = 0.499 +- 0.164 (in-sample avg dev_std = 0.578)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7913650000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.555
NEC for r=1.0 class 0 = 0.478 +- 0.291 (in-sample avg dev_std = 0.560)
NEC for r=1.0 class 1 = 0.443 +- 0.291 (in-sample avg dev_std = 0.560)
NEC for r=1.0 class 2 = 0.571 +- 0.291 (in-sample avg dev_std = 0.560)
NEC for r=1.0 all KL = 0.523 +- 0.291 (in-sample avg dev_std = 0.560)
NEC for r=1.0 all L1 = 0.496 +- 0.170 (in-sample avg dev_std = 0.560)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:36:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:08 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:21 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:23 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:36:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8972
Train Loss: 0.4272
ID Validation ACCURACY: 0.8990
ID Validation Loss: 0.4477
ID Test ACCURACY: 0.9030
ID Test Loss: 0.4154
OOD Validation ACCURACY: 0.9210
OOD Validation Loss: 0.3677
OOD Test ACCURACY: 0.6950
OOD Test Loss: 0.7662

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.8812
Train Loss: 0.4545
ID Validation ACCURACY: 0.8767
ID Validation Loss: 0.4837
ID Test ACCURACY: 0.8840
ID Test Loss: 0.4477
OOD Validation ACCURACY: 0.9280
OOD Validation Loss: 0.3667
OOD Test ACCURACY: 0.6257
OOD Test Loss: 1.1210

[0m[1;37mINFO[0m: [1mChartInfo 0.9030 0.6950 0.8840 0.6257 0.8767 0.9280[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.697
WIoU for r=0.3 = 0.649
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.774
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.779
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.779


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.611
Model XAI F1 of binarized graphs for r=0.3 =  0.6970112500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.64909375
len(reference) = 796
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.449
SUFF++ for r=0.3 class 0 = 0.495 +- 0.271 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 1 = 0.479 +- 0.271 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 2 = 0.448 +- 0.271 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all KL = 0.412 +- 0.271 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all L1 = 0.474 +- 0.153 (in-sample avg dev_std = 0.594)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  0.62544
Model XAI WIoU of binarized graphs for r=0.6 =  0.7744150000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.738
SUFF++ for r=0.6 class 0 = 0.652 +- 0.251 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 class 1 = 0.697 +- 0.251 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 class 2 = 0.604 +- 0.251 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 all KL = 0.655 +- 0.251 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.6 all L1 = 0.652 +- 0.169 (in-sample avg dev_std = 0.441)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.48908124999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.7788925
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.831
SUFF++ for r=0.9 class 0 = 0.792 +- 0.194 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 1 = 0.782 +- 0.194 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 class 2 = 0.796 +- 0.194 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all KL = 0.854 +- 0.194 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.9 all L1 = 0.79 +- 0.176 (in-sample avg dev_std = 0.257)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  0.6970112500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.64909375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.586 +- 0.283 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 1 = 0.489 +- 0.283 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 2 = 0.62 +- 0.283 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all KL = 0.602 +- 0.283 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all L1 = 0.564 +- 0.155 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  0.62544
Model XAI WIoU of binarized graphs for r=0.6 =  0.7744150000000001
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.465
NEC for r=0.6 class 0 = 0.575 +- 0.306 (in-sample avg dev_std = 0.492)
NEC for r=0.6 class 1 = 0.435 +- 0.306 (in-sample avg dev_std = 0.492)
NEC for r=0.6 class 2 = 0.64 +- 0.306 (in-sample avg dev_std = 0.492)
NEC for r=0.6 all KL = 0.564 +- 0.306 (in-sample avg dev_std = 0.492)
NEC for r=0.6 all L1 = 0.548 +- 0.181 (in-sample avg dev_std = 0.492)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.897
Model XAI F1 of binarized graphs for r=0.9 =  0.48908124999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.7788925
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.523 +- 0.307 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 1 = 0.41 +- 0.307 (in-sample avg dev_std = 0.536)
NEC for r=0.9 class 2 = 0.594 +- 0.307 (in-sample avg dev_std = 0.536)
NEC for r=0.9 all KL = 0.521 +- 0.307 (in-sample avg dev_std = 0.536)
NEC for r=0.9 all L1 = 0.508 +- 0.174 (in-sample avg dev_std = 0.536)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.897
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7788675
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.541
NEC for r=1.0 class 0 = 0.511 +- 0.303 (in-sample avg dev_std = 0.525)
NEC for r=1.0 class 1 = 0.412 +- 0.303 (in-sample avg dev_std = 0.525)
NEC for r=1.0 class 2 = 0.589 +- 0.303 (in-sample avg dev_std = 0.525)
NEC for r=1.0 all KL = 0.509 +- 0.303 (in-sample avg dev_std = 0.525)
NEC for r=1.0 all L1 = 0.503 +- 0.173 (in-sample avg dev_std = 0.525)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:37:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:52 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:54 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:56 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:37:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 124...
[0m[1;37mINFO[0m: [1mCheckpoint 124: 
-----------------------------------
Train ACCURACY: 0.8979
Train Loss: 0.4207
ID Validation ACCURACY: 0.8973
ID Validation Loss: 0.4417
ID Test ACCURACY: 0.8983
ID Test Loss: 0.4343
OOD Validation ACCURACY: 0.8787
OOD Validation Loss: 0.4566
OOD Test ACCURACY: 0.7470
OOD Test Loss: 0.7194

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8898
Train Loss: 0.4455
ID Validation ACCURACY: 0.8893
ID Validation Loss: 0.4661
ID Test ACCURACY: 0.8897
ID Test Loss: 0.4398
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3359
OOD Test ACCURACY: 0.7320
OOD Test Loss: 0.7218

[0m[1;37mINFO[0m: [1mChartInfo 0.8983 0.7470 0.8897 0.7320 0.8893 0.9317[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.733
WIoU for r=0.3 = 0.726
F1 for r=0.6 = 0.636
WIoU for r=0.6 = 0.810
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.810
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.810


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.672
Model XAI F1 of binarized graphs for r=0.3 =  0.7325087499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7262662499999999
len(reference) = 799
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.466
SUFF++ for r=0.3 class 0 = 0.503 +- 0.279 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 1 = 0.542 +- 0.279 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 2 = 0.459 +- 0.279 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 all KL = 0.414 +- 0.279 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 all L1 = 0.502 +- 0.184 (in-sample avg dev_std = 0.583)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.861
Model XAI F1 of binarized graphs for r=0.6 =  0.6356700000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.80958625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.71
SUFF++ for r=0.6 class 0 = 0.557 +- 0.304 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 1 = 0.74 +- 0.304 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 class 2 = 0.605 +- 0.304 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all KL = 0.59 +- 0.304 (in-sample avg dev_std = 0.480)
SUFF++ for r=0.6 all L1 = 0.635 +- 0.218 (in-sample avg dev_std = 0.480)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.48908375
Model XAI WIoU of binarized graphs for r=0.9 =  0.80962375
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.812
SUFF++ for r=0.9 class 0 = 0.662 +- 0.249 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.785 +- 0.249 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.834 +- 0.249 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.802 +- 0.249 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.759 +- 0.216 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.67
Model XAI F1 of binarized graphs for r=0.3 =  0.7325087499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7262662499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.39
NEC for r=0.3 class 0 = 0.586 +- 0.286 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 1 = 0.561 +- 0.286 (in-sample avg dev_std = 0.451)
NEC for r=0.3 class 2 = 0.629 +- 0.286 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all KL = 0.654 +- 0.286 (in-sample avg dev_std = 0.451)
NEC for r=0.3 all L1 = 0.591 +- 0.153 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.6356700000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.80958625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.57 +- 0.299 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.516 +- 0.299 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.619 +- 0.299 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.625 +- 0.299 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.567 +- 0.164 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.896
Model XAI F1 of binarized graphs for r=0.9 =  0.48908375
Model XAI WIoU of binarized graphs for r=0.9 =  0.80962375
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.524
NEC for r=0.9 class 0 = 0.528 +- 0.288 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 1 = 0.488 +- 0.288 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 2 = 0.551 +- 0.288 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all KL = 0.562 +- 0.288 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all L1 = 0.522 +- 0.162 (in-sample avg dev_std = 0.540)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.896
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.8096187499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.54 +- 0.284 (in-sample avg dev_std = 0.550)
NEC for r=1.0 class 1 = 0.478 +- 0.284 (in-sample avg dev_std = 0.550)
NEC for r=1.0 class 2 = 0.532 +- 0.284 (in-sample avg dev_std = 0.550)
NEC for r=1.0 all KL = 0.558 +- 0.284 (in-sample avg dev_std = 0.550)
NEC for r=1.0 all L1 = 0.516 +- 0.162 (in-sample avg dev_std = 0.550)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:39:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:10 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:23 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:25 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:27 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:29 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:39:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9111
Train Loss: 0.4118
ID Validation ACCURACY: 0.9100
ID Validation Loss: 0.4282
ID Test ACCURACY: 0.9093
ID Test Loss: 0.4292
OOD Validation ACCURACY: 0.8720
OOD Validation Loss: 0.4700
OOD Test ACCURACY: 0.6660
OOD Test Loss: 0.8918

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 146...
[0m[1;37mINFO[0m: [1mCheckpoint 146: 
-----------------------------------
Train ACCURACY: 0.8854
Train Loss: 0.4498
ID Validation ACCURACY: 0.8820
ID Validation Loss: 0.4694
ID Test ACCURACY: 0.8770
ID Test Loss: 0.4720
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.3373
OOD Test ACCURACY: 0.5787
OOD Test Loss: 1.0425

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.6660 0.8770 0.5787 0.8820 0.9293[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.750
WIoU for r=0.3 = 0.752
F1 for r=0.6 = 0.628
WIoU for r=0.6 = 0.853
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.846
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.846


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.698
Model XAI F1 of binarized graphs for r=0.3 =  0.7495212499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.752405
len(reference) = 797
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.504
SUFF++ for r=0.3 class 0 = 0.55 +- 0.284 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 1 = 0.528 +- 0.284 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 2 = 0.48 +- 0.284 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all KL = 0.409 +- 0.284 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all L1 = 0.52 +- 0.170 (in-sample avg dev_std = 0.599)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.62809125
Model XAI WIoU of binarized graphs for r=0.6 =  0.85293625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.755
SUFF++ for r=0.6 class 0 = 0.627 +- 0.272 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1 = 0.683 +- 0.272 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 2 = 0.707 +- 0.272 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.663 +- 0.272 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.672 +- 0.190 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.48857999999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.84634625
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.858
SUFF++ for r=0.9 class 0 = 0.781 +- 0.186 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.82 +- 0.186 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.878 +- 0.186 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.872 +- 0.186 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.825 +- 0.153 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.695
Model XAI F1 of binarized graphs for r=0.3 =  0.7495212499999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.752405
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.399
NEC for r=0.3 class 0 = 0.587 +- 0.294 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 1 = 0.527 +- 0.294 (in-sample avg dev_std = 0.484)
NEC for r=0.3 class 2 = 0.631 +- 0.294 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all KL = 0.668 +- 0.294 (in-sample avg dev_std = 0.484)
NEC for r=0.3 all L1 = 0.581 +- 0.150 (in-sample avg dev_std = 0.484)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.62809125
Model XAI WIoU of binarized graphs for r=0.6 =  0.85293625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.485
NEC for r=0.6 class 0 = 0.547 +- 0.308 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 1 = 0.48 +- 0.308 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 2 = 0.648 +- 0.308 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all KL = 0.585 +- 0.308 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all L1 = 0.557 +- 0.168 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  0.48857999999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.84634625
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.545
NEC for r=0.9 class 0 = 0.511 +- 0.302 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 1 = 0.437 +- 0.302 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 2 = 0.586 +- 0.302 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all KL = 0.529 +- 0.302 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all L1 = 0.51 +- 0.169 (in-sample avg dev_std = 0.540)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.911
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.84634625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.579
NEC for r=1.0 class 0 = 0.498 +- 0.305 (in-sample avg dev_std = 0.544)
NEC for r=1.0 class 1 = 0.413 +- 0.305 (in-sample avg dev_std = 0.544)
NEC for r=1.0 class 2 = 0.562 +- 0.305 (in-sample avg dev_std = 0.544)
NEC for r=1.0 all KL = 0.508 +- 0.305 (in-sample avg dev_std = 0.544)
NEC for r=1.0 all L1 = 0.49 +- 0.171 (in-sample avg dev_std = 0.544)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:40:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:40:42 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:40:55 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:40:57 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:40:59 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:00 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:41:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9082
Train Loss: 0.4161
ID Validation ACCURACY: 0.9060
ID Validation Loss: 0.4276
ID Test ACCURACY: 0.9077
ID Test Loss: 0.4175
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3282
OOD Test ACCURACY: 0.8457
OOD Test Loss: 0.4898

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.8790
Train Loss: 0.4656
ID Validation ACCURACY: 0.8803
ID Validation Loss: 0.4735
ID Test ACCURACY: 0.8743
ID Test Loss: 0.4768
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3354
OOD Test ACCURACY: 0.8413
OOD Test Loss: 0.5178

[0m[1;37mINFO[0m: [1mChartInfo 0.9077 0.8457 0.8743 0.8413 0.8803 0.9317[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.735
WIoU for r=0.3 = 0.719
F1 for r=0.6 = 0.632
WIoU for r=0.6 = 0.827
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.825
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.824


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.615
Model XAI F1 of binarized graphs for r=0.3 =  0.73496
Model XAI WIoU of binarized graphs for r=0.3 =  0.71891625
len(reference) = 795
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.445
SUFF++ for r=0.3 class 0 = 0.499 +- 0.267 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 1 = 0.499 +- 0.267 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 2 = 0.428 +- 0.267 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all KL = 0.405 +- 0.267 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all L1 = 0.476 +- 0.149 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  0.6316875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.82688875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.733
SUFF++ for r=0.6 class 0 = 0.623 +- 0.277 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 1 = 0.697 +- 0.277 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 class 2 = 0.639 +- 0.277 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all KL = 0.624 +- 0.277 (in-sample avg dev_std = 0.459)
SUFF++ for r=0.6 all L1 = 0.653 +- 0.199 (in-sample avg dev_std = 0.459)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.48920874999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.8250737499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.836
SUFF++ for r=0.9 class 0 = 0.757 +- 0.214 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 1 = 0.778 +- 0.214 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 2 = 0.838 +- 0.214 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all KL = 0.844 +- 0.214 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all L1 = 0.79 +- 0.193 (in-sample avg dev_std = 0.275)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  0.73496
Model XAI WIoU of binarized graphs for r=0.3 =  0.71891625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.351
NEC for r=0.3 class 0 = 0.609 +- 0.291 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 1 = 0.585 +- 0.291 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 2 = 0.614 +- 0.291 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all KL = 0.657 +- 0.291 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all L1 = 0.602 +- 0.163 (in-sample avg dev_std = 0.468)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.845
Model XAI F1 of binarized graphs for r=0.6 =  0.6316875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.82688875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.463
NEC for r=0.6 class 0 = 0.539 +- 0.288 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.58 +- 0.288 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.618 +- 0.288 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.635 +- 0.288 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.579 +- 0.156 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.48920874999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.8250737499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.513
NEC for r=0.9 class 0 = 0.496 +- 0.276 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 1 = 0.537 +- 0.276 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 2 = 0.569 +- 0.276 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all KL = 0.565 +- 0.276 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all L1 = 0.533 +- 0.157 (in-sample avg dev_std = 0.540)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.8244962499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.535
NEC for r=1.0 class 0 = 0.49 +- 0.268 (in-sample avg dev_std = 0.544)
NEC for r=1.0 class 1 = 0.527 +- 0.268 (in-sample avg dev_std = 0.544)
NEC for r=1.0 class 2 = 0.553 +- 0.268 (in-sample avg dev_std = 0.544)
NEC for r=1.0 all KL = 0.553 +- 0.268 (in-sample avg dev_std = 0.544)
NEC for r=1.0 all L1 = 0.523 +- 0.151 (in-sample avg dev_std = 0.544)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.427, 0.624, 0.89, 1.0], 'all_L1': [0.502, 0.648, 0.848, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.412, 0.655, 0.854, 1.0], 'all_L1': [0.474, 0.652, 0.79, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.414, 0.59, 0.802, 1.0], 'all_L1': [0.502, 0.635, 0.759, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.409, 0.663, 0.872, 1.0], 'all_L1': [0.52, 0.672, 0.825, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.405, 0.624, 0.844, 1.0], 'all_L1': [0.476, 0.653, 0.79, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.612, 0.589, 0.531, 0.523], 'all_L1': [0.566, 0.545, 0.499, 0.496]}), defaultdict(<class 'list'>, {'all_KL': [0.602, 0.564, 0.521, 0.509], 'all_L1': [0.564, 0.548, 0.508, 0.503]}), defaultdict(<class 'list'>, {'all_KL': [0.654, 0.625, 0.562, 0.558], 'all_L1': [0.591, 0.567, 0.522, 0.516]}), defaultdict(<class 'list'>, {'all_KL': [0.668, 0.585, 0.529, 0.508], 'all_L1': [0.581, 0.557, 0.51, 0.49]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.635, 0.565, 0.553], 'all_L1': [0.602, 0.579, 0.533, 0.523]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.495 +- 0.017, 0.652 +- 0.012, 0.802 +- 0.031, 1.000 +- 0.000
suff++ class all_KL  =  0.413 +- 0.007, 0.631 +- 0.026, 0.852 +- 0.030, 1.000 +- 0.000
suff++_acc_int  =  0.465 +- 0.021, 0.731 +- 0.016, 0.839 +- 0.017
nec class all_L1  =  0.581 +- 0.015, 0.559 +- 0.013, 0.514 +- 0.012, 0.506 +- 0.012
nec class all_KL  =  0.639 +- 0.026, 0.600 +- 0.026, 0.542 +- 0.018, 0.530 +- 0.021
nec_acc_int  =  0.377 +- 0.018, 0.472 +- 0.011, 0.535 +- 0.015, 0.549 +- 0.016


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.538 +- 0.011, 0.606 +- 0.008, 0.658 +- 0.012, 0.753 +- 0.006
Faith. Armon (L1)= 		  =  0.534 +- 0.012, 0.602 +- 0.008, 0.626 +- 0.007, 0.672 +- 0.011
Faith. GMean (L1)= 	  =  0.536 +- 0.011, 0.604 +- 0.008, 0.642 +- 0.009, 0.711 +- 0.009
Faith. Aritm (KL)= 		  =  0.526 +- 0.011, 0.615 +- 0.009, 0.697 +- 0.011, 0.765 +- 0.011
Faith. Armon (KL)= 		  =  0.502 +- 0.007, 0.614 +- 0.010, 0.662 +- 0.010, 0.693 +- 0.018
Faith. GMean (KL)= 	  =  0.514 +- 0.009, 0.615 +- 0.010, 0.679 +- 0.009, 0.728 +- 0.015
Computed for split load_split = id



Completed in  0:07:38.525002  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:42:40 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:42:40 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:42:53 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:42:55 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:42:58 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:00 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ACCURACY: 0.8933
Train Loss: 0.4689
ID Validation ACCURACY: 0.8867
ID Validation Loss: 0.4937
ID Test ACCURACY: 0.9010
ID Test Loss: 0.4439
OOD Validation ACCURACY: 0.6550
OOD Validation Loss: 1.5131
OOD Test ACCURACY: 0.3787
OOD Test Loss: 2.5757

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ACCURACY: 0.5774
Train Loss: 1.3209
ID Validation ACCURACY: 0.5740
ID Validation Loss: 1.3483
ID Test ACCURACY: 0.5860
ID Test Loss: 1.2983
OOD Validation ACCURACY: 0.9227
OOD Validation Loss: 0.4906
OOD Test ACCURACY: 0.3487
OOD Test Loss: 9.0129

[0m[1;37mINFO[0m: [1mChartInfo 0.9010 0.3787 0.5860 0.3487 0.5740 0.9227[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.6 = 0.571
WIoU for r=0.6 = 0.702


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  0.57138375
Model XAI WIoU of binarized graphs for r=0.6 =  0.70186375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.624
SUFF++ for r=0.6 class 0 = 0.43 +- 0.275 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 class 1 = 0.547 +- 0.275 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 class 2 = 0.61 +- 0.275 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 all KL = 0.472 +- 0.275 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.6 all L1 = 0.528 +- 0.203 (in-sample avg dev_std = 0.569)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  0.57138375
Model XAI WIoU of binarized graphs for r=0.6 =  0.70186375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.615 +- 0.250 (in-sample avg dev_std = 0.643)
NEC for r=0.6 class 1 = 0.559 +- 0.250 (in-sample avg dev_std = 0.643)
NEC for r=0.6 class 2 = 0.668 +- 0.250 (in-sample avg dev_std = 0.643)
NEC for r=0.6 all KL = 0.693 +- 0.250 (in-sample avg dev_std = 0.643)
NEC for r=0.6 all L1 = 0.613 +- 0.150 (in-sample avg dev_std = 0.643)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:43:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:42 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:44 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:43:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 86...
[0m[1;37mINFO[0m: [1mCheckpoint 86: 
-----------------------------------
Train ACCURACY: 0.8799
Train Loss: 0.4851
ID Validation ACCURACY: 0.8757
ID Validation Loss: 0.5174
ID Test ACCURACY: 0.8873
ID Test Loss: 0.4680
OOD Validation ACCURACY: 0.6670
OOD Validation Loss: 0.9447
OOD Test ACCURACY: 0.4367
OOD Test Loss: 3.0736

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ACCURACY: 0.8507
Train Loss: 0.4884
ID Validation ACCURACY: 0.8450
ID Validation Loss: 0.5152
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4707
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4447
OOD Test ACCURACY: 0.3857
OOD Test Loss: 4.2847

[0m[1;37mINFO[0m: [1mChartInfo 0.8873 0.4367 0.8610 0.3857 0.8450 0.9313[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.6 = 0.607
WIoU for r=0.6 = 0.719


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6067125
Model XAI WIoU of binarized graphs for r=0.6 =  0.71919625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.661
SUFF++ for r=0.6 class 0 = 0.512 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 1 = 0.637 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 2 = 0.582 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all KL = 0.471 +- 0.299 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all L1 = 0.577 +- 0.213 (in-sample avg dev_std = 0.576)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.88
Model XAI F1 of binarized graphs for r=0.6 =  0.6067125
Model XAI WIoU of binarized graphs for r=0.6 =  0.71919625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.458
NEC for r=0.6 class 0 = 0.593 +- 0.254 (in-sample avg dev_std = 0.671)
NEC for r=0.6 class 1 = 0.555 +- 0.254 (in-sample avg dev_std = 0.671)
NEC for r=0.6 class 2 = 0.668 +- 0.254 (in-sample avg dev_std = 0.671)
NEC for r=0.6 all KL = 0.731 +- 0.254 (in-sample avg dev_std = 0.671)
NEC for r=0.6 all L1 = 0.604 +- 0.161 (in-sample avg dev_std = 0.671)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:44:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:08 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:21 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:23 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:28 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.9108
Train Loss: 0.4126
ID Validation ACCURACY: 0.9080
ID Validation Loss: 0.4411
ID Test ACCURACY: 0.9153
ID Test Loss: 0.4096
OOD Validation ACCURACY: 0.9047
OOD Validation Loss: 0.4491
OOD Test ACCURACY: 0.4210
OOD Test Loss: 3.6186

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ACCURACY: 0.8849
Train Loss: 0.5208
ID Validation ACCURACY: 0.8813
ID Validation Loss: 0.5566
ID Test ACCURACY: 0.8920
ID Test Loss: 0.5012
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4367
OOD Test ACCURACY: 0.3817
OOD Test Loss: 5.1552

[0m[1;37mINFO[0m: [1mChartInfo 0.9153 0.4210 0.8920 0.3817 0.8813 0.9313[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.6 = 0.588
WIoU for r=0.6 = 0.674


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.916
Model XAI F1 of binarized graphs for r=0.6 =  0.587665
Model XAI WIoU of binarized graphs for r=0.6 =  0.67352625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.667
SUFF++ for r=0.6 class 0 = 0.457 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.6 class 1 = 0.585 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.6 class 2 = 0.693 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.6 all KL = 0.475 +- 0.300 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.6 all L1 = 0.577 +- 0.223 (in-sample avg dev_std = 0.608)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.916
Model XAI F1 of binarized graphs for r=0.6 =  0.587665
Model XAI WIoU of binarized graphs for r=0.6 =  0.67352625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.455
NEC for r=0.6 class 0 = 0.625 +- 0.254 (in-sample avg dev_std = 0.667)
NEC for r=0.6 class 1 = 0.545 +- 0.254 (in-sample avg dev_std = 0.667)
NEC for r=0.6 class 2 = 0.644 +- 0.254 (in-sample avg dev_std = 0.667)
NEC for r=0.6 all KL = 0.717 +- 0.254 (in-sample avg dev_std = 0.667)
NEC for r=0.6 all L1 = 0.604 +- 0.158 (in-sample avg dev_std = 0.667)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:44:51 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:44:51 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:05 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:07 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:09 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 72...
[0m[1;37mINFO[0m: [1mCheckpoint 72: 
-----------------------------------
Train ACCURACY: 0.8929
Train Loss: 0.4784
ID Validation ACCURACY: 0.8877
ID Validation Loss: 0.5235
ID Test ACCURACY: 0.9007
ID Test Loss: 0.4658
OOD Validation ACCURACY: 0.8657
OOD Validation Loss: 0.4939
OOD Test ACCURACY: 0.4123
OOD Test Loss: 4.0821

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 0...
[0m[1;37mINFO[0m: [1mCheckpoint 0: 
-----------------------------------
Train ACCURACY: 0.4968
Train Loss: 1.1639
ID Validation ACCURACY: 0.4947
ID Validation Loss: 1.2213
ID Test ACCURACY: 0.4953
ID Test Loss: 1.1575
OOD Validation ACCURACY: 0.9307
OOD Validation Loss: 0.4981
OOD Test ACCURACY: 0.3283
OOD Test Loss: 9.9458

[0m[1;37mINFO[0m: [1mChartInfo 0.9007 0.4123 0.4953 0.3283 0.4947 0.9307[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.6 = 0.603
WIoU for r=0.6 = 0.728


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.6033575
Model XAI WIoU of binarized graphs for r=0.6 =  0.72781125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.685
SUFF++ for r=0.6 class 0 = 0.46 +- 0.341 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 1 = 0.699 +- 0.341 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 class 2 = 0.7 +- 0.341 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all KL = 0.497 +- 0.341 (in-sample avg dev_std = 0.577)
SUFF++ for r=0.6 all L1 = 0.619 +- 0.263 (in-sample avg dev_std = 0.577)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.6033575
Model XAI WIoU of binarized graphs for r=0.6 =  0.72781125
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.412
NEC for r=0.6 class 0 = 0.671 +- 0.222 (in-sample avg dev_std = 0.702)
NEC for r=0.6 class 1 = 0.581 +- 0.222 (in-sample avg dev_std = 0.702)
NEC for r=0.6 class 2 = 0.676 +- 0.222 (in-sample avg dev_std = 0.702)
NEC for r=0.6 all KL = 0.825 +- 0.222 (in-sample avg dev_std = 0.702)
NEC for r=0.6 all L1 = 0.642 +- 0.161 (in-sample avg dev_std = 0.702)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:45:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:33 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:46 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:48 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:50 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:45:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 16...
[0m[1;37mINFO[0m: [1mCheckpoint 16: 
-----------------------------------
Train ACCURACY: 0.8887
Train Loss: 0.4924
ID Validation ACCURACY: 0.8847
ID Validation Loss: 0.5324
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4691
OOD Validation ACCURACY: 0.7167
OOD Validation Loss: 1.3877
OOD Test ACCURACY: 0.3873
OOD Test Loss: 3.5672

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 45...
[0m[1;37mINFO[0m: [1mCheckpoint 45: 
-----------------------------------
Train ACCURACY: 0.8089
Train Loss: 0.6907
ID Validation ACCURACY: 0.8030
ID Validation Loss: 0.7150
ID Test ACCURACY: 0.8183
ID Test Loss: 0.6665
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.4273
OOD Test ACCURACY: 0.4333
OOD Test Loss: 4.3285

[0m[1;37mINFO[0m: [1mChartInfo 0.8977 0.3873 0.8183 0.4333 0.8030 0.9317[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.6 = 0.606
WIoU for r=0.6 = 0.688


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.60587
Model XAI WIoU of binarized graphs for r=0.6 =  0.687945
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.661
SUFF++ for r=0.6 class 0 = 0.455 +- 0.331 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 1 = 0.738 +- 0.331 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 class 2 = 0.648 +- 0.331 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all KL = 0.514 +- 0.331 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.6 all L1 = 0.613 +- 0.251 (in-sample avg dev_std = 0.576)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.60587
Model XAI WIoU of binarized graphs for r=0.6 =  0.687945
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.42
NEC for r=0.6 class 0 = 0.629 +- 0.242 (in-sample avg dev_std = 0.702)
NEC for r=0.6 class 1 = 0.556 +- 0.242 (in-sample avg dev_std = 0.702)
NEC for r=0.6 class 2 = 0.685 +- 0.242 (in-sample avg dev_std = 0.702)
NEC for r=0.6 all KL = 0.763 +- 0.242 (in-sample avg dev_std = 0.702)
NEC for r=0.6 all L1 = 0.622 +- 0.168 (in-sample avg dev_std = 0.702)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.472], 'all_L1': [0.528]}), defaultdict(<class 'list'>, {'all_KL': [0.471], 'all_L1': [0.577]}), defaultdict(<class 'list'>, {'all_KL': [0.475], 'all_L1': [0.577]}), defaultdict(<class 'list'>, {'all_KL': [0.497], 'all_L1': [0.619]}), defaultdict(<class 'list'>, {'all_KL': [0.514], 'all_L1': [0.613]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.693], 'all_L1': [0.613]}), defaultdict(<class 'list'>, {'all_KL': [0.731], 'all_L1': [0.604]}), defaultdict(<class 'list'>, {'all_KL': [0.717], 'all_L1': [0.604]}), defaultdict(<class 'list'>, {'all_KL': [0.825], 'all_L1': [0.642]}), defaultdict(<class 'list'>, {'all_KL': [0.763], 'all_L1': [0.622]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.583 +- 0.033
suff++ class all_KL  =  0.486 +- 0.017
suff++_acc_int  =  0.660 +- 0.020
nec class all_L1  =  0.617 +- 0.014
nec class all_KL  =  0.746 +- 0.046
nec_acc_int  =  0.435 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.600 +- 0.021
Faith. Armon (L1)= 		  =  0.599 +- 0.022
Faith. GMean (L1)= 	  =  0.599 +- 0.022
Faith. Aritm (KL)= 		  =  0.616 +- 0.029
Faith. Armon (KL)= 		  =  0.588 +- 0.024
Faith. GMean (KL)= 	  =  0.602 +- 0.027
Computed for split load_split = id



Completed in  0:03:37.771723  for CIGAGIN GOODMotif/basis



DONE CIGA GOODMotif/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:46:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:46:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 102...
[0m[1;37mINFO[0m: [1mCheckpoint 102: 
-----------------------------------
Train ACCURACY: 0.8846
Train Loss: 0.4663
ID Validation ACCURACY: 0.8883
ID Validation Loss: 0.4567
ID Test ACCURACY: 0.8753
ID Test Loss: 0.4923
OOD Validation ACCURACY: 0.8767
OOD Validation Loss: 0.5561
OOD Test ACCURACY: 0.8990
OOD Test Loss: 0.4482

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ACCURACY: 0.8700
Train Loss: 0.4809
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.4691
ID Test ACCURACY: 0.8660
ID Test Loss: 0.5000
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4306
OOD Test ACCURACY: 0.6947
OOD Test Loss: 0.8828

[0m[1;37mINFO[0m: [1mChartInfo 0.8753 0.8990 0.8660 0.6947 0.8710 0.9313[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.716
WIoU for r=0.3 = 0.680
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.753
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.747
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.747


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.543
Model XAI F1 of binarized graphs for r=0.3 =  0.7155362500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.67951625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.532
SUFF++ for r=0.3 class 0 = 0.563 +- 0.295 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 class 1 = 0.557 +- 0.295 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 class 2 = 0.557 +- 0.295 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 all KL = 0.516 +- 0.295 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.3 all L1 = 0.559 +- 0.198 (in-sample avg dev_std = 0.520)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.6161525
Model XAI WIoU of binarized graphs for r=0.6 =  0.7525425000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0 = 0.698 +- 0.252 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 1 = 0.672 +- 0.252 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 class 2 = 0.685 +- 0.252 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all KL = 0.718 +- 0.252 (in-sample avg dev_std = 0.379)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.203 (in-sample avg dev_std = 0.379)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  0.47311
Model XAI WIoU of binarized graphs for r=0.9 =  0.74703875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.81
SUFF++ for r=0.9 class 0 = 0.792 +- 0.193 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 1 = 0.726 +- 0.193 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 2 = 0.797 +- 0.193 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all KL = 0.853 +- 0.193 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all L1 = 0.772 +- 0.194 (in-sample avg dev_std = 0.259)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.543
Model XAI F1 of binarized graphs for r=0.3 =  0.7155362500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.67951625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.378
NEC for r=0.3 class 0 = 0.58 +- 0.294 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 1 = 0.497 +- 0.294 (in-sample avg dev_std = 0.446)
NEC for r=0.3 class 2 = 0.581 +- 0.294 (in-sample avg dev_std = 0.446)
NEC for r=0.3 all KL = 0.59 +- 0.294 (in-sample avg dev_std = 0.446)
NEC for r=0.3 all L1 = 0.553 +- 0.172 (in-sample avg dev_std = 0.446)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.6161525
Model XAI WIoU of binarized graphs for r=0.6 =  0.7525425000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.5
NEC for r=0.6 class 0 = 0.573 +- 0.320 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 1 = 0.417 +- 0.320 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 2 = 0.616 +- 0.320 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all KL = 0.544 +- 0.320 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all L1 = 0.537 +- 0.182 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.886
Model XAI F1 of binarized graphs for r=0.9 =  0.47311
Model XAI WIoU of binarized graphs for r=0.9 =  0.74703875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.596
NEC for r=0.9 class 0 = 0.51 +- 0.301 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 1 = 0.384 +- 0.301 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 2 = 0.505 +- 0.301 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all KL = 0.461 +- 0.301 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all L1 = 0.467 +- 0.171 (in-sample avg dev_std = 0.516)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.89
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7469425
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.605
NEC for r=1.0 class 0 = 0.506 +- 0.303 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 1 = 0.377 +- 0.303 (in-sample avg dev_std = 0.515)
NEC for r=1.0 class 2 = 0.495 +- 0.303 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all KL = 0.453 +- 0.303 (in-sample avg dev_std = 0.515)
NEC for r=1.0 all L1 = 0.46 +- 0.170 (in-sample avg dev_std = 0.515)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:48:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:48:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 110...
[0m[1;37mINFO[0m: [1mCheckpoint 110: 
-----------------------------------
Train ACCURACY: 0.8872
Train Loss: 0.4454
ID Validation ACCURACY: 0.8927
ID Validation Loss: 0.4356
ID Test ACCURACY: 0.8933
ID Test Loss: 0.4534
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.4829
OOD Test ACCURACY: 0.8907
OOD Test Loss: 0.4426

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 0.8367
Train Loss: 0.5254
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.5010
ID Test ACCURACY: 0.8350
ID Test Loss: 0.5355
OOD Validation ACCURACY: 0.9210
OOD Validation Loss: 0.5277
OOD Test ACCURACY: 0.8627
OOD Test Loss: 0.5303

[0m[1;37mINFO[0m: [1mChartInfo 0.8933 0.8907 0.8350 0.8627 0.8440 0.9210[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.739
WIoU for r=0.3 = 0.724
F1 for r=0.6 = 0.616
WIoU for r=0.6 = 0.786
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.785
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.785


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.665
Model XAI F1 of binarized graphs for r=0.3 =  0.7386725
Model XAI WIoU of binarized graphs for r=0.3 =  0.7235349999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.52
SUFF++ for r=0.3 class 0 = 0.501 +- 0.261 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 1 = 0.634 +- 0.261 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 2 = 0.524 +- 0.261 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all KL = 0.483 +- 0.261 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all L1 = 0.552 +- 0.158 (in-sample avg dev_std = 0.541)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.61632875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7859
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.717
SUFF++ for r=0.6 class 0 = 0.646 +- 0.250 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1 = 0.634 +- 0.250 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 2 = 0.665 +- 0.250 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.645 +- 0.250 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.649 +- 0.188 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47275625
Model XAI WIoU of binarized graphs for r=0.9 =  0.78460625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.816
SUFF++ for r=0.9 class 0 = 0.79 +- 0.199 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 1 = 0.794 +- 0.199 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 2 = 0.797 +- 0.199 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all KL = 0.852 +- 0.199 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all L1 = 0.794 +- 0.192 (in-sample avg dev_std = 0.275)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.665
Model XAI F1 of binarized graphs for r=0.3 =  0.7386725
Model XAI WIoU of binarized graphs for r=0.3 =  0.7235349999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.377
NEC for r=0.3 class 0 = 0.57 +- 0.276 (in-sample avg dev_std = 0.408)
NEC for r=0.3 class 1 = 0.517 +- 0.276 (in-sample avg dev_std = 0.408)
NEC for r=0.3 class 2 = 0.586 +- 0.276 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all KL = 0.619 +- 0.276 (in-sample avg dev_std = 0.408)
NEC for r=0.3 all L1 = 0.558 +- 0.144 (in-sample avg dev_std = 0.408)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  0.61632875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7859
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.447
NEC for r=0.6 class 0 = 0.554 +- 0.306 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 1 = 0.52 +- 0.306 (in-sample avg dev_std = 0.446)
NEC for r=0.6 class 2 = 0.612 +- 0.306 (in-sample avg dev_std = 0.446)
NEC for r=0.6 all KL = 0.593 +- 0.306 (in-sample avg dev_std = 0.446)
NEC for r=0.6 all L1 = 0.563 +- 0.166 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47275625
Model XAI WIoU of binarized graphs for r=0.9 =  0.78460625
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.482 +- 0.282 (in-sample avg dev_std = 0.495)
NEC for r=0.9 class 1 = 0.477 +- 0.282 (in-sample avg dev_std = 0.495)
NEC for r=0.9 class 2 = 0.537 +- 0.282 (in-sample avg dev_std = 0.495)
NEC for r=0.9 all KL = 0.492 +- 0.282 (in-sample avg dev_std = 0.495)
NEC for r=0.9 all L1 = 0.499 +- 0.164 (in-sample avg dev_std = 0.495)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7847825
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.548
NEC for r=1.0 class 0 = 0.485 +- 0.278 (in-sample avg dev_std = 0.498)
NEC for r=1.0 class 1 = 0.47 +- 0.278 (in-sample avg dev_std = 0.498)
NEC for r=1.0 class 2 = 0.545 +- 0.278 (in-sample avg dev_std = 0.498)
NEC for r=1.0 all KL = 0.494 +- 0.278 (in-sample avg dev_std = 0.498)
NEC for r=1.0 all L1 = 0.501 +- 0.158 (in-sample avg dev_std = 0.498)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:49:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:49:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.9123
Train Loss: 0.4007
ID Validation ACCURACY: 0.9150
ID Validation Loss: 0.3813
ID Test ACCURACY: 0.9053
ID Test Loss: 0.4430
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.3879
OOD Test ACCURACY: 0.7097
OOD Test Loss: 0.7779

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8903
Train Loss: 0.4322
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4222
ID Test ACCURACY: 0.8893
ID Test Loss: 0.4666
OOD Validation ACCURACY: 0.9303
OOD Validation Loss: 0.3953
OOD Test ACCURACY: 0.8417
OOD Test Loss: 0.6994

[0m[1;37mINFO[0m: [1mChartInfo 0.9053 0.7097 0.8893 0.8417 0.8910 0.9303[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.673
WIoU for r=0.3 = 0.596
F1 for r=0.6 = 0.602
WIoU for r=0.6 = 0.689
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.700
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.700


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.509
Model XAI F1 of binarized graphs for r=0.3 =  0.6729925
Model XAI WIoU of binarized graphs for r=0.3 =  0.5961862499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.419
SUFF++ for r=0.3 class 0 = 0.465 +- 0.254 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 1 = 0.529 +- 0.254 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 class 2 = 0.468 +- 0.254 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all KL = 0.428 +- 0.254 (in-sample avg dev_std = 0.552)
SUFF++ for r=0.3 all L1 = 0.487 +- 0.157 (in-sample avg dev_std = 0.552)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  0.6022437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.68860125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.735
SUFF++ for r=0.6 class 0 = 0.638 +- 0.286 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 class 1 = 0.679 +- 0.286 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 class 2 = 0.676 +- 0.286 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all KL = 0.627 +- 0.286 (in-sample avg dev_std = 0.474)
SUFF++ for r=0.6 all L1 = 0.665 +- 0.204 (in-sample avg dev_std = 0.474)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.47302125000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.70028
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.842
SUFF++ for r=0.9 class 0 = 0.78 +- 0.202 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 1 = 0.8 +- 0.202 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 class 2 = 0.821 +- 0.202 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all KL = 0.838 +- 0.202 (in-sample avg dev_std = 0.270)
SUFF++ for r=0.9 all L1 = 0.801 +- 0.184 (in-sample avg dev_std = 0.270)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.509
Model XAI F1 of binarized graphs for r=0.3 =  0.6729925
Model XAI WIoU of binarized graphs for r=0.3 =  0.5961862499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.342
NEC for r=0.3 class 0 = 0.586 +- 0.281 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 1 = 0.537 +- 0.281 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 2 = 0.579 +- 0.281 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all KL = 0.608 +- 0.281 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all L1 = 0.568 +- 0.166 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  0.6022437500000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.68860125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.461
NEC for r=0.6 class 0 = 0.58 +- 0.280 (in-sample avg dev_std = 0.548)
NEC for r=0.6 class 1 = 0.509 +- 0.280 (in-sample avg dev_std = 0.548)
NEC for r=0.6 class 2 = 0.622 +- 0.280 (in-sample avg dev_std = 0.548)
NEC for r=0.6 all KL = 0.635 +- 0.280 (in-sample avg dev_std = 0.548)
NEC for r=0.6 all L1 = 0.572 +- 0.165 (in-sample avg dev_std = 0.548)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.47302125000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.70028
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.538
NEC for r=0.9 class 0 = 0.531 +- 0.291 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 1 = 0.475 +- 0.291 (in-sample avg dev_std = 0.588)
NEC for r=0.9 class 2 = 0.564 +- 0.291 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all KL = 0.571 +- 0.291 (in-sample avg dev_std = 0.588)
NEC for r=0.9 all L1 = 0.524 +- 0.166 (in-sample avg dev_std = 0.588)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.918
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7003287499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.529 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=1.0 class 1 = 0.483 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=1.0 class 2 = 0.544 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=1.0 all KL = 0.56 +- 0.284 (in-sample avg dev_std = 0.578)
NEC for r=1.0 all L1 = 0.519 +- 0.164 (in-sample avg dev_std = 0.578)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:50:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:50:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.5315
ID Validation ACCURACY: 0.8940
ID Validation Loss: 0.5268
ID Test ACCURACY: 0.8807
ID Test Loss: 0.5595
OOD Validation ACCURACY: 0.8480
OOD Validation Loss: 0.5785
OOD Test ACCURACY: 0.9053
OOD Test Loss: 0.4997

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 116...
[0m[1;37mINFO[0m: [1mCheckpoint 116: 
-----------------------------------
Train ACCURACY: 0.8415
Train Loss: 0.5162
ID Validation ACCURACY: 0.8440
ID Validation Loss: 0.4990
ID Test ACCURACY: 0.8423
ID Test Loss: 0.5364
OOD Validation ACCURACY: 0.9043
OOD Validation Loss: 0.5293
OOD Test ACCURACY: 0.7010
OOD Test Loss: 0.9220

[0m[1;37mINFO[0m: [1mChartInfo 0.8807 0.9053 0.8423 0.7010 0.8440 0.9043[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.752
WIoU for r=0.3 = 0.849
F1 for r=0.6 = 0.607
WIoU for r=0.6 = 0.908
F1 for r=0.9 = 0.472
WIoU for r=0.9 = 0.911
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.911


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  0.7518324999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8494974999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.517
SUFF++ for r=0.3 class 0 = 0.53 +- 0.296 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 1 = 0.656 +- 0.296 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 class 2 = 0.532 +- 0.296 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all KL = 0.585 +- 0.296 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.3 all L1 = 0.571 +- 0.168 (in-sample avg dev_std = 0.460)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.60748625
Model XAI WIoU of binarized graphs for r=0.6 =  0.9079487499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.737
SUFF++ for r=0.6 class 0 = 0.626 +- 0.196 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 class 1 = 0.75 +- 0.196 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 class 2 = 0.752 +- 0.196 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all KL = 0.794 +- 0.196 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all L1 = 0.71 +- 0.179 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  0.4723375
Model XAI WIoU of binarized graphs for r=0.9 =  0.91110875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.84
SUFF++ for r=0.9 class 0 = 0.828 +- 0.124 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 1 = 0.855 +- 0.124 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 class 2 = 0.878 +- 0.124 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all KL = 0.93 +- 0.124 (in-sample avg dev_std = 0.191)
SUFF++ for r=0.9 all L1 = 0.854 +- 0.145 (in-sample avg dev_std = 0.191)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  0.7518324999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.8494974999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.337
NEC for r=0.3 class 0 = 0.456 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 1 = 0.462 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 2 = 0.579 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all KL = 0.481 +- 0.338 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all L1 = 0.501 +- 0.174 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.60748625
Model XAI WIoU of binarized graphs for r=0.6 =  0.9079487499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.47
NEC for r=0.6 class 0 = 0.413 +- 0.306 (in-sample avg dev_std = 0.452)
NEC for r=0.6 class 1 = 0.433 +- 0.306 (in-sample avg dev_std = 0.452)
NEC for r=0.6 class 2 = 0.584 +- 0.306 (in-sample avg dev_std = 0.452)
NEC for r=0.6 all KL = 0.431 +- 0.306 (in-sample avg dev_std = 0.452)
NEC for r=0.6 all L1 = 0.479 +- 0.176 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.882
Model XAI F1 of binarized graphs for r=0.9 =  0.4723375
Model XAI WIoU of binarized graphs for r=0.9 =  0.91110875
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.539
NEC for r=0.9 class 0 = 0.376 +- 0.292 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 1 = 0.384 +- 0.292 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 2 = 0.521 +- 0.292 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all KL = 0.357 +- 0.292 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all L1 = 0.429 +- 0.172 (in-sample avg dev_std = 0.458)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.882
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.91110875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.547
NEC for r=1.0 class 0 = 0.373 +- 0.293 (in-sample avg dev_std = 0.459)
NEC for r=1.0 class 1 = 0.369 +- 0.293 (in-sample avg dev_std = 0.459)
NEC for r=1.0 class 2 = 0.508 +- 0.293 (in-sample avg dev_std = 0.459)
NEC for r=1.0 all KL = 0.347 +- 0.293 (in-sample avg dev_std = 0.459)
NEC for r=1.0 all L1 = 0.418 +- 0.172 (in-sample avg dev_std = 0.459)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:51:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:51:42 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8887
Train Loss: 0.4987
ID Validation ACCURACY: 0.8910
ID Validation Loss: 0.4744
ID Test ACCURACY: 0.8860
ID Test Loss: 0.5215
OOD Validation ACCURACY: 0.8970
OOD Validation Loss: 0.5042
OOD Test ACCURACY: 0.8647
OOD Test Loss: 0.5045

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.7957
Train Loss: 0.6628
ID Validation ACCURACY: 0.7933
ID Validation Loss: 0.6550
ID Test ACCURACY: 0.7830
ID Test Loss: 0.7186
OOD Validation ACCURACY: 0.9107
OOD Validation Loss: 0.5086
OOD Test ACCURACY: 0.8793
OOD Test Loss: 0.5214

[0m[1;37mINFO[0m: [1mChartInfo 0.8860 0.8647 0.7830 0.8793 0.7933 0.9107[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.706
WIoU for r=0.3 = 0.653
F1 for r=0.6 = 0.604
WIoU for r=0.6 = 0.714
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.707
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.707


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.579
Model XAI F1 of binarized graphs for r=0.3 =  0.705965
Model XAI WIoU of binarized graphs for r=0.3 =  0.6525075000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.561
SUFF++ for r=0.3 class 0 = 0.485 +- 0.305 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 1 = 0.531 +- 0.305 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 class 2 = 0.501 +- 0.305 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all KL = 0.378 +- 0.305 (in-sample avg dev_std = 0.594)
SUFF++ for r=0.3 all L1 = 0.505 +- 0.193 (in-sample avg dev_std = 0.594)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  0.6040475
Model XAI WIoU of binarized graphs for r=0.6 =  0.714225
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.767
SUFF++ for r=0.6 class 0 = 0.634 +- 0.299 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 1 = 0.711 +- 0.299 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 class 2 = 0.709 +- 0.299 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all KL = 0.64 +- 0.299 (in-sample avg dev_std = 0.438)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.215 (in-sample avg dev_std = 0.438)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47308624999999993
Model XAI WIoU of binarized graphs for r=0.9 =  0.70713375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.841
SUFF++ for r=0.9 class 0 = 0.756 +- 0.233 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 1 = 0.809 +- 0.233 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 class 2 = 0.85 +- 0.233 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all KL = 0.839 +- 0.233 (in-sample avg dev_std = 0.286)
SUFF++ for r=0.9 all L1 = 0.806 +- 0.201 (in-sample avg dev_std = 0.286)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.581
Model XAI F1 of binarized graphs for r=0.3 =  0.705965
Model XAI WIoU of binarized graphs for r=0.3 =  0.6525075000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.39
NEC for r=0.3 class 0 = 0.598 +- 0.303 (in-sample avg dev_std = 0.555)
NEC for r=0.3 class 1 = 0.538 +- 0.303 (in-sample avg dev_std = 0.555)
NEC for r=0.3 class 2 = 0.67 +- 0.303 (in-sample avg dev_std = 0.555)
NEC for r=0.3 all KL = 0.714 +- 0.303 (in-sample avg dev_std = 0.555)
NEC for r=0.3 all L1 = 0.604 +- 0.162 (in-sample avg dev_std = 0.555)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  0.6040475
Model XAI WIoU of binarized graphs for r=0.6 =  0.714225
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.491
NEC for r=0.6 class 0 = 0.509 +- 0.322 (in-sample avg dev_std = 0.552)
NEC for r=0.6 class 1 = 0.478 +- 0.322 (in-sample avg dev_std = 0.552)
NEC for r=0.6 class 2 = 0.616 +- 0.322 (in-sample avg dev_std = 0.552)
NEC for r=0.6 all KL = 0.618 +- 0.322 (in-sample avg dev_std = 0.552)
NEC for r=0.6 all L1 = 0.536 +- 0.174 (in-sample avg dev_std = 0.552)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.47308624999999993
Model XAI WIoU of binarized graphs for r=0.9 =  0.70713375
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.577
NEC for r=0.9 class 0 = 0.448 +- 0.312 (in-sample avg dev_std = 0.564)
NEC for r=0.9 class 1 = 0.42 +- 0.312 (in-sample avg dev_std = 0.564)
NEC for r=0.9 class 2 = 0.549 +- 0.312 (in-sample avg dev_std = 0.564)
NEC for r=0.9 all KL = 0.52 +- 0.312 (in-sample avg dev_std = 0.564)
NEC for r=0.9 all L1 = 0.474 +- 0.169 (in-sample avg dev_std = 0.564)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7069325000000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.572
NEC for r=1.0 class 0 = 0.451 +- 0.308 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 1 = 0.429 +- 0.308 (in-sample avg dev_std = 0.569)
NEC for r=1.0 class 2 = 0.533 +- 0.308 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all KL = 0.518 +- 0.308 (in-sample avg dev_std = 0.569)
NEC for r=1.0 all L1 = 0.472 +- 0.164 (in-sample avg dev_std = 0.569)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.516, 0.718, 0.853, 1.0], 'all_L1': [0.559, 0.685, 0.772, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.645, 0.852, 1.0], 'all_L1': [0.552, 0.649, 0.794, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.428, 0.627, 0.838, 1.0], 'all_L1': [0.487, 0.665, 0.801, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.585, 0.794, 0.93, 1.0], 'all_L1': [0.571, 0.71, 0.854, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.378, 0.64, 0.839, 1.0], 'all_L1': [0.505, 0.685, 0.806, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.59, 0.544, 0.461, 0.453], 'all_L1': [0.553, 0.537, 0.467, 0.46]}), defaultdict(<class 'list'>, {'all_KL': [0.619, 0.593, 0.492, 0.494], 'all_L1': [0.558, 0.563, 0.499, 0.501]}), defaultdict(<class 'list'>, {'all_KL': [0.608, 0.635, 0.571, 0.56], 'all_L1': [0.568, 0.572, 0.524, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.481, 0.431, 0.357, 0.347], 'all_L1': [0.501, 0.479, 0.429, 0.418]}), defaultdict(<class 'list'>, {'all_KL': [0.714, 0.618, 0.52, 0.518], 'all_L1': [0.604, 0.536, 0.474, 0.472]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.535 +- 0.033, 0.679 +- 0.021, 0.805 +- 0.027, 1.000 +- 0.000
suff++ class all_KL  =  0.478 +- 0.071, 0.685 +- 0.063, 0.862 +- 0.034, 1.000 +- 0.000
suff++_acc_int  =  0.510 +- 0.048, 0.745 +- 0.020, 0.830 +- 0.014
nec class all_L1  =  0.557 +- 0.033, 0.537 +- 0.032, 0.479 +- 0.032, 0.474 +- 0.035
nec class all_KL  =  0.602 +- 0.074, 0.564 +- 0.073, 0.480 +- 0.071, 0.474 +- 0.073
nec_acc_int  =  0.365 +- 0.021, 0.474 +- 0.019, 0.557 +- 0.025, 0.563 +- 0.023


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.546 +- 0.012, 0.608 +- 0.008, 0.642 +- 0.014, 0.737 +- 0.017
Faith. Armon (L1)= 		  =  0.544 +- 0.013, 0.599 +- 0.014, 0.599 +- 0.022, 0.642 +- 0.032
Faith. GMean (L1)= 	  =  0.545 +- 0.012, 0.603 +- 0.011, 0.620 +- 0.017, 0.688 +- 0.026
Faith. Aritm (KL)= 		  =  0.540 +- 0.013, 0.624 +- 0.007, 0.671 +- 0.021, 0.737 +- 0.036
Faith. Armon (KL)= 		  =  0.524 +- 0.022, 0.611 +- 0.027, 0.612 +- 0.055, 0.640 +- 0.070
Faith. GMean (KL)= 	  =  0.532 +- 0.016, 0.618 +- 0.017, 0.641 +- 0.038, 0.687 +- 0.055
Computed for split load_split = id



Completed in  0:06:09.829379  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:53:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3767
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.3771
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4310
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3978
OOD Test ACCURACY: 0.4087
OOD Test Loss: 27.1216

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9248
Train Loss: 0.3767
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.3771
ID Test ACCURACY: 0.9193
ID Test Loss: 0.4310
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3978
OOD Test ACCURACY: 0.4087
OOD Test Loss: 27.1216

[0m[1;37mINFO[0m: [1mChartInfo 0.9193 0.4087 0.9193 0.4087 0.9243 0.9260[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.508
WIoU for r=0.8 = 0.661


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.93
Model XAI F1 of binarized graphs for r=0.8 =  0.5076662500000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.6609175
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.714
SUFF++ for r=0.8 class 0 = 0.484 +- 0.315 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.8 class 1 = 0.593 +- 0.315 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.8 class 2 = 0.889 +- 0.315 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.8 all KL = 0.628 +- 0.315 (in-sample avg dev_std = 0.504)
SUFF++ for r=0.8 all L1 = 0.66 +- 0.254 (in-sample avg dev_std = 0.504)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.93
Model XAI F1 of binarized graphs for r=0.8 =  0.5076662500000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.6609175
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.452
NEC for r=0.8 class 0 = 0.652 +- 0.234 (in-sample avg dev_std = 0.697)
NEC for r=0.8 class 1 = 0.592 +- 0.234 (in-sample avg dev_std = 0.697)
NEC for r=0.8 class 2 = 0.56 +- 0.234 (in-sample avg dev_std = 0.697)
NEC for r=0.8 all KL = 0.721 +- 0.234 (in-sample avg dev_std = 0.697)
NEC for r=0.8 all L1 = 0.601 +- 0.167 (in-sample avg dev_std = 0.697)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:53:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:53:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ACCURACY: 0.8638
Train Loss: 0.5776
ID Validation ACCURACY: 0.8760
ID Validation Loss: 0.5248
ID Test ACCURACY: 0.8623
ID Test Loss: 0.5892
OOD Validation ACCURACY: 0.8237
OOD Validation Loss: 0.5364
OOD Test ACCURACY: 0.6500
OOD Test Loss: 2.0536

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 84...
[0m[1;37mINFO[0m: [1mCheckpoint 84: 
-----------------------------------
Train ACCURACY: 0.8533
Train Loss: 0.5252
ID Validation ACCURACY: 0.8630
ID Validation Loss: 0.4912
ID Test ACCURACY: 0.8500
ID Test Loss: 0.5371
OOD Validation ACCURACY: 0.8757
OOD Validation Loss: 0.4826
OOD Test ACCURACY: 0.4940
OOD Test Loss: 5.1451

[0m[1;37mINFO[0m: [1mChartInfo 0.8623 0.6500 0.8500 0.4940 0.8630 0.8757[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.508
WIoU for r=0.8 = 0.735


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  0.508
Model XAI WIoU of binarized graphs for r=0.8 =  0.7349525
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.736
SUFF++ for r=0.8 class 0 = 0.625 +- 0.317 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.8 class 1 = 0.909 +- 0.317 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.8 class 2 = 0.67 +- 0.317 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.8 all KL = 0.718 +- 0.317 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.8 all L1 = 0.733 +- 0.252 (in-sample avg dev_std = 0.403)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  0.508
Model XAI WIoU of binarized graphs for r=0.8 =  0.7349525
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.452
NEC for r=0.8 class 0 = 0.589 +- 0.259 (in-sample avg dev_std = 0.725)
NEC for r=0.8 class 1 = 0.461 +- 0.259 (in-sample avg dev_std = 0.725)
NEC for r=0.8 class 2 = 0.652 +- 0.259 (in-sample avg dev_std = 0.725)
NEC for r=0.8 all KL = 0.719 +- 0.259 (in-sample avg dev_std = 0.725)
NEC for r=0.8 all L1 = 0.569 +- 0.198 (in-sample avg dev_std = 0.725)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:54:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9147
Train Loss: 0.4936
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4879
ID Test ACCURACY: 0.9093
ID Test Loss: 0.5467
OOD Validation ACCURACY: 0.8387
OOD Validation Loss: 0.5746
OOD Test ACCURACY: 0.4087
OOD Test Loss: 32.4148

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ACCURACY: 0.8200
Train Loss: 0.6115
ID Validation ACCURACY: 0.8157
ID Validation Loss: 0.6203
ID Test ACCURACY: 0.8157
ID Test Loss: 0.6734
OOD Validation ACCURACY: 0.8897
OOD Validation Loss: 0.4646
OOD Test ACCURACY: 0.3343
OOD Test Loss: 29.0064

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.4087 0.8157 0.3343 0.8157 0.8897[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.511
WIoU for r=0.8 = 0.490


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.92
Model XAI F1 of binarized graphs for r=0.8 =  0.51117625
Model XAI WIoU of binarized graphs for r=0.8 =  0.49030500000000005
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.642
SUFF++ for r=0.8 class 0 = 0.457 +- 0.322 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.8 class 1 = 0.526 +- 0.322 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.8 class 2 = 0.919 +- 0.322 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.8 all KL = 0.623 +- 0.322 (in-sample avg dev_std = 0.514)
SUFF++ for r=0.8 all L1 = 0.639 +- 0.269 (in-sample avg dev_std = 0.514)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.92
Model XAI F1 of binarized graphs for r=0.8 =  0.51117625
Model XAI WIoU of binarized graphs for r=0.8 =  0.49030500000000005
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.47
NEC for r=0.8 class 0 = 0.633 +- 0.239 (in-sample avg dev_std = 0.719)
NEC for r=0.8 class 1 = 0.588 +- 0.239 (in-sample avg dev_std = 0.719)
NEC for r=0.8 class 2 = 0.556 +- 0.239 (in-sample avg dev_std = 0.719)
NEC for r=0.8 all KL = 0.771 +- 0.239 (in-sample avg dev_std = 0.719)
NEC for r=0.8 all L1 = 0.592 +- 0.173 (in-sample avg dev_std = 0.719)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:54:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9185
Train Loss: 0.4761
ID Validation ACCURACY: 0.9243
ID Validation Loss: 0.4624
ID Test ACCURACY: 0.9137
ID Test Loss: 0.5178
OOD Validation ACCURACY: 0.8713
OOD Validation Loss: 0.5049
OOD Test ACCURACY: 0.4087
OOD Test Loss: 34.3607

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.9192
Train Loss: 0.4721
ID Validation ACCURACY: 0.9240
ID Validation Loss: 0.4583
ID Test ACCURACY: 0.9157
ID Test Loss: 0.5307
OOD Validation ACCURACY: 0.9143
OOD Validation Loss: 0.4105
OOD Test ACCURACY: 0.4087
OOD Test Loss: 17.9440

[0m[1;37mINFO[0m: [1mChartInfo 0.9137 0.4087 0.9157 0.4087 0.9240 0.9143[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.513
WIoU for r=0.8 = 0.506


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.921
Model XAI F1 of binarized graphs for r=0.8 =  0.51289875
Model XAI WIoU of binarized graphs for r=0.8 =  0.5059825000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.755
SUFF++ for r=0.8 class 0 = 0.558 +- 0.297 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.8 class 1 = 0.646 +- 0.297 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.8 class 2 = 0.882 +- 0.297 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.8 all KL = 0.68 +- 0.297 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.8 all L1 = 0.699 +- 0.243 (in-sample avg dev_std = 0.446)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.921
Model XAI F1 of binarized graphs for r=0.8 =  0.51289875
Model XAI WIoU of binarized graphs for r=0.8 =  0.5059825000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.459
NEC for r=0.8 class 0 = 0.67 +- 0.240 (in-sample avg dev_std = 0.715)
NEC for r=0.8 class 1 = 0.563 +- 0.240 (in-sample avg dev_std = 0.715)
NEC for r=0.8 class 2 = 0.575 +- 0.240 (in-sample avg dev_std = 0.715)
NEC for r=0.8 all KL = 0.773 +- 0.240 (in-sample avg dev_std = 0.715)
NEC for r=0.8 all L1 = 0.602 +- 0.179 (in-sample avg dev_std = 0.715)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:54:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 10:54:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.8962
Train Loss: 0.4182
ID Validation ACCURACY: 0.9057
ID Validation Loss: 0.4121
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4527
OOD Validation ACCURACY: 0.9027
OOD Validation Loss: 0.4390
OOD Test ACCURACY: 0.4087
OOD Test Loss: 28.0354

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8330
Train Loss: 0.5186
ID Validation ACCURACY: 0.8323
ID Validation Loss: 0.5186
ID Test ACCURACY: 0.8267
ID Test Loss: 0.5417
OOD Validation ACCURACY: 0.9140
OOD Validation Loss: 0.4398
OOD Test ACCURACY: 0.4087
OOD Test Loss: 25.0431

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.4087 0.8267 0.4087 0.8323 0.9140[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.8 = 0.472
WIoU for r=0.8 = 0.655


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.895
Model XAI F1 of binarized graphs for r=0.8 =  0.47186125000000007
Model XAI WIoU of binarized graphs for r=0.8 =  0.6553650000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.593
SUFF++ for r=0.8 class 0 = 0.362 +- 0.325 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.8 class 1 = 0.592 +- 0.325 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.8 class 2 = 0.62 +- 0.325 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.8 all KL = 0.488 +- 0.325 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.8 all L1 = 0.526 +- 0.254 (in-sample avg dev_std = 0.455)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.895
Model XAI F1 of binarized graphs for r=0.8 =  0.47186125000000007
Model XAI WIoU of binarized graphs for r=0.8 =  0.6553650000000001
len(reference) = 800
Effective ratio: 0.812 +- 0.010
Model Accuracy over intervened graphs for r=0.8 =  0.455
NEC for r=0.8 class 0 = 0.639 +- 0.231 (in-sample avg dev_std = 0.691)
NEC for r=0.8 class 1 = 0.577 +- 0.231 (in-sample avg dev_std = 0.691)
NEC for r=0.8 class 2 = 0.62 +- 0.231 (in-sample avg dev_std = 0.691)
NEC for r=0.8 all KL = 0.721 +- 0.231 (in-sample avg dev_std = 0.691)
NEC for r=0.8 all L1 = 0.612 +- 0.147 (in-sample avg dev_std = 0.691)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.628], 'all_L1': [0.66]}), defaultdict(<class 'list'>, {'all_KL': [0.718], 'all_L1': [0.733]}), defaultdict(<class 'list'>, {'all_KL': [0.623], 'all_L1': [0.639]}), defaultdict(<class 'list'>, {'all_KL': [0.68], 'all_L1': [0.699]}), defaultdict(<class 'list'>, {'all_KL': [0.488], 'all_L1': [0.526]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.721], 'all_L1': [0.601]}), defaultdict(<class 'list'>, {'all_KL': [0.719], 'all_L1': [0.569]}), defaultdict(<class 'list'>, {'all_KL': [0.771], 'all_L1': [0.592]}), defaultdict(<class 'list'>, {'all_KL': [0.773], 'all_L1': [0.602]}), defaultdict(<class 'list'>, {'all_KL': [0.721], 'all_L1': [0.612]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.651 +- 0.071
suff++ class all_KL  =  0.627 +- 0.078
suff++_acc_int  =  0.688 +- 0.061
nec class all_L1  =  0.595 +- 0.015
nec class all_KL  =  0.741 +- 0.025
nec_acc_int  =  0.458 +- 0.007


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.623 +- 0.030
Faith. Armon (L1)= 		  =  0.619 +- 0.029
Faith. GMean (L1)= 	  =  0.621 +- 0.030
Faith. Aritm (KL)= 		  =  0.684 +- 0.044
Faith. Armon (KL)= 		  =  0.677 +- 0.051
Faith. GMean (KL)= 	  =  0.681 +- 0.047
Computed for split load_split = id



Completed in  0:01:54.872085  for CIGAGIN GOODMotif2/basis



DONE CIGA GOODMotif2/basis

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:55:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:55:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:55:59 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:03 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:07 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:56:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.8827
Train Loss: 0.3987
ID Validation ACCURACY: 0.8930
ID Validation Loss: 0.3834
ID Test ACCURACY: 0.8840
ID Test Loss: 0.4012
OOD Validation ACCURACY: 0.7283
OOD Validation Loss: 1.1107
OOD Test ACCURACY: 0.3310
OOD Test Loss: 21.6677

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 65...
[0m[1;37mINFO[0m: [1mCheckpoint 65: 
-----------------------------------
Train ACCURACY: 0.8045
Train Loss: 0.7745
ID Validation ACCURACY: 0.8013
ID Validation Loss: 0.7842
ID Test ACCURACY: 0.8077
ID Test Loss: 0.7623
OOD Validation ACCURACY: 0.7757
OOD Validation Loss: 3.1424
OOD Test ACCURACY: 0.3323
OOD Test Loss: 22.8137

[0m[1;37mINFO[0m: [1mChartInfo 0.8840 0.3310 0.8077 0.3323 0.8013 0.7757[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.504
WIoU for r=0.3 = 0.380
F1 for r=0.6 = 0.583
WIoU for r=0.6 = 0.466
F1 for r=0.9 = 0.538
WIoU for r=0.9 = 0.438
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.420


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.367
Model XAI F1 of binarized graphs for r=0.3 =  0.5035925
Model XAI WIoU of binarized graphs for r=0.3 =  0.37988
len(reference) = 765
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.352
SUFF++ for r=0.3 class 0 = 0.754 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 1 = 0.796 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 class 2 = 0.783 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all KL = 0.894 +- 0.134 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.3 all L1 = 0.777 +- 0.141 (in-sample avg dev_std = 0.266)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  0.58298625
Model XAI WIoU of binarized graphs for r=0.6 =  0.46586500000000003
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.492
SUFF++ for r=0.6 class 0 = 0.722 +- 0.229 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 1 = 0.86 +- 0.229 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 2 = 0.735 +- 0.229 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all KL = 0.818 +- 0.229 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all L1 = 0.773 +- 0.201 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.801
Model XAI F1 of binarized graphs for r=0.9 =  0.537875
Model XAI WIoU of binarized graphs for r=0.9 =  0.43775875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.797
SUFF++ for r=0.9 class 0 = 0.768 +- 0.194 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 1 = 0.861 +- 0.194 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 class 2 = 0.832 +- 0.194 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all KL = 0.874 +- 0.194 (in-sample avg dev_std = 0.250)
SUFF++ for r=0.9 all L1 = 0.821 +- 0.214 (in-sample avg dev_std = 0.250)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.369
Model XAI F1 of binarized graphs for r=0.3 =  0.5035925
Model XAI WIoU of binarized graphs for r=0.3 =  0.37988
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.343
NEC for r=0.3 class 0 = 0.28 +- 0.179 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 1 = 0.22 +- 0.179 (in-sample avg dev_std = 0.210)
NEC for r=0.3 class 2 = 0.236 +- 0.179 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all KL = 0.122 +- 0.179 (in-sample avg dev_std = 0.210)
NEC for r=0.3 all L1 = 0.245 +- 0.177 (in-sample avg dev_std = 0.210)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  0.58298625
Model XAI WIoU of binarized graphs for r=0.6 =  0.46586500000000003
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.423
NEC for r=0.6 class 0 = 0.408 +- 0.275 (in-sample avg dev_std = 0.445)
NEC for r=0.6 class 1 = 0.236 +- 0.275 (in-sample avg dev_std = 0.445)
NEC for r=0.6 class 2 = 0.421 +- 0.275 (in-sample avg dev_std = 0.445)
NEC for r=0.6 all KL = 0.317 +- 0.275 (in-sample avg dev_std = 0.445)
NEC for r=0.6 all L1 = 0.354 +- 0.229 (in-sample avg dev_std = 0.445)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.801
Model XAI F1 of binarized graphs for r=0.9 =  0.537875
Model XAI WIoU of binarized graphs for r=0.9 =  0.43775875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.517
NEC for r=0.9 class 0 = 0.614 +- 0.286 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 1 = 0.334 +- 0.286 (in-sample avg dev_std = 0.543)
NEC for r=0.9 class 2 = 0.596 +- 0.286 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all KL = 0.515 +- 0.286 (in-sample avg dev_std = 0.543)
NEC for r=0.9 all L1 = 0.514 +- 0.217 (in-sample avg dev_std = 0.543)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.894
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.42040875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.553
NEC for r=1.0 class 0 = 0.566 +- 0.303 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 1 = 0.327 +- 0.303 (in-sample avg dev_std = 0.562)
NEC for r=1.0 class 2 = 0.552 +- 0.303 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all KL = 0.492 +- 0.303 (in-sample avg dev_std = 0.562)
NEC for r=1.0 all L1 = 0.481 +- 0.223 (in-sample avg dev_std = 0.562)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:57:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:24 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:38 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:40 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:42 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:45 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:57:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.3913
ID Validation ACCURACY: 0.8960
ID Validation Loss: 0.3740
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3923
OOD Validation ACCURACY: 0.6763
OOD Validation Loss: 1.0331
OOD Test ACCURACY: 0.3673
OOD Test Loss: 6.2730

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ACCURACY: 0.8292
Train Loss: 0.6194
ID Validation ACCURACY: 0.8333
ID Validation Loss: 0.6112
ID Test ACCURACY: 0.8327
ID Test Loss: 0.6185
OOD Validation ACCURACY: 0.7947
OOD Validation Loss: 2.4540
OOD Test ACCURACY: 0.3827
OOD Test Loss: 9.6786

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.3673 0.8327 0.3827 0.8333 0.7947[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.503
WIoU for r=0.3 = 0.378
F1 for r=0.6 = 0.578
WIoU for r=0.6 = 0.463
F1 for r=0.9 = 0.535
WIoU for r=0.9 = 0.445
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.432


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.374
Model XAI F1 of binarized graphs for r=0.3 =  0.50318625
Model XAI WIoU of binarized graphs for r=0.3 =  0.37834625000000005
len(reference) = 746
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.359
SUFF++ for r=0.3 class 0 = 0.789 +- 0.143 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 1 = 0.816 +- 0.143 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 2 = 0.801 +- 0.143 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all KL = 0.911 +- 0.143 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all L1 = 0.802 +- 0.126 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.569
Model XAI F1 of binarized graphs for r=0.6 =  0.5783450000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.46326
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.52
SUFF++ for r=0.6 class 0 = 0.67 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.806 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.705 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.759 +- 0.249 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.727 +- 0.198 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  0.5346175
Model XAI WIoU of binarized graphs for r=0.9 =  0.44534375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.773
SUFF++ for r=0.9 class 0 = 0.803 +- 0.215 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 1 = 0.883 +- 0.215 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 class 2 = 0.816 +- 0.215 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all KL = 0.863 +- 0.215 (in-sample avg dev_std = 0.304)
SUFF++ for r=0.9 all L1 = 0.834 +- 0.203 (in-sample avg dev_std = 0.304)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.371
Model XAI F1 of binarized graphs for r=0.3 =  0.50318625
Model XAI WIoU of binarized graphs for r=0.3 =  0.37834625000000005
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.218 +- 0.181 (in-sample avg dev_std = 0.185)
NEC for r=0.3 class 1 = 0.19 +- 0.181 (in-sample avg dev_std = 0.185)
NEC for r=0.3 class 2 = 0.19 +- 0.181 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all KL = 0.096 +- 0.181 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all L1 = 0.199 +- 0.166 (in-sample avg dev_std = 0.185)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.569
Model XAI F1 of binarized graphs for r=0.6 =  0.5783450000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.46326
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.417
NEC for r=0.6 class 0 = 0.456 +- 0.308 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 1 = 0.287 +- 0.308 (in-sample avg dev_std = 0.456)
NEC for r=0.6 class 2 = 0.46 +- 0.308 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all KL = 0.361 +- 0.308 (in-sample avg dev_std = 0.456)
NEC for r=0.6 all L1 = 0.4 +- 0.230 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  0.5346175
Model XAI WIoU of binarized graphs for r=0.9 =  0.44534375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.493
NEC for r=0.9 class 0 = 0.59 +- 0.290 (in-sample avg dev_std = 0.597)
NEC for r=0.9 class 1 = 0.349 +- 0.290 (in-sample avg dev_std = 0.597)
NEC for r=0.9 class 2 = 0.559 +- 0.290 (in-sample avg dev_std = 0.597)
NEC for r=0.9 all KL = 0.531 +- 0.290 (in-sample avg dev_std = 0.597)
NEC for r=0.9 all L1 = 0.499 +- 0.209 (in-sample avg dev_std = 0.597)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.904
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.43184
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.536
NEC for r=1.0 class 0 = 0.592 +- 0.299 (in-sample avg dev_std = 0.610)
NEC for r=1.0 class 1 = 0.361 +- 0.299 (in-sample avg dev_std = 0.610)
NEC for r=1.0 class 2 = 0.554 +- 0.299 (in-sample avg dev_std = 0.610)
NEC for r=1.0 all KL = 0.541 +- 0.299 (in-sample avg dev_std = 0.610)
NEC for r=1.0 all L1 = 0.501 +- 0.211 (in-sample avg dev_std = 0.610)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 22:58:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 10:58:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:12 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:14 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:18 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:24 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:24 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 10:59:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3014
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.2957
ID Test ACCURACY: 0.9313
ID Test Loss: 0.3056
OOD Validation ACCURACY: 0.8693
OOD Validation Loss: 0.4349
OOD Test ACCURACY: 0.4197
OOD Test Loss: 3.0359

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.9283
Train Loss: 0.3001
ID Validation ACCURACY: 0.9340
ID Validation Loss: 0.2878
ID Test ACCURACY: 0.9307
ID Test Loss: 0.3011
OOD Validation ACCURACY: 0.9180
OOD Validation Loss: 0.3532
OOD Test ACCURACY: 0.4307
OOD Test Loss: 2.2044

[0m[1;37mINFO[0m: [1mChartInfo 0.9313 0.4197 0.9307 0.4307 0.9340 0.9180[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.593
WIoU for r=0.3 = 0.478
F1 for r=0.6 = 0.625
WIoU for r=0.6 = 0.594
F1 for r=0.9 = 0.532
WIoU for r=0.9 = 0.597
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.597


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.404
Model XAI F1 of binarized graphs for r=0.3 =  0.592795
Model XAI WIoU of binarized graphs for r=0.3 =  0.47816374999999994
len(reference) = 774
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.365
SUFF++ for r=0.3 class 0 = 0.847 +- 0.213 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 class 1 = 0.923 +- 0.213 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 class 2 = 0.843 +- 0.213 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all KL = 0.895 +- 0.213 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.3 all L1 = 0.871 +- 0.180 (in-sample avg dev_std = 0.294)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  0.62505875
Model XAI WIoU of binarized graphs for r=0.6 =  0.593855
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.74 +- 0.233 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 class 1 = 0.861 +- 0.233 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 class 2 = 0.759 +- 0.233 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 all KL = 0.799 +- 0.233 (in-sample avg dev_std = 0.431)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.204 (in-sample avg dev_std = 0.431)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  0.53213125
Model XAI WIoU of binarized graphs for r=0.9 =  0.59742875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.798
SUFF++ for r=0.9 class 0 = 0.839 +- 0.175 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 1 = 0.925 +- 0.175 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 class 2 = 0.909 +- 0.175 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all KL = 0.912 +- 0.175 (in-sample avg dev_std = 0.266)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.172 (in-sample avg dev_std = 0.266)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.404
Model XAI F1 of binarized graphs for r=0.3 =  0.592795
Model XAI WIoU of binarized graphs for r=0.3 =  0.47816374999999994
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.173 +- 0.247 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 1 = 0.119 +- 0.247 (in-sample avg dev_std = 0.159)
NEC for r=0.3 class 2 = 0.179 +- 0.247 (in-sample avg dev_std = 0.159)
NEC for r=0.3 all KL = 0.111 +- 0.247 (in-sample avg dev_std = 0.159)
NEC for r=0.3 all L1 = 0.157 +- 0.225 (in-sample avg dev_std = 0.159)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.676
Model XAI F1 of binarized graphs for r=0.6 =  0.62505875
Model XAI WIoU of binarized graphs for r=0.6 =  0.593855
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.398
NEC for r=0.6 class 0 = 0.528 +- 0.371 (in-sample avg dev_std = 0.478)
NEC for r=0.6 class 1 = 0.251 +- 0.371 (in-sample avg dev_std = 0.478)
NEC for r=0.6 class 2 = 0.52 +- 0.371 (in-sample avg dev_std = 0.478)
NEC for r=0.6 all KL = 0.441 +- 0.371 (in-sample avg dev_std = 0.478)
NEC for r=0.6 all L1 = 0.432 +- 0.290 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  0.53213125
Model XAI WIoU of binarized graphs for r=0.9 =  0.59742875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.494
NEC for r=0.9 class 0 = 0.627 +- 0.331 (in-sample avg dev_std = 0.600)
NEC for r=0.9 class 1 = 0.276 +- 0.331 (in-sample avg dev_std = 0.600)
NEC for r=0.9 class 2 = 0.587 +- 0.331 (in-sample avg dev_std = 0.600)
NEC for r=0.9 all KL = 0.549 +- 0.331 (in-sample avg dev_std = 0.600)
NEC for r=0.9 all L1 = 0.495 +- 0.259 (in-sample avg dev_std = 0.600)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.938
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.596785
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.547
NEC for r=1.0 class 0 = 0.622 +- 0.336 (in-sample avg dev_std = 0.645)
NEC for r=1.0 class 1 = 0.253 +- 0.336 (in-sample avg dev_std = 0.645)
NEC for r=1.0 class 2 = 0.597 +- 0.336 (in-sample avg dev_std = 0.645)
NEC for r=1.0 all KL = 0.569 +- 0.336 (in-sample avg dev_std = 0.645)
NEC for r=1.0 all L1 = 0.489 +- 0.264 (in-sample avg dev_std = 0.645)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:00:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:32 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:45 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:47 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:49 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:00:59 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 123...
[0m[1;37mINFO[0m: [1mCheckpoint 123: 
-----------------------------------
Train ACCURACY: 0.9266
Train Loss: 0.3084
ID Validation ACCURACY: 0.9333
ID Validation Loss: 0.2927
ID Test ACCURACY: 0.9300
ID Test Loss: 0.3020
OOD Validation ACCURACY: 0.7857
OOD Validation Loss: 0.8791
OOD Test ACCURACY: 0.5160
OOD Test Loss: 2.9408

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.9069
Train Loss: 0.3431
ID Validation ACCURACY: 0.9113
ID Validation Loss: 0.3325
ID Test ACCURACY: 0.9107
ID Test Loss: 0.3433
OOD Validation ACCURACY: 0.8867
OOD Validation Loss: 0.4057
OOD Test ACCURACY: 0.5663
OOD Test Loss: 1.7709

[0m[1;37mINFO[0m: [1mChartInfo 0.9300 0.5160 0.9107 0.5663 0.9113 0.8867[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.425
WIoU for r=0.3 = 0.365
F1 for r=0.6 = 0.434
WIoU for r=0.6 = 0.376
F1 for r=0.9 = 0.476
WIoU for r=0.9 = 0.416
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.419


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.466
Model XAI F1 of binarized graphs for r=0.3 =  0.42458125
Model XAI WIoU of binarized graphs for r=0.3 =  0.36473875
len(reference) = 792
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.411
SUFF++ for r=0.3 class 0 = 0.578 +- 0.324 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.3 class 1 = 0.778 +- 0.324 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.3 class 2 = 0.744 +- 0.324 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.3 all KL = 0.695 +- 0.324 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.3 all L1 = 0.699 +- 0.284 (in-sample avg dev_std = 0.434)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.581
Model XAI F1 of binarized graphs for r=0.6 =  0.43358374999999993
Model XAI WIoU of binarized graphs for r=0.6 =  0.37583
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.47
SUFF++ for r=0.6 class 0 = 0.381 +- 0.274 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 class 1 = 0.613 +- 0.274 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 class 2 = 0.547 +- 0.274 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 all KL = 0.52 +- 0.274 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 all L1 = 0.513 +- 0.226 (in-sample avg dev_std = 0.535)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47570999999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.4158725
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.738
SUFF++ for r=0.9 class 0 = 0.637 +- 0.291 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.9 class 1 = 0.759 +- 0.291 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.9 class 2 = 0.717 +- 0.291 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.9 all KL = 0.693 +- 0.291 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.9 all L1 = 0.704 +- 0.242 (in-sample avg dev_std = 0.508)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.465
Model XAI F1 of binarized graphs for r=0.3 =  0.42458125
Model XAI WIoU of binarized graphs for r=0.3 =  0.36473875
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.355
NEC for r=0.3 class 0 = 0.473 +- 0.362 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 1 = 0.213 +- 0.362 (in-sample avg dev_std = 0.384)
NEC for r=0.3 class 2 = 0.369 +- 0.362 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all KL = 0.359 +- 0.362 (in-sample avg dev_std = 0.384)
NEC for r=0.3 all L1 = 0.351 +- 0.317 (in-sample avg dev_std = 0.384)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.585
Model XAI F1 of binarized graphs for r=0.6 =  0.43358374999999993
Model XAI WIoU of binarized graphs for r=0.6 =  0.37583
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.436
NEC for r=0.6 class 0 = 0.637 +- 0.310 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 1 = 0.34 +- 0.310 (in-sample avg dev_std = 0.515)
NEC for r=0.6 class 2 = 0.557 +- 0.310 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all KL = 0.512 +- 0.310 (in-sample avg dev_std = 0.515)
NEC for r=0.6 all L1 = 0.511 +- 0.251 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.47570999999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.4158725
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.541
NEC for r=0.9 class 0 = 0.613 +- 0.325 (in-sample avg dev_std = 0.625)
NEC for r=0.9 class 1 = 0.253 +- 0.325 (in-sample avg dev_std = 0.625)
NEC for r=0.9 class 2 = 0.594 +- 0.325 (in-sample avg dev_std = 0.625)
NEC for r=0.9 all KL = 0.548 +- 0.325 (in-sample avg dev_std = 0.625)
NEC for r=0.9 all L1 = 0.485 +- 0.259 (in-sample avg dev_std = 0.625)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.4187075
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.558
NEC for r=1.0 class 0 = 0.601 +- 0.301 (in-sample avg dev_std = 0.675)
NEC for r=1.0 class 1 = 0.282 +- 0.301 (in-sample avg dev_std = 0.675)
NEC for r=1.0 class 2 = 0.591 +- 0.301 (in-sample avg dev_std = 0.675)
NEC for r=1.0 all KL = 0.574 +- 0.301 (in-sample avg dev_std = 0.675)
NEC for r=1.0 all L1 = 0.49 +- 0.236 (in-sample avg dev_std = 0.675)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:02:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:06 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:18 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:26 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:02:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 112...
[0m[1;37mINFO[0m: [1mCheckpoint 112: 
-----------------------------------
Train ACCURACY: 0.9028
Train Loss: 0.3784
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.3693
ID Test ACCURACY: 0.9047
ID Test Loss: 0.3724
OOD Validation ACCURACY: 0.8107
OOD Validation Loss: 0.5547
OOD Test ACCURACY: 0.4367
OOD Test Loss: 3.7916

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ACCURACY: 0.8753
Train Loss: 0.4256
ID Validation ACCURACY: 0.8767
ID Validation Loss: 0.4180
ID Test ACCURACY: 0.8850
ID Test Loss: 0.4110
OOD Validation ACCURACY: 0.8257
OOD Validation Loss: 0.5473
OOD Test ACCURACY: 0.6033
OOD Test Loss: 1.3601

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.4367 0.8850 0.6033 0.8767 0.8257[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.330
WIoU for r=0.3 = 0.252
F1 for r=0.6 = 0.427
WIoU for r=0.6 = 0.324
F1 for r=0.9 = 0.510
WIoU for r=0.9 = 0.405
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.407


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.332
Model XAI F1 of binarized graphs for r=0.3 =  0.3295225
Model XAI WIoU of binarized graphs for r=0.3 =  0.25154375
len(reference) = 792
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.341
SUFF++ for r=0.3 class 0 = 0.736 +- 0.161 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 1 = 0.759 +- 0.161 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 2 = 0.776 +- 0.161 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 all KL = 0.862 +- 0.161 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 all L1 = 0.757 +- 0.148 (in-sample avg dev_std = 0.317)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.411
Model XAI F1 of binarized graphs for r=0.6 =  0.42664
Model XAI WIoU of binarized graphs for r=0.6 =  0.324205
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.406
SUFF++ for r=0.6 class 0 = 0.558 +- 0.261 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 1 = 0.635 +- 0.261 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 class 2 = 0.569 +- 0.261 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all KL = 0.634 +- 0.261 (in-sample avg dev_std = 0.520)
SUFF++ for r=0.6 all L1 = 0.588 +- 0.193 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.729
Model XAI F1 of binarized graphs for r=0.9 =  0.5104925
Model XAI WIoU of binarized graphs for r=0.9 =  0.40545875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.655
SUFF++ for r=0.9 class 0 = 0.584 +- 0.298 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.9 class 1 = 0.814 +- 0.298 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.9 class 2 = 0.61 +- 0.298 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.9 all KL = 0.681 +- 0.298 (in-sample avg dev_std = 0.469)
SUFF++ for r=0.9 all L1 = 0.67 +- 0.266 (in-sample avg dev_std = 0.469)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.33
Model XAI F1 of binarized graphs for r=0.3 =  0.3295225
Model XAI WIoU of binarized graphs for r=0.3 =  0.25154375
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.298
NEC for r=0.3 class 0 = 0.247 +- 0.182 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 1 = 0.214 +- 0.182 (in-sample avg dev_std = 0.195)
NEC for r=0.3 class 2 = 0.204 +- 0.182 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all KL = 0.112 +- 0.182 (in-sample avg dev_std = 0.195)
NEC for r=0.3 all L1 = 0.222 +- 0.185 (in-sample avg dev_std = 0.195)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.412
Model XAI F1 of binarized graphs for r=0.6 =  0.42664
Model XAI WIoU of binarized graphs for r=0.6 =  0.324205
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.384
NEC for r=0.6 class 0 = 0.461 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 1 = 0.379 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.6 class 2 = 0.447 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all KL = 0.378 +- 0.297 (in-sample avg dev_std = 0.475)
NEC for r=0.6 all L1 = 0.429 +- 0.221 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.5104925
Model XAI WIoU of binarized graphs for r=0.9 =  0.40545875000000003
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.491
NEC for r=0.9 class 0 = 0.631 +- 0.313 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 1 = 0.27 +- 0.313 (in-sample avg dev_std = 0.550)
NEC for r=0.9 class 2 = 0.608 +- 0.313 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all KL = 0.508 +- 0.313 (in-sample avg dev_std = 0.550)
NEC for r=0.9 all L1 = 0.501 +- 0.245 (in-sample avg dev_std = 0.550)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.40675125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.561
NEC for r=1.0 class 0 = 0.596 +- 0.326 (in-sample avg dev_std = 0.603)
NEC for r=1.0 class 1 = 0.239 +- 0.326 (in-sample avg dev_std = 0.603)
NEC for r=1.0 class 2 = 0.595 +- 0.326 (in-sample avg dev_std = 0.603)
NEC for r=1.0 all KL = 0.517 +- 0.326 (in-sample avg dev_std = 0.603)
NEC for r=1.0 all L1 = 0.475 +- 0.249 (in-sample avg dev_std = 0.603)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.894, 0.818, 0.874, 1.0], 'all_L1': [0.777, 0.773, 0.821, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.911, 0.759, 0.863, 1.0], 'all_L1': [0.802, 0.727, 0.834, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.895, 0.799, 0.912, 1.0], 'all_L1': [0.871, 0.787, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.695, 0.52, 0.693, 1.0], 'all_L1': [0.699, 0.513, 0.704, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.862, 0.634, 0.681, 1.0], 'all_L1': [0.757, 0.588, 0.67, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.122, 0.317, 0.515, 0.492], 'all_L1': [0.245, 0.354, 0.514, 0.481]}), defaultdict(<class 'list'>, {'all_KL': [0.096, 0.361, 0.531, 0.541], 'all_L1': [0.199, 0.4, 0.499, 0.501]}), defaultdict(<class 'list'>, {'all_KL': [0.111, 0.441, 0.549, 0.569], 'all_L1': [0.157, 0.432, 0.495, 0.489]}), defaultdict(<class 'list'>, {'all_KL': [0.359, 0.512, 0.548, 0.574], 'all_L1': [0.351, 0.511, 0.485, 0.49]}), defaultdict(<class 'list'>, {'all_KL': [0.112, 0.378, 0.508, 0.517], 'all_L1': [0.222, 0.429, 0.501, 0.475]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.781 +- 0.056, 0.678 +- 0.108, 0.784 +- 0.083, 1.000 +- 0.000
suff++ class all_KL  =  0.851 +- 0.080, 0.706 +- 0.113, 0.805 +- 0.097, 1.000 +- 0.000
suff++_acc_int  =  0.366 +- 0.024, 0.503 +- 0.073, 0.752 +- 0.053
nec class all_L1  =  0.235 +- 0.065, 0.425 +- 0.051, 0.499 +- 0.009, 0.487 +- 0.009
nec class all_KL  =  0.160 +- 0.100, 0.402 +- 0.068, 0.530 +- 0.017, 0.539 +- 0.031
nec_acc_int  =  0.336 +- 0.020, 0.412 +- 0.019, 0.507 +- 0.019, 0.551 +- 0.009


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.508 +- 0.012, 0.551 +- 0.038, 0.641 +- 0.043, 0.744 +- 0.004
Faith. Armon (L1)= 		  =  0.354 +- 0.067, 0.514 +- 0.025, 0.608 +- 0.028, 0.655 +- 0.008
Faith. GMean (L1)= 	  =  0.422 +- 0.042, 0.532 +- 0.028, 0.625 +- 0.035, 0.698 +- 0.006
Faith. Aritm (KL)= 		  =  0.506 +- 0.013, 0.554 +- 0.041, 0.667 +- 0.051, 0.769 +- 0.016
Faith. Armon (KL)= 		  =  0.252 +- 0.112, 0.501 +- 0.039, 0.637 +- 0.036, 0.700 +- 0.026
Faith. GMean (KL)= 	  =  0.350 +- 0.075, 0.526 +- 0.035, 0.652 +- 0.043, 0.734 +- 0.021
Computed for split load_split = id



Completed in  0:07:55.238732  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:04:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:09 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:22 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:23 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:29 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 48...
[0m[1;37mINFO[0m: [1mCheckpoint 48: 
-----------------------------------
Train ACCURACY: 0.8899
Train Loss: 0.5257
ID Validation ACCURACY: 0.8960
ID Validation Loss: 0.4847
ID Test ACCURACY: 0.8937
ID Test Loss: 0.5229
OOD Validation ACCURACY: 0.6193
OOD Validation Loss: 1.1712
OOD Test ACCURACY: 0.4250
OOD Test Loss: 6.2644

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 79...
[0m[1;37mINFO[0m: [1mCheckpoint 79: 
-----------------------------------
Train ACCURACY: 0.8699
Train Loss: 0.5291
ID Validation ACCURACY: 0.8790
ID Validation Loss: 0.4662
ID Test ACCURACY: 0.8723
ID Test Loss: 0.5479
OOD Validation ACCURACY: 0.7500
OOD Validation Loss: 0.6795
OOD Test ACCURACY: 0.4680
OOD Test Loss: 3.3662

[0m[1;37mINFO[0m: [1mChartInfo 0.8937 0.4250 0.8723 0.4680 0.8790 0.7500[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.8 = 0.532
WIoU for r=0.8 = 0.535


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.902
Model XAI F1 of binarized graphs for r=0.8 =  0.53205125
Model XAI WIoU of binarized graphs for r=0.8 =  0.5353112499999999
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.719
SUFF++ for r=0.8 class 0 = 0.538 +- 0.371 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 class 1 = 0.721 +- 0.371 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 class 2 = 0.802 +- 0.371 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 all KL = 0.62 +- 0.371 (in-sample avg dev_std = 0.501)
SUFF++ for r=0.8 all L1 = 0.686 +- 0.277 (in-sample avg dev_std = 0.501)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.902
Model XAI F1 of binarized graphs for r=0.8 =  0.53205125
Model XAI WIoU of binarized graphs for r=0.8 =  0.5353112499999999
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.445
NEC for r=0.8 class 0 = 0.586 +- 0.261 (in-sample avg dev_std = 0.660)
NEC for r=0.8 class 1 = 0.595 +- 0.261 (in-sample avg dev_std = 0.660)
NEC for r=0.8 class 2 = 0.595 +- 0.261 (in-sample avg dev_std = 0.660)
NEC for r=0.8 all KL = 0.744 +- 0.261 (in-sample avg dev_std = 0.660)
NEC for r=0.8 all L1 = 0.592 +- 0.190 (in-sample avg dev_std = 0.660)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:04:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 11:04:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:18 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 44...
[0m[1;37mINFO[0m: [1mCheckpoint 44: 
-----------------------------------
Train ACCURACY: 0.8903
Train Loss: 0.5320
ID Validation ACCURACY: 0.8943
ID Validation Loss: 0.4871
ID Test ACCURACY: 0.8910
ID Test Loss: 0.5314
OOD Validation ACCURACY: 0.6970
OOD Validation Loss: 0.9031
OOD Test ACCURACY: 0.5007
OOD Test Loss: 6.0511

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.8831
Train Loss: 0.5175
ID Validation ACCURACY: 0.8833
ID Validation Loss: 0.4767
ID Test ACCURACY: 0.8860
ID Test Loss: 0.5135
OOD Validation ACCURACY: 0.7723
OOD Validation Loss: 0.6911
OOD Test ACCURACY: 0.4477
OOD Test Loss: 2.0349

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.5007 0.8860 0.4477 0.8833 0.7723[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.8 = 0.518
WIoU for r=0.8 = 0.514


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.892
Model XAI F1 of binarized graphs for r=0.8 =  0.5179962499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.51411125
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.694
SUFF++ for r=0.8 class 0 = 0.522 +- 0.380 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.8 class 1 = 0.7 +- 0.380 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.8 class 2 = 0.796 +- 0.380 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.8 all KL = 0.601 +- 0.380 (in-sample avg dev_std = 0.461)
SUFF++ for r=0.8 all L1 = 0.672 +- 0.286 (in-sample avg dev_std = 0.461)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.892
Model XAI F1 of binarized graphs for r=0.8 =  0.5179962499999999
Model XAI WIoU of binarized graphs for r=0.8 =  0.51411125
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.443
NEC for r=0.8 class 0 = 0.598 +- 0.252 (in-sample avg dev_std = 0.672)
NEC for r=0.8 class 1 = 0.609 +- 0.252 (in-sample avg dev_std = 0.672)
NEC for r=0.8 class 2 = 0.593 +- 0.252 (in-sample avg dev_std = 0.672)
NEC for r=0.8 all KL = 0.76 +- 0.252 (in-sample avg dev_std = 0.672)
NEC for r=0.8 all L1 = 0.6 +- 0.181 (in-sample avg dev_std = 0.672)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:05:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:45 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:57 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 11:05:59 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:01 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:05 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 64...
[0m[1;37mINFO[0m: [1mCheckpoint 64: 
-----------------------------------
Train ACCURACY: 0.8937
Train Loss: 0.5698
ID Validation ACCURACY: 0.9000
ID Validation Loss: 0.5288
ID Test ACCURACY: 0.8943
ID Test Loss: 0.5798
OOD Validation ACCURACY: 0.6730
OOD Validation Loss: 1.3851
OOD Test ACCURACY: 0.4563
OOD Test Loss: 4.4608

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.8583
Train Loss: 0.7164
ID Validation ACCURACY: 0.8650
ID Validation Loss: 0.6880
ID Test ACCURACY: 0.8517
ID Test Loss: 0.7220
OOD Validation ACCURACY: 0.7457
OOD Validation Loss: 1.4504
OOD Test ACCURACY: 0.4083
OOD Test Loss: 6.2487

[0m[1;37mINFO[0m: [1mChartInfo 0.8943 0.4563 0.8517 0.4083 0.8650 0.7457[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.8 = 0.532
WIoU for r=0.8 = 0.524


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.902
Model XAI F1 of binarized graphs for r=0.8 =  0.5317475
Model XAI WIoU of binarized graphs for r=0.8 =  0.52396
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.725
SUFF++ for r=0.8 class 0 = 0.542 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 class 1 = 0.769 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 class 2 = 0.826 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 all KL = 0.645 +- 0.369 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.8 all L1 = 0.712 +- 0.288 (in-sample avg dev_std = 0.444)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.902
Model XAI F1 of binarized graphs for r=0.8 =  0.5317475
Model XAI WIoU of binarized graphs for r=0.8 =  0.52396
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.437
NEC for r=0.8 class 0 = 0.593 +- 0.247 (in-sample avg dev_std = 0.702)
NEC for r=0.8 class 1 = 0.632 +- 0.247 (in-sample avg dev_std = 0.702)
NEC for r=0.8 class 2 = 0.61 +- 0.247 (in-sample avg dev_std = 0.702)
NEC for r=0.8 all KL = 0.795 +- 0.247 (in-sample avg dev_std = 0.702)
NEC for r=0.8 all L1 = 0.612 +- 0.189 (in-sample avg dev_std = 0.702)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:06:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:31 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:45 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:51 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 11:06:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 27...
[0m[1;37mINFO[0m: [1mCheckpoint 27: 
-----------------------------------
Train ACCURACY: 0.8753
Train Loss: 0.5158
ID Validation ACCURACY: 0.8807
ID Validation Loss: 0.4789
ID Test ACCURACY: 0.8773
ID Test Loss: 0.5165
OOD Validation ACCURACY: 0.6493
OOD Validation Loss: 1.1427
OOD Test ACCURACY: 0.4040
OOD Test Loss: 2.8675

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ACCURACY: 0.8559
Train Loss: 0.5232
ID Validation ACCURACY: 0.8650
ID Validation Loss: 0.4809
ID Test ACCURACY: 0.8633
ID Test Loss: 0.5159
OOD Validation ACCURACY: 0.7123
OOD Validation Loss: 0.8312
OOD Test ACCURACY: 0.3543
OOD Test Loss: 8.7485

[0m[1;37mINFO[0m: [1mChartInfo 0.8773 0.4040 0.8633 0.3543 0.8650 0.7123[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.8 = 0.554
WIoU for r=0.8 = 0.583


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.877
Model XAI F1 of binarized graphs for r=0.8 =  0.5541825
Model XAI WIoU of binarized graphs for r=0.8 =  0.5828375
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.753
SUFF++ for r=0.8 class 0 = 0.688 +- 0.294 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.8 class 1 = 0.602 +- 0.294 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.8 class 2 = 0.875 +- 0.294 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.8 all KL = 0.715 +- 0.294 (in-sample avg dev_std = 0.387)
SUFF++ for r=0.8 all L1 = 0.72 +- 0.239 (in-sample avg dev_std = 0.387)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.877
Model XAI F1 of binarized graphs for r=0.8 =  0.5541825
Model XAI WIoU of binarized graphs for r=0.8 =  0.5828375
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.438
NEC for r=0.8 class 0 = 0.602 +- 0.258 (in-sample avg dev_std = 0.617)
NEC for r=0.8 class 1 = 0.602 +- 0.258 (in-sample avg dev_std = 0.617)
NEC for r=0.8 class 2 = 0.602 +- 0.258 (in-sample avg dev_std = 0.617)
NEC for r=0.8 all KL = 0.704 +- 0.258 (in-sample avg dev_std = 0.617)
NEC for r=0.8 all L1 = 0.602 +- 0.165 (in-sample avg dev_std = 0.617)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:07:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:18 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:31 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:33 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:35 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:38 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/07/2024 11:07:45 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 37...
[0m[1;37mINFO[0m: [1mCheckpoint 37: 
-----------------------------------
Train ACCURACY: 0.8598
Train Loss: 0.5187
ID Validation ACCURACY: 0.8710
ID Validation Loss: 0.4867
ID Test ACCURACY: 0.8650
ID Test Loss: 0.5182
OOD Validation ACCURACY: 0.6850
OOD Validation Loss: 0.7691
OOD Test ACCURACY: 0.3613
OOD Test Loss: 3.5062

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 48...
[0m[1;37mINFO[0m: [1mCheckpoint 48: 
-----------------------------------
Train ACCURACY: 0.8180
Train Loss: 0.7026
ID Validation ACCURACY: 0.8267
ID Validation Loss: 0.6541
ID Test ACCURACY: 0.8193
ID Test Loss: 0.6900
OOD Validation ACCURACY: 0.8000
OOD Validation Loss: 0.6826
OOD Test ACCURACY: 0.4330
OOD Test Loss: 1.3960

[0m[1;37mINFO[0m: [1mChartInfo 0.8650 0.3613 0.8193 0.4330 0.8267 0.8000[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.8 = 0.576
WIoU for r=0.8 = 0.721


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.875
Model XAI F1 of binarized graphs for r=0.8 =  0.5763925000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.7209362500000001
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.798
SUFF++ for r=0.8 class 0 = 0.744 +- 0.221 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 1 = 0.779 +- 0.221 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 class 2 = 0.844 +- 0.221 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all KL = 0.84 +- 0.221 (in-sample avg dev_std = 0.300)
SUFF++ for r=0.8 all L1 = 0.789 +- 0.203 (in-sample avg dev_std = 0.300)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.875
Model XAI F1 of binarized graphs for r=0.8 =  0.5763925000000001
Model XAI WIoU of binarized graphs for r=0.8 =  0.7209362500000001
len(reference) = 800
Effective ratio: 0.813 +- 0.012
Model Accuracy over intervened graphs for r=0.8 =  0.482
NEC for r=0.8 class 0 = 0.646 +- 0.325 (in-sample avg dev_std = 0.529)
NEC for r=0.8 class 1 = 0.365 +- 0.325 (in-sample avg dev_std = 0.529)
NEC for r=0.8 class 2 = 0.623 +- 0.325 (in-sample avg dev_std = 0.529)
NEC for r=0.8 all KL = 0.589 +- 0.325 (in-sample avg dev_std = 0.529)
NEC for r=0.8 all L1 = 0.544 +- 0.231 (in-sample avg dev_std = 0.529)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.62], 'all_L1': [0.686]}), defaultdict(<class 'list'>, {'all_KL': [0.601], 'all_L1': [0.672]}), defaultdict(<class 'list'>, {'all_KL': [0.645], 'all_L1': [0.712]}), defaultdict(<class 'list'>, {'all_KL': [0.715], 'all_L1': [0.72]}), defaultdict(<class 'list'>, {'all_KL': [0.84], 'all_L1': [0.789]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.744], 'all_L1': [0.592]}), defaultdict(<class 'list'>, {'all_KL': [0.76], 'all_L1': [0.6]}), defaultdict(<class 'list'>, {'all_KL': [0.795], 'all_L1': [0.612]}), defaultdict(<class 'list'>, {'all_KL': [0.704], 'all_L1': [0.602]}), defaultdict(<class 'list'>, {'all_KL': [0.589], 'all_L1': [0.544]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.716 +- 0.040
suff++ class all_KL  =  0.684 +- 0.087
suff++_acc_int  =  0.738 +- 0.035
nec class all_L1  =  0.590 +- 0.024
nec class all_KL  =  0.718 +- 0.071
nec_acc_int  =  0.449 +- 0.017


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.653 +- 0.013
Faith. Armon (L1)= 		  =  0.645 +- 0.010
Faith. GMean (L1)= 	  =  0.649 +- 0.011
Faith. Aritm (KL)= 		  =  0.701 +- 0.017
Faith. Armon (KL)= 		  =  0.692 +- 0.017
Faith. GMean (KL)= 	  =  0.697 +- 0.016
Computed for split load_split = id



Completed in  0:03:57.345484  for CIGAGIN GOODMotif/size



DONE CIGA GOODMotif/size

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Tue May  7 23:08:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/07/2024 11:08:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0002
ID Validation ACCURACY: 0.9210
ID Validation Loss: 0.4334
ID Test ACCURACY: 0.9151
ID Test Loss: 0.4930
OOD Validation ACCURACY: 0.8823
OOD Validation Loss: 0.6328
OOD Test ACCURACY: 0.8311
OOD Test Loss: 1.1309

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 162...
[0m[1;37mINFO[0m: [1mCheckpoint 162: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0004
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.4056
ID Test ACCURACY: 0.9130
ID Test Loss: 0.4650
OOD Validation ACCURACY: 0.8837
OOD Validation Loss: 0.6111
OOD Test ACCURACY: 0.8308
OOD Test Loss: 1.1121

[0m[1;37mINFO[0m: [1mChartInfo 0.9151 0.8311 0.9130 0.8308 0.9172 0.8837[0mGOODSST2(5301)
Data example from id_test: Data(x=[5, 768], edge_index=[2, 8], y=[1, 1], idx=[1], sentence_tokens=[5], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_test: (tensor([0., 1.]), tensor([2181, 3120]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


[1;31mERROR[0m: 05/07/2024 11:08:43 PM - utils.py - line 87 : [1mTraceback (most recent call last):
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 625, in goodtg
    main()
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 525, in main
    evaluate_metric(args)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 321, in evaluate_metric
    score, acc_int, results = pipeline.compute_metric_ratio(
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/pipelines/basic_pipeline.py", line 877, in compute_metric_ratio
    causal_subgraphs_r[ratio][j],
IndexError: list index out of range
[0m
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:46:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:44 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:46 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:46 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:46 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:48 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:46:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 35...
[0m[1;37mINFO[0m: [1mCheckpoint 35: 
-----------------------------------
Train ACCURACY: 0.9819
Train Loss: 0.0593
ID Validation ACCURACY: 0.6877
ID Validation Loss: 1.6620
ID Test ACCURACY: 0.6462
ID Test Loss: 1.7034
OOD Validation ACCURACY: 0.5798
OOD Validation Loss: 2.5076
OOD Test ACCURACY: 0.5333
OOD Test Loss: 3.8144

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ACCURACY: 0.7409
Train Loss: 0.6367
ID Validation ACCURACY: 0.6643
ID Validation Loss: 0.8006
ID Test ACCURACY: 0.6841
ID Test Loss: 0.7824
OOD Validation ACCURACY: 0.6213
OOD Validation Loss: 0.9502
OOD Test ACCURACY: 0.5765
OOD Test Loss: 1.1552

[0m[1;37mINFO[0m: [1mChartInfo 0.6462 0.5333 0.6841 0.5765 0.6643 0.6213[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.55
SUFF++ for r=0.3 class 0 = 0.578 +- 0.254 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 class 1 = 0.655 +- 0.254 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 class 2 = 0.679 +- 0.254 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 all KL = 0.58 +- 0.254 (in-sample avg dev_std = 0.534)
SUFF++ for r=0.3 all L1 = 0.643 +- 0.203 (in-sample avg dev_std = 0.534)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.633
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.604
SUFF++ for r=0.6 class 0 = 0.725 +- 0.222 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 1 = 0.769 +- 0.222 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 class 2 = 0.815 +- 0.222 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all KL = 0.765 +- 0.222 (in-sample avg dev_std = 0.375)
SUFF++ for r=0.6 all L1 = 0.772 +- 0.191 (in-sample avg dev_std = 0.375)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.636
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.626
SUFF++ for r=0.9 class 0 = 0.857 +- 0.126 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 1 = 0.888 +- 0.126 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 2 = 0.904 +- 0.126 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all KL = 0.928 +- 0.126 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all L1 = 0.885 +- 0.146 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.598
NEC for r=0.3 class 0 = 0.355 +- 0.255 (in-sample avg dev_std = 0.325)
NEC for r=0.3 class 1 = 0.256 +- 0.255 (in-sample avg dev_std = 0.325)
NEC for r=0.3 class 2 = 0.228 +- 0.255 (in-sample avg dev_std = 0.325)
NEC for r=0.3 all KL = 0.245 +- 0.255 (in-sample avg dev_std = 0.325)
NEC for r=0.3 all L1 = 0.272 +- 0.228 (in-sample avg dev_std = 0.325)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.633
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.627
NEC for r=0.6 class 0 = 0.262 +- 0.220 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 1 = 0.184 +- 0.220 (in-sample avg dev_std = 0.295)
NEC for r=0.6 class 2 = 0.17 +- 0.220 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all KL = 0.17 +- 0.220 (in-sample avg dev_std = 0.295)
NEC for r=0.6 all L1 = 0.199 +- 0.201 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.637
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.635
NEC for r=0.9 class 0 = 0.174 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.9 class 1 = 0.12 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.9 class 2 = 0.111 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.9 all KL = 0.086 +- 0.157 (in-sample avg dev_std = 0.204)
NEC for r=0.9 all L1 = 0.131 +- 0.165 (in-sample avg dev_std = 0.204)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.644
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.641
NEC for r=1.0 class 0 = 0.136 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 1 = 0.104 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 2 = 0.094 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=1.0 all KL = 0.06 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=1.0 all L1 = 0.109 +- 0.141 (in-sample avg dev_std = 0.162)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:47:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:44 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:46 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:46 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:47 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:48 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:47:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ACCURACY: 0.9873
Train Loss: 0.0557
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.2333
ID Test ACCURACY: 0.6751
ID Test Loss: 1.2914
OOD Validation ACCURACY: 0.6235
OOD Validation Loss: 1.5984
OOD Test ACCURACY: 0.5710
OOD Test Loss: 2.1738

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 10...
[0m[1;37mINFO[0m: [1mCheckpoint 10: 
-----------------------------------
Train ACCURACY: 0.8039
Train Loss: 0.4968
ID Validation ACCURACY: 0.6949
ID Validation Loss: 0.7512
ID Test ACCURACY: 0.6931
ID Test Loss: 0.7845
OOD Validation ACCURACY: 0.6476
OOD Validation Loss: 0.9328
OOD Test ACCURACY: 0.5779
OOD Test Loss: 1.2430

[0m[1;37mINFO[0m: [1mChartInfo 0.6751 0.5710 0.6931 0.5779 0.6949 0.6476[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.575
SUFF++ for r=0.3 class 0 = 0.595 +- 0.222 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 1 = 0.644 +- 0.222 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 class 2 = 0.704 +- 0.222 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all KL = 0.659 +- 0.222 (in-sample avg dev_std = 0.463)
SUFF++ for r=0.3 all L1 = 0.649 +- 0.177 (in-sample avg dev_std = 0.463)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.63
SUFF++ for r=0.6 class 0 = 0.697 +- 0.211 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 1 = 0.76 +- 0.211 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 class 2 = 0.78 +- 0.211 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all KL = 0.771 +- 0.211 (in-sample avg dev_std = 0.367)
SUFF++ for r=0.6 all L1 = 0.75 +- 0.187 (in-sample avg dev_std = 0.367)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.669
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.66
SUFF++ for r=0.9 class 0 = 0.872 +- 0.113 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 class 1 = 0.888 +- 0.113 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.113 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 all KL = 0.932 +- 0.113 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.144 (in-sample avg dev_std = 0.202)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.618
NEC for r=0.3 class 0 = 0.274 +- 0.216 (in-sample avg dev_std = 0.264)
NEC for r=0.3 class 1 = 0.257 +- 0.216 (in-sample avg dev_std = 0.264)
NEC for r=0.3 class 2 = 0.227 +- 0.216 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all KL = 0.176 +- 0.216 (in-sample avg dev_std = 0.264)
NEC for r=0.3 all L1 = 0.252 +- 0.206 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.673
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.647
NEC for r=0.6 class 0 = 0.218 +- 0.193 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 1 = 0.184 +- 0.193 (in-sample avg dev_std = 0.247)
NEC for r=0.6 class 2 = 0.174 +- 0.193 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all KL = 0.133 +- 0.193 (in-sample avg dev_std = 0.247)
NEC for r=0.6 all L1 = 0.19 +- 0.190 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.67
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0 = 0.148 +- 0.121 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 1 = 0.116 +- 0.121 (in-sample avg dev_std = 0.176)
NEC for r=0.9 class 2 = 0.122 +- 0.121 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all KL = 0.068 +- 0.121 (in-sample avg dev_std = 0.176)
NEC for r=0.9 all L1 = 0.126 +- 0.150 (in-sample avg dev_std = 0.176)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.673
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.668
NEC for r=1.0 class 0 = 0.12 +- 0.108 (in-sample avg dev_std = 0.166)
NEC for r=1.0 class 1 = 0.099 +- 0.108 (in-sample avg dev_std = 0.166)
NEC for r=1.0 class 2 = 0.116 +- 0.108 (in-sample avg dev_std = 0.166)
NEC for r=1.0 all KL = 0.056 +- 0.108 (in-sample avg dev_std = 0.166)
NEC for r=1.0 all L1 = 0.109 +- 0.139 (in-sample avg dev_std = 0.166)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:48:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:44 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:46 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:46 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:46 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:48 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:48:49 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ACCURACY: 0.9622
Train Loss: 0.1169
ID Validation ACCURACY: 0.7058
ID Validation Loss: 1.0059
ID Test ACCURACY: 0.6588
ID Test Loss: 1.1823
OOD Validation ACCURACY: 0.6319
OOD Validation Loss: 1.4492
OOD Test ACCURACY: 0.5635
OOD Test Loss: 2.1363

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.8077
Train Loss: 0.4721
ID Validation ACCURACY: 0.7004
ID Validation Loss: 0.7735
ID Test ACCURACY: 0.6895
ID Test Loss: 0.8005
OOD Validation ACCURACY: 0.6420
OOD Validation Loss: 0.9580
OOD Test ACCURACY: 0.5964
OOD Test Loss: 1.2456

[0m[1;37mINFO[0m: [1mChartInfo 0.6588 0.5635 0.6895 0.5964 0.7004 0.6420[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.628
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.574
SUFF++ for r=0.3 class 0 = 0.666 +- 0.183 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 class 1 = 0.71 +- 0.183 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 class 2 = 0.618 +- 0.183 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 all KL = 0.733 +- 0.183 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.3 all L1 = 0.672 +- 0.161 (in-sample avg dev_std = 0.413)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.625
SUFF++ for r=0.6 class 0 = 0.725 +- 0.186 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 1 = 0.79 +- 0.186 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 2 = 0.711 +- 0.186 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all KL = 0.795 +- 0.186 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all L1 = 0.75 +- 0.170 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.664
SUFF++ for r=0.9 class 0 = 0.86 +- 0.093 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 1 = 0.894 +- 0.093 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 class 2 = 0.879 +- 0.093 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all KL = 0.943 +- 0.093 (in-sample avg dev_std = 0.185)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.133 (in-sample avg dev_std = 0.185)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.628
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.617
NEC for r=0.3 class 0 = 0.264 +- 0.186 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 1 = 0.226 +- 0.186 (in-sample avg dev_std = 0.240)
NEC for r=0.3 class 2 = 0.288 +- 0.186 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all KL = 0.155 +- 0.186 (in-sample avg dev_std = 0.240)
NEC for r=0.3 all L1 = 0.254 +- 0.191 (in-sample avg dev_std = 0.240)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.646
NEC for r=0.6 class 0 = 0.201 +- 0.148 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 1 = 0.163 +- 0.148 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 2 = 0.204 +- 0.148 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all KL = 0.104 +- 0.148 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all L1 = 0.185 +- 0.169 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.682
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.672
NEC for r=0.9 class 0 = 0.146 +- 0.100 (in-sample avg dev_std = 0.150)
NEC for r=0.9 class 1 = 0.107 +- 0.100 (in-sample avg dev_std = 0.150)
NEC for r=0.9 class 2 = 0.135 +- 0.100 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all KL = 0.056 +- 0.100 (in-sample avg dev_std = 0.150)
NEC for r=0.9 all L1 = 0.125 +- 0.142 (in-sample avg dev_std = 0.150)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.659
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.67
NEC for r=1.0 class 0 = 0.128 +- 0.096 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 1 = 0.098 +- 0.096 (in-sample avg dev_std = 0.151)
NEC for r=1.0 class 2 = 0.124 +- 0.096 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all KL = 0.05 +- 0.096 (in-sample avg dev_std = 0.151)
NEC for r=1.0 all L1 = 0.113 +- 0.135 (in-sample avg dev_std = 0.151)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:49:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:43 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:44 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:45 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:45 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:47 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:49:48 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7076
ID Validation Loss: 2.3068
ID Test ACCURACY: 0.6697
ID Test Loss: 2.5476
OOD Validation ACCURACY: 0.6118
OOD Validation Loss: 2.8631
OOD Test ACCURACY: 0.5559
OOD Test Loss: 3.9096

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ACCURACY: 0.7730
Train Loss: 0.5461
ID Validation ACCURACY: 0.6877
ID Validation Loss: 0.7610
ID Test ACCURACY: 0.6841
ID Test Loss: 0.7794
OOD Validation ACCURACY: 0.6431
OOD Validation Loss: 0.8959
OOD Test ACCURACY: 0.5944
OOD Test Loss: 1.0740

[0m[1;37mINFO[0m: [1mChartInfo 0.6697 0.5559 0.6841 0.5944 0.6877 0.6431[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0 = 0.628 +- 0.322 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 class 1 = 0.696 +- 0.322 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 class 2 = 0.592 +- 0.322 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 all KL = 0.371 +- 0.322 (in-sample avg dev_std = 0.650)
SUFF++ for r=0.3 all L1 = 0.648 +- 0.217 (in-sample avg dev_std = 0.650)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.62
SUFF++ for r=0.6 class 0 = 0.702 +- 0.334 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 1 = 0.793 +- 0.334 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 class 2 = 0.713 +- 0.334 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 all KL = 0.582 +- 0.334 (in-sample avg dev_std = 0.510)
SUFF++ for r=0.6 all L1 = 0.747 +- 0.215 (in-sample avg dev_std = 0.510)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.667
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.666
SUFF++ for r=0.9 class 0 = 0.883 +- 0.155 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 1 = 0.918 +- 0.155 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 class 2 = 0.89 +- 0.155 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all KL = 0.91 +- 0.155 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.9 all L1 = 0.901 +- 0.146 (in-sample avg dev_std = 0.239)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.646
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0 = 0.304 +- 0.338 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1 = 0.194 +- 0.338 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 2 = 0.224 +- 0.338 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.29 +- 0.338 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.23 +- 0.267 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.662
NEC for r=0.6 class 0 = 0.18 +- 0.249 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 1 = 0.123 +- 0.249 (in-sample avg dev_std = 0.282)
NEC for r=0.6 class 2 = 0.141 +- 0.249 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all KL = 0.155 +- 0.249 (in-sample avg dev_std = 0.282)
NEC for r=0.6 all L1 = 0.143 +- 0.199 (in-sample avg dev_std = 0.282)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.666
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.664
NEC for r=0.9 class 0 = 0.108 +- 0.129 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 1 = 0.076 +- 0.129 (in-sample avg dev_std = 0.163)
NEC for r=0.9 class 2 = 0.086 +- 0.129 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all KL = 0.06 +- 0.129 (in-sample avg dev_std = 0.163)
NEC for r=0.9 all L1 = 0.087 +- 0.141 (in-sample avg dev_std = 0.163)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.668
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.668
NEC for r=1.0 class 0 = 0.102 +- 0.120 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 1 = 0.065 +- 0.120 (in-sample avg dev_std = 0.162)
NEC for r=1.0 class 2 = 0.08 +- 0.120 (in-sample avg dev_std = 0.162)
NEC for r=1.0 all KL = 0.053 +- 0.120 (in-sample avg dev_std = 0.162)
NEC for r=1.0 all L1 = 0.079 +- 0.136 (in-sample avg dev_std = 0.162)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:50:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:41 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:43 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:43 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:44 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:45 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:50:47 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 65...
[0m[1;37mINFO[0m: [1mCheckpoint 65: 
-----------------------------------
Train ACCURACY: 0.9988
Train Loss: 0.0094
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.7565
ID Test ACCURACY: 0.6643
ID Test Loss: 2.0819
OOD Validation ACCURACY: 0.6084
OOD Validation Loss: 2.4105
OOD Test ACCURACY: 0.5450
OOD Test Loss: 3.1833

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 22...
[0m[1;37mINFO[0m: [1mCheckpoint 22: 
-----------------------------------
Train ACCURACY: 0.9317
Train Loss: 0.2018
ID Validation ACCURACY: 0.6859
ID Validation Loss: 0.9593
ID Test ACCURACY: 0.6769
ID Test Loss: 1.0846
OOD Validation ACCURACY: 0.6476
OOD Validation Loss: 1.2904
OOD Test ACCURACY: 0.6026
OOD Test Loss: 1.8131

[0m[1;37mINFO[0m: [1mChartInfo 0.6643 0.5450 0.6769 0.6026 0.6859 0.6476[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.588
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.538
SUFF++ for r=0.3 class 0 = 0.637 +- 0.281 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 class 1 = 0.685 +- 0.281 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 class 2 = 0.594 +- 0.281 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 all KL = 0.543 +- 0.281 (in-sample avg dev_std = 0.542)
SUFF++ for r=0.3 all L1 = 0.646 +- 0.204 (in-sample avg dev_std = 0.542)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.633
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.595
SUFF++ for r=0.6 class 0 = 0.724 +- 0.274 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.274 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 class 2 = 0.699 +- 0.274 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all KL = 0.675 +- 0.274 (in-sample avg dev_std = 0.440)
SUFF++ for r=0.6 all L1 = 0.735 +- 0.210 (in-sample avg dev_std = 0.440)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.658
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.65
SUFF++ for r=0.9 class 0 = 0.876 +- 0.139 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 1 = 0.884 +- 0.139 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 class 2 = 0.866 +- 0.139 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all KL = 0.909 +- 0.139 (in-sample avg dev_std = 0.229)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.160 (in-sample avg dev_std = 0.229)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.588
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.595
NEC for r=0.3 class 0 = 0.268 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.3 class 1 = 0.254 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.3 class 2 = 0.303 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.3 all KL = 0.263 +- 0.281 (in-sample avg dev_std = 0.331)
NEC for r=0.3 all L1 = 0.272 +- 0.247 (in-sample avg dev_std = 0.331)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.633
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.607
NEC for r=0.6 class 0 = 0.192 +- 0.223 (in-sample avg dev_std = 0.292)
NEC for r=0.6 class 1 = 0.159 +- 0.223 (in-sample avg dev_std = 0.292)
NEC for r=0.6 class 2 = 0.227 +- 0.223 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all KL = 0.163 +- 0.223 (in-sample avg dev_std = 0.292)
NEC for r=0.6 all L1 = 0.187 +- 0.209 (in-sample avg dev_std = 0.292)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.659
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.638
NEC for r=0.9 class 0 = 0.116 +- 0.152 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 1 = 0.111 +- 0.152 (in-sample avg dev_std = 0.175)
NEC for r=0.9 class 2 = 0.117 +- 0.152 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all KL = 0.078 +- 0.152 (in-sample avg dev_std = 0.175)
NEC for r=0.9 all L1 = 0.114 +- 0.165 (in-sample avg dev_std = 0.175)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.662
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.639
NEC for r=1.0 class 0 = 0.095 +- 0.134 (in-sample avg dev_std = 0.169)
NEC for r=1.0 class 1 = 0.098 +- 0.134 (in-sample avg dev_std = 0.169)
NEC for r=1.0 class 2 = 0.109 +- 0.134 (in-sample avg dev_std = 0.169)
NEC for r=1.0 all KL = 0.064 +- 0.134 (in-sample avg dev_std = 0.169)
NEC for r=1.0 all L1 = 0.1 +- 0.155 (in-sample avg dev_std = 0.169)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.58, 0.765, 0.928, 1.0], 'all_L1': [0.643, 0.772, 0.885, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.659, 0.771, 0.932, 1.0], 'all_L1': [0.649, 0.75, 0.88, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.733, 0.795, 0.943, 1.0], 'all_L1': [0.672, 0.75, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.371, 0.582, 0.91, 1.0], 'all_L1': [0.648, 0.747, 0.901, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.543, 0.675, 0.909, 1.0], 'all_L1': [0.646, 0.735, 0.877, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.245, 0.17, 0.086, 0.06], 'all_L1': [0.272, 0.199, 0.131, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.176, 0.133, 0.068, 0.056], 'all_L1': [0.252, 0.19, 0.126, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.155, 0.104, 0.056, 0.05], 'all_L1': [0.254, 0.185, 0.125, 0.113]}), defaultdict(<class 'list'>, {'all_KL': [0.29, 0.155, 0.06, 0.053], 'all_L1': [0.23, 0.143, 0.087, 0.079]}), defaultdict(<class 'list'>, {'all_KL': [0.263, 0.163, 0.078, 0.064], 'all_L1': [0.272, 0.187, 0.114, 0.1]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.652 +- 0.010, 0.751 +- 0.012, 0.885 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.577 +- 0.122, 0.718 +- 0.079, 0.924 +- 0.013, 1.000 +- 0.000
suff++_acc_int  =  0.561 +- 0.015, 0.615 +- 0.013, 0.653 +- 0.015
nec class all_L1  =  0.256 +- 0.016, 0.181 +- 0.019, 0.117 +- 0.016, 0.102 +- 0.012
nec class all_KL  =  0.226 +- 0.052, 0.145 +- 0.024, 0.070 +- 0.011, 0.057 +- 0.005
nec_acc_int  =  0.612 +- 0.014, 0.638 +- 0.019, 0.655 +- 0.015, 0.657 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.454 +- 0.008, 0.466 +- 0.013, 0.501 +- 0.005, 0.551 +- 0.006
Faith. Armon (L1)= 		  =  0.367 +- 0.016, 0.291 +- 0.026, 0.206 +- 0.025, 0.185 +- 0.020
Faith. GMean (L1)= 	  =  0.408 +- 0.012, 0.368 +- 0.022, 0.320 +- 0.022, 0.319 +- 0.020
Faith. Aritm (KL)= 		  =  0.401 +- 0.038, 0.431 +- 0.035, 0.497 +- 0.007, 0.528 +- 0.002
Faith. Armon (KL)= 		  =  0.312 +- 0.038, 0.239 +- 0.033, 0.129 +- 0.019, 0.107 +- 0.009
Faith. GMean (KL)= 	  =  0.352 +- 0.021, 0.320 +- 0.025, 0.253 +- 0.020, 0.238 +- 0.010
Computed for split load_split = id



Completed in  0:04:59.164213  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:51:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:51:58 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:00 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:00 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:01 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:02 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:04 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7004
ID Validation Loss: 1.4395
ID Test ACCURACY: 0.6498
ID Test Loss: 1.7556
OOD Validation ACCURACY: 0.6269
OOD Validation Loss: 1.7485
OOD Test ACCURACY: 0.5676
OOD Test Loss: 2.4674

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6931
ID Validation Loss: 1.6611
ID Test ACCURACY: 0.6588
ID Test Loss: 1.9403
OOD Validation ACCURACY: 0.6409
OOD Validation Loss: 2.1076
OOD Test ACCURACY: 0.5813
OOD Test Loss: 2.4255

[0m[1;37mINFO[0m: [1mChartInfo 0.6498 0.5676 0.6588 0.5813 0.6931 0.6409[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.632
SUFF++ for r=0.6 class 0 = 0.758 +- 0.254 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 1 = 0.804 +- 0.254 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 class 2 = 0.764 +- 0.254 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all KL = 0.713 +- 0.254 (in-sample avg dev_std = 0.416)
SUFF++ for r=0.6 all L1 = 0.781 +- 0.185 (in-sample avg dev_std = 0.416)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.648
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.639
NEC for r=0.6 class 0 = 0.161 +- 0.198 (in-sample avg dev_std = 0.197)
NEC for r=0.6 class 1 = 0.14 +- 0.198 (in-sample avg dev_std = 0.197)
NEC for r=0.6 class 2 = 0.149 +- 0.198 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all KL = 0.117 +- 0.198 (in-sample avg dev_std = 0.197)
NEC for r=0.6 all L1 = 0.148 +- 0.198 (in-sample avg dev_std = 0.197)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:52:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:24 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:25 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:25 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:26 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:27 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:29 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6968
ID Validation Loss: 1.8803
ID Test ACCURACY: 0.6552
ID Test Loss: 2.0303
OOD Validation ACCURACY: 0.6415
OOD Validation Loss: 2.1364
OOD Test ACCURACY: 0.5580
OOD Test Loss: 2.5377

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 195...
[0m[1;37mINFO[0m: [1mCheckpoint 195: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6895
ID Validation Loss: 1.7708
ID Test ACCURACY: 0.6625
ID Test Loss: 1.9030
OOD Validation ACCURACY: 0.6471
OOD Validation Loss: 2.0345
OOD Test ACCURACY: 0.5553
OOD Test Loss: 2.4157

[0m[1;37mINFO[0m: [1mChartInfo 0.6552 0.5580 0.6625 0.5553 0.6895 0.6471[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.657
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.613
SUFF++ for r=0.6 class 0 = 0.761 +- 0.298 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 class 1 = 0.859 +- 0.298 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 class 2 = 0.733 +- 0.298 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 all KL = 0.718 +- 0.298 (in-sample avg dev_std = 0.425)
SUFF++ for r=0.6 all L1 = 0.797 +- 0.199 (in-sample avg dev_std = 0.425)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.657
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.634
NEC for r=0.6 class 0 = 0.172 +- 0.202 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 1 = 0.094 +- 0.202 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 2 = 0.16 +- 0.202 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all KL = 0.112 +- 0.202 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all L1 = 0.133 +- 0.197 (in-sample avg dev_std = 0.200)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:52:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:47 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:48 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:49 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:49 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:50 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:52:52 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 127...
[0m[1;37mINFO[0m: [1mCheckpoint 127: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.7004
ID Validation Loss: 2.4023
ID Test ACCURACY: 0.6282
ID Test Loss: 2.7740
OOD Validation ACCURACY: 0.6246
OOD Validation Loss: 2.7762
OOD Test ACCURACY: 0.5635
OOD Test Loss: 3.1692

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6679
ID Validation Loss: 2.4808
ID Test ACCURACY: 0.6462
ID Test Loss: 2.5342
OOD Validation ACCURACY: 0.6431
OOD Validation Loss: 2.6516
OOD Test ACCURACY: 0.5765
OOD Test Loss: 2.9538

[0m[1;37mINFO[0m: [1mChartInfo 0.6282 0.5635 0.6462 0.5765 0.6679 0.6431[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.626
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0 = 0.797 +- 0.290 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 1 = 0.778 +- 0.290 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 class 2 = 0.782 +- 0.290 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all KL = 0.709 +- 0.290 (in-sample avg dev_std = 0.409)
SUFF++ for r=0.6 all L1 = 0.784 +- 0.220 (in-sample avg dev_std = 0.409)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.626
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0 = 0.146 +- 0.241 (in-sample avg dev_std = 0.290)
NEC for r=0.6 class 1 = 0.165 +- 0.241 (in-sample avg dev_std = 0.290)
NEC for r=0.6 class 2 = 0.164 +- 0.241 (in-sample avg dev_std = 0.290)
NEC for r=0.6 all KL = 0.163 +- 0.241 (in-sample avg dev_std = 0.290)
NEC for r=0.6 all L1 = 0.16 +- 0.207 (in-sample avg dev_std = 0.290)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:53:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:09 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:11 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:12 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:12 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:13 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:15 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.6780
ID Test ACCURACY: 0.6408
ID Test Loss: 1.9436
OOD Validation ACCURACY: 0.6353
OOD Validation Loss: 1.9583
OOD Test ACCURACY: 0.5662
OOD Test Loss: 2.4517

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 72...
[0m[1;37mINFO[0m: [1mCheckpoint 72: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6715
ID Validation Loss: 2.2080
ID Test ACCURACY: 0.6462
ID Test Loss: 2.5187
OOD Validation ACCURACY: 0.6465
OOD Validation Loss: 2.4911
OOD Test ACCURACY: 0.5779
OOD Test Loss: 2.9096

[0m[1;37mINFO[0m: [1mChartInfo 0.6408 0.5662 0.6462 0.5779 0.6715 0.6465[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.632
SUFF++ for r=0.6 class 0 = 0.728 +- 0.281 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 1 = 0.813 +- 0.281 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 2 = 0.783 +- 0.281 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all KL = 0.721 +- 0.281 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all L1 = 0.782 +- 0.222 (in-sample avg dev_std = 0.414)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.64
NEC for r=0.6 class 0 = 0.162 +- 0.193 (in-sample avg dev_std = 0.251)
NEC for r=0.6 class 1 = 0.116 +- 0.193 (in-sample avg dev_std = 0.251)
NEC for r=0.6 class 2 = 0.139 +- 0.193 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all KL = 0.118 +- 0.193 (in-sample avg dev_std = 0.251)
NEC for r=0.6 all L1 = 0.134 +- 0.185 (in-sample avg dev_std = 0.251)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:53:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:33 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:35 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:35 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:36 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:37 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:53:38 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 131...
[0m[1;37mINFO[0m: [1mCheckpoint 131: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6841
ID Validation Loss: 2.1540
ID Test ACCURACY: 0.6462
ID Test Loss: 2.4067
OOD Validation ACCURACY: 0.6123
OOD Validation Loss: 2.5559
OOD Test ACCURACY: 0.5511
OOD Test Loss: 3.1148

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 190...
[0m[1;37mINFO[0m: [1mCheckpoint 190: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0000
ID Validation ACCURACY: 0.6643
ID Validation Loss: 2.4438
ID Test ACCURACY: 0.6408
ID Test Loss: 2.7934
OOD Validation ACCURACY: 0.6359
OOD Validation Loss: 2.7242
OOD Test ACCURACY: 0.5704
OOD Test Loss: 3.1535

[0m[1;37mINFO[0m: [1mChartInfo 0.6462 0.5511 0.6408 0.5704 0.6643 0.6359[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.608
SUFF++ for r=0.6 class 0 = 0.765 +- 0.286 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 1 = 0.78 +- 0.286 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 class 2 = 0.783 +- 0.286 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all KL = 0.708 +- 0.286 (in-sample avg dev_std = 0.419)
SUFF++ for r=0.6 all L1 = 0.777 +- 0.222 (in-sample avg dev_std = 0.419)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.637
NEC for r=0.6 class 0 = 0.156 +- 0.220 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 1 = 0.147 +- 0.220 (in-sample avg dev_std = 0.271)
NEC for r=0.6 class 2 = 0.152 +- 0.220 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all KL = 0.141 +- 0.220 (in-sample avg dev_std = 0.271)
NEC for r=0.6 all L1 = 0.151 +- 0.195 (in-sample avg dev_std = 0.271)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.713], 'all_L1': [0.781]}), defaultdict(<class 'list'>, {'all_KL': [0.718], 'all_L1': [0.797]}), defaultdict(<class 'list'>, {'all_KL': [0.709], 'all_L1': [0.784]}), defaultdict(<class 'list'>, {'all_KL': [0.721], 'all_L1': [0.782]}), defaultdict(<class 'list'>, {'all_KL': [0.708], 'all_L1': [0.777]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.117], 'all_L1': [0.148]}), defaultdict(<class 'list'>, {'all_KL': [0.112], 'all_L1': [0.133]}), defaultdict(<class 'list'>, {'all_KL': [0.163], 'all_L1': [0.16]}), defaultdict(<class 'list'>, {'all_KL': [0.118], 'all_L1': [0.134]}), defaultdict(<class 'list'>, {'all_KL': [0.141], 'all_L1': [0.151]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.784 +- 0.007
suff++ class all_KL  =  0.714 +- 0.005
suff++_acc_int  =  0.619 +- 0.010
nec class all_L1  =  0.145 +- 0.010
nec class all_KL  =  0.130 +- 0.019
nec_acc_int  =  0.635 +- 0.005


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.465 +- 0.004
Faith. Armon (L1)= 		  =  0.245 +- 0.015
Faith. GMean (L1)= 	  =  0.337 +- 0.011
Faith. Aritm (KL)= 		  =  0.422 +- 0.008
Faith. Armon (KL)= 		  =  0.220 +- 0.027
Faith. GMean (KL)= 	  =  0.304 +- 0.021
Computed for split load_split = id



Completed in  0:02:01.339201  for CIGAvGIN GOODTwitter/length



DONE CIGA GOODTwitter/length

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:54:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:08 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:11 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:14 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:18 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:20 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:54:21 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ROC-AUC: 0.9716
Train Loss: 0.0653
ID Validation ROC-AUC: 0.8412
ID Validation Loss: 0.1394
ID Test ROC-AUC: 0.7964
ID Test Loss: 0.1371
OOD Validation ROC-AUC: 0.7570
OOD Validation Loss: 0.1376
OOD Test ROC-AUC: 0.7331
OOD Test Loss: 0.0930

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ROC-AUC: 0.8810
Train Loss: 0.1019
ID Validation ROC-AUC: 0.8118
ID Validation Loss: 0.1338
ID Test ROC-AUC: 0.8103
ID Test Loss: 0.1133
OOD Validation ROC-AUC: 0.7797
OOD Validation Loss: 0.1199
OOD Test ROC-AUC: 0.7043
OOD Test Loss: 0.0856

[0m[1;37mINFO[0m: [1mChartInfo 0.7964 0.7331 0.8103 0.7043 0.8118 0.7797[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:54:22 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.717
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 260
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.604
SUFF++ for r=0.3 class 0.0 = 0.946 +- 0.070 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 class 1.0 = 0.883 +- 0.070 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 all KL = 0.957 +- 0.070 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.3 all L1 = 0.913 +- 0.105 (in-sample avg dev_std = 0.146)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.809
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.755
SUFF++ for r=0.6 class 0.0 = 0.959 +- 0.109 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 class 1.0 = 0.831 +- 0.109 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 all KL = 0.947 +- 0.109 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.6 all L1 = 0.895 +- 0.143 (in-sample avg dev_std = 0.160)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.802
SUFF++ for r=0.9 class 0.0 = 0.986 +- 0.040 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.040 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all KL = 0.989 +- 0.040 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all L1 = 0.965 +- 0.066 (in-sample avg dev_std = 0.093)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.71
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.662
NEC for r=0.3 class 0.0 = 0.044 +- 0.039 (in-sample avg dev_std = 0.086)
NEC for r=0.3 class 1.0 = 0.089 +- 0.039 (in-sample avg dev_std = 0.086)
NEC for r=0.3 all KL = 0.024 +- 0.039 (in-sample avg dev_std = 0.086)
NEC for r=0.3 all L1 = 0.066 +- 0.080 (in-sample avg dev_std = 0.086)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.809
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.786
NEC for r=0.6 class 0.0 = 0.042 +- 0.109 (in-sample avg dev_std = 0.167)
NEC for r=0.6 class 1.0 = 0.154 +- 0.109 (in-sample avg dev_std = 0.167)
NEC for r=0.6 all KL = 0.05 +- 0.109 (in-sample avg dev_std = 0.167)
NEC for r=0.6 all L1 = 0.098 +- 0.132 (in-sample avg dev_std = 0.167)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.808
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.8
NEC for r=0.9 class 0.0 = 0.044 +- 0.165 (in-sample avg dev_std = 0.221)
NEC for r=0.9 class 1.0 = 0.187 +- 0.165 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all KL = 0.085 +- 0.165 (in-sample avg dev_std = 0.221)
NEC for r=0.9 all L1 = 0.116 +- 0.159 (in-sample avg dev_std = 0.221)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.814
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.797
NEC for r=1.0 class 0.0 = 0.047 +- 0.173 (in-sample avg dev_std = 0.241)
NEC for r=1.0 class 1.0 = 0.196 +- 0.173 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all KL = 0.095 +- 0.173 (in-sample avg dev_std = 0.241)
NEC for r=1.0 all L1 = 0.121 +- 0.162 (in-sample avg dev_std = 0.241)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:54:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:50 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:54 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:54:57 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:00 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:03 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ROC-AUC: 0.9881
Train Loss: 0.0502
ID Validation ROC-AUC: 0.8421
ID Validation Loss: 0.1583
ID Test ROC-AUC: 0.7976
ID Test Loss: 0.1471
OOD Validation ROC-AUC: 0.7386
OOD Validation Loss: 0.1672
OOD Test ROC-AUC: 0.7071
OOD Test Loss: 0.1073

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 77...
[0m[1;37mINFO[0m: [1mCheckpoint 77: 
-----------------------------------
Train ROC-AUC: 0.9117
Train Loss: 0.0938
ID Validation ROC-AUC: 0.8079
ID Validation Loss: 0.1347
ID Test ROC-AUC: 0.7889
ID Test Loss: 0.1161
OOD Validation ROC-AUC: 0.7802
OOD Validation Loss: 0.1159
OOD Test ROC-AUC: 0.6996
OOD Test Loss: 0.0890

[0m[1;37mINFO[0m: [1mChartInfo 0.7976 0.7071 0.7889 0.6996 0.8079 0.7802[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:55:04 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.693
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 254
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.59
SUFF++ for r=0.3 class 0.0 = 0.947 +- 0.093 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 class 1.0 = 0.856 +- 0.093 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 all KL = 0.948 +- 0.093 (in-sample avg dev_std = 0.156)
SUFF++ for r=0.3 all L1 = 0.902 +- 0.130 (in-sample avg dev_std = 0.156)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.728
SUFF++ for r=0.6 class 0.0 = 0.956 +- 0.127 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.6 class 1.0 = 0.82 +- 0.127 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.6 all KL = 0.934 +- 0.127 (in-sample avg dev_std = 0.196)
SUFF++ for r=0.6 all L1 = 0.888 +- 0.158 (in-sample avg dev_std = 0.196)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.792
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.785
SUFF++ for r=0.9 class 0.0 = 0.983 +- 0.085 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 class 1.0 = 0.934 +- 0.085 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all KL = 0.975 +- 0.085 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.9 all L1 = 0.958 +- 0.093 (in-sample avg dev_std = 0.129)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.7
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.692
NEC for r=0.3 class 0.0 = 0.047 +- 0.057 (in-sample avg dev_std = 0.092)
NEC for r=0.3 class 1.0 = 0.109 +- 0.057 (in-sample avg dev_std = 0.092)
NEC for r=0.3 all KL = 0.031 +- 0.057 (in-sample avg dev_std = 0.092)
NEC for r=0.3 all L1 = 0.078 +- 0.104 (in-sample avg dev_std = 0.092)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.722
NEC for r=0.6 class 0.0 = 0.043 +- 0.135 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 1.0 = 0.175 +- 0.135 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all KL = 0.067 +- 0.135 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all L1 = 0.109 +- 0.160 (in-sample avg dev_std = 0.189)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.792
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.749
NEC for r=0.9 class 0.0 = 0.051 +- 0.215 (in-sample avg dev_std = 0.278)
NEC for r=0.9 class 1.0 = 0.221 +- 0.215 (in-sample avg dev_std = 0.278)
NEC for r=0.9 all KL = 0.122 +- 0.215 (in-sample avg dev_std = 0.278)
NEC for r=0.9 all L1 = 0.136 +- 0.192 (in-sample avg dev_std = 0.278)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.807
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.755
NEC for r=1.0 class 0.0 = 0.057 +- 0.241 (in-sample avg dev_std = 0.292)
NEC for r=1.0 class 1.0 = 0.23 +- 0.241 (in-sample avg dev_std = 0.292)
NEC for r=1.0 all KL = 0.148 +- 0.241 (in-sample avg dev_std = 0.292)
NEC for r=1.0 all L1 = 0.143 +- 0.197 (in-sample avg dev_std = 0.292)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:55:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:33 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:37 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:40 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 156...
[0m[1;37mINFO[0m: [1mCheckpoint 156: 
-----------------------------------
Train ROC-AUC: 0.9869
Train Loss: 0.0538
ID Validation ROC-AUC: 0.8431
ID Validation Loss: 0.1490
ID Test ROC-AUC: 0.8115
ID Test Loss: 0.1338
OOD Validation ROC-AUC: 0.7762
OOD Validation Loss: 0.1394
OOD Test ROC-AUC: 0.7383
OOD Test Loss: 0.0997

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ROC-AUC: 0.9764
Train Loss: 0.0628
ID Validation ROC-AUC: 0.8350
ID Validation Loss: 0.1429
ID Test ROC-AUC: 0.8089
ID Test Loss: 0.1287
OOD Validation ROC-AUC: 0.7881
OOD Validation Loss: 0.1266
OOD Test ROC-AUC: 0.7471
OOD Test Loss: 0.0945

[0m[1;37mINFO[0m: [1mChartInfo 0.8115 0.7383 0.8089 0.7471 0.8350 0.7881[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:55:46 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.767
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 255
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.626
SUFF++ for r=0.3 class 0.0 = 0.926 +- 0.093 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.3 class 1.0 = 0.806 +- 0.093 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.3 all KL = 0.93 +- 0.093 (in-sample avg dev_std = 0.182)
SUFF++ for r=0.3 all L1 = 0.864 +- 0.141 (in-sample avg dev_std = 0.182)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.753
SUFF++ for r=0.6 class 0.0 = 0.943 +- 0.112 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.6 class 1.0 = 0.826 +- 0.112 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.6 all KL = 0.937 +- 0.112 (in-sample avg dev_std = 0.186)
SUFF++ for r=0.6 all L1 = 0.885 +- 0.143 (in-sample avg dev_std = 0.186)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.815
SUFF++ for r=0.9 class 0.0 = 0.982 +- 0.064 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.9 class 1.0 = 0.925 +- 0.064 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.9 all KL = 0.979 +- 0.064 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.9 all L1 = 0.954 +- 0.086 (in-sample avg dev_std = 0.126)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.757
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.688
NEC for r=0.3 class 0.0 = 0.062 +- 0.072 (in-sample avg dev_std = 0.117)
NEC for r=0.3 class 1.0 = 0.146 +- 0.072 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all KL = 0.038 +- 0.072 (in-sample avg dev_std = 0.117)
NEC for r=0.3 all L1 = 0.104 +- 0.120 (in-sample avg dev_std = 0.117)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.799
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.773
NEC for r=0.6 class 0.0 = 0.06 +- 0.120 (in-sample avg dev_std = 0.198)
NEC for r=0.6 class 1.0 = 0.177 +- 0.120 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all KL = 0.067 +- 0.120 (in-sample avg dev_std = 0.198)
NEC for r=0.6 all L1 = 0.118 +- 0.139 (in-sample avg dev_std = 0.198)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.79
NEC for r=0.9 class 0.0 = 0.058 +- 0.209 (in-sample avg dev_std = 0.271)
NEC for r=0.9 class 1.0 = 0.227 +- 0.209 (in-sample avg dev_std = 0.271)
NEC for r=0.9 all KL = 0.127 +- 0.209 (in-sample avg dev_std = 0.271)
NEC for r=0.9 all L1 = 0.142 +- 0.182 (in-sample avg dev_std = 0.271)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.822
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.777
NEC for r=1.0 class 0.0 = 0.069 +- 0.224 (in-sample avg dev_std = 0.270)
NEC for r=1.0 class 1.0 = 0.225 +- 0.224 (in-sample avg dev_std = 0.270)
NEC for r=1.0 all KL = 0.143 +- 0.224 (in-sample avg dev_std = 0.270)
NEC for r=1.0 all L1 = 0.147 +- 0.192 (in-sample avg dev_std = 0.270)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:56:14 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:14 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:18 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:21 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:24 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ROC-AUC: 0.9788
Train Loss: 0.0657
ID Validation ROC-AUC: 0.8378
ID Validation Loss: 0.1396
ID Test ROC-AUC: 0.8109
ID Test Loss: 0.1227
OOD Validation ROC-AUC: 0.7665
OOD Validation Loss: 0.1310
OOD Test ROC-AUC: 0.7331
OOD Test Loss: 0.0936

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 139...
[0m[1;37mINFO[0m: [1mCheckpoint 139: 
-----------------------------------
Train ROC-AUC: 0.9723
Train Loss: 0.0782
ID Validation ROC-AUC: 0.8167
ID Validation Loss: 0.1530
ID Test ROC-AUC: 0.8037
ID Test Loss: 0.1332
OOD Validation ROC-AUC: 0.7875
OOD Validation Loss: 0.1295
OOD Test ROC-AUC: 0.6782
OOD Test Loss: 0.1101

[0m[1;37mINFO[0m: [1mChartInfo 0.8109 0.7331 0.8037 0.6782 0.8167 0.7875[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:56:27 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 254
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.601
SUFF++ for r=0.3 class 0.0 = 0.972 +- 0.047 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.3 class 1.0 = 0.913 +- 0.047 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.3 all KL = 0.976 +- 0.047 (in-sample avg dev_std = 0.075)
SUFF++ for r=0.3 all L1 = 0.943 +- 0.086 (in-sample avg dev_std = 0.075)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.734
SUFF++ for r=0.6 class 0.0 = 0.975 +- 0.082 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 class 1.0 = 0.874 +- 0.082 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all KL = 0.966 +- 0.082 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all L1 = 0.925 +- 0.117 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.824
SUFF++ for r=0.9 class 0.0 = 0.99 +- 0.045 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.045 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all KL = 0.986 +- 0.045 (in-sample avg dev_std = 0.103)
SUFF++ for r=0.9 all L1 = 0.961 +- 0.076 (in-sample avg dev_std = 0.103)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.704
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.676
NEC for r=0.3 class 0.0 = 0.023 +- 0.029 (in-sample avg dev_std = 0.057)
NEC for r=0.3 class 1.0 = 0.06 +- 0.029 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all KL = 0.011 +- 0.029 (in-sample avg dev_std = 0.057)
NEC for r=0.3 all L1 = 0.042 +- 0.062 (in-sample avg dev_std = 0.057)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.793
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.749
NEC for r=0.6 class 0.0 = 0.026 +- 0.063 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.117 +- 0.063 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.028 +- 0.063 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.071 +- 0.110 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.827
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.792
NEC for r=0.9 class 0.0 = 0.035 +- 0.144 (in-sample avg dev_std = 0.188)
NEC for r=0.9 class 1.0 = 0.184 +- 0.144 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all KL = 0.073 +- 0.144 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all L1 = 0.109 +- 0.162 (in-sample avg dev_std = 0.188)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.832
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.778
NEC for r=1.0 class 0.0 = 0.038 +- 0.182 (in-sample avg dev_std = 0.237)
NEC for r=1.0 class 1.0 = 0.218 +- 0.182 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all KL = 0.101 +- 0.182 (in-sample avg dev_std = 0.237)
NEC for r=1.0 all L1 = 0.128 +- 0.181 (in-sample avg dev_std = 0.237)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:56:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:56:56 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:00 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:03 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:06 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ROC-AUC: 0.9928
Train Loss: 0.0421
ID Validation ROC-AUC: 0.8460
ID Validation Loss: 0.1580
ID Test ROC-AUC: 0.8091
ID Test Loss: 0.1489
OOD Validation ROC-AUC: 0.7496
OOD Validation Loss: 0.1650
OOD Test ROC-AUC: 0.7077
OOD Test Loss: 0.1190

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ROC-AUC: 0.9781
Train Loss: 0.0600
ID Validation ROC-AUC: 0.8358
ID Validation Loss: 0.1409
ID Test ROC-AUC: 0.8118
ID Test Loss: 0.1303
OOD Validation ROC-AUC: 0.7903
OOD Validation Loss: 0.1230
OOD Test ROC-AUC: 0.7362
OOD Test Loss: 0.0936

[0m[1;37mINFO[0m: [1mChartInfo 0.8091 0.7077 0.8118 0.7362 0.8358 0.7903[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:57:09 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.726
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 260
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.602
SUFF++ for r=0.3 class 0.0 = 0.956 +- 0.118 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.3 class 1.0 = 0.847 +- 0.118 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.3 all KL = 0.936 +- 0.118 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.3 all L1 = 0.9 +- 0.150 (in-sample avg dev_std = 0.178)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.719
SUFF++ for r=0.6 class 0.0 = 0.955 +- 0.166 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 class 1.0 = 0.788 +- 0.166 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all KL = 0.909 +- 0.166 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.6 all L1 = 0.871 +- 0.176 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0.0 = 0.982 +- 0.083 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 class 1.0 = 0.929 +- 0.083 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all KL = 0.976 +- 0.083 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.9 all L1 = 0.955 +- 0.093 (in-sample avg dev_std = 0.139)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.717
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.696
NEC for r=0.3 class 0.0 = 0.035 +- 0.067 (in-sample avg dev_std = 0.118)
NEC for r=0.3 class 1.0 = 0.121 +- 0.067 (in-sample avg dev_std = 0.118)
NEC for r=0.3 all KL = 0.035 +- 0.067 (in-sample avg dev_std = 0.118)
NEC for r=0.3 all L1 = 0.078 +- 0.117 (in-sample avg dev_std = 0.118)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.747
NEC for r=0.6 class 0.0 = 0.059 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=0.6 class 1.0 = 0.17 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all KL = 0.077 +- 0.153 (in-sample avg dev_std = 0.203)
NEC for r=0.6 all L1 = 0.115 +- 0.159 (in-sample avg dev_std = 0.203)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.834
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.788
NEC for r=0.9 class 0.0 = 0.057 +- 0.209 (in-sample avg dev_std = 0.256)
NEC for r=0.9 class 1.0 = 0.21 +- 0.209 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all KL = 0.125 +- 0.209 (in-sample avg dev_std = 0.256)
NEC for r=0.9 all L1 = 0.133 +- 0.181 (in-sample avg dev_std = 0.256)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.792
NEC for r=1.0 class 0.0 = 0.052 +- 0.225 (in-sample avg dev_std = 0.283)
NEC for r=1.0 class 1.0 = 0.224 +- 0.225 (in-sample avg dev_std = 0.283)
NEC for r=1.0 all KL = 0.141 +- 0.225 (in-sample avg dev_std = 0.283)
NEC for r=1.0 all L1 = 0.138 +- 0.185 (in-sample avg dev_std = 0.283)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.957, 0.947, 0.989, 1.0], 'all_L1': [0.913, 0.895, 0.965, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.948, 0.934, 0.975, 1.0], 'all_L1': [0.902, 0.888, 0.958, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.93, 0.937, 0.979, 1.0], 'all_L1': [0.864, 0.885, 0.954, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.976, 0.966, 0.986, 1.0], 'all_L1': [0.943, 0.925, 0.961, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.936, 0.909, 0.976, 1.0], 'all_L1': [0.9, 0.871, 0.955, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.024, 0.05, 0.085, 0.095], 'all_L1': [0.066, 0.098, 0.116, 0.121]}), defaultdict(<class 'list'>, {'all_KL': [0.031, 0.067, 0.122, 0.148], 'all_L1': [0.078, 0.109, 0.136, 0.143]}), defaultdict(<class 'list'>, {'all_KL': [0.038, 0.067, 0.127, 0.143], 'all_L1': [0.104, 0.118, 0.142, 0.147]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.028, 0.073, 0.101], 'all_L1': [0.042, 0.071, 0.109, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.035, 0.077, 0.125, 0.141], 'all_L1': [0.078, 0.115, 0.133, 0.138]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.904 +- 0.025, 0.893 +- 0.018, 0.959 +- 0.004, 1.000 +- 0.000
suff++ class all_KL  =  0.949 +- 0.016, 0.939 +- 0.019, 0.981 +- 0.006, 1.000 +- 0.000
suff++_acc_int  =  0.605 +- 0.011, 0.738 +- 0.014, 0.810 +- 0.015
nec class all_L1  =  0.074 +- 0.020, 0.102 +- 0.017, 0.127 +- 0.013, 0.135 +- 0.010
nec class all_KL  =  0.028 +- 0.010, 0.058 +- 0.017, 0.106 +- 0.023, 0.126 +- 0.023
nec_acc_int  =  0.683 +- 0.012, 0.755 +- 0.022, 0.784 +- 0.018, 0.780 +- 0.015


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.489 +- 0.003, 0.498 +- 0.003, 0.543 +- 0.005, 0.568 +- 0.005
Faith. Armon (L1)= 		  =  0.135 +- 0.034, 0.183 +- 0.028, 0.224 +- 0.020, 0.238 +- 0.015
Faith. GMean (L1)= 	  =  0.255 +- 0.033, 0.301 +- 0.024, 0.349 +- 0.017, 0.368 +- 0.013
Faith. Aritm (KL)= 		  =  0.489 +- 0.003, 0.498 +- 0.003, 0.544 +- 0.009, 0.563 +- 0.011
Faith. Armon (KL)= 		  =  0.054 +- 0.018, 0.108 +- 0.031, 0.191 +- 0.037, 0.222 +- 0.036
Faith. GMean (KL)= 	  =  0.159 +- 0.030, 0.229 +- 0.036, 0.321 +- 0.035, 0.353 +- 0.033
Computed for split load_split = id



Completed in  0:03:32.106887  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:57:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:50 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:54 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:57:57 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:00 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:03 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ROC-AUC: 0.9940
Train Loss: 0.0391
ID Validation ROC-AUC: 0.8450
ID Validation Loss: 0.1821
ID Test ROC-AUC: 0.8077
ID Test Loss: 0.1679
OOD Validation ROC-AUC: 0.6969
OOD Validation Loss: 0.2009
OOD Test ROC-AUC: 0.6673
OOD Test Loss: 0.1473

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ROC-AUC: 0.9930
Train Loss: 0.0404
ID Validation ROC-AUC: 0.8284
ID Validation Loss: 0.1766
ID Test ROC-AUC: 0.8100
ID Test Loss: 0.1597
OOD Validation ROC-AUC: 0.7746
OOD Validation Loss: 0.1708
OOD Test ROC-AUC: 0.6410
OOD Test Loss: 0.1507

[0m[1;37mINFO[0m: [1mChartInfo 0.8077 0.6673 0.8100 0.6410 0.8284 0.7746[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:58:04 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.643
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.508
SUFF++ for r=0.8 class 0.0 = 0.666 +- 0.297 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.8 class 1.0 = 0.665 +- 0.297 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.8 all KL = 0.572 +- 0.297 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.8 all L1 = 0.665 +- 0.222 (in-sample avg dev_std = 0.522)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.643
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.526
NEC for r=0.8 class 0.0 = 0.288 +- 0.299 (in-sample avg dev_std = 0.269)
NEC for r=0.8 class 1.0 = 0.24 +- 0.299 (in-sample avg dev_std = 0.269)
NEC for r=0.8 all KL = 0.28 +- 0.299 (in-sample avg dev_std = 0.269)
NEC for r=0.8 all L1 = 0.264 +- 0.259 (in-sample avg dev_std = 0.269)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:58:15 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:15 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:19 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:23 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:26 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 129...
[0m[1;37mINFO[0m: [1mCheckpoint 129: 
-----------------------------------
Train ROC-AUC: 0.9987
Train Loss: 0.0183
ID Validation ROC-AUC: 0.8436
ID Validation Loss: 0.1867
ID Test ROC-AUC: 0.7972
ID Test Loss: 0.1808
OOD Validation ROC-AUC: 0.7113
OOD Validation Loss: 0.2083
OOD Test ROC-AUC: 0.6616
OOD Test Loss: 0.1540

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ROC-AUC: 0.8665
Train Loss: 0.1133
ID Validation ROC-AUC: 0.8073
ID Validation Loss: 0.1400
ID Test ROC-AUC: 0.8000
ID Test Loss: 0.1208
OOD Validation ROC-AUC: 0.7821
OOD Validation Loss: 0.1218
OOD Test ROC-AUC: 0.6412
OOD Test Loss: 0.0947

[0m[1;37mINFO[0m: [1mChartInfo 0.7972 0.6616 0.8000 0.6412 0.8073 0.7821[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:58:29 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.659
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.554
SUFF++ for r=0.8 class 0.0 = 0.899 +- 0.262 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.8 class 1.0 = 0.787 +- 0.262 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.8 all KL = 0.826 +- 0.262 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.8 all L1 = 0.843 +- 0.233 (in-sample avg dev_std = 0.271)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.659
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.626
NEC for r=0.8 class 0.0 = 0.158 +- 0.299 (in-sample avg dev_std = 0.292)
NEC for r=0.8 class 1.0 = 0.26 +- 0.299 (in-sample avg dev_std = 0.292)
NEC for r=0.8 all KL = 0.229 +- 0.299 (in-sample avg dev_std = 0.292)
NEC for r=0.8 all L1 = 0.209 +- 0.261 (in-sample avg dev_std = 0.292)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:58:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:39 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:43 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:46 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:49 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 32...
[0m[1;37mINFO[0m: [1mCheckpoint 32: 
-----------------------------------
Train ROC-AUC: 0.9615
Train Loss: 0.0758
ID Validation ROC-AUC: 0.8439
ID Validation Loss: 0.1249
ID Test ROC-AUC: 0.7995
ID Test Loss: 0.1163
OOD Validation ROC-AUC: 0.7437
OOD Validation Loss: 0.1234
OOD Test ROC-AUC: 0.6739
OOD Test Loss: 0.0957

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ROC-AUC: 0.8809
Train Loss: 0.1125
ID Validation ROC-AUC: 0.8182
ID Validation Loss: 0.1392
ID Test ROC-AUC: 0.7843
ID Test Loss: 0.1272
OOD Validation ROC-AUC: 0.7800
OOD Validation Loss: 0.1249
OOD Test ROC-AUC: 0.6692
OOD Test Loss: 0.0917

[0m[1;37mINFO[0m: [1mChartInfo 0.7995 0.6739 0.7843 0.6692 0.8182 0.7800[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:58:52 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.672
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.612
SUFF++ for r=0.8 class 0.0 = 0.923 +- 0.098 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.8 class 1.0 = 0.859 +- 0.098 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.8 all KL = 0.928 +- 0.098 (in-sample avg dev_std = 0.162)
SUFF++ for r=0.8 all L1 = 0.891 +- 0.120 (in-sample avg dev_std = 0.162)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.672
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.617
NEC for r=0.8 class 0.0 = 0.069 +- 0.080 (in-sample avg dev_std = 0.098)
NEC for r=0.8 class 1.0 = 0.106 +- 0.080 (in-sample avg dev_std = 0.098)
NEC for r=0.8 all KL = 0.046 +- 0.080 (in-sample avg dev_std = 0.098)
NEC for r=0.8 all L1 = 0.087 +- 0.106 (in-sample avg dev_std = 0.098)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:59:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:03 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:06 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:09 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:12 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ROC-AUC: 0.9983
Train Loss: 0.0242
ID Validation ROC-AUC: 0.8431
ID Validation Loss: 0.1834
ID Test ROC-AUC: 0.8028
ID Test Loss: 0.1734
OOD Validation ROC-AUC: 0.7364
OOD Validation Loss: 0.2070
OOD Test ROC-AUC: 0.6626
OOD Test Loss: 0.1633

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 38...
[0m[1;37mINFO[0m: [1mCheckpoint 38: 
-----------------------------------
Train ROC-AUC: 0.9560
Train Loss: 0.0779
ID Validation ROC-AUC: 0.8151
ID Validation Loss: 0.1518
ID Test ROC-AUC: 0.7777
ID Test Loss: 0.1370
OOD Validation ROC-AUC: 0.7910
OOD Validation Loss: 0.1230
OOD Test ROC-AUC: 0.6634
OOD Test Loss: 0.1055

[0m[1;37mINFO[0m: [1mChartInfo 0.8028 0.6626 0.7777 0.6634 0.8151 0.7910[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:59:15 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.641
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.559
SUFF++ for r=0.8 class 0.0 = 0.788 +- 0.315 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.8 class 1.0 = 0.741 +- 0.315 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.8 all KL = 0.639 +- 0.315 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.8 all L1 = 0.764 +- 0.217 (in-sample avg dev_std = 0.471)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.641
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.626
NEC for r=0.8 class 0.0 = 0.137 +- 0.260 (in-sample avg dev_std = 0.263)
NEC for r=0.8 class 1.0 = 0.156 +- 0.260 (in-sample avg dev_std = 0.263)
NEC for r=0.8 all KL = 0.188 +- 0.260 (in-sample avg dev_std = 0.263)
NEC for r=0.8 all L1 = 0.147 +- 0.198 (in-sample avg dev_std = 0.263)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 10:59:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:26 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:29 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:33 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:36 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ROC-AUC: 0.9711
Train Loss: 0.0868
ID Validation ROC-AUC: 0.8464
ID Validation Loss: 0.1631
ID Test ROC-AUC: 0.8070
ID Test Loss: 0.1620
OOD Validation ROC-AUC: 0.7678
OOD Validation Loss: 0.1715
OOD Test ROC-AUC: 0.7207
OOD Test Loss: 0.1109

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 8...
[0m[1;37mINFO[0m: [1mCheckpoint 8: 
-----------------------------------
Train ROC-AUC: 0.8237
Train Loss: 0.1344
ID Validation ROC-AUC: 0.7836
ID Validation Loss: 0.1594
ID Test ROC-AUC: 0.7505
ID Test Loss: 0.1407
OOD Validation ROC-AUC: 0.7881
OOD Validation Loss: 0.1099
OOD Test ROC-AUC: 0.7056
OOD Test Loss: 0.1049

[0m[1;37mINFO[0m: [1mChartInfo 0.8070 0.7207 0.7505 0.7056 0.7836 0.7881[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 10:59:39 AM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.674
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.644
SUFF++ for r=0.8 class 0.0 = 0.723 +- 0.206 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.8 class 1.0 = 0.725 +- 0.206 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.8 all KL = 0.781 +- 0.206 (in-sample avg dev_std = 0.362)
SUFF++ for r=0.8 all L1 = 0.724 +- 0.187 (in-sample avg dev_std = 0.362)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.8


Computing with masking

Model ROC-AUC of binarized graphs for r=0.8 =  0.674
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 272
Effective ratio: 0.808 +- 0.007
Model ROC-AUC over intervened graphs for r=0.8 =  0.629
NEC for r=0.8 class 0.0 = 0.204 +- 0.174 (in-sample avg dev_std = 0.229)
NEC for r=0.8 class 1.0 = 0.235 +- 0.174 (in-sample avg dev_std = 0.229)
NEC for r=0.8 all KL = 0.139 +- 0.174 (in-sample avg dev_std = 0.229)
NEC for r=0.8 all L1 = 0.219 +- 0.200 (in-sample avg dev_std = 0.229)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.572], 'all_L1': [0.665]}), defaultdict(<class 'list'>, {'all_KL': [0.826], 'all_L1': [0.843]}), defaultdict(<class 'list'>, {'all_KL': [0.928], 'all_L1': [0.891]}), defaultdict(<class 'list'>, {'all_KL': [0.639], 'all_L1': [0.764]}), defaultdict(<class 'list'>, {'all_KL': [0.781], 'all_L1': [0.724]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.28], 'all_L1': [0.264]}), defaultdict(<class 'list'>, {'all_KL': [0.229], 'all_L1': [0.209]}), defaultdict(<class 'list'>, {'all_KL': [0.046], 'all_L1': [0.087]}), defaultdict(<class 'list'>, {'all_KL': [0.188], 'all_L1': [0.147]}), defaultdict(<class 'list'>, {'all_KL': [0.139], 'all_L1': [0.219]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.777 +- 0.081
suff++ class all_KL  =  0.749 +- 0.128
suff++_acc_int  =  0.576 +- 0.048
nec class all_L1  =  0.185 +- 0.062
nec class all_KL  =  0.176 +- 0.080
nec_acc_int  =  0.605 +- 0.040


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.481 +- 0.025
Faith. Armon (L1)= 		  =  0.291 +- 0.079
Faith. GMean (L1)= 	  =  0.370 +- 0.055
Faith. Aritm (KL)= 		  =  0.463 +- 0.041
Faith. Armon (KL)= 		  =  0.270 +- 0.104
Faith. GMean (KL)= 	  =  0.344 +- 0.078
Computed for split load_split = id



Completed in  0:02:01.480798  for CIGAvGIN GOODHIV/scaffold



DONE CIGA GOODHIV/scaffold

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:00:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:00:03 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:00:34 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:00:44 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:00:55 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:10 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:25 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:01:26 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 174...
[0m[1;37mINFO[0m: [1mCheckpoint 174: 
-----------------------------------
Train ROC-AUC: 0.9747
Train Loss: 0.1592
ID Validation ROC-AUC: 0.9216
ID Validation Loss: 0.3096
ID Test ROC-AUC: 0.9242
ID Test Loss: 0.3130
OOD Validation ROC-AUC: 0.6625
OOD Validation Loss: 0.4639
OOD Test ROC-AUC: 0.7200
OOD Test Loss: 0.6879

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ROC-AUC: 0.9117
Train Loss: 0.2596
ID Validation ROC-AUC: 0.8990
ID Validation Loss: 0.2737
ID Test ROC-AUC: 0.9017
ID Test Loss: 0.2762
OOD Validation ROC-AUC: 0.6935
OOD Validation Loss: 0.2996
OOD Test ROC-AUC: 0.7346
OOD Test Loss: 0.4781

[0m[1;37mINFO[0m: [1mChartInfo 0.9242 0.7200 0.9017 0.7346 0.8990 0.6935[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:01:27 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.655
SUFF++ for r=0.3 class 0.0 = 0.699 +- 0.135 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 class 1.0 = 0.682 +- 0.135 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all KL = 0.83 +- 0.135 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all L1 = 0.684 +- 0.130 (in-sample avg dev_std = 0.319)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.797
SUFF++ for r=0.6 class 0.0 = 0.689 +- 0.170 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 class 1.0 = 0.799 +- 0.170 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 all KL = 0.849 +- 0.170 (in-sample avg dev_std = 0.308)
SUFF++ for r=0.6 all L1 = 0.786 +- 0.185 (in-sample avg dev_std = 0.308)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.896
SUFF++ for r=0.9 class 0.0 = 0.839 +- 0.118 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 class 1.0 = 0.932 +- 0.118 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all KL = 0.952 +- 0.118 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.9 all L1 = 0.921 +- 0.138 (in-sample avg dev_std = 0.183)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.68
NEC for r=0.3 class 0.0 = 0.261 +- 0.137 (in-sample avg dev_std = 0.267)
NEC for r=0.3 class 1.0 = 0.287 +- 0.137 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all KL = 0.14 +- 0.137 (in-sample avg dev_std = 0.267)
NEC for r=0.3 all L1 = 0.284 +- 0.143 (in-sample avg dev_std = 0.267)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.805
NEC for r=0.6 class 0.0 = 0.237 +- 0.145 (in-sample avg dev_std = 0.257)
NEC for r=0.6 class 1.0 = 0.171 +- 0.145 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all KL = 0.112 +- 0.145 (in-sample avg dev_std = 0.257)
NEC for r=0.6 all L1 = 0.179 +- 0.162 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.915
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.876
NEC for r=0.9 class 0.0 = 0.271 +- 0.183 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 1.0 = 0.112 +- 0.183 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all KL = 0.111 +- 0.183 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all L1 = 0.131 +- 0.175 (in-sample avg dev_std = 0.268)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.929
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.885
NEC for r=1.0 class 0.0 = 0.294 +- 0.196 (in-sample avg dev_std = 0.276)
NEC for r=1.0 class 1.0 = 0.1 +- 0.196 (in-sample avg dev_std = 0.276)
NEC for r=1.0 all KL = 0.113 +- 0.196 (in-sample avg dev_std = 0.276)
NEC for r=1.0 all L1 = 0.123 +- 0.182 (in-sample avg dev_std = 0.276)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:02:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:02:57 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:03:27 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:03:37 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:03:47 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:03 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:18 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:04:19 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9783
Train Loss: 0.1269
ID Validation ROC-AUC: 0.9244
ID Validation Loss: 0.2658
ID Test ROC-AUC: 0.9267
ID Test Loss: 0.2679
OOD Validation ROC-AUC: 0.6593
OOD Validation Loss: 0.4783
OOD Test ROC-AUC: 0.7128
OOD Test Loss: 0.6262

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9086
Train Loss: 0.2436
ID Validation ROC-AUC: 0.8959
ID Validation Loss: 0.2566
ID Test ROC-AUC: 0.8988
ID Test Loss: 0.2585
OOD Validation ROC-AUC: 0.6869
OOD Validation Loss: 0.2916
OOD Test ROC-AUC: 0.7309
OOD Test Loss: 0.4531

[0m[1;37mINFO[0m: [1mChartInfo 0.9267 0.7128 0.8988 0.7309 0.8959 0.6869[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:04:20 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.65
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 782
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
SUFF++ for r=0.3 class 0.0 = 0.755 +- 0.110 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 class 1.0 = 0.766 +- 0.110 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all KL = 0.897 +- 0.110 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all L1 = 0.765 +- 0.099 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.761
SUFF++ for r=0.6 class 0.0 = 0.79 +- 0.153 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 class 1.0 = 0.802 +- 0.153 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all KL = 0.877 +- 0.153 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.6 all L1 = 0.8 +- 0.144 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.905
SUFF++ for r=0.9 class 0.0 = 0.898 +- 0.067 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.067 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all KL = 0.977 +- 0.067 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all L1 = 0.946 +- 0.083 (in-sample avg dev_std = 0.130)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0.0 = 0.173 +- 0.086 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 1.0 = 0.206 +- 0.086 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all KL = 0.073 +- 0.086 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all L1 = 0.202 +- 0.113 (in-sample avg dev_std = 0.209)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.831
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.784
NEC for r=0.6 class 0.0 = 0.216 +- 0.116 (in-sample avg dev_std = 0.238)
NEC for r=0.6 class 1.0 = 0.165 +- 0.116 (in-sample avg dev_std = 0.238)
NEC for r=0.6 all KL = 0.091 +- 0.116 (in-sample avg dev_std = 0.238)
NEC for r=0.6 all L1 = 0.171 +- 0.130 (in-sample avg dev_std = 0.238)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.858
NEC for r=0.9 class 0.0 = 0.262 +- 0.129 (in-sample avg dev_std = 0.227)
NEC for r=0.9 class 1.0 = 0.118 +- 0.129 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all KL = 0.087 +- 0.129 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all L1 = 0.135 +- 0.150 (in-sample avg dev_std = 0.227)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.922
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.877
NEC for r=1.0 class 0.0 = 0.283 +- 0.157 (in-sample avg dev_std = 0.248)
NEC for r=1.0 class 1.0 = 0.111 +- 0.157 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all KL = 0.097 +- 0.157 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all L1 = 0.131 +- 0.164 (in-sample avg dev_std = 0.248)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:05:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:05:46 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:06:16 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:06:26 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:06:36 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:06:52 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ROC-AUC: 0.9586
Train Loss: 0.1793
ID Validation ROC-AUC: 0.9217
ID Validation Loss: 0.2533
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2525
OOD Validation ROC-AUC: 0.6759
OOD Validation Loss: 0.3745
OOD Test ROC-AUC: 0.7109
OOD Test Loss: 0.5685

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ROC-AUC: 0.9479
Train Loss: 0.1985
ID Validation ROC-AUC: 0.9155
ID Validation Loss: 0.2618
ID Test ROC-AUC: 0.9197
ID Test Loss: 0.2606
OOD Validation ROC-AUC: 0.6885
OOD Validation Loss: 0.3598
OOD Test ROC-AUC: 0.7250
OOD Test Loss: 0.5469

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7109 0.9197 0.7250 0.9155 0.6885[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:07:07 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.765
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.66
SUFF++ for r=0.3 class 0.0 = 0.716 +- 0.083 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 class 1.0 = 0.724 +- 0.083 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all KL = 0.884 +- 0.083 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all L1 = 0.723 +- 0.106 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.878
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.79
SUFF++ for r=0.6 class 0.0 = 0.664 +- 0.091 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 class 1.0 = 0.842 +- 0.091 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all KL = 0.908 +- 0.091 (in-sample avg dev_std = 0.228)
SUFF++ for r=0.6 all L1 = 0.82 +- 0.147 (in-sample avg dev_std = 0.228)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.884
SUFF++ for r=0.9 class 0.0 = 0.777 +- 0.058 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.9 class 1.0 = 0.927 +- 0.058 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.9 all KL = 0.964 +- 0.058 (in-sample avg dev_std = 0.151)
SUFF++ for r=0.9 all L1 = 0.909 +- 0.115 (in-sample avg dev_std = 0.151)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.765
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.736
NEC for r=0.3 class 0.0 = 0.216 +- 0.088 (in-sample avg dev_std = 0.204)
NEC for r=0.3 class 1.0 = 0.262 +- 0.088 (in-sample avg dev_std = 0.204)
NEC for r=0.3 all KL = 0.095 +- 0.088 (in-sample avg dev_std = 0.204)
NEC for r=0.3 all L1 = 0.256 +- 0.121 (in-sample avg dev_std = 0.204)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.878
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.836
NEC for r=0.6 class 0.0 = 0.245 +- 0.090 (in-sample avg dev_std = 0.179)
NEC for r=0.6 class 1.0 = 0.149 +- 0.090 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all KL = 0.073 +- 0.090 (in-sample avg dev_std = 0.179)
NEC for r=0.6 all L1 = 0.161 +- 0.132 (in-sample avg dev_std = 0.179)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.879
NEC for r=0.9 class 0.0 = 0.22 +- 0.091 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 1.0 = 0.095 +- 0.091 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all KL = 0.055 +- 0.091 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all L1 = 0.109 +- 0.127 (in-sample avg dev_std = 0.172)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.923
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.884
NEC for r=1.0 class 0.0 = 0.218 +- 0.095 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1.0 = 0.09 +- 0.095 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.056 +- 0.095 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.106 +- 0.127 (in-sample avg dev_std = 0.173)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:08:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:08:42 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:09:12 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:09:22 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:09:32 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:09:48 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ROC-AUC: 0.9561
Train Loss: 0.1699
ID Validation ROC-AUC: 0.9223
ID Validation Loss: 0.2340
ID Test ROC-AUC: 0.9235
ID Test Loss: 0.2358
OOD Validation ROC-AUC: 0.6576
OOD Validation Loss: 0.3970
OOD Test ROC-AUC: 0.7067
OOD Test Loss: 0.5494

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ROC-AUC: 0.9016
Train Loss: 0.2482
ID Validation ROC-AUC: 0.8949
ID Validation Loss: 0.2557
ID Test ROC-AUC: 0.8953
ID Test Loss: 0.2587
OOD Validation ROC-AUC: 0.6908
OOD Validation Loss: 0.2916
OOD Test ROC-AUC: 0.7285
OOD Test Loss: 0.4503

[0m[1;37mINFO[0m: [1mChartInfo 0.9235 0.7067 0.8953 0.7285 0.8949 0.6908[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:10:03 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.596
SUFF++ for r=0.3 class 0.0 = 0.744 +- 0.073 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 1.0 = 0.753 +- 0.073 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all KL = 0.918 +- 0.073 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all L1 = 0.752 +- 0.087 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.753
SUFF++ for r=0.6 class 0.0 = 0.727 +- 0.090 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 class 1.0 = 0.778 +- 0.090 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all KL = 0.899 +- 0.090 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.6 all L1 = 0.772 +- 0.118 (in-sample avg dev_std = 0.247)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.884
SUFF++ for r=0.9 class 0.0 = 0.801 +- 0.081 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 class 1.0 = 0.901 +- 0.081 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all KL = 0.95 +- 0.081 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all L1 = 0.889 +- 0.115 (in-sample avg dev_std = 0.180)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.608
NEC for r=0.3 class 0.0 = 0.196 +- 0.065 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1.0 = 0.218 +- 0.065 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.06 +- 0.065 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.216 +- 0.101 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.783
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.758
NEC for r=0.6 class 0.0 = 0.245 +- 0.100 (in-sample avg dev_std = 0.211)
NEC for r=0.6 class 1.0 = 0.222 +- 0.100 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all KL = 0.096 +- 0.100 (in-sample avg dev_std = 0.211)
NEC for r=0.6 all L1 = 0.225 +- 0.124 (in-sample avg dev_std = 0.211)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.92
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.869
NEC for r=0.9 class 0.0 = 0.207 +- 0.105 (in-sample avg dev_std = 0.205)
NEC for r=0.9 class 1.0 = 0.142 +- 0.105 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all KL = 0.08 +- 0.105 (in-sample avg dev_std = 0.205)
NEC for r=0.9 all L1 = 0.15 +- 0.130 (in-sample avg dev_std = 0.205)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.877
NEC for r=1.0 class 0.0 = 0.211 +- 0.106 (in-sample avg dev_std = 0.198)
NEC for r=1.0 class 1.0 = 0.114 +- 0.106 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all KL = 0.07 +- 0.106 (in-sample avg dev_std = 0.198)
NEC for r=1.0 all L1 = 0.126 +- 0.127 (in-sample avg dev_std = 0.198)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:11:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:11:36 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:07 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:16 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:27 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:43 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ROC-AUC: 0.9604
Train Loss: 0.1577
ID Validation ROC-AUC: 0.9213
ID Validation Loss: 0.2276
ID Test ROC-AUC: 0.9231
ID Test Loss: 0.2288
OOD Validation ROC-AUC: 0.6638
OOD Validation Loss: 0.4052
OOD Test ROC-AUC: 0.7105
OOD Test Loss: 0.5421

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ROC-AUC: 0.8989
Train Loss: 0.2529
ID Validation ROC-AUC: 0.8912
ID Validation Loss: 0.2608
ID Test ROC-AUC: 0.8911
ID Test Loss: 0.2654
OOD Validation ROC-AUC: 0.6866
OOD Validation Loss: 0.2898
OOD Test ROC-AUC: 0.7229
OOD Test Loss: 0.4564

[0m[1;37mINFO[0m: [1mChartInfo 0.9231 0.7105 0.8911 0.7229 0.8912 0.6866[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:12:58 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.587
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.603
SUFF++ for r=0.3 class 0.0 = 0.768 +- 0.063 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 class 1.0 = 0.751 +- 0.063 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all KL = 0.92 +- 0.063 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.3 all L1 = 0.753 +- 0.086 (in-sample avg dev_std = 0.243)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.742
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.7
SUFF++ for r=0.6 class 0.0 = 0.728 +- 0.127 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 class 1.0 = 0.736 +- 0.127 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all KL = 0.858 +- 0.127 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.6 all L1 = 0.735 +- 0.110 (in-sample avg dev_std = 0.276)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.879
SUFF++ for r=0.9 class 0.0 = 0.844 +- 0.102 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 class 1.0 = 0.885 +- 0.102 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all KL = 0.942 +- 0.102 (in-sample avg dev_std = 0.172)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.112 (in-sample avg dev_std = 0.172)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.587
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.614
NEC for r=0.3 class 0.0 = 0.233 +- 0.074 (in-sample avg dev_std = 0.196)
NEC for r=0.3 class 1.0 = 0.246 +- 0.074 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all KL = 0.075 +- 0.074 (in-sample avg dev_std = 0.196)
NEC for r=0.3 all L1 = 0.244 +- 0.109 (in-sample avg dev_std = 0.196)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.742
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.739
NEC for r=0.6 class 0.0 = 0.25 +- 0.134 (in-sample avg dev_std = 0.260)
NEC for r=0.6 class 1.0 = 0.261 +- 0.134 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all KL = 0.135 +- 0.134 (in-sample avg dev_std = 0.260)
NEC for r=0.6 all L1 = 0.26 +- 0.124 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.849
NEC for r=0.9 class 0.0 = 0.21 +- 0.159 (in-sample avg dev_std = 0.263)
NEC for r=0.9 class 1.0 = 0.196 +- 0.159 (in-sample avg dev_std = 0.263)
NEC for r=0.9 all KL = 0.132 +- 0.159 (in-sample avg dev_std = 0.263)
NEC for r=0.9 all L1 = 0.198 +- 0.134 (in-sample avg dev_std = 0.263)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.86
NEC for r=1.0 class 0.0 = 0.19 +- 0.164 (in-sample avg dev_std = 0.255)
NEC for r=1.0 class 1.0 = 0.164 +- 0.164 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all KL = 0.12 +- 0.164 (in-sample avg dev_std = 0.255)
NEC for r=1.0 all L1 = 0.167 +- 0.133 (in-sample avg dev_std = 0.255)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.83, 0.849, 0.952, 1.0], 'all_L1': [0.684, 0.786, 0.921, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.897, 0.877, 0.977, 1.0], 'all_L1': [0.765, 0.8, 0.946, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.884, 0.908, 0.964, 1.0], 'all_L1': [0.723, 0.82, 0.909, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.918, 0.899, 0.95, 1.0], 'all_L1': [0.752, 0.772, 0.889, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.92, 0.858, 0.942, 1.0], 'all_L1': [0.753, 0.735, 0.88, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.14, 0.112, 0.111, 0.113], 'all_L1': [0.284, 0.179, 0.131, 0.123]}), defaultdict(<class 'list'>, {'all_KL': [0.073, 0.091, 0.087, 0.097], 'all_L1': [0.202, 0.171, 0.135, 0.131]}), defaultdict(<class 'list'>, {'all_KL': [0.095, 0.073, 0.055, 0.056], 'all_L1': [0.256, 0.161, 0.109, 0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.06, 0.096, 0.08, 0.07], 'all_L1': [0.216, 0.225, 0.15, 0.126]}), defaultdict(<class 'list'>, {'all_KL': [0.075, 0.135, 0.132, 0.12], 'all_L1': [0.244, 0.26, 0.198, 0.167]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.735 +- 0.029, 0.783 +- 0.029, 0.909 +- 0.023, 1.000 +- 0.000
suff++ class all_KL  =  0.890 +- 0.033, 0.878 +- 0.023, 0.957 +- 0.012, 1.000 +- 0.000
suff++_acc_int  =  0.619 +- 0.033, 0.761 +- 0.034, 0.890 +- 0.009
nec class all_L1  =  0.240 +- 0.029, 0.199 +- 0.037, 0.145 +- 0.030, 0.131 +- 0.020
nec class all_KL  =  0.089 +- 0.028, 0.101 +- 0.021, 0.093 +- 0.026, 0.091 +- 0.025
nec_acc_int  =  0.649 +- 0.051, 0.784 +- 0.034, 0.866 +- 0.011, 0.876 +- 0.009


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.488 +- 0.006, 0.491 +- 0.006, 0.527 +- 0.012, 0.565 +- 0.010
Faith. Armon (L1)= 		  =  0.361 +- 0.029, 0.315 +- 0.044, 0.248 +- 0.043, 0.230 +- 0.031
Faith. GMean (L1)= 	  =  0.419 +- 0.018, 0.392 +- 0.029, 0.360 +- 0.033, 0.360 +- 0.027
Faith. Aritm (KL)= 		  =  0.489 +- 0.005, 0.490 +- 0.007, 0.525 +- 0.011, 0.546 +- 0.012
Faith. Armon (KL)= 		  =  0.159 +- 0.044, 0.181 +- 0.033, 0.168 +- 0.044, 0.166 +- 0.042
Faith. GMean (KL)= 	  =  0.277 +- 0.037, 0.296 +- 0.028, 0.295 +- 0.042, 0.299 +- 0.042
Computed for split load_split = id



Completed in  0:14:28.957403  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:14:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:14:48 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:15:19 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:15:29 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:15:39 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:15:54 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:16:10 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 23...
[0m[1;37mINFO[0m: [1mCheckpoint 23: 
-----------------------------------
Train ROC-AUC: 0.9686
Train Loss: 0.1597
ID Validation ROC-AUC: 0.9236
ID Validation Loss: 0.2366
ID Test ROC-AUC: 0.9233
ID Test Loss: 0.2412
OOD Validation ROC-AUC: 0.6572
OOD Validation Loss: 0.3846
OOD Test ROC-AUC: 0.6967
OOD Test Loss: 0.5574

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 1...
[0m[1;37mINFO[0m: [1mCheckpoint 1: 
-----------------------------------
Train ROC-AUC: 0.8713
Train Loss: 0.2869
ID Validation ROC-AUC: 0.8665
ID Validation Loss: 0.2911
ID Test ROC-AUC: 0.8695
ID Test Loss: 0.2927
OOD Validation ROC-AUC: 0.6861
OOD Validation Loss: 0.2792
OOD Test ROC-AUC: 0.7034
OOD Test Loss: 0.4207

[0m[1;37mINFO[0m: [1mChartInfo 0.9233 0.6967 0.8695 0.7034 0.8665 0.6861[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:16:11 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.63
SUFF++ for r=0.6 class 0.0 = 0.81 +- 0.050 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.6 class 1.0 = 0.866 +- 0.050 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.6 all KL = 0.951 +- 0.050 (in-sample avg dev_std = 0.143)
SUFF++ for r=0.6 all L1 = 0.859 +- 0.074 (in-sample avg dev_std = 0.143)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.69
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.694
NEC for r=0.6 class 0.0 = 0.128 +- 0.027 (in-sample avg dev_std = 0.086)
NEC for r=0.6 class 1.0 = 0.086 +- 0.027 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all KL = 0.019 +- 0.027 (in-sample avg dev_std = 0.086)
NEC for r=0.6 all L1 = 0.091 +- 0.063 (in-sample avg dev_std = 0.086)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:16:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:16:46 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:17:16 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:17:26 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:17:37 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:17:52 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:07 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:08 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:08 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:08 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:18:08 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 37...
[0m[1;37mINFO[0m: [1mCheckpoint 37: 
-----------------------------------
Train ROC-AUC: 0.9829
Train Loss: 0.1261
ID Validation ROC-AUC: 0.9196
ID Validation Loss: 0.2917
ID Test ROC-AUC: 0.9170
ID Test Loss: 0.3056
OOD Validation ROC-AUC: 0.6433
OOD Validation Loss: 0.4965
OOD Test ROC-AUC: 0.6785
OOD Test Loss: 0.7235

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8825
Train Loss: 0.2710
ID Validation ROC-AUC: 0.8746
ID Validation Loss: 0.2831
ID Test ROC-AUC: 0.8768
ID Test Loss: 0.2841
OOD Validation ROC-AUC: 0.6840
OOD Validation Loss: 0.3139
OOD Test ROC-AUC: 0.7101
OOD Test Loss: 0.4991

[0m[1;37mINFO[0m: [1mChartInfo 0.9170 0.6785 0.8768 0.7101 0.8746 0.6840[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:18:08 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0.0 = 0.704 +- 0.138 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 class 1.0 = 0.82 +- 0.138 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all KL = 0.856 +- 0.138 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.6 all L1 = 0.806 +- 0.171 (in-sample avg dev_std = 0.242)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.707
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.696
NEC for r=0.6 class 0.0 = 0.284 +- 0.124 (in-sample avg dev_std = 0.171)
NEC for r=0.6 class 1.0 = 0.155 +- 0.124 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all KL = 0.103 +- 0.124 (in-sample avg dev_std = 0.171)
NEC for r=0.6 all L1 = 0.17 +- 0.172 (in-sample avg dev_std = 0.171)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:18:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:18:42 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:19:12 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:19:22 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:19:32 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:19:48 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ROC-AUC: 0.9540
Train Loss: 0.1749
ID Validation ROC-AUC: 0.9236
ID Validation Loss: 0.2164
ID Test ROC-AUC: 0.9206
ID Test Loss: 0.2244
OOD Validation ROC-AUC: 0.6596
OOD Validation Loss: 0.3480
OOD Test ROC-AUC: 0.6987
OOD Test Loss: 0.4931

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8972
Train Loss: 0.2438
ID Validation ROC-AUC: 0.8845
ID Validation Loss: 0.2539
ID Test ROC-AUC: 0.8865
ID Test Loss: 0.2549
OOD Validation ROC-AUC: 0.6935
OOD Validation Loss: 0.2839
OOD Test ROC-AUC: 0.7162
OOD Test Loss: 0.4332

[0m[1;37mINFO[0m: [1mChartInfo 0.9206 0.6987 0.8865 0.7162 0.8845 0.6935[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:20:03 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.545
SUFF++ for r=0.6 class 0.0 = 0.885 +- 0.023 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.6 class 1.0 = 0.884 +- 0.023 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.6 all KL = 0.983 +- 0.023 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.6 all L1 = 0.884 +- 0.045 (in-sample avg dev_std = 0.105)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.59
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.561
NEC for r=0.6 class 0.0 = 0.06 +- 0.020 (in-sample avg dev_std = 0.058)
NEC for r=0.6 class 1.0 = 0.065 +- 0.020 (in-sample avg dev_std = 0.058)
NEC for r=0.6 all KL = 0.006 +- 0.020 (in-sample avg dev_std = 0.058)
NEC for r=0.6 all L1 = 0.065 +- 0.034 (in-sample avg dev_std = 0.058)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:20:38 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:20:38 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:09 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:18 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:29 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:44 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:21:59 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 31...
[0m[1;37mINFO[0m: [1mCheckpoint 31: 
-----------------------------------
Train ROC-AUC: 0.9785
Train Loss: 0.1297
ID Validation ROC-AUC: 0.9231
ID Validation Loss: 0.2533
ID Test ROC-AUC: 0.9232
ID Test Loss: 0.2591
OOD Validation ROC-AUC: 0.6355
OOD Validation Loss: 0.4365
OOD Test ROC-AUC: 0.6820
OOD Test Loss: 0.6119

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 7...
[0m[1;37mINFO[0m: [1mCheckpoint 7: 
-----------------------------------
Train ROC-AUC: 0.9090
Train Loss: 0.2539
ID Validation ROC-AUC: 0.8928
ID Validation Loss: 0.2745
ID Test ROC-AUC: 0.8905
ID Test Loss: 0.2822
OOD Validation ROC-AUC: 0.6800
OOD Validation Loss: 0.3263
OOD Test ROC-AUC: 0.7103
OOD Test Loss: 0.5223

[0m[1;37mINFO[0m: [1mChartInfo 0.9232 0.6820 0.8905 0.7103 0.8928 0.6800[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:22:00 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.616
SUFF++ for r=0.6 class 0.0 = 0.723 +- 0.220 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 class 1.0 = 0.677 +- 0.220 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 all KL = 0.807 +- 0.220 (in-sample avg dev_std = 0.325)
SUFF++ for r=0.6 all L1 = 0.682 +- 0.164 (in-sample avg dev_std = 0.325)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.618
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.575
NEC for r=0.6 class 0.0 = 0.214 +- 0.139 (in-sample avg dev_std = 0.221)
NEC for r=0.6 class 1.0 = 0.196 +- 0.139 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all KL = 0.088 +- 0.139 (in-sample avg dev_std = 0.221)
NEC for r=0.6 all L1 = 0.198 +- 0.139 (in-sample avg dev_std = 0.221)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:22:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 11:22:34 AM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:04 AM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:14 AM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:24 AM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:40 AM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit Backbone:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mCreating vGINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit CLF:  3
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ROC-AUC: 0.9685
Train Loss: 0.1653
ID Validation ROC-AUC: 0.9224
ID Validation Loss: 0.2315
ID Test ROC-AUC: 0.9196
ID Test Loss: 0.2391
OOD Validation ROC-AUC: 0.6434
OOD Validation Loss: 0.3691
OOD Test ROC-AUC: 0.6778
OOD Test Loss: 0.5284

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 3...
[0m[1;37mINFO[0m: [1mCheckpoint 3: 
-----------------------------------
Train ROC-AUC: 0.8955
Train Loss: 0.2439
ID Validation ROC-AUC: 0.8855
ID Validation Loss: 0.2541
ID Test ROC-AUC: 0.8869
ID Test Loss: 0.2554
OOD Validation ROC-AUC: 0.6944
OOD Validation Loss: 0.2933
OOD Test ROC-AUC: 0.7180
OOD Test Loss: 0.4561

[0m[1;37mINFO[0m: [1mChartInfo 0.9196 0.6778 0.8869 0.7180 0.8855 0.6944[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 11:23:55 AM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.334
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.434
SUFF++ for r=0.6 class 0.0 = 0.888 +- 0.011 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.6 class 1.0 = 0.918 +- 0.011 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.6 all KL = 0.992 +- 0.011 (in-sample avg dev_std = 0.073)
SUFF++ for r=0.6 all L1 = 0.914 +- 0.046 (in-sample avg dev_std = 0.073)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.334
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.325
NEC for r=0.6 class 0.0 = 0.052 +- 0.004 (in-sample avg dev_std = 0.035)
NEC for r=0.6 class 1.0 = 0.04 +- 0.004 (in-sample avg dev_std = 0.035)
NEC for r=0.6 all KL = 0.002 +- 0.004 (in-sample avg dev_std = 0.035)
NEC for r=0.6 all L1 = 0.042 +- 0.024 (in-sample avg dev_std = 0.035)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.951], 'all_L1': [0.859]}), defaultdict(<class 'list'>, {'all_KL': [0.856], 'all_L1': [0.806]}), defaultdict(<class 'list'>, {'all_KL': [0.983], 'all_L1': [0.884]}), defaultdict(<class 'list'>, {'all_KL': [0.807], 'all_L1': [0.682]}), defaultdict(<class 'list'>, {'all_KL': [0.992], 'all_L1': [0.914]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.019], 'all_L1': [0.091]}), defaultdict(<class 'list'>, {'all_KL': [0.103], 'all_L1': [0.17]}), defaultdict(<class 'list'>, {'all_KL': [0.006], 'all_L1': [0.065]}), defaultdict(<class 'list'>, {'all_KL': [0.088], 'all_L1': [0.198]}), defaultdict(<class 'list'>, {'all_KL': [0.002], 'all_L1': [0.042]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.829 +- 0.082
suff++ class all_KL  =  0.918 +- 0.073
suff++_acc_int  =  0.571 +- 0.075
nec class all_L1  =  0.113 +- 0.061
nec class all_KL  =  0.044 +- 0.043
nec_acc_int  =  0.570 +- 0.135


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.471 +- 0.016
Faith. Armon (L1)= 		  =  0.191 +- 0.089
Faith. GMean (L1)= 	  =  0.291 +- 0.069
Faith. Aritm (KL)= 		  =  0.481 +- 0.018
Faith. Armon (KL)= 		  =  0.079 +- 0.076
Faith. GMean (KL)= 	  =  0.164 +- 0.101
Computed for split load_split = id



Completed in  0:09:42.354568  for CIGAvGIN LBAPcore/assay



DONE CIGA LBAPcore/assay

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:24:46 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:24:47 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9879
Train Loss: 0.0408
ID Validation ACCURACY: 0.8967
ID Validation Loss: 0.3836
ID Test ACCURACY: 0.8910
ID Test Loss: 0.3737
OOD Validation ACCURACY: 0.8210
OOD Validation Loss: 0.7581
OOD Test ACCURACY: 0.3357
OOD Test Loss: 4.8493

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ACCURACY: 0.9669
Train Loss: 0.1038
ID Validation ACCURACY: 0.8889
ID Validation Loss: 0.3636
ID Test ACCURACY: 0.8920
ID Test Loss: 0.3454
OOD Validation ACCURACY: 0.8796
OOD Validation Loss: 0.3944
OOD Test ACCURACY: 0.5937
OOD Test Loss: 1.5026

[0m[1;37mINFO[0m: [1mChartInfo 0.8910 0.3357 0.8920 0.5937 0.8889 0.8796[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.601 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 1 = 0.573 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 2 = 0.606 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 3 = 0.615 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 4 = 0.618 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 5 = 0.604 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 6 = 0.596 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 7 = 0.596 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 8 = 0.582 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 9 = 0.59 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all KL = 0.731 +- 0.145 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all L1 = 0.598 +- 0.110 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.25
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.163
SUFF++ for r=0.6 class 0 = 0.406 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1 = 0.356 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 2 = 0.389 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 3 = 0.382 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 4 = 0.376 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 5 = 0.392 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 6 = 0.428 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 7 = 0.421 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 8 = 0.384 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 9 = 0.41 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.359 +- 0.220 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.394 +- 0.126 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.768
SUFF++ for r=0.9 class 0 = 0.919 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 1 = 0.913 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 2 = 0.786 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 3 = 0.779 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 4 = 0.797 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 5 = 0.783 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 6 = 0.854 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 7 = 0.83 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 8 = 0.844 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 9 = 0.748 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all KL = 0.848 +- 0.214 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all L1 = 0.827 +- 0.199 (in-sample avg dev_std = 0.247)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.116
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
NEC for r=0.3 class 0 = 0.407 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 1 = 0.418 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 2 = 0.394 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 3 = 0.402 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 4 = 0.404 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 5 = 0.403 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 6 = 0.408 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 7 = 0.405 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 8 = 0.395 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 class 9 = 0.398 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all KL = 0.239 +- 0.147 (in-sample avg dev_std = 0.221)
NEC for r=0.3 all L1 = 0.404 +- 0.116 (in-sample avg dev_std = 0.221)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.25
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.208
NEC for r=0.6 class 0 = 0.458 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 1 = 0.485 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 2 = 0.505 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 3 = 0.496 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 4 = 0.537 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 5 = 0.513 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 6 = 0.49 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 7 = 0.509 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 8 = 0.527 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 class 9 = 0.534 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all KL = 0.457 +- 0.203 (in-sample avg dev_std = 0.329)
NEC for r=0.6 all L1 = 0.505 +- 0.136 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.659
NEC for r=0.9 class 0 = 0.305 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.198 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.367 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 3 = 0.438 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 4 = 0.385 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 5 = 0.505 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 6 = 0.38 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 7 = 0.417 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 8 = 0.324 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 9 = 0.466 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.523 +- 0.303 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.375 +- 0.244 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.951
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.848
NEC for r=1.0 class 0 = 0.101 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 1 = 0.061 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 2 = 0.279 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 3 = 0.328 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 4 = 0.213 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 5 = 0.306 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 6 = 0.227 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 7 = 0.207 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 8 = 0.167 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 class 9 = 0.392 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 all KL = 0.359 +- 0.325 (in-sample avg dev_std = 0.386)
NEC for r=1.0 all L1 = 0.225 +- 0.235 (in-sample avg dev_std = 0.386)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:31:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:46 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:31:47 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 198...
[0m[1;37mINFO[0m: [1mCheckpoint 198: 
-----------------------------------
Train ACCURACY: 0.9954
Train Loss: 0.0235
ID Validation ACCURACY: 0.9044
ID Validation Loss: 0.3485
ID Test ACCURACY: 0.8980
ID Test Loss: 0.3777
OOD Validation ACCURACY: 0.8489
OOD Validation Loss: 0.5902
OOD Test ACCURACY: 0.4007
OOD Test Loss: 3.1852

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 79...
[0m[1;37mINFO[0m: [1mCheckpoint 79: 
-----------------------------------
Train ACCURACY: 0.9265
Train Loss: 0.2243
ID Validation ACCURACY: 0.8853
ID Validation Loss: 0.3617
ID Test ACCURACY: 0.8787
ID Test Loss: 0.3669
OOD Validation ACCURACY: 0.8706
OOD Validation Loss: 0.3979
OOD Test ACCURACY: 0.4916
OOD Test Loss: 2.4039

[0m[1;37mINFO[0m: [1mChartInfo 0.8980 0.4007 0.8787 0.4916 0.8853 0.8706[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.58 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 1 = 0.53 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 2 = 0.572 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 3 = 0.575 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 4 = 0.568 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 5 = 0.572 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 6 = 0.556 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 7 = 0.572 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 8 = 0.55 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 class 9 = 0.555 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 all KL = 0.674 +- 0.134 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.3 all L1 = 0.563 +- 0.084 (in-sample avg dev_std = 0.311)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.278
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.194
SUFF++ for r=0.6 class 0 = 0.475 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 1 = 0.478 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 2 = 0.481 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 3 = 0.44 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 4 = 0.48 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 5 = 0.44 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 6 = 0.453 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 7 = 0.486 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 8 = 0.421 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 class 9 = 0.426 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all KL = 0.482 +- 0.219 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.6 all L1 = 0.458 +- 0.140 (in-sample avg dev_std = 0.285)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.757
SUFF++ for r=0.9 class 0 = 0.923 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 1 = 0.926 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 2 = 0.787 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 3 = 0.737 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 4 = 0.782 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 5 = 0.782 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 6 = 0.815 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 7 = 0.781 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 8 = 0.755 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 class 9 = 0.731 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 all KL = 0.795 +- 0.254 (in-sample avg dev_std = 0.291)
SUFF++ for r=0.9 all L1 = 0.803 +- 0.208 (in-sample avg dev_std = 0.291)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
NEC for r=0.3 class 0 = 0.361 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 1 = 0.367 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 2 = 0.327 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 3 = 0.347 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 4 = 0.342 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 5 = 0.359 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 6 = 0.358 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 7 = 0.355 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 8 = 0.334 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 class 9 = 0.37 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 all KL = 0.175 +- 0.124 (in-sample avg dev_std = 0.174)
NEC for r=0.3 all L1 = 0.352 +- 0.108 (in-sample avg dev_std = 0.174)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.278
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.219
NEC for r=0.6 class 0 = 0.428 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 1 = 0.427 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 2 = 0.456 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 3 = 0.475 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 4 = 0.47 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 5 = 0.48 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 6 = 0.517 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 7 = 0.471 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 8 = 0.507 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 class 9 = 0.518 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 all KL = 0.397 +- 0.203 (in-sample avg dev_std = 0.285)
NEC for r=0.6 all L1 = 0.474 +- 0.135 (in-sample avg dev_std = 0.285)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.82
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.667
NEC for r=0.9 class 0 = 0.28 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 1 = 0.096 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 2 = 0.37 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 3 = 0.475 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 4 = 0.369 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 5 = 0.476 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 6 = 0.368 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 7 = 0.386 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 8 = 0.486 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 class 9 = 0.497 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 all KL = 0.526 +- 0.313 (in-sample avg dev_std = 0.427)
NEC for r=0.9 all L1 = 0.376 +- 0.251 (in-sample avg dev_std = 0.427)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.955
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.85
NEC for r=1.0 class 0 = 0.098 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 1 = 0.032 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 2 = 0.244 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 3 = 0.321 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 4 = 0.233 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 5 = 0.264 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 6 = 0.212 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 7 = 0.228 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 8 = 0.244 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 class 9 = 0.372 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 all KL = 0.36 +- 0.329 (in-sample avg dev_std = 0.373)
NEC for r=1.0 all L1 = 0.222 +- 0.233 (in-sample avg dev_std = 0.373)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:38:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:38:50 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9962
Train Loss: 0.0184
ID Validation ACCURACY: 0.8971
ID Validation Loss: 0.4034
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3939
OOD Validation ACCURACY: 0.7454
OOD Validation Loss: 1.2265
OOD Test ACCURACY: 0.2080
OOD Test Loss: 15.1594

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.9543
Train Loss: 0.1370
ID Validation ACCURACY: 0.8837
ID Validation Loss: 0.3612
ID Test ACCURACY: 0.8867
ID Test Loss: 0.3557
OOD Validation ACCURACY: 0.8760
OOD Validation Loss: 0.3949
OOD Test ACCURACY: 0.6457
OOD Test Loss: 1.3561

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.2080 0.8867 0.6457 0.8837 0.8760[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.44 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 1 = 0.342 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 2 = 0.442 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 3 = 0.447 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 4 = 0.439 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 5 = 0.445 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 6 = 0.452 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 7 = 0.442 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 8 = 0.45 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 9 = 0.447 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all KL = 0.483 +- 0.178 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all L1 = 0.433 +- 0.090 (in-sample avg dev_std = 0.443)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.271
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.174
SUFF++ for r=0.6 class 0 = 0.297 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 1 = 0.488 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 2 = 0.313 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 3 = 0.306 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 4 = 0.354 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 5 = 0.321 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 6 = 0.332 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 7 = 0.342 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 8 = 0.335 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 9 = 0.34 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 all KL = 0.182 +- 0.160 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 all L1 = 0.346 +- 0.116 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.749
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.281
SUFF++ for r=0.9 class 0 = 0.256 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 1 = 0.963 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 2 = 0.294 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 3 = 0.243 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 4 = 0.234 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 5 = 0.241 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 6 = 0.248 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 7 = 0.229 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 8 = 0.294 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 class 9 = 0.253 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 all KL = 0.136 +- 0.312 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.9 all L1 = 0.337 +- 0.252 (in-sample avg dev_std = 0.511)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.111
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.088
NEC for r=0.3 class 0 = 0.581 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 1 = 0.574 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 2 = 0.531 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 3 = 0.538 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 4 = 0.512 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 5 = 0.53 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 6 = 0.514 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 7 = 0.508 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 8 = 0.537 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 class 9 = 0.528 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all KL = 0.434 +- 0.208 (in-sample avg dev_std = 0.209)
NEC for r=0.3 all L1 = 0.536 +- 0.121 (in-sample avg dev_std = 0.209)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.271
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.168
NEC for r=0.6 class 0 = 0.703 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 1 = 0.551 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 2 = 0.702 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 3 = 0.691 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 4 = 0.629 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 5 = 0.666 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 6 = 0.647 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 7 = 0.66 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 8 = 0.651 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 9 = 0.647 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all KL = 0.766 +- 0.213 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all L1 = 0.653 +- 0.135 (in-sample avg dev_std = 0.360)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.75
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.57
NEC for r=0.9 class 0 = 0.511 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 1 = 0.048 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 2 = 0.403 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 3 = 0.512 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 4 = 0.595 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 5 = 0.555 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 6 = 0.622 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 7 = 0.571 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 8 = 0.374 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 class 9 = 0.66 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 all KL = 0.617 +- 0.319 (in-sample avg dev_std = 0.442)
NEC for r=0.9 all L1 = 0.477 +- 0.261 (in-sample avg dev_std = 0.442)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.95
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.852
NEC for r=1.0 class 0 = 0.109 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 1 = 0.02 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 2 = 0.281 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 3 = 0.239 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 4 = 0.218 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 5 = 0.289 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 6 = 0.269 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 7 = 0.289 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 8 = 0.157 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 class 9 = 0.362 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 all KL = 0.379 +- 0.354 (in-sample avg dev_std = 0.394)
NEC for r=1.0 all L1 = 0.22 +- 0.242 (in-sample avg dev_std = 0.394)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:46:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:46:26 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ACCURACY: 0.9953
Train Loss: 0.0210
ID Validation ACCURACY: 0.8947
ID Validation Loss: 0.4144
ID Test ACCURACY: 0.8940
ID Test Loss: 0.4075
OOD Validation ACCURACY: 0.8159
OOD Validation Loss: 0.9172
OOD Test ACCURACY: 0.1800
OOD Test Loss: 30.3619

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9521
Train Loss: 0.1419
ID Validation ACCURACY: 0.8747
ID Validation Loss: 0.3859
ID Test ACCURACY: 0.8801
ID Test Loss: 0.3806
OOD Validation ACCURACY: 0.8700
OOD Validation Loss: 0.4310
OOD Test ACCURACY: 0.7046
OOD Test Loss: 1.0001

[0m[1;37mINFO[0m: [1mChartInfo 0.8940 0.1800 0.8801 0.7046 0.8747 0.8700[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.55 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 1 = 0.523 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 2 = 0.535 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 3 = 0.565 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 4 = 0.551 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 5 = 0.525 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 6 = 0.556 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 7 = 0.529 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 8 = 0.539 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 class 9 = 0.518 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all KL = 0.622 +- 0.156 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.3 all L1 = 0.539 +- 0.103 (in-sample avg dev_std = 0.328)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.243
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.158
SUFF++ for r=0.6 class 0 = 0.366 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 1 = 0.391 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 2 = 0.42 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 3 = 0.398 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 4 = 0.404 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 5 = 0.383 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 6 = 0.361 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 7 = 0.392 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 8 = 0.351 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 9 = 0.373 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all KL = 0.322 +- 0.210 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all L1 = 0.384 +- 0.131 (in-sample avg dev_std = 0.410)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.783
SUFF++ for r=0.9 class 0 = 0.913 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1 = 0.963 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 2 = 0.766 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 3 = 0.808 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 4 = 0.848 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 5 = 0.773 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 6 = 0.865 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 7 = 0.818 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 8 = 0.845 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 9 = 0.755 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.844 +- 0.231 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.838 +- 0.204 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.095
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.103
NEC for r=0.3 class 0 = 0.388 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 1 = 0.408 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 2 = 0.377 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 3 = 0.366 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 4 = 0.359 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 5 = 0.395 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 6 = 0.387 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 7 = 0.38 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 8 = 0.387 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 class 9 = 0.384 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all KL = 0.225 +- 0.151 (in-sample avg dev_std = 0.215)
NEC for r=0.3 all L1 = 0.383 +- 0.123 (in-sample avg dev_std = 0.215)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.243
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.202
NEC for r=0.6 class 0 = 0.513 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 1 = 0.433 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 2 = 0.463 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 3 = 0.52 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 4 = 0.509 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 5 = 0.5 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 6 = 0.556 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 7 = 0.502 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 8 = 0.527 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 class 9 = 0.569 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all KL = 0.481 +- 0.234 (in-sample avg dev_std = 0.328)
NEC for r=0.6 all L1 = 0.508 +- 0.174 (in-sample avg dev_std = 0.328)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.675
NEC for r=0.9 class 0 = 0.311 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 1 = 0.077 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 2 = 0.426 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 3 = 0.456 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 4 = 0.271 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 5 = 0.497 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 6 = 0.434 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 7 = 0.383 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 8 = 0.306 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 class 9 = 0.481 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all KL = 0.523 +- 0.328 (in-sample avg dev_std = 0.447)
NEC for r=0.9 all L1 = 0.359 +- 0.257 (in-sample avg dev_std = 0.447)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.95
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.846
NEC for r=1.0 class 0 = 0.113 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 1 = 0.023 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 2 = 0.337 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 3 = 0.255 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 4 = 0.166 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 5 = 0.278 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 6 = 0.23 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 7 = 0.215 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 8 = 0.178 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 class 9 = 0.315 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all KL = 0.354 +- 0.341 (in-sample avg dev_std = 0.385)
NEC for r=1.0 all L1 = 0.208 +- 0.234 (in-sample avg dev_std = 0.385)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 11:53:41 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:41 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 11:53:42 AM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 177...
[0m[1;37mINFO[0m: [1mCheckpoint 177: 
-----------------------------------
Train ACCURACY: 0.9977
Train Loss: 0.0148
ID Validation ACCURACY: 0.8996
ID Validation Loss: 0.3885
ID Test ACCURACY: 0.8940
ID Test Loss: 0.3976
OOD Validation ACCURACY: 0.6997
OOD Validation Loss: 1.7319
OOD Test ACCURACY: 0.1520
OOD Test Loss: 75.5642

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 62...
[0m[1;37mINFO[0m: [1mCheckpoint 62: 
-----------------------------------
Train ACCURACY: 0.9054
Train Loss: 0.2814
ID Validation ACCURACY: 0.8654
ID Validation Loss: 0.4107
ID Test ACCURACY: 0.8644
ID Test Loss: 0.4072
OOD Validation ACCURACY: 0.8570
OOD Validation Loss: 0.4363
OOD Test ACCURACY: 0.7327
OOD Test Loss: 0.9882

[0m[1;37mINFO[0m: [1mChartInfo 0.8940 0.1520 0.8644 0.7327 0.8654 0.8570[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
SUFF++ for r=0.3 class 0 = 0.459 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 1 = 0.437 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 2 = 0.474 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 3 = 0.488 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 4 = 0.466 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 5 = 0.474 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 6 = 0.466 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 7 = 0.461 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 8 = 0.445 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 class 9 = 0.417 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 all KL = 0.453 +- 0.231 (in-sample avg dev_std = 0.427)
SUFF++ for r=0.3 all L1 = 0.458 +- 0.136 (in-sample avg dev_std = 0.427)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.145
SUFF++ for r=0.6 class 0 = 0.376 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 1 = 0.41 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 2 = 0.4 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 3 = 0.456 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 4 = 0.457 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 5 = 0.421 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 6 = 0.471 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 7 = 0.435 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 8 = 0.575 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 class 9 = 0.488 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all KL = 0.3 +- 0.292 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.6 all L1 = 0.449 +- 0.224 (in-sample avg dev_std = 0.443)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.751
SUFF++ for r=0.9 class 0 = 0.926 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 1 = 0.908 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 2 = 0.747 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 3 = 0.703 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 4 = 0.829 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 5 = 0.765 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 6 = 0.786 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 7 = 0.829 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 8 = 0.846 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 class 9 = 0.734 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all KL = 0.801 +- 0.260 (in-sample avg dev_std = 0.296)
SUFF++ for r=0.9 all L1 = 0.809 +- 0.216 (in-sample avg dev_std = 0.296)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
NEC for r=0.3 class 0 = 0.434 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 1 = 0.48 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 2 = 0.439 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 3 = 0.41 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 4 = 0.474 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 5 = 0.464 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 6 = 0.472 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 7 = 0.455 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 8 = 0.462 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 9 = 0.498 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all KL = 0.362 +- 0.224 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all L1 = 0.459 +- 0.155 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.169
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.138
NEC for r=0.6 class 0 = 0.507 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 1 = 0.495 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 2 = 0.459 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 3 = 0.431 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 4 = 0.428 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 5 = 0.435 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 6 = 0.43 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 7 = 0.468 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 8 = 0.34 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 class 9 = 0.413 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all KL = 0.472 +- 0.289 (in-sample avg dev_std = 0.399)
NEC for r=0.6 all L1 = 0.441 +- 0.240 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.806
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.614
NEC for r=0.9 class 0 = 0.257 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 1 = 0.229 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 2 = 0.448 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 3 = 0.615 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 4 = 0.343 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 5 = 0.545 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 6 = 0.422 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 7 = 0.366 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 8 = 0.303 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 9 = 0.505 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all KL = 0.576 +- 0.334 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all L1 = 0.4 +- 0.268 (in-sample avg dev_std = 0.467)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.84
NEC for r=1.0 class 0 = 0.102 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 1 = 0.033 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 2 = 0.325 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 3 = 0.398 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 4 = 0.157 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 5 = 0.308 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 6 = 0.237 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 7 = 0.2 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 8 = 0.18 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 class 9 = 0.338 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all KL = 0.389 +- 0.358 (in-sample avg dev_std = 0.395)
NEC for r=1.0 all L1 = 0.224 +- 0.248 (in-sample avg dev_std = 0.395)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.731, 0.359, 0.848, 1.0], 'all_L1': [0.598, 0.394, 0.827, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.674, 0.482, 0.795, 1.0], 'all_L1': [0.563, 0.458, 0.803, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.182, 0.136, 1.0], 'all_L1': [0.433, 0.346, 0.337, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.622, 0.322, 0.844, 1.0], 'all_L1': [0.539, 0.384, 0.838, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.453, 0.3, 0.801, 1.0], 'all_L1': [0.458, 0.449, 0.809, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.239, 0.457, 0.523, 0.359], 'all_L1': [0.404, 0.505, 0.375, 0.225]}), defaultdict(<class 'list'>, {'all_KL': [0.175, 0.397, 0.526, 0.36], 'all_L1': [0.352, 0.474, 0.376, 0.222]}), defaultdict(<class 'list'>, {'all_KL': [0.434, 0.766, 0.617, 0.379], 'all_L1': [0.536, 0.653, 0.477, 0.22]}), defaultdict(<class 'list'>, {'all_KL': [0.225, 0.481, 0.523, 0.354], 'all_L1': [0.383, 0.508, 0.359, 0.208]}), defaultdict(<class 'list'>, {'all_KL': [0.362, 0.472, 0.576, 0.389], 'all_L1': [0.459, 0.441, 0.4, 0.224]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.518 +- 0.063, 0.406 +- 0.042, 0.723 +- 0.193, 1.000 +- 0.000
suff++ class all_KL  =  0.593 +- 0.108, 0.329 +- 0.097, 0.685 +- 0.275, 1.000 +- 0.000
suff++_acc_int  =  0.102 +- 0.004, 0.167 +- 0.017, 0.668 +- 0.194
nec class all_L1  =  0.427 +- 0.065, 0.516 +- 0.073, 0.397 +- 0.042, 0.220 +- 0.006
nec class all_KL  =  0.287 +- 0.096, 0.515 +- 0.129, 0.553 +- 0.038, 0.368 +- 0.013
nec_acc_int  =  0.099 +- 0.007, 0.187 +- 0.030, 0.637 +- 0.040, 0.847 +- 0.004


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.472 +- 0.017, 0.461 +- 0.021, 0.560 +- 0.077, 0.610 +- 0.003
Faith. Armon (L1)= 		  =  0.460 +- 0.019, 0.449 +- 0.010, 0.492 +- 0.050, 0.360 +- 0.008
Faith. GMean (L1)= 	  =  0.466 +- 0.017, 0.455 +- 0.013, 0.525 +- 0.062, 0.469 +- 0.007
Faith. Aritm (KL)= 		  =  0.440 +- 0.028, 0.422 +- 0.031, 0.619 +- 0.122, 0.684 +- 0.007
Faith. Armon (KL)= 		  =  0.366 +- 0.061, 0.377 +- 0.047, 0.564 +- 0.171, 0.538 +- 0.014
Faith. GMean (KL)= 	  =  0.400 +- 0.039, 0.397 +- 0.023, 0.589 +- 0.150, 0.607 +- 0.011
Computed for split load_split = id



Completed in  0:36:23.507320  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:01:21 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:01:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 72...
[0m[1;37mINFO[0m: [1mCheckpoint 72: 
-----------------------------------
Train ACCURACY: 0.3715
Train Loss: 2.7499
ID Validation ACCURACY: 0.3654
ID Validation Loss: 2.7861
ID Test ACCURACY: 0.3729
ID Test Loss: 2.7814
OOD Validation ACCURACY: 0.3491
OOD Validation Loss: 3.1257
OOD Test ACCURACY: 0.2690
OOD Test Loss: 4.6794

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 85...
[0m[1;37mINFO[0m: [1mCheckpoint 85: 
-----------------------------------
Train ACCURACY: 0.3198
Train Loss: 3.3902
ID Validation ACCURACY: 0.3150
ID Validation Loss: 3.4229
ID Test ACCURACY: 0.3230
ID Test Loss: 3.4163
OOD Validation ACCURACY: 0.3611
OOD Validation Loss: 3.3370
OOD Test ACCURACY: 0.2419
OOD Test Loss: 7.8889

[0m[1;37mINFO[0m: [1mChartInfo 0.3729 0.2690 0.3230 0.2419 0.3150 0.3611[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.387
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.205
SUFF++ for r=0.6 class 0 = 0.332 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 1 = 0.46 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 2 = 0.309 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 3 = 0.278 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 4 = 0.428 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 5 = 0.306 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 6 = 0.36 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 7 = 0.37 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 8 = 0.294 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 class 9 = 0.428 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all KL = 0.224 +- 0.232 (in-sample avg dev_std = 0.567)
SUFF++ for r=0.6 all L1 = 0.358 +- 0.136 (in-sample avg dev_std = 0.567)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.387
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.262
NEC for r=0.6 class 0 = 0.252 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 1 = 0.582 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 2 = 0.588 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 3 = 0.557 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 4 = 0.434 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 5 = 0.551 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 6 = 0.504 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 7 = 0.515 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 8 = 0.531 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 class 9 = 0.403 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 all KL = 0.449 +- 0.256 (in-sample avg dev_std = 0.267)
NEC for r=0.6 all L1 = 0.495 +- 0.209 (in-sample avg dev_std = 0.267)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:03:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:50 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:03:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 87...
[0m[1;37mINFO[0m: [1mCheckpoint 87: 
-----------------------------------
Train ACCURACY: 0.7181
Train Loss: 0.8746
ID Validation ACCURACY: 0.6574
ID Validation Loss: 1.2188
ID Test ACCURACY: 0.6584
ID Test Loss: 1.2023
OOD Validation ACCURACY: 0.4703
OOD Validation Loss: 2.8402
OOD Test ACCURACY: 0.1883
OOD Test Loss: 15.9927

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.6624
Train Loss: 1.0155
ID Validation ACCURACY: 0.6256
ID Validation Loss: 1.1994
ID Test ACCURACY: 0.6141
ID Test Loss: 1.2223
OOD Validation ACCURACY: 0.5277
OOD Validation Loss: 1.8377
OOD Test ACCURACY: 0.2083
OOD Test Loss: 11.1952

[0m[1;37mINFO[0m: [1mChartInfo 0.6584 0.1883 0.6141 0.2083 0.6256 0.5277[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.694
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.215
SUFF++ for r=0.6 class 0 = 0.237 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 1 = 0.343 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 2 = 0.217 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 3 = 0.191 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 4 = 0.253 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 5 = 0.239 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 6 = 0.205 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 7 = 0.255 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 8 = 0.197 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 class 9 = 0.28 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 all KL = 0.032 +- 0.067 (in-sample avg dev_std = 0.591)
SUFF++ for r=0.6 all L1 = 0.243 +- 0.103 (in-sample avg dev_std = 0.591)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.694
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.45
NEC for r=0.6 class 0 = 0.648 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 1 = 0.333 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 2 = 0.542 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 3 = 0.586 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 4 = 0.533 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 5 = 0.613 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 6 = 0.639 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 7 = 0.632 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 8 = 0.511 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 class 9 = 0.567 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 all KL = 0.695 +- 0.260 (in-sample avg dev_std = 0.447)
NEC for r=0.6 all L1 = 0.557 +- 0.211 (in-sample avg dev_std = 0.447)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:06:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:06:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 56...
[0m[1;37mINFO[0m: [1mCheckpoint 56: 
-----------------------------------
Train ACCURACY: 0.4452
Train Loss: 1.8491
ID Validation ACCURACY: 0.4349
ID Validation Loss: 1.9176
ID Test ACCURACY: 0.4390
ID Test Loss: 1.8691
OOD Validation ACCURACY: 0.3544
OOD Validation Loss: 2.4861
OOD Test ACCURACY: 0.2210
OOD Test Loss: 3.7235

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 73...
[0m[1;37mINFO[0m: [1mCheckpoint 73: 
-----------------------------------
Train ACCURACY: 0.4067
Train Loss: 2.3142
ID Validation ACCURACY: 0.3957
ID Validation Loss: 2.4284
ID Test ACCURACY: 0.4073
ID Test Loss: 2.3439
OOD Validation ACCURACY: 0.3826
OOD Validation Loss: 2.4420
OOD Test ACCURACY: 0.2560
OOD Test Loss: 4.6004

[0m[1;37mINFO[0m: [1mChartInfo 0.4390 0.2210 0.4073 0.2560 0.3957 0.3826[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.431
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.188
SUFF++ for r=0.6 class 0 = 0.244 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 1 = 0.436 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 2 = 0.23 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 3 = 0.242 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 4 = 0.215 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 5 = 0.238 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 6 = 0.246 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 7 = 0.248 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 8 = 0.228 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 class 9 = 0.245 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all KL = 0.076 +- 0.142 (in-sample avg dev_std = 0.513)
SUFF++ for r=0.6 all L1 = 0.26 +- 0.106 (in-sample avg dev_std = 0.513)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.431
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.343
NEC for r=0.6 class 0 = 0.197 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1 = 0.485 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 2 = 0.526 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 3 = 0.558 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 4 = 0.416 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 5 = 0.488 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 6 = 0.486 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 7 = 0.525 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 8 = 0.419 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 9 = 0.378 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.361 +- 0.215 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.451 +- 0.184 (in-sample avg dev_std = 0.264)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:08:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:08:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:08:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ACCURACY: 0.6588
Train Loss: 0.9911
ID Validation ACCURACY: 0.6276
ID Validation Loss: 1.1178
ID Test ACCURACY: 0.6277
ID Test Loss: 1.1142
OOD Validation ACCURACY: 0.4983
OOD Validation Loss: 1.7285
OOD Test ACCURACY: 0.2486
OOD Test Loss: 4.9047

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ACCURACY: 0.5989
Train Loss: 1.1783
ID Validation ACCURACY: 0.5699
ID Validation Loss: 1.3077
ID Test ACCURACY: 0.5776
ID Test Loss: 1.2851
OOD Validation ACCURACY: 0.5351
OOD Validation Loss: 1.4928
OOD Test ACCURACY: 0.2547
OOD Test Loss: 5.2471

[0m[1;37mINFO[0m: [1mChartInfo 0.6277 0.2486 0.5776 0.2547 0.5699 0.5351[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument splits in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.242
SUFF++ for r=0.6 class 0 = 0.294 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 1 = 0.797 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 2 = 0.215 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 3 = 0.205 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 4 = 0.255 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 5 = 0.221 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 6 = 0.211 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 7 = 0.218 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 8 = 0.224 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 class 9 = 0.259 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all KL = 0.107 +- 0.232 (in-sample avg dev_std = 0.558)
SUFF++ for r=0.6 all L1 = 0.299 +- 0.206 (in-sample avg dev_std = 0.558)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.444
NEC for r=0.6 class 0 = 0.596 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1 = 0.119 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 2 = 0.49 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 3 = 0.512 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 4 = 0.493 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 5 = 0.575 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 6 = 0.599 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 7 = 0.619 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 8 = 0.534 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 9 = 0.596 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.526 +- 0.266 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.506 +- 0.216 (in-sample avg dev_std = 0.317)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:11:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:20 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit CIGAvGIN
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit Backbone:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mCreating vGINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit CLF:  5
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:11:21 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 42...
[0m[1;37mINFO[0m: [1mCheckpoint 42: 
-----------------------------------
Train ACCURACY: 0.4206
Train Loss: 1.8923
ID Validation ACCURACY: 0.4203
ID Validation Loss: 1.9484
ID Test ACCURACY: 0.4191
ID Test Loss: 1.8983
OOD Validation ACCURACY: 0.3490
OOD Validation Loss: 2.3843
OOD Test ACCURACY: 0.2689
OOD Test Loss: 2.7813

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 49...
[0m[1;37mINFO[0m: [1mCheckpoint 49: 
-----------------------------------
Train ACCURACY: 0.4088
Train Loss: 1.8664
ID Validation ACCURACY: 0.4009
ID Validation Loss: 1.9187
ID Test ACCURACY: 0.4040
ID Test Loss: 1.9019
OOD Validation ACCURACY: 0.3840
OOD Validation Loss: 2.1207
OOD Test ACCURACY: 0.2513
OOD Test Loss: 3.0490

[0m[1;37mINFO[0m: [1mChartInfo 0.4191 0.2689 0.4040 0.2513 0.4009 0.3840[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument splits in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument ratios in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.43
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.23
SUFF++ for r=0.6 class 0 = 0.329 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 1 = 0.605 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 2 = 0.269 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 3 = 0.302 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 4 = 0.284 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 5 = 0.29 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 6 = 0.275 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 7 = 0.295 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 8 = 0.297 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 9 = 0.289 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 all KL = 0.194 +- 0.213 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 all L1 = 0.329 +- 0.137 (in-sample avg dev_std = 0.570)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.43
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.397
NEC for r=0.6 class 0 = 0.232 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 1 = 0.331 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 2 = 0.463 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 3 = 0.47 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 4 = 0.389 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 5 = 0.481 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 6 = 0.491 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 7 = 0.476 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 8 = 0.466 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 class 9 = 0.427 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all KL = 0.307 +- 0.185 (in-sample avg dev_std = 0.237)
NEC for r=0.6 all L1 = 0.422 +- 0.166 (in-sample avg dev_std = 0.237)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.224], 'all_L1': [0.358]}), defaultdict(<class 'list'>, {'all_KL': [0.032], 'all_L1': [0.243]}), defaultdict(<class 'list'>, {'all_KL': [0.076], 'all_L1': [0.26]}), defaultdict(<class 'list'>, {'all_KL': [0.107], 'all_L1': [0.299]}), defaultdict(<class 'list'>, {'all_KL': [0.194], 'all_L1': [0.329]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.449], 'all_L1': [0.495]}), defaultdict(<class 'list'>, {'all_KL': [0.695], 'all_L1': [0.557]}), defaultdict(<class 'list'>, {'all_KL': [0.361], 'all_L1': [0.451]}), defaultdict(<class 'list'>, {'all_KL': [0.526], 'all_L1': [0.506]}), defaultdict(<class 'list'>, {'all_KL': [0.307], 'all_L1': [0.422]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.298 +- 0.042
suff++ class all_KL  =  0.127 +- 0.072
suff++_acc_int  =  0.216 +- 0.019
nec class all_L1  =  0.486 +- 0.047
nec class all_KL  =  0.468 +- 0.136
nec_acc_int  =  0.379 +- 0.070


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.392 +- 0.024
Faith. Armon (L1)= 		  =  0.366 +- 0.030
Faith. GMean (L1)= 	  =  0.379 +- 0.026
Faith. Aritm (KL)= 		  =  0.297 +- 0.054
Faith. Armon (KL)= 		  =  0.180 +- 0.083
Faith. GMean (KL)= 	  =  0.223 +- 0.060
Computed for split load_split = id



Completed in  0:12:28.823751  for CIGAvGIN GOODCMNIST/color



DONE CIGA GOODCMNIST/color

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:14:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:07 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:25 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:14:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 104...
[0m[1;37mINFO[0m: [1mCheckpoint 104: 
-----------------------------------
Train ACCURACY: 0.9199
Train Loss: 0.4046
ID Validation ACCURACY: 0.9187
ID Validation Loss: 0.4190
ID Test ACCURACY: 0.9173
ID Test Loss: 0.4155
OOD Validation ACCURACY: 0.8993
OOD Validation Loss: 0.4204
OOD Test ACCURACY: 0.8580
OOD Test Loss: 0.4743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9207
Train Loss: 0.3963
ID Validation ACCURACY: 0.9180
ID Validation Loss: 0.4080
ID Test ACCURACY: 0.9190
ID Test Loss: 0.4092
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.3561
OOD Test ACCURACY: 0.8053
OOD Test Loss: 0.5858

[0m[1;37mINFO[0m: [1mChartInfo 0.9173 0.8580 0.9190 0.8053 0.9180 0.9230[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.729
WIoU for r=0.3 = 0.676
F1 for r=0.6 = 0.623
WIoU for r=0.6 = 0.702
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.705
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.705


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.625
Model XAI F1 of binarized graphs for r=0.3 =  0.72949
Model XAI WIoU of binarized graphs for r=0.3 =  0.6759162499999999
len(reference) = 797
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.479
SUFF++ for r=0.3 class 0 = 0.432 +- 0.265 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 1 = 0.478 +- 0.265 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 class 2 = 0.581 +- 0.265 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all KL = 0.408 +- 0.265 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.3 all L1 = 0.496 +- 0.176 (in-sample avg dev_std = 0.570)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6234474999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7022562499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.688
SUFF++ for r=0.6 class 0 = 0.479 +- 0.267 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 1 = 0.616 +- 0.267 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 class 2 = 0.68 +- 0.267 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all KL = 0.548 +- 0.267 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.6 all L1 = 0.591 +- 0.198 (in-sample avg dev_std = 0.500)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.48878625
Model XAI WIoU of binarized graphs for r=0.9 =  0.70473375
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.861
SUFF++ for r=0.9 class 0 = 0.795 +- 0.163 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 1 = 0.757 +- 0.163 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 class 2 = 0.847 +- 0.163 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all KL = 0.866 +- 0.163 (in-sample avg dev_std = 0.242)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.159 (in-sample avg dev_std = 0.242)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  0.72949
Model XAI WIoU of binarized graphs for r=0.3 =  0.6759162499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.368
NEC for r=0.3 class 0 = 0.651 +- 0.233 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 1 = 0.594 +- 0.233 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 2 = 0.602 +- 0.233 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all KL = 0.745 +- 0.233 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all L1 = 0.616 +- 0.135 (in-sample avg dev_std = 0.493)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  0.6234474999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7022562499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.436
NEC for r=0.6 class 0 = 0.597 +- 0.275 (in-sample avg dev_std = 0.492)
NEC for r=0.6 class 1 = 0.592 +- 0.275 (in-sample avg dev_std = 0.492)
NEC for r=0.6 class 2 = 0.593 +- 0.275 (in-sample avg dev_std = 0.492)
NEC for r=0.6 all KL = 0.658 +- 0.275 (in-sample avg dev_std = 0.492)
NEC for r=0.6 all L1 = 0.594 +- 0.154 (in-sample avg dev_std = 0.492)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.48878625
Model XAI WIoU of binarized graphs for r=0.9 =  0.70473375
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.518 +- 0.276 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 1 = 0.54 +- 0.276 (in-sample avg dev_std = 0.541)
NEC for r=0.9 class 2 = 0.543 +- 0.276 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all KL = 0.558 +- 0.276 (in-sample avg dev_std = 0.541)
NEC for r=0.9 all L1 = 0.533 +- 0.155 (in-sample avg dev_std = 0.541)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7046237500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.539
NEC for r=1.0 class 0 = 0.493 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 class 1 = 0.53 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 class 2 = 0.536 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 all KL = 0.53 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 all L1 = 0.519 +- 0.163 (in-sample avg dev_std = 0.521)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:15:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:35 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:47 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:49 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:51 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:53 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:15:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ACCURACY: 0.9093
Train Loss: 0.4153
ID Validation ACCURACY: 0.9077
ID Validation Loss: 0.4259
ID Test ACCURACY: 0.9133
ID Test Loss: 0.4117
OOD Validation ACCURACY: 0.8497
OOD Validation Loss: 0.4942
OOD Test ACCURACY: 0.7820
OOD Test Loss: 0.6459

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8288
Train Loss: 0.5416
ID Validation ACCURACY: 0.8220
ID Validation Loss: 0.5634
ID Test ACCURACY: 0.8233
ID Test Loss: 0.5510
OOD Validation ACCURACY: 0.8977
OOD Validation Loss: 0.4180
OOD Test ACCURACY: 0.7627
OOD Test Loss: 0.6773

[0m[1;37mINFO[0m: [1mChartInfo 0.9133 0.7820 0.8233 0.7627 0.8220 0.8977[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.707
WIoU for r=0.3 = 0.681
F1 for r=0.6 = 0.626
WIoU for r=0.6 = 0.796
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.803
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.803


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  0.7065174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.680505
len(reference) = 798
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.466
SUFF++ for r=0.3 class 0 = 0.43 +- 0.253 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 1 = 0.491 +- 0.253 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 2 = 0.469 +- 0.253 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all KL = 0.375 +- 0.253 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all L1 = 0.463 +- 0.152 (in-sample avg dev_std = 0.610)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.861
Model XAI F1 of binarized graphs for r=0.6 =  0.6255175
Model XAI WIoU of binarized graphs for r=0.6 =  0.79622375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.734
SUFF++ for r=0.6 class 0 = 0.568 +- 0.263 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 1 = 0.682 +- 0.263 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 2 = 0.656 +- 0.263 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all KL = 0.598 +- 0.263 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all L1 = 0.635 +- 0.187 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.48902124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.8026025
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0 = 0.802 +- 0.132 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 1 = 0.847 +- 0.132 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 class 2 = 0.875 +- 0.132 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all KL = 0.896 +- 0.132 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.9 all L1 = 0.841 +- 0.132 (in-sample avg dev_std = 0.238)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.674
Model XAI F1 of binarized graphs for r=0.3 =  0.7065174999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.680505
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.635 +- 0.245 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 1 = 0.645 +- 0.245 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 2 = 0.64 +- 0.245 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all KL = 0.708 +- 0.245 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all L1 = 0.64 +- 0.132 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  0.6255175
Model XAI WIoU of binarized graphs for r=0.6 =  0.79622375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.454
NEC for r=0.6 class 0 = 0.57 +- 0.291 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 1 = 0.594 +- 0.291 (in-sample avg dev_std = 0.486)
NEC for r=0.6 class 2 = 0.6 +- 0.291 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all KL = 0.638 +- 0.291 (in-sample avg dev_std = 0.486)
NEC for r=0.6 all L1 = 0.588 +- 0.153 (in-sample avg dev_std = 0.486)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.48902124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.8026025
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.535
NEC for r=0.9 class 0 = 0.516 +- 0.286 (in-sample avg dev_std = 0.530)
NEC for r=0.9 class 1 = 0.533 +- 0.286 (in-sample avg dev_std = 0.530)
NEC for r=0.9 class 2 = 0.52 +- 0.286 (in-sample avg dev_std = 0.530)
NEC for r=0.9 all KL = 0.543 +- 0.286 (in-sample avg dev_std = 0.530)
NEC for r=0.9 all L1 = 0.523 +- 0.161 (in-sample avg dev_std = 0.530)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.8026025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.492 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 class 1 = 0.534 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 class 2 = 0.511 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 all KL = 0.525 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 all L1 = 0.512 +- 0.164 (in-sample avg dev_std = 0.528)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:17:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:03 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:15 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:17 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:19 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:20 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:17:22 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ACCURACY: 0.9147
Train Loss: 0.4029
ID Validation ACCURACY: 0.9103
ID Validation Loss: 0.4205
ID Test ACCURACY: 0.9083
ID Test Loss: 0.4147
OOD Validation ACCURACY: 0.8440
OOD Validation Loss: 0.4769
OOD Test ACCURACY: 0.8217
OOD Test Loss: 0.6118

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8890
Train Loss: 0.4742
ID Validation ACCURACY: 0.8847
ID Validation Loss: 0.4966
ID Test ACCURACY: 0.8883
ID Test Loss: 0.4729
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3740
OOD Test ACCURACY: 0.6043
OOD Test Loss: 1.1293

[0m[1;37mINFO[0m: [1mChartInfo 0.9083 0.8217 0.8883 0.6043 0.8847 0.9260[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.714
WIoU for r=0.3 = 0.695
F1 for r=0.6 = 0.627
WIoU for r=0.6 = 0.809
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.813
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.813


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.708
Model XAI F1 of binarized graphs for r=0.3 =  0.71383625
Model XAI WIoU of binarized graphs for r=0.3 =  0.694975
len(reference) = 790
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.493
SUFF++ for r=0.3 class 0 = 0.447 +- 0.254 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 1 = 0.491 +- 0.254 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 2 = 0.49 +- 0.254 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all KL = 0.364 +- 0.254 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all L1 = 0.476 +- 0.169 (in-sample avg dev_std = 0.628)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  0.6274425
Model XAI WIoU of binarized graphs for r=0.6 =  0.80949625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.743
SUFF++ for r=0.6 class 0 = 0.573 +- 0.289 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.289 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 class 2 = 0.67 +- 0.289 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all KL = 0.571 +- 0.289 (in-sample avg dev_std = 0.489)
SUFF++ for r=0.6 all L1 = 0.635 +- 0.198 (in-sample avg dev_std = 0.489)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.489
Model XAI WIoU of binarized graphs for r=0.9 =  0.8127362499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.855
SUFF++ for r=0.9 class 0 = 0.801 +- 0.183 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.803 +- 0.183 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.876 +- 0.183 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.869 +- 0.183 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.160 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.707
Model XAI F1 of binarized graphs for r=0.3 =  0.71383625
Model XAI WIoU of binarized graphs for r=0.3 =  0.694975
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.36
NEC for r=0.3 class 0 = 0.656 +- 0.243 (in-sample avg dev_std = 0.471)
NEC for r=0.3 class 1 = 0.621 +- 0.243 (in-sample avg dev_std = 0.471)
NEC for r=0.3 class 2 = 0.652 +- 0.243 (in-sample avg dev_std = 0.471)
NEC for r=0.3 all KL = 0.733 +- 0.243 (in-sample avg dev_std = 0.471)
NEC for r=0.3 all L1 = 0.643 +- 0.131 (in-sample avg dev_std = 0.471)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  0.6274425
Model XAI WIoU of binarized graphs for r=0.6 =  0.80949625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.466
NEC for r=0.6 class 0 = 0.579 +- 0.281 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 1 = 0.586 +- 0.281 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 2 = 0.581 +- 0.281 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all KL = 0.66 +- 0.281 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all L1 = 0.582 +- 0.154 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.489
Model XAI WIoU of binarized graphs for r=0.9 =  0.8127362499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.558
NEC for r=0.9 class 0 = 0.506 +- 0.280 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 1 = 0.534 +- 0.280 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 2 = 0.504 +- 0.280 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all KL = 0.555 +- 0.280 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all L1 = 0.515 +- 0.158 (in-sample avg dev_std = 0.554)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.8127324999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.558
NEC for r=1.0 class 0 = 0.506 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 1 = 0.52 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 2 = 0.494 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all KL = 0.544 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all L1 = 0.507 +- 0.167 (in-sample avg dev_std = 0.545)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:18:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:29 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:43 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:45 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:48 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:50 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:18:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9206
Train Loss: 0.4075
ID Validation ACCURACY: 0.9150
ID Validation Loss: 0.4315
ID Test ACCURACY: 0.9157
ID Test Loss: 0.4215
OOD Validation ACCURACY: 0.8893
OOD Validation Loss: 0.4249
OOD Test ACCURACY: 0.7647
OOD Test Loss: 0.6361

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8867
Train Loss: 0.4496
ID Validation ACCURACY: 0.8873
ID Validation Loss: 0.4598
ID Test ACCURACY: 0.8847
ID Test Loss: 0.4508
OOD Validation ACCURACY: 0.9143
OOD Validation Loss: 0.3926
OOD Test ACCURACY: 0.5360
OOD Test Loss: 1.0543

[0m[1;37mINFO[0m: [1mChartInfo 0.9157 0.7647 0.8847 0.5360 0.8873 0.9143[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.723
WIoU for r=0.3 = 0.723
F1 for r=0.6 = 0.628
WIoU for r=0.6 = 0.794
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.795
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.795


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.688
Model XAI F1 of binarized graphs for r=0.3 =  0.7229899999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7232237499999999
len(reference) = 797
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.507
SUFF++ for r=0.3 class 0 = 0.528 +- 0.270 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 class 1 = 0.579 +- 0.270 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 class 2 = 0.502 +- 0.270 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all KL = 0.388 +- 0.270 (in-sample avg dev_std = 0.625)
SUFF++ for r=0.3 all L1 = 0.537 +- 0.184 (in-sample avg dev_std = 0.625)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.6276975
Model XAI WIoU of binarized graphs for r=0.6 =  0.7941875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.722
SUFF++ for r=0.6 class 0 = 0.553 +- 0.276 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 1 = 0.68 +- 0.276 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 class 2 = 0.648 +- 0.276 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all KL = 0.548 +- 0.276 (in-sample avg dev_std = 0.525)
SUFF++ for r=0.6 all L1 = 0.627 +- 0.180 (in-sample avg dev_std = 0.525)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.48898624999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951712499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.864
SUFF++ for r=0.9 class 0 = 0.82 +- 0.180 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 1 = 0.81 +- 0.180 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 class 2 = 0.853 +- 0.180 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all KL = 0.874 +- 0.180 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.9 all L1 = 0.827 +- 0.168 (in-sample avg dev_std = 0.252)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.691
Model XAI F1 of binarized graphs for r=0.3 =  0.7229899999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7232237499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.378
NEC for r=0.3 class 0 = 0.589 +- 0.280 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 1 = 0.518 +- 0.280 (in-sample avg dev_std = 0.507)
NEC for r=0.3 class 2 = 0.605 +- 0.280 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all KL = 0.69 +- 0.280 (in-sample avg dev_std = 0.507)
NEC for r=0.3 all L1 = 0.57 +- 0.201 (in-sample avg dev_std = 0.507)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.6276975
Model XAI WIoU of binarized graphs for r=0.6 =  0.7941875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.423
NEC for r=0.6 class 0 = 0.611 +- 0.281 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 1 = 0.563 +- 0.281 (in-sample avg dev_std = 0.528)
NEC for r=0.6 class 2 = 0.639 +- 0.281 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all KL = 0.689 +- 0.281 (in-sample avg dev_std = 0.528)
NEC for r=0.6 all L1 = 0.604 +- 0.155 (in-sample avg dev_std = 0.528)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.904
Model XAI F1 of binarized graphs for r=0.9 =  0.48898624999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951712499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.507
NEC for r=0.9 class 0 = 0.533 +- 0.284 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 1 = 0.526 +- 0.284 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 2 = 0.568 +- 0.284 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all KL = 0.588 +- 0.284 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all L1 = 0.542 +- 0.156 (in-sample avg dev_std = 0.554)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7951712499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.525
NEC for r=1.0 class 0 = 0.509 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 1 = 0.508 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 2 = 0.553 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all KL = 0.554 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all L1 = 0.523 +- 0.161 (in-sample avg dev_std = 0.548)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:20:08 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:08 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:21 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:23 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:20:29 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.9203
Train Loss: 0.3905
ID Validation ACCURACY: 0.9223
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.9180
ID Test Loss: 0.4033
OOD Validation ACCURACY: 0.8893
OOD Validation Loss: 0.4035
OOD Test ACCURACY: 0.7510
OOD Test Loss: 0.7925

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.8950
Train Loss: 0.4249
ID Validation ACCURACY: 0.8940
ID Validation Loss: 0.4447
ID Test ACCURACY: 0.8920
ID Test Loss: 0.4247
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3254
OOD Test ACCURACY: 0.6273
OOD Test Loss: 1.0432

[0m[1;37mINFO[0m: [1mChartInfo 0.9180 0.7510 0.8920 0.6273 0.8940 0.9317[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.716
WIoU for r=0.3 = 0.685
F1 for r=0.6 = 0.627
WIoU for r=0.6 = 0.754
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.754


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.691
Model XAI F1 of binarized graphs for r=0.3 =  0.7161949999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6846625000000001
len(reference) = 795
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.489
SUFF++ for r=0.3 class 0 = 0.403 +- 0.241 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 class 1 = 0.521 +- 0.241 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 class 2 = 0.506 +- 0.241 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all KL = 0.348 +- 0.241 (in-sample avg dev_std = 0.624)
SUFF++ for r=0.3 all L1 = 0.476 +- 0.169 (in-sample avg dev_std = 0.624)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6274649999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7541225
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.728
SUFF++ for r=0.6 class 0 = 0.524 +- 0.270 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 1 = 0.714 +- 0.270 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 class 2 = 0.679 +- 0.270 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all KL = 0.573 +- 0.270 (in-sample avg dev_std = 0.475)
SUFF++ for r=0.6 all L1 = 0.638 +- 0.202 (in-sample avg dev_std = 0.475)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.48923125
Model XAI WIoU of binarized graphs for r=0.9 =  0.7537962500000001
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.832
SUFF++ for r=0.9 class 0 = 0.744 +- 0.194 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 1 = 0.774 +- 0.194 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 class 2 = 0.839 +- 0.194 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 all KL = 0.836 +- 0.194 (in-sample avg dev_std = 0.283)
SUFF++ for r=0.9 all L1 = 0.785 +- 0.189 (in-sample avg dev_std = 0.283)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.691
Model XAI F1 of binarized graphs for r=0.3 =  0.7161949999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6846625000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.392
NEC for r=0.3 class 0 = 0.643 +- 0.227 (in-sample avg dev_std = 0.559)
NEC for r=0.3 class 1 = 0.606 +- 0.227 (in-sample avg dev_std = 0.559)
NEC for r=0.3 class 2 = 0.614 +- 0.227 (in-sample avg dev_std = 0.559)
NEC for r=0.3 all KL = 0.756 +- 0.227 (in-sample avg dev_std = 0.559)
NEC for r=0.3 all L1 = 0.621 +- 0.131 (in-sample avg dev_std = 0.559)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6274649999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7541225
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.464
NEC for r=0.6 class 0 = 0.595 +- 0.282 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 1 = 0.561 +- 0.282 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 2 = 0.591 +- 0.282 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all KL = 0.669 +- 0.282 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all L1 = 0.582 +- 0.163 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.48923125
Model XAI WIoU of binarized graphs for r=0.9 =  0.7537962500000001
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.565
NEC for r=0.9 class 0 = 0.5 +- 0.290 (in-sample avg dev_std = 0.553)
NEC for r=0.9 class 1 = 0.508 +- 0.290 (in-sample avg dev_std = 0.553)
NEC for r=0.9 class 2 = 0.547 +- 0.290 (in-sample avg dev_std = 0.553)
NEC for r=0.9 all KL = 0.565 +- 0.290 (in-sample avg dev_std = 0.553)
NEC for r=0.9 all L1 = 0.518 +- 0.162 (in-sample avg dev_std = 0.553)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.919
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.75372
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.58
NEC for r=1.0 class 0 = 0.503 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 1 = 0.517 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 2 = 0.52 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all KL = 0.556 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all L1 = 0.514 +- 0.152 (in-sample avg dev_std = 0.555)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.408, 0.548, 0.866, 1.0], 'all_L1': [0.496, 0.591, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.375, 0.598, 0.896, 1.0], 'all_L1': [0.463, 0.635, 0.841, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.364, 0.571, 0.869, 1.0], 'all_L1': [0.476, 0.635, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.388, 0.548, 0.874, 1.0], 'all_L1': [0.537, 0.627, 0.827, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.348, 0.573, 0.836, 1.0], 'all_L1': [0.476, 0.638, 0.785, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.745, 0.658, 0.558, 0.53], 'all_L1': [0.616, 0.594, 0.533, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.708, 0.638, 0.543, 0.525], 'all_L1': [0.64, 0.588, 0.523, 0.512]}), defaultdict(<class 'list'>, {'all_KL': [0.733, 0.66, 0.555, 0.544], 'all_L1': [0.643, 0.582, 0.515, 0.507]}), defaultdict(<class 'list'>, {'all_KL': [0.69, 0.689, 0.588, 0.554], 'all_L1': [0.57, 0.604, 0.542, 0.523]}), defaultdict(<class 'list'>, {'all_KL': [0.756, 0.669, 0.565, 0.556], 'all_L1': [0.621, 0.582, 0.518, 0.514]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.490 +- 0.026, 0.625 +- 0.017, 0.816 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.377 +- 0.020, 0.568 +- 0.019, 0.868 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.487 +- 0.014, 0.723 +- 0.019, 0.857 +- 0.014
nec class all_L1  =  0.618 +- 0.026, 0.590 +- 0.008, 0.526 +- 0.010, 0.515 +- 0.006
nec class all_KL  =  0.726 +- 0.024, 0.663 +- 0.017, 0.562 +- 0.015, 0.542 +- 0.012
nec_acc_int  =  0.370 +- 0.014, 0.449 +- 0.017, 0.540 +- 0.021, 0.548 +- 0.019


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.554 +- 0.004, 0.608 +- 0.008, 0.671 +- 0.012, 0.757 +- 0.003
Faith. Armon (L1)= 		  =  0.545 +- 0.006, 0.607 +- 0.008, 0.640 +- 0.010, 0.680 +- 0.005
Faith. GMean (L1)= 	  =  0.549 +- 0.004, 0.607 +- 0.008, 0.655 +- 0.011, 0.718 +- 0.004
Faith. Aritm (KL)= 		  =  0.552 +- 0.013, 0.615 +- 0.006, 0.715 +- 0.010, 0.771 +- 0.006
Faith. Armon (KL)= 		  =  0.495 +- 0.017, 0.611 +- 0.007, 0.682 +- 0.011, 0.703 +- 0.011
Faith. GMean (KL)= 	  =  0.523 +- 0.014, 0.613 +- 0.007, 0.698 +- 0.010, 0.736 +- 0.008
Computed for split load_split = id



Completed in  0:07:33.262257  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:21:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:21:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9077
Train Loss: 0.4320
ID Validation ACCURACY: 0.9117
ID Validation Loss: 0.4033
ID Test ACCURACY: 0.9047
ID Test Loss: 0.4417
OOD Validation ACCURACY: 0.9277
OOD Validation Loss: 0.3670
OOD Test ACCURACY: 0.9023
OOD Test Loss: 0.4492

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8641
Train Loss: 0.4637
ID Validation ACCURACY: 0.8727
ID Validation Loss: 0.4477
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4772
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.7927
OOD Test Loss: 0.6936

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.9023 0.8610 0.7927 0.8727 0.9313[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.712
WIoU for r=0.3 = 0.671
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.706
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.710
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.710


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  0.7122787500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6706725
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.499
SUFF++ for r=0.3 class 0 = 0.451 +- 0.261 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.3 class 1 = 0.597 +- 0.261 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.3 class 2 = 0.516 +- 0.261 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.3 all KL = 0.338 +- 0.261 (in-sample avg dev_std = 0.634)
SUFF++ for r=0.3 all L1 = 0.521 +- 0.183 (in-sample avg dev_std = 0.634)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.61004125
Model XAI WIoU of binarized graphs for r=0.6 =  0.70587125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.72
SUFF++ for r=0.6 class 0 = 0.559 +- 0.281 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.6 class 1 = 0.63 +- 0.281 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.6 class 2 = 0.669 +- 0.281 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.6 all KL = 0.492 +- 0.281 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.6 all L1 = 0.62 +- 0.197 (in-sample avg dev_std = 0.551)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.47318625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7097649999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.825
SUFF++ for r=0.9 class 0 = 0.823 +- 0.256 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 1 = 0.789 +- 0.256 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 2 = 0.77 +- 0.256 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all KL = 0.797 +- 0.256 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all L1 = 0.793 +- 0.213 (in-sample avg dev_std = 0.316)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  0.7122787500000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.6706725
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.351
NEC for r=0.3 class 0 = 0.65 +- 0.220 (in-sample avg dev_std = 0.538)
NEC for r=0.3 class 1 = 0.534 +- 0.220 (in-sample avg dev_std = 0.538)
NEC for r=0.3 class 2 = 0.628 +- 0.220 (in-sample avg dev_std = 0.538)
NEC for r=0.3 all KL = 0.792 +- 0.220 (in-sample avg dev_std = 0.538)
NEC for r=0.3 all L1 = 0.605 +- 0.154 (in-sample avg dev_std = 0.538)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.895
Model XAI F1 of binarized graphs for r=0.6 =  0.61004125
Model XAI WIoU of binarized graphs for r=0.6 =  0.70587125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.445
NEC for r=0.6 class 0 = 0.614 +- 0.242 (in-sample avg dev_std = 0.594)
NEC for r=0.6 class 1 = 0.609 +- 0.242 (in-sample avg dev_std = 0.594)
NEC for r=0.6 class 2 = 0.605 +- 0.242 (in-sample avg dev_std = 0.594)
NEC for r=0.6 all KL = 0.75 +- 0.242 (in-sample avg dev_std = 0.594)
NEC for r=0.6 all L1 = 0.609 +- 0.140 (in-sample avg dev_std = 0.594)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.47318625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7097649999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.528
NEC for r=0.9 class 0 = 0.5 +- 0.280 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 1 = 0.566 +- 0.280 (in-sample avg dev_std = 0.624)
NEC for r=0.9 class 2 = 0.552 +- 0.280 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all KL = 0.659 +- 0.280 (in-sample avg dev_std = 0.624)
NEC for r=0.9 all L1 = 0.539 +- 0.162 (in-sample avg dev_std = 0.624)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7097649999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.501 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 1 = 0.551 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 2 = 0.535 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all KL = 0.643 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all L1 = 0.529 +- 0.169 (in-sample avg dev_std = 0.619)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:23:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:23:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9162
Train Loss: 0.4093
ID Validation ACCURACY: 0.9230
ID Validation Loss: 0.3818
ID Test ACCURACY: 0.9110
ID Test Loss: 0.4274
OOD Validation ACCURACY: 0.9130
OOD Validation Loss: 0.4851
OOD Test ACCURACY: 0.8380
OOD Test Loss: 0.4985

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.8970
Train Loss: 0.4289
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.4071
ID Test ACCURACY: 0.8917
ID Test Loss: 0.4442
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4515
OOD Test ACCURACY: 0.8837
OOD Test Loss: 0.4862

[0m[1;37mINFO[0m: [1mChartInfo 0.9110 0.8380 0.8917 0.8837 0.9023 0.9293[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.704
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.749
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.754


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  0.7264400000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7041775
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.521
SUFF++ for r=0.3 class 0 = 0.444 +- 0.293 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 1 = 0.626 +- 0.293 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 class 2 = 0.534 +- 0.293 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all KL = 0.42 +- 0.293 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.3 all L1 = 0.534 +- 0.200 (in-sample avg dev_std = 0.599)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.899
Model XAI F1 of binarized graphs for r=0.6 =  0.61115875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7494737499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.754
SUFF++ for r=0.6 class 0 = 0.586 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 1 = 0.724 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 class 2 = 0.691 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all KL = 0.622 +- 0.264 (in-sample avg dev_std = 0.452)
SUFF++ for r=0.6 all L1 = 0.667 +- 0.196 (in-sample avg dev_std = 0.452)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47308625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7536912499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0 = 0.804 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1 = 0.808 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.879 +- 0.171 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.826 +- 0.170 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  0.7264400000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7041775
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.34
NEC for r=0.3 class 0 = 0.67 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 1 = 0.53 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.3 class 2 = 0.595 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all KL = 0.71 +- 0.266 (in-sample avg dev_std = 0.458)
NEC for r=0.3 all L1 = 0.599 +- 0.189 (in-sample avg dev_std = 0.458)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.901
Model XAI F1 of binarized graphs for r=0.6 =  0.61115875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7494737499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.441
NEC for r=0.6 class 0 = 0.613 +- 0.293 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 1 = 0.563 +- 0.293 (in-sample avg dev_std = 0.520)
NEC for r=0.6 class 2 = 0.611 +- 0.293 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all KL = 0.681 +- 0.293 (in-sample avg dev_std = 0.520)
NEC for r=0.6 all L1 = 0.596 +- 0.165 (in-sample avg dev_std = 0.520)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47308625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7536912499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.54
NEC for r=0.9 class 0 = 0.539 +- 0.286 (in-sample avg dev_std = 0.569)
NEC for r=0.9 class 1 = 0.511 +- 0.286 (in-sample avg dev_std = 0.569)
NEC for r=0.9 class 2 = 0.535 +- 0.286 (in-sample avg dev_std = 0.569)
NEC for r=0.9 all KL = 0.577 +- 0.286 (in-sample avg dev_std = 0.569)
NEC for r=0.9 all L1 = 0.529 +- 0.158 (in-sample avg dev_std = 0.569)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7536912499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.521 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 1 = 0.505 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 2 = 0.525 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all KL = 0.562 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all L1 = 0.517 +- 0.164 (in-sample avg dev_std = 0.571)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:24:26 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:24:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.9011
Train Loss: 0.4339
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.4039
ID Test ACCURACY: 0.9043
ID Test Loss: 0.4420
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.4746
OOD Test ACCURACY: 0.8267
OOD Test Loss: 0.4981

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.8969
Train Loss: 0.4316
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.4049
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4367
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.4768
OOD Test ACCURACY: 0.8177
OOD Test Loss: 0.5880

[0m[1;37mINFO[0m: [1mChartInfo 0.9043 0.8267 0.8977 0.8177 0.9050 0.9297[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.686
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.718
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.717
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.717


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.701
Model XAI F1 of binarized graphs for r=0.3 =  0.72575
Model XAI WIoU of binarized graphs for r=0.3 =  0.6864087499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.49
SUFF++ for r=0.3 class 0 = 0.365 +- 0.296 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 1 = 0.62 +- 0.296 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 2 = 0.525 +- 0.296 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all KL = 0.402 +- 0.296 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all L1 = 0.503 +- 0.201 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.61088875
Model XAI WIoU of binarized graphs for r=0.6 =  0.717885
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.714
SUFF++ for r=0.6 class 0 = 0.512 +- 0.274 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 1 = 0.709 +- 0.274 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 class 2 = 0.698 +- 0.274 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all KL = 0.607 +- 0.274 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.6 all L1 = 0.64 +- 0.218 (in-sample avg dev_std = 0.470)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.47278875
Model XAI WIoU of binarized graphs for r=0.9 =  0.71724125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.843
SUFF++ for r=0.9 class 0 = 0.798 +- 0.176 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 1 = 0.775 +- 0.176 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 2 = 0.858 +- 0.176 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all KL = 0.864 +- 0.176 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all L1 = 0.811 +- 0.174 (in-sample avg dev_std = 0.254)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.701
Model XAI F1 of binarized graphs for r=0.3 =  0.72575
Model XAI WIoU of binarized graphs for r=0.3 =  0.6864087499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.388
NEC for r=0.3 class 0 = 0.679 +- 0.285 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 1 = 0.481 +- 0.285 (in-sample avg dev_std = 0.496)
NEC for r=0.3 class 2 = 0.543 +- 0.285 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all KL = 0.663 +- 0.285 (in-sample avg dev_std = 0.496)
NEC for r=0.3 all L1 = 0.567 +- 0.206 (in-sample avg dev_std = 0.496)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.61088875
Model XAI WIoU of binarized graphs for r=0.6 =  0.717885
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.482
NEC for r=0.6 class 0 = 0.628 +- 0.294 (in-sample avg dev_std = 0.548)
NEC for r=0.6 class 1 = 0.523 +- 0.294 (in-sample avg dev_std = 0.548)
NEC for r=0.6 class 2 = 0.578 +- 0.294 (in-sample avg dev_std = 0.548)
NEC for r=0.6 all KL = 0.656 +- 0.294 (in-sample avg dev_std = 0.548)
NEC for r=0.6 all L1 = 0.577 +- 0.170 (in-sample avg dev_std = 0.548)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.47278875
Model XAI WIoU of binarized graphs for r=0.9 =  0.71724125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.55
NEC for r=0.9 class 0 = 0.563 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.499 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.512 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.572 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.525 +- 0.165 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.71724125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.54 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 1 = 0.498 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 2 = 0.507 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all KL = 0.552 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all L1 = 0.515 +- 0.167 (in-sample avg dev_std = 0.571)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:25:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:25:53 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ACCURACY: 0.8988
Train Loss: 0.4539
ID Validation ACCURACY: 0.9030
ID Validation Loss: 0.4374
ID Test ACCURACY: 0.8997
ID Test Loss: 0.4667
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.4777
OOD Test ACCURACY: 0.8460
OOD Test Loss: 0.5987

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.8639
Train Loss: 0.4728
ID Validation ACCURACY: 0.8680
ID Validation Loss: 0.4616
ID Test ACCURACY: 0.8647
ID Test Loss: 0.4806
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4486
OOD Test ACCURACY: 0.7277
OOD Test Loss: 0.7415

[0m[1;37mINFO[0m: [1mChartInfo 0.8997 0.8460 0.8647 0.7277 0.8680 0.9313[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.730
WIoU for r=0.3 = 0.717
F1 for r=0.6 = 0.615
WIoU for r=0.6 = 0.789
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.792
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.792


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.7301050000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7167174999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.467
SUFF++ for r=0.3 class 0 = 0.438 +- 0.280 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 class 1 = 0.65 +- 0.280 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 class 2 = 0.488 +- 0.280 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 all KL = 0.42 +- 0.280 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.3 all L1 = 0.524 +- 0.182 (in-sample avg dev_std = 0.592)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.615425
Model XAI WIoU of binarized graphs for r=0.6 =  0.7886650000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.705
SUFF++ for r=0.6 class 0 = 0.568 +- 0.281 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.6 class 1 = 0.682 +- 0.281 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.6 class 2 = 0.584 +- 0.281 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.6 all KL = 0.559 +- 0.281 (in-sample avg dev_std = 0.523)
SUFF++ for r=0.6 all L1 = 0.611 +- 0.185 (in-sample avg dev_std = 0.523)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4729375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7921012500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.828
SUFF++ for r=0.9 class 0 = 0.774 +- 0.213 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 1 = 0.776 +- 0.213 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 class 2 = 0.758 +- 0.213 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all KL = 0.818 +- 0.213 (in-sample avg dev_std = 0.299)
SUFF++ for r=0.9 all L1 = 0.769 +- 0.181 (in-sample avg dev_std = 0.299)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.7301050000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7167174999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.358
NEC for r=0.3 class 0 = 0.673 +- 0.295 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 1 = 0.489 +- 0.295 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 2 = 0.634 +- 0.295 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all KL = 0.695 +- 0.295 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all L1 = 0.6 +- 0.202 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.615425
Model XAI WIoU of binarized graphs for r=0.6 =  0.7886650000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.459
NEC for r=0.6 class 0 = 0.615 +- 0.283 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.555 +- 0.283 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.622 +- 0.283 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.658 +- 0.283 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.598 +- 0.154 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4729375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7921012500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.512
NEC for r=0.9 class 0 = 0.529 +- 0.289 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 1 = 0.517 +- 0.289 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 2 = 0.569 +- 0.289 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all KL = 0.557 +- 0.289 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all L1 = 0.539 +- 0.154 (in-sample avg dev_std = 0.516)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7921012500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.525
NEC for r=1.0 class 0 = 0.515 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 1 = 0.508 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 2 = 0.557 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all KL = 0.538 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all L1 = 0.527 +- 0.153 (in-sample avg dev_std = 0.512)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:27:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:27:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 150...
[0m[1;37mINFO[0m: [1mCheckpoint 150: 
-----------------------------------
Train ACCURACY: 0.9096
Train Loss: 0.4091
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.3875
ID Test ACCURACY: 0.9030
ID Test Loss: 0.4331
OOD Validation ACCURACY: 0.9240
OOD Validation Loss: 0.4585
OOD Test ACCURACY: 0.8997
OOD Test Loss: 0.4258

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.4702
ID Validation ACCURACY: 0.8970
ID Validation Loss: 0.4634
ID Test ACCURACY: 0.8937
ID Test Loss: 0.4939
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4938
OOD Test ACCURACY: 0.8903
OOD Test Loss: 0.4810

[0m[1;37mINFO[0m: [1mChartInfo 0.9030 0.8997 0.8937 0.8903 0.8970 0.9293[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.700
WIoU for r=0.3 = 0.675
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.772
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.769
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.769


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.533
Model XAI F1 of binarized graphs for r=0.3 =  0.699675
Model XAI WIoU of binarized graphs for r=0.3 =  0.6746000000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.44
SUFF++ for r=0.3 class 0 = 0.433 +- 0.260 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 1 = 0.527 +- 0.260 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 2 = 0.542 +- 0.260 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all KL = 0.43 +- 0.260 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all L1 = 0.501 +- 0.174 (in-sample avg dev_std = 0.586)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.611415
Model XAI WIoU of binarized graphs for r=0.6 =  0.7717050000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.672
SUFF++ for r=0.6 class 0 = 0.485 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 class 1 = 0.627 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 class 2 = 0.679 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 all KL = 0.554 +- 0.275 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.6 all L1 = 0.598 +- 0.191 (in-sample avg dev_std = 0.535)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.47296374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7689675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0 = 0.751 +- 0.180 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.806 +- 0.180 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.832 +- 0.180 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.845 +- 0.180 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.797 +- 0.166 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  0.699675
Model XAI WIoU of binarized graphs for r=0.3 =  0.6746000000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.338
NEC for r=0.3 class 0 = 0.604 +- 0.264 (in-sample avg dev_std = 0.523)
NEC for r=0.3 class 1 = 0.571 +- 0.264 (in-sample avg dev_std = 0.523)
NEC for r=0.3 class 2 = 0.576 +- 0.264 (in-sample avg dev_std = 0.523)
NEC for r=0.3 all KL = 0.665 +- 0.264 (in-sample avg dev_std = 0.523)
NEC for r=0.3 all L1 = 0.583 +- 0.156 (in-sample avg dev_std = 0.523)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.611415
Model XAI WIoU of binarized graphs for r=0.6 =  0.7717050000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.453
NEC for r=0.6 class 0 = 0.607 +- 0.284 (in-sample avg dev_std = 0.526)
NEC for r=0.6 class 1 = 0.588 +- 0.284 (in-sample avg dev_std = 0.526)
NEC for r=0.6 class 2 = 0.559 +- 0.284 (in-sample avg dev_std = 0.526)
NEC for r=0.6 all KL = 0.647 +- 0.284 (in-sample avg dev_std = 0.526)
NEC for r=0.6 all L1 = 0.584 +- 0.163 (in-sample avg dev_std = 0.526)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.47296374999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7689675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.547
NEC for r=0.9 class 0 = 0.543 +- 0.283 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 1 = 0.483 +- 0.283 (in-sample avg dev_std = 0.551)
NEC for r=0.9 class 2 = 0.522 +- 0.283 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all KL = 0.544 +- 0.283 (in-sample avg dev_std = 0.551)
NEC for r=0.9 all L1 = 0.516 +- 0.166 (in-sample avg dev_std = 0.551)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.909
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7689675
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.549
NEC for r=1.0 class 0 = 0.522 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 1 = 0.489 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 2 = 0.521 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all KL = 0.527 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all L1 = 0.511 +- 0.163 (in-sample avg dev_std = 0.549)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.338, 0.492, 0.797, 1.0], 'all_L1': [0.521, 0.62, 0.793, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.42, 0.622, 0.879, 1.0], 'all_L1': [0.534, 0.667, 0.826, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.402, 0.607, 0.864, 1.0], 'all_L1': [0.503, 0.64, 0.811, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.42, 0.559, 0.818, 1.0], 'all_L1': [0.524, 0.611, 0.769, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.43, 0.554, 0.845, 1.0], 'all_L1': [0.501, 0.598, 0.797, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.792, 0.75, 0.659, 0.643], 'all_L1': [0.605, 0.609, 0.539, 0.529]}), defaultdict(<class 'list'>, {'all_KL': [0.71, 0.681, 0.577, 0.562], 'all_L1': [0.599, 0.596, 0.529, 0.517]}), defaultdict(<class 'list'>, {'all_KL': [0.663, 0.656, 0.572, 0.552], 'all_L1': [0.567, 0.577, 0.525, 0.515]}), defaultdict(<class 'list'>, {'all_KL': [0.695, 0.658, 0.557, 0.538], 'all_L1': [0.6, 0.598, 0.539, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.665, 0.647, 0.544, 0.527], 'all_L1': [0.583, 0.584, 0.516, 0.511]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.517 +- 0.013, 0.627 +- 0.024, 0.799 +- 0.019, 1.000 +- 0.000
suff++ class all_KL  =  0.402 +- 0.033, 0.567 +- 0.046, 0.841 +- 0.030, 1.000 +- 0.000
suff++_acc_int  =  0.484 +- 0.028, 0.713 +- 0.026, 0.844 +- 0.018
nec class all_L1  =  0.591 +- 0.014, 0.593 +- 0.011, 0.530 +- 0.009, 0.520 +- 0.007
nec class all_KL  =  0.705 +- 0.047, 0.678 +- 0.038, 0.582 +- 0.040, 0.564 +- 0.041
nec_acc_int  =  0.355 +- 0.018, 0.456 +- 0.014, 0.535 +- 0.014, 0.544 +- 0.010


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.554 +- 0.013, 0.610 +- 0.013, 0.664 +- 0.008, 0.760 +- 0.003
Faith. Armon (L1)= 		  =  0.551 +- 0.013, 0.609 +- 0.013, 0.637 +- 0.006, 0.684 +- 0.006
Faith. GMean (L1)= 	  =  0.552 +- 0.013, 0.610 +- 0.013, 0.650 +- 0.007, 0.721 +- 0.005
Faith. Aritm (KL)= 		  =  0.553 +- 0.012, 0.623 +- 0.018, 0.711 +- 0.017, 0.782 +- 0.021
Faith. Armon (KL)= 		  =  0.510 +- 0.020, 0.615 +- 0.022, 0.686 +- 0.022, 0.721 +- 0.033
Faith. GMean (KL)= 	  =  0.531 +- 0.012, 0.619 +- 0.019, 0.699 +- 0.019, 0.751 +- 0.027
Computed for split load_split = id



Completed in  0:06:46.578285  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:28:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:28:53 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:10 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:18 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:29:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.8868
Train Loss: 0.4263
ID Validation ACCURACY: 0.8903
ID Validation Loss: 0.4063
ID Test ACCURACY: 0.8870
ID Test Loss: 0.4328
OOD Validation ACCURACY: 0.7457
OOD Validation Loss: 5.4460
OOD Test ACCURACY: 0.5017
OOD Test Loss: 29.7885

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ACCURACY: 0.8296
Train Loss: 0.5063
ID Validation ACCURACY: 0.8310
ID Validation Loss: 0.4794
ID Test ACCURACY: 0.8297
ID Test Loss: 0.5080
OOD Validation ACCURACY: 0.8050
OOD Validation Loss: 2.5637
OOD Test ACCURACY: 0.6360
OOD Test Loss: 14.4751

[0m[1;37mINFO[0m: [1mChartInfo 0.8870 0.5017 0.8297 0.6360 0.8310 0.8050[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.597
WIoU for r=0.3 = 0.473
F1 for r=0.6 = 0.636
WIoU for r=0.6 = 0.575
F1 for r=0.9 = 0.539
WIoU for r=0.9 = 0.564
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.560


Evaluating SUFF++ for seed 1 with load_split id

[1;31mERROR[0m: 05/08/2024 12:29:43 PM - utils.py - line 87 : [1mTraceback (most recent call last):
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/bin/goodtg", line 33, in <module>
    sys.exit(load_entry_point('graph-ood', 'console_scripts', 'goodtg')())
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 637, in goodtg
    try:
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 537, in main
    if args.task == 'eval_metric':
  File "/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/kernel/main.py", line 333, in evaluate_metric
    score, acc_int, results = pipeline.compute_metric_ratio(
  File "/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
TypeError: compute_metric_ratio() missing 1 required positional argument: 'split'
[0m
[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:32:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:32:47 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:00 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:04 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:06 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:33:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 104...
[0m[1;37mINFO[0m: [1mCheckpoint 104: 
-----------------------------------
Train ACCURACY: 0.9199
Train Loss: 0.4046
ID Validation ACCURACY: 0.9187
ID Validation Loss: 0.4190
ID Test ACCURACY: 0.9173
ID Test Loss: 0.4155
OOD Validation ACCURACY: 0.8993
OOD Validation Loss: 0.4204
OOD Test ACCURACY: 0.8580
OOD Test Loss: 0.4743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9207
Train Loss: 0.3963
ID Validation ACCURACY: 0.9180
ID Validation Loss: 0.4080
ID Test ACCURACY: 0.9190
ID Test Loss: 0.4092
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.3561
OOD Test ACCURACY: 0.8053
OOD Test Loss: 0.5858

[0m[1;37mINFO[0m: [1mChartInfo 0.9173 0.8580 0.9190 0.8053 0.9180 0.9230[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.729
WIoU for r=0.3 = 0.676
F1 for r=0.6 = 0.623
WIoU for r=0.6 = 0.702
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.705
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.705


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.625
Model XAI F1 of binarized graphs for r=0.3 =  0.7293575
Model XAI WIoU of binarized graphs for r=0.3 =  0.67584375
len(reference) = 797
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.479
SUFF++ for r=0.3 class 0 = 0.412 +- 0.263 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 class 1 = 0.481 +- 0.263 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 class 2 = 0.582 +- 0.263 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 all KL = 0.4 +- 0.263 (in-sample avg dev_std = 0.569)
SUFF++ for r=0.3 all L1 = 0.49 +- 0.174 (in-sample avg dev_std = 0.569)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.868
Model XAI F1 of binarized graphs for r=0.6 =  0.6234474999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7022562499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.684
SUFF++ for r=0.6 class 0 = 0.48 +- 0.272 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 class 1 = 0.612 +- 0.272 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 class 2 = 0.672 +- 0.272 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 all KL = 0.544 +- 0.272 (in-sample avg dev_std = 0.505)
SUFF++ for r=0.6 all L1 = 0.587 +- 0.200 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.48878625
Model XAI WIoU of binarized graphs for r=0.9 =  0.70473375
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.862
SUFF++ for r=0.9 class 0 = 0.796 +- 0.163 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1 = 0.754 +- 0.163 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 2 = 0.849 +- 0.163 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.867 +- 0.163 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.799 +- 0.160 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.623
Model XAI F1 of binarized graphs for r=0.3 =  0.7293575
Model XAI WIoU of binarized graphs for r=0.3 =  0.67584375
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.365
NEC for r=0.3 class 0 = 0.654 +- 0.231 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 1 = 0.593 +- 0.231 (in-sample avg dev_std = 0.486)
NEC for r=0.3 class 2 = 0.602 +- 0.231 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all KL = 0.744 +- 0.231 (in-sample avg dev_std = 0.486)
NEC for r=0.3 all L1 = 0.616 +- 0.134 (in-sample avg dev_std = 0.486)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6234474999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7022562499999999
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.452
NEC for r=0.6 class 0 = 0.6 +- 0.276 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 1 = 0.588 +- 0.276 (in-sample avg dev_std = 0.493)
NEC for r=0.6 class 2 = 0.586 +- 0.276 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all KL = 0.655 +- 0.276 (in-sample avg dev_std = 0.493)
NEC for r=0.6 all L1 = 0.592 +- 0.155 (in-sample avg dev_std = 0.493)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.916
Model XAI F1 of binarized graphs for r=0.9 =  0.48878625
Model XAI WIoU of binarized graphs for r=0.9 =  0.70473375
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.518
NEC for r=0.9 class 0 = 0.52 +- 0.277 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 1 = 0.547 +- 0.277 (in-sample avg dev_std = 0.534)
NEC for r=0.9 class 2 = 0.552 +- 0.277 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all KL = 0.563 +- 0.277 (in-sample avg dev_std = 0.534)
NEC for r=0.9 all L1 = 0.539 +- 0.157 (in-sample avg dev_std = 0.534)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.92
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7046237500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.539
NEC for r=1.0 class 0 = 0.493 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 class 1 = 0.53 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 class 2 = 0.536 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 all KL = 0.53 +- 0.279 (in-sample avg dev_std = 0.521)
NEC for r=1.0 all L1 = 0.519 +- 0.163 (in-sample avg dev_std = 0.521)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:34:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:24 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:36 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:38 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:42 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:34:44 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ACCURACY: 0.9093
Train Loss: 0.4153
ID Validation ACCURACY: 0.9077
ID Validation Loss: 0.4259
ID Test ACCURACY: 0.9133
ID Test Loss: 0.4117
OOD Validation ACCURACY: 0.8497
OOD Validation Loss: 0.4942
OOD Test ACCURACY: 0.7820
OOD Test Loss: 0.6459

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 120...
[0m[1;37mINFO[0m: [1mCheckpoint 120: 
-----------------------------------
Train ACCURACY: 0.8288
Train Loss: 0.5416
ID Validation ACCURACY: 0.8220
ID Validation Loss: 0.5634
ID Test ACCURACY: 0.8233
ID Test Loss: 0.5510
OOD Validation ACCURACY: 0.8977
OOD Validation Loss: 0.4180
OOD Test ACCURACY: 0.7627
OOD Test Loss: 0.6773

[0m[1;37mINFO[0m: [1mChartInfo 0.9133 0.7820 0.8233 0.7627 0.8220 0.8977[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.706
WIoU for r=0.3 = 0.680
F1 for r=0.6 = 0.626
WIoU for r=0.6 = 0.796
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.803
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.803


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.673
Model XAI F1 of binarized graphs for r=0.3 =  0.7064474999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.68047
len(reference) = 798
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.477
SUFF++ for r=0.3 class 0 = 0.422 +- 0.254 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 1 = 0.486 +- 0.254 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 class 2 = 0.467 +- 0.254 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all KL = 0.368 +- 0.254 (in-sample avg dev_std = 0.617)
SUFF++ for r=0.3 all L1 = 0.458 +- 0.149 (in-sample avg dev_std = 0.617)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.858
Model XAI F1 of binarized graphs for r=0.6 =  0.6255175
Model XAI WIoU of binarized graphs for r=0.6 =  0.79622375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.73
SUFF++ for r=0.6 class 0 = 0.573 +- 0.265 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 1 = 0.693 +- 0.265 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 class 2 = 0.662 +- 0.265 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all KL = 0.608 +- 0.265 (in-sample avg dev_std = 0.471)
SUFF++ for r=0.6 all L1 = 0.643 +- 0.185 (in-sample avg dev_std = 0.471)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.48902124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.8026025
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0 = 0.797 +- 0.130 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 1 = 0.849 +- 0.130 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.130 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all KL = 0.895 +- 0.130 (in-sample avg dev_std = 0.243)
SUFF++ for r=0.9 all L1 = 0.84 +- 0.131 (in-sample avg dev_std = 0.243)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.675
Model XAI F1 of binarized graphs for r=0.3 =  0.7064474999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.68047
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.348
NEC for r=0.3 class 0 = 0.636 +- 0.252 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 1 = 0.641 +- 0.252 (in-sample avg dev_std = 0.459)
NEC for r=0.3 class 2 = 0.645 +- 0.252 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all KL = 0.708 +- 0.252 (in-sample avg dev_std = 0.459)
NEC for r=0.3 all L1 = 0.641 +- 0.137 (in-sample avg dev_std = 0.459)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.858
Model XAI F1 of binarized graphs for r=0.6 =  0.6255175
Model XAI WIoU of binarized graphs for r=0.6 =  0.79622375
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.449
NEC for r=0.6 class 0 = 0.568 +- 0.294 (in-sample avg dev_std = 0.483)
NEC for r=0.6 class 1 = 0.595 +- 0.294 (in-sample avg dev_std = 0.483)
NEC for r=0.6 class 2 = 0.605 +- 0.294 (in-sample avg dev_std = 0.483)
NEC for r=0.6 all KL = 0.639 +- 0.294 (in-sample avg dev_std = 0.483)
NEC for r=0.6 all L1 = 0.589 +- 0.155 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.909
Model XAI F1 of binarized graphs for r=0.9 =  0.48902124999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.8026025
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.529
NEC for r=0.9 class 0 = 0.51 +- 0.283 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 1 = 0.541 +- 0.283 (in-sample avg dev_std = 0.537)
NEC for r=0.9 class 2 = 0.526 +- 0.283 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all KL = 0.546 +- 0.283 (in-sample avg dev_std = 0.537)
NEC for r=0.9 all L1 = 0.526 +- 0.157 (in-sample avg dev_std = 0.537)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.8026025
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.54
NEC for r=1.0 class 0 = 0.492 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 class 1 = 0.534 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 class 2 = 0.511 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 all KL = 0.525 +- 0.287 (in-sample avg dev_std = 0.528)
NEC for r=1.0 all L1 = 0.512 +- 0.164 (in-sample avg dev_std = 0.528)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:35:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:35:57 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:10 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:12 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:14 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:36:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ACCURACY: 0.9147
Train Loss: 0.4029
ID Validation ACCURACY: 0.9103
ID Validation Loss: 0.4205
ID Test ACCURACY: 0.9083
ID Test Loss: 0.4147
OOD Validation ACCURACY: 0.8440
OOD Validation Loss: 0.4769
OOD Test ACCURACY: 0.8217
OOD Test Loss: 0.6118

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8890
Train Loss: 0.4742
ID Validation ACCURACY: 0.8847
ID Validation Loss: 0.4966
ID Test ACCURACY: 0.8883
ID Test Loss: 0.4729
OOD Validation ACCURACY: 0.9260
OOD Validation Loss: 0.3740
OOD Test ACCURACY: 0.6043
OOD Test Loss: 1.1293

[0m[1;37mINFO[0m: [1mChartInfo 0.9083 0.8217 0.8883 0.6043 0.8847 0.9260[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.714
WIoU for r=0.3 = 0.695
F1 for r=0.6 = 0.627
WIoU for r=0.6 = 0.809
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.813
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.813


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.708
Model XAI F1 of binarized graphs for r=0.3 =  0.71383625
Model XAI WIoU of binarized graphs for r=0.3 =  0.694975
len(reference) = 790
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.504
SUFF++ for r=0.3 class 0 = 0.449 +- 0.252 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 1 = 0.493 +- 0.252 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 class 2 = 0.493 +- 0.252 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all KL = 0.364 +- 0.252 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.3 all L1 = 0.478 +- 0.168 (in-sample avg dev_std = 0.628)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.863
Model XAI F1 of binarized graphs for r=0.6 =  0.6274425
Model XAI WIoU of binarized graphs for r=0.6 =  0.80949625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.743
SUFF++ for r=0.6 class 0 = 0.577 +- 0.291 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 class 1 = 0.662 +- 0.291 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 class 2 = 0.662 +- 0.291 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 all KL = 0.565 +- 0.291 (in-sample avg dev_std = 0.496)
SUFF++ for r=0.6 all L1 = 0.633 +- 0.194 (in-sample avg dev_std = 0.496)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.489
Model XAI WIoU of binarized graphs for r=0.9 =  0.8127362499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.859
SUFF++ for r=0.9 class 0 = 0.8 +- 0.182 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 1 = 0.806 +- 0.182 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 class 2 = 0.878 +- 0.182 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all KL = 0.87 +- 0.182 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.9 all L1 = 0.827 +- 0.159 (in-sample avg dev_std = 0.264)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.707
Model XAI F1 of binarized graphs for r=0.3 =  0.71383625
Model XAI WIoU of binarized graphs for r=0.3 =  0.694975
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.653 +- 0.244 (in-sample avg dev_std = 0.469)
NEC for r=0.3 class 1 = 0.616 +- 0.244 (in-sample avg dev_std = 0.469)
NEC for r=0.3 class 2 = 0.656 +- 0.244 (in-sample avg dev_std = 0.469)
NEC for r=0.3 all KL = 0.732 +- 0.244 (in-sample avg dev_std = 0.469)
NEC for r=0.3 all L1 = 0.642 +- 0.134 (in-sample avg dev_std = 0.469)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.861
Model XAI F1 of binarized graphs for r=0.6 =  0.6274425
Model XAI WIoU of binarized graphs for r=0.6 =  0.80949625
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.464
NEC for r=0.6 class 0 = 0.589 +- 0.278 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.591 +- 0.278 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.575 +- 0.278 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.662 +- 0.278 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.585 +- 0.152 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.892
Model XAI F1 of binarized graphs for r=0.9 =  0.489
Model XAI WIoU of binarized graphs for r=0.9 =  0.8127362499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.563
NEC for r=0.9 class 0 = 0.505 +- 0.285 (in-sample avg dev_std = 0.552)
NEC for r=0.9 class 1 = 0.526 +- 0.285 (in-sample avg dev_std = 0.552)
NEC for r=0.9 class 2 = 0.5 +- 0.285 (in-sample avg dev_std = 0.552)
NEC for r=0.9 all KL = 0.552 +- 0.285 (in-sample avg dev_std = 0.552)
NEC for r=0.9 all L1 = 0.511 +- 0.164 (in-sample avg dev_std = 0.552)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.8127324999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.558
NEC for r=1.0 class 0 = 0.506 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 1 = 0.52 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 class 2 = 0.494 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all KL = 0.544 +- 0.287 (in-sample avg dev_std = 0.545)
NEC for r=1.0 all L1 = 0.507 +- 0.167 (in-sample avg dev_std = 0.545)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:37:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:29 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:45 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:47 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:50 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:52 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:37:54 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9206
Train Loss: 0.4075
ID Validation ACCURACY: 0.9150
ID Validation Loss: 0.4315
ID Test ACCURACY: 0.9157
ID Test Loss: 0.4215
OOD Validation ACCURACY: 0.8893
OOD Validation Loss: 0.4249
OOD Test ACCURACY: 0.7647
OOD Test Loss: 0.6361

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.8867
Train Loss: 0.4496
ID Validation ACCURACY: 0.8873
ID Validation Loss: 0.4598
ID Test ACCURACY: 0.8847
ID Test Loss: 0.4508
OOD Validation ACCURACY: 0.9143
OOD Validation Loss: 0.3926
OOD Test ACCURACY: 0.5360
OOD Test Loss: 1.0543

[0m[1;37mINFO[0m: [1mChartInfo 0.9157 0.7647 0.8847 0.5360 0.8873 0.9143[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.723
WIoU for r=0.3 = 0.723
F1 for r=0.6 = 0.628
WIoU for r=0.6 = 0.794
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.795
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.795


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.69
Model XAI F1 of binarized graphs for r=0.3 =  0.7229249999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7232237499999999
len(reference) = 797
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.511
SUFF++ for r=0.3 class 0 = 0.533 +- 0.271 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 class 1 = 0.595 +- 0.271 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 class 2 = 0.491 +- 0.271 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 all KL = 0.393 +- 0.271 (in-sample avg dev_std = 0.621)
SUFF++ for r=0.3 all L1 = 0.541 +- 0.186 (in-sample avg dev_std = 0.621)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.6276975
Model XAI WIoU of binarized graphs for r=0.6 =  0.7941875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.719
SUFF++ for r=0.6 class 0 = 0.558 +- 0.281 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 class 1 = 0.677 +- 0.281 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 class 2 = 0.647 +- 0.281 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 all KL = 0.549 +- 0.281 (in-sample avg dev_std = 0.522)
SUFF++ for r=0.6 all L1 = 0.627 +- 0.184 (in-sample avg dev_std = 0.522)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.905
Model XAI F1 of binarized graphs for r=0.9 =  0.48898624999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951712499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0 = 0.816 +- 0.180 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 1 = 0.805 +- 0.180 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 class 2 = 0.855 +- 0.180 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all KL = 0.871 +- 0.180 (in-sample avg dev_std = 0.259)
SUFF++ for r=0.9 all L1 = 0.825 +- 0.167 (in-sample avg dev_std = 0.259)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.69
Model XAI F1 of binarized graphs for r=0.3 =  0.7229249999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.7232237499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.376
NEC for r=0.3 class 0 = 0.594 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.3 class 1 = 0.519 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.3 class 2 = 0.613 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.3 all KL = 0.696 +- 0.277 (in-sample avg dev_std = 0.504)
NEC for r=0.3 all L1 = 0.574 +- 0.200 (in-sample avg dev_std = 0.504)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  0.6276975
Model XAI WIoU of binarized graphs for r=0.6 =  0.7941875
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.613 +- 0.278 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 1 = 0.566 +- 0.278 (in-sample avg dev_std = 0.521)
NEC for r=0.6 class 2 = 0.639 +- 0.278 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all KL = 0.691 +- 0.278 (in-sample avg dev_std = 0.521)
NEC for r=0.6 all L1 = 0.605 +- 0.152 (in-sample avg dev_std = 0.521)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.901
Model XAI F1 of binarized graphs for r=0.9 =  0.48898624999999996
Model XAI WIoU of binarized graphs for r=0.9 =  0.7951712499999999
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.506
NEC for r=0.9 class 0 = 0.529 +- 0.288 (in-sample avg dev_std = 0.562)
NEC for r=0.9 class 1 = 0.526 +- 0.288 (in-sample avg dev_std = 0.562)
NEC for r=0.9 class 2 = 0.567 +- 0.288 (in-sample avg dev_std = 0.562)
NEC for r=0.9 all KL = 0.587 +- 0.288 (in-sample avg dev_std = 0.562)
NEC for r=0.9 all L1 = 0.54 +- 0.159 (in-sample avg dev_std = 0.562)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.7951712499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.525
NEC for r=1.0 class 0 = 0.509 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 1 = 0.508 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 class 2 = 0.553 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all KL = 0.554 +- 0.287 (in-sample avg dev_std = 0.548)
NEC for r=1.0 all L1 = 0.523 +- 0.161 (in-sample avg dev_std = 0.548)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:39:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:30 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:44 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:46 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:48 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:50 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1m Data(edge_index=[2, 64], x=[18, 1], node_gt=[18], edge_gt=[64], y=[1], env_id=[1], ori_edge_index=[2, 64], node_perm=[18], num_nodes=18)
[0mData(edge_index=[2, 52], x=[19, 1], node_gt=[19], edge_gt=[52], y=[1], env_id=[1], ori_edge_index=[2, 52], node_perm=[19], num_nodes=19)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:39:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.9203
Train Loss: 0.3905
ID Validation ACCURACY: 0.9223
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.9180
ID Test Loss: 0.4033
OOD Validation ACCURACY: 0.8893
OOD Validation Loss: 0.4035
OOD Test ACCURACY: 0.7510
OOD Test Loss: 0.7925

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.8950
Train Loss: 0.4249
ID Validation ACCURACY: 0.8940
ID Validation Loss: 0.4447
ID Test ACCURACY: 0.8920
ID Test Loss: 0.4247
OOD Validation ACCURACY: 0.9317
OOD Validation Loss: 0.3254
OOD Test ACCURACY: 0.6273
OOD Test Loss: 1.0432

[0m[1;37mINFO[0m: [1mChartInfo 0.9180 0.7510 0.8920 0.6273 0.8940 0.9317[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 26], x=[12, 1], node_gt=[12], edge_gt=[26], y=[1], env_id=[1], ori_edge_index=[2, 26], node_perm=[12], num_nodes=12)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1012, 1021,  967]))

Gold ratio (id_test) =  tensor(0.3175) +- tensor(0.1645)
F1 for r=0.3 = 0.716
WIoU for r=0.3 = 0.685
F1 for r=0.6 = 0.627
WIoU for r=0.6 = 0.754
F1 for r=0.9 = 0.489
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.459
WIoU for r=1.0 = 0.754


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.691
Model XAI F1 of binarized graphs for r=0.3 =  0.7161949999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6846625000000001
len(reference) = 795
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.487
SUFF++ for r=0.3 class 0 = 0.406 +- 0.248 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 1 = 0.515 +- 0.248 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 class 2 = 0.514 +- 0.248 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all KL = 0.352 +- 0.248 (in-sample avg dev_std = 0.623)
SUFF++ for r=0.3 all L1 = 0.478 +- 0.172 (in-sample avg dev_std = 0.623)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6274649999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7541225
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.723
SUFF++ for r=0.6 class 0 = 0.523 +- 0.272 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 1 = 0.708 +- 0.272 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.272 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all KL = 0.568 +- 0.272 (in-sample avg dev_std = 0.484)
SUFF++ for r=0.6 all L1 = 0.635 +- 0.198 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.48923125
Model XAI WIoU of binarized graphs for r=0.9 =  0.7537962500000001
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0 = 0.744 +- 0.195 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 1 = 0.773 +- 0.195 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 class 2 = 0.837 +- 0.195 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all KL = 0.834 +- 0.195 (in-sample avg dev_std = 0.278)
SUFF++ for r=0.9 all L1 = 0.784 +- 0.191 (in-sample avg dev_std = 0.278)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.691
Model XAI F1 of binarized graphs for r=0.3 =  0.7161949999999999
Model XAI WIoU of binarized graphs for r=0.3 =  0.6846625000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.396
NEC for r=0.3 class 0 = 0.638 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 class 1 = 0.611 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 class 2 = 0.604 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 all KL = 0.755 +- 0.223 (in-sample avg dev_std = 0.562)
NEC for r=0.3 all L1 = 0.618 +- 0.131 (in-sample avg dev_std = 0.562)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.865
Model XAI F1 of binarized graphs for r=0.6 =  0.6274649999999999
Model XAI WIoU of binarized graphs for r=0.6 =  0.7541225
len(reference) = 800
Effective ratio: 0.612 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.458
NEC for r=0.6 class 0 = 0.591 +- 0.279 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 1 = 0.568 +- 0.279 (in-sample avg dev_std = 0.529)
NEC for r=0.6 class 2 = 0.606 +- 0.279 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all KL = 0.677 +- 0.279 (in-sample avg dev_std = 0.529)
NEC for r=0.6 all L1 = 0.588 +- 0.159 (in-sample avg dev_std = 0.529)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.919
Model XAI F1 of binarized graphs for r=0.9 =  0.48923125
Model XAI WIoU of binarized graphs for r=0.9 =  0.7537962500000001
len(reference) = 800
Effective ratio: 0.915 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.585
NEC for r=0.9 class 0 = 0.508 +- 0.288 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 1 = 0.5 +- 0.288 (in-sample avg dev_std = 0.560)
NEC for r=0.9 class 2 = 0.53 +- 0.288 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all KL = 0.562 +- 0.288 (in-sample avg dev_std = 0.560)
NEC for r=0.9 all L1 = 0.513 +- 0.161 (in-sample avg dev_std = 0.560)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.919
Model XAI F1 of binarized graphs for r=1.0 =  0.45948124999999995
Model XAI WIoU of binarized graphs for r=1.0 =  0.75372
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.58
NEC for r=1.0 class 0 = 0.503 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 1 = 0.517 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 2 = 0.52 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all KL = 0.556 +- 0.274 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all L1 = 0.514 +- 0.152 (in-sample avg dev_std = 0.555)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.4, 0.544, 0.867, 1.0], 'all_L1': [0.49, 0.587, 0.799, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.368, 0.608, 0.895, 1.0], 'all_L1': [0.458, 0.643, 0.84, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.364, 0.565, 0.87, 1.0], 'all_L1': [0.478, 0.633, 0.827, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.393, 0.549, 0.871, 1.0], 'all_L1': [0.541, 0.627, 0.825, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.352, 0.568, 0.834, 1.0], 'all_L1': [0.478, 0.635, 0.784, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.744, 0.655, 0.563, 0.53], 'all_L1': [0.616, 0.592, 0.539, 0.519]}), defaultdict(<class 'list'>, {'all_KL': [0.708, 0.639, 0.546, 0.525], 'all_L1': [0.641, 0.589, 0.526, 0.512]}), defaultdict(<class 'list'>, {'all_KL': [0.732, 0.662, 0.552, 0.544], 'all_L1': [0.642, 0.585, 0.511, 0.507]}), defaultdict(<class 'list'>, {'all_KL': [0.696, 0.691, 0.587, 0.554], 'all_L1': [0.574, 0.605, 0.54, 0.523]}), defaultdict(<class 'list'>, {'all_KL': [0.755, 0.677, 0.562, 0.556], 'all_L1': [0.618, 0.588, 0.513, 0.514]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.489 +- 0.028, 0.625 +- 0.020, 0.815 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.375 +- 0.018, 0.567 +- 0.023, 0.867 +- 0.019, 1.000 +- 0.000
suff++_acc_int  =  0.492 +- 0.014, 0.720 +- 0.020, 0.858 +- 0.015
nec class all_L1  =  0.618 +- 0.025, 0.592 +- 0.007, 0.526 +- 0.012, 0.515 +- 0.006
nec class all_KL  =  0.727 +- 0.022, 0.665 +- 0.018, 0.562 +- 0.014, 0.542 +- 0.012
nec_acc_int  =  0.370 +- 0.016, 0.451 +- 0.011, 0.540 +- 0.029, 0.548 +- 0.019


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.554 +- 0.005, 0.608 +- 0.010, 0.670 +- 0.013, 0.757 +- 0.003
Faith. Armon (L1)= 		  =  0.545 +- 0.008, 0.608 +- 0.010, 0.639 +- 0.012, 0.680 +- 0.005
Faith. GMean (L1)= 	  =  0.549 +- 0.006, 0.608 +- 0.010, 0.655 +- 0.012, 0.718 +- 0.004
Faith. Aritm (KL)= 		  =  0.551 +- 0.012, 0.616 +- 0.009, 0.715 +- 0.010, 0.771 +- 0.006
Faith. Armon (KL)= 		  =  0.495 +- 0.015, 0.611 +- 0.010, 0.682 +- 0.010, 0.703 +- 0.011
Faith. GMean (KL)= 	  =  0.522 +- 0.012, 0.614 +- 0.009, 0.698 +- 0.010, 0.736 +- 0.008
Computed for split load_split = id



Completed in  0:08:23.670902  for LECIGIN GOODMotif/basis



DONE LECI GOODMotif/basis readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:41:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:41:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9077
Train Loss: 0.4320
ID Validation ACCURACY: 0.9117
ID Validation Loss: 0.4033
ID Test ACCURACY: 0.9047
ID Test Loss: 0.4417
OOD Validation ACCURACY: 0.9277
OOD Validation Loss: 0.3670
OOD Test ACCURACY: 0.9023
OOD Test Loss: 0.4492

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 130...
[0m[1;37mINFO[0m: [1mCheckpoint 130: 
-----------------------------------
Train ACCURACY: 0.8641
Train Loss: 0.4637
ID Validation ACCURACY: 0.8727
ID Validation Loss: 0.4477
ID Test ACCURACY: 0.8610
ID Test Loss: 0.4772
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.7927
OOD Test Loss: 0.6936

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.9023 0.8610 0.7927 0.8727 0.9313[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.712
WIoU for r=0.3 = 0.671
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.706
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.710
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.710


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  0.7121925
Model XAI WIoU of binarized graphs for r=0.3 =  0.67059625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.504
SUFF++ for r=0.3 class 0 = 0.446 +- 0.261 (in-sample avg dev_std = 0.635)
SUFF++ for r=0.3 class 1 = 0.607 +- 0.261 (in-sample avg dev_std = 0.635)
SUFF++ for r=0.3 class 2 = 0.513 +- 0.261 (in-sample avg dev_std = 0.635)
SUFF++ for r=0.3 all KL = 0.337 +- 0.261 (in-sample avg dev_std = 0.635)
SUFF++ for r=0.3 all L1 = 0.521 +- 0.185 (in-sample avg dev_std = 0.635)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.886
Model XAI F1 of binarized graphs for r=0.6 =  0.61016125
Model XAI WIoU of binarized graphs for r=0.6 =  0.70587125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.724
SUFF++ for r=0.6 class 0 = 0.561 +- 0.286 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 1 = 0.636 +- 0.286 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 2 = 0.672 +- 0.286 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all KL = 0.501 +- 0.286 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all L1 = 0.624 +- 0.199 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.47318625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7097649999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0 = 0.82 +- 0.252 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 class 1 = 0.793 +- 0.252 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 class 2 = 0.775 +- 0.252 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 all KL = 0.801 +- 0.252 (in-sample avg dev_std = 0.307)
SUFF++ for r=0.9 all L1 = 0.796 +- 0.211 (in-sample avg dev_std = 0.307)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.606
Model XAI F1 of binarized graphs for r=0.3 =  0.7121925
Model XAI WIoU of binarized graphs for r=0.3 =  0.67059625
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.35
NEC for r=0.3 class 0 = 0.649 +- 0.219 (in-sample avg dev_std = 0.542)
NEC for r=0.3 class 1 = 0.532 +- 0.219 (in-sample avg dev_std = 0.542)
NEC for r=0.3 class 2 = 0.619 +- 0.219 (in-sample avg dev_std = 0.542)
NEC for r=0.3 all KL = 0.79 +- 0.219 (in-sample avg dev_std = 0.542)
NEC for r=0.3 all L1 = 0.601 +- 0.156 (in-sample avg dev_std = 0.542)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.894
Model XAI F1 of binarized graphs for r=0.6 =  0.61016125
Model XAI WIoU of binarized graphs for r=0.6 =  0.70587125
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.447
NEC for r=0.6 class 0 = 0.599 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 1 = 0.616 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=0.6 class 2 = 0.607 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all KL = 0.747 +- 0.245 (in-sample avg dev_std = 0.593)
NEC for r=0.6 all L1 = 0.607 +- 0.142 (in-sample avg dev_std = 0.593)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.914
Model XAI F1 of binarized graphs for r=0.9 =  0.47318625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7097649999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.515
NEC for r=0.9 class 0 = 0.512 +- 0.276 (in-sample avg dev_std = 0.627)
NEC for r=0.9 class 1 = 0.565 +- 0.276 (in-sample avg dev_std = 0.627)
NEC for r=0.9 class 2 = 0.562 +- 0.276 (in-sample avg dev_std = 0.627)
NEC for r=0.9 all KL = 0.669 +- 0.276 (in-sample avg dev_std = 0.627)
NEC for r=0.9 all L1 = 0.547 +- 0.161 (in-sample avg dev_std = 0.627)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7097649999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.545
NEC for r=1.0 class 0 = 0.501 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 1 = 0.551 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 class 2 = 0.535 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all KL = 0.643 +- 0.283 (in-sample avg dev_std = 0.619)
NEC for r=1.0 all L1 = 0.529 +- 0.169 (in-sample avg dev_std = 0.619)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:42:57 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:42:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 188...
[0m[1;37mINFO[0m: [1mCheckpoint 188: 
-----------------------------------
Train ACCURACY: 0.9162
Train Loss: 0.4093
ID Validation ACCURACY: 0.9230
ID Validation Loss: 0.3818
ID Test ACCURACY: 0.9110
ID Test Loss: 0.4274
OOD Validation ACCURACY: 0.9130
OOD Validation Loss: 0.4851
OOD Test ACCURACY: 0.8380
OOD Test Loss: 0.4985

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ACCURACY: 0.8970
Train Loss: 0.4289
ID Validation ACCURACY: 0.9023
ID Validation Loss: 0.4071
ID Test ACCURACY: 0.8917
ID Test Loss: 0.4442
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4515
OOD Test ACCURACY: 0.8837
OOD Test Loss: 0.4862

[0m[1;37mINFO[0m: [1mChartInfo 0.9110 0.8380 0.8917 0.8837 0.9023 0.9293[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.704
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.749
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.754
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.754


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.652
Model XAI F1 of binarized graphs for r=0.3 =  0.7264400000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7041775
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.519
SUFF++ for r=0.3 class 0 = 0.449 +- 0.296 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 class 1 = 0.627 +- 0.296 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 class 2 = 0.522 +- 0.296 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 all KL = 0.419 +- 0.296 (in-sample avg dev_std = 0.596)
SUFF++ for r=0.3 all L1 = 0.532 +- 0.201 (in-sample avg dev_std = 0.596)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.896
Model XAI F1 of binarized graphs for r=0.6 =  0.61115875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7494737499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.758
SUFF++ for r=0.6 class 0 = 0.594 +- 0.263 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 1 = 0.73 +- 0.263 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 2 = 0.688 +- 0.263 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all KL = 0.626 +- 0.263 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all L1 = 0.671 +- 0.195 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47308625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7536912499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.88
SUFF++ for r=0.9 class 0 = 0.812 +- 0.169 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 1 = 0.812 +- 0.169 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 class 2 = 0.864 +- 0.169 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all KL = 0.883 +- 0.169 (in-sample avg dev_std = 0.236)
SUFF++ for r=0.9 all L1 = 0.83 +- 0.167 (in-sample avg dev_std = 0.236)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.651
Model XAI F1 of binarized graphs for r=0.3 =  0.7264400000000001
Model XAI WIoU of binarized graphs for r=0.3 =  0.7041775
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.339
NEC for r=0.3 class 0 = 0.662 +- 0.269 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 1 = 0.529 +- 0.269 (in-sample avg dev_std = 0.468)
NEC for r=0.3 class 2 = 0.6 +- 0.269 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all KL = 0.711 +- 0.269 (in-sample avg dev_std = 0.468)
NEC for r=0.3 all L1 = 0.597 +- 0.191 (in-sample avg dev_std = 0.468)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.9
Model XAI F1 of binarized graphs for r=0.6 =  0.61115875
Model XAI WIoU of binarized graphs for r=0.6 =  0.7494737499999999
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.443
NEC for r=0.6 class 0 = 0.614 +- 0.291 (in-sample avg dev_std = 0.519)
NEC for r=0.6 class 1 = 0.566 +- 0.291 (in-sample avg dev_std = 0.519)
NEC for r=0.6 class 2 = 0.605 +- 0.291 (in-sample avg dev_std = 0.519)
NEC for r=0.6 all KL = 0.679 +- 0.291 (in-sample avg dev_std = 0.519)
NEC for r=0.6 all L1 = 0.595 +- 0.164 (in-sample avg dev_std = 0.519)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.925
Model XAI F1 of binarized graphs for r=0.9 =  0.47308625
Model XAI WIoU of binarized graphs for r=0.9 =  0.7536912499999999
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.536
NEC for r=0.9 class 0 = 0.534 +- 0.287 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 1 = 0.507 +- 0.287 (in-sample avg dev_std = 0.571)
NEC for r=0.9 class 2 = 0.538 +- 0.287 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all KL = 0.575 +- 0.287 (in-sample avg dev_std = 0.571)
NEC for r=0.9 all L1 = 0.526 +- 0.161 (in-sample avg dev_std = 0.571)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.925
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7536912499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.521 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 1 = 0.505 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 2 = 0.525 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all KL = 0.562 +- 0.293 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all L1 = 0.517 +- 0.164 (in-sample avg dev_std = 0.571)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:44:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:44:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.9011
Train Loss: 0.4339
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.4039
ID Test ACCURACY: 0.9043
ID Test Loss: 0.4420
OOD Validation ACCURACY: 0.9230
OOD Validation Loss: 0.4746
OOD Test ACCURACY: 0.8267
OOD Test Loss: 0.4981

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.8969
Train Loss: 0.4316
ID Validation ACCURACY: 0.9050
ID Validation Loss: 0.4049
ID Test ACCURACY: 0.8977
ID Test Loss: 0.4367
OOD Validation ACCURACY: 0.9297
OOD Validation Loss: 0.4768
OOD Test ACCURACY: 0.8177
OOD Test Loss: 0.5880

[0m[1;37mINFO[0m: [1mChartInfo 0.9043 0.8267 0.8977 0.8177 0.9050 0.9297[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.726
WIoU for r=0.3 = 0.686
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.718
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.717
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.717


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.702
Model XAI F1 of binarized graphs for r=0.3 =  0.72575
Model XAI WIoU of binarized graphs for r=0.3 =  0.6864087499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0 = 0.359 +- 0.296 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 1 = 0.607 +- 0.296 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 class 2 = 0.52 +- 0.296 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all KL = 0.39 +- 0.296 (in-sample avg dev_std = 0.608)
SUFF++ for r=0.3 all L1 = 0.496 +- 0.198 (in-sample avg dev_std = 0.608)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.61088875
Model XAI WIoU of binarized graphs for r=0.6 =  0.717885
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.716
SUFF++ for r=0.6 class 0 = 0.513 +- 0.275 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 1 = 0.701 +- 0.275 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 2 = 0.702 +- 0.275 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all KL = 0.603 +- 0.275 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all L1 = 0.64 +- 0.216 (in-sample avg dev_std = 0.476)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.47288875
Model XAI WIoU of binarized graphs for r=0.9 =  0.71724125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.847
SUFF++ for r=0.9 class 0 = 0.797 +- 0.178 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 1 = 0.779 +- 0.178 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 class 2 = 0.862 +- 0.178 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all KL = 0.866 +- 0.178 (in-sample avg dev_std = 0.256)
SUFF++ for r=0.9 all L1 = 0.814 +- 0.174 (in-sample avg dev_std = 0.256)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.702
Model XAI F1 of binarized graphs for r=0.3 =  0.72575
Model XAI WIoU of binarized graphs for r=0.3 =  0.6864087499999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.382
NEC for r=0.3 class 0 = 0.681 +- 0.284 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 1 = 0.48 +- 0.284 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 2 = 0.55 +- 0.284 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all KL = 0.667 +- 0.284 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all L1 = 0.57 +- 0.206 (in-sample avg dev_std = 0.493)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.882
Model XAI F1 of binarized graphs for r=0.6 =  0.61088875
Model XAI WIoU of binarized graphs for r=0.6 =  0.717885
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.475
NEC for r=0.6 class 0 = 0.634 +- 0.292 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 1 = 0.527 +- 0.292 (in-sample avg dev_std = 0.539)
NEC for r=0.6 class 2 = 0.582 +- 0.292 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all KL = 0.659 +- 0.292 (in-sample avg dev_std = 0.539)
NEC for r=0.6 all L1 = 0.581 +- 0.169 (in-sample avg dev_std = 0.539)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.91
Model XAI F1 of binarized graphs for r=0.9 =  0.47288875
Model XAI WIoU of binarized graphs for r=0.9 =  0.71724125
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.537
NEC for r=0.9 class 0 = 0.555 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 1 = 0.496 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 class 2 = 0.53 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all KL = 0.573 +- 0.291 (in-sample avg dev_std = 0.575)
NEC for r=0.9 all L1 = 0.527 +- 0.163 (in-sample avg dev_std = 0.575)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.71724125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0 = 0.54 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 1 = 0.498 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 class 2 = 0.507 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all KL = 0.552 +- 0.294 (in-sample avg dev_std = 0.571)
NEC for r=1.0 all L1 = 0.515 +- 0.167 (in-sample avg dev_std = 0.571)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:45:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:45:44 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 134...
[0m[1;37mINFO[0m: [1mCheckpoint 134: 
-----------------------------------
Train ACCURACY: 0.8988
Train Loss: 0.4539
ID Validation ACCURACY: 0.9030
ID Validation Loss: 0.4374
ID Test ACCURACY: 0.8997
ID Test Loss: 0.4667
OOD Validation ACCURACY: 0.9270
OOD Validation Loss: 0.4777
OOD Test ACCURACY: 0.8460
OOD Test Loss: 0.5987

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.8639
Train Loss: 0.4728
ID Validation ACCURACY: 0.8680
ID Validation Loss: 0.4616
ID Test ACCURACY: 0.8647
ID Test Loss: 0.4806
OOD Validation ACCURACY: 0.9313
OOD Validation Loss: 0.4486
OOD Test ACCURACY: 0.7277
OOD Test Loss: 0.7415

[0m[1;37mINFO[0m: [1mChartInfo 0.8997 0.8460 0.8647 0.7277 0.8680 0.9313[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.730
WIoU for r=0.3 = 0.717
F1 for r=0.6 = 0.615
WIoU for r=0.6 = 0.789
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.792
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.792


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.7299325
Model XAI WIoU of binarized graphs for r=0.3 =  0.7167174999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.469
SUFF++ for r=0.3 class 0 = 0.436 +- 0.283 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 class 1 = 0.652 +- 0.283 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 class 2 = 0.479 +- 0.283 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all KL = 0.415 +- 0.283 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all L1 = 0.521 +- 0.183 (in-sample avg dev_std = 0.604)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.615425
Model XAI WIoU of binarized graphs for r=0.6 =  0.7886650000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.698
SUFF++ for r=0.6 class 0 = 0.567 +- 0.283 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 1 = 0.673 +- 0.283 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 class 2 = 0.598 +- 0.283 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all KL = 0.562 +- 0.283 (in-sample avg dev_std = 0.516)
SUFF++ for r=0.6 all L1 = 0.612 +- 0.189 (in-sample avg dev_std = 0.516)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4729375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7921012500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.828
SUFF++ for r=0.9 class 0 = 0.778 +- 0.212 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 class 1 = 0.776 +- 0.212 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 class 2 = 0.758 +- 0.212 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all KL = 0.818 +- 0.212 (in-sample avg dev_std = 0.302)
SUFF++ for r=0.9 all L1 = 0.77 +- 0.181 (in-sample avg dev_std = 0.302)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.655
Model XAI F1 of binarized graphs for r=0.3 =  0.7299325
Model XAI WIoU of binarized graphs for r=0.3 =  0.7167174999999999
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.363
NEC for r=0.3 class 0 = 0.668 +- 0.295 (in-sample avg dev_std = 0.475)
NEC for r=0.3 class 1 = 0.483 +- 0.295 (in-sample avg dev_std = 0.475)
NEC for r=0.3 class 2 = 0.635 +- 0.295 (in-sample avg dev_std = 0.475)
NEC for r=0.3 all KL = 0.692 +- 0.295 (in-sample avg dev_std = 0.475)
NEC for r=0.3 all L1 = 0.596 +- 0.203 (in-sample avg dev_std = 0.475)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.89
Model XAI F1 of binarized graphs for r=0.6 =  0.615425
Model XAI WIoU of binarized graphs for r=0.6 =  0.7886650000000001
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.467
NEC for r=0.6 class 0 = 0.611 +- 0.284 (in-sample avg dev_std = 0.503)
NEC for r=0.6 class 1 = 0.552 +- 0.284 (in-sample avg dev_std = 0.503)
NEC for r=0.6 class 2 = 0.625 +- 0.284 (in-sample avg dev_std = 0.503)
NEC for r=0.6 all KL = 0.658 +- 0.284 (in-sample avg dev_std = 0.503)
NEC for r=0.6 all L1 = 0.596 +- 0.155 (in-sample avg dev_std = 0.503)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.913
Model XAI F1 of binarized graphs for r=0.9 =  0.4729375
Model XAI WIoU of binarized graphs for r=0.9 =  0.7921012500000001
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.509
NEC for r=0.9 class 0 = 0.53 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 1 = 0.524 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.9 class 2 = 0.569 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all KL = 0.56 +- 0.288 (in-sample avg dev_std = 0.516)
NEC for r=0.9 all L1 = 0.541 +- 0.155 (in-sample avg dev_std = 0.516)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.913
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7921012500000001
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.525
NEC for r=1.0 class 0 = 0.515 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 1 = 0.508 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 class 2 = 0.557 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all KL = 0.538 +- 0.288 (in-sample avg dev_std = 0.512)
NEC for r=1.0 all L1 = 0.527 +- 0.153 (in-sample avg dev_std = 0.512)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:47:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:47:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 150...
[0m[1;37mINFO[0m: [1mCheckpoint 150: 
-----------------------------------
Train ACCURACY: 0.9096
Train Loss: 0.4091
ID Validation ACCURACY: 0.9127
ID Validation Loss: 0.3875
ID Test ACCURACY: 0.9030
ID Test Loss: 0.4331
OOD Validation ACCURACY: 0.9240
OOD Validation Loss: 0.4585
OOD Test ACCURACY: 0.8997
OOD Test Loss: 0.4258

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.8893
Train Loss: 0.4702
ID Validation ACCURACY: 0.8970
ID Validation Loss: 0.4634
ID Test ACCURACY: 0.8937
ID Test Loss: 0.4939
OOD Validation ACCURACY: 0.9293
OOD Validation Loss: 0.4938
OOD Test ACCURACY: 0.8903
OOD Test Loss: 0.4810

[0m[1;37mINFO[0m: [1mChartInfo 0.9030 0.8997 0.8937 0.8903 0.8970 0.9293[0mGOODMotif2(3000)
Data example from id_test: Data(edge_index=[2, 56], x=[16, 1], node_gt=[16], edge_gt=[56], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=16)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([ 988,  973, 1039]))

Gold ratio (id_test) =  tensor(0.3032) +- tensor(0.1592)
F1 for r=0.3 = 0.700
WIoU for r=0.3 = 0.675
F1 for r=0.6 = 0.611
WIoU for r=0.6 = 0.772
F1 for r=0.9 = 0.473
WIoU for r=0.9 = 0.769
F1 for r=1.0 = 0.444
WIoU for r=1.0 = 0.769


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.521
Model XAI F1 of binarized graphs for r=0.3 =  0.699675
Model XAI WIoU of binarized graphs for r=0.3 =  0.6746000000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.432
SUFF++ for r=0.3 class 0 = 0.432 +- 0.265 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 1 = 0.525 +- 0.265 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 class 2 = 0.537 +- 0.265 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all KL = 0.428 +- 0.265 (in-sample avg dev_std = 0.584)
SUFF++ for r=0.3 all L1 = 0.499 +- 0.175 (in-sample avg dev_std = 0.584)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.61147625
Model XAI WIoU of binarized graphs for r=0.6 =  0.77174875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.67
SUFF++ for r=0.6 class 0 = 0.499 +- 0.277 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.6 class 1 = 0.622 +- 0.277 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.6 class 2 = 0.674 +- 0.277 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.6 all KL = 0.554 +- 0.277 (in-sample avg dev_std = 0.539)
SUFF++ for r=0.6 all L1 = 0.6 +- 0.190 (in-sample avg dev_std = 0.539)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.47286374999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.7689675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.845
SUFF++ for r=0.9 class 0 = 0.748 +- 0.182 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 1 = 0.805 +- 0.182 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 class 2 = 0.831 +- 0.182 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all KL = 0.843 +- 0.182 (in-sample avg dev_std = 0.277)
SUFF++ for r=0.9 all L1 = 0.795 +- 0.168 (in-sample avg dev_std = 0.277)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.533
Model XAI F1 of binarized graphs for r=0.3 =  0.699675
Model XAI WIoU of binarized graphs for r=0.3 =  0.6746000000000001
len(reference) = 800
Effective ratio: 0.312 +- 0.010
Model Accuracy over intervened graphs for r=0.3 =  0.354
NEC for r=0.3 class 0 = 0.615 +- 0.261 (in-sample avg dev_std = 0.520)
NEC for r=0.3 class 1 = 0.569 +- 0.261 (in-sample avg dev_std = 0.520)
NEC for r=0.3 class 2 = 0.577 +- 0.261 (in-sample avg dev_std = 0.520)
NEC for r=0.3 all KL = 0.673 +- 0.261 (in-sample avg dev_std = 0.520)
NEC for r=0.3 all L1 = 0.587 +- 0.158 (in-sample avg dev_std = 0.520)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.87
Model XAI F1 of binarized graphs for r=0.6 =  0.61147625
Model XAI WIoU of binarized graphs for r=0.6 =  0.77174875
len(reference) = 800
Effective ratio: 0.611 +- 0.007
Model Accuracy over intervened graphs for r=0.6 =  0.453
NEC for r=0.6 class 0 = 0.609 +- 0.286 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 1 = 0.583 +- 0.286 (in-sample avg dev_std = 0.531)
NEC for r=0.6 class 2 = 0.565 +- 0.286 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all KL = 0.648 +- 0.286 (in-sample avg dev_std = 0.531)
NEC for r=0.6 all L1 = 0.585 +- 0.163 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  0.47286374999999997
Model XAI WIoU of binarized graphs for r=0.9 =  0.7689675
len(reference) = 800
Effective ratio: 0.914 +- 0.011
Model Accuracy over intervened graphs for r=0.9 =  0.533
NEC for r=0.9 class 0 = 0.549 +- 0.282 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 1 = 0.494 +- 0.282 (in-sample avg dev_std = 0.557)
NEC for r=0.9 class 2 = 0.533 +- 0.282 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all KL = 0.555 +- 0.282 (in-sample avg dev_std = 0.557)
NEC for r=0.9 all L1 = 0.526 +- 0.163 (in-sample avg dev_std = 0.557)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.909
Model XAI F1 of binarized graphs for r=1.0 =  0.44384
Model XAI WIoU of binarized graphs for r=1.0 =  0.7689675
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.549
NEC for r=1.0 class 0 = 0.522 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 1 = 0.489 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 class 2 = 0.521 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all KL = 0.527 +- 0.284 (in-sample avg dev_std = 0.549)
NEC for r=1.0 all L1 = 0.511 +- 0.163 (in-sample avg dev_std = 0.549)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.337, 0.501, 0.801, 1.0], 'all_L1': [0.521, 0.624, 0.796, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.419, 0.626, 0.883, 1.0], 'all_L1': [0.532, 0.671, 0.83, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.39, 0.603, 0.866, 1.0], 'all_L1': [0.496, 0.64, 0.814, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.415, 0.562, 0.818, 1.0], 'all_L1': [0.521, 0.612, 0.77, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.428, 0.554, 0.843, 1.0], 'all_L1': [0.499, 0.6, 0.795, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.79, 0.747, 0.669, 0.643], 'all_L1': [0.601, 0.607, 0.547, 0.529]}), defaultdict(<class 'list'>, {'all_KL': [0.711, 0.679, 0.575, 0.562], 'all_L1': [0.597, 0.595, 0.526, 0.517]}), defaultdict(<class 'list'>, {'all_KL': [0.667, 0.659, 0.573, 0.552], 'all_L1': [0.57, 0.581, 0.527, 0.515]}), defaultdict(<class 'list'>, {'all_KL': [0.692, 0.658, 0.56, 0.538], 'all_L1': [0.596, 0.596, 0.541, 0.527]}), defaultdict(<class 'list'>, {'all_KL': [0.673, 0.648, 0.555, 0.527], 'all_L1': [0.587, 0.585, 0.526, 0.511]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.514 +- 0.014, 0.629 +- 0.025, 0.801 +- 0.020, 1.000 +- 0.000
suff++ class all_KL  =  0.398 +- 0.033, 0.569 +- 0.043, 0.842 +- 0.030, 1.000 +- 0.000
suff++_acc_int  =  0.484 +- 0.031, 0.713 +- 0.029, 0.846 +- 0.018
nec class all_L1  =  0.590 +- 0.011, 0.593 +- 0.009, 0.533 +- 0.009, 0.520 +- 0.007
nec class all_KL  =  0.707 +- 0.044, 0.678 +- 0.036, 0.586 +- 0.042, 0.564 +- 0.041
nec_acc_int  =  0.358 +- 0.015, 0.457 +- 0.012, 0.526 +- 0.012, 0.544 +- 0.010


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.552 +- 0.012, 0.611 +- 0.013, 0.667 +- 0.008, 0.760 +- 0.003
Faith. Armon (L1)= 		  =  0.549 +- 0.012, 0.610 +- 0.013, 0.640 +- 0.006, 0.684 +- 0.006
Faith. GMean (L1)= 	  =  0.551 +- 0.012, 0.611 +- 0.013, 0.654 +- 0.006, 0.721 +- 0.005
Faith. Aritm (KL)= 		  =  0.552 +- 0.013, 0.624 +- 0.018, 0.714 +- 0.018, 0.782 +- 0.021
Faith. Armon (KL)= 		  =  0.507 +- 0.021, 0.617 +- 0.021, 0.690 +- 0.023, 0.721 +- 0.033
Faith. GMean (KL)= 	  =  0.529 +- 0.014, 0.620 +- 0.019, 0.702 +- 0.020, 0.751 +- 0.027
Computed for split load_split = id



Completed in  0:06:58.671726  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:48:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:48:35 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:48:49 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:48:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:48:53 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:48:57 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:49:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 193...
[0m[1;37mINFO[0m: [1mCheckpoint 193: 
-----------------------------------
Train ACCURACY: 0.8868
Train Loss: 0.4263
ID Validation ACCURACY: 0.8903
ID Validation Loss: 0.4063
ID Test ACCURACY: 0.8870
ID Test Loss: 0.4328
OOD Validation ACCURACY: 0.7457
OOD Validation Loss: 5.4460
OOD Test ACCURACY: 0.5017
OOD Test Loss: 29.7885

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ACCURACY: 0.8296
Train Loss: 0.5063
ID Validation ACCURACY: 0.8310
ID Validation Loss: 0.4794
ID Test ACCURACY: 0.8297
ID Test Loss: 0.5080
OOD Validation ACCURACY: 0.8050
OOD Validation Loss: 2.5637
OOD Test ACCURACY: 0.6360
OOD Test Loss: 14.4751

[0m[1;37mINFO[0m: [1mChartInfo 0.8870 0.5017 0.8297 0.6360 0.8310 0.8050[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.597
WIoU for r=0.3 = 0.473
F1 for r=0.6 = 0.636
WIoU for r=0.6 = 0.575
F1 for r=0.9 = 0.539
WIoU for r=0.9 = 0.564
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.560


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.437
Model XAI F1 of binarized graphs for r=0.3 =  0.59663625
Model XAI WIoU of binarized graphs for r=0.3 =  0.47281875
len(reference) = 776
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.382
SUFF++ for r=0.3 class 0 = 0.651 +- 0.186 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 class 1 = 0.681 +- 0.186 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 class 2 = 0.634 +- 0.186 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all KL = 0.795 +- 0.186 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all L1 = 0.656 +- 0.133 (in-sample avg dev_std = 0.319)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.685
Model XAI F1 of binarized graphs for r=0.6 =  0.63589
Model XAI WIoU of binarized graphs for r=0.6 =  0.57537875
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0 = 0.555 +- 0.290 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 1 = 0.764 +- 0.290 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 class 2 = 0.653 +- 0.290 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all KL = 0.665 +- 0.290 (in-sample avg dev_std = 0.494)
SUFF++ for r=0.6 all L1 = 0.658 +- 0.239 (in-sample avg dev_std = 0.494)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.848
Model XAI F1 of binarized graphs for r=0.9 =  0.5387837499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.56425875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.816
SUFF++ for r=0.9 class 0 = 0.77 +- 0.245 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 1 = 0.861 +- 0.245 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 2 = 0.881 +- 0.245 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all KL = 0.859 +- 0.245 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all L1 = 0.837 +- 0.228 (in-sample avg dev_std = 0.269)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.434
Model XAI F1 of binarized graphs for r=0.3 =  0.59663625
Model XAI WIoU of binarized graphs for r=0.3 =  0.47281875
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.313
NEC for r=0.3 class 0 = 0.39 +- 0.236 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 1 = 0.363 +- 0.236 (in-sample avg dev_std = 0.269)
NEC for r=0.3 class 2 = 0.395 +- 0.236 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all KL = 0.241 +- 0.236 (in-sample avg dev_std = 0.269)
NEC for r=0.3 all L1 = 0.383 +- 0.173 (in-sample avg dev_std = 0.269)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.685
Model XAI F1 of binarized graphs for r=0.6 =  0.63589
Model XAI WIoU of binarized graphs for r=0.6 =  0.57537875
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.439
NEC for r=0.6 class 0 = 0.568 +- 0.295 (in-sample avg dev_std = 0.530)
NEC for r=0.6 class 1 = 0.402 +- 0.295 (in-sample avg dev_std = 0.530)
NEC for r=0.6 class 2 = 0.625 +- 0.295 (in-sample avg dev_std = 0.530)
NEC for r=0.6 all KL = 0.55 +- 0.295 (in-sample avg dev_std = 0.530)
NEC for r=0.6 all L1 = 0.531 +- 0.212 (in-sample avg dev_std = 0.530)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.848
Model XAI F1 of binarized graphs for r=0.9 =  0.5387837499999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.56425875
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.513
NEC for r=0.9 class 0 = 0.613 +- 0.274 (in-sample avg dev_std = 0.580)
NEC for r=0.9 class 1 = 0.418 +- 0.274 (in-sample avg dev_std = 0.580)
NEC for r=0.9 class 2 = 0.606 +- 0.274 (in-sample avg dev_std = 0.580)
NEC for r=0.9 all KL = 0.592 +- 0.274 (in-sample avg dev_std = 0.580)
NEC for r=0.9 all L1 = 0.545 +- 0.200 (in-sample avg dev_std = 0.580)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.55998875
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.543
NEC for r=1.0 class 0 = 0.588 +- 0.276 (in-sample avg dev_std = 0.601)
NEC for r=1.0 class 1 = 0.405 +- 0.276 (in-sample avg dev_std = 0.601)
NEC for r=1.0 class 2 = 0.584 +- 0.276 (in-sample avg dev_std = 0.601)
NEC for r=1.0 all KL = 0.573 +- 0.276 (in-sample avg dev_std = 0.601)
NEC for r=1.0 all L1 = 0.525 +- 0.200 (in-sample avg dev_std = 0.601)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:50:20 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:20 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:33 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:34 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:36 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:50:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 138...
[0m[1;37mINFO[0m: [1mCheckpoint 138: 
-----------------------------------
Train ACCURACY: 0.8933
Train Loss: 0.3734
ID Validation ACCURACY: 0.8993
ID Validation Loss: 0.3605
ID Test ACCURACY: 0.8947
ID Test Loss: 0.3748
OOD Validation ACCURACY: 0.7443
OOD Validation Loss: 0.8304
OOD Test ACCURACY: 0.3473
OOD Test Loss: 19.0323

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 157...
[0m[1;37mINFO[0m: [1mCheckpoint 157: 
-----------------------------------
Train ACCURACY: 0.8452
Train Loss: 0.7879
ID Validation ACCURACY: 0.8510
ID Validation Loss: 0.7727
ID Test ACCURACY: 0.8510
ID Test Loss: 0.7561
OOD Validation ACCURACY: 0.8023
OOD Validation Loss: 4.4919
OOD Test ACCURACY: 0.4070
OOD Test Loss: 19.4874

[0m[1;37mINFO[0m: [1mChartInfo 0.8947 0.3473 0.8510 0.4070 0.8510 0.8023[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.611
WIoU for r=0.3 = 0.489
F1 for r=0.6 = 0.635
WIoU for r=0.6 = 0.573
F1 for r=0.9 = 0.538
WIoU for r=0.9 = 0.571
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.568


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.39
Model XAI F1 of binarized graphs for r=0.3 =  0.61135875
Model XAI WIoU of binarized graphs for r=0.3 =  0.48915875
len(reference) = 774
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.368
SUFF++ for r=0.3 class 0 = 0.649 +- 0.222 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 class 1 = 0.667 +- 0.222 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 class 2 = 0.619 +- 0.222 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all KL = 0.765 +- 0.222 (in-sample avg dev_std = 0.359)
SUFF++ for r=0.3 all L1 = 0.645 +- 0.153 (in-sample avg dev_std = 0.359)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.63466625
Model XAI WIoU of binarized graphs for r=0.6 =  0.5732937499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.603
SUFF++ for r=0.6 class 0 = 0.597 +- 0.279 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.777 +- 0.279 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.668 +- 0.279 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.689 +- 0.279 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.681 +- 0.229 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.84
Model XAI F1 of binarized graphs for r=0.9 =  0.5382275
Model XAI WIoU of binarized graphs for r=0.9 =  0.5709125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.809
SUFF++ for r=0.9 class 0 = 0.759 +- 0.244 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.864 +- 0.244 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.874 +- 0.244 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.857 +- 0.244 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.832 +- 0.232 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.391
Model XAI F1 of binarized graphs for r=0.3 =  0.61135875
Model XAI WIoU of binarized graphs for r=0.3 =  0.48915875
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.345
NEC for r=0.3 class 0 = 0.364 +- 0.259 (in-sample avg dev_std = 0.317)
NEC for r=0.3 class 1 = 0.375 +- 0.259 (in-sample avg dev_std = 0.317)
NEC for r=0.3 class 2 = 0.407 +- 0.259 (in-sample avg dev_std = 0.317)
NEC for r=0.3 all KL = 0.264 +- 0.259 (in-sample avg dev_std = 0.317)
NEC for r=0.3 all L1 = 0.382 +- 0.186 (in-sample avg dev_std = 0.317)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.664
Model XAI F1 of binarized graphs for r=0.6 =  0.63466625
Model XAI WIoU of binarized graphs for r=0.6 =  0.5732937499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.439
NEC for r=0.6 class 0 = 0.53 +- 0.282 (in-sample avg dev_std = 0.532)
NEC for r=0.6 class 1 = 0.405 +- 0.282 (in-sample avg dev_std = 0.532)
NEC for r=0.6 class 2 = 0.589 +- 0.282 (in-sample avg dev_std = 0.532)
NEC for r=0.6 all KL = 0.525 +- 0.282 (in-sample avg dev_std = 0.532)
NEC for r=0.6 all L1 = 0.507 +- 0.212 (in-sample avg dev_std = 0.532)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.841
Model XAI F1 of binarized graphs for r=0.9 =  0.5382275
Model XAI WIoU of binarized graphs for r=0.9 =  0.5709125
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.509
NEC for r=0.9 class 0 = 0.621 +- 0.240 (in-sample avg dev_std = 0.594)
NEC for r=0.9 class 1 = 0.42 +- 0.240 (in-sample avg dev_std = 0.594)
NEC for r=0.9 class 2 = 0.599 +- 0.240 (in-sample avg dev_std = 0.594)
NEC for r=0.9 all KL = 0.577 +- 0.240 (in-sample avg dev_std = 0.594)
NEC for r=0.9 all L1 = 0.546 +- 0.182 (in-sample avg dev_std = 0.594)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.899
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.5677774999999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.544
NEC for r=1.0 class 0 = 0.602 +- 0.246 (in-sample avg dev_std = 0.597)
NEC for r=1.0 class 1 = 0.408 +- 0.246 (in-sample avg dev_std = 0.597)
NEC for r=1.0 class 2 = 0.567 +- 0.246 (in-sample avg dev_std = 0.597)
NEC for r=1.0 all KL = 0.549 +- 0.246 (in-sample avg dev_std = 0.597)
NEC for r=1.0 all L1 = 0.525 +- 0.188 (in-sample avg dev_std = 0.597)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:52:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:17 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:30 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:32 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:34 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:38 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:52:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 52...
[0m[1;37mINFO[0m: [1mCheckpoint 52: 
-----------------------------------
Train ACCURACY: 0.8962
Train Loss: 0.3853
ID Validation ACCURACY: 0.9043
ID Validation Loss: 0.3623
ID Test ACCURACY: 0.8960
ID Test Loss: 0.3830
OOD Validation ACCURACY: 0.7817
OOD Validation Loss: 0.7805
OOD Test ACCURACY: 0.6063
OOD Test Loss: 2.6911

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ACCURACY: 0.8508
Train Loss: 0.4639
ID Validation ACCURACY: 0.8667
ID Validation Loss: 0.4374
ID Test ACCURACY: 0.8593
ID Test Loss: 0.4592
OOD Validation ACCURACY: 0.8360
OOD Validation Loss: 0.8923
OOD Test ACCURACY: 0.4013
OOD Test Loss: 4.3777

[0m[1;37mINFO[0m: [1mChartInfo 0.8960 0.6063 0.8593 0.4013 0.8667 0.8360[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.543
WIoU for r=0.3 = 0.469
F1 for r=0.6 = 0.580
WIoU for r=0.6 = 0.590
F1 for r=0.9 = 0.532
WIoU for r=0.9 = 0.609
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.610


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.447
Model XAI F1 of binarized graphs for r=0.3 =  0.54302125
Model XAI WIoU of binarized graphs for r=0.3 =  0.4692725
len(reference) = 760
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.389
SUFF++ for r=0.3 class 0 = 0.715 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 class 1 = 0.778 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 class 2 = 0.714 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 all KL = 0.859 +- 0.172 (in-sample avg dev_std = 0.297)
SUFF++ for r=0.3 all L1 = 0.735 +- 0.131 (in-sample avg dev_std = 0.297)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.567
Model XAI F1 of binarized graphs for r=0.6 =  0.57972
Model XAI WIoU of binarized graphs for r=0.6 =  0.58964375
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.552
SUFF++ for r=0.6 class 0 = 0.706 +- 0.232 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1 = 0.856 +- 0.232 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 2 = 0.746 +- 0.232 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.812 +- 0.232 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.769 +- 0.193 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  0.5317574999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.60921
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.8
SUFF++ for r=0.9 class 0 = 0.865 +- 0.146 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 1 = 0.921 +- 0.146 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 class 2 = 0.895 +- 0.146 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all KL = 0.928 +- 0.146 (in-sample avg dev_std = 0.245)
SUFF++ for r=0.9 all L1 = 0.894 +- 0.151 (in-sample avg dev_std = 0.245)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.438
Model XAI F1 of binarized graphs for r=0.3 =  0.54302125
Model XAI WIoU of binarized graphs for r=0.3 =  0.4692725
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.361
NEC for r=0.3 class 0 = 0.314 +- 0.232 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 1 = 0.31 +- 0.232 (in-sample avg dev_std = 0.231)
NEC for r=0.3 class 2 = 0.317 +- 0.232 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all KL = 0.185 +- 0.232 (in-sample avg dev_std = 0.231)
NEC for r=0.3 all L1 = 0.314 +- 0.192 (in-sample avg dev_std = 0.231)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.567
Model XAI F1 of binarized graphs for r=0.6 =  0.57972
Model XAI WIoU of binarized graphs for r=0.6 =  0.58964375
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.449
NEC for r=0.6 class 0 = 0.419 +- 0.293 (in-sample avg dev_std = 0.448)
NEC for r=0.6 class 1 = 0.34 +- 0.293 (in-sample avg dev_std = 0.448)
NEC for r=0.6 class 2 = 0.447 +- 0.293 (in-sample avg dev_std = 0.448)
NEC for r=0.6 all KL = 0.365 +- 0.293 (in-sample avg dev_std = 0.448)
NEC for r=0.6 all L1 = 0.401 +- 0.229 (in-sample avg dev_std = 0.448)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.805
Model XAI F1 of binarized graphs for r=0.9 =  0.5317574999999999
Model XAI WIoU of binarized graphs for r=0.9 =  0.60921
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.545
NEC for r=0.9 class 0 = 0.566 +- 0.278 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 1 = 0.379 +- 0.278 (in-sample avg dev_std = 0.554)
NEC for r=0.9 class 2 = 0.574 +- 0.278 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all KL = 0.511 +- 0.278 (in-sample avg dev_std = 0.554)
NEC for r=0.9 all L1 = 0.506 +- 0.202 (in-sample avg dev_std = 0.554)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.908
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.6097137499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.587
NEC for r=1.0 class 0 = 0.569 +- 0.284 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 1 = 0.366 +- 0.284 (in-sample avg dev_std = 0.555)
NEC for r=1.0 class 2 = 0.587 +- 0.284 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all KL = 0.512 +- 0.284 (in-sample avg dev_std = 0.555)
NEC for r=1.0 all L1 = 0.506 +- 0.202 (in-sample avg dev_std = 0.555)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:53:58 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:53:58 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:10 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:12 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:14 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:54:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 169...
[0m[1;37mINFO[0m: [1mCheckpoint 169: 
-----------------------------------
Train ACCURACY: 0.9292
Train Loss: 0.2964
ID Validation ACCURACY: 0.9363
ID Validation Loss: 0.2924
ID Test ACCURACY: 0.9300
ID Test Loss: 0.3058
OOD Validation ACCURACY: 0.9060
OOD Validation Loss: 0.3917
OOD Test ACCURACY: 0.6020
OOD Test Loss: 1.1717

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 132...
[0m[1;37mINFO[0m: [1mCheckpoint 132: 
-----------------------------------
Train ACCURACY: 0.9289
Train Loss: 0.3040
ID Validation ACCURACY: 0.9353
ID Validation Loss: 0.2952
ID Test ACCURACY: 0.9313
ID Test Loss: 0.3088
OOD Validation ACCURACY: 0.9193
OOD Validation Loss: 0.3703
OOD Test ACCURACY: 0.6457
OOD Test Loss: 1.2464

[0m[1;37mINFO[0m: [1mChartInfo 0.9300 0.6020 0.9313 0.6457 0.9353 0.9193[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.564
WIoU for r=0.3 = 0.490
F1 for r=0.6 = 0.582
WIoU for r=0.6 = 0.613
F1 for r=0.9 = 0.526
WIoU for r=0.9 = 0.632
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.634


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.481
Model XAI F1 of binarized graphs for r=0.3 =  0.56371375
Model XAI WIoU of binarized graphs for r=0.3 =  0.49011250000000006
len(reference) = 751
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.397
SUFF++ for r=0.3 class 0 = 0.636 +- 0.197 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 1 = 0.679 +- 0.197 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 2 = 0.668 +- 0.197 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all KL = 0.781 +- 0.197 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.136 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  0.5817875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.61326875
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.588
SUFF++ for r=0.6 class 0 = 0.687 +- 0.213 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 1 = 0.77 +- 0.213 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 2 = 0.704 +- 0.213 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all KL = 0.776 +- 0.213 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all L1 = 0.72 +- 0.191 (in-sample avg dev_std = 0.422)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.774
Model XAI F1 of binarized graphs for r=0.9 =  0.52642
Model XAI WIoU of binarized graphs for r=0.9 =  0.63239375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.778
SUFF++ for r=0.9 class 0 = 0.879 +- 0.158 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 1 = 0.907 +- 0.158 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 class 2 = 0.922 +- 0.158 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all KL = 0.921 +- 0.158 (in-sample avg dev_std = 0.274)
SUFF++ for r=0.9 all L1 = 0.902 +- 0.150 (in-sample avg dev_std = 0.274)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.475
Model XAI F1 of binarized graphs for r=0.3 =  0.56371375
Model XAI WIoU of binarized graphs for r=0.3 =  0.49011250000000006
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.391
NEC for r=0.3 class 0 = 0.374 +- 0.277 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 1 = 0.299 +- 0.277 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 2 = 0.355 +- 0.277 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all KL = 0.234 +- 0.277 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all L1 = 0.342 +- 0.212 (in-sample avg dev_std = 0.301)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.608
Model XAI F1 of binarized graphs for r=0.6 =  0.5817875000000001
Model XAI WIoU of binarized graphs for r=0.6 =  0.61326875
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.44
NEC for r=0.6 class 0 = 0.475 +- 0.288 (in-sample avg dev_std = 0.461)
NEC for r=0.6 class 1 = 0.359 +- 0.288 (in-sample avg dev_std = 0.461)
NEC for r=0.6 class 2 = 0.454 +- 0.288 (in-sample avg dev_std = 0.461)
NEC for r=0.6 all KL = 0.387 +- 0.288 (in-sample avg dev_std = 0.461)
NEC for r=0.6 all L1 = 0.429 +- 0.208 (in-sample avg dev_std = 0.461)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.774
Model XAI F1 of binarized graphs for r=0.9 =  0.52642
Model XAI WIoU of binarized graphs for r=0.9 =  0.63239375
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.532
NEC for r=0.9 class 0 = 0.537 +- 0.287 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 1 = 0.361 +- 0.287 (in-sample avg dev_std = 0.574)
NEC for r=0.9 class 2 = 0.562 +- 0.287 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all KL = 0.517 +- 0.287 (in-sample avg dev_std = 0.574)
NEC for r=0.9 all L1 = 0.486 +- 0.219 (in-sample avg dev_std = 0.574)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.939
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.63412375
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.59
NEC for r=1.0 class 0 = 0.593 +- 0.286 (in-sample avg dev_std = 0.623)
NEC for r=1.0 class 1 = 0.338 +- 0.286 (in-sample avg dev_std = 0.623)
NEC for r=1.0 class 2 = 0.584 +- 0.286 (in-sample avg dev_std = 0.623)
NEC for r=1.0 all KL = 0.577 +- 0.286 (in-sample avg dev_std = 0.623)
NEC for r=1.0 all L1 = 0.504 +- 0.220 (in-sample avg dev_std = 0.623)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:55:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:30 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:42 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:44 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:46 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:50 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mDataset: {'train': GOODMotif(18000), 'id_val': GOODMotif(3000), 'id_test': GOODMotif(3000), 'val': GOODMotif(3000), 'test': GOODMotif(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1m Data(edge_index=[2, 58], x=[17, 1], node_gt=[17], edge_gt=[58], y=[1], env_id=[1], ori_edge_index=[2, 58], node_perm=[17], num_nodes=17)
[0mData(edge_index=[2, 80], x=[22, 1], node_gt=[22], edge_gt=[80], y=[1], env_id=[1], ori_edge_index=[2, 80], node_perm=[22], num_nodes=22)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:55:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ACCURACY: 0.9277
Train Loss: 0.3045
ID Validation ACCURACY: 0.9360
ID Validation Loss: 0.2927
ID Test ACCURACY: 0.9303
ID Test Loss: 0.3051
OOD Validation ACCURACY: 0.9160
OOD Validation Loss: 0.3805
OOD Test ACCURACY: 0.6473
OOD Test Loss: 0.9928

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 88...
[0m[1;37mINFO[0m: [1mCheckpoint 88: 
-----------------------------------
Train ACCURACY: 0.9278
Train Loss: 0.3080
ID Validation ACCURACY: 0.9353
ID Validation Loss: 0.2959
ID Test ACCURACY: 0.9303
ID Test Loss: 0.3113
OOD Validation ACCURACY: 0.9190
OOD Validation Loss: 0.3687
OOD Test ACCURACY: 0.6710
OOD Test Loss: 0.9696

[0m[1;37mINFO[0m: [1mChartInfo 0.9303 0.6473 0.9303 0.6710 0.9353 0.9190[0mGOODMotif(3000)
Data example from id_test: Data(edge_index=[2, 42], x=[20, 1], node_gt=[20], edge_gt=[42], y=[1], env_id=[1], ori_edge_index=[2, 42], node_perm=[20], num_nodes=20)
Label distribution from id_test: (tensor([0, 1, 2]), tensor([1006, 1011,  983]))

Gold ratio (id_test) =  tensor(0.3660) +- tensor(0.1922)
F1 for r=0.3 = 0.562
WIoU for r=0.3 = 0.476
F1 for r=0.6 = 0.610
WIoU for r=0.6 = 0.622
F1 for r=0.9 = 0.531
WIoU for r=0.9 = 0.627
F1 for r=1.0 = 0.509
WIoU for r=1.0 = 0.627


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.416
Model XAI F1 of binarized graphs for r=0.3 =  0.56173625
Model XAI WIoU of binarized graphs for r=0.3 =  0.47649
len(reference) = 783
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.375
SUFF++ for r=0.3 class 0 = 0.643 +- 0.179 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 class 1 = 0.685 +- 0.179 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 class 2 = 0.655 +- 0.179 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all KL = 0.799 +- 0.179 (in-sample avg dev_std = 0.370)
SUFF++ for r=0.3 all L1 = 0.661 +- 0.144 (in-sample avg dev_std = 0.370)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.60958625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6223037499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.62
SUFF++ for r=0.6 class 0 = 0.723 +- 0.237 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 1 = 0.834 +- 0.237 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 2 = 0.741 +- 0.237 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all KL = 0.802 +- 0.237 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.206 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  0.5313375
Model XAI WIoU of binarized graphs for r=0.9 =  0.6265149999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.791
SUFF++ for r=0.9 class 0 = 0.841 +- 0.206 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 1 = 0.902 +- 0.206 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 class 2 = 0.902 +- 0.206 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all KL = 0.892 +- 0.206 (in-sample avg dev_std = 0.282)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.181 (in-sample avg dev_std = 0.282)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.414
Model XAI F1 of binarized graphs for r=0.3 =  0.56173625
Model XAI WIoU of binarized graphs for r=0.3 =  0.47649
len(reference) = 800
Effective ratio: 0.314 +- 0.012
Model Accuracy over intervened graphs for r=0.3 =  0.376
NEC for r=0.3 class 0 = 0.378 +- 0.229 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 1 = 0.372 +- 0.229 (in-sample avg dev_std = 0.288)
NEC for r=0.3 class 2 = 0.372 +- 0.229 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all KL = 0.231 +- 0.229 (in-sample avg dev_std = 0.288)
NEC for r=0.3 all L1 = 0.374 +- 0.185 (in-sample avg dev_std = 0.288)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.663
Model XAI F1 of binarized graphs for r=0.6 =  0.60958625
Model XAI WIoU of binarized graphs for r=0.6 =  0.6223037499999999
len(reference) = 800
Effective ratio: 0.614 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.442
NEC for r=0.6 class 0 = 0.514 +- 0.297 (in-sample avg dev_std = 0.463)
NEC for r=0.6 class 1 = 0.42 +- 0.297 (in-sample avg dev_std = 0.463)
NEC for r=0.6 class 2 = 0.504 +- 0.297 (in-sample avg dev_std = 0.463)
NEC for r=0.6 all KL = 0.46 +- 0.297 (in-sample avg dev_std = 0.463)
NEC for r=0.6 all L1 = 0.479 +- 0.221 (in-sample avg dev_std = 0.463)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.803
Model XAI F1 of binarized graphs for r=0.9 =  0.5313375
Model XAI WIoU of binarized graphs for r=0.9 =  0.6265149999999999
len(reference) = 800
Effective ratio: 0.914 +- 0.012
Model Accuracy over intervened graphs for r=0.9 =  0.537
NEC for r=0.9 class 0 = 0.571 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.9 class 1 = 0.408 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.9 class 2 = 0.579 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.9 all KL = 0.551 +- 0.268 (in-sample avg dev_std = 0.580)
NEC for r=0.9 all L1 = 0.519 +- 0.196 (in-sample avg dev_std = 0.580)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  0.5090349999999999
Model XAI WIoU of binarized graphs for r=1.0 =  0.62663625
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.587
NEC for r=1.0 class 0 = 0.579 +- 0.265 (in-sample avg dev_std = 0.624)
NEC for r=1.0 class 1 = 0.407 +- 0.265 (in-sample avg dev_std = 0.624)
NEC for r=1.0 class 2 = 0.583 +- 0.265 (in-sample avg dev_std = 0.624)
NEC for r=1.0 all KL = 0.586 +- 0.265 (in-sample avg dev_std = 0.624)
NEC for r=1.0 all L1 = 0.522 +- 0.196 (in-sample avg dev_std = 0.624)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.795, 0.665, 0.859, 1.0], 'all_L1': [0.656, 0.658, 0.837, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.765, 0.689, 0.857, 1.0], 'all_L1': [0.645, 0.681, 0.832, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.859, 0.812, 0.928, 1.0], 'all_L1': [0.735, 0.769, 0.894, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.781, 0.776, 0.921, 1.0], 'all_L1': [0.661, 0.72, 0.902, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.799, 0.802, 0.892, 1.0], 'all_L1': [0.661, 0.766, 0.882, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.241, 0.55, 0.592, 0.573], 'all_L1': [0.383, 0.531, 0.545, 0.525]}), defaultdict(<class 'list'>, {'all_KL': [0.264, 0.525, 0.577, 0.549], 'all_L1': [0.382, 0.507, 0.546, 0.525]}), defaultdict(<class 'list'>, {'all_KL': [0.185, 0.365, 0.511, 0.512], 'all_L1': [0.314, 0.401, 0.506, 0.506]}), defaultdict(<class 'list'>, {'all_KL': [0.234, 0.387, 0.517, 0.577], 'all_L1': [0.342, 0.429, 0.486, 0.504]}), defaultdict(<class 'list'>, {'all_KL': [0.231, 0.46, 0.551, 0.586], 'all_L1': [0.374, 0.479, 0.519, 0.522]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.672 +- 0.032, 0.719 +- 0.044, 0.869 +- 0.029, 1.000 +- 0.000
suff++ class all_KL  =  0.800 +- 0.032, 0.749 +- 0.060, 0.891 +- 0.030, 1.000 +- 0.000
suff++_acc_int  =  0.382 +- 0.010, 0.599 +- 0.028, 0.799 +- 0.014
nec class all_L1  =  0.359 +- 0.027, 0.469 +- 0.048, 0.520 +- 0.023, 0.516 +- 0.009
nec class all_KL  =  0.231 +- 0.026, 0.457 +- 0.073, 0.550 +- 0.032, 0.559 +- 0.027
nec_acc_int  =  0.357 +- 0.027, 0.442 +- 0.004, 0.527 +- 0.014, 0.570 +- 0.022


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.515 +- 0.008, 0.594 +- 0.016, 0.695 +- 0.005, 0.758 +- 0.005
Faith. Armon (L1)= 		  =  0.466 +- 0.018, 0.565 +- 0.027, 0.650 +- 0.011, 0.681 +- 0.008
Faith. GMean (L1)= 	  =  0.490 +- 0.010, 0.579 +- 0.020, 0.672 +- 0.005, 0.719 +- 0.007
Faith. Aritm (KL)= 		  =  0.515 +- 0.005, 0.603 +- 0.017, 0.720 +- 0.003, 0.780 +- 0.013
Faith. Armon (KL)= 		  =  0.357 +- 0.029, 0.561 +- 0.042, 0.679 +- 0.016, 0.717 +- 0.022
Faith. GMean (KL)= 	  =  0.429 +- 0.017, 0.581 +- 0.029, 0.699 +- 0.009, 0.748 +- 0.018
Computed for split load_split = id



Completed in  0:08:33.476836  for LECIvGIN GOODMotif/size



DONE LECI GOODMotif/size readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:57:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:21 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:22 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:57:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 67...
[0m[1;37mINFO[0m: [1mCheckpoint 67: 
-----------------------------------
Train ACCURACY: 0.9996
Train Loss: 0.0019
ID Validation ACCURACY: 0.6913
ID Validation Loss: 2.0131
ID Test ACCURACY: 0.6787
ID Test Loss: 2.1331
OOD Validation ACCURACY: 0.5972
OOD Validation Loss: 2.8178
OOD Test ACCURACY: 0.5566
OOD Test Loss: 3.9666

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 17...
[0m[1;37mINFO[0m: [1mCheckpoint 17: 
-----------------------------------
Train ACCURACY: 0.9004
Train Loss: 0.2795
ID Validation ACCURACY: 0.6625
ID Validation Loss: 0.9229
ID Test ACCURACY: 0.6931
ID Test Loss: 0.9534
OOD Validation ACCURACY: 0.6235
OOD Validation Loss: 1.2698
OOD Test ACCURACY: 0.5704
OOD Test Loss: 1.9723

[0m[1;37mINFO[0m: [1mChartInfo 0.6787 0.5566 0.6931 0.5704 0.6625 0.6235[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0 = 0.634 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 1 = 0.687 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 class 2 = 0.66 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all KL = 0.492 +- 0.300 (in-sample avg dev_std = 0.586)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.213 (in-sample avg dev_std = 0.586)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.631
SUFF++ for r=0.6 class 0 = 0.756 +- 0.292 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 1 = 0.806 +- 0.292 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 class 2 = 0.789 +- 0.292 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all KL = 0.713 +- 0.292 (in-sample avg dev_std = 0.415)
SUFF++ for r=0.6 all L1 = 0.789 +- 0.212 (in-sample avg dev_std = 0.415)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.678
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.664
SUFF++ for r=0.9 class 0 = 0.907 +- 0.140 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 1 = 0.898 +- 0.140 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 class 2 = 0.899 +- 0.140 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all KL = 0.926 +- 0.140 (in-sample avg dev_std = 0.206)
SUFF++ for r=0.9 all L1 = 0.901 +- 0.150 (in-sample avg dev_std = 0.206)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.617
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.636
NEC for r=0.3 class 0 = 0.22 +- 0.296 (in-sample avg dev_std = 0.341)
NEC for r=0.3 class 1 = 0.229 +- 0.296 (in-sample avg dev_std = 0.341)
NEC for r=0.3 class 2 = 0.215 +- 0.296 (in-sample avg dev_std = 0.341)
NEC for r=0.3 all KL = 0.239 +- 0.296 (in-sample avg dev_std = 0.341)
NEC for r=0.3 all L1 = 0.222 +- 0.244 (in-sample avg dev_std = 0.341)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.661
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.661
NEC for r=0.6 class 0 = 0.16 +- 0.244 (in-sample avg dev_std = 0.256)
NEC for r=0.6 class 1 = 0.143 +- 0.244 (in-sample avg dev_std = 0.256)
NEC for r=0.6 class 2 = 0.15 +- 0.244 (in-sample avg dev_std = 0.256)
NEC for r=0.6 all KL = 0.146 +- 0.244 (in-sample avg dev_std = 0.256)
NEC for r=0.6 all L1 = 0.149 +- 0.211 (in-sample avg dev_std = 0.256)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.677
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.671
NEC for r=0.9 class 0 = 0.112 +- 0.173 (in-sample avg dev_std = 0.198)
NEC for r=0.9 class 1 = 0.108 +- 0.173 (in-sample avg dev_std = 0.198)
NEC for r=0.9 class 2 = 0.111 +- 0.173 (in-sample avg dev_std = 0.198)
NEC for r=0.9 all KL = 0.086 +- 0.173 (in-sample avg dev_std = 0.198)
NEC for r=0.9 all L1 = 0.11 +- 0.177 (in-sample avg dev_std = 0.198)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.677
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.665
NEC for r=1.0 class 0 = 0.095 +- 0.155 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1 = 0.092 +- 0.155 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 2 = 0.099 +- 0.155 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.07 +- 0.155 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.095 +- 0.160 (in-sample avg dev_std = 0.191)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:58:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:24 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:26 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:26 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:27 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:29 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:58:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.9201
Train Loss: 0.2250
ID Validation ACCURACY: 0.6949
ID Validation Loss: 1.0071
ID Test ACCURACY: 0.6841
ID Test Loss: 1.0211
OOD Validation ACCURACY: 0.6297
OOD Validation Loss: 1.2650
OOD Test ACCURACY: 0.5916
OOD Test Loss: 1.6996

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 6...
[0m[1;37mINFO[0m: [1mCheckpoint 6: 
-----------------------------------
Train ACCURACY: 0.7459
Train Loss: 0.5974
ID Validation ACCURACY: 0.6805
ID Validation Loss: 0.7660
ID Test ACCURACY: 0.6895
ID Test Loss: 0.7495
OOD Validation ACCURACY: 0.6403
OOD Validation Loss: 0.8572
OOD Test ACCURACY: 0.6095
OOD Test Loss: 1.0455

[0m[1;37mINFO[0m: [1mChartInfo 0.6841 0.5916 0.6895 0.6095 0.6805 0.6403[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.564
SUFF++ for r=0.3 class 0 = 0.659 +- 0.137 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 class 1 = 0.693 +- 0.137 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 class 2 = 0.75 +- 0.137 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all KL = 0.817 +- 0.137 (in-sample avg dev_std = 0.346)
SUFF++ for r=0.3 all L1 = 0.701 +- 0.124 (in-sample avg dev_std = 0.346)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.622
SUFF++ for r=0.6 class 0 = 0.719 +- 0.141 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 class 1 = 0.756 +- 0.141 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 class 2 = 0.795 +- 0.141 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 all KL = 0.843 +- 0.141 (in-sample avg dev_std = 0.312)
SUFF++ for r=0.6 all L1 = 0.758 +- 0.141 (in-sample avg dev_std = 0.312)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0 = 0.87 +- 0.054 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 1 = 0.895 +- 0.054 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 class 2 = 0.903 +- 0.054 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all KL = 0.962 +- 0.054 (in-sample avg dev_std = 0.145)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.103 (in-sample avg dev_std = 0.145)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.613
NEC for r=0.3 class 0 = 0.246 +- 0.121 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 1 = 0.221 +- 0.121 (in-sample avg dev_std = 0.187)
NEC for r=0.3 class 2 = 0.206 +- 0.121 (in-sample avg dev_std = 0.187)
NEC for r=0.3 all KL = 0.098 +- 0.121 (in-sample avg dev_std = 0.187)
NEC for r=0.3 all L1 = 0.223 +- 0.138 (in-sample avg dev_std = 0.187)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.651
NEC for r=0.6 class 0 = 0.219 +- 0.110 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1 = 0.169 +- 0.110 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 2 = 0.155 +- 0.110 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.079 +- 0.110 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.177 +- 0.134 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.69
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0 = 0.134 +- 0.069 (in-sample avg dev_std = 0.130)
NEC for r=0.9 class 1 = 0.116 +- 0.069 (in-sample avg dev_std = 0.130)
NEC for r=0.9 class 2 = 0.116 +- 0.069 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all KL = 0.042 +- 0.069 (in-sample avg dev_std = 0.130)
NEC for r=0.9 all L1 = 0.12 +- 0.116 (in-sample avg dev_std = 0.130)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0 = 0.124 +- 0.067 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 1 = 0.095 +- 0.067 (in-sample avg dev_std = 0.123)
NEC for r=1.0 class 2 = 0.106 +- 0.067 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all KL = 0.036 +- 0.067 (in-sample avg dev_std = 0.123)
NEC for r=1.0 all L1 = 0.106 +- 0.110 (in-sample avg dev_std = 0.123)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 12:59:43 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:43 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:45 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:46 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:47 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:49 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 12:59:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 18...
[0m[1;37mINFO[0m: [1mCheckpoint 18: 
-----------------------------------
Train ACCURACY: 0.9139
Train Loss: 0.2503
ID Validation ACCURACY: 0.7076
ID Validation Loss: 0.8689
ID Test ACCURACY: 0.6895
ID Test Loss: 0.9759
OOD Validation ACCURACY: 0.6409
OOD Validation Loss: 1.2142
OOD Test ACCURACY: 0.5854
OOD Test Loss: 1.6093

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ACCURACY: 0.9382
Train Loss: 0.1587
ID Validation ACCURACY: 0.6968
ID Validation Loss: 1.0487
ID Test ACCURACY: 0.6661
ID Test Loss: 1.2152
OOD Validation ACCURACY: 0.6521
OOD Validation Loss: 1.4007
OOD Test ACCURACY: 0.5909
OOD Test Loss: 1.8758

[0m[1;37mINFO[0m: [1mChartInfo 0.6895 0.5854 0.6661 0.5909 0.6968 0.6521[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.567
SUFF++ for r=0.3 class 0 = 0.685 +- 0.145 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 1 = 0.709 +- 0.145 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 class 2 = 0.646 +- 0.145 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all KL = 0.796 +- 0.145 (in-sample avg dev_std = 0.364)
SUFF++ for r=0.3 all L1 = 0.684 +- 0.134 (in-sample avg dev_std = 0.364)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.62
SUFF++ for r=0.6 class 0 = 0.755 +- 0.151 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 1 = 0.779 +- 0.151 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 class 2 = 0.7 +- 0.151 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all KL = 0.833 +- 0.151 (in-sample avg dev_std = 0.320)
SUFF++ for r=0.6 all L1 = 0.75 +- 0.158 (in-sample avg dev_std = 0.320)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.68
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.67
SUFF++ for r=0.9 class 0 = 0.869 +- 0.077 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 1 = 0.885 +- 0.077 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 class 2 = 0.886 +- 0.077 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all KL = 0.954 +- 0.077 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.9 all L1 = 0.881 +- 0.116 (in-sample avg dev_std = 0.158)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.617
NEC for r=0.3 class 0 = 0.244 +- 0.124 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1 = 0.225 +- 0.124 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 2 = 0.251 +- 0.124 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.107 +- 0.124 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.238 +- 0.149 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.659
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.661
NEC for r=0.6 class 0 = 0.205 +- 0.121 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1 = 0.174 +- 0.121 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 2 = 0.184 +- 0.121 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.089 +- 0.121 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.185 +- 0.148 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.671
NEC for r=0.9 class 0 = 0.139 +- 0.067 (in-sample avg dev_std = 0.139)
NEC for r=0.9 class 1 = 0.112 +- 0.067 (in-sample avg dev_std = 0.139)
NEC for r=0.9 class 2 = 0.125 +- 0.067 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all KL = 0.043 +- 0.067 (in-sample avg dev_std = 0.139)
NEC for r=0.9 all L1 = 0.123 +- 0.115 (in-sample avg dev_std = 0.139)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.688
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.689
NEC for r=1.0 class 0 = 0.12 +- 0.073 (in-sample avg dev_std = 0.124)
NEC for r=1.0 class 1 = 0.1 +- 0.073 (in-sample avg dev_std = 0.124)
NEC for r=1.0 class 2 = 0.108 +- 0.073 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all KL = 0.037 +- 0.073 (in-sample avg dev_std = 0.124)
NEC for r=1.0 all L1 = 0.107 +- 0.116 (in-sample avg dev_std = 0.124)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:00:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:49 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:52 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:54 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:55 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:00:56 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ACCURACY: 0.9764
Train Loss: 0.0983
ID Validation ACCURACY: 0.7040
ID Validation Loss: 1.0781
ID Test ACCURACY: 0.6841
ID Test Loss: 1.1423
OOD Validation ACCURACY: 0.6151
OOD Validation Loss: 1.3992
OOD Test ACCURACY: 0.5724
OOD Test Loss: 1.9331

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ACCURACY: 0.7807
Train Loss: 0.5276
ID Validation ACCURACY: 0.6859
ID Validation Loss: 0.7585
ID Test ACCURACY: 0.6787
ID Test Loss: 0.7813
OOD Validation ACCURACY: 0.6415
OOD Validation Loss: 0.8864
OOD Test ACCURACY: 0.5964
OOD Test Loss: 1.0649

[0m[1;37mINFO[0m: [1mChartInfo 0.6841 0.5724 0.6787 0.5964 0.6859 0.6415[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0 = 0.711 +- 0.156 (in-sample avg dev_std = 0.358)
SUFF++ for r=0.3 class 1 = 0.717 +- 0.156 (in-sample avg dev_std = 0.358)
SUFF++ for r=0.3 class 2 = 0.694 +- 0.156 (in-sample avg dev_std = 0.358)
SUFF++ for r=0.3 all KL = 0.802 +- 0.156 (in-sample avg dev_std = 0.358)
SUFF++ for r=0.3 all L1 = 0.709 +- 0.132 (in-sample avg dev_std = 0.358)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.649
SUFF++ for r=0.6 class 0 = 0.758 +- 0.132 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 1 = 0.808 +- 0.132 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 class 2 = 0.778 +- 0.132 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all KL = 0.875 +- 0.132 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.6 all L1 = 0.787 +- 0.140 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.683
SUFF++ for r=0.9 class 0 = 0.876 +- 0.045 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1 = 0.9 +- 0.045 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 2 = 0.902 +- 0.045 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.962 +- 0.045 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.895 +- 0.094 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.626
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.629
NEC for r=0.3 class 0 = 0.253 +- 0.157 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1 = 0.231 +- 0.157 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 2 = 0.256 +- 0.157 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.126 +- 0.157 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.244 +- 0.161 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.666
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.671
NEC for r=0.6 class 0 = 0.187 +- 0.109 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 1 = 0.153 +- 0.109 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 2 = 0.172 +- 0.109 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all KL = 0.072 +- 0.109 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all L1 = 0.167 +- 0.141 (in-sample avg dev_std = 0.159)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.688
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.683
NEC for r=0.9 class 0 = 0.133 +- 0.064 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 1 = 0.105 +- 0.064 (in-sample avg dev_std = 0.120)
NEC for r=0.9 class 2 = 0.112 +- 0.064 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all KL = 0.04 +- 0.064 (in-sample avg dev_std = 0.120)
NEC for r=0.9 all L1 = 0.114 +- 0.114 (in-sample avg dev_std = 0.120)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.682
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.68
NEC for r=1.0 class 0 = 0.133 +- 0.076 (in-sample avg dev_std = 0.130)
NEC for r=1.0 class 1 = 0.095 +- 0.076 (in-sample avg dev_std = 0.130)
NEC for r=1.0 class 2 = 0.104 +- 0.076 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all KL = 0.043 +- 0.076 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all L1 = 0.107 +- 0.117 (in-sample avg dev_std = 0.130)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:01:59 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODTwitter
[0m[1;34mDEBUG[0m: 05/08/2024 01:01:59 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:01 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:04 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mDataset: {'train': GOODTwitter(2590), 'id_val': GOODTwitter(554), 'id_test': GOODTwitter(554), 'val': GOODTwitter(1785), 'test': GOODTwitter(1457), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1m Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
[0mData(x=[10, 768], edge_index=[2, 18], y=[1], idx=[1], sentence_tokens=[10], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 18], node_perm=[10])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.001
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:02:06 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ACCURACY: 0.9347
Train Loss: 0.2081
ID Validation ACCURACY: 0.6968
ID Validation Loss: 0.9057
ID Test ACCURACY: 0.6787
ID Test Loss: 1.0057
OOD Validation ACCURACY: 0.6308
OOD Validation Loss: 1.1621
OOD Test ACCURACY: 0.5683
OOD Test Loss: 1.6111

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ACCURACY: 0.8336
Train Loss: 0.4248
ID Validation ACCURACY: 0.6841
ID Validation Loss: 0.7984
ID Test ACCURACY: 0.6787
ID Test Loss: 0.8109
OOD Validation ACCURACY: 0.6459
OOD Validation Loss: 0.9402
OOD Test ACCURACY: 0.5978
OOD Test Loss: 1.1689

[0m[1;37mINFO[0m: [1mChartInfo 0.6787 0.5683 0.6787 0.5978 0.6841 0.6459[0mGOODTwitter(554)
Data example from id_test: Data(x=[7, 768], edge_index=[2, 12], y=[1], idx=[1], sentence_tokens=[7], length=[1], domain_id=[1], env_id=[1], ori_edge_index=[2, 12], node_perm=[7])
Label distribution from id_test: (tensor([0, 1, 2]), tensor([138, 251, 165]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.623
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0 = 0.72 +- 0.110 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 class 1 = 0.759 +- 0.110 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 class 2 = 0.685 +- 0.110 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 all KL = 0.858 +- 0.110 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 all L1 = 0.727 +- 0.108 (in-sample avg dev_std = 0.295)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.627
SUFF++ for r=0.6 class 0 = 0.746 +- 0.129 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 class 1 = 0.81 +- 0.129 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 class 2 = 0.752 +- 0.129 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 all KL = 0.877 +- 0.129 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.6 all L1 = 0.777 +- 0.129 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.662
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 544
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.668
SUFF++ for r=0.9 class 0 = 0.882 +- 0.041 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 1 = 0.907 +- 0.041 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 class 2 = 0.907 +- 0.041 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all KL = 0.971 +- 0.041 (in-sample avg dev_std = 0.125)
SUFF++ for r=0.9 all L1 = 0.901 +- 0.090 (in-sample avg dev_std = 0.125)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.623
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 551
Effective ratio: 0.315 +- 0.015
Model Accuracy over intervened graphs for r=0.3 =  0.611
NEC for r=0.3 class 0 = 0.247 +- 0.109 (in-sample avg dev_std = 0.162)
NEC for r=0.3 class 1 = 0.196 +- 0.109 (in-sample avg dev_std = 0.162)
NEC for r=0.3 class 2 = 0.257 +- 0.109 (in-sample avg dev_std = 0.162)
NEC for r=0.3 all KL = 0.088 +- 0.109 (in-sample avg dev_std = 0.162)
NEC for r=0.3 all L1 = 0.227 +- 0.134 (in-sample avg dev_std = 0.162)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.655
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 551
Effective ratio: 0.616 +- 0.016
Model Accuracy over intervened graphs for r=0.6 =  0.657
NEC for r=0.6 class 0 = 0.189 +- 0.111 (in-sample avg dev_std = 0.162)
NEC for r=0.6 class 1 = 0.149 +- 0.111 (in-sample avg dev_std = 0.162)
NEC for r=0.6 class 2 = 0.196 +- 0.111 (in-sample avg dev_std = 0.162)
NEC for r=0.6 all KL = 0.07 +- 0.111 (in-sample avg dev_std = 0.162)
NEC for r=0.6 all L1 = 0.172 +- 0.133 (in-sample avg dev_std = 0.162)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 551
Effective ratio: 0.916 +- 0.017
Model Accuracy over intervened graphs for r=0.9 =  0.672
NEC for r=0.9 class 0 = 0.137 +- 0.063 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 1 = 0.1 +- 0.063 (in-sample avg dev_std = 0.114)
NEC for r=0.9 class 2 = 0.129 +- 0.063 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all KL = 0.037 +- 0.063 (in-sample avg dev_std = 0.114)
NEC for r=0.9 all L1 = 0.118 +- 0.109 (in-sample avg dev_std = 0.114)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.677
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 551
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.675
NEC for r=1.0 class 0 = 0.126 +- 0.073 (in-sample avg dev_std = 0.119)
NEC for r=1.0 class 1 = 0.093 +- 0.073 (in-sample avg dev_std = 0.119)
NEC for r=1.0 class 2 = 0.111 +- 0.073 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all KL = 0.036 +- 0.073 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all L1 = 0.107 +- 0.113 (in-sample avg dev_std = 0.119)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.492, 0.713, 0.926, 1.0], 'all_L1': [0.666, 0.789, 0.901, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.817, 0.843, 0.962, 1.0], 'all_L1': [0.701, 0.758, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.796, 0.833, 0.954, 1.0], 'all_L1': [0.684, 0.75, 0.881, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.802, 0.875, 0.962, 1.0], 'all_L1': [0.709, 0.787, 0.895, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.858, 0.877, 0.971, 1.0], 'all_L1': [0.727, 0.777, 0.901, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.239, 0.146, 0.086, 0.07], 'all_L1': [0.222, 0.149, 0.11, 0.095]}), defaultdict(<class 'list'>, {'all_KL': [0.098, 0.079, 0.042, 0.036], 'all_L1': [0.223, 0.177, 0.12, 0.106]}), defaultdict(<class 'list'>, {'all_KL': [0.107, 0.089, 0.043, 0.037], 'all_L1': [0.238, 0.185, 0.123, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.126, 0.072, 0.04, 0.043], 'all_L1': [0.244, 0.167, 0.114, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.088, 0.07, 0.037, 0.036], 'all_L1': [0.227, 0.172, 0.118, 0.107]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.697 +- 0.021, 0.772 +- 0.016, 0.894 +- 0.007, 1.000 +- 0.000
suff++ class all_KL  =  0.753 +- 0.132, 0.828 +- 0.060, 0.955 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.575 +- 0.009, 0.630 +- 0.010, 0.674 +- 0.008
nec class all_L1  =  0.231 +- 0.009, 0.170 +- 0.012, 0.117 +- 0.005, 0.104 +- 0.005
nec class all_KL  =  0.132 +- 0.055, 0.091 +- 0.028, 0.050 +- 0.018, 0.044 +- 0.013
nec_acc_int  =  0.621 +- 0.010, 0.660 +- 0.007, 0.677 +- 0.007, 0.680 +- 0.009


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.464 +- 0.012, 0.471 +- 0.004, 0.505 +- 0.002, 0.552 +- 0.002
Faith. Armon (L1)= 		  =  0.347 +- 0.011, 0.278 +- 0.015, 0.207 +- 0.007, 0.189 +- 0.008
Faith. GMean (L1)= 	  =  0.401 +- 0.011, 0.362 +- 0.010, 0.323 +- 0.005, 0.323 +- 0.007
Faith. Aritm (KL)= 		  =  0.442 +- 0.039, 0.460 +- 0.016, 0.502 +- 0.003, 0.522 +- 0.007
Faith. Armon (KL)= 		  =  0.213 +- 0.058, 0.162 +- 0.042, 0.094 +- 0.032, 0.085 +- 0.024
Faith. GMean (KL)= 	  =  0.302 +- 0.025, 0.270 +- 0.027, 0.214 +- 0.034, 0.209 +- 0.029
Computed for split load_split = id



Completed in  0:06:00.002939  for LECIvGIN GOODTwitter/length



DONE LECI GOODTwitter/length readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:03:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:36 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:39 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:42 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:03:45 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 173...
[0m[1;37mINFO[0m: [1mCheckpoint 173: 
-----------------------------------
Train ROC-AUC: 0.9923
Train Loss: 0.0410
ID Validation ROC-AUC: 0.8459
ID Validation Loss: 0.1578
ID Test ROC-AUC: 0.8062
ID Test Loss: 0.1517
OOD Validation ROC-AUC: 0.7360
OOD Validation Loss: 0.1621
OOD Test ROC-AUC: 0.6792
OOD Test Loss: 0.1219

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 53...
[0m[1;37mINFO[0m: [1mCheckpoint 53: 
-----------------------------------
Train ROC-AUC: 0.9014
Train Loss: 0.0989
ID Validation ROC-AUC: 0.8203
ID Validation Loss: 0.1281
ID Test ROC-AUC: 0.8137
ID Test Loss: 0.1121
OOD Validation ROC-AUC: 0.7751
OOD Validation Loss: 0.1065
OOD Test ROC-AUC: 0.7337
OOD Test Loss: 0.0844

[0m[1;37mINFO[0m: [1mChartInfo 0.8062 0.6792 0.8137 0.7337 0.8203 0.7751[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 01:03:46 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 260
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
SUFF++ for r=0.3 class 0.0 = 0.949 +- 0.041 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.3 class 1.0 = 0.911 +- 0.041 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.3 all KL = 0.973 +- 0.041 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.3 all L1 = 0.93 +- 0.075 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.784
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.723
SUFF++ for r=0.6 class 0.0 = 0.968 +- 0.120 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 class 1.0 = 0.827 +- 0.120 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 all KL = 0.943 +- 0.120 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 all L1 = 0.897 +- 0.155 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.813
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.8
SUFF++ for r=0.9 class 0.0 = 0.985 +- 0.112 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 class 1.0 = 0.915 +- 0.112 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all KL = 0.969 +- 0.112 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all L1 = 0.95 +- 0.113 (in-sample avg dev_std = 0.169)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.667
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.621
NEC for r=0.3 class 0.0 = 0.047 +- 0.029 (in-sample avg dev_std = 0.064)
NEC for r=0.3 class 1.0 = 0.072 +- 0.029 (in-sample avg dev_std = 0.064)
NEC for r=0.3 all KL = 0.018 +- 0.029 (in-sample avg dev_std = 0.064)
NEC for r=0.3 all L1 = 0.059 +- 0.059 (in-sample avg dev_std = 0.064)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.784
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.739
NEC for r=0.6 class 0.0 = 0.042 +- 0.130 (in-sample avg dev_std = 0.163)
NEC for r=0.6 class 1.0 = 0.161 +- 0.130 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all KL = 0.061 +- 0.130 (in-sample avg dev_std = 0.163)
NEC for r=0.6 all L1 = 0.101 +- 0.154 (in-sample avg dev_std = 0.163)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.813
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.774
NEC for r=0.9 class 0.0 = 0.046 +- 0.245 (in-sample avg dev_std = 0.273)
NEC for r=0.9 class 1.0 = 0.245 +- 0.245 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all KL = 0.138 +- 0.245 (in-sample avg dev_std = 0.273)
NEC for r=0.9 all L1 = 0.145 +- 0.214 (in-sample avg dev_std = 0.273)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.808
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.752
NEC for r=1.0 class 0.0 = 0.05 +- 0.277 (in-sample avg dev_std = 0.306)
NEC for r=1.0 class 1.0 = 0.254 +- 0.277 (in-sample avg dev_std = 0.306)
NEC for r=1.0 all KL = 0.166 +- 0.277 (in-sample avg dev_std = 0.306)
NEC for r=1.0 all L1 = 0.152 +- 0.224 (in-sample avg dev_std = 0.306)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:04:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:17 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:27 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:04:30 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 121...
[0m[1;37mINFO[0m: [1mCheckpoint 121: 
-----------------------------------
Train ROC-AUC: 0.9710
Train Loss: 0.0713
ID Validation ROC-AUC: 0.8526
ID Validation Loss: 0.1392
ID Test ROC-AUC: 0.7996
ID Test Loss: 0.1358
OOD Validation ROC-AUC: 0.7613
OOD Validation Loss: 0.1391
OOD Test ROC-AUC: 0.7520
OOD Test Loss: 0.0942

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 50...
[0m[1;37mINFO[0m: [1mCheckpoint 50: 
-----------------------------------
Train ROC-AUC: 0.9037
Train Loss: 0.0960
ID Validation ROC-AUC: 0.8175
ID Validation Loss: 0.1281
ID Test ROC-AUC: 0.8267
ID Test Loss: 0.1115
OOD Validation ROC-AUC: 0.7871
OOD Validation Loss: 0.1090
OOD Test ROC-AUC: 0.7157
OOD Test Loss: 0.0855

[0m[1;37mINFO[0m: [1mChartInfo 0.7996 0.7520 0.8267 0.7157 0.8175 0.7871[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 01:04:32 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.686
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 254
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.554
SUFF++ for r=0.3 class 0.0 = 0.941 +- 0.044 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.3 class 1.0 = 0.886 +- 0.044 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.3 all KL = 0.974 +- 0.044 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.3 all L1 = 0.914 +- 0.077 (in-sample avg dev_std = 0.108)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.778
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.695
SUFF++ for r=0.6 class 0.0 = 0.964 +- 0.089 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 class 1.0 = 0.85 +- 0.089 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 all KL = 0.957 +- 0.089 (in-sample avg dev_std = 0.140)
SUFF++ for r=0.6 all L1 = 0.907 +- 0.136 (in-sample avg dev_std = 0.140)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.804
SUFF++ for r=0.9 class 0.0 = 0.991 +- 0.092 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.9 class 1.0 = 0.936 +- 0.092 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.9 all KL = 0.979 +- 0.092 (in-sample avg dev_std = 0.123)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.090 (in-sample avg dev_std = 0.123)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.683
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.649
NEC for r=0.3 class 0.0 = 0.049 +- 0.016 (in-sample avg dev_std = 0.048)
NEC for r=0.3 class 1.0 = 0.08 +- 0.016 (in-sample avg dev_std = 0.048)
NEC for r=0.3 all KL = 0.011 +- 0.016 (in-sample avg dev_std = 0.048)
NEC for r=0.3 all L1 = 0.064 +- 0.051 (in-sample avg dev_std = 0.048)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.778
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.739
NEC for r=0.6 class 0.0 = 0.027 +- 0.074 (in-sample avg dev_std = 0.122)
NEC for r=0.6 class 1.0 = 0.13 +- 0.074 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all KL = 0.032 +- 0.074 (in-sample avg dev_std = 0.122)
NEC for r=0.6 all L1 = 0.078 +- 0.123 (in-sample avg dev_std = 0.122)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.77
NEC for r=0.9 class 0.0 = 0.023 +- 0.181 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 1.0 = 0.182 +- 0.181 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all KL = 0.078 +- 0.181 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all L1 = 0.102 +- 0.172 (in-sample avg dev_std = 0.210)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.812
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.763
NEC for r=1.0 class 0.0 = 0.024 +- 0.223 (in-sample avg dev_std = 0.235)
NEC for r=1.0 class 1.0 = 0.205 +- 0.223 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all KL = 0.109 +- 0.223 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all L1 = 0.115 +- 0.192 (in-sample avg dev_std = 0.235)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:05:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:01 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:04 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:11 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 126...
[0m[1;37mINFO[0m: [1mCheckpoint 126: 
-----------------------------------
Train ROC-AUC: 0.9701
Train Loss: 0.0706
ID Validation ROC-AUC: 0.8330
ID Validation Loss: 0.1409
ID Test ROC-AUC: 0.8429
ID Test Loss: 0.1165
OOD Validation ROC-AUC: 0.7600
OOD Validation Loss: 0.1232
OOD Test ROC-AUC: 0.7059
OOD Test Loss: 0.0934

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 101...
[0m[1;37mINFO[0m: [1mCheckpoint 101: 
-----------------------------------
Train ROC-AUC: 0.9417
Train Loss: 0.0879
ID Validation ROC-AUC: 0.8157
ID Validation Loss: 0.1418
ID Test ROC-AUC: 0.7987
ID Test Loss: 0.1294
OOD Validation ROC-AUC: 0.7798
OOD Validation Loss: 0.1255
OOD Test ROC-AUC: 0.7014
OOD Test Loss: 0.0943

[0m[1;37mINFO[0m: [1mChartInfo 0.8429 0.7059 0.7987 0.7014 0.8157 0.7798[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 01:05:16 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.698
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 255
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.583
SUFF++ for r=0.3 class 0.0 = 0.941 +- 0.036 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.3 class 1.0 = 0.901 +- 0.036 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.3 all KL = 0.978 +- 0.036 (in-sample avg dev_std = 0.086)
SUFF++ for r=0.3 all L1 = 0.921 +- 0.068 (in-sample avg dev_std = 0.086)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.729
SUFF++ for r=0.6 class 0.0 = 0.969 +- 0.061 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.6 class 1.0 = 0.886 +- 0.061 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.6 all KL = 0.975 +- 0.061 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.6 all L1 = 0.927 +- 0.106 (in-sample avg dev_std = 0.108)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.852
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.064 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.064 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.985 +- 0.064 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.083 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.673
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.638
NEC for r=0.3 class 0.0 = 0.049 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 class 1.0 = 0.073 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 all KL = 0.011 +- 0.027 (in-sample avg dev_std = 0.042)
NEC for r=0.3 all L1 = 0.061 +- 0.058 (in-sample avg dev_std = 0.042)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.8
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.749
NEC for r=0.6 class 0.0 = 0.025 +- 0.068 (in-sample avg dev_std = 0.112)
NEC for r=0.6 class 1.0 = 0.109 +- 0.068 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all KL = 0.025 +- 0.068 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all L1 = 0.067 +- 0.107 (in-sample avg dev_std = 0.112)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.861
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.808
NEC for r=0.9 class 0.0 = 0.02 +- 0.191 (in-sample avg dev_std = 0.223)
NEC for r=0.9 class 1.0 = 0.191 +- 0.191 (in-sample avg dev_std = 0.223)
NEC for r=0.9 all KL = 0.083 +- 0.191 (in-sample avg dev_std = 0.223)
NEC for r=0.9 all L1 = 0.106 +- 0.183 (in-sample avg dev_std = 0.223)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.863
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0.0 = 0.02 +- 0.217 (in-sample avg dev_std = 0.227)
NEC for r=1.0 class 1.0 = 0.206 +- 0.217 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all KL = 0.1 +- 0.217 (in-sample avg dev_std = 0.227)
NEC for r=1.0 all L1 = 0.113 +- 0.200 (in-sample avg dev_std = 0.227)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:05:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:45 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:49 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:52 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:55 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ROC-AUC: 0.9793
Train Loss: 0.0613
ID Validation ROC-AUC: 0.8456
ID Validation Loss: 0.1501
ID Test ROC-AUC: 0.8055
ID Test Loss: 0.1348
OOD Validation ROC-AUC: 0.7453
OOD Validation Loss: 0.1579
OOD Test ROC-AUC: 0.7238
OOD Test Loss: 0.1098

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 123...
[0m[1;37mINFO[0m: [1mCheckpoint 123: 
-----------------------------------
Train ROC-AUC: 0.9652
Train Loss: 0.0835
ID Validation ROC-AUC: 0.8234
ID Validation Loss: 0.1556
ID Test ROC-AUC: 0.8100
ID Test Loss: 0.1307
OOD Validation ROC-AUC: 0.7813
OOD Validation Loss: 0.1347
OOD Test ROC-AUC: 0.7610
OOD Test Loss: 0.0941

[0m[1;37mINFO[0m: [1mChartInfo 0.8055 0.7238 0.8100 0.7610 0.8234 0.7813[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 01:05:58 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.692
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 254
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.588
SUFF++ for r=0.3 class 0.0 = 0.917 +- 0.045 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.3 class 1.0 = 0.86 +- 0.045 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.3 all KL = 0.963 +- 0.045 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.3 all L1 = 0.889 +- 0.084 (in-sample avg dev_std = 0.128)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.784
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.727
SUFF++ for r=0.6 class 0.0 = 0.956 +- 0.089 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 class 1.0 = 0.838 +- 0.089 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all KL = 0.956 +- 0.089 (in-sample avg dev_std = 0.158)
SUFF++ for r=0.6 all L1 = 0.897 +- 0.128 (in-sample avg dev_std = 0.158)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.819
SUFF++ for r=0.9 class 0.0 = 0.993 +- 0.046 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 class 1.0 = 0.935 +- 0.046 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all KL = 0.986 +- 0.046 (in-sample avg dev_std = 0.102)
SUFF++ for r=0.9 all L1 = 0.964 +- 0.081 (in-sample avg dev_std = 0.102)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.693
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.68
NEC for r=0.3 class 0.0 = 0.064 +- 0.020 (in-sample avg dev_std = 0.069)
NEC for r=0.3 class 1.0 = 0.093 +- 0.020 (in-sample avg dev_std = 0.069)
NEC for r=0.3 all KL = 0.016 +- 0.020 (in-sample avg dev_std = 0.069)
NEC for r=0.3 all L1 = 0.079 +- 0.059 (in-sample avg dev_std = 0.069)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.784
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.745
NEC for r=0.6 class 0.0 = 0.038 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.135 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.032 +- 0.063 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.086 +- 0.111 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.825
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.799
NEC for r=0.9 class 0.0 = 0.021 +- 0.147 (in-sample avg dev_std = 0.197)
NEC for r=0.9 class 1.0 = 0.176 +- 0.147 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all KL = 0.069 +- 0.147 (in-sample avg dev_std = 0.197)
NEC for r=0.9 all L1 = 0.099 +- 0.162 (in-sample avg dev_std = 0.197)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.827
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.788
NEC for r=1.0 class 0.0 = 0.024 +- 0.183 (in-sample avg dev_std = 0.235)
NEC for r=1.0 class 1.0 = 0.194 +- 0.183 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all KL = 0.094 +- 0.183 (in-sample avg dev_std = 0.235)
NEC for r=1.0 all L1 = 0.109 +- 0.175 (in-sample avg dev_std = 0.235)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:06:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODHIV
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:36 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:40 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:44 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mDataset: {'train': GOODHIV(24682), 'id_val': GOODHIV(4112), 'id_test': GOODHIV(4112), 'val': GOODHIV(4113), 'test': GOODHIV(4108), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1m Data(x=[21, 9], edge_index=[2, 46], edge_attr=[46, 3], y=[1, 1], smiles='CC1CCCN2C(=O)CN(Cc3ccccc3)CC(=O)N12', idx=[1], scaffold='O=C1CN(Cc2ccccc2)CC(=O)N2CCCCN12', domain_id=[1], env_id=[1])
[0mData(x=[14, 9], edge_index=[2, 30], edge_attr=[30, 3], y=[1, 1], smiles='O=C1CSc2cc([N+](=O)[O-])ccc2N1', idx=[1], scaffold='O=C1CSc2ccccc2N1', domain_id=[1], env_id=[1], ori_edge_index=[2, 30], node_perm=[14])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:06:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ROC-AUC: 0.9746
Train Loss: 0.0672
ID Validation ROC-AUC: 0.8419
ID Validation Loss: 0.1412
ID Test ROC-AUC: 0.8028
ID Test Loss: 0.1301
OOD Validation ROC-AUC: 0.7447
OOD Validation Loss: 0.1352
OOD Test ROC-AUC: 0.7243
OOD Test Loss: 0.0925

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 191...
[0m[1;37mINFO[0m: [1mCheckpoint 191: 
-----------------------------------
Train ROC-AUC: 0.9905
Train Loss: 0.0444
ID Validation ROC-AUC: 0.8359
ID Validation Loss: 0.1532
ID Test ROC-AUC: 0.7955
ID Test Loss: 0.1437
OOD Validation ROC-AUC: 0.7701
OOD Validation Loss: 0.1443
OOD Test ROC-AUC: 0.7345
OOD Test Loss: 0.1002

[0m[1;37mINFO[0m: [1mChartInfo 0.8028 0.7243 0.7955 0.7345 0.8359 0.7701[0mGOODHIV(4112)
Data example from id_test: Data(x=[23, 9], edge_index=[2, 48], edge_attr=[48, 3], y=[1, 1], smiles='Cc1occc1C(=S)Nc1ccc(Cl)c(C(=O)OCC(C)C)c1', idx=[1], scaffold='S=C(Nc1ccccc1)c1ccoc1', domain_id=[1], env_id=[1], ori_edge_index=[2, 48], node_perm=[23])
Label distribution from id_test: (tensor([0., 1.]), tensor([3976,  136]))
[1;34mDEBUG[0m: 05/08/2024 01:06:49 PM : [1mUnbalanced warning for GOODHIV (id_test)
[0mCreating balanced dataset: (tensor([0., 1.]), tensor([136, 136]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.676
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 260
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.573
SUFF++ for r=0.3 class 0.0 = 0.906 +- 0.042 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.3 class 1.0 = 0.858 +- 0.042 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.3 all KL = 0.964 +- 0.042 (in-sample avg dev_std = 0.127)
SUFF++ for r=0.3 all L1 = 0.881 +- 0.082 (in-sample avg dev_std = 0.127)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.761
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.722
SUFF++ for r=0.6 class 0.0 = 0.953 +- 0.066 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 class 1.0 = 0.857 +- 0.066 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all KL = 0.965 +- 0.066 (in-sample avg dev_std = 0.129)
SUFF++ for r=0.6 all L1 = 0.905 +- 0.114 (in-sample avg dev_std = 0.129)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.807
SUFF++ for r=0.9 class 0.0 = 0.992 +- 0.063 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 class 1.0 = 0.94 +- 0.063 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all KL = 0.986 +- 0.063 (in-sample avg dev_std = 0.108)
SUFF++ for r=0.9 all L1 = 0.966 +- 0.079 (in-sample avg dev_std = 0.108)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.659
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 272
Effective ratio: 0.309 +- 0.007
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
NEC for r=0.3 class 0.0 = 0.065 +- 0.020 (in-sample avg dev_std = 0.066)
NEC for r=0.3 class 1.0 = 0.084 +- 0.020 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all KL = 0.013 +- 0.020 (in-sample avg dev_std = 0.066)
NEC for r=0.3 all L1 = 0.074 +- 0.059 (in-sample avg dev_std = 0.066)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.761
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 272
Effective ratio: 0.608 +- 0.007
Model ROC-AUC over intervened graphs for r=0.6 =  0.738
NEC for r=0.6 class 0.0 = 0.042 +- 0.072 (in-sample avg dev_std = 0.130)
NEC for r=0.6 class 1.0 = 0.129 +- 0.072 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all KL = 0.032 +- 0.072 (in-sample avg dev_std = 0.130)
NEC for r=0.6 all L1 = 0.085 +- 0.114 (in-sample avg dev_std = 0.130)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 272
Effective ratio: 0.908 +- 0.007
Model ROC-AUC over intervened graphs for r=0.9 =  0.768
NEC for r=0.9 class 0.0 = 0.028 +- 0.157 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 1.0 = 0.182 +- 0.157 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all KL = 0.077 +- 0.157 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all L1 = 0.105 +- 0.164 (in-sample avg dev_std = 0.210)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.816
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 272
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.773
NEC for r=1.0 class 0.0 = 0.021 +- 0.195 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1.0 = 0.195 +- 0.195 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.092 +- 0.195 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.108 +- 0.179 (in-sample avg dev_std = 0.238)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.973, 0.943, 0.969, 1.0], 'all_L1': [0.93, 0.897, 0.95, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.974, 0.957, 0.979, 1.0], 'all_L1': [0.914, 0.907, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.978, 0.975, 0.985, 1.0], 'all_L1': [0.921, 0.927, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.963, 0.956, 0.986, 1.0], 'all_L1': [0.889, 0.897, 0.964, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.964, 0.965, 0.986, 1.0], 'all_L1': [0.881, 0.905, 0.966, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.018, 0.061, 0.138, 0.166], 'all_L1': [0.059, 0.101, 0.145, 0.152]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.032, 0.078, 0.109], 'all_L1': [0.064, 0.078, 0.102, 0.115]}), defaultdict(<class 'list'>, {'all_KL': [0.011, 0.025, 0.083, 0.1], 'all_L1': [0.061, 0.067, 0.106, 0.113]}), defaultdict(<class 'list'>, {'all_KL': [0.016, 0.032, 0.069, 0.094], 'all_L1': [0.079, 0.086, 0.099, 0.109]}), defaultdict(<class 'list'>, {'all_KL': [0.013, 0.032, 0.077, 0.092], 'all_L1': [0.074, 0.085, 0.105, 0.108]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.907 +- 0.019, 0.907 +- 0.011, 0.962 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.970 +- 0.006, 0.959 +- 0.011, 0.981 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.576 +- 0.012, 0.719 +- 0.013, 0.816 +- 0.019
nec class all_L1  =  0.067 +- 0.008, 0.083 +- 0.011, 0.111 +- 0.017, 0.119 +- 0.016
nec class all_KL  =  0.014 +- 0.003, 0.036 +- 0.013, 0.089 +- 0.025, 0.112 +- 0.028
nec_acc_int  =  0.645 +- 0.019, 0.742 +- 0.004, 0.784 +- 0.016, 0.776 +- 0.018


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.487 +- 0.006, 0.495 +- 0.003, 0.537 +- 0.006, 0.560 +- 0.008
Faith. Armon (L1)= 		  =  0.125 +- 0.013, 0.153 +- 0.018, 0.199 +- 0.026, 0.213 +- 0.026
Faith. GMean (L1)= 	  =  0.247 +- 0.012, 0.274 +- 0.017, 0.326 +- 0.023, 0.345 +- 0.023
Faith. Aritm (KL)= 		  =  0.492 +- 0.003, 0.498 +- 0.003, 0.535 +- 0.010, 0.556 +- 0.014
Faith. Armon (KL)= 		  =  0.027 +- 0.005, 0.070 +- 0.023, 0.162 +- 0.040, 0.201 +- 0.043
Faith. GMean (KL)= 	  =  0.115 +- 0.011, 0.184 +- 0.029, 0.293 +- 0.037, 0.333 +- 0.038
Computed for split load_split = id



Completed in  0:03:53.155428  for LECIvGIN GOODHIV/scaffold



DONE LECI GOODHIV/scaffold readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:07:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:07:36 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:08:10 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:08:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:08:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:08:48 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:09:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 154...
[0m[1;37mINFO[0m: [1mCheckpoint 154: 
-----------------------------------
Train ROC-AUC: 0.9727
Train Loss: 0.1378
ID Validation ROC-AUC: 0.9248
ID Validation Loss: 0.2674
ID Test ROC-AUC: 0.9280
ID Test Loss: 0.2650
OOD Validation ROC-AUC: 0.6550
OOD Validation Loss: 0.4948
OOD Test ROC-AUC: 0.7073
OOD Test Loss: 0.6679

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 56...
[0m[1;37mINFO[0m: [1mCheckpoint 56: 
-----------------------------------
Train ROC-AUC: 0.9313
Train Loss: 0.2369
ID Validation ROC-AUC: 0.9115
ID Validation Loss: 0.2655
ID Test ROC-AUC: 0.9145
ID Test Loss: 0.2678
OOD Validation ROC-AUC: 0.7016
OOD Validation Loss: 0.3203
OOD Test ROC-AUC: 0.7225
OOD Test Loss: 0.5195

[0m[1;37mINFO[0m: [1mChartInfo 0.9280 0.7073 0.9145 0.7225 0.9115 0.7016[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:09:06 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.745
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.626
SUFF++ for r=0.3 class 0.0 = 0.607 +- 0.203 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.3 class 1.0 = 0.692 +- 0.203 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.3 all KL = 0.721 +- 0.203 (in-sample avg dev_std = 0.428)
SUFF++ for r=0.3 all L1 = 0.682 +- 0.161 (in-sample avg dev_std = 0.428)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.864
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.787
SUFF++ for r=0.6 class 0.0 = 0.65 +- 0.164 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.6 class 1.0 = 0.87 +- 0.164 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.6 all KL = 0.876 +- 0.164 (in-sample avg dev_std = 0.258)
SUFF++ for r=0.6 all L1 = 0.844 +- 0.180 (in-sample avg dev_std = 0.258)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.932
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0.0 = 0.647 +- 0.140 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 class 1.0 = 0.928 +- 0.140 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all KL = 0.93 +- 0.140 (in-sample avg dev_std = 0.180)
SUFF++ for r=0.9 all L1 = 0.895 +- 0.172 (in-sample avg dev_std = 0.180)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.745
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.687
NEC for r=0.3 class 0.0 = 0.381 +- 0.230 (in-sample avg dev_std = 0.363)
NEC for r=0.3 class 1.0 = 0.308 +- 0.230 (in-sample avg dev_std = 0.363)
NEC for r=0.3 all KL = 0.262 +- 0.230 (in-sample avg dev_std = 0.363)
NEC for r=0.3 all L1 = 0.317 +- 0.187 (in-sample avg dev_std = 0.363)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.864
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.818
NEC for r=0.6 class 0.0 = 0.327 +- 0.185 (in-sample avg dev_std = 0.263)
NEC for r=0.6 class 1.0 = 0.145 +- 0.185 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all KL = 0.141 +- 0.185 (in-sample avg dev_std = 0.263)
NEC for r=0.6 all L1 = 0.167 +- 0.178 (in-sample avg dev_std = 0.263)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.932
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.877
NEC for r=0.9 class 0.0 = 0.308 +- 0.149 (in-sample avg dev_std = 0.230)
NEC for r=0.9 class 1.0 = 0.087 +- 0.149 (in-sample avg dev_std = 0.230)
NEC for r=0.9 all KL = 0.086 +- 0.149 (in-sample avg dev_std = 0.230)
NEC for r=0.9 all L1 = 0.114 +- 0.163 (in-sample avg dev_std = 0.230)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.932
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.893
NEC for r=1.0 class 0.0 = 0.328 +- 0.152 (in-sample avg dev_std = 0.232)
NEC for r=1.0 class 1.0 = 0.086 +- 0.152 (in-sample avg dev_std = 0.232)
NEC for r=1.0 all KL = 0.083 +- 0.152 (in-sample avg dev_std = 0.232)
NEC for r=1.0 all L1 = 0.115 +- 0.171 (in-sample avg dev_std = 0.232)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:10:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:10:53 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:11:45 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:00 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:12:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ROC-AUC: 0.9651
Train Loss: 0.1565
ID Validation ROC-AUC: 0.9232
ID Validation Loss: 0.2486
ID Test ROC-AUC: 0.9247
ID Test Loss: 0.2522
OOD Validation ROC-AUC: 0.6738
OOD Validation Loss: 0.4349
OOD Test ROC-AUC: 0.7050
OOD Test Loss: 0.6209

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9095
Train Loss: 0.2555
ID Validation ROC-AUC: 0.8966
ID Validation Loss: 0.2709
ID Test ROC-AUC: 0.8993
ID Test Loss: 0.2732
OOD Validation ROC-AUC: 0.6989
OOD Validation Loss: 0.3054
OOD Test ROC-AUC: 0.7302
OOD Test Loss: 0.4911

[0m[1;37mINFO[0m: [1mChartInfo 0.9247 0.7050 0.8993 0.7302 0.8966 0.6989[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:12:35 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.547
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.548
SUFF++ for r=0.3 class 0.0 = 0.658 +- 0.142 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 class 1.0 = 0.642 +- 0.142 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all KL = 0.798 +- 0.142 (in-sample avg dev_std = 0.382)
SUFF++ for r=0.3 all L1 = 0.644 +- 0.119 (in-sample avg dev_std = 0.382)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.741
SUFF++ for r=0.6 class 0.0 = 0.636 +- 0.194 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 class 1.0 = 0.692 +- 0.194 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all KL = 0.748 +- 0.194 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.6 all L1 = 0.685 +- 0.179 (in-sample avg dev_std = 0.390)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.886
SUFF++ for r=0.9 class 0.0 = 0.786 +- 0.161 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 class 1.0 = 0.888 +- 0.161 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all KL = 0.909 +- 0.161 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.9 all L1 = 0.876 +- 0.165 (in-sample avg dev_std = 0.224)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.547
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
NEC for r=0.3 class 0.0 = 0.27 +- 0.144 (in-sample avg dev_std = 0.271)
NEC for r=0.3 class 1.0 = 0.289 +- 0.144 (in-sample avg dev_std = 0.271)
NEC for r=0.3 all KL = 0.133 +- 0.144 (in-sample avg dev_std = 0.271)
NEC for r=0.3 all L1 = 0.287 +- 0.144 (in-sample avg dev_std = 0.271)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.825
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.785
NEC for r=0.6 class 0.0 = 0.275 +- 0.208 (in-sample avg dev_std = 0.332)
NEC for r=0.6 class 1.0 = 0.288 +- 0.208 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all KL = 0.212 +- 0.208 (in-sample avg dev_std = 0.332)
NEC for r=0.6 all L1 = 0.287 +- 0.183 (in-sample avg dev_std = 0.332)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.911
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.863
NEC for r=0.9 class 0.0 = 0.22 +- 0.182 (in-sample avg dev_std = 0.267)
NEC for r=0.9 class 1.0 = 0.14 +- 0.182 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all KL = 0.129 +- 0.182 (in-sample avg dev_std = 0.267)
NEC for r=0.9 all L1 = 0.15 +- 0.170 (in-sample avg dev_std = 0.267)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.932
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.887
NEC for r=1.0 class 0.0 = 0.209 +- 0.179 (in-sample avg dev_std = 0.253)
NEC for r=1.0 class 1.0 = 0.111 +- 0.179 (in-sample avg dev_std = 0.253)
NEC for r=1.0 all KL = 0.106 +- 0.179 (in-sample avg dev_std = 0.253)
NEC for r=1.0 all L1 = 0.122 +- 0.161 (in-sample avg dev_std = 0.253)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:14:18 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:14:19 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:14:51 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:02 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:13 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:31 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:51 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:15:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 119...
[0m[1;37mINFO[0m: [1mCheckpoint 119: 
-----------------------------------
Train ROC-AUC: 0.9599
Train Loss: 0.1725
ID Validation ROC-AUC: 0.9219
ID Validation Loss: 0.2486
ID Test ROC-AUC: 0.9238
ID Test Loss: 0.2502
OOD Validation ROC-AUC: 0.6637
OOD Validation Loss: 0.3933
OOD Test ROC-AUC: 0.7126
OOD Test Loss: 0.5743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 24...
[0m[1;37mINFO[0m: [1mCheckpoint 24: 
-----------------------------------
Train ROC-AUC: 0.9060
Train Loss: 0.2554
ID Validation ROC-AUC: 0.8940
ID Validation Loss: 0.2686
ID Test ROC-AUC: 0.8978
ID Test Loss: 0.2703
OOD Validation ROC-AUC: 0.6978
OOD Validation Loss: 0.2989
OOD Test ROC-AUC: 0.7280
OOD Test Loss: 0.4799

[0m[1;37mINFO[0m: [1mChartInfo 0.9238 0.7126 0.8978 0.7280 0.8940 0.6978[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:15:53 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.639
SUFF++ for r=0.3 class 0.0 = 0.704 +- 0.149 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 class 1.0 = 0.697 +- 0.149 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all KL = 0.82 +- 0.149 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.3 all L1 = 0.698 +- 0.135 (in-sample avg dev_std = 0.342)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.854
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.797
SUFF++ for r=0.6 class 0.0 = 0.71 +- 0.127 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 class 1.0 = 0.847 +- 0.127 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 all KL = 0.886 +- 0.127 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.6 all L1 = 0.831 +- 0.161 (in-sample avg dev_std = 0.235)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.886
SUFF++ for r=0.9 class 0.0 = 0.762 +- 0.110 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 class 1.0 = 0.933 +- 0.110 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all KL = 0.95 +- 0.110 (in-sample avg dev_std = 0.155)
SUFF++ for r=0.9 all L1 = 0.913 +- 0.136 (in-sample avg dev_std = 0.155)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.645
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.651
NEC for r=0.3 class 0.0 = 0.283 +- 0.160 (in-sample avg dev_std = 0.284)
NEC for r=0.3 class 1.0 = 0.295 +- 0.160 (in-sample avg dev_std = 0.284)
NEC for r=0.3 all KL = 0.166 +- 0.160 (in-sample avg dev_std = 0.284)
NEC for r=0.3 all L1 = 0.293 +- 0.140 (in-sample avg dev_std = 0.284)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.854
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.817
NEC for r=0.6 class 0.0 = 0.284 +- 0.144 (in-sample avg dev_std = 0.217)
NEC for r=0.6 class 1.0 = 0.159 +- 0.144 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all KL = 0.117 +- 0.144 (in-sample avg dev_std = 0.217)
NEC for r=0.6 all L1 = 0.174 +- 0.157 (in-sample avg dev_std = 0.217)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.923
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.893
NEC for r=0.9 class 0.0 = 0.227 +- 0.102 (in-sample avg dev_std = 0.157)
NEC for r=0.9 class 1.0 = 0.072 +- 0.102 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all KL = 0.054 +- 0.102 (in-sample avg dev_std = 0.157)
NEC for r=0.9 all L1 = 0.09 +- 0.133 (in-sample avg dev_std = 0.157)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.935
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.9
NEC for r=1.0 class 0.0 = 0.228 +- 0.098 (in-sample avg dev_std = 0.148)
NEC for r=1.0 class 1.0 = 0.056 +- 0.098 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all KL = 0.043 +- 0.098 (in-sample avg dev_std = 0.148)
NEC for r=1.0 all L1 = 0.076 +- 0.128 (in-sample avg dev_std = 0.148)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:17:45 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:17:45 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:18:19 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:18:30 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:18:41 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:18:58 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ROC-AUC: 0.9683
Train Loss: 0.1544
ID Validation ROC-AUC: 0.9248
ID Validation Loss: 0.2444
ID Test ROC-AUC: 0.9244
ID Test Loss: 0.2478
OOD Validation ROC-AUC: 0.6793
OOD Validation Loss: 0.3957
OOD Test ROC-AUC: 0.7158
OOD Test Loss: 0.5602

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 92...
[0m[1;37mINFO[0m: [1mCheckpoint 92: 
-----------------------------------
Train ROC-AUC: 0.9510
Train Loss: 0.1952
ID Validation ROC-AUC: 0.9178
ID Validation Loss: 0.2653
ID Test ROC-AUC: 0.9200
ID Test Loss: 0.2655
OOD Validation ROC-AUC: 0.6963
OOD Validation Loss: 0.3695
OOD Test ROC-AUC: 0.7235
OOD Test Loss: 0.5689

[0m[1;37mINFO[0m: [1mChartInfo 0.9244 0.7158 0.9200 0.7235 0.9178 0.6963[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:19:14 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.725
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.643
SUFF++ for r=0.3 class 0.0 = 0.691 +- 0.108 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 class 1.0 = 0.753 +- 0.108 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 all KL = 0.868 +- 0.108 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.3 all L1 = 0.745 +- 0.115 (in-sample avg dev_std = 0.276)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.803
SUFF++ for r=0.6 class 0.0 = 0.71 +- 0.122 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 class 1.0 = 0.867 +- 0.122 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 all KL = 0.897 +- 0.122 (in-sample avg dev_std = 0.224)
SUFF++ for r=0.6 all L1 = 0.848 +- 0.147 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.936
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.898
SUFF++ for r=0.9 class 0.0 = 0.781 +- 0.122 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 class 1.0 = 0.92 +- 0.122 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all KL = 0.942 +- 0.122 (in-sample avg dev_std = 0.174)
SUFF++ for r=0.9 all L1 = 0.903 +- 0.137 (in-sample avg dev_std = 0.174)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.725
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.718
NEC for r=0.3 class 0.0 = 0.249 +- 0.108 (in-sample avg dev_std = 0.206)
NEC for r=0.3 class 1.0 = 0.214 +- 0.108 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all KL = 0.095 +- 0.108 (in-sample avg dev_std = 0.206)
NEC for r=0.3 all L1 = 0.218 +- 0.123 (in-sample avg dev_std = 0.206)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.876
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.839
NEC for r=0.6 class 0.0 = 0.267 +- 0.147 (in-sample avg dev_std = 0.223)
NEC for r=0.6 class 1.0 = 0.153 +- 0.147 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all KL = 0.122 +- 0.147 (in-sample avg dev_std = 0.223)
NEC for r=0.6 all L1 = 0.167 +- 0.146 (in-sample avg dev_std = 0.223)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.936
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.885
NEC for r=0.9 class 0.0 = 0.265 +- 0.128 (in-sample avg dev_std = 0.209)
NEC for r=0.9 class 1.0 = 0.102 +- 0.128 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all KL = 0.081 +- 0.128 (in-sample avg dev_std = 0.209)
NEC for r=0.9 all L1 = 0.122 +- 0.148 (in-sample avg dev_std = 0.209)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.939
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.885
NEC for r=1.0 class 0.0 = 0.251 +- 0.139 (in-sample avg dev_std = 0.218)
NEC for r=1.0 class 1.0 = 0.087 +- 0.139 (in-sample avg dev_std = 0.218)
NEC for r=1.0 all KL = 0.074 +- 0.139 (in-sample avg dev_std = 0.218)
NEC for r=1.0 all L1 = 0.107 +- 0.147 (in-sample avg dev_std = 0.218)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:21:05 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:05 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:39 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/08/2024 01:21:51 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:19 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mUsing the fixed _explain_ functionality
[0mmitigation_virtual in vGINMolEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:22:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ROC-AUC: 0.9712
Train Loss: 0.1682
ID Validation ROC-AUC: 0.9235
ID Validation Loss: 0.3171
ID Test ROC-AUC: 0.9267
ID Test Loss: 0.3191
OOD Validation ROC-AUC: 0.6651
OOD Validation Loss: 0.5310
OOD Test ROC-AUC: 0.7146
OOD Test Loss: 0.7641

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 26...
[0m[1;37mINFO[0m: [1mCheckpoint 26: 
-----------------------------------
Train ROC-AUC: 0.9105
Train Loss: 0.2495
ID Validation ROC-AUC: 0.8984
ID Validation Loss: 0.2622
ID Test ROC-AUC: 0.9001
ID Test Loss: 0.2660
OOD Validation ROC-AUC: 0.7015
OOD Validation Loss: 0.2936
OOD Test ROC-AUC: 0.7252
OOD Test Loss: 0.4753

[0m[1;37mINFO[0m: [1mChartInfo 0.9267 0.7146 0.9001 0.7252 0.8984 0.7015[0mLBAPcore(11683)
Data example from id_test: Data(x=[33, 39], edge_index=[2, 72], edge_attr=[72, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 72], node_perm=[33])
Label distribution from id_test: (tensor([0., 1.]), tensor([ 1386, 10297]))
[1;34mDEBUG[0m: 05/08/2024 01:22:37 PM : [1mUnbalanced warning for LBAPcore (id_test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.56
SUFF++ for r=0.3 class 0.0 = 0.662 +- 0.191 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 class 1.0 = 0.609 +- 0.191 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all KL = 0.716 +- 0.191 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.3 all L1 = 0.615 +- 0.129 (in-sample avg dev_std = 0.451)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.802
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.768
SUFF++ for r=0.6 class 0.0 = 0.647 +- 0.184 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 class 1.0 = 0.734 +- 0.184 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all KL = 0.782 +- 0.184 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all L1 = 0.724 +- 0.180 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.893
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.86
SUFF++ for r=0.9 class 0.0 = 0.743 +- 0.158 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 class 1.0 = 0.901 +- 0.158 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all KL = 0.916 +- 0.158 (in-sample avg dev_std = 0.212)
SUFF++ for r=0.9 all L1 = 0.882 +- 0.158 (in-sample avg dev_std = 0.212)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.586
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.538
NEC for r=0.3 class 0.0 = 0.355 +- 0.206 (in-sample avg dev_std = 0.385)
NEC for r=0.3 class 1.0 = 0.383 +- 0.206 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all KL = 0.271 +- 0.206 (in-sample avg dev_std = 0.385)
NEC for r=0.3 all L1 = 0.38 +- 0.162 (in-sample avg dev_std = 0.385)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.802
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.755
NEC for r=0.6 class 0.0 = 0.352 +- 0.204 (in-sample avg dev_std = 0.374)
NEC for r=0.6 class 1.0 = 0.284 +- 0.204 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all KL = 0.234 +- 0.204 (in-sample avg dev_std = 0.374)
NEC for r=0.6 all L1 = 0.292 +- 0.176 (in-sample avg dev_std = 0.374)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.893
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.906 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.845
NEC for r=0.9 class 0.0 = 0.289 +- 0.195 (in-sample avg dev_std = 0.282)
NEC for r=0.9 class 1.0 = 0.142 +- 0.195 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all KL = 0.139 +- 0.195 (in-sample avg dev_std = 0.282)
NEC for r=0.9 all L1 = 0.159 +- 0.176 (in-sample avg dev_std = 0.282)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.922
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.853
NEC for r=1.0 class 0.0 = 0.233 +- 0.160 (in-sample avg dev_std = 0.240)
NEC for r=1.0 class 1.0 = 0.097 +- 0.160 (in-sample avg dev_std = 0.240)
NEC for r=1.0 all KL = 0.096 +- 0.160 (in-sample avg dev_std = 0.240)
NEC for r=1.0 all L1 = 0.113 +- 0.147 (in-sample avg dev_std = 0.240)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.721, 0.876, 0.93, 1.0], 'all_L1': [0.682, 0.844, 0.895, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.798, 0.748, 0.909, 1.0], 'all_L1': [0.644, 0.685, 0.876, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.82, 0.886, 0.95, 1.0], 'all_L1': [0.698, 0.831, 0.913, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.868, 0.897, 0.942, 1.0], 'all_L1': [0.745, 0.848, 0.903, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.716, 0.782, 0.916, 1.0], 'all_L1': [0.615, 0.724, 0.882, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.262, 0.141, 0.086, 0.083], 'all_L1': [0.317, 0.167, 0.114, 0.115]}), defaultdict(<class 'list'>, {'all_KL': [0.133, 0.212, 0.129, 0.106], 'all_L1': [0.287, 0.287, 0.15, 0.122]}), defaultdict(<class 'list'>, {'all_KL': [0.166, 0.117, 0.054, 0.043], 'all_L1': [0.293, 0.174, 0.09, 0.076]}), defaultdict(<class 'list'>, {'all_KL': [0.095, 0.122, 0.081, 0.074], 'all_L1': [0.218, 0.167, 0.122, 0.107]}), defaultdict(<class 'list'>, {'all_KL': [0.271, 0.234, 0.139, 0.096], 'all_L1': [0.38, 0.292, 0.159, 0.113]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.677 +- 0.045, 0.786 +- 0.068, 0.894 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.785 +- 0.059, 0.838 +- 0.061, 0.929 +- 0.015, 1.000 +- 0.000
suff++_acc_int  =  0.603 +- 0.041, 0.779 +- 0.022, 0.882 +- 0.012
nec class all_L1  =  0.299 +- 0.052, 0.217 +- 0.059, 0.127 +- 0.025, 0.107 +- 0.016
nec class all_KL  =  0.185 +- 0.070, 0.165 +- 0.048, 0.098 +- 0.032, 0.080 +- 0.022
nec_acc_int  =  0.631 +- 0.070, 0.803 +- 0.029, 0.873 +- 0.017, 0.884 +- 0.016


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.488 +- 0.013, 0.502 +- 0.008, 0.510 +- 0.007, 0.553 +- 0.008
Faith. Armon (L1)= 		  =  0.410 +- 0.044, 0.333 +- 0.063, 0.221 +- 0.038, 0.192 +- 0.027
Faith. GMean (L1)= 	  =  0.447 +- 0.028, 0.407 +- 0.037, 0.335 +- 0.031, 0.325 +- 0.026
Faith. Aritm (KL)= 		  =  0.485 +- 0.011, 0.502 +- 0.011, 0.514 +- 0.009, 0.540 +- 0.011
Faith. Armon (KL)= 		  =  0.291 +- 0.087, 0.271 +- 0.063, 0.175 +- 0.052, 0.148 +- 0.038
Faith. GMean (KL)= 	  =  0.371 +- 0.060, 0.366 +- 0.041, 0.297 +- 0.047, 0.281 +- 0.041
Computed for split load_split = id



Completed in  0:17:03.109883  for LECIvGIN LBAPcore/assay



DONE LECI LBAPcore/assay readout

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:24:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:51 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:24:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9982
Train Loss: 0.0116
ID Validation ACCURACY: 0.9041
ID Validation Loss: 0.3838
ID Test ACCURACY: 0.9016
ID Test Loss: 0.4021
OOD Validation ACCURACY: 0.8686
OOD Validation Loss: 0.5562
OOD Test ACCURACY: 0.5691
OOD Test Loss: 5.0866

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9945
Train Loss: 0.0234
ID Validation ACCURACY: 0.9013
ID Validation Loss: 0.3604
ID Test ACCURACY: 0.9033
ID Test Loss: 0.3697
OOD Validation ACCURACY: 0.8911
OOD Validation Loss: 0.4327
OOD Test ACCURACY: 0.7119
OOD Test Loss: 1.6593

[0m[1;37mINFO[0m: [1mChartInfo 0.9016 0.5691 0.9033 0.7119 0.9013 0.8911[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.513 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 1 = 0.476 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 2 = 0.498 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 3 = 0.517 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 4 = 0.502 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 5 = 0.511 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 6 = 0.491 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 7 = 0.497 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 8 = 0.5 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 class 9 = 0.51 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all KL = 0.627 +- 0.121 (in-sample avg dev_std = 0.390)
SUFF++ for r=0.3 all L1 = 0.501 +- 0.075 (in-sample avg dev_std = 0.390)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.206
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.155
SUFF++ for r=0.6 class 0 = 0.364 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 1 = 0.419 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 2 = 0.406 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 3 = 0.391 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 4 = 0.373 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 5 = 0.377 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 6 = 0.368 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 7 = 0.379 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 8 = 0.376 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 class 9 = 0.362 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all KL = 0.301 +- 0.198 (in-sample avg dev_std = 0.413)
SUFF++ for r=0.6 all L1 = 0.382 +- 0.126 (in-sample avg dev_std = 0.413)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.781
SUFF++ for r=0.9 class 0 = 0.908 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 1 = 0.932 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 2 = 0.801 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 3 = 0.705 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 4 = 0.834 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 5 = 0.783 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 6 = 0.808 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 7 = 0.857 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 8 = 0.842 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 class 9 = 0.74 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all KL = 0.825 +- 0.237 (in-sample avg dev_std = 0.265)
SUFF++ for r=0.9 all L1 = 0.823 +- 0.204 (in-sample avg dev_std = 0.265)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.123
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
NEC for r=0.3 class 0 = 0.377 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 1 = 0.37 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 2 = 0.363 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 3 = 0.365 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 4 = 0.348 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 5 = 0.388 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 6 = 0.359 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 7 = 0.373 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 8 = 0.356 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 class 9 = 0.345 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all KL = 0.166 +- 0.091 (in-sample avg dev_std = 0.160)
NEC for r=0.3 all L1 = 0.364 +- 0.092 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.206
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
NEC for r=0.6 class 0 = 0.575 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 1 = 0.492 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 2 = 0.449 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 3 = 0.479 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 4 = 0.491 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 5 = 0.529 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 6 = 0.499 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 7 = 0.502 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 8 = 0.546 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 class 9 = 0.563 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all KL = 0.475 +- 0.233 (in-sample avg dev_std = 0.318)
NEC for r=0.6 all L1 = 0.512 +- 0.165 (in-sample avg dev_std = 0.318)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.624
NEC for r=0.9 class 0 = 0.31 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 1 = 0.206 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 2 = 0.37 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 3 = 0.558 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 4 = 0.301 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 5 = 0.537 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 6 = 0.478 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 7 = 0.384 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 8 = 0.377 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 class 9 = 0.558 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 all KL = 0.584 +- 0.329 (in-sample avg dev_std = 0.470)
NEC for r=0.9 all L1 = 0.404 +- 0.265 (in-sample avg dev_std = 0.470)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.835
NEC for r=1.0 class 0 = 0.111 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 1 = 0.049 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 2 = 0.257 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 3 = 0.406 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 4 = 0.165 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 5 = 0.272 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 6 = 0.298 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 7 = 0.168 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 8 = 0.187 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 class 9 = 0.375 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all KL = 0.402 +- 0.370 (in-sample avg dev_std = 0.414)
NEC for r=1.0 all L1 = 0.226 +- 0.251 (in-sample avg dev_std = 0.414)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:32:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:32:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ACCURACY: 0.9895
Train Loss: 0.0368
ID Validation ACCURACY: 0.8991
ID Validation Loss: 0.3644
ID Test ACCURACY: 0.8936
ID Test Loss: 0.3839
OOD Validation ACCURACY: 0.8770
OOD Validation Loss: 0.4499
OOD Test ACCURACY: 0.4940
OOD Test Loss: 2.9614

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 161...
[0m[1;37mINFO[0m: [1mCheckpoint 161: 
-----------------------------------
Train ACCURACY: 0.9911
Train Loss: 0.0328
ID Validation ACCURACY: 0.8986
ID Validation Loss: 0.3696
ID Test ACCURACY: 0.8951
ID Test Loss: 0.3805
OOD Validation ACCURACY: 0.8856
OOD Validation Loss: 0.4241
OOD Test ACCURACY: 0.5491
OOD Test Loss: 2.5001

[0m[1;37mINFO[0m: [1mChartInfo 0.8936 0.4940 0.8951 0.5491 0.8986 0.8856[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
SUFF++ for r=0.3 class 0 = 0.613 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 1 = 0.576 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 2 = 0.57 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 3 = 0.598 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 4 = 0.568 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 5 = 0.583 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 6 = 0.597 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 7 = 0.563 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 8 = 0.591 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 class 9 = 0.596 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 all KL = 0.768 +- 0.104 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.3 all L1 = 0.585 +- 0.102 (in-sample avg dev_std = 0.330)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.119
SUFF++ for r=0.6 class 0 = 0.396 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 1 = 0.409 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 2 = 0.391 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 3 = 0.413 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 4 = 0.399 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 5 = 0.368 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 6 = 0.414 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 7 = 0.416 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 8 = 0.405 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 9 = 0.406 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all KL = 0.379 +- 0.225 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all L1 = 0.402 +- 0.149 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.755
SUFF++ for r=0.9 class 0 = 0.912 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 1 = 0.89 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 2 = 0.768 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 3 = 0.733 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 4 = 0.782 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 5 = 0.764 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 6 = 0.809 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 7 = 0.847 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 8 = 0.773 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 class 9 = 0.745 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all KL = 0.826 +- 0.226 (in-sample avg dev_std = 0.271)
SUFF++ for r=0.9 all L1 = 0.804 +- 0.208 (in-sample avg dev_std = 0.271)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.102
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
NEC for r=0.3 class 0 = 0.285 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 1 = 0.291 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 2 = 0.313 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 3 = 0.311 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 4 = 0.318 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 5 = 0.308 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 6 = 0.305 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 7 = 0.325 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 8 = 0.312 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 class 9 = 0.3 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 all KL = 0.13 +- 0.090 (in-sample avg dev_std = 0.138)
NEC for r=0.3 all L1 = 0.307 +- 0.099 (in-sample avg dev_std = 0.138)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.117
NEC for r=0.6 class 0 = 0.525 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 1 = 0.477 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 2 = 0.547 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 3 = 0.55 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 4 = 0.548 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 5 = 0.567 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 6 = 0.52 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 7 = 0.522 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 8 = 0.527 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 class 9 = 0.513 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 all KL = 0.48 +- 0.221 (in-sample avg dev_std = 0.308)
NEC for r=0.6 all L1 = 0.528 +- 0.163 (in-sample avg dev_std = 0.308)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.814
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.603
NEC for r=0.9 class 0 = 0.342 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.218 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.327 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 3 = 0.544 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 4 = 0.392 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 5 = 0.521 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 6 = 0.445 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 7 = 0.421 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 8 = 0.473 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 9 = 0.513 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.557 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.416 +- 0.255 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.949
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.834
NEC for r=1.0 class 0 = 0.127 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 1 = 0.047 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 2 = 0.26 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 3 = 0.36 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 4 = 0.186 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 5 = 0.299 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 6 = 0.277 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 7 = 0.208 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 8 = 0.26 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 9 = 0.352 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 all KL = 0.375 +- 0.337 (in-sample avg dev_std = 0.392)
NEC for r=1.0 all L1 = 0.235 +- 0.237 (in-sample avg dev_std = 0.392)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:40:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:40:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:40:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 0.9977
Train Loss: 0.0122
ID Validation ACCURACY: 0.9020
ID Validation Loss: 0.4048
ID Test ACCURACY: 0.8964
ID Test Loss: 0.4180
OOD Validation ACCURACY: 0.8684
OOD Validation Loss: 0.5222
OOD Test ACCURACY: 0.3916
OOD Test Loss: 6.8162

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9677
Train Loss: 0.0990
ID Validation ACCURACY: 0.8980
ID Validation Loss: 0.3369
ID Test ACCURACY: 0.8956
ID Test Loss: 0.3387
OOD Validation ACCURACY: 0.8854
OOD Validation Loss: 0.3793
OOD Test ACCURACY: 0.7431
OOD Test Loss: 1.0135

[0m[1;37mINFO[0m: [1mChartInfo 0.8964 0.3916 0.8956 0.7431 0.8980 0.8854[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.1
SUFF++ for r=0.3 class 0 = 0.471 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 1 = 0.436 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 2 = 0.458 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 3 = 0.464 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 4 = 0.456 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 5 = 0.45 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 6 = 0.459 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 7 = 0.438 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 8 = 0.44 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 class 9 = 0.458 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 all KL = 0.522 +- 0.169 (in-sample avg dev_std = 0.454)
SUFF++ for r=0.3 all L1 = 0.452 +- 0.102 (in-sample avg dev_std = 0.454)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.196
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.144
SUFF++ for r=0.6 class 0 = 0.333 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 1 = 0.331 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 2 = 0.343 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 3 = 0.358 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 4 = 0.387 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 5 = 0.349 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 6 = 0.379 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 7 = 0.378 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 8 = 0.375 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 9 = 0.401 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all KL = 0.279 +- 0.214 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all L1 = 0.363 +- 0.143 (in-sample avg dev_std = 0.455)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.768
SUFF++ for r=0.9 class 0 = 0.94 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 1 = 0.913 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 2 = 0.731 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 3 = 0.75 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 4 = 0.786 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 5 = 0.722 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 6 = 0.808 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 7 = 0.814 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 8 = 0.863 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 class 9 = 0.783 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all KL = 0.809 +- 0.252 (in-sample avg dev_std = 0.288)
SUFF++ for r=0.9 all L1 = 0.813 +- 0.216 (in-sample avg dev_std = 0.288)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
NEC for r=0.3 class 0 = 0.392 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 1 = 0.418 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 2 = 0.395 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 3 = 0.424 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 4 = 0.407 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 5 = 0.411 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 6 = 0.426 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 7 = 0.421 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 8 = 0.43 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 class 9 = 0.406 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all KL = 0.263 +- 0.156 (in-sample avg dev_std = 0.228)
NEC for r=0.3 all L1 = 0.413 +- 0.127 (in-sample avg dev_std = 0.228)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.196
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.165
NEC for r=0.6 class 0 = 0.568 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 1 = 0.504 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 2 = 0.525 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 3 = 0.504 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 4 = 0.502 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 5 = 0.532 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 6 = 0.533 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 7 = 0.527 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 8 = 0.479 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 9 = 0.498 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all KL = 0.509 +- 0.224 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all L1 = 0.517 +- 0.164 (in-sample avg dev_std = 0.354)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.647
NEC for r=0.9 class 0 = 0.256 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 1 = 0.18 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 2 = 0.383 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 3 = 0.5 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 4 = 0.399 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 5 = 0.559 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 6 = 0.478 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 7 = 0.383 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 8 = 0.302 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 class 9 = 0.423 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all KL = 0.54 +- 0.339 (in-sample avg dev_std = 0.461)
NEC for r=0.9 all L1 = 0.383 +- 0.268 (in-sample avg dev_std = 0.461)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.946
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.848
NEC for r=1.0 class 0 = 0.09 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 1 = 0.045 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 2 = 0.264 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 3 = 0.31 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 4 = 0.243 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 5 = 0.306 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 6 = 0.267 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 7 = 0.2 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 8 = 0.174 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 class 9 = 0.258 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all KL = 0.38 +- 0.364 (in-sample avg dev_std = 0.407)
NEC for r=1.0 all L1 = 0.213 +- 0.242 (in-sample avg dev_std = 0.407)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:47:44 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:44 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:47:45 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:47:46 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9970
Train Loss: 0.0158
ID Validation ACCURACY: 0.9020
ID Validation Loss: 0.3897
ID Test ACCURACY: 0.8953
ID Test Loss: 0.4044
OOD Validation ACCURACY: 0.8734
OOD Validation Loss: 0.5272
OOD Test ACCURACY: 0.6619
OOD Test Loss: 1.9791

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9799
Train Loss: 0.0665
ID Validation ACCURACY: 0.8979
ID Validation Loss: 0.3461
ID Test ACCURACY: 0.8966
ID Test Loss: 0.3492
OOD Validation ACCURACY: 0.8897
OOD Validation Loss: 0.3708
OOD Test ACCURACY: 0.7326
OOD Test Loss: 1.0225

[0m[1;37mINFO[0m: [1mChartInfo 0.8953 0.6619 0.8966 0.7326 0.8979 0.8897[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.098
SUFF++ for r=0.3 class 0 = 0.666 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 1 = 0.639 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 2 = 0.621 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 3 = 0.636 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 4 = 0.647 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 5 = 0.632 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 6 = 0.629 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 7 = 0.614 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 8 = 0.621 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 class 9 = 0.65 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 all KL = 0.817 +- 0.102 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.3 all L1 = 0.635 +- 0.097 (in-sample avg dev_std = 0.235)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.132
SUFF++ for r=0.6 class 0 = 0.315 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 1 = 0.379 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 2 = 0.369 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 3 = 0.369 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 4 = 0.418 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 5 = 0.384 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 6 = 0.404 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 7 = 0.389 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 8 = 0.408 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 class 9 = 0.399 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all KL = 0.307 +- 0.235 (in-sample avg dev_std = 0.392)
SUFF++ for r=0.6 all L1 = 0.384 +- 0.152 (in-sample avg dev_std = 0.392)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.76
SUFF++ for r=0.9 class 0 = 0.943 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 1 = 0.916 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 2 = 0.711 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 3 = 0.795 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 4 = 0.842 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 5 = 0.757 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 6 = 0.808 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 7 = 0.819 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 8 = 0.831 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 class 9 = 0.73 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all KL = 0.828 +- 0.227 (in-sample avg dev_std = 0.254)
SUFF++ for r=0.9 all L1 = 0.817 +- 0.205 (in-sample avg dev_std = 0.254)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.091
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
NEC for r=0.3 class 0 = 0.28 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 1 = 0.309 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 2 = 0.302 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 3 = 0.287 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 4 = 0.291 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 5 = 0.313 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 6 = 0.307 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 7 = 0.311 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 8 = 0.309 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 9 = 0.313 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all KL = 0.138 +- 0.103 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all L1 = 0.302 +- 0.090 (in-sample avg dev_std = 0.140)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.174
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.137
NEC for r=0.6 class 0 = 0.579 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 1 = 0.543 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 2 = 0.501 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 3 = 0.538 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 4 = 0.49 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 5 = 0.515 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 6 = 0.488 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 7 = 0.529 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 8 = 0.481 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 9 = 0.527 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all KL = 0.494 +- 0.221 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all L1 = 0.519 +- 0.155 (in-sample avg dev_std = 0.354)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.233 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 1 = 0.195 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 2 = 0.524 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 3 = 0.49 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 4 = 0.35 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 5 = 0.526 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 6 = 0.435 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 7 = 0.429 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 8 = 0.332 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 class 9 = 0.573 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all KL = 0.583 +- 0.327 (in-sample avg dev_std = 0.471)
NEC for r=0.9 all L1 = 0.405 +- 0.267 (in-sample avg dev_std = 0.471)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.833
NEC for r=1.0 class 0 = 0.08 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 1 = 0.022 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 2 = 0.345 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 3 = 0.314 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 4 = 0.176 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 5 = 0.295 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 6 = 0.278 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 7 = 0.229 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 8 = 0.169 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 class 9 = 0.436 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all KL = 0.395 +- 0.370 (in-sample avg dev_std = 0.415)
NEC for r=1.0 all L1 = 0.231 +- 0.255 (in-sample avg dev_std = 0.415)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Wed May  8 13:55:24 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:25 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0mLECIvGIN
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mInit vGINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mUsing no mitigation (None)
[0mmitigation_virtual in vGINEncoder =  None
[1;34mDEBUG[0m: 05/08/2024 01:55:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9950
Train Loss: 0.0231
ID Validation ACCURACY: 0.9024
ID Validation Loss: 0.3659
ID Test ACCURACY: 0.8969
ID Test Loss: 0.3748
OOD Validation ACCURACY: 0.8824
OOD Validation Loss: 0.4311
OOD Test ACCURACY: 0.7293
OOD Test Loss: 1.2294

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 136...
[0m[1;37mINFO[0m: [1mCheckpoint 136: 
-----------------------------------
Train ACCURACY: 0.9895
Train Loss: 0.0364
ID Validation ACCURACY: 0.8990
ID Validation Loss: 0.3635
ID Test ACCURACY: 0.9014
ID Test Loss: 0.3583
OOD Validation ACCURACY: 0.8921
OOD Validation Loss: 0.4134
OOD Test ACCURACY: 0.7336
OOD Test Loss: 1.4819

[0m[1;37mINFO[0m: [1mChartInfo 0.8969 0.7293 0.9014 0.7336 0.8990 0.8921[0mGOODCMNIST(7000)
Data example from id_test: Data(x=[75, 3], edge_index=[2, 1351], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1351], node_perm=[75])
Label distribution from id_test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([657, 814, 676, 706, 676, 663, 688, 748, 702, 670]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.101
SUFF++ for r=0.3 class 0 = 0.568 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 1 = 0.533 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 2 = 0.521 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 3 = 0.548 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 4 = 0.54 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 5 = 0.534 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 6 = 0.54 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 7 = 0.523 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 8 = 0.546 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 9 = 0.548 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all KL = 0.654 +- 0.128 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all L1 = 0.54 +- 0.094 (in-sample avg dev_std = 0.365)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
SUFF++ for r=0.6 class 0 = 0.372 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 1 = 0.424 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 2 = 0.427 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 3 = 0.411 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 4 = 0.399 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 5 = 0.38 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 6 = 0.416 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 7 = 0.427 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 8 = 0.395 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 class 9 = 0.438 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all KL = 0.424 +- 0.225 (in-sample avg dev_std = 0.356)
SUFF++ for r=0.6 all L1 = 0.41 +- 0.148 (in-sample avg dev_std = 0.356)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.765
SUFF++ for r=0.9 class 0 = 0.919 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 1 = 0.892 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 2 = 0.767 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 3 = 0.761 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 4 = 0.813 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 5 = 0.742 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 6 = 0.823 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 7 = 0.836 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 8 = 0.85 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 class 9 = 0.733 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all KL = 0.83 +- 0.228 (in-sample avg dev_std = 0.269)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.203 (in-sample avg dev_std = 0.269)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
NEC for r=0.3 class 0 = 0.324 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 1 = 0.339 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 2 = 0.338 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 3 = 0.32 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 4 = 0.338 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 5 = 0.34 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 6 = 0.342 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 7 = 0.331 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 8 = 0.337 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 class 9 = 0.329 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all KL = 0.148 +- 0.081 (in-sample avg dev_std = 0.140)
NEC for r=0.3 all L1 = 0.334 +- 0.083 (in-sample avg dev_std = 0.140)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.176
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.138
NEC for r=0.6 class 0 = 0.519 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 1 = 0.528 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 2 = 0.489 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 3 = 0.519 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 4 = 0.514 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 5 = 0.533 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 6 = 0.502 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 7 = 0.502 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 8 = 0.506 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 class 9 = 0.487 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 all KL = 0.428 +- 0.194 (in-sample avg dev_std = 0.306)
NEC for r=0.6 all L1 = 0.51 +- 0.140 (in-sample avg dev_std = 0.306)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.819
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.627
NEC for r=0.9 class 0 = 0.238 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.322 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.433 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 3 = 0.519 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 4 = 0.376 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 5 = 0.566 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 6 = 0.411 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 7 = 0.364 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 8 = 0.304 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 9 = 0.507 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.552 +- 0.310 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.402 +- 0.252 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.951
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.846
NEC for r=1.0 class 0 = 0.1 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 1 = 0.06 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 2 = 0.302 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 3 = 0.328 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 4 = 0.192 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 5 = 0.288 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 6 = 0.251 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 7 = 0.212 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 8 = 0.154 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 class 9 = 0.335 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 all KL = 0.376 +- 0.340 (in-sample avg dev_std = 0.389)
NEC for r=1.0 all L1 = 0.219 +- 0.238 (in-sample avg dev_std = 0.389)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.627, 0.301, 0.825, 1.0], 'all_L1': [0.501, 0.382, 0.823, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.768, 0.379, 0.826, 1.0], 'all_L1': [0.585, 0.402, 0.804, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.522, 0.279, 0.809, 1.0], 'all_L1': [0.452, 0.363, 0.813, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.817, 0.307, 0.828, 1.0], 'all_L1': [0.635, 0.384, 0.817, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.654, 0.424, 0.83, 1.0], 'all_L1': [0.54, 0.41, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.166, 0.475, 0.584, 0.402], 'all_L1': [0.364, 0.512, 0.404, 0.226]}), defaultdict(<class 'list'>, {'all_KL': [0.13, 0.48, 0.557, 0.375], 'all_L1': [0.307, 0.528, 0.416, 0.235]}), defaultdict(<class 'list'>, {'all_KL': [0.263, 0.509, 0.54, 0.38], 'all_L1': [0.413, 0.517, 0.383, 0.213]}), defaultdict(<class 'list'>, {'all_KL': [0.138, 0.494, 0.583, 0.395], 'all_L1': [0.302, 0.519, 0.405, 0.231]}), defaultdict(<class 'list'>, {'all_KL': [0.148, 0.428, 0.552, 0.376], 'all_L1': [0.334, 0.51, 0.402, 0.219]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_test
suff++ class all_L1  =  0.543 +- 0.064, 0.388 +- 0.016, 0.814 +- 0.006, 1.000 +- 0.000
suff++ class all_KL  =  0.678 +- 0.105, 0.338 +- 0.055, 0.824 +- 0.007, 1.000 +- 0.000
suff++_acc_int  =  0.099 +- 0.002, 0.134 +- 0.014, 0.766 +- 0.009
nec class all_L1  =  0.344 +- 0.041, 0.517 +- 0.006, 0.402 +- 0.011, 0.225 +- 0.008
nec class all_KL  =  0.169 +- 0.049, 0.477 +- 0.027, 0.563 +- 0.017, 0.386 +- 0.011
nec_acc_int  =  0.105 +- 0.009, 0.142 +- 0.016, 0.625 +- 0.014, 0.839 +- 0.006


 -------------------------------------------------- 
Computing faithfulness

Eval split id_test
Faith. Aritm (L1)= 		  =  0.443 +- 0.014, 0.453 +- 0.009, 0.608 +- 0.005, 0.612 +- 0.004
Faith. Armon (L1)= 		  =  0.416 +- 0.010, 0.443 +- 0.011, 0.538 +- 0.009, 0.367 +- 0.011
Faith. GMean (L1)= 	  =  0.429 +- 0.005, 0.448 +- 0.010, 0.572 +- 0.007, 0.474 +- 0.008
Faith. Aritm (KL)= 		  =  0.423 +- 0.034, 0.408 +- 0.017, 0.693 +- 0.011, 0.693 +- 0.005
Faith. Armon (KL)= 		  =  0.262 +- 0.046, 0.391 +- 0.028, 0.669 +- 0.014, 0.556 +- 0.011
Faith. GMean (KL)= 	  =  0.331 +- 0.021, 0.399 +- 0.022, 0.681 +- 0.013, 0.621 +- 0.009
Computed for split load_split = id



Completed in  0:38:14.582585  for LECIvGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color readout
DONE all :)
