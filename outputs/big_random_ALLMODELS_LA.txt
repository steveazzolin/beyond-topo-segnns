Time to compute metrics for random explanations!
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:41:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:41:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 157...
[0m[1;37mINFO[0m: [1mCheckpoint 157: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0018
ID Validation ACCURACY: 0.9183
ID Validation Loss: 0.3380
ID Test ACCURACY: 0.9172
ID Test Loss: 0.3753
OOD Validation ACCURACY: 0.8775
OOD Validation Loss: 0.3681
OOD Test ACCURACY: 0.8031
OOD Test Loss: 0.5385

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 117...
[0m[1;37mINFO[0m: [1mCheckpoint 117: 
-----------------------------------
Train ACCURACY: 0.9990
Train Loss: 0.0067
ID Validation ACCURACY: 0.9136
ID Validation Loss: 0.3073
ID Test ACCURACY: 0.9130
ID Test Loss: 0.3474
OOD Validation ACCURACY: 0.8809
OOD Validation Loss: 0.3430
OOD Test ACCURACY: 0.8340
OOD Test Loss: 0.4255

[0m[1;37mINFO[0m: [1mChartInfo 0.9172 0.8031 0.9130 0.8340 0.9136 0.8809[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:41:32 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.811
SUFF++ for r=0.6 class 0.0 = 0.738 +- 0.343 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 class 1.0 = 0.89 +- 0.343 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all KL = 0.691 +- 0.343 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.6 all L1 = 0.826 +- 0.197 (in-sample avg dev_std = 0.490)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.887
SUFF++ for r=0.9 class 0.0 = 0.965 +- 0.075 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 class 1.0 = 0.98 +- 0.075 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all KL = 0.985 +- 0.075 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all L1 = 0.973 +- 0.079 (in-sample avg dev_std = 0.070)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.645
SUFF++ for r=0.3 class 0.0 = 0.655 +- 0.334 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 class 1.0 = 0.923 +- 0.334 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all KL = 0.703 +- 0.334 (in-sample avg dev_std = 0.500)
SUFF++ for r=0.3 all L1 = 0.793 +- 0.225 (in-sample avg dev_std = 0.500)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.724
SUFF++ for r=0.6 class 0.0 = 0.701 +- 0.241 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 class 1.0 = 0.929 +- 0.241 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all KL = 0.8 +- 0.241 (in-sample avg dev_std = 0.402)
SUFF++ for r=0.6 all L1 = 0.819 +- 0.193 (in-sample avg dev_std = 0.402)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.811
SUFF++ for r=0.9 class 0.0 = 0.888 +- 0.058 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.058 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all KL = 0.967 +- 0.058 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.9 all L1 = 0.925 +- 0.095 (in-sample avg dev_std = 0.160)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.881
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.868
NEC for r=0.6 class 0.0 = 0.055 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=0.6 class 1.0 = 0.037 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all KL = 0.041 +- 0.145 (in-sample avg dev_std = 0.114)
NEC for r=0.6 all L1 = 0.044 +- 0.124 (in-sample avg dev_std = 0.114)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.033 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=0.9 class 1.0 = 0.023 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=0.9 all KL = 0.017 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=0.9 all L1 = 0.027 +- 0.090 (in-sample avg dev_std = 0.076)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.884
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.033 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=1.0 class 1.0 = 0.023 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=1.0 all KL = 0.017 +- 0.089 (in-sample avg dev_std = 0.076)
NEC for r=1.0 all L1 = 0.027 +- 0.090 (in-sample avg dev_std = 0.076)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.728
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.708
NEC for r=0.3 class 0.0 = 0.136 +- 0.160 (in-sample avg dev_std = 0.181)
NEC for r=0.3 class 1.0 = 0.022 +- 0.160 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all KL = 0.064 +- 0.160 (in-sample avg dev_std = 0.181)
NEC for r=0.3 all L1 = 0.077 +- 0.153 (in-sample avg dev_std = 0.181)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.785
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.771
NEC for r=0.6 class 0.0 = 0.126 +- 0.105 (in-sample avg dev_std = 0.140)
NEC for r=0.6 class 1.0 = 0.03 +- 0.105 (in-sample avg dev_std = 0.140)
NEC for r=0.6 all KL = 0.04 +- 0.105 (in-sample avg dev_std = 0.140)
NEC for r=0.6 all L1 = 0.076 +- 0.136 (in-sample avg dev_std = 0.140)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.822
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.819
NEC for r=0.9 class 0.0 = 0.059 +- 0.029 (in-sample avg dev_std = 0.067)
NEC for r=0.9 class 1.0 = 0.026 +- 0.029 (in-sample avg dev_std = 0.067)
NEC for r=0.9 all KL = 0.01 +- 0.029 (in-sample avg dev_std = 0.067)
NEC for r=0.9 all L1 = 0.042 +- 0.073 (in-sample avg dev_std = 0.067)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.825
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.824
NEC for r=1.0 class 0.0 = 0.039 +- 0.022 (in-sample avg dev_std = 0.052)
NEC for r=1.0 class 1.0 = 0.021 +- 0.022 (in-sample avg dev_std = 0.052)
NEC for r=1.0 all KL = 0.006 +- 0.022 (in-sample avg dev_std = 0.052)
NEC for r=1.0 all L1 = 0.029 +- 0.059 (in-sample avg dev_std = 0.052)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:43:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:32 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:43:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0038
ID Validation ACCURACY: 0.9200
ID Validation Loss: 0.3551
ID Test ACCURACY: 0.9093
ID Test Loss: 0.4267
OOD Validation ACCURACY: 0.8753
OOD Validation Loss: 0.3988
OOD Test ACCURACY: 0.7891
OOD Test Loss: 0.6170

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0004
ID Validation ACCURACY: 0.9191
ID Validation Loss: 0.4356
ID Test ACCURACY: 0.9140
ID Test Loss: 0.4797
OOD Validation ACCURACY: 0.8836
OOD Validation Loss: 0.4121
OOD Test ACCURACY: 0.8148
OOD Test Loss: 0.5531

[0m[1;37mINFO[0m: [1mChartInfo 0.9093 0.7891 0.9140 0.8148 0.9191 0.8836[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:43:33 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.82
SUFF++ for r=0.6 class 0.0 = 0.822 +- 0.331 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 class 1.0 = 0.81 +- 0.331 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all KL = 0.666 +- 0.331 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.6 all L1 = 0.815 +- 0.200 (in-sample avg dev_std = 0.456)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.092 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 class 1.0 = 0.968 +- 0.092 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all KL = 0.98 +- 0.092 (in-sample avg dev_std = 0.098)
SUFF++ for r=0.9 all L1 = 0.963 +- 0.103 (in-sample avg dev_std = 0.098)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.693
SUFF++ for r=0.3 class 0.0 = 0.621 +- 0.277 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 class 1.0 = 0.675 +- 0.277 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all KL = 0.483 +- 0.277 (in-sample avg dev_std = 0.636)
SUFF++ for r=0.3 all L1 = 0.649 +- 0.170 (in-sample avg dev_std = 0.636)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.764
SUFF++ for r=0.6 class 0.0 = 0.719 +- 0.205 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 class 1.0 = 0.869 +- 0.205 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all KL = 0.789 +- 0.205 (in-sample avg dev_std = 0.384)
SUFF++ for r=0.6 all L1 = 0.797 +- 0.175 (in-sample avg dev_std = 0.384)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.793
SUFF++ for r=0.9 class 0.0 = 0.878 +- 0.054 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.054 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all KL = 0.967 +- 0.054 (in-sample avg dev_std = 0.153)
SUFF++ for r=0.9 all L1 = 0.921 +- 0.102 (in-sample avg dev_std = 0.153)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.867
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.863
NEC for r=0.6 class 0.0 = 0.083 +- 0.226 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 1.0 = 0.097 +- 0.226 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all KL = 0.096 +- 0.226 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all L1 = 0.091 +- 0.189 (in-sample avg dev_std = 0.189)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.888
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.041 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=0.9 class 1.0 = 0.03 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=0.9 all KL = 0.022 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=0.9 all L1 = 0.035 +- 0.100 (in-sample avg dev_std = 0.081)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.041 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=1.0 class 1.0 = 0.029 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all KL = 0.021 +- 0.093 (in-sample avg dev_std = 0.081)
NEC for r=1.0 all L1 = 0.034 +- 0.099 (in-sample avg dev_std = 0.081)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.798
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.794
NEC for r=0.3 class 0.0 = 0.174 +- 0.200 (in-sample avg dev_std = 0.238)
NEC for r=0.3 class 1.0 = 0.127 +- 0.200 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all KL = 0.12 +- 0.200 (in-sample avg dev_std = 0.238)
NEC for r=0.3 all L1 = 0.15 +- 0.203 (in-sample avg dev_std = 0.238)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.812
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.806
NEC for r=0.6 class 0.0 = 0.137 +- 0.110 (in-sample avg dev_std = 0.161)
NEC for r=0.6 class 1.0 = 0.069 +- 0.110 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all KL = 0.054 +- 0.110 (in-sample avg dev_std = 0.161)
NEC for r=0.6 all L1 = 0.102 +- 0.143 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.807
NEC for r=0.9 class 0.0 = 0.079 +- 0.037 (in-sample avg dev_std = 0.080)
NEC for r=0.9 class 1.0 = 0.03 +- 0.037 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all KL = 0.015 +- 0.037 (in-sample avg dev_std = 0.080)
NEC for r=0.9 all L1 = 0.054 +- 0.084 (in-sample avg dev_std = 0.080)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.804
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.803
NEC for r=1.0 class 0.0 = 0.047 +- 0.031 (in-sample avg dev_std = 0.060)
NEC for r=1.0 class 1.0 = 0.02 +- 0.031 (in-sample avg dev_std = 0.060)
NEC for r=1.0 all KL = 0.008 +- 0.031 (in-sample avg dev_std = 0.060)
NEC for r=1.0 all L1 = 0.033 +- 0.065 (in-sample avg dev_std = 0.060)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:45:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:45:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 164...
[0m[1;37mINFO[0m: [1mCheckpoint 164: 
-----------------------------------
Train ACCURACY: 0.9998
Train Loss: 0.0007
ID Validation ACCURACY: 0.9172
ID Validation Loss: 0.4352
ID Test ACCURACY: 0.9164
ID Test Loss: 0.4480
OOD Validation ACCURACY: 0.8825
OOD Validation Loss: 0.4191
OOD Test ACCURACY: 0.8136
OOD Test Loss: 0.5985

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0007
ID Validation ACCURACY: 0.9161
ID Validation Loss: 0.4185
ID Test ACCURACY: 0.9178
ID Test Loss: 0.4294
OOD Validation ACCURACY: 0.8842
OOD Validation Loss: 0.3814
OOD Test ACCURACY: 0.8224
OOD Test Loss: 0.5053

[0m[1;37mINFO[0m: [1mChartInfo 0.9164 0.8136 0.9178 0.8224 0.9161 0.8842[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:45:37 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.843
SUFF++ for r=0.6 class 0.0 = 0.77 +- 0.331 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.6 class 1.0 = 0.903 +- 0.331 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.6 all KL = 0.711 +- 0.331 (in-sample avg dev_std = 0.442)
SUFF++ for r=0.6 all L1 = 0.848 +- 0.186 (in-sample avg dev_std = 0.442)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.906
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.895
SUFF++ for r=0.9 class 0.0 = 0.958 +- 0.073 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 class 1.0 = 0.982 +- 0.073 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all KL = 0.985 +- 0.073 (in-sample avg dev_std = 0.070)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.089 (in-sample avg dev_std = 0.070)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.678
SUFF++ for r=0.3 class 0.0 = 0.61 +- 0.360 (in-sample avg dev_std = 0.590)
SUFF++ for r=0.3 class 1.0 = 0.866 +- 0.360 (in-sample avg dev_std = 0.590)
SUFF++ for r=0.3 all KL = 0.565 +- 0.360 (in-sample avg dev_std = 0.590)
SUFF++ for r=0.3 all L1 = 0.742 +- 0.228 (in-sample avg dev_std = 0.590)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.804
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.742
SUFF++ for r=0.6 class 0.0 = 0.715 +- 0.269 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 class 1.0 = 0.917 +- 0.269 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all KL = 0.757 +- 0.269 (in-sample avg dev_std = 0.429)
SUFF++ for r=0.6 all L1 = 0.819 +- 0.193 (in-sample avg dev_std = 0.429)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.814
SUFF++ for r=0.9 class 0.0 = 0.891 +- 0.072 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 class 1.0 = 0.957 +- 0.072 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 all KL = 0.958 +- 0.072 (in-sample avg dev_std = 0.178)
SUFF++ for r=0.9 all L1 = 0.925 +- 0.104 (in-sample avg dev_std = 0.178)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.891
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.87
NEC for r=0.6 class 0.0 = 0.067 +- 0.166 (in-sample avg dev_std = 0.123)
NEC for r=0.6 class 1.0 = 0.046 +- 0.166 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all KL = 0.059 +- 0.166 (in-sample avg dev_std = 0.123)
NEC for r=0.6 all L1 = 0.055 +- 0.136 (in-sample avg dev_std = 0.123)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.888
NEC for r=0.9 class 0.0 = 0.04 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=0.9 class 1.0 = 0.019 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all KL = 0.017 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=0.9 all L1 = 0.028 +- 0.093 (in-sample avg dev_std = 0.070)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.902
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.888
NEC for r=1.0 class 0.0 = 0.041 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=1.0 class 1.0 = 0.019 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all KL = 0.017 +- 0.087 (in-sample avg dev_std = 0.070)
NEC for r=1.0 all L1 = 0.028 +- 0.093 (in-sample avg dev_std = 0.070)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.777
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.758
NEC for r=0.3 class 0.0 = 0.157 +- 0.211 (in-sample avg dev_std = 0.213)
NEC for r=0.3 class 1.0 = 0.035 +- 0.211 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all KL = 0.093 +- 0.211 (in-sample avg dev_std = 0.213)
NEC for r=0.3 all L1 = 0.094 +- 0.188 (in-sample avg dev_std = 0.213)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.804
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.8
NEC for r=0.6 class 0.0 = 0.102 +- 0.101 (in-sample avg dev_std = 0.126)
NEC for r=0.6 class 1.0 = 0.033 +- 0.101 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all KL = 0.038 +- 0.101 (in-sample avg dev_std = 0.126)
NEC for r=0.6 all L1 = 0.066 +- 0.126 (in-sample avg dev_std = 0.126)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.83
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.823
NEC for r=0.9 class 0.0 = 0.054 +- 0.037 (in-sample avg dev_std = 0.074)
NEC for r=0.9 class 1.0 = 0.03 +- 0.037 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all KL = 0.013 +- 0.037 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all L1 = 0.041 +- 0.078 (in-sample avg dev_std = 0.074)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.834
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.828
NEC for r=1.0 class 0.0 = 0.036 +- 0.026 (in-sample avg dev_std = 0.057)
NEC for r=1.0 class 1.0 = 0.021 +- 0.026 (in-sample avg dev_std = 0.057)
NEC for r=1.0 all KL = 0.007 +- 0.026 (in-sample avg dev_std = 0.057)
NEC for r=1.0 all L1 = 0.028 +- 0.060 (in-sample avg dev_std = 0.057)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:47:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 99...
[0m[1;37mINFO[0m: [1mCheckpoint 99: 
-----------------------------------
Train ACCURACY: 0.9987
Train Loss: 0.0071
ID Validation ACCURACY: 0.9149
ID Validation Loss: 0.3353
ID Test ACCURACY: 0.9098
ID Test Loss: 0.3559
OOD Validation ACCURACY: 0.8657
OOD Validation Loss: 0.3762
OOD Test ACCURACY: 0.7989
OOD Test Loss: 0.5418

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 115...
[0m[1;37mINFO[0m: [1mCheckpoint 115: 
-----------------------------------
Train ACCURACY: 0.9994
Train Loss: 0.0052
ID Validation ACCURACY: 0.9110
ID Validation Loss: 0.3513
ID Test ACCURACY: 0.9119
ID Test Loss: 0.3779
OOD Validation ACCURACY: 0.8795
OOD Validation Loss: 0.3487
OOD Test ACCURACY: 0.8314
OOD Test Loss: 0.4254

[0m[1;37mINFO[0m: [1mChartInfo 0.9098 0.7989 0.9119 0.8314 0.9110 0.8795[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:47:36 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.82
SUFF++ for r=0.6 class 0.0 = 0.773 +- 0.292 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1.0 = 0.879 +- 0.292 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.736 +- 0.292 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.835 +- 0.190 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.883
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.885
SUFF++ for r=0.9 class 0.0 = 0.953 +- 0.052 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 class 1.0 = 0.979 +- 0.052 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all KL = 0.986 +- 0.052 (in-sample avg dev_std = 0.080)
SUFF++ for r=0.9 all L1 = 0.967 +- 0.086 (in-sample avg dev_std = 0.080)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.827
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.717
SUFF++ for r=0.3 class 0.0 = 0.618 +- 0.299 (in-sample avg dev_std = 0.647)
SUFF++ for r=0.3 class 1.0 = 0.772 +- 0.299 (in-sample avg dev_std = 0.647)
SUFF++ for r=0.3 all KL = 0.483 +- 0.299 (in-sample avg dev_std = 0.647)
SUFF++ for r=0.3 all L1 = 0.697 +- 0.194 (in-sample avg dev_std = 0.647)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.766
SUFF++ for r=0.6 class 0.0 = 0.732 +- 0.204 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 1.0 = 0.881 +- 0.204 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all KL = 0.789 +- 0.204 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all L1 = 0.809 +- 0.170 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.803
SUFF++ for r=0.9 class 0.0 = 0.89 +- 0.050 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.050 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all KL = 0.97 +- 0.050 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all L1 = 0.924 +- 0.091 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.877
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.864
NEC for r=0.6 class 0.0 = 0.061 +- 0.127 (in-sample avg dev_std = 0.103)
NEC for r=0.6 class 1.0 = 0.05 +- 0.127 (in-sample avg dev_std = 0.103)
NEC for r=0.6 all KL = 0.041 +- 0.127 (in-sample avg dev_std = 0.103)
NEC for r=0.6 all L1 = 0.055 +- 0.142 (in-sample avg dev_std = 0.103)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.053 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=0.9 class 1.0 = 0.025 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all KL = 0.02 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=0.9 all L1 = 0.037 +- 0.104 (in-sample avg dev_std = 0.074)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.053 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=1.0 class 1.0 = 0.025 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all KL = 0.02 +- 0.083 (in-sample avg dev_std = 0.074)
NEC for r=1.0 all L1 = 0.037 +- 0.104 (in-sample avg dev_std = 0.074)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.827
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.82
NEC for r=0.3 class 0.0 = 0.119 +- 0.179 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1.0 = 0.066 +- 0.179 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.08 +- 0.179 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.091 +- 0.170 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.815
NEC for r=0.6 class 0.0 = 0.11 +- 0.090 (in-sample avg dev_std = 0.131)
NEC for r=0.6 class 1.0 = 0.054 +- 0.090 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all KL = 0.039 +- 0.090 (in-sample avg dev_std = 0.131)
NEC for r=0.6 all L1 = 0.081 +- 0.131 (in-sample avg dev_std = 0.131)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.815
NEC for r=0.9 class 0.0 = 0.071 +- 0.027 (in-sample avg dev_std = 0.071)
NEC for r=0.9 class 1.0 = 0.031 +- 0.027 (in-sample avg dev_std = 0.071)
NEC for r=0.9 all KL = 0.012 +- 0.027 (in-sample avg dev_std = 0.071)
NEC for r=0.9 all L1 = 0.051 +- 0.077 (in-sample avg dev_std = 0.071)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.82
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.818
NEC for r=1.0 class 0.0 = 0.041 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=1.0 class 1.0 = 0.019 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all KL = 0.005 +- 0.017 (in-sample avg dev_std = 0.050)
NEC for r=1.0 all L1 = 0.029 +- 0.054 (in-sample avg dev_std = 0.050)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:49:35 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0005
ID Validation ACCURACY: 0.9153
ID Validation Loss: 0.4322
ID Test ACCURACY: 0.9144
ID Test Loss: 0.5002
OOD Validation ACCURACY: 0.8788
OOD Validation Loss: 0.4087
OOD Test ACCURACY: 0.8256
OOD Test Loss: 0.4929

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 137...
[0m[1;37mINFO[0m: [1mCheckpoint 137: 
-----------------------------------
Train ACCURACY: 0.9997
Train Loss: 0.0030
ID Validation ACCURACY: 0.9117
ID Validation Loss: 0.3966
ID Test ACCURACY: 0.9117
ID Test Loss: 0.4474
OOD Validation ACCURACY: 0.8814
OOD Validation Loss: 0.3906
OOD Test ACCURACY: 0.8333
OOD Test Loss: 0.4454

[0m[1;37mINFO[0m: [1mChartInfo 0.9144 0.8256 0.9117 0.8333 0.9117 0.8814[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:49:36 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.814
SUFF++ for r=0.6 class 0.0 = 0.817 +- 0.358 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 class 1.0 = 0.805 +- 0.358 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 all KL = 0.618 +- 0.358 (in-sample avg dev_std = 0.511)
SUFF++ for r=0.6 all L1 = 0.81 +- 0.202 (in-sample avg dev_std = 0.511)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.889
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.874
SUFF++ for r=0.9 class 0.0 = 0.962 +- 0.095 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1.0 = 0.976 +- 0.095 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.978 +- 0.095 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.97 +- 0.095 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.804
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.705
SUFF++ for r=0.3 class 0.0 = 0.81 +- 0.332 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 class 1.0 = 0.63 +- 0.332 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all KL = 0.537 +- 0.332 (in-sample avg dev_std = 0.604)
SUFF++ for r=0.3 all L1 = 0.717 +- 0.198 (in-sample avg dev_std = 0.604)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.792
SUFF++ for r=0.6 class 0.0 = 0.828 +- 0.229 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 class 1.0 = 0.776 +- 0.229 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all KL = 0.746 +- 0.229 (in-sample avg dev_std = 0.422)
SUFF++ for r=0.6 all L1 = 0.801 +- 0.168 (in-sample avg dev_std = 0.422)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.844
SUFF++ for r=0.9 class 0.0 = 0.911 +- 0.053 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 class 1.0 = 0.945 +- 0.053 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all KL = 0.968 +- 0.053 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all L1 = 0.928 +- 0.095 (in-sample avg dev_std = 0.146)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.871
NEC for r=0.6 class 0.0 = 0.075 +- 0.177 (in-sample avg dev_std = 0.148)
NEC for r=0.6 class 1.0 = 0.05 +- 0.177 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all KL = 0.065 +- 0.177 (in-sample avg dev_std = 0.148)
NEC for r=0.6 all L1 = 0.06 +- 0.152 (in-sample avg dev_std = 0.148)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.882
NEC for r=0.9 class 0.0 = 0.032 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=0.9 class 1.0 = 0.024 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all KL = 0.02 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=0.9 all L1 = 0.028 +- 0.088 (in-sample avg dev_std = 0.068)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.882
NEC for r=1.0 class 0.0 = 0.032 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=1.0 class 1.0 = 0.024 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all KL = 0.02 +- 0.088 (in-sample avg dev_std = 0.068)
NEC for r=1.0 all L1 = 0.028 +- 0.088 (in-sample avg dev_std = 0.068)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.804
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.79
NEC for r=0.3 class 0.0 = 0.065 +- 0.176 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1.0 = 0.135 +- 0.176 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.084 +- 0.176 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.101 +- 0.174 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.839
NEC for r=0.6 class 0.0 = 0.068 +- 0.090 (in-sample avg dev_std = 0.140)
NEC for r=0.6 class 1.0 = 0.09 +- 0.090 (in-sample avg dev_std = 0.140)
NEC for r=0.6 all KL = 0.042 +- 0.090 (in-sample avg dev_std = 0.140)
NEC for r=0.6 all L1 = 0.079 +- 0.129 (in-sample avg dev_std = 0.140)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.854
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.849
NEC for r=0.9 class 0.0 = 0.054 +- 0.040 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 1.0 = 0.043 +- 0.040 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all KL = 0.015 +- 0.040 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all L1 = 0.048 +- 0.084 (in-sample avg dev_std = 0.085)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.847
NEC for r=1.0 class 0.0 = 0.038 +- 0.028 (in-sample avg dev_std = 0.056)
NEC for r=1.0 class 1.0 = 0.022 +- 0.028 (in-sample avg dev_std = 0.056)
NEC for r=1.0 all KL = 0.008 +- 0.028 (in-sample avg dev_std = 0.056)
NEC for r=1.0 all L1 = 0.03 +- 0.062 (in-sample avg dev_std = 0.056)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.691, 0.985, 1.0], 'all_L1': [0.826, 0.973, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.666, 0.98, 1.0], 'all_L1': [0.815, 0.963, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.711, 0.985, 1.0], 'all_L1': [0.848, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.736, 0.986, 1.0], 'all_L1': [0.835, 0.967, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.618, 0.978, 1.0], 'all_L1': [0.81, 0.97, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.041, 0.017, 0.017], 'all_L1': [0.044, 0.027, 0.027]}), defaultdict(<class 'list'>, {'all_KL': [0.096, 0.022, 0.021], 'all_L1': [0.091, 0.035, 0.034]}), defaultdict(<class 'list'>, {'all_KL': [0.059, 0.017, 0.017], 'all_L1': [0.055, 0.028, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.02, 0.02], 'all_L1': [0.055, 0.037, 0.037]}), defaultdict(<class 'list'>, {'all_KL': [0.065, 0.02, 0.02], 'all_L1': [0.06, 0.028, 0.028]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.703, 0.8, 0.967, 1.0], 'all_L1': [0.793, 0.819, 0.925, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.789, 0.967, 1.0], 'all_L1': [0.649, 0.797, 0.921, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.565, 0.757, 0.958, 1.0], 'all_L1': [0.742, 0.819, 0.925, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.483, 0.789, 0.97, 1.0], 'all_L1': [0.697, 0.809, 0.924, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.537, 0.746, 0.968, 1.0], 'all_L1': [0.717, 0.801, 0.928, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.064, 0.04, 0.01, 0.006], 'all_L1': [0.077, 0.076, 0.042, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.12, 0.054, 0.015, 0.008], 'all_L1': [0.15, 0.102, 0.054, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.093, 0.038, 0.013, 0.007], 'all_L1': [0.094, 0.066, 0.041, 0.028]}), defaultdict(<class 'list'>, {'all_KL': [0.08, 0.039, 0.012, 0.005], 'all_L1': [0.091, 0.081, 0.051, 0.029]}), defaultdict(<class 'list'>, {'all_KL': [0.084, 0.042, 0.015, 0.008], 'all_L1': [0.101, 0.079, 0.048, 0.03]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.827 +- 0.014, 0.969 +- 0.003, 1.000 +- 0.000
suff++ class all_KL  =  0.684 +- 0.040, 0.983 +- 0.003, 1.000 +- 0.000
suff++_acc_int  =  0.822 +- 0.011, 0.885 +- 0.007
nec class all_L1  =  0.061 +- 0.016, 0.031 +- 0.004, 0.031 +- 0.004
nec class all_KL  =  0.060 +- 0.020, 0.019 +- 0.002, 0.019 +- 0.002
nec_acc_int  =  0.867 +- 0.003, 0.879 +- 0.005, 0.879 +- 0.005

Eval split test
suff++ class all_L1  =  0.720 +- 0.048, 0.809 +- 0.009, 0.925 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.554 +- 0.081, 0.776 +- 0.021, 0.966 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.687 +- 0.025, 0.758 +- 0.023, 0.813 +- 0.017
nec class all_L1  =  0.103 +- 0.025, 0.081 +- 0.012, 0.047 +- 0.005, 0.030 +- 0.002
nec class all_KL  =  0.088 +- 0.018, 0.043 +- 0.006, 0.013 +- 0.002, 0.007 +- 0.001
nec_acc_int  =  0.774 +- 0.039, 0.806 +- 0.022, 0.823 +- 0.014, 0.824 +- 0.014


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.444 +- 0.008, 0.500 +- 0.001, 0.515 +- 0.002
Faith. Armon (L1)= 		  =  0.113 +- 0.027, 0.060 +- 0.008, 0.060 +- 0.007
Faith. GMean (L1)= 	  =  0.223 +- 0.027, 0.173 +- 0.011, 0.175 +- 0.011
Faith. Aritm (KL)= 		  =  0.372 +- 0.017, 0.501 +- 0.001, 0.509 +- 0.001
Faith. Armon (KL)= 		  =  0.110 +- 0.033, 0.038 +- 0.004, 0.037 +- 0.003
Faith. GMean (KL)= 	  =  0.200 +- 0.030, 0.137 +- 0.007, 0.138 +- 0.006

Eval split test
Faith. Aritm (L1)= 		  =  0.411 +- 0.014, 0.445 +- 0.003, 0.486 +- 0.002, 0.515 +- 0.001
Faith. Armon (L1)= 		  =  0.178 +- 0.035, 0.147 +- 0.019, 0.090 +- 0.009, 0.058 +- 0.003
Faith. GMean (L1)= 	  =  0.269 +- 0.023, 0.255 +- 0.017, 0.209 +- 0.011, 0.173 +- 0.005
Faith. Aritm (KL)= 		  =  0.321 +- 0.035, 0.409 +- 0.011, 0.489 +- 0.002, 0.503 +- 0.001
Faith. Armon (KL)= 		  =  0.150 +- 0.025, 0.081 +- 0.010, 0.026 +- 0.004, 0.014 +- 0.002
Faith. GMean (KL)= 	  =  0.218 +- 0.015, 0.181 +- 0.013, 0.112 +- 0.008, 0.082 +- 0.007
Computed for split load_split = id



Completed in  0:10:08.369295  for LECIGIN GOODSST2/length



DONE LECI GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:51:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 07:51:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0753
ID Validation ACCURACY: 0.8595
ID Validation Loss: 0.7797
ID Test ACCURACY: 0.8602
ID Test Loss: 0.8691
OOD Validation ACCURACY: 0.8551
OOD Validation Loss: 1.0470
OOD Test ACCURACY: 0.8144
OOD Test Loss: 1.2121

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 118...
[0m[1;37mINFO[0m: [1mCheckpoint 118: 
-----------------------------------
Train ACCURACY: 0.9463
Train Loss: 0.0867
ID Validation ACCURACY: 0.8510
ID Validation Loss: 0.5780
ID Test ACCURACY: 0.8459
ID Test Loss: 0.6869
OOD Validation ACCURACY: 0.8562
OOD Validation Loss: 0.6896
OOD Test ACCURACY: 0.8071
OOD Test Loss: 0.8209

[0m[1;37mINFO[0m: [1mChartInfo 0.8602 0.8144 0.8459 0.8071 0.8510 0.8562[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:51:51 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.829
SUFF++ for r=0.8 class 0.0 = 0.927 +- 0.295 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.8 class 1.0 = 0.857 +- 0.295 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.8 all KL = 0.788 +- 0.295 (in-sample avg dev_std = 0.354)
SUFF++ for r=0.8 all L1 = 0.886 +- 0.171 (in-sample avg dev_std = 0.354)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.822
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.797
SUFF++ for r=0.8 class 0.0 = 0.881 +- 0.242 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.8 class 1.0 = 0.856 +- 0.242 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.8 all KL = 0.821 +- 0.242 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.8 all L1 = 0.868 +- 0.184 (in-sample avg dev_std = 0.323)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.835
NEC for r=0.8 class 0.0 = 0.068 +- 0.208 (in-sample avg dev_std = 0.183)
NEC for r=0.8 class 1.0 = 0.082 +- 0.208 (in-sample avg dev_std = 0.183)
NEC for r=0.8 all KL = 0.086 +- 0.208 (in-sample avg dev_std = 0.183)
NEC for r=0.8 all L1 = 0.076 +- 0.170 (in-sample avg dev_std = 0.183)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.822
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.807
NEC for r=0.8 class 0.0 = 0.084 +- 0.194 (in-sample avg dev_std = 0.207)
NEC for r=0.8 class 1.0 = 0.108 +- 0.194 (in-sample avg dev_std = 0.207)
NEC for r=0.8 all KL = 0.095 +- 0.194 (in-sample avg dev_std = 0.207)
NEC for r=0.8 all L1 = 0.097 +- 0.177 (in-sample avg dev_std = 0.207)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:52:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8589
ID Validation Loss: 1.0551
ID Test ACCURACY: 0.8568
ID Test Loss: 1.1414
OOD Validation ACCURACY: 0.8585
OOD Validation Loss: 1.4193
OOD Test ACCURACY: 0.8148
OOD Test Loss: 1.5478

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8589
ID Validation Loss: 1.0551
ID Test ACCURACY: 0.8568
ID Test Loss: 1.1414
OOD Validation ACCURACY: 0.8585
OOD Validation Loss: 1.4193
OOD Test ACCURACY: 0.8148
OOD Test Loss: 1.5478

[0m[1;37mINFO[0m: [1mChartInfo 0.8568 0.8148 0.8568 0.8148 0.8589 0.8585[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:52:37 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.825
SUFF++ for r=0.8 class 0.0 = 0.92 +- 0.326 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.8 class 1.0 = 0.878 +- 0.326 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.8 all KL = 0.788 +- 0.326 (in-sample avg dev_std = 0.360)
SUFF++ for r=0.8 all L1 = 0.895 +- 0.181 (in-sample avg dev_std = 0.360)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.798
SUFF++ for r=0.8 class 0.0 = 0.894 +- 0.281 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.8 class 1.0 = 0.845 +- 0.281 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.8 all KL = 0.795 +- 0.281 (in-sample avg dev_std = 0.343)
SUFF++ for r=0.8 all L1 = 0.868 +- 0.196 (in-sample avg dev_std = 0.343)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.86
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.843
NEC for r=0.8 class 0.0 = 0.066 +- 0.237 (in-sample avg dev_std = 0.215)
NEC for r=0.8 class 1.0 = 0.081 +- 0.237 (in-sample avg dev_std = 0.215)
NEC for r=0.8 all KL = 0.097 +- 0.237 (in-sample avg dev_std = 0.215)
NEC for r=0.8 all L1 = 0.075 +- 0.186 (in-sample avg dev_std = 0.215)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.831
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.82
NEC for r=0.8 class 0.0 = 0.074 +- 0.208 (in-sample avg dev_std = 0.221)
NEC for r=0.8 class 1.0 = 0.102 +- 0.208 (in-sample avg dev_std = 0.221)
NEC for r=0.8 all KL = 0.096 +- 0.208 (in-sample avg dev_std = 0.221)
NEC for r=0.8 all L1 = 0.088 +- 0.178 (in-sample avg dev_std = 0.221)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:53:19 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 140...
[0m[1;37mINFO[0m: [1mCheckpoint 140: 
-----------------------------------
Train ACCURACY: 0.9486
Train Loss: 0.0789
ID Validation ACCURACY: 0.8576
ID Validation Loss: 0.6405
ID Test ACCURACY: 0.8581
ID Test Loss: 0.6827
OOD Validation ACCURACY: 0.8483
OOD Validation Loss: 0.8788
OOD Test ACCURACY: 0.7888
OOD Test Loss: 1.2864

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ACCURACY: 0.9444
Train Loss: 0.0955
ID Validation ACCURACY: 0.8453
ID Validation Loss: 0.4763
ID Test ACCURACY: 0.8466
ID Test Loss: 0.5186
OOD Validation ACCURACY: 0.8569
OOD Validation Loss: 0.5734
OOD Test ACCURACY: 0.7985
OOD Test Loss: 0.8428

[0m[1;37mINFO[0m: [1mChartInfo 0.8581 0.7888 0.8466 0.7985 0.8453 0.8569[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:53:20 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.87
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.85
SUFF++ for r=0.8 class 0.0 = 0.835 +- 0.248 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.8 class 1.0 = 0.941 +- 0.248 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.8 all KL = 0.839 +- 0.248 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.8 all L1 = 0.897 +- 0.159 (in-sample avg dev_std = 0.330)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.805
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.776
SUFF++ for r=0.8 class 0.0 = 0.778 +- 0.233 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.8 class 1.0 = 0.931 +- 0.233 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.8 all KL = 0.829 +- 0.233 (in-sample avg dev_std = 0.311)
SUFF++ for r=0.8 all L1 = 0.857 +- 0.192 (in-sample avg dev_std = 0.311)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.87
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.865
NEC for r=0.8 class 0.0 = 0.099 +- 0.162 (in-sample avg dev_std = 0.136)
NEC for r=0.8 class 1.0 = 0.039 +- 0.162 (in-sample avg dev_std = 0.136)
NEC for r=0.8 all KL = 0.068 +- 0.162 (in-sample avg dev_std = 0.136)
NEC for r=0.8 all L1 = 0.064 +- 0.137 (in-sample avg dev_std = 0.136)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.805
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.793
NEC for r=0.8 class 0.0 = 0.154 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.8 class 1.0 = 0.053 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.8 all KL = 0.09 +- 0.170 (in-sample avg dev_std = 0.192)
NEC for r=0.8 all L1 = 0.102 +- 0.171 (in-sample avg dev_std = 0.192)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:54:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 180...
[0m[1;37mINFO[0m: [1mCheckpoint 180: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8555
ID Validation Loss: 1.0889
ID Test ACCURACY: 0.8591
ID Test Loss: 1.1779
OOD Validation ACCURACY: 0.8291
OOD Validation Loss: 1.8486
OOD Test ACCURACY: 0.7282
OOD Test Loss: 3.5316

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 109...
[0m[1;37mINFO[0m: [1mCheckpoint 109: 
-----------------------------------
Train ACCURACY: 0.9418
Train Loss: 0.0951
ID Validation ACCURACY: 0.8398
ID Validation Loss: 0.7123
ID Test ACCURACY: 0.8421
ID Test Loss: 0.8161
OOD Validation ACCURACY: 0.8581
OOD Validation Loss: 0.8140
OOD Test ACCURACY: 0.8226
OOD Test Loss: 0.9192

[0m[1;37mINFO[0m: [1mChartInfo 0.8591 0.7282 0.8421 0.8226 0.8398 0.8581[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:54:04 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.842
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.832
SUFF++ for r=0.8 class 0.0 = 0.807 +- 0.347 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.8 class 1.0 = 0.953 +- 0.347 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.8 all KL = 0.763 +- 0.347 (in-sample avg dev_std = 0.369)
SUFF++ for r=0.8 all L1 = 0.892 +- 0.179 (in-sample avg dev_std = 0.369)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.735
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.697
SUFF++ for r=0.8 class 0.0 = 0.769 +- 0.309 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.8 class 1.0 = 0.974 +- 0.309 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.8 all KL = 0.809 +- 0.309 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.8 all L1 = 0.875 +- 0.210 (in-sample avg dev_std = 0.351)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.842
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.859
NEC for r=0.8 class 0.0 = 0.107 +- 0.228 (in-sample avg dev_std = 0.209)
NEC for r=0.8 class 1.0 = 0.027 +- 0.228 (in-sample avg dev_std = 0.209)
NEC for r=0.8 all KL = 0.086 +- 0.228 (in-sample avg dev_std = 0.209)
NEC for r=0.8 all L1 = 0.06 +- 0.161 (in-sample avg dev_std = 0.209)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.735
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.734
NEC for r=0.8 class 0.0 = 0.151 +- 0.223 (in-sample avg dev_std = 0.236)
NEC for r=0.8 class 1.0 = 0.024 +- 0.223 (in-sample avg dev_std = 0.236)
NEC for r=0.8 all KL = 0.098 +- 0.223 (in-sample avg dev_std = 0.236)
NEC for r=0.8 all L1 = 0.085 +- 0.182 (in-sample avg dev_std = 0.236)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:54:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8600
ID Validation Loss: 0.9380
ID Test ACCURACY: 0.8612
ID Test Loss: 1.0013
OOD Validation ACCURACY: 0.8654
OOD Validation Loss: 1.0363
OOD Test ACCURACY: 0.8221
OOD Test Loss: 1.1633

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8600
ID Validation Loss: 0.9380
ID Test ACCURACY: 0.8612
ID Test Loss: 1.0013
OOD Validation ACCURACY: 0.8654
OOD Validation Loss: 1.0363
OOD Test ACCURACY: 0.8221
OOD Test Loss: 1.1633

[0m[1;37mINFO[0m: [1mChartInfo 0.8612 0.8221 0.8612 0.8221 0.8600 0.8654[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:54:48 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.8 = nan
WIoU for r=0.8 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.877
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.855
SUFF++ for r=0.8 class 0.0 = 0.915 +- 0.323 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.8 class 1.0 = 0.903 +- 0.323 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.8 all KL = 0.794 +- 0.323 (in-sample avg dev_std = 0.342)
SUFF++ for r=0.8 all L1 = 0.908 +- 0.167 (in-sample avg dev_std = 0.342)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.832
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.817
SUFF++ for r=0.8 class 0.0 = 0.87 +- 0.258 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.8 class 1.0 = 0.875 +- 0.258 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.8 all KL = 0.809 +- 0.258 (in-sample avg dev_std = 0.328)
SUFF++ for r=0.8 all L1 = 0.872 +- 0.187 (in-sample avg dev_std = 0.328)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.877
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 285
Effective ratio: 0.796 +- 0.301
Model Accuracy over intervened graphs for r=0.8 =  0.874
NEC for r=0.8 class 0.0 = 0.065 +- 0.231 (in-sample avg dev_std = 0.214)
NEC for r=0.8 class 1.0 = 0.063 +- 0.231 (in-sample avg dev_std = 0.214)
NEC for r=0.8 all KL = 0.09 +- 0.231 (in-sample avg dev_std = 0.214)
NEC for r=0.8 all L1 = 0.064 +- 0.168 (in-sample avg dev_std = 0.214)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.8


Computing with masking

Model Accuracy of binarized graphs for r=0.8 =  0.832
Model XAI F1 of binarized graphs for r=0.8 =  nan
Model XAI WIoU of binarized graphs for r=0.8 =  nan
len(reference) = 800
Effective ratio: 0.810 +- 0.008
Model Accuracy over intervened graphs for r=0.8 =  0.832
NEC for r=0.8 class 0.0 = 0.088 +- 0.202 (in-sample avg dev_std = 0.226)
NEC for r=0.8 class 1.0 = 0.089 +- 0.202 (in-sample avg dev_std = 0.226)
NEC for r=0.8 all KL = 0.097 +- 0.202 (in-sample avg dev_std = 0.226)
NEC for r=0.8 all L1 = 0.088 +- 0.173 (in-sample avg dev_std = 0.226)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.788], 'all_L1': [0.886]}), defaultdict(<class 'list'>, {'all_KL': [0.788], 'all_L1': [0.895]}), defaultdict(<class 'list'>, {'all_KL': [0.839], 'all_L1': [0.897]}), defaultdict(<class 'list'>, {'all_KL': [0.763], 'all_L1': [0.892]}), defaultdict(<class 'list'>, {'all_KL': [0.794], 'all_L1': [0.908]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.086], 'all_L1': [0.076]}), defaultdict(<class 'list'>, {'all_KL': [0.097], 'all_L1': [0.075]}), defaultdict(<class 'list'>, {'all_KL': [0.068], 'all_L1': [0.064]}), defaultdict(<class 'list'>, {'all_KL': [0.086], 'all_L1': [0.06]}), defaultdict(<class 'list'>, {'all_KL': [0.09], 'all_L1': [0.064]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.821], 'all_L1': [0.868]}), defaultdict(<class 'list'>, {'all_KL': [0.795], 'all_L1': [0.868]}), defaultdict(<class 'list'>, {'all_KL': [0.829], 'all_L1': [0.857]}), defaultdict(<class 'list'>, {'all_KL': [0.809], 'all_L1': [0.875]}), defaultdict(<class 'list'>, {'all_KL': [0.809], 'all_L1': [0.872]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.095], 'all_L1': [0.097]}), defaultdict(<class 'list'>, {'all_KL': [0.096], 'all_L1': [0.088]}), defaultdict(<class 'list'>, {'all_KL': [0.09], 'all_L1': [0.102]}), defaultdict(<class 'list'>, {'all_KL': [0.098], 'all_L1': [0.085]}), defaultdict(<class 'list'>, {'all_KL': [0.097], 'all_L1': [0.088]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.896 +- 0.007
suff++ class all_KL  =  0.794 +- 0.025
suff++_acc_int  =  0.838 +- 0.012
nec class all_L1  =  0.068 +- 0.006
nec class all_KL  =  0.085 +- 0.010
nec_acc_int  =  0.855 +- 0.014

Eval split test
suff++ class all_L1  =  0.868 +- 0.006
suff++ class all_KL  =  0.813 +- 0.012
suff++_acc_int  =  0.777 +- 0.042
nec class all_L1  =  0.092 +- 0.006
nec class all_KL  =  0.095 +- 0.003
nec_acc_int  =  0.797 +- 0.034


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.482 +- 0.004
Faith. Armon (L1)= 		  =  0.126 +- 0.011
Faith. GMean (L1)= 	  =  0.246 +- 0.011
Faith. Aritm (KL)= 		  =  0.440 +- 0.009
Faith. Armon (KL)= 		  =  0.154 +- 0.016
Faith. GMean (KL)= 	  =  0.260 +- 0.013

Eval split test
Faith. Aritm (L1)= 		  =  0.480 +- 0.001
Faith. Armon (L1)= 		  =  0.166 +- 0.010
Faith. GMean (L1)= 	  =  0.282 +- 0.009
Faith. Aritm (KL)= 		  =  0.454 +- 0.005
Faith. Armon (KL)= 		  =  0.170 +- 0.004
Faith. GMean (KL)= 	  =  0.278 +- 0.003
Computed for split load_split = id



Completed in  0:03:45.179585  for CIGAGIN GOODSST2/length



DONE CIGA GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:55:47 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 07:55:48 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9108
ID Validation Loss: 0.6777
ID Test ACCURACY: 0.9070
ID Test Loss: 0.7678
OOD Validation ACCURACY: 0.8696
OOD Validation Loss: 0.8953
OOD Test ACCURACY: 0.8189
OOD Test Loss: 1.1731

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9085
ID Validation Loss: 0.6426
ID Test ACCURACY: 0.9093
ID Test Loss: 0.7163
OOD Validation ACCURACY: 0.8700
OOD Validation Loss: 0.8695
OOD Test ACCURACY: 0.8171
OOD Test Loss: 1.1992

[0m[1;37mINFO[0m: [1mChartInfo 0.9070 0.8189 0.9093 0.8171 0.9085 0.8700[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:55:49 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.819
SUFF++ for r=0.6 class 0.0 = 0.845 +- 0.366 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.6 class 1.0 = 0.782 +- 0.366 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.6 all KL = 0.612 +- 0.366 (in-sample avg dev_std = 0.497)
SUFF++ for r=0.6 all L1 = 0.808 +- 0.211 (in-sample avg dev_std = 0.497)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.872
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.863
SUFF++ for r=0.9 class 0.0 = 0.937 +- 0.144 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 class 1.0 = 0.965 +- 0.144 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 all KL = 0.957 +- 0.144 (in-sample avg dev_std = 0.114)
SUFF++ for r=0.9 all L1 = 0.952 +- 0.135 (in-sample avg dev_std = 0.114)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.734
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.66
SUFF++ for r=0.3 class 0.0 = 0.91 +- 0.379 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 class 1.0 = 0.636 +- 0.379 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all KL = 0.599 +- 0.379 (in-sample avg dev_std = 0.553)
SUFF++ for r=0.3 all L1 = 0.769 +- 0.231 (in-sample avg dev_std = 0.553)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.767
SUFF++ for r=0.6 class 0.0 = 0.874 +- 0.327 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 1.0 = 0.726 +- 0.327 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all KL = 0.652 +- 0.327 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all L1 = 0.798 +- 0.196 (in-sample avg dev_std = 0.492)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.835
SUFF++ for r=0.9 class 0.0 = 0.922 +- 0.138 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 class 1.0 = 0.932 +- 0.138 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 all KL = 0.935 +- 0.138 (in-sample avg dev_std = 0.192)
SUFF++ for r=0.9 all L1 = 0.927 +- 0.139 (in-sample avg dev_std = 0.192)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.876
NEC for r=0.6 class 0.0 = 0.112 +- 0.224 (in-sample avg dev_std = 0.201)
NEC for r=0.6 class 1.0 = 0.068 +- 0.224 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all KL = 0.094 +- 0.224 (in-sample avg dev_std = 0.201)
NEC for r=0.6 all L1 = 0.086 +- 0.191 (in-sample avg dev_std = 0.201)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.875
NEC for r=0.9 class 0.0 = 0.067 +- 0.133 (in-sample avg dev_std = 0.121)
NEC for r=0.9 class 1.0 = 0.026 +- 0.133 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all KL = 0.039 +- 0.133 (in-sample avg dev_std = 0.121)
NEC for r=0.9 all L1 = 0.043 +- 0.130 (in-sample avg dev_std = 0.121)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.888
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.061 +- 0.139 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 1.0 = 0.023 +- 0.139 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all KL = 0.039 +- 0.139 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all L1 = 0.039 +- 0.124 (in-sample avg dev_std = 0.122)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.734
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.732
NEC for r=0.3 class 0.0 = 0.038 +- 0.182 (in-sample avg dev_std = 0.194)
NEC for r=0.3 class 1.0 = 0.125 +- 0.182 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all KL = 0.079 +- 0.182 (in-sample avg dev_std = 0.194)
NEC for r=0.3 all L1 = 0.083 +- 0.170 (in-sample avg dev_std = 0.194)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.829
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.819
NEC for r=0.6 class 0.0 = 0.063 +- 0.160 (in-sample avg dev_std = 0.182)
NEC for r=0.6 class 1.0 = 0.1 +- 0.160 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all KL = 0.068 +- 0.160 (in-sample avg dev_std = 0.182)
NEC for r=0.6 all L1 = 0.082 +- 0.162 (in-sample avg dev_std = 0.182)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.85
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.839
NEC for r=0.9 class 0.0 = 0.07 +- 0.126 (in-sample avg dev_std = 0.142)
NEC for r=0.9 class 1.0 = 0.056 +- 0.126 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all KL = 0.048 +- 0.126 (in-sample avg dev_std = 0.142)
NEC for r=0.9 all L1 = 0.063 +- 0.137 (in-sample avg dev_std = 0.142)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.839
NEC for r=1.0 class 0.0 = 0.067 +- 0.122 (in-sample avg dev_std = 0.132)
NEC for r=1.0 class 1.0 = 0.039 +- 0.122 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all KL = 0.043 +- 0.122 (in-sample avg dev_std = 0.132)
NEC for r=1.0 all L1 = 0.053 +- 0.125 (in-sample avg dev_std = 0.132)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 19:57:56 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:57 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:57 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 07:57:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:57 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:58 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 07:57:58 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 07:57:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9106
ID Validation Loss: 0.6509
ID Test ACCURACY: 0.9106
ID Test Loss: 0.7601
OOD Validation ACCURACY: 0.8655
OOD Validation Loss: 0.9153
OOD Test ACCURACY: 0.8004
OOD Test Loss: 1.3538

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9081
ID Validation Loss: 0.6904
ID Test ACCURACY: 0.9102
ID Test Loss: 0.8084
OOD Validation ACCURACY: 0.8689
OOD Validation Loss: 1.0019
OOD Test ACCURACY: 0.8170
OOD Test Loss: 1.3197

[0m[1;37mINFO[0m: [1mChartInfo 0.9106 0.8004 0.9102 0.8170 0.9081 0.8689[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 07:57:58 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.823
SUFF++ for r=0.6 class 0.0 = 0.811 +- 0.375 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 class 1.0 = 0.815 +- 0.375 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all KL = 0.61 +- 0.375 (in-sample avg dev_std = 0.498)
SUFF++ for r=0.6 all L1 = 0.813 +- 0.206 (in-sample avg dev_std = 0.498)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.894
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.893
SUFF++ for r=0.9 class 0.0 = 0.947 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 class 1.0 = 0.974 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all KL = 0.966 +- 0.136 (in-sample avg dev_std = 0.107)
SUFF++ for r=0.9 all L1 = 0.962 +- 0.114 (in-sample avg dev_std = 0.107)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.715
SUFF++ for r=0.3 class 0.0 = 0.633 +- 0.329 (in-sample avg dev_std = 0.726)
SUFF++ for r=0.3 class 1.0 = 0.711 +- 0.329 (in-sample avg dev_std = 0.726)
SUFF++ for r=0.3 all KL = 0.309 +- 0.329 (in-sample avg dev_std = 0.726)
SUFF++ for r=0.3 all L1 = 0.673 +- 0.200 (in-sample avg dev_std = 0.726)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.738 +- 0.346 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 class 1.0 = 0.847 +- 0.346 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all KL = 0.608 +- 0.346 (in-sample avg dev_std = 0.508)
SUFF++ for r=0.6 all L1 = 0.795 +- 0.200 (in-sample avg dev_std = 0.508)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0.0 = 0.888 +- 0.131 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 1.0 = 0.961 +- 0.131 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all KL = 0.934 +- 0.131 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all L1 = 0.926 +- 0.142 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.884
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.871
NEC for r=0.6 class 0.0 = 0.098 +- 0.233 (in-sample avg dev_std = 0.202)
NEC for r=0.6 class 1.0 = 0.067 +- 0.233 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all KL = 0.099 +- 0.233 (in-sample avg dev_std = 0.202)
NEC for r=0.6 all L1 = 0.08 +- 0.177 (in-sample avg dev_std = 0.202)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.884
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.883
NEC for r=0.9 class 0.0 = 0.047 +- 0.131 (in-sample avg dev_std = 0.091)
NEC for r=0.9 class 1.0 = 0.034 +- 0.131 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all KL = 0.035 +- 0.131 (in-sample avg dev_std = 0.091)
NEC for r=0.9 all L1 = 0.039 +- 0.123 (in-sample avg dev_std = 0.091)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.898
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.884
NEC for r=1.0 class 0.0 = 0.052 +- 0.142 (in-sample avg dev_std = 0.108)
NEC for r=1.0 class 1.0 = 0.034 +- 0.142 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all KL = 0.04 +- 0.142 (in-sample avg dev_std = 0.108)
NEC for r=1.0 all L1 = 0.041 +- 0.132 (in-sample avg dev_std = 0.108)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.824
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.815
NEC for r=0.3 class 0.0 = 0.147 +- 0.287 (in-sample avg dev_std = 0.286)
NEC for r=0.3 class 1.0 = 0.08 +- 0.287 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all KL = 0.156 +- 0.287 (in-sample avg dev_std = 0.286)
NEC for r=0.3 all L1 = 0.113 +- 0.214 (in-sample avg dev_std = 0.286)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.853
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.835
NEC for r=0.6 class 0.0 = 0.11 +- 0.177 (in-sample avg dev_std = 0.195)
NEC for r=0.6 class 1.0 = 0.056 +- 0.177 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all KL = 0.081 +- 0.177 (in-sample avg dev_std = 0.195)
NEC for r=0.6 all L1 = 0.082 +- 0.163 (in-sample avg dev_std = 0.195)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.829
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.822
NEC for r=0.9 class 0.0 = 0.09 +- 0.118 (in-sample avg dev_std = 0.143)
NEC for r=0.9 class 1.0 = 0.038 +- 0.118 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all KL = 0.046 +- 0.118 (in-sample avg dev_std = 0.143)
NEC for r=0.9 all L1 = 0.063 +- 0.138 (in-sample avg dev_std = 0.143)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.83
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.82
NEC for r=1.0 class 0.0 = 0.086 +- 0.128 (in-sample avg dev_std = 0.147)
NEC for r=1.0 class 1.0 = 0.038 +- 0.128 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all KL = 0.046 +- 0.128 (in-sample avg dev_std = 0.147)
NEC for r=1.0 all L1 = 0.061 +- 0.140 (in-sample avg dev_std = 0.147)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:00:03 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 181...
[0m[1;37mINFO[0m: [1mCheckpoint 181: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0003
ID Validation ACCURACY: 0.9083
ID Validation Loss: 0.6573
ID Test ACCURACY: 0.9010
ID Test Loss: 0.7687
OOD Validation ACCURACY: 0.8624
OOD Validation Loss: 0.9332
OOD Test ACCURACY: 0.7946
OOD Test Loss: 1.4098

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9986
Train Loss: 0.0061
ID Validation ACCURACY: 0.9002
ID Validation Loss: 0.5441
ID Test ACCURACY: 0.9019
ID Test Loss: 0.6312
OOD Validation ACCURACY: 0.8690
OOD Validation Loss: 0.7354
OOD Test ACCURACY: 0.8188
OOD Test Loss: 0.9821

[0m[1;37mINFO[0m: [1mChartInfo 0.9010 0.7946 0.9019 0.8188 0.9002 0.8690[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 08:00:04 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.801
SUFF++ for r=0.6 class 0.0 = 0.679 +- 0.370 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 class 1.0 = 0.937 +- 0.370 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all KL = 0.68 +- 0.370 (in-sample avg dev_std = 0.460)
SUFF++ for r=0.6 all L1 = 0.829 +- 0.222 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.877
SUFF++ for r=0.9 class 0.0 = 0.913 +- 0.135 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 class 1.0 = 0.966 +- 0.135 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all KL = 0.954 +- 0.135 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.9 all L1 = 0.943 +- 0.146 (in-sample avg dev_std = 0.142)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.59
SUFF++ for r=0.3 class 0.0 = 0.757 +- 0.309 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 1.0 = 0.968 +- 0.309 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all KL = 0.816 +- 0.309 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all L1 = 0.866 +- 0.223 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.648
SUFF++ for r=0.6 class 0.0 = 0.718 +- 0.305 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 class 1.0 = 0.972 +- 0.305 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all KL = 0.8 +- 0.305 (in-sample avg dev_std = 0.394)
SUFF++ for r=0.6 all L1 = 0.849 +- 0.217 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.791
SUFF++ for r=0.9 class 0.0 = 0.869 +- 0.164 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 class 1.0 = 0.971 +- 0.164 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all KL = 0.926 +- 0.164 (in-sample avg dev_std = 0.203)
SUFF++ for r=0.9 all L1 = 0.922 +- 0.155 (in-sample avg dev_std = 0.203)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.86
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.851
NEC for r=0.6 class 0.0 = 0.154 +- 0.244 (in-sample avg dev_std = 0.191)
NEC for r=0.6 class 1.0 = 0.037 +- 0.244 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all KL = 0.097 +- 0.244 (in-sample avg dev_std = 0.191)
NEC for r=0.6 all L1 = 0.086 +- 0.206 (in-sample avg dev_std = 0.191)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.881
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.878
NEC for r=0.9 class 0.0 = 0.081 +- 0.141 (in-sample avg dev_std = 0.132)
NEC for r=0.9 class 1.0 = 0.029 +- 0.141 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all KL = 0.042 +- 0.141 (in-sample avg dev_std = 0.132)
NEC for r=0.9 all L1 = 0.051 +- 0.144 (in-sample avg dev_std = 0.132)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.879
NEC for r=1.0 class 0.0 = 0.076 +- 0.147 (in-sample avg dev_std = 0.122)
NEC for r=1.0 class 1.0 = 0.027 +- 0.147 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all KL = 0.042 +- 0.147 (in-sample avg dev_std = 0.122)
NEC for r=1.0 all L1 = 0.047 +- 0.142 (in-sample avg dev_std = 0.122)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.634
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.634
NEC for r=0.3 class 0.0 = 0.147 +- 0.196 (in-sample avg dev_std = 0.193)
NEC for r=0.3 class 1.0 = 0.02 +- 0.196 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all KL = 0.084 +- 0.196 (in-sample avg dev_std = 0.193)
NEC for r=0.3 all L1 = 0.081 +- 0.176 (in-sample avg dev_std = 0.193)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.714
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.699
NEC for r=0.6 class 0.0 = 0.143 +- 0.149 (in-sample avg dev_std = 0.178)
NEC for r=0.6 class 1.0 = 0.015 +- 0.149 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all KL = 0.063 +- 0.149 (in-sample avg dev_std = 0.178)
NEC for r=0.6 all L1 = 0.077 +- 0.157 (in-sample avg dev_std = 0.178)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.798
NEC for r=0.9 class 0.0 = 0.12 +- 0.161 (in-sample avg dev_std = 0.174)
NEC for r=0.9 class 1.0 = 0.027 +- 0.161 (in-sample avg dev_std = 0.174)
NEC for r=0.9 all KL = 0.063 +- 0.161 (in-sample avg dev_std = 0.174)
NEC for r=0.9 all L1 = 0.072 +- 0.156 (in-sample avg dev_std = 0.174)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.824
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.811
NEC for r=1.0 class 0.0 = 0.095 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 class 1.0 = 0.03 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all KL = 0.049 +- 0.136 (in-sample avg dev_std = 0.152)
NEC for r=1.0 all L1 = 0.061 +- 0.141 (in-sample avg dev_std = 0.152)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:02:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 189...
[0m[1;37mINFO[0m: [1mCheckpoint 189: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9123
ID Validation Loss: 0.7334
ID Test ACCURACY: 0.9047
ID Test Loss: 0.8153
OOD Validation ACCURACY: 0.8584
OOD Validation Loss: 1.0858
OOD Test ACCURACY: 0.8021
OOD Test Loss: 1.6001

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 192...
[0m[1;37mINFO[0m: [1mCheckpoint 192: 
-----------------------------------
Train ACCURACY: 1.0000
Train Loss: 0.0001
ID Validation ACCURACY: 0.9091
ID Validation Loss: 0.7365
ID Test ACCURACY: 0.9076
ID Test Loss: 0.8317
OOD Validation ACCURACY: 0.8656
OOD Validation Loss: 1.0826
OOD Test ACCURACY: 0.8208
OOD Test Loss: 1.3300

[0m[1;37mINFO[0m: [1mChartInfo 0.9047 0.8021 0.9076 0.8208 0.9091 0.8656[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 08:02:07 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.776
SUFF++ for r=0.6 class 0.0 = 0.704 +- 0.386 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 class 1.0 = 0.899 +- 0.386 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all KL = 0.657 +- 0.386 (in-sample avg dev_std = 0.468)
SUFF++ for r=0.6 all L1 = 0.817 +- 0.230 (in-sample avg dev_std = 0.468)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.878
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.878
SUFF++ for r=0.9 class 0.0 = 0.945 +- 0.129 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.9 class 1.0 = 0.972 +- 0.129 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.9 all KL = 0.957 +- 0.129 (in-sample avg dev_std = 0.126)
SUFF++ for r=0.9 all L1 = 0.96 +- 0.120 (in-sample avg dev_std = 0.126)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.671
SUFF++ for r=0.3 class 0.0 = 0.58 +- 0.407 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 class 1.0 = 0.854 +- 0.407 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 all KL = 0.466 +- 0.407 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.3 all L1 = 0.721 +- 0.241 (in-sample avg dev_std = 0.641)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.724
SUFF++ for r=0.6 class 0.0 = 0.696 +- 0.383 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 class 1.0 = 0.939 +- 0.383 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 all KL = 0.678 +- 0.383 (in-sample avg dev_std = 0.473)
SUFF++ for r=0.6 all L1 = 0.821 +- 0.229 (in-sample avg dev_std = 0.473)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.797
SUFF++ for r=0.9 class 0.0 = 0.872 +- 0.206 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 class 1.0 = 0.963 +- 0.206 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all KL = 0.901 +- 0.206 (in-sample avg dev_std = 0.246)
SUFF++ for r=0.9 all L1 = 0.919 +- 0.163 (in-sample avg dev_std = 0.246)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.846
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.832
NEC for r=0.6 class 0.0 = 0.129 +- 0.252 (in-sample avg dev_std = 0.230)
NEC for r=0.6 class 1.0 = 0.051 +- 0.252 (in-sample avg dev_std = 0.230)
NEC for r=0.6 all KL = 0.107 +- 0.252 (in-sample avg dev_std = 0.230)
NEC for r=0.6 all L1 = 0.083 +- 0.190 (in-sample avg dev_std = 0.230)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.877
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.873
NEC for r=0.9 class 0.0 = 0.053 +- 0.136 (in-sample avg dev_std = 0.117)
NEC for r=0.9 class 1.0 = 0.024 +- 0.136 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all KL = 0.037 +- 0.136 (in-sample avg dev_std = 0.117)
NEC for r=0.9 all L1 = 0.036 +- 0.122 (in-sample avg dev_std = 0.117)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.881
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.875
NEC for r=1.0 class 0.0 = 0.052 +- 0.132 (in-sample avg dev_std = 0.119)
NEC for r=1.0 class 1.0 = 0.019 +- 0.132 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all KL = 0.032 +- 0.132 (in-sample avg dev_std = 0.119)
NEC for r=1.0 all L1 = 0.033 +- 0.119 (in-sample avg dev_std = 0.119)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.79
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.76
NEC for r=0.3 class 0.0 = 0.2 +- 0.310 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 1.0 = 0.051 +- 0.310 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all KL = 0.176 +- 0.310 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all L1 = 0.123 +- 0.219 (in-sample avg dev_std = 0.314)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.772
NEC for r=0.6 class 0.0 = 0.16 +- 0.254 (in-sample avg dev_std = 0.262)
NEC for r=0.6 class 1.0 = 0.038 +- 0.254 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all KL = 0.119 +- 0.254 (in-sample avg dev_std = 0.262)
NEC for r=0.6 all L1 = 0.097 +- 0.202 (in-sample avg dev_std = 0.262)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.809
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.804
NEC for r=0.9 class 0.0 = 0.12 +- 0.197 (in-sample avg dev_std = 0.201)
NEC for r=0.9 class 1.0 = 0.03 +- 0.197 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all KL = 0.079 +- 0.197 (in-sample avg dev_std = 0.201)
NEC for r=0.9 all L1 = 0.073 +- 0.170 (in-sample avg dev_std = 0.201)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.821
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.819
NEC for r=1.0 class 0.0 = 0.08 +- 0.145 (in-sample avg dev_std = 0.146)
NEC for r=1.0 class 1.0 = 0.03 +- 0.145 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all KL = 0.049 +- 0.145 (in-sample avg dev_std = 0.146)
NEC for r=1.0 all L1 = 0.055 +- 0.143 (in-sample avg dev_std = 0.146)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:04:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 179...
[0m[1;37mINFO[0m: [1mCheckpoint 179: 
-----------------------------------
Train ACCURACY: 0.9999
Train Loss: 0.0002
ID Validation ACCURACY: 0.9125
ID Validation Loss: 0.6781
ID Test ACCURACY: 0.9078
ID Test Loss: 0.7621
OOD Validation ACCURACY: 0.8649
OOD Validation Loss: 0.8836
OOD Test ACCURACY: 0.8196
OOD Test Loss: 1.0439

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 141...
[0m[1;37mINFO[0m: [1mCheckpoint 141: 
-----------------------------------
Train ACCURACY: 0.9983
Train Loss: 0.0070
ID Validation ACCURACY: 0.9044
ID Validation Loss: 0.4896
ID Test ACCURACY: 0.9053
ID Test Loss: 0.5898
OOD Validation ACCURACY: 0.8681
OOD Validation Loss: 0.7049
OOD Test ACCURACY: 0.8276
OOD Test Loss: 0.8462

[0m[1;37mINFO[0m: [1mChartInfo 0.9078 0.8196 0.9053 0.8276 0.9044 0.8681[0mGOODSST2(5301)
Data example from id_val: Data(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
Label distribution from id_val: (tensor([0., 1.]), tensor([2144, 3157]))
[1;34mDEBUG[0m: 09/28/2024 08:04:08 PM : [1mUnbalanced warning for GOODSST2 (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.794
SUFF++ for r=0.6 class 0.0 = 0.731 +- 0.370 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 class 1.0 = 0.86 +- 0.370 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 all KL = 0.626 +- 0.370 (in-sample avg dev_std = 0.465)
SUFF++ for r=0.6 all L1 = 0.806 +- 0.225 (in-sample avg dev_std = 0.465)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.9
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 180
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.881
SUFF++ for r=0.9 class 0.0 = 0.934 +- 0.155 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.953 +- 0.155 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.951 +- 0.155 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.945 +- 0.144 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.708
SUFF++ for r=0.3 class 0.0 = 0.627 +- 0.294 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 class 1.0 = 0.708 +- 0.294 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 all KL = 0.443 +- 0.294 (in-sample avg dev_std = 0.622)
SUFF++ for r=0.3 all L1 = 0.669 +- 0.187 (in-sample avg dev_std = 0.622)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.737
SUFF++ for r=0.6 class 0.0 = 0.682 +- 0.286 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1.0 = 0.874 +- 0.286 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.685 +- 0.286 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.781 +- 0.202 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.824
SUFF++ for r=0.9 class 0.0 = 0.878 +- 0.141 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 class 1.0 = 0.946 +- 0.141 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 all KL = 0.926 +- 0.141 (in-sample avg dev_std = 0.202)
SUFF++ for r=0.9 all L1 = 0.913 +- 0.152 (in-sample avg dev_std = 0.202)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.849
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 285
Effective ratio: 0.647 +- 0.269
Model Accuracy over intervened graphs for r=0.6 =  0.835
NEC for r=0.6 class 0.0 = 0.127 +- 0.258 (in-sample avg dev_std = 0.199)
NEC for r=0.6 class 1.0 = 0.079 +- 0.258 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all KL = 0.117 +- 0.258 (in-sample avg dev_std = 0.199)
NEC for r=0.6 all L1 = 0.099 +- 0.209 (in-sample avg dev_std = 0.199)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.891
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 285
Effective ratio: 0.862 +- 0.317
Model Accuracy over intervened graphs for r=0.9 =  0.881
NEC for r=0.9 class 0.0 = 0.051 +- 0.135 (in-sample avg dev_std = 0.111)
NEC for r=0.9 class 1.0 = 0.037 +- 0.135 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all KL = 0.037 +- 0.135 (in-sample avg dev_std = 0.111)
NEC for r=0.9 all L1 = 0.043 +- 0.128 (in-sample avg dev_std = 0.111)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.891
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 285
Effective ratio: 0.882 +- 0.322
Model Accuracy over intervened graphs for r=1.0 =  0.877
NEC for r=1.0 class 0.0 = 0.045 +- 0.150 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.043 +- 0.150 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.042 +- 0.150 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.043 +- 0.139 (in-sample avg dev_std = 0.125)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.801
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.776
NEC for r=0.3 class 0.0 = 0.2 +- 0.271 (in-sample avg dev_std = 0.314)
NEC for r=0.3 class 1.0 = 0.152 +- 0.271 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all KL = 0.19 +- 0.271 (in-sample avg dev_std = 0.314)
NEC for r=0.3 all L1 = 0.175 +- 0.227 (in-sample avg dev_std = 0.314)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.788
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.783
NEC for r=0.6 class 0.0 = 0.174 +- 0.179 (in-sample avg dev_std = 0.225)
NEC for r=0.6 class 1.0 = 0.077 +- 0.179 (in-sample avg dev_std = 0.225)
NEC for r=0.6 all KL = 0.104 +- 0.179 (in-sample avg dev_std = 0.225)
NEC for r=0.6 all L1 = 0.124 +- 0.188 (in-sample avg dev_std = 0.225)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.825
NEC for r=0.9 class 0.0 = 0.108 +- 0.137 (in-sample avg dev_std = 0.164)
NEC for r=0.9 class 1.0 = 0.05 +- 0.137 (in-sample avg dev_std = 0.164)
NEC for r=0.9 all KL = 0.058 +- 0.137 (in-sample avg dev_std = 0.164)
NEC for r=0.9 all L1 = 0.078 +- 0.156 (in-sample avg dev_std = 0.164)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.854
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.841
NEC for r=1.0 class 0.0 = 0.069 +- 0.111 (in-sample avg dev_std = 0.130)
NEC for r=1.0 class 1.0 = 0.042 +- 0.111 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all KL = 0.039 +- 0.111 (in-sample avg dev_std = 0.130)
NEC for r=1.0 all L1 = 0.055 +- 0.125 (in-sample avg dev_std = 0.130)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.612, 0.957, 1.0], 'all_L1': [0.808, 0.952, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.61, 0.966, 1.0], 'all_L1': [0.813, 0.962, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.68, 0.954, 1.0], 'all_L1': [0.829, 0.943, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.657, 0.957, 1.0], 'all_L1': [0.817, 0.96, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.626, 0.951, 1.0], 'all_L1': [0.806, 0.945, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.094, 0.039, 0.039], 'all_L1': [0.086, 0.043, 0.039]}), defaultdict(<class 'list'>, {'all_KL': [0.099, 0.035, 0.04], 'all_L1': [0.08, 0.039, 0.041]}), defaultdict(<class 'list'>, {'all_KL': [0.097, 0.042, 0.042], 'all_L1': [0.086, 0.051, 0.047]}), defaultdict(<class 'list'>, {'all_KL': [0.107, 0.037, 0.032], 'all_L1': [0.083, 0.036, 0.033]}), defaultdict(<class 'list'>, {'all_KL': [0.117, 0.037, 0.042], 'all_L1': [0.099, 0.043, 0.043]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.599, 0.652, 0.935, 1.0], 'all_L1': [0.769, 0.798, 0.927, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.309, 0.608, 0.934, 1.0], 'all_L1': [0.673, 0.795, 0.926, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.816, 0.8, 0.926, 1.0], 'all_L1': [0.866, 0.849, 0.922, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.466, 0.678, 0.901, 1.0], 'all_L1': [0.721, 0.821, 0.919, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.443, 0.685, 0.926, 1.0], 'all_L1': [0.669, 0.781, 0.913, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.079, 0.068, 0.048, 0.043], 'all_L1': [0.083, 0.082, 0.063, 0.053]}), defaultdict(<class 'list'>, {'all_KL': [0.156, 0.081, 0.046, 0.046], 'all_L1': [0.113, 0.082, 0.063, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.084, 0.063, 0.063, 0.049], 'all_L1': [0.081, 0.077, 0.072, 0.061]}), defaultdict(<class 'list'>, {'all_KL': [0.176, 0.119, 0.079, 0.049], 'all_L1': [0.123, 0.097, 0.073, 0.055]}), defaultdict(<class 'list'>, {'all_KL': [0.19, 0.104, 0.058, 0.039], 'all_L1': [0.175, 0.124, 0.078, 0.055]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.815 +- 0.008, 0.952 +- 0.008, 1.000 +- 0.000
suff++ class all_KL  =  0.637 +- 0.027, 0.957 +- 0.005, 1.000 +- 0.000
suff++_acc_int  =  0.803 +- 0.017, 0.878 +- 0.010
nec class all_L1  =  0.087 +- 0.006, 0.042 +- 0.005, 0.041 +- 0.005
nec class all_KL  =  0.103 +- 0.008, 0.038 +- 0.002, 0.039 +- 0.004
nec_acc_int  =  0.853 +- 0.018, 0.878 +- 0.004, 0.878 +- 0.003

Eval split test
suff++ class all_L1  =  0.740 +- 0.073, 0.809 +- 0.024, 0.921 +- 0.005, 1.000 +- 0.000
suff++ class all_KL  =  0.527 +- 0.171, 0.685 +- 0.064, 0.924 +- 0.012, 1.000 +- 0.000
suff++_acc_int  =  0.669 +- 0.045, 0.731 +- 0.046, 0.813 +- 0.017
nec class all_L1  =  0.115 +- 0.034, 0.092 +- 0.017, 0.070 +- 0.006, 0.057 +- 0.003
nec class all_KL  =  0.137 +- 0.047, 0.087 +- 0.021, 0.059 +- 0.012, 0.045 +- 0.004
nec_acc_int  =  0.743 +- 0.061, 0.781 +- 0.047, 0.818 +- 0.015, 0.826 +- 0.012


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.451 +- 0.004, 0.497 +- 0.002, 0.520 +- 0.002
Faith. Armon (L1)= 		  =  0.157 +- 0.010, 0.081 +- 0.009, 0.078 +- 0.009
Faith. GMean (L1)= 	  =  0.266 +- 0.009, 0.201 +- 0.011, 0.201 +- 0.012
Faith. Aritm (KL)= 		  =  0.370 +- 0.014, 0.498 +- 0.002, 0.519 +- 0.002
Faith. Armon (KL)= 		  =  0.177 +- 0.012, 0.073 +- 0.004, 0.075 +- 0.007
Faith. GMean (KL)= 	  =  0.256 +- 0.012, 0.191 +- 0.006, 0.197 +- 0.010

Eval split test
Faith. Aritm (L1)= 		  =  0.427 +- 0.026, 0.451 +- 0.010, 0.496 +- 0.001, 0.528 +- 0.002
Faith. Armon (L1)= 		  =  0.196 +- 0.047, 0.165 +- 0.027, 0.130 +- 0.010, 0.108 +- 0.006
Faith. GMean (L1)= 	  =  0.287 +- 0.031, 0.272 +- 0.022, 0.253 +- 0.010, 0.239 +- 0.007
Faith. Aritm (KL)= 		  =  0.332 +- 0.070, 0.386 +- 0.031, 0.492 +- 0.002, 0.523 +- 0.002
Faith. Armon (KL)= 		  =  0.204 +- 0.052, 0.153 +- 0.033, 0.110 +- 0.021, 0.086 +- 0.007
Faith. GMean (KL)= 	  =  0.255 +- 0.031, 0.242 +- 0.029, 0.232 +- 0.022, 0.212 +- 0.009
Computed for split load_split = id



Completed in  0:10:26.090984  for GSATGIN GOODSST2/length



DONE GSAT GOODSST2/length
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:06:25 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:06:25 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:06:56 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:05 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:16 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:31 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:46 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:07:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9683
Train Loss: 0.1420
ID Validation ROC-AUC: 0.9217
ID Validation Loss: 0.2255
ID Test ROC-AUC: 0.9251
ID Test Loss: 0.2246
OOD Validation ROC-AUC: 0.6374
OOD Validation Loss: 0.4787
OOD Test ROC-AUC: 0.6853
OOD Test Loss: 0.5698

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 23...
[0m[1;37mINFO[0m: [1mCheckpoint 23: 
-----------------------------------
Train ROC-AUC: 0.9140
Train Loss: 0.2226
ID Validation ROC-AUC: 0.9010
ID Validation Loss: 0.2385
ID Test ROC-AUC: 0.9039
ID Test Loss: 0.2385
OOD Validation ROC-AUC: 0.6822
OOD Validation Loss: 0.3129
OOD Test ROC-AUC: 0.7143
OOD Test Loss: 0.4523

[0m[1;37mINFO[0m: [1mChartInfo 0.9251 0.6853 0.9039 0.7143 0.9010 0.6822[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:07:48 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:07:53 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.682 +- 0.310 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.3 class 1.0 = 0.777 +- 0.310 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.3 all KL = 0.561 +- 0.310 (in-sample avg dev_std = 0.434)
SUFF++ for r=0.3 all L1 = 0.766 +- 0.196 (in-sample avg dev_std = 0.434)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.607
SUFF++ for r=0.6 class 0.0 = 0.78 +- 0.219 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.6 class 1.0 = 0.856 +- 0.219 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.6 all KL = 0.8 +- 0.219 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.6 all L1 = 0.847 +- 0.166 (in-sample avg dev_std = 0.295)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.647
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.601
SUFF++ for r=0.9 class 0.0 = 0.78 +- 0.156 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 class 1.0 = 0.848 +- 0.156 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all KL = 0.889 +- 0.156 (in-sample avg dev_std = 0.223)
SUFF++ for r=0.9 all L1 = 0.84 +- 0.177 (in-sample avg dev_std = 0.223)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.52
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.541
SUFF++ for r=0.3 class 0.0 = 0.71 +- 0.305 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 class 1.0 = 0.711 +- 0.305 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all KL = 0.539 +- 0.305 (in-sample avg dev_std = 0.470)
SUFF++ for r=0.3 all L1 = 0.711 +- 0.206 (in-sample avg dev_std = 0.470)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.547
SUFF++ for r=0.6 class 0.0 = 0.778 +- 0.239 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 class 1.0 = 0.798 +- 0.239 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all KL = 0.765 +- 0.239 (in-sample avg dev_std = 0.329)
SUFF++ for r=0.6 all L1 = 0.794 +- 0.193 (in-sample avg dev_std = 0.329)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.574
SUFF++ for r=0.9 class 0.0 = 0.783 +- 0.169 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 class 1.0 = 0.819 +- 0.169 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all KL = 0.876 +- 0.169 (in-sample avg dev_std = 0.244)
SUFF++ for r=0.9 all L1 = 0.813 +- 0.187 (in-sample avg dev_std = 0.244)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.636
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.652
NEC for r=0.3 class 0.0 = 0.286 +- 0.334 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1.0 = 0.187 +- 0.334 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.323 +- 0.334 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.199 +- 0.210 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.653
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.647
NEC for r=0.6 class 0.0 = 0.249 +- 0.221 (in-sample avg dev_std = 0.278)
NEC for r=0.6 class 1.0 = 0.132 +- 0.221 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all KL = 0.176 +- 0.221 (in-sample avg dev_std = 0.278)
NEC for r=0.6 all L1 = 0.145 +- 0.166 (in-sample avg dev_std = 0.278)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.647
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.648
NEC for r=0.9 class 0.0 = 0.246 +- 0.158 (in-sample avg dev_std = 0.227)
NEC for r=0.9 class 1.0 = 0.152 +- 0.158 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all KL = 0.117 +- 0.158 (in-sample avg dev_std = 0.227)
NEC for r=0.9 all L1 = 0.163 +- 0.178 (in-sample avg dev_std = 0.227)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.649
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.64
NEC for r=1.0 class 0.0 = 0.27 +- 0.156 (in-sample avg dev_std = 0.248)
NEC for r=1.0 class 1.0 = 0.152 +- 0.156 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all KL = 0.113 +- 0.156 (in-sample avg dev_std = 0.248)
NEC for r=1.0 all L1 = 0.166 +- 0.173 (in-sample avg dev_std = 0.248)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.52
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.565
NEC for r=0.3 class 0.0 = 0.253 +- 0.321 (in-sample avg dev_std = 0.410)
NEC for r=0.3 class 1.0 = 0.254 +- 0.321 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all KL = 0.35 +- 0.321 (in-sample avg dev_std = 0.410)
NEC for r=0.3 all L1 = 0.254 +- 0.229 (in-sample avg dev_std = 0.410)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.576
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.597
NEC for r=0.6 class 0.0 = 0.234 +- 0.243 (in-sample avg dev_std = 0.334)
NEC for r=0.6 class 1.0 = 0.191 +- 0.243 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all KL = 0.215 +- 0.243 (in-sample avg dev_std = 0.334)
NEC for r=0.6 all L1 = 0.198 +- 0.195 (in-sample avg dev_std = 0.334)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.58
NEC for r=0.9 class 0.0 = 0.242 +- 0.199 (in-sample avg dev_std = 0.285)
NEC for r=0.9 class 1.0 = 0.194 +- 0.199 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all KL = 0.15 +- 0.199 (in-sample avg dev_std = 0.285)
NEC for r=0.9 all L1 = 0.202 +- 0.192 (in-sample avg dev_std = 0.285)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.582
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.596
NEC for r=1.0 class 0.0 = 0.251 +- 0.192 (in-sample avg dev_std = 0.294)
NEC for r=1.0 class 1.0 = 0.198 +- 0.192 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all KL = 0.149 +- 0.192 (in-sample avg dev_std = 0.294)
NEC for r=1.0 all L1 = 0.207 +- 0.191 (in-sample avg dev_std = 0.294)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:11:09 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:11:09 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:11:40 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:11:50 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:00 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:16 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 167...
[0m[1;37mINFO[0m: [1mCheckpoint 167: 
-----------------------------------
Train ROC-AUC: 0.9686
Train Loss: 0.1412
ID Validation ROC-AUC: 0.9211
ID Validation Loss: 0.2263
ID Test ROC-AUC: 0.9251
ID Test Loss: 0.2237
OOD Validation ROC-AUC: 0.6449
OOD Validation Loss: 0.4664
OOD Test ROC-AUC: 0.6906
OOD Test Loss: 0.5564

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 30...
[0m[1;37mINFO[0m: [1mCheckpoint 30: 
-----------------------------------
Train ROC-AUC: 0.9194
Train Loss: 0.2142
ID Validation ROC-AUC: 0.9010
ID Validation Loss: 0.2357
ID Test ROC-AUC: 0.9053
ID Test Loss: 0.2328
OOD Validation ROC-AUC: 0.6935
OOD Validation Loss: 0.3224
OOD Test ROC-AUC: 0.7183
OOD Test Loss: 0.4429

[0m[1;37mINFO[0m: [1mChartInfo 0.9251 0.6906 0.9053 0.7183 0.9010 0.6935[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:12:31 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:12:35 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.666
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
SUFF++ for r=0.3 class 0.0 = 0.705 +- 0.312 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 1.0 = 0.777 +- 0.312 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all KL = 0.619 +- 0.312 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all L1 = 0.769 +- 0.214 (in-sample avg dev_std = 0.445)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.555
SUFF++ for r=0.6 class 0.0 = 0.855 +- 0.233 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 class 1.0 = 0.906 +- 0.233 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all KL = 0.84 +- 0.233 (in-sample avg dev_std = 0.260)
SUFF++ for r=0.6 all L1 = 0.9 +- 0.159 (in-sample avg dev_std = 0.260)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.585
SUFF++ for r=0.9 class 0.0 = 0.89 +- 0.136 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 class 1.0 = 0.916 +- 0.136 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all KL = 0.931 +- 0.136 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.9 all L1 = 0.913 +- 0.145 (in-sample avg dev_std = 0.164)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.5
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.489
SUFF++ for r=0.3 class 0.0 = 0.764 +- 0.311 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 class 1.0 = 0.743 +- 0.311 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all KL = 0.612 +- 0.311 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.3 all L1 = 0.746 +- 0.226 (in-sample avg dev_std = 0.445)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.487
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.504
SUFF++ for r=0.6 class 0.0 = 0.875 +- 0.253 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 class 1.0 = 0.87 +- 0.253 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 all KL = 0.816 +- 0.253 (in-sample avg dev_std = 0.280)
SUFF++ for r=0.6 all L1 = 0.871 +- 0.187 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.513
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.507
SUFF++ for r=0.9 class 0.0 = 0.882 +- 0.163 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 class 1.0 = 0.889 +- 0.163 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all KL = 0.908 +- 0.163 (in-sample avg dev_std = 0.193)
SUFF++ for r=0.9 all L1 = 0.888 +- 0.168 (in-sample avg dev_std = 0.193)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.666
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.609
NEC for r=0.3 class 0.0 = 0.262 +- 0.298 (in-sample avg dev_std = 0.355)
NEC for r=0.3 class 1.0 = 0.171 +- 0.298 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all KL = 0.249 +- 0.298 (in-sample avg dev_std = 0.355)
NEC for r=0.3 all L1 = 0.181 +- 0.213 (in-sample avg dev_std = 0.355)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.646
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.606
NEC for r=0.6 class 0.0 = 0.152 +- 0.223 (in-sample avg dev_std = 0.244)
NEC for r=0.6 class 1.0 = 0.085 +- 0.223 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all KL = 0.134 +- 0.223 (in-sample avg dev_std = 0.244)
NEC for r=0.6 all L1 = 0.093 +- 0.158 (in-sample avg dev_std = 0.244)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.626
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.564
NEC for r=0.9 class 0.0 = 0.117 +- 0.144 (in-sample avg dev_std = 0.181)
NEC for r=0.9 class 1.0 = 0.086 +- 0.144 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all KL = 0.081 +- 0.144 (in-sample avg dev_std = 0.181)
NEC for r=0.9 all L1 = 0.09 +- 0.141 (in-sample avg dev_std = 0.181)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.632
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.563
NEC for r=1.0 class 0.0 = 0.136 +- 0.130 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1.0 = 0.097 +- 0.130 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.077 +- 0.130 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.101 +- 0.145 (in-sample avg dev_std = 0.173)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.5
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.49
NEC for r=0.3 class 0.0 = 0.19 +- 0.310 (in-sample avg dev_std = 0.373)
NEC for r=0.3 class 1.0 = 0.221 +- 0.310 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all KL = 0.273 +- 0.310 (in-sample avg dev_std = 0.373)
NEC for r=0.3 all L1 = 0.216 +- 0.236 (in-sample avg dev_std = 0.373)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.487
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.489
NEC for r=0.6 class 0.0 = 0.123 +- 0.243 (in-sample avg dev_std = 0.269)
NEC for r=0.6 class 1.0 = 0.121 +- 0.243 (in-sample avg dev_std = 0.269)
NEC for r=0.6 all KL = 0.161 +- 0.243 (in-sample avg dev_std = 0.269)
NEC for r=0.6 all L1 = 0.121 +- 0.181 (in-sample avg dev_std = 0.269)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.513
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.503
NEC for r=0.9 class 0.0 = 0.129 +- 0.174 (in-sample avg dev_std = 0.212)
NEC for r=0.9 class 1.0 = 0.118 +- 0.174 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all KL = 0.108 +- 0.174 (in-sample avg dev_std = 0.212)
NEC for r=0.9 all L1 = 0.12 +- 0.170 (in-sample avg dev_std = 0.212)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.519
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.502
NEC for r=1.0 class 0.0 = 0.148 +- 0.158 (in-sample avg dev_std = 0.217)
NEC for r=1.0 class 1.0 = 0.127 +- 0.158 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all KL = 0.098 +- 0.158 (in-sample avg dev_std = 0.217)
NEC for r=1.0 all L1 = 0.131 +- 0.169 (in-sample avg dev_std = 0.217)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:15:52 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:15:52 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:16:23 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:16:33 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:16:44 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:00 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ROC-AUC: 0.9700
Train Loss: 0.1384
ID Validation ROC-AUC: 0.9239
ID Validation Loss: 0.2236
ID Test ROC-AUC: 0.9258
ID Test Loss: 0.2238
OOD Validation ROC-AUC: 0.6361
OOD Validation Loss: 0.4564
OOD Test ROC-AUC: 0.6863
OOD Test Loss: 0.5633

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 21...
[0m[1;37mINFO[0m: [1mCheckpoint 21: 
-----------------------------------
Train ROC-AUC: 0.9076
Train Loss: 0.2268
ID Validation ROC-AUC: 0.8921
ID Validation Loss: 0.2443
ID Test ROC-AUC: 0.8980
ID Test Loss: 0.2413
OOD Validation ROC-AUC: 0.6868
OOD Validation Loss: 0.3111
OOD Test ROC-AUC: 0.7174
OOD Test Loss: 0.4442

[0m[1;37mINFO[0m: [1mChartInfo 0.9258 0.6863 0.8980 0.7174 0.8921 0.6868[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:17:15 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:17:20 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.542
SUFF++ for r=0.3 class 0.0 = 0.679 +- 0.269 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 class 1.0 = 0.709 +- 0.269 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 all KL = 0.669 +- 0.269 (in-sample avg dev_std = 0.376)
SUFF++ for r=0.3 all L1 = 0.706 +- 0.241 (in-sample avg dev_std = 0.376)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.537
SUFF++ for r=0.6 class 0.0 = 0.77 +- 0.227 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 class 1.0 = 0.816 +- 0.227 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all KL = 0.832 +- 0.227 (in-sample avg dev_std = 0.233)
SUFF++ for r=0.6 all L1 = 0.811 +- 0.236 (in-sample avg dev_std = 0.233)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.61
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.566
SUFF++ for r=0.9 class 0.0 = 0.815 +- 0.167 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 class 1.0 = 0.884 +- 0.167 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all KL = 0.911 +- 0.167 (in-sample avg dev_std = 0.169)
SUFF++ for r=0.9 all L1 = 0.876 +- 0.188 (in-sample avg dev_std = 0.169)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.532
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.535
SUFF++ for r=0.3 class 0.0 = 0.64 +- 0.263 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 class 1.0 = 0.663 +- 0.263 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all KL = 0.651 +- 0.263 (in-sample avg dev_std = 0.393)
SUFF++ for r=0.3 all L1 = 0.659 +- 0.240 (in-sample avg dev_std = 0.393)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.555
SUFF++ for r=0.6 class 0.0 = 0.687 +- 0.239 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 class 1.0 = 0.785 +- 0.239 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all KL = 0.799 +- 0.239 (in-sample avg dev_std = 0.252)
SUFF++ for r=0.6 all L1 = 0.768 +- 0.248 (in-sample avg dev_std = 0.252)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.622
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.596
SUFF++ for r=0.9 class 0.0 = 0.808 +- 0.177 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.9 class 1.0 = 0.868 +- 0.177 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.9 all KL = 0.895 +- 0.177 (in-sample avg dev_std = 0.199)
SUFF++ for r=0.9 all L1 = 0.858 +- 0.197 (in-sample avg dev_std = 0.199)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.531
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.566
NEC for r=0.3 class 0.0 = 0.282 +- 0.268 (in-sample avg dev_std = 0.362)
NEC for r=0.3 class 1.0 = 0.264 +- 0.268 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all KL = 0.27 +- 0.268 (in-sample avg dev_std = 0.362)
NEC for r=0.3 all L1 = 0.266 +- 0.234 (in-sample avg dev_std = 0.362)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.548
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.547
NEC for r=0.6 class 0.0 = 0.209 +- 0.209 (in-sample avg dev_std = 0.261)
NEC for r=0.6 class 1.0 = 0.178 +- 0.209 (in-sample avg dev_std = 0.261)
NEC for r=0.6 all KL = 0.159 +- 0.209 (in-sample avg dev_std = 0.261)
NEC for r=0.6 all L1 = 0.182 +- 0.211 (in-sample avg dev_std = 0.261)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.61
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.572
NEC for r=0.9 class 0.0 = 0.185 +- 0.154 (in-sample avg dev_std = 0.199)
NEC for r=0.9 class 1.0 = 0.12 +- 0.154 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all KL = 0.098 +- 0.154 (in-sample avg dev_std = 0.199)
NEC for r=0.9 all L1 = 0.127 +- 0.179 (in-sample avg dev_std = 0.199)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.647
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.581
NEC for r=1.0 class 0.0 = 0.197 +- 0.151 (in-sample avg dev_std = 0.203)
NEC for r=1.0 class 1.0 = 0.105 +- 0.151 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all KL = 0.092 +- 0.151 (in-sample avg dev_std = 0.203)
NEC for r=1.0 all L1 = 0.115 +- 0.164 (in-sample avg dev_std = 0.203)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.532
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.531
NEC for r=0.3 class 0.0 = 0.353 +- 0.270 (in-sample avg dev_std = 0.366)
NEC for r=0.3 class 1.0 = 0.312 +- 0.270 (in-sample avg dev_std = 0.366)
NEC for r=0.3 all KL = 0.3 +- 0.270 (in-sample avg dev_std = 0.366)
NEC for r=0.3 all L1 = 0.319 +- 0.245 (in-sample avg dev_std = 0.366)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.611
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.578
NEC for r=0.6 class 0.0 = 0.291 +- 0.225 (in-sample avg dev_std = 0.273)
NEC for r=0.6 class 1.0 = 0.208 +- 0.225 (in-sample avg dev_std = 0.273)
NEC for r=0.6 all KL = 0.189 +- 0.225 (in-sample avg dev_std = 0.273)
NEC for r=0.6 all L1 = 0.222 +- 0.228 (in-sample avg dev_std = 0.273)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.622
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.587
NEC for r=0.9 class 0.0 = 0.214 +- 0.185 (in-sample avg dev_std = 0.224)
NEC for r=0.9 class 1.0 = 0.138 +- 0.185 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all KL = 0.121 +- 0.185 (in-sample avg dev_std = 0.224)
NEC for r=0.9 all L1 = 0.151 +- 0.198 (in-sample avg dev_std = 0.224)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.614
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.586
NEC for r=1.0 class 0.0 = 0.211 +- 0.190 (in-sample avg dev_std = 0.229)
NEC for r=1.0 class 1.0 = 0.142 +- 0.190 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all KL = 0.123 +- 0.190 (in-sample avg dev_std = 0.229)
NEC for r=1.0 all L1 = 0.153 +- 0.200 (in-sample avg dev_std = 0.229)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:20:36 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:20:37 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:06 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:16 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:27 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:42 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 199...
[0m[1;37mINFO[0m: [1mCheckpoint 199: 
-----------------------------------
Train ROC-AUC: 0.9701
Train Loss: 0.1379
ID Validation ROC-AUC: 0.9219
ID Validation Loss: 0.2309
ID Test ROC-AUC: 0.9249
ID Test Loss: 0.2294
OOD Validation ROC-AUC: 0.6427
OOD Validation Loss: 0.4806
OOD Test ROC-AUC: 0.6915
OOD Test Loss: 0.5778

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 58...
[0m[1;37mINFO[0m: [1mCheckpoint 58: 
-----------------------------------
Train ROC-AUC: 0.9368
Train Loss: 0.1927
ID Validation ROC-AUC: 0.9098
ID Validation Loss: 0.2281
ID Test ROC-AUC: 0.9159
ID Test Loss: 0.2220
OOD Validation ROC-AUC: 0.6858
OOD Validation Loss: 0.3482
OOD Test ROC-AUC: 0.7149
OOD Test Loss: 0.4585

[0m[1;37mINFO[0m: [1mChartInfo 0.9249 0.6915 0.9159 0.7149 0.9098 0.6858[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:21:58 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:22:02 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.58
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.517
SUFF++ for r=0.3 class 0.0 = 0.701 +- 0.286 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 class 1.0 = 0.739 +- 0.286 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all KL = 0.616 +- 0.286 (in-sample avg dev_std = 0.456)
SUFF++ for r=0.3 all L1 = 0.735 +- 0.196 (in-sample avg dev_std = 0.456)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.512
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.511
SUFF++ for r=0.6 class 0.0 = 0.774 +- 0.239 (in-sample avg dev_std = 0.358)
SUFF++ for r=0.6 class 1.0 = 0.765 +- 0.239 (in-sample avg dev_std = 0.358)
SUFF++ for r=0.6 all KL = 0.759 +- 0.239 (in-sample avg dev_std = 0.358)
SUFF++ for r=0.6 all L1 = 0.766 +- 0.211 (in-sample avg dev_std = 0.358)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.576
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.544
SUFF++ for r=0.9 class 0.0 = 0.847 +- 0.171 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 class 1.0 = 0.884 +- 0.171 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all KL = 0.901 +- 0.171 (in-sample avg dev_std = 0.201)
SUFF++ for r=0.9 all L1 = 0.88 +- 0.170 (in-sample avg dev_std = 0.201)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.53
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.494
SUFF++ for r=0.3 class 0.0 = 0.737 +- 0.276 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 1.0 = 0.707 +- 0.276 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 all KL = 0.607 +- 0.276 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 all L1 = 0.712 +- 0.201 (in-sample avg dev_std = 0.467)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.475
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.496
SUFF++ for r=0.6 class 0.0 = 0.79 +- 0.252 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 class 1.0 = 0.757 +- 0.252 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 all KL = 0.742 +- 0.252 (in-sample avg dev_std = 0.368)
SUFF++ for r=0.6 all L1 = 0.762 +- 0.214 (in-sample avg dev_std = 0.368)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.526
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.526
SUFF++ for r=0.9 class 0.0 = 0.867 +- 0.165 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 class 1.0 = 0.87 +- 0.165 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 all KL = 0.897 +- 0.165 (in-sample avg dev_std = 0.200)
SUFF++ for r=0.9 all L1 = 0.87 +- 0.174 (in-sample avg dev_std = 0.200)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.58
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
NEC for r=0.3 class 0.0 = 0.273 +- 0.284 (in-sample avg dev_std = 0.389)
NEC for r=0.3 class 1.0 = 0.231 +- 0.284 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all KL = 0.299 +- 0.284 (in-sample avg dev_std = 0.389)
NEC for r=0.3 all L1 = 0.236 +- 0.208 (in-sample avg dev_std = 0.389)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.512
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.554
NEC for r=0.6 class 0.0 = 0.203 +- 0.226 (in-sample avg dev_std = 0.321)
NEC for r=0.6 class 1.0 = 0.212 +- 0.226 (in-sample avg dev_std = 0.321)
NEC for r=0.6 all KL = 0.204 +- 0.226 (in-sample avg dev_std = 0.321)
NEC for r=0.6 all L1 = 0.211 +- 0.197 (in-sample avg dev_std = 0.321)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.576
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.547
NEC for r=0.9 class 0.0 = 0.157 +- 0.183 (in-sample avg dev_std = 0.246)
NEC for r=0.9 class 1.0 = 0.133 +- 0.183 (in-sample avg dev_std = 0.246)
NEC for r=0.9 all KL = 0.127 +- 0.183 (in-sample avg dev_std = 0.246)
NEC for r=0.9 all L1 = 0.135 +- 0.168 (in-sample avg dev_std = 0.246)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.562
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.551
NEC for r=1.0 class 0.0 = 0.143 +- 0.151 (in-sample avg dev_std = 0.206)
NEC for r=1.0 class 1.0 = 0.099 +- 0.151 (in-sample avg dev_std = 0.206)
NEC for r=1.0 all KL = 0.091 +- 0.151 (in-sample avg dev_std = 0.206)
NEC for r=1.0 all L1 = 0.104 +- 0.144 (in-sample avg dev_std = 0.206)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.53
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.524
NEC for r=0.3 class 0.0 = 0.247 +- 0.292 (in-sample avg dev_std = 0.400)
NEC for r=0.3 class 1.0 = 0.248 +- 0.292 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all KL = 0.3 +- 0.292 (in-sample avg dev_std = 0.400)
NEC for r=0.3 all L1 = 0.248 +- 0.217 (in-sample avg dev_std = 0.400)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.475
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.527
NEC for r=0.6 class 0.0 = 0.21 +- 0.237 (in-sample avg dev_std = 0.338)
NEC for r=0.6 class 1.0 = 0.223 +- 0.237 (in-sample avg dev_std = 0.338)
NEC for r=0.6 all KL = 0.224 +- 0.237 (in-sample avg dev_std = 0.338)
NEC for r=0.6 all L1 = 0.221 +- 0.206 (in-sample avg dev_std = 0.338)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.526
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.527
NEC for r=0.9 class 0.0 = 0.152 +- 0.180 (in-sample avg dev_std = 0.242)
NEC for r=0.9 class 1.0 = 0.144 +- 0.180 (in-sample avg dev_std = 0.242)
NEC for r=0.9 all KL = 0.127 +- 0.180 (in-sample avg dev_std = 0.242)
NEC for r=0.9 all L1 = 0.145 +- 0.181 (in-sample avg dev_std = 0.242)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.518
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.526
NEC for r=1.0 class 0.0 = 0.124 +- 0.161 (in-sample avg dev_std = 0.231)
NEC for r=1.0 class 1.0 = 0.121 +- 0.161 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all KL = 0.104 +- 0.161 (in-sample avg dev_std = 0.231)
NEC for r=1.0 all L1 = 0.121 +- 0.164 (in-sample avg dev_std = 0.231)
model_dirname= repr_LECIGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:25:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:25:12 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:25:42 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:25:52 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:02 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:17 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 149...
[0m[1;37mINFO[0m: [1mCheckpoint 149: 
-----------------------------------
Train ROC-AUC: 0.9611
Train Loss: 0.1567
ID Validation ROC-AUC: 0.9233
ID Validation Loss: 0.2180
ID Test ROC-AUC: 0.9240
ID Test Loss: 0.2206
OOD Validation ROC-AUC: 0.6334
OOD Validation Loss: 0.4667
OOD Test ROC-AUC: 0.6879
OOD Test Loss: 0.5492

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.9251
Train Loss: 0.2093
ID Validation ROC-AUC: 0.9033
ID Validation Loss: 0.2367
ID Test ROC-AUC: 0.9102
ID Test Loss: 0.2300
OOD Validation ROC-AUC: 0.6806
OOD Validation Loss: 0.3241
OOD Test ROC-AUC: 0.7074
OOD Test Loss: 0.4616

[0m[1;37mINFO[0m: [1mChartInfo 0.9240 0.6879 0.9102 0.7074 0.9033 0.6806[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:26:32 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:26:37 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.704
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.623
SUFF++ for r=0.3 class 0.0 = 0.742 +- 0.308 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 class 1.0 = 0.899 +- 0.308 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 all KL = 0.741 +- 0.308 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 all L1 = 0.88 +- 0.178 (in-sample avg dev_std = 0.295)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.692
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.635
SUFF++ for r=0.6 class 0.0 = 0.909 +- 0.133 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 class 1.0 = 0.977 +- 0.133 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all KL = 0.945 +- 0.133 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.6 all L1 = 0.969 +- 0.084 (in-sample avg dev_std = 0.124)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.642
SUFF++ for r=0.9 class 0.0 = 0.965 +- 0.054 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 class 1.0 = 0.988 +- 0.054 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 all KL = 0.989 +- 0.054 (in-sample avg dev_std = 0.056)
SUFF++ for r=0.9 all L1 = 0.986 +- 0.050 (in-sample avg dev_std = 0.056)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.597
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
SUFF++ for r=0.3 class 0.0 = 0.795 +- 0.294 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 class 1.0 = 0.87 +- 0.294 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all KL = 0.713 +- 0.294 (in-sample avg dev_std = 0.319)
SUFF++ for r=0.3 all L1 = 0.857 +- 0.174 (in-sample avg dev_std = 0.319)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.587
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.593
SUFF++ for r=0.6 class 0.0 = 0.917 +- 0.149 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 class 1.0 = 0.961 +- 0.149 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all KL = 0.932 +- 0.149 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all L1 = 0.954 +- 0.109 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.579
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.579
SUFF++ for r=0.9 class 0.0 = 0.965 +- 0.064 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.9 class 1.0 = 0.984 +- 0.064 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.9 all KL = 0.985 +- 0.064 (in-sample avg dev_std = 0.061)
SUFF++ for r=0.9 all L1 = 0.98 +- 0.061 (in-sample avg dev_std = 0.061)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.704
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.699
NEC for r=0.3 class 0.0 = 0.232 +- 0.278 (in-sample avg dev_std = 0.250)
NEC for r=0.3 class 1.0 = 0.083 +- 0.278 (in-sample avg dev_std = 0.250)
NEC for r=0.3 all KL = 0.179 +- 0.278 (in-sample avg dev_std = 0.250)
NEC for r=0.3 all L1 = 0.1 +- 0.171 (in-sample avg dev_std = 0.250)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.692
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.673
NEC for r=0.6 class 0.0 = 0.105 +- 0.151 (in-sample avg dev_std = 0.146)
NEC for r=0.6 class 1.0 = 0.027 +- 0.151 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all KL = 0.063 +- 0.151 (in-sample avg dev_std = 0.146)
NEC for r=0.6 all L1 = 0.036 +- 0.093 (in-sample avg dev_std = 0.146)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.655
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.648
NEC for r=0.9 class 0.0 = 0.052 +- 0.076 (in-sample avg dev_std = 0.085)
NEC for r=0.9 class 1.0 = 0.016 +- 0.076 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all KL = 0.024 +- 0.076 (in-sample avg dev_std = 0.085)
NEC for r=0.9 all L1 = 0.02 +- 0.052 (in-sample avg dev_std = 0.085)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.647
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.659
NEC for r=1.0 class 0.0 = 0.064 +- 0.073 (in-sample avg dev_std = 0.075)
NEC for r=1.0 class 1.0 = 0.014 +- 0.073 (in-sample avg dev_std = 0.075)
NEC for r=1.0 all KL = 0.019 +- 0.073 (in-sample avg dev_std = 0.075)
NEC for r=1.0 all L1 = 0.02 +- 0.063 (in-sample avg dev_std = 0.075)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.597
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.584
NEC for r=0.3 class 0.0 = 0.196 +- 0.295 (in-sample avg dev_std = 0.281)
NEC for r=0.3 class 1.0 = 0.118 +- 0.295 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all KL = 0.21 +- 0.295 (in-sample avg dev_std = 0.281)
NEC for r=0.3 all L1 = 0.131 +- 0.188 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.587
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.587
NEC for r=0.6 class 0.0 = 0.093 +- 0.165 (in-sample avg dev_std = 0.159)
NEC for r=0.6 class 1.0 = 0.043 +- 0.165 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all KL = 0.078 +- 0.165 (in-sample avg dev_std = 0.159)
NEC for r=0.6 all L1 = 0.052 +- 0.112 (in-sample avg dev_std = 0.159)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.579
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.569
NEC for r=0.9 class 0.0 = 0.041 +- 0.090 (in-sample avg dev_std = 0.092)
NEC for r=0.9 class 1.0 = 0.024 +- 0.090 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all KL = 0.029 +- 0.090 (in-sample avg dev_std = 0.092)
NEC for r=0.9 all L1 = 0.027 +- 0.068 (in-sample avg dev_std = 0.092)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.556
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.57
NEC for r=1.0 class 0.0 = 0.04 +- 0.070 (in-sample avg dev_std = 0.087)
NEC for r=1.0 class 1.0 = 0.022 +- 0.070 (in-sample avg dev_std = 0.087)
NEC for r=1.0 all KL = 0.023 +- 0.070 (in-sample avg dev_std = 0.087)
NEC for r=1.0 all L1 = 0.025 +- 0.066 (in-sample avg dev_std = 0.087)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.561, 0.8, 0.889, 1.0], 'all_L1': [0.766, 0.847, 0.84, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.619, 0.84, 0.931, 1.0], 'all_L1': [0.769, 0.9, 0.913, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.669, 0.832, 0.911, 1.0], 'all_L1': [0.706, 0.811, 0.876, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.616, 0.759, 0.901, 1.0], 'all_L1': [0.735, 0.766, 0.88, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.741, 0.945, 0.989, 1.0], 'all_L1': [0.88, 0.969, 0.986, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.323, 0.176, 0.117, 0.113], 'all_L1': [0.199, 0.145, 0.163, 0.166]}), defaultdict(<class 'list'>, {'all_KL': [0.249, 0.134, 0.081, 0.077], 'all_L1': [0.181, 0.093, 0.09, 0.101]}), defaultdict(<class 'list'>, {'all_KL': [0.27, 0.159, 0.098, 0.092], 'all_L1': [0.266, 0.182, 0.127, 0.115]}), defaultdict(<class 'list'>, {'all_KL': [0.299, 0.204, 0.127, 0.091], 'all_L1': [0.236, 0.211, 0.135, 0.104]}), defaultdict(<class 'list'>, {'all_KL': [0.179, 0.063, 0.024, 0.019], 'all_L1': [0.1, 0.036, 0.02, 0.02]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.539, 0.765, 0.876, 1.0], 'all_L1': [0.711, 0.794, 0.813, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.612, 0.816, 0.908, 1.0], 'all_L1': [0.746, 0.871, 0.888, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.651, 0.799, 0.895, 1.0], 'all_L1': [0.659, 0.768, 0.858, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.607, 0.742, 0.897, 1.0], 'all_L1': [0.712, 0.762, 0.87, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.713, 0.932, 0.985, 1.0], 'all_L1': [0.857, 0.954, 0.98, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.35, 0.215, 0.15, 0.149], 'all_L1': [0.254, 0.198, 0.202, 0.207]}), defaultdict(<class 'list'>, {'all_KL': [0.273, 0.161, 0.108, 0.098], 'all_L1': [0.216, 0.121, 0.12, 0.131]}), defaultdict(<class 'list'>, {'all_KL': [0.3, 0.189, 0.121, 0.123], 'all_L1': [0.319, 0.222, 0.151, 0.153]}), defaultdict(<class 'list'>, {'all_KL': [0.3, 0.224, 0.127, 0.104], 'all_L1': [0.248, 0.221, 0.145, 0.121]}), defaultdict(<class 'list'>, {'all_KL': [0.21, 0.078, 0.029, 0.023], 'all_L1': [0.131, 0.052, 0.027, 0.025]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.771 +- 0.059, 0.859 +- 0.071, 0.899 +- 0.049, 1.000 +- 0.000
suff++ class all_KL  =  0.641 +- 0.060, 0.835 +- 0.062, 0.924 +- 0.035, 1.000 +- 0.000
suff++_acc_int  =  0.565 +- 0.037, 0.569 +- 0.046, 0.587 +- 0.033
nec class all_L1  =  0.196 +- 0.056, 0.133 +- 0.063, 0.107 +- 0.049, 0.101 +- 0.047
nec class all_KL  =  0.264 +- 0.049, 0.147 +- 0.048, 0.089 +- 0.036, 0.078 +- 0.032
nec_acc_int  =  0.619 +- 0.051, 0.605 +- 0.050, 0.596 +- 0.043, 0.599 +- 0.043

Eval split test
suff++ class all_L1  =  0.737 +- 0.066, 0.830 +- 0.073, 0.882 +- 0.055, 1.000 +- 0.000
suff++ class all_KL  =  0.624 +- 0.057, 0.811 +- 0.066, 0.912 +- 0.038, 1.000 +- 0.000
suff++_acc_int  =  0.525 +- 0.030, 0.539 +- 0.036, 0.556 +- 0.034
nec class all_L1  =  0.234 +- 0.061, 0.163 +- 0.067, 0.129 +- 0.058, 0.127 +- 0.059
nec class all_KL  =  0.287 +- 0.046, 0.173 +- 0.053, 0.107 +- 0.041, 0.099 +- 0.042
nec_acc_int  =  0.538 +- 0.033, 0.556 +- 0.041, 0.553 +- 0.033, 0.556 +- 0.036


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.484 +- 0.005, 0.496 +- 0.004, 0.503 +- 0.002, 0.551 +- 0.023
Faith. Armon (L1)= 		  =  0.306 +- 0.071, 0.223 +- 0.094, 0.186 +- 0.081, 0.180 +- 0.079
Faith. GMean (L1)= 	  =  0.382 +- 0.047, 0.323 +- 0.078, 0.295 +- 0.082, 0.306 +- 0.088
Faith. Aritm (KL)= 		  =  0.453 +- 0.013, 0.491 +- 0.008, 0.507 +- 0.004, 0.539 +- 0.016
Faith. Armon (KL)= 		  =  0.368 +- 0.044, 0.245 +- 0.070, 0.160 +- 0.062, 0.144 +- 0.057
Faith. GMean (KL)= 	  =  0.407 +- 0.025, 0.342 +- 0.053, 0.278 +- 0.065, 0.271 +- 0.069

Eval split test
Faith. Aritm (L1)= 		  =  0.485 +- 0.005, 0.496 +- 0.004, 0.505 +- 0.002, 0.564 +- 0.030
Faith. Armon (L1)= 		  =  0.347 +- 0.067, 0.263 +- 0.095, 0.219 +- 0.091, 0.221 +- 0.097
Faith. GMean (L1)= 	  =  0.408 +- 0.041, 0.353 +- 0.073, 0.322 +- 0.084, 0.343 +- 0.099
Faith. Aritm (KL)= 		  =  0.455 +- 0.012, 0.492 +- 0.007, 0.510 +- 0.002, 0.550 +- 0.021
Faith. Armon (KL)= 		  =  0.388 +- 0.035, 0.280 +- 0.073, 0.188 +- 0.069, 0.178 +- 0.072
Faith. GMean (KL)= 	  =  0.420 +- 0.020, 0.367 +- 0.051, 0.302 +- 0.069, 0.305 +- 0.081
Computed for split load_split = id



Completed in  0:23:18.358932  for LECIGIN LBAPcore/assay



DONE LECI LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:30:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:30:01 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:30:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:30:43 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:30:53 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:09 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 08:31:25 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 60...
[0m[1;37mINFO[0m: [1mCheckpoint 60: 
-----------------------------------
Train ROC-AUC: 0.9644
Train Loss: 0.3162
ID Validation ROC-AUC: 0.9159
ID Validation Loss: 0.4976
ID Test ROC-AUC: 0.9149
ID Test Loss: 0.5133
OOD Validation ROC-AUC: 0.6062
OOD Validation Loss: 0.7427
OOD Test ROC-AUC: 0.6845
OOD Test Loss: 1.0938

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 11...
[0m[1;37mINFO[0m: [1mCheckpoint 11: 
-----------------------------------
Train ROC-AUC: 0.9089
Train Loss: 0.3173
ID Validation ROC-AUC: 0.8910
ID Validation Loss: 0.3404
ID Test ROC-AUC: 0.8888
ID Test Loss: 0.3479
OOD Validation ROC-AUC: 0.6543
OOD Validation Loss: 0.3422
OOD Test ROC-AUC: 0.6990
OOD Test Loss: 0.5882

[0m[1;37mINFO[0m: [1mChartInfo 0.9149 0.6845 0.8888 0.6990 0.8910 0.6543[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:31:26 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:31:36 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.561
SUFF++ for r=0.6 class 0.0 = 0.592 +- 0.289 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 class 1.0 = 0.654 +- 0.289 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 all KL = 0.495 +- 0.289 (in-sample avg dev_std = 0.570)
SUFF++ for r=0.6 all L1 = 0.647 +- 0.192 (in-sample avg dev_std = 0.570)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.537
SUFF++ for r=0.6 class 0.0 = 0.591 +- 0.285 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.6 class 1.0 = 0.633 +- 0.285 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.6 all KL = 0.525 +- 0.285 (in-sample avg dev_std = 0.551)
SUFF++ for r=0.6 all L1 = 0.626 +- 0.199 (in-sample avg dev_std = 0.551)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.637
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.589
NEC for r=0.6 class 0.0 = 0.388 +- 0.329 (in-sample avg dev_std = 0.552)
NEC for r=0.6 class 1.0 = 0.336 +- 0.329 (in-sample avg dev_std = 0.552)
NEC for r=0.6 all KL = 0.467 +- 0.329 (in-sample avg dev_std = 0.552)
NEC for r=0.6 all L1 = 0.342 +- 0.213 (in-sample avg dev_std = 0.552)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.572
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.541
NEC for r=0.6 class 0.0 = 0.379 +- 0.310 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1.0 = 0.34 +- 0.310 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.411 +- 0.310 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.347 +- 0.210 (in-sample avg dev_std = 0.505)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:32:39 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:32:39 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:33:11 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:33:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:33:32 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:33:48 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 50...
[0m[1;37mINFO[0m: [1mCheckpoint 50: 
-----------------------------------
Train ROC-AUC: 0.9658
Train Loss: 0.1509
ID Validation ROC-AUC: 0.9099
ID Validation Loss: 0.2557
ID Test ROC-AUC: 0.9129
ID Test Loss: 0.2578
OOD Validation ROC-AUC: 0.6398
OOD Validation Loss: 0.4377
OOD Test ROC-AUC: 0.6781
OOD Test Loss: 0.5882

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ROC-AUC: 0.9221
Train Loss: 0.2152
ID Validation ROC-AUC: 0.8909
ID Validation Loss: 0.2509
ID Test ROC-AUC: 0.8972
ID Test Loss: 0.2480
OOD Validation ROC-AUC: 0.6624
OOD Validation Loss: 0.3222
OOD Test ROC-AUC: 0.7061
OOD Test Loss: 0.4680

[0m[1;37mINFO[0m: [1mChartInfo 0.9129 0.6781 0.8972 0.7061 0.8909 0.6624[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:34:03 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:34:12 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.437
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.5
SUFF++ for r=0.6 class 0.0 = 0.686 +- 0.170 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 class 1.0 = 0.667 +- 0.170 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all KL = 0.746 +- 0.170 (in-sample avg dev_std = 0.396)
SUFF++ for r=0.6 all L1 = 0.669 +- 0.164 (in-sample avg dev_std = 0.396)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.442
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.483
SUFF++ for r=0.6 class 0.0 = 0.693 +- 0.170 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 class 1.0 = 0.667 +- 0.170 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all KL = 0.735 +- 0.170 (in-sample avg dev_std = 0.414)
SUFF++ for r=0.6 all L1 = 0.671 +- 0.161 (in-sample avg dev_std = 0.414)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.437
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.455
NEC for r=0.6 class 0.0 = 0.28 +- 0.169 (in-sample avg dev_std = 0.317)
NEC for r=0.6 class 1.0 = 0.285 +- 0.169 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all KL = 0.188 +- 0.169 (in-sample avg dev_std = 0.317)
NEC for r=0.6 all L1 = 0.284 +- 0.166 (in-sample avg dev_std = 0.317)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.442
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.451
NEC for r=0.6 class 0.0 = 0.282 +- 0.180 (in-sample avg dev_std = 0.336)
NEC for r=0.6 class 1.0 = 0.297 +- 0.180 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all KL = 0.211 +- 0.180 (in-sample avg dev_std = 0.336)
NEC for r=0.6 all L1 = 0.294 +- 0.174 (in-sample avg dev_std = 0.336)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:35:16 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:35:16 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:35:47 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:35:58 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:08 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:24 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 20...
[0m[1;37mINFO[0m: [1mCheckpoint 20: 
-----------------------------------
Train ROC-AUC: 0.9373
Train Loss: 0.1953
ID Validation ROC-AUC: 0.9097
ID Validation Loss: 0.2289
ID Test ROC-AUC: 0.9081
ID Test Loss: 0.2333
OOD Validation ROC-AUC: 0.6243
OOD Validation Loss: 0.3584
OOD Test ROC-AUC: 0.6758
OOD Test Loss: 0.4758

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ROC-AUC: 0.9088
Train Loss: 0.2311
ID Validation ROC-AUC: 0.8849
ID Validation Loss: 0.2505
ID Test ROC-AUC: 0.8879
ID Test Loss: 0.2510
OOD Validation ROC-AUC: 0.6619
OOD Validation Loss: 0.3260
OOD Test ROC-AUC: 0.6983
OOD Test Loss: 0.4346

[0m[1;37mINFO[0m: [1mChartInfo 0.9081 0.6758 0.8879 0.6983 0.8849 0.6619[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:36:40 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:36:49 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.429
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.427
SUFF++ for r=0.6 class 0.0 = 0.726 +- 0.077 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 class 1.0 = 0.722 +- 0.077 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 all KL = 0.896 +- 0.077 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 all L1 = 0.722 +- 0.095 (in-sample avg dev_std = 0.267)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.503
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.465
SUFF++ for r=0.6 class 0.0 = 0.728 +- 0.078 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 class 1.0 = 0.716 +- 0.078 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 all KL = 0.894 +- 0.078 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.6 all L1 = 0.718 +- 0.094 (in-sample avg dev_std = 0.267)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.429
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.437
NEC for r=0.6 class 0.0 = 0.222 +- 0.062 (in-sample avg dev_std = 0.200)
NEC for r=0.6 class 1.0 = 0.209 +- 0.062 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all KL = 0.06 +- 0.062 (in-sample avg dev_std = 0.200)
NEC for r=0.6 all L1 = 0.21 +- 0.093 (in-sample avg dev_std = 0.200)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.503
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.477
NEC for r=0.6 class 0.0 = 0.21 +- 0.066 (in-sample avg dev_std = 0.189)
NEC for r=0.6 class 1.0 = 0.212 +- 0.066 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all KL = 0.059 +- 0.066 (in-sample avg dev_std = 0.189)
NEC for r=0.6 all L1 = 0.212 +- 0.093 (in-sample avg dev_std = 0.189)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:37:53 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:37:53 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:38:25 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:38:35 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:38:45 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:02 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 59...
[0m[1;37mINFO[0m: [1mCheckpoint 59: 
-----------------------------------
Train ROC-AUC: 0.9662
Train Loss: 0.1724
ID Validation ROC-AUC: 0.9138
ID Validation Loss: 0.3123
ID Test ROC-AUC: 0.9111
ID Test Loss: 0.3263
OOD Validation ROC-AUC: 0.5895
OOD Validation Loss: 0.6025
OOD Test ROC-AUC: 0.6681
OOD Test Loss: 0.7747

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ROC-AUC: 0.9269
Train Loss: 0.2093
ID Validation ROC-AUC: 0.8991
ID Validation Loss: 0.2421
ID Test ROC-AUC: 0.9021
ID Test Loss: 0.2424
OOD Validation ROC-AUC: 0.6642
OOD Validation Loss: 0.3339
OOD Test ROC-AUC: 0.6850
OOD Test Loss: 0.4826

[0m[1;37mINFO[0m: [1mChartInfo 0.9111 0.6681 0.9021 0.6850 0.8991 0.6642[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:39:18 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:39:27 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.339
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.418
SUFF++ for r=0.6 class 0.0 = 0.974 +- 0.076 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 class 1.0 = 0.988 +- 0.076 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 all KL = 0.975 +- 0.076 (in-sample avg dev_std = 0.078)
SUFF++ for r=0.6 all L1 = 0.986 +- 0.046 (in-sample avg dev_std = 0.078)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.405
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.453
SUFF++ for r=0.6 class 0.0 = 0.976 +- 0.085 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.6 class 1.0 = 0.981 +- 0.085 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.6 all KL = 0.969 +- 0.085 (in-sample avg dev_std = 0.087)
SUFF++ for r=0.6 all L1 = 0.98 +- 0.060 (in-sample avg dev_std = 0.087)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.339
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.411
NEC for r=0.6 class 0.0 = 0.024 +- 0.101 (in-sample avg dev_std = 0.091)
NEC for r=0.6 class 1.0 = 0.021 +- 0.101 (in-sample avg dev_std = 0.091)
NEC for r=0.6 all KL = 0.04 +- 0.101 (in-sample avg dev_std = 0.091)
NEC for r=0.6 all L1 = 0.021 +- 0.061 (in-sample avg dev_std = 0.091)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.405
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.461
NEC for r=0.6 class 0.0 = 0.037 +- 0.120 (in-sample avg dev_std = 0.112)
NEC for r=0.6 class 1.0 = 0.029 +- 0.120 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all KL = 0.051 +- 0.120 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all L1 = 0.03 +- 0.075 (in-sample avg dev_std = 0.112)
model_dirname= repr_CIGAGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:40:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:40:31 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:02 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:12 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:23 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:39 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mCreating GINFeatExtractor:  3
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing  1  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 51...
[0m[1;37mINFO[0m: [1mCheckpoint 51: 
-----------------------------------
Train ROC-AUC: 0.9661
Train Loss: 0.1473
ID Validation ROC-AUC: 0.9133
ID Validation Loss: 0.2363
ID Test ROC-AUC: 0.9109
ID Test Loss: 0.2418
OOD Validation ROC-AUC: 0.6302
OOD Validation Loss: 0.4522
OOD Test ROC-AUC: 0.6797
OOD Test Loss: 0.5703

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 9...
[0m[1;37mINFO[0m: [1mCheckpoint 9: 
-----------------------------------
Train ROC-AUC: 0.9108
Train Loss: 0.2361
ID Validation ROC-AUC: 0.8892
ID Validation Loss: 0.2523
ID Test ROC-AUC: 0.8864
ID Test Loss: 0.2555
OOD Validation ROC-AUC: 0.6513
OOD Validation Loss: 0.3289
OOD Test ROC-AUC: 0.7073
OOD Test Loss: 0.4218

[0m[1;37mINFO[0m: [1mChartInfo 0.9109 0.6797 0.8864 0.7073 0.8892 0.6513[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:41:55 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:42:04 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.683
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.651
SUFF++ for r=0.6 class 0.0 = 0.98 +- 0.110 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 class 1.0 = 0.993 +- 0.110 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 all KL = 0.971 +- 0.110 (in-sample avg dev_std = 0.084)
SUFF++ for r=0.6 all L1 = 0.991 +- 0.036 (in-sample avg dev_std = 0.084)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.57
SUFF++ for r=0.6 class 0.0 = 0.976 +- 0.138 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 class 1.0 = 0.988 +- 0.138 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 all KL = 0.96 +- 0.138 (in-sample avg dev_std = 0.115)
SUFF++ for r=0.6 all L1 = 0.986 +- 0.053 (in-sample avg dev_std = 0.115)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.683
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.689
NEC for r=0.6 class 0.0 = 0.057 +- 0.140 (in-sample avg dev_std = 0.104)
NEC for r=0.6 class 1.0 = 0.01 +- 0.140 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all KL = 0.042 +- 0.140 (in-sample avg dev_std = 0.104)
NEC for r=0.6 all L1 = 0.015 +- 0.063 (in-sample avg dev_std = 0.104)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.609
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.582
NEC for r=0.6 class 0.0 = 0.038 +- 0.197 (in-sample avg dev_std = 0.142)
NEC for r=0.6 class 1.0 = 0.025 +- 0.197 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all KL = 0.077 +- 0.197 (in-sample avg dev_std = 0.142)
NEC for r=0.6 all L1 = 0.027 +- 0.081 (in-sample avg dev_std = 0.142)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.495], 'all_L1': [0.647]}), defaultdict(<class 'list'>, {'all_KL': [0.746], 'all_L1': [0.669]}), defaultdict(<class 'list'>, {'all_KL': [0.896], 'all_L1': [0.722]}), defaultdict(<class 'list'>, {'all_KL': [0.975], 'all_L1': [0.986]}), defaultdict(<class 'list'>, {'all_KL': [0.971], 'all_L1': [0.991]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.467], 'all_L1': [0.342]}), defaultdict(<class 'list'>, {'all_KL': [0.188], 'all_L1': [0.284]}), defaultdict(<class 'list'>, {'all_KL': [0.06], 'all_L1': [0.21]}), defaultdict(<class 'list'>, {'all_KL': [0.04], 'all_L1': [0.021]}), defaultdict(<class 'list'>, {'all_KL': [0.042], 'all_L1': [0.015]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.525], 'all_L1': [0.626]}), defaultdict(<class 'list'>, {'all_KL': [0.735], 'all_L1': [0.671]}), defaultdict(<class 'list'>, {'all_KL': [0.894], 'all_L1': [0.718]}), defaultdict(<class 'list'>, {'all_KL': [0.969], 'all_L1': [0.98]}), defaultdict(<class 'list'>, {'all_KL': [0.96], 'all_L1': [0.986]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.411], 'all_L1': [0.347]}), defaultdict(<class 'list'>, {'all_KL': [0.211], 'all_L1': [0.294]}), defaultdict(<class 'list'>, {'all_KL': [0.059], 'all_L1': [0.212]}), defaultdict(<class 'list'>, {'all_KL': [0.051], 'all_L1': [0.03]}), defaultdict(<class 'list'>, {'all_KL': [0.077], 'all_L1': [0.027]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.803 +- 0.153
suff++ class all_KL  =  0.817 +- 0.181
suff++_acc_int  =  0.511 +- 0.087
nec class all_L1  =  0.174 +- 0.134
nec class all_KL  =  0.159 +- 0.163
nec_acc_int  =  0.516 +- 0.106

Eval split test
suff++ class all_L1  =  0.796 +- 0.155
suff++ class all_KL  =  0.817 +- 0.168
suff++_acc_int  =  0.502 +- 0.045
nec class all_L1  =  0.182 +- 0.133
nec class all_KL  =  0.162 +- 0.138
nec_acc_int  =  0.502 +- 0.051


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.489 +- 0.015
Faith. Armon (L1)= 		  =  0.248 +- 0.178
Faith. GMean (L1)= 	  =  0.312 +- 0.149
Faith. Aritm (KL)= 		  =  0.488 +- 0.016
Faith. Armon (KL)= 		  =  0.210 +- 0.158
Faith. GMean (KL)= 	  =  0.297 +- 0.112

Eval split test
Faith. Aritm (L1)= 		  =  0.489 +- 0.015
Faith. Armon (L1)= 		  =  0.259 +- 0.170
Faith. GMean (L1)= 	  =  0.327 +- 0.133
Faith. Aritm (KL)= 		  =  0.489 +- 0.021
Faith. Armon (KL)= 		  =  0.228 +- 0.143
Faith. GMean (KL)= 	  =  0.316 +- 0.096
Computed for split load_split = id



Completed in  0:13:08.666935  for CIGAGIN LBAPcore/assay



DONE CIGA LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:43:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:43:29 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:00 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:11 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:21 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:37 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 08:44:52 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.9575
Train Loss: 0.1735
ID Validation ROC-AUC: 0.9126
ID Validation Loss: 0.2431
ID Test ROC-AUC: 0.9180
ID Test Loss: 0.2370
OOD Validation ROC-AUC: 0.6443
OOD Validation Loss: 0.5116
OOD Test ROC-AUC: 0.6826
OOD Test Loss: 0.6087

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 54...
[0m[1;37mINFO[0m: [1mCheckpoint 54: 
-----------------------------------
Train ROC-AUC: 0.9308
Train Loss: 0.2188
ID Validation ROC-AUC: 0.9073
ID Validation Loss: 0.2593
ID Test ROC-AUC: 0.9108
ID Test Loss: 0.2562
OOD Validation ROC-AUC: 0.6898
OOD Validation Loss: 0.3322
OOD Test ROC-AUC: 0.7117
OOD Test Loss: 0.5314

[0m[1;37mINFO[0m: [1mChartInfo 0.9180 0.6826 0.9108 0.7117 0.9073 0.6898[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:44:54 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:44:58 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.593
SUFF++ for r=0.3 class 0.0 = 0.714 +- 0.191 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 class 1.0 = 0.813 +- 0.191 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all KL = 0.809 +- 0.191 (in-sample avg dev_std = 0.281)
SUFF++ for r=0.3 all L1 = 0.802 +- 0.181 (in-sample avg dev_std = 0.281)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.633
SUFF++ for r=0.6 class 0.0 = 0.721 +- 0.139 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.6 class 1.0 = 0.827 +- 0.139 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.6 all KL = 0.87 +- 0.139 (in-sample avg dev_std = 0.239)
SUFF++ for r=0.6 all L1 = 0.815 +- 0.152 (in-sample avg dev_std = 0.239)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.695
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.663
SUFF++ for r=0.9 class 0.0 = 0.837 +- 0.092 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 class 1.0 = 0.882 +- 0.092 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all KL = 0.943 +- 0.092 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.9 all L1 = 0.877 +- 0.120 (in-sample avg dev_std = 0.152)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.577
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.55
SUFF++ for r=0.3 class 0.0 = 0.738 +- 0.187 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.3 class 1.0 = 0.791 +- 0.187 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.3 all KL = 0.789 +- 0.187 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.3 all L1 = 0.783 +- 0.175 (in-sample avg dev_std = 0.305)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.598
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.55
SUFF++ for r=0.6 class 0.0 = 0.74 +- 0.143 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 class 1.0 = 0.792 +- 0.143 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all KL = 0.851 +- 0.143 (in-sample avg dev_std = 0.268)
SUFF++ for r=0.6 all L1 = 0.784 +- 0.158 (in-sample avg dev_std = 0.268)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.572
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.565
SUFF++ for r=0.9 class 0.0 = 0.834 +- 0.076 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 class 1.0 = 0.857 +- 0.076 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all KL = 0.942 +- 0.076 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.9 all L1 = 0.853 +- 0.129 (in-sample avg dev_std = 0.147)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.59
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.623
NEC for r=0.3 class 0.0 = 0.296 +- 0.216 (in-sample avg dev_std = 0.285)
NEC for r=0.3 class 1.0 = 0.186 +- 0.216 (in-sample avg dev_std = 0.285)
NEC for r=0.3 all KL = 0.19 +- 0.216 (in-sample avg dev_std = 0.285)
NEC for r=0.3 all L1 = 0.199 +- 0.184 (in-sample avg dev_std = 0.285)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.675
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.677
NEC for r=0.6 class 0.0 = 0.27 +- 0.152 (in-sample avg dev_std = 0.249)
NEC for r=0.6 class 1.0 = 0.171 +- 0.152 (in-sample avg dev_std = 0.249)
NEC for r=0.6 all KL = 0.13 +- 0.152 (in-sample avg dev_std = 0.249)
NEC for r=0.6 all L1 = 0.183 +- 0.147 (in-sample avg dev_std = 0.249)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.694
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.688
NEC for r=0.9 class 0.0 = 0.198 +- 0.105 (in-sample avg dev_std = 0.198)
NEC for r=0.9 class 1.0 = 0.136 +- 0.105 (in-sample avg dev_std = 0.198)
NEC for r=0.9 all KL = 0.079 +- 0.105 (in-sample avg dev_std = 0.198)
NEC for r=0.9 all L1 = 0.143 +- 0.118 (in-sample avg dev_std = 0.198)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.701
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.7
NEC for r=1.0 class 0.0 = 0.185 +- 0.090 (in-sample avg dev_std = 0.171)
NEC for r=1.0 class 1.0 = 0.117 +- 0.090 (in-sample avg dev_std = 0.171)
NEC for r=1.0 all KL = 0.063 +- 0.090 (in-sample avg dev_std = 0.171)
NEC for r=1.0 all L1 = 0.125 +- 0.115 (in-sample avg dev_std = 0.171)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.576
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.567
NEC for r=0.3 class 0.0 = 0.252 +- 0.205 (in-sample avg dev_std = 0.301)
NEC for r=0.3 class 1.0 = 0.201 +- 0.205 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all KL = 0.19 +- 0.205 (in-sample avg dev_std = 0.301)
NEC for r=0.3 all L1 = 0.21 +- 0.186 (in-sample avg dev_std = 0.301)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.598
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.588
NEC for r=0.6 class 0.0 = 0.264 +- 0.153 (in-sample avg dev_std = 0.281)
NEC for r=0.6 class 1.0 = 0.209 +- 0.153 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all KL = 0.151 +- 0.153 (in-sample avg dev_std = 0.281)
NEC for r=0.6 all L1 = 0.218 +- 0.156 (in-sample avg dev_std = 0.281)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.572
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.594
NEC for r=0.9 class 0.0 = 0.224 +- 0.091 (in-sample avg dev_std = 0.210)
NEC for r=0.9 class 1.0 = 0.167 +- 0.091 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all KL = 0.086 +- 0.091 (in-sample avg dev_std = 0.210)
NEC for r=0.9 all L1 = 0.176 +- 0.126 (in-sample avg dev_std = 0.210)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.575
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.587
NEC for r=1.0 class 0.0 = 0.192 +- 0.088 (in-sample avg dev_std = 0.191)
NEC for r=1.0 class 1.0 = 0.144 +- 0.088 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all KL = 0.072 +- 0.088 (in-sample avg dev_std = 0.191)
NEC for r=1.0 all L1 = 0.152 +- 0.119 (in-sample avg dev_std = 0.191)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:48:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:48:00 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:48:32 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:48:42 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:48:53 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:08 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ROC-AUC: 0.9581
Train Loss: 0.1675
ID Validation ROC-AUC: 0.9155
ID Validation Loss: 0.2388
ID Test ROC-AUC: 0.9181
ID Test Loss: 0.2360
OOD Validation ROC-AUC: 0.6422
OOD Validation Loss: 0.5090
OOD Test ROC-AUC: 0.6891
OOD Test Loss: 0.6078

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.9226
Train Loss: 0.2146
ID Validation ROC-AUC: 0.8997
ID Validation Loss: 0.2460
ID Test ROC-AUC: 0.9051
ID Test Loss: 0.2424
OOD Validation ROC-AUC: 0.6819
OOD Validation Loss: 0.3340
OOD Test ROC-AUC: 0.6983
OOD Test Loss: 0.4973

[0m[1;37mINFO[0m: [1mChartInfo 0.9181 0.6891 0.9051 0.6983 0.8997 0.6819[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:49:24 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:49:28 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.537
SUFF++ for r=0.3 class 0.0 = 0.76 +- 0.229 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.3 class 1.0 = 0.839 +- 0.229 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.3 all KL = 0.795 +- 0.229 (in-sample avg dev_std = 0.314)
SUFF++ for r=0.3 all L1 = 0.829 +- 0.177 (in-sample avg dev_std = 0.314)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.602
SUFF++ for r=0.6 class 0.0 = 0.722 +- 0.166 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 class 1.0 = 0.814 +- 0.166 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all KL = 0.841 +- 0.166 (in-sample avg dev_std = 0.272)
SUFF++ for r=0.6 all L1 = 0.804 +- 0.170 (in-sample avg dev_std = 0.272)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.663
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.624
SUFF++ for r=0.9 class 0.0 = 0.764 +- 0.119 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 class 1.0 = 0.84 +- 0.119 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all KL = 0.917 +- 0.119 (in-sample avg dev_std = 0.194)
SUFF++ for r=0.9 all L1 = 0.831 +- 0.146 (in-sample avg dev_std = 0.194)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.518
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
SUFF++ for r=0.3 class 0.0 = 0.763 +- 0.234 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 class 1.0 = 0.785 +- 0.234 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 all KL = 0.76 +- 0.234 (in-sample avg dev_std = 0.334)
SUFF++ for r=0.3 all L1 = 0.782 +- 0.197 (in-sample avg dev_std = 0.334)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.532
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.549
SUFF++ for r=0.6 class 0.0 = 0.721 +- 0.175 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.6 class 1.0 = 0.764 +- 0.175 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.6 all KL = 0.81 +- 0.175 (in-sample avg dev_std = 0.301)
SUFF++ for r=0.6 all L1 = 0.757 +- 0.182 (in-sample avg dev_std = 0.301)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.539
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.563
SUFF++ for r=0.9 class 0.0 = 0.787 +- 0.120 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 class 1.0 = 0.8 +- 0.120 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 all KL = 0.903 +- 0.120 (in-sample avg dev_std = 0.213)
SUFF++ for r=0.9 all L1 = 0.798 +- 0.153 (in-sample avg dev_std = 0.213)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.549
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.627
NEC for r=0.3 class 0.0 = 0.262 +- 0.228 (in-sample avg dev_std = 0.283)
NEC for r=0.3 class 1.0 = 0.156 +- 0.228 (in-sample avg dev_std = 0.283)
NEC for r=0.3 all KL = 0.19 +- 0.228 (in-sample avg dev_std = 0.283)
NEC for r=0.3 all L1 = 0.169 +- 0.178 (in-sample avg dev_std = 0.283)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.619
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.648
NEC for r=0.6 class 0.0 = 0.281 +- 0.164 (in-sample avg dev_std = 0.264)
NEC for r=0.6 class 1.0 = 0.186 +- 0.164 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all KL = 0.156 +- 0.164 (in-sample avg dev_std = 0.264)
NEC for r=0.6 all L1 = 0.197 +- 0.160 (in-sample avg dev_std = 0.264)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.664
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.663
NEC for r=0.9 class 0.0 = 0.252 +- 0.126 (in-sample avg dev_std = 0.236)
NEC for r=0.9 class 1.0 = 0.185 +- 0.126 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all KL = 0.106 +- 0.126 (in-sample avg dev_std = 0.236)
NEC for r=0.9 all L1 = 0.193 +- 0.140 (in-sample avg dev_std = 0.236)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.67
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0.0 = 0.224 +- 0.113 (in-sample avg dev_std = 0.219)
NEC for r=1.0 class 1.0 = 0.164 +- 0.113 (in-sample avg dev_std = 0.219)
NEC for r=1.0 all KL = 0.088 +- 0.113 (in-sample avg dev_std = 0.219)
NEC for r=1.0 all L1 = 0.171 +- 0.135 (in-sample avg dev_std = 0.219)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.517
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.561
NEC for r=0.3 class 0.0 = 0.229 +- 0.237 (in-sample avg dev_std = 0.307)
NEC for r=0.3 class 1.0 = 0.201 +- 0.237 (in-sample avg dev_std = 0.307)
NEC for r=0.3 all KL = 0.209 +- 0.237 (in-sample avg dev_std = 0.307)
NEC for r=0.3 all L1 = 0.205 +- 0.197 (in-sample avg dev_std = 0.307)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.532
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.569
NEC for r=0.6 class 0.0 = 0.265 +- 0.178 (in-sample avg dev_std = 0.294)
NEC for r=0.6 class 1.0 = 0.228 +- 0.178 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all KL = 0.175 +- 0.178 (in-sample avg dev_std = 0.294)
NEC for r=0.6 all L1 = 0.234 +- 0.167 (in-sample avg dev_std = 0.294)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.539
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.557
NEC for r=0.9 class 0.0 = 0.24 +- 0.131 (in-sample avg dev_std = 0.254)
NEC for r=0.9 class 1.0 = 0.224 +- 0.131 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all KL = 0.12 +- 0.131 (in-sample avg dev_std = 0.254)
NEC for r=0.9 all L1 = 0.227 +- 0.149 (in-sample avg dev_std = 0.254)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.538
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.571
NEC for r=1.0 class 0.0 = 0.215 +- 0.120 (in-sample avg dev_std = 0.239)
NEC for r=1.0 class 1.0 = 0.199 +- 0.120 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all KL = 0.099 +- 0.120 (in-sample avg dev_std = 0.239)
NEC for r=1.0 all L1 = 0.202 +- 0.142 (in-sample avg dev_std = 0.239)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:52:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:52:31 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:03 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:13 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:24 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:40 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 172...
[0m[1;37mINFO[0m: [1mCheckpoint 172: 
-----------------------------------
Train ROC-AUC: 0.9565
Train Loss: 0.1673
ID Validation ROC-AUC: 0.9166
ID Validation Loss: 0.2335
ID Test ROC-AUC: 0.9184
ID Test Loss: 0.2312
OOD Validation ROC-AUC: 0.6443
OOD Validation Loss: 0.4868
OOD Test ROC-AUC: 0.6885
OOD Test Loss: 0.5753

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 13...
[0m[1;37mINFO[0m: [1mCheckpoint 13: 
-----------------------------------
Train ROC-AUC: 0.8916
Train Loss: 0.2426
ID Validation ROC-AUC: 0.8768
ID Validation Loss: 0.2559
ID Test ROC-AUC: 0.8832
ID Test Loss: 0.2531
OOD Validation ROC-AUC: 0.6829
OOD Validation Loss: 0.2941
OOD Test ROC-AUC: 0.6934
OOD Test Loss: 0.4478

[0m[1;37mINFO[0m: [1mChartInfo 0.9184 0.6885 0.8832 0.6934 0.8768 0.6829[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:53:55 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:53:59 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.532
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.53
SUFF++ for r=0.3 class 0.0 = 0.55 +- 0.220 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.3 class 1.0 = 0.556 +- 0.220 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.3 all KL = 0.603 +- 0.220 (in-sample avg dev_std = 0.535)
SUFF++ for r=0.3 all L1 = 0.555 +- 0.130 (in-sample avg dev_std = 0.535)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.538
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.544
SUFF++ for r=0.6 class 0.0 = 0.61 +- 0.195 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 class 1.0 = 0.628 +- 0.195 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all KL = 0.729 +- 0.195 (in-sample avg dev_std = 0.444)
SUFF++ for r=0.6 all L1 = 0.626 +- 0.139 (in-sample avg dev_std = 0.444)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.561
SUFF++ for r=0.9 class 0.0 = 0.771 +- 0.108 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 class 1.0 = 0.771 +- 0.108 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all KL = 0.908 +- 0.108 (in-sample avg dev_std = 0.240)
SUFF++ for r=0.9 all L1 = 0.771 +- 0.130 (in-sample avg dev_std = 0.240)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.524
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.543
SUFF++ for r=0.3 class 0.0 = 0.545 +- 0.220 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 class 1.0 = 0.558 +- 0.220 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all KL = 0.606 +- 0.220 (in-sample avg dev_std = 0.530)
SUFF++ for r=0.3 all L1 = 0.556 +- 0.133 (in-sample avg dev_std = 0.530)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.531
SUFF++ for r=0.6 class 0.0 = 0.634 +- 0.189 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 class 1.0 = 0.637 +- 0.189 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all KL = 0.732 +- 0.189 (in-sample avg dev_std = 0.446)
SUFF++ for r=0.6 all L1 = 0.636 +- 0.140 (in-sample avg dev_std = 0.446)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.545
SUFF++ for r=0.9 class 0.0 = 0.767 +- 0.107 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 class 1.0 = 0.775 +- 0.107 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all KL = 0.905 +- 0.107 (in-sample avg dev_std = 0.247)
SUFF++ for r=0.9 all L1 = 0.774 +- 0.129 (in-sample avg dev_std = 0.247)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.532
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.559
NEC for r=0.3 class 0.0 = 0.35 +- 0.254 (in-sample avg dev_std = 0.464)
NEC for r=0.3 class 1.0 = 0.376 +- 0.254 (in-sample avg dev_std = 0.464)
NEC for r=0.3 all KL = 0.309 +- 0.254 (in-sample avg dev_std = 0.464)
NEC for r=0.3 all L1 = 0.373 +- 0.190 (in-sample avg dev_std = 0.464)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.538
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.57
NEC for r=0.6 class 0.0 = 0.303 +- 0.201 (in-sample avg dev_std = 0.382)
NEC for r=0.6 class 1.0 = 0.305 +- 0.201 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all KL = 0.202 +- 0.201 (in-sample avg dev_std = 0.382)
NEC for r=0.6 all L1 = 0.305 +- 0.171 (in-sample avg dev_std = 0.382)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.57
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.578
NEC for r=0.9 class 0.0 = 0.235 +- 0.116 (in-sample avg dev_std = 0.265)
NEC for r=0.9 class 1.0 = 0.237 +- 0.116 (in-sample avg dev_std = 0.265)
NEC for r=0.9 all KL = 0.101 +- 0.116 (in-sample avg dev_std = 0.265)
NEC for r=0.9 all L1 = 0.237 +- 0.131 (in-sample avg dev_std = 0.265)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.573
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0.0 = 0.208 +- 0.101 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1.0 = 0.207 +- 0.101 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.078 +- 0.101 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.207 +- 0.120 (in-sample avg dev_std = 0.238)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.525
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.537
NEC for r=0.3 class 0.0 = 0.374 +- 0.254 (in-sample avg dev_std = 0.441)
NEC for r=0.3 class 1.0 = 0.36 +- 0.254 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all KL = 0.293 +- 0.254 (in-sample avg dev_std = 0.441)
NEC for r=0.3 all L1 = 0.362 +- 0.194 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.54
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.559
NEC for r=0.6 class 0.0 = 0.311 +- 0.208 (in-sample avg dev_std = 0.365)
NEC for r=0.6 class 1.0 = 0.303 +- 0.208 (in-sample avg dev_std = 0.365)
NEC for r=0.6 all KL = 0.205 +- 0.208 (in-sample avg dev_std = 0.365)
NEC for r=0.6 all L1 = 0.304 +- 0.182 (in-sample avg dev_std = 0.365)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.567
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.574
NEC for r=0.9 class 0.0 = 0.225 +- 0.128 (in-sample avg dev_std = 0.268)
NEC for r=0.9 class 1.0 = 0.233 +- 0.128 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all KL = 0.106 +- 0.128 (in-sample avg dev_std = 0.268)
NEC for r=0.9 all L1 = 0.232 +- 0.140 (in-sample avg dev_std = 0.268)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.57
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.585
NEC for r=1.0 class 0.0 = 0.213 +- 0.108 (in-sample avg dev_std = 0.238)
NEC for r=1.0 class 1.0 = 0.206 +- 0.108 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all KL = 0.084 +- 0.108 (in-sample avg dev_std = 0.238)
NEC for r=1.0 all L1 = 0.207 +- 0.127 (in-sample avg dev_std = 0.238)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 20:57:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 08:57:02 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 08:57:34 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 08:57:44 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 08:57:54 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:10 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 185...
[0m[1;37mINFO[0m: [1mCheckpoint 185: 
-----------------------------------
Train ROC-AUC: 0.9582
Train Loss: 0.1732
ID Validation ROC-AUC: 0.9167
ID Validation Loss: 0.2422
ID Test ROC-AUC: 0.9192
ID Test Loss: 0.2373
OOD Validation ROC-AUC: 0.6602
OOD Validation Loss: 0.5268
OOD Test ROC-AUC: 0.6848
OOD Test Loss: 0.6351

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 15...
[0m[1;37mINFO[0m: [1mCheckpoint 15: 
-----------------------------------
Train ROC-AUC: 0.8939
Train Loss: 0.2644
ID Validation ROC-AUC: 0.8796
ID Validation Loss: 0.2781
ID Test ROC-AUC: 0.8853
ID Test Loss: 0.2732
OOD Validation ROC-AUC: 0.6941
OOD Validation Loss: 0.3916
OOD Test ROC-AUC: 0.6881
OOD Test Loss: 0.4866

[0m[1;37mINFO[0m: [1mChartInfo 0.9192 0.6848 0.8853 0.6881 0.8796 0.6941[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 08:58:26 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 08:58:30 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.471
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.451
SUFF++ for r=0.3 class 0.0 = 0.601 +- 0.251 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 class 1.0 = 0.578 +- 0.251 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all KL = 0.526 +- 0.251 (in-sample avg dev_std = 0.582)
SUFF++ for r=0.3 all L1 = 0.581 +- 0.157 (in-sample avg dev_std = 0.582)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.516
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.473
SUFF++ for r=0.6 class 0.0 = 0.684 +- 0.193 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 class 1.0 = 0.659 +- 0.193 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all KL = 0.721 +- 0.193 (in-sample avg dev_std = 0.430)
SUFF++ for r=0.6 all L1 = 0.662 +- 0.141 (in-sample avg dev_std = 0.430)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.469
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.473
SUFF++ for r=0.9 class 0.0 = 0.789 +- 0.152 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 class 1.0 = 0.752 +- 0.152 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all KL = 0.86 +- 0.152 (in-sample avg dev_std = 0.285)
SUFF++ for r=0.9 all L1 = 0.757 +- 0.153 (in-sample avg dev_std = 0.285)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.508
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.461
SUFF++ for r=0.3 class 0.0 = 0.621 +- 0.254 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 class 1.0 = 0.6 +- 0.254 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all KL = 0.549 +- 0.254 (in-sample avg dev_std = 0.562)
SUFF++ for r=0.3 all L1 = 0.604 +- 0.163 (in-sample avg dev_std = 0.562)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.448
SUFF++ for r=0.6 class 0.0 = 0.688 +- 0.196 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 class 1.0 = 0.66 +- 0.196 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all KL = 0.731 +- 0.196 (in-sample avg dev_std = 0.410)
SUFF++ for r=0.6 all L1 = 0.665 +- 0.157 (in-sample avg dev_std = 0.410)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.433
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.444
SUFF++ for r=0.9 class 0.0 = 0.802 +- 0.145 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 class 1.0 = 0.752 +- 0.145 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all KL = 0.87 +- 0.145 (in-sample avg dev_std = 0.267)
SUFF++ for r=0.9 all L1 = 0.76 +- 0.156 (in-sample avg dev_std = 0.267)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.471
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.485
NEC for r=0.3 class 0.0 = 0.323 +- 0.263 (in-sample avg dev_std = 0.442)
NEC for r=0.3 class 1.0 = 0.314 +- 0.263 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all KL = 0.315 +- 0.263 (in-sample avg dev_std = 0.442)
NEC for r=0.3 all L1 = 0.315 +- 0.201 (in-sample avg dev_std = 0.442)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.517
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.485
NEC for r=0.6 class 0.0 = 0.299 +- 0.186 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 1.0 = 0.279 +- 0.186 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all KL = 0.204 +- 0.186 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all L1 = 0.282 +- 0.159 (in-sample avg dev_std = 0.357)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.469
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.484
NEC for r=0.9 class 0.0 = 0.274 +- 0.160 (in-sample avg dev_std = 0.324)
NEC for r=0.9 class 1.0 = 0.263 +- 0.160 (in-sample avg dev_std = 0.324)
NEC for r=0.9 all KL = 0.164 +- 0.160 (in-sample avg dev_std = 0.324)
NEC for r=0.9 all L1 = 0.264 +- 0.144 (in-sample avg dev_std = 0.324)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.466
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.479
NEC for r=1.0 class 0.0 = 0.26 +- 0.145 (in-sample avg dev_std = 0.322)
NEC for r=1.0 class 1.0 = 0.252 +- 0.145 (in-sample avg dev_std = 0.322)
NEC for r=1.0 all KL = 0.152 +- 0.145 (in-sample avg dev_std = 0.322)
NEC for r=1.0 all L1 = 0.253 +- 0.137 (in-sample avg dev_std = 0.322)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.508
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.485
NEC for r=0.3 class 0.0 = 0.276 +- 0.261 (in-sample avg dev_std = 0.407)
NEC for r=0.3 class 1.0 = 0.293 +- 0.261 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all KL = 0.285 +- 0.261 (in-sample avg dev_std = 0.407)
NEC for r=0.3 all L1 = 0.29 +- 0.199 (in-sample avg dev_std = 0.407)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.485
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.468
NEC for r=0.6 class 0.0 = 0.267 +- 0.194 (in-sample avg dev_std = 0.352)
NEC for r=0.6 class 1.0 = 0.28 +- 0.194 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all KL = 0.203 +- 0.194 (in-sample avg dev_std = 0.352)
NEC for r=0.6 all L1 = 0.278 +- 0.163 (in-sample avg dev_std = 0.352)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.433
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.438
NEC for r=0.9 class 0.0 = 0.219 +- 0.148 (in-sample avg dev_std = 0.315)
NEC for r=0.9 class 1.0 = 0.273 +- 0.148 (in-sample avg dev_std = 0.315)
NEC for r=0.9 all KL = 0.158 +- 0.148 (in-sample avg dev_std = 0.315)
NEC for r=0.9 all L1 = 0.264 +- 0.146 (in-sample avg dev_std = 0.315)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.424
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.434
NEC for r=1.0 class 0.0 = 0.215 +- 0.145 (in-sample avg dev_std = 0.304)
NEC for r=1.0 class 1.0 = 0.257 +- 0.145 (in-sample avg dev_std = 0.304)
NEC for r=1.0 all KL = 0.146 +- 0.145 (in-sample avg dev_std = 0.304)
NEC for r=1.0 all L1 = 0.25 +- 0.146 (in-sample avg dev_std = 0.304)
model_dirname= repr_GSATGIN_3l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 21:01:33 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 09/28/2024 09:01:33 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:04 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:15 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:25 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:41 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mUsing the fixed _explain_ functionality
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 173...
[0m[1;37mINFO[0m: [1mCheckpoint 173: 
-----------------------------------
Train ROC-AUC: 0.9582
Train Loss: 0.1714
ID Validation ROC-AUC: 0.9187
ID Validation Loss: 0.2342
ID Test ROC-AUC: 0.9179
ID Test Loss: 0.2354
OOD Validation ROC-AUC: 0.6444
OOD Validation Loss: 0.5164
OOD Test ROC-AUC: 0.6886
OOD Test Loss: 0.5929

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 43...
[0m[1;37mINFO[0m: [1mCheckpoint 43: 
-----------------------------------
Train ROC-AUC: 0.9287
Train Loss: 0.2120
ID Validation ROC-AUC: 0.9078
ID Validation Loss: 0.2413
ID Test ROC-AUC: 0.9121
ID Test Loss: 0.2387
OOD Validation ROC-AUC: 0.6847
OOD Validation Loss: 0.3180
OOD Test ROC-AUC: 0.7131
OOD Test Loss: 0.4739

[0m[1;37mINFO[0m: [1mChartInfo 0.9179 0.6886 0.9121 0.7131 0.9078 0.6847[0mLBAPcore(11314)
Data example from id_val: Data(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
Label distribution from id_val: (tensor([0., 1.]), tensor([1318, 9996]))
[1;34mDEBUG[0m: 09/28/2024 09:02:57 PM : [1mUnbalanced warning for LBAPcore (id_val)
[0m/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
LBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 09/28/2024 09:03:01 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.483
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.526
SUFF++ for r=0.3 class 0.0 = 0.767 +- 0.216 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 class 1.0 = 0.768 +- 0.216 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 all KL = 0.766 +- 0.216 (in-sample avg dev_std = 0.323)
SUFF++ for r=0.3 all L1 = 0.768 +- 0.203 (in-sample avg dev_std = 0.323)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.588
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.576
SUFF++ for r=0.6 class 0.0 = 0.828 +- 0.132 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 class 1.0 = 0.855 +- 0.132 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all KL = 0.894 +- 0.132 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.6 all L1 = 0.852 +- 0.139 (in-sample avg dev_std = 0.214)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.607
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.599
SUFF++ for r=0.9 class 0.0 = 0.895 +- 0.090 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 class 1.0 = 0.922 +- 0.090 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all KL = 0.96 +- 0.090 (in-sample avg dev_std = 0.130)
SUFF++ for r=0.9 all L1 = 0.919 +- 0.101 (in-sample avg dev_std = 0.130)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.506
SUFF++ for r=0.3 class 0.0 = 0.748 +- 0.224 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 class 1.0 = 0.751 +- 0.224 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all KL = 0.744 +- 0.224 (in-sample avg dev_std = 0.365)
SUFF++ for r=0.3 all L1 = 0.751 +- 0.195 (in-sample avg dev_std = 0.365)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.518
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.52
SUFF++ for r=0.6 class 0.0 = 0.808 +- 0.149 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 class 1.0 = 0.82 +- 0.149 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 all KL = 0.87 +- 0.149 (in-sample avg dev_std = 0.257)
SUFF++ for r=0.6 all L1 = 0.818 +- 0.156 (in-sample avg dev_std = 0.257)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.539
SUFF++ for r=0.9 class 0.0 = 0.881 +- 0.103 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 class 1.0 = 0.898 +- 0.103 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all KL = 0.949 +- 0.103 (in-sample avg dev_std = 0.146)
SUFF++ for r=0.9 all L1 = 0.895 +- 0.122 (in-sample avg dev_std = 0.146)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.483
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.307 +- 0.005
Model ROC-AUC over intervened graphs for r=0.3 =  0.558
NEC for r=0.3 class 0.0 = 0.236 +- 0.225 (in-sample avg dev_std = 0.318)
NEC for r=0.3 class 1.0 = 0.213 +- 0.225 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all KL = 0.204 +- 0.225 (in-sample avg dev_std = 0.318)
NEC for r=0.3 all L1 = 0.216 +- 0.197 (in-sample avg dev_std = 0.318)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.588
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.607 +- 0.005
Model ROC-AUC over intervened graphs for r=0.6 =  0.596
NEC for r=0.6 class 0.0 = 0.175 +- 0.142 (in-sample avg dev_std = 0.224)
NEC for r=0.6 class 1.0 = 0.144 +- 0.142 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all KL = 0.105 +- 0.142 (in-sample avg dev_std = 0.224)
NEC for r=0.6 all L1 = 0.148 +- 0.136 (in-sample avg dev_std = 0.224)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.607
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.601
NEC for r=0.9 class 0.0 = 0.127 +- 0.106 (in-sample avg dev_std = 0.172)
NEC for r=0.9 class 1.0 = 0.102 +- 0.106 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all KL = 0.064 +- 0.106 (in-sample avg dev_std = 0.172)
NEC for r=0.9 all L1 = 0.105 +- 0.112 (in-sample avg dev_std = 0.172)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.619
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.603
NEC for r=1.0 class 0.0 = 0.113 +- 0.092 (in-sample avg dev_std = 0.155)
NEC for r=1.0 class 1.0 = 0.085 +- 0.092 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all KL = 0.052 +- 0.092 (in-sample avg dev_std = 0.155)
NEC for r=1.0 all L1 = 0.088 +- 0.100 (in-sample avg dev_std = 0.155)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.511
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.524
NEC for r=0.3 class 0.0 = 0.259 +- 0.234 (in-sample avg dev_std = 0.324)
NEC for r=0.3 class 1.0 = 0.232 +- 0.234 (in-sample avg dev_std = 0.324)
NEC for r=0.3 all KL = 0.223 +- 0.234 (in-sample avg dev_std = 0.324)
NEC for r=0.3 all L1 = 0.236 +- 0.204 (in-sample avg dev_std = 0.324)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.518
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.546
NEC for r=0.6 class 0.0 = 0.206 +- 0.158 (in-sample avg dev_std = 0.245)
NEC for r=0.6 class 1.0 = 0.173 +- 0.158 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all KL = 0.124 +- 0.158 (in-sample avg dev_std = 0.245)
NEC for r=0.6 all L1 = 0.178 +- 0.154 (in-sample avg dev_std = 0.245)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.561
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.547
NEC for r=0.9 class 0.0 = 0.138 +- 0.114 (in-sample avg dev_std = 0.188)
NEC for r=0.9 class 1.0 = 0.128 +- 0.114 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all KL = 0.074 +- 0.114 (in-sample avg dev_std = 0.188)
NEC for r=0.9 all L1 = 0.13 +- 0.127 (in-sample avg dev_std = 0.188)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.56
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.546
NEC for r=1.0 class 0.0 = 0.124 +- 0.101 (in-sample avg dev_std = 0.174)
NEC for r=1.0 class 1.0 = 0.112 +- 0.101 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all KL = 0.062 +- 0.101 (in-sample avg dev_std = 0.174)
NEC for r=1.0 all L1 = 0.114 +- 0.120 (in-sample avg dev_std = 0.174)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.809, 0.87, 0.943, 1.0], 'all_L1': [0.802, 0.815, 0.877, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.795, 0.841, 0.917, 1.0], 'all_L1': [0.829, 0.804, 0.831, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.603, 0.729, 0.908, 1.0], 'all_L1': [0.555, 0.626, 0.771, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.526, 0.721, 0.86, 1.0], 'all_L1': [0.581, 0.662, 0.757, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.766, 0.894, 0.96, 1.0], 'all_L1': [0.768, 0.852, 0.919, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.19, 0.13, 0.079, 0.063], 'all_L1': [0.199, 0.183, 0.143, 0.125]}), defaultdict(<class 'list'>, {'all_KL': [0.19, 0.156, 0.106, 0.088], 'all_L1': [0.169, 0.197, 0.193, 0.171]}), defaultdict(<class 'list'>, {'all_KL': [0.309, 0.202, 0.101, 0.078], 'all_L1': [0.373, 0.305, 0.237, 0.207]}), defaultdict(<class 'list'>, {'all_KL': [0.315, 0.204, 0.164, 0.152], 'all_L1': [0.315, 0.282, 0.264, 0.253]}), defaultdict(<class 'list'>, {'all_KL': [0.204, 0.105, 0.064, 0.052], 'all_L1': [0.216, 0.148, 0.105, 0.088]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.789, 0.851, 0.942, 1.0], 'all_L1': [0.783, 0.784, 0.853, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.76, 0.81, 0.903, 1.0], 'all_L1': [0.782, 0.757, 0.798, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.606, 0.732, 0.905, 1.0], 'all_L1': [0.556, 0.636, 0.774, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.549, 0.731, 0.87, 1.0], 'all_L1': [0.604, 0.665, 0.76, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.744, 0.87, 0.949, 1.0], 'all_L1': [0.751, 0.818, 0.895, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.19, 0.151, 0.086, 0.072], 'all_L1': [0.21, 0.218, 0.176, 0.152]}), defaultdict(<class 'list'>, {'all_KL': [0.209, 0.175, 0.12, 0.099], 'all_L1': [0.205, 0.234, 0.227, 0.202]}), defaultdict(<class 'list'>, {'all_KL': [0.293, 0.205, 0.106, 0.084], 'all_L1': [0.362, 0.304, 0.232, 0.207]}), defaultdict(<class 'list'>, {'all_KL': [0.285, 0.203, 0.158, 0.146], 'all_L1': [0.29, 0.278, 0.264, 0.25]}), defaultdict(<class 'list'>, {'all_KL': [0.223, 0.124, 0.074, 0.062], 'all_L1': [0.236, 0.178, 0.13, 0.114]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.707 +- 0.115, 0.752 +- 0.090, 0.831 +- 0.062, 1.000 +- 0.000
suff++ class all_KL  =  0.700 +- 0.114, 0.811 +- 0.072, 0.918 +- 0.034, 1.000 +- 0.000
suff++_acc_int  =  0.527 +- 0.045, 0.565 +- 0.055, 0.584 +- 0.065
nec class all_L1  =  0.254 +- 0.077, 0.223 +- 0.060, 0.188 +- 0.059, 0.169 +- 0.058
nec class all_KL  =  0.242 +- 0.058, 0.159 +- 0.039, 0.103 +- 0.034, 0.087 +- 0.035
nec_acc_int  =  0.570 +- 0.052, 0.595 +- 0.067, 0.603 +- 0.072, 0.606 +- 0.076

Eval split test
suff++ class all_L1  =  0.695 +- 0.096, 0.732 +- 0.070, 0.816 +- 0.051, 1.000 +- 0.000
suff++ class all_KL  =  0.690 +- 0.094, 0.799 +- 0.058, 0.914 +- 0.029, 1.000 +- 0.000
suff++_acc_int  =  0.524 +- 0.036, 0.520 +- 0.038, 0.531 +- 0.045
nec class all_L1  =  0.261 +- 0.059, 0.242 +- 0.044, 0.206 +- 0.047, 0.185 +- 0.047
nec class all_KL  =  0.240 +- 0.041, 0.172 +- 0.031, 0.109 +- 0.029, 0.093 +- 0.029
nec_acc_int  =  0.535 +- 0.029, 0.546 +- 0.041, 0.542 +- 0.054, 0.545 +- 0.057


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.481 +- 0.021, 0.487 +- 0.015, 0.510 +- 0.003, 0.584 +- 0.029
Faith. Armon (L1)= 		  =  0.358 +- 0.060, 0.335 +- 0.060, 0.300 +- 0.075, 0.285 +- 0.086
Faith. GMean (L1)= 	  =  0.413 +- 0.027, 0.402 +- 0.030, 0.388 +- 0.050, 0.404 +- 0.073
Faith. Aritm (KL)= 		  =  0.471 +- 0.029, 0.485 +- 0.017, 0.510 +- 0.003, 0.543 +- 0.017
Faith. Armon (KL)= 		  =  0.348 +- 0.044, 0.262 +- 0.051, 0.183 +- 0.053, 0.158 +- 0.057
Faith. GMean (KL)= 	  =  0.403 +- 0.016, 0.354 +- 0.030, 0.302 +- 0.043, 0.289 +- 0.056

Eval split test
Faith. Aritm (L1)= 		  =  0.478 +- 0.021, 0.487 +- 0.014, 0.511 +- 0.004, 0.592 +- 0.024
Faith. Armon (L1)= 		  =  0.369 +- 0.042, 0.359 +- 0.041, 0.324 +- 0.058, 0.310 +- 0.068
Faith. GMean (L1)= 	  =  0.419 +- 0.017, 0.417 +- 0.020, 0.405 +- 0.037, 0.426 +- 0.057
Faith. Aritm (KL)= 		  =  0.465 +- 0.028, 0.485 +- 0.015, 0.511 +- 0.003, 0.546 +- 0.015
Faith. Armon (KL)= 		  =  0.349 +- 0.032, 0.280 +- 0.039, 0.193 +- 0.045, 0.168 +- 0.048
Faith. GMean (KL)= 	  =  0.402 +- 0.012, 0.367 +- 0.022, 0.312 +- 0.037, 0.301 +- 0.046
Computed for split load_split = id



Completed in  0:22:36.200937  for GSATGIN LBAPcore/assay



DONE GSAT LBAPcore/assay
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 21:06:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:06:23 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 171...
[0m[1;37mINFO[0m: [1mCheckpoint 171: 
-----------------------------------
Train ACCURACY: 0.9980
Train Loss: 0.0132
ID Validation ACCURACY: 0.8966
ID Validation Loss: 0.3887
ID Test ACCURACY: 0.8907
ID Test Loss: 0.4205
OOD Validation ACCURACY: 0.8411
OOD Validation Loss: 0.6435
OOD Test ACCURACY: 0.6240
OOD Test Loss: 1.7705

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 133...
[0m[1;37mINFO[0m: [1mCheckpoint 133: 
-----------------------------------
Train ACCURACY: 0.9873
Train Loss: 0.0485
ID Validation ACCURACY: 0.8889
ID Validation Loss: 0.3611
ID Test ACCURACY: 0.8913
ID Test Loss: 0.3604
OOD Validation ACCURACY: 0.8866
OOD Validation Loss: 0.3823
OOD Test ACCURACY: 0.7620
OOD Test Loss: 0.8839

[0m[1;37mINFO[0m: [1mChartInfo 0.8907 0.6240 0.8913 0.7620 0.8889 0.8866[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.135
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.104
SUFF++ for r=0.3 class 0 = 0.482 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 1 = 0.459 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 2 = 0.436 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 3 = 0.451 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 4 = 0.452 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 5 = 0.472 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 6 = 0.468 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 7 = 0.431 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 8 = 0.457 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 class 9 = 0.45 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all KL = 0.487 +- 0.225 (in-sample avg dev_std = 0.423)
SUFF++ for r=0.3 all L1 = 0.455 +- 0.145 (in-sample avg dev_std = 0.423)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.234
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.201
SUFF++ for r=0.6 class 0 = 0.442 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 1 = 0.734 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 2 = 0.404 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 3 = 0.421 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 4 = 0.45 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 5 = 0.483 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 6 = 0.421 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 7 = 0.461 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 8 = 0.413 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 class 9 = 0.367 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 all KL = 0.405 +- 0.318 (in-sample avg dev_std = 0.261)
SUFF++ for r=0.6 all L1 = 0.463 +- 0.250 (in-sample avg dev_std = 0.261)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.774
SUFF++ for r=0.9 class 0 = 0.941 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 1 = 0.969 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 2 = 0.733 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 3 = 0.743 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 4 = 0.841 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 5 = 0.77 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 6 = 0.783 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 7 = 0.799 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 8 = 0.811 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 class 9 = 0.773 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all KL = 0.815 +- 0.262 (in-sample avg dev_std = 0.275)
SUFF++ for r=0.9 all L1 = 0.818 +- 0.218 (in-sample avg dev_std = 0.275)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.145
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.119
SUFF++ for r=0.3 class 0 = 0.511 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 1 = 0.422 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 2 = 0.471 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 3 = 0.476 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 4 = 0.467 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 5 = 0.496 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 6 = 0.522 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 7 = 0.459 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 8 = 0.472 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 class 9 = 0.459 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all KL = 0.576 +- 0.214 (in-sample avg dev_std = 0.380)
SUFF++ for r=0.3 all L1 = 0.475 +- 0.136 (in-sample avg dev_std = 0.380)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.206
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.207
SUFF++ for r=0.6 class 0 = 0.523 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 1 = 0.66 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 2 = 0.427 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 3 = 0.477 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 4 = 0.449 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 5 = 0.464 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 6 = 0.483 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 7 = 0.494 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 8 = 0.507 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 class 9 = 0.473 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all KL = 0.492 +- 0.286 (in-sample avg dev_std = 0.238)
SUFF++ for r=0.6 all L1 = 0.498 +- 0.234 (in-sample avg dev_std = 0.238)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.544
SUFF++ for r=0.9 class 0 = 0.694 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 1 = 0.906 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 2 = 0.704 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 3 = 0.731 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 4 = 0.784 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 5 = 0.708 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 6 = 0.689 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 7 = 0.767 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 8 = 0.678 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 class 9 = 0.682 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 all KL = 0.778 +- 0.243 (in-sample avg dev_std = 0.294)
SUFF++ for r=0.9 all L1 = 0.736 +- 0.217 (in-sample avg dev_std = 0.294)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.135
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.125
NEC for r=0.3 class 0 = 0.485 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 1 = 0.451 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 2 = 0.536 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 3 = 0.512 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 4 = 0.521 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 5 = 0.518 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 6 = 0.467 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 7 = 0.495 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 8 = 0.513 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 class 9 = 0.509 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 all KL = 0.459 +- 0.229 (in-sample avg dev_std = 0.360)
NEC for r=0.3 all L1 = 0.5 +- 0.155 (in-sample avg dev_std = 0.360)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.234
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.205
NEC for r=0.6 class 0 = 0.524 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 1 = 0.234 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 2 = 0.516 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 3 = 0.537 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 4 = 0.537 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 5 = 0.485 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 6 = 0.57 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 7 = 0.517 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 8 = 0.55 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 9 = 0.594 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 all KL = 0.55 +- 0.289 (in-sample avg dev_std = 0.396)
NEC for r=0.6 all L1 = 0.503 +- 0.221 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.824
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.625
NEC for r=0.9 class 0 = 0.199 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 1 = 0.104 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 2 = 0.459 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 3 = 0.57 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 4 = 0.359 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 5 = 0.465 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 6 = 0.457 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 7 = 0.467 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 8 = 0.418 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 class 9 = 0.513 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all KL = 0.579 +- 0.339 (in-sample avg dev_std = 0.458)
NEC for r=0.9 all L1 = 0.398 +- 0.273 (in-sample avg dev_std = 0.458)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.959
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.83
NEC for r=1.0 class 0 = 0.085 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 1 = 0.031 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 2 = 0.273 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 3 = 0.336 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 4 = 0.182 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 5 = 0.301 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 6 = 0.315 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 7 = 0.23 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 8 = 0.273 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 class 9 = 0.404 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all KL = 0.4 +- 0.362 (in-sample avg dev_std = 0.402)
NEC for r=1.0 all L1 = 0.239 +- 0.253 (in-sample avg dev_std = 0.402)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.145
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.439 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 1 = 0.474 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 2 = 0.462 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 3 = 0.473 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 4 = 0.489 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 5 = 0.466 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 6 = 0.468 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 7 = 0.489 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 8 = 0.502 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 9 = 0.467 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all KL = 0.365 +- 0.199 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all L1 = 0.473 +- 0.141 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.206
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.207
NEC for r=0.6 class 0 = 0.449 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 1 = 0.319 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 2 = 0.528 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 3 = 0.516 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 4 = 0.511 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 5 = 0.51 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 6 = 0.487 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 7 = 0.489 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 8 = 0.472 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 class 9 = 0.548 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 all KL = 0.476 +- 0.264 (in-sample avg dev_std = 0.346)
NEC for r=0.6 all L1 = 0.481 +- 0.209 (in-sample avg dev_std = 0.346)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.58
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.441
NEC for r=0.9 class 0 = 0.582 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.177 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.529 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 3 = 0.577 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 4 = 0.437 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 5 = 0.535 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 6 = 0.591 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 7 = 0.434 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 8 = 0.613 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 9 = 0.539 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.607 +- 0.291 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.498 +- 0.239 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.639
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.582
NEC for r=1.0 class 0 = 0.531 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 1 = 0.105 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 2 = 0.529 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 3 = 0.448 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 4 = 0.423 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 5 = 0.458 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 6 = 0.49 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 7 = 0.397 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 8 = 0.561 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 class 9 = 0.409 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 all KL = 0.553 +- 0.322 (in-sample avg dev_std = 0.443)
NEC for r=1.0 all L1 = 0.432 +- 0.261 (in-sample avg dev_std = 0.443)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 21:18:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:18:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 153...
[0m[1;37mINFO[0m: [1mCheckpoint 153: 
-----------------------------------
Train ACCURACY: 0.9954
Train Loss: 0.0228
ID Validation ACCURACY: 0.8981
ID Validation Loss: 0.3829
ID Test ACCURACY: 0.8943
ID Test Loss: 0.3885
OOD Validation ACCURACY: 0.8581
OOD Validation Loss: 0.5298
OOD Test ACCURACY: 0.4854
OOD Test Loss: 2.6066

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 85...
[0m[1;37mINFO[0m: [1mCheckpoint 85: 
-----------------------------------
Train ACCURACY: 0.9603
Train Loss: 0.1231
ID Validation ACCURACY: 0.8851
ID Validation Loss: 0.3467
ID Test ACCURACY: 0.8873
ID Test Loss: 0.3649
OOD Validation ACCURACY: 0.8796
OOD Validation Loss: 0.4010
OOD Test ACCURACY: 0.6567
OOD Test Loss: 1.3853

[0m[1;37mINFO[0m: [1mChartInfo 0.8943 0.4854 0.8873 0.6567 0.8851 0.8796[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.124
SUFF++ for r=0.3 class 0 = 0.493 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 1 = 0.57 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 2 = 0.508 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 3 = 0.479 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 4 = 0.583 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 5 = 0.532 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 6 = 0.527 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 7 = 0.52 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 8 = 0.541 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 class 9 = 0.558 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all KL = 0.459 +- 0.216 (in-sample avg dev_std = 0.441)
SUFF++ for r=0.3 all L1 = 0.531 +- 0.162 (in-sample avg dev_std = 0.441)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.236
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.215
SUFF++ for r=0.6 class 0 = 0.394 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 1 = 0.665 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 2 = 0.373 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 3 = 0.396 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 4 = 0.375 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 5 = 0.368 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 6 = 0.357 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 7 = 0.382 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 8 = 0.395 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 class 9 = 0.4 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all KL = 0.348 +- 0.262 (in-sample avg dev_std = 0.348)
SUFF++ for r=0.6 all L1 = 0.414 +- 0.194 (in-sample avg dev_std = 0.348)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.446
SUFF++ for r=0.9 class 0 = 0.427 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 1 = 0.775 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 2 = 0.396 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 3 = 0.348 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 4 = 0.436 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 5 = 0.321 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 6 = 0.362 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 7 = 0.616 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 8 = 0.371 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 class 9 = 0.322 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all KL = 0.275 +- 0.310 (in-sample avg dev_std = 0.421)
SUFF++ for r=0.9 all L1 = 0.445 +- 0.264 (in-sample avg dev_std = 0.421)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.097
SUFF++ for r=0.3 class 0 = 0.514 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 1 = 0.559 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 2 = 0.507 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 3 = 0.523 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 4 = 0.501 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 5 = 0.527 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 6 = 0.536 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 7 = 0.535 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 8 = 0.537 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 class 9 = 0.527 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 all KL = 0.505 +- 0.190 (in-sample avg dev_std = 0.397)
SUFF++ for r=0.3 all L1 = 0.527 +- 0.139 (in-sample avg dev_std = 0.397)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.214
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.175
SUFF++ for r=0.6 class 0 = 0.474 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 1 = 0.595 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 2 = 0.4 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 3 = 0.4 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 4 = 0.37 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 5 = 0.449 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 6 = 0.424 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 7 = 0.44 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 8 = 0.389 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 class 9 = 0.369 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 all KL = 0.392 +- 0.240 (in-sample avg dev_std = 0.378)
SUFF++ for r=0.6 all L1 = 0.433 +- 0.173 (in-sample avg dev_std = 0.378)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.295
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.213
SUFF++ for r=0.9 class 0 = 0.502 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 1 = 0.887 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 2 = 0.378 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 3 = 0.384 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 4 = 0.43 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 5 = 0.367 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 6 = 0.402 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 7 = 0.505 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 8 = 0.39 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 class 9 = 0.376 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 all KL = 0.332 +- 0.303 (in-sample avg dev_std = 0.405)
SUFF++ for r=0.9 all L1 = 0.468 +- 0.246 (in-sample avg dev_std = 0.405)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.126
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.133
NEC for r=0.3 class 0 = 0.451 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 1 = 0.377 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 2 = 0.425 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 3 = 0.469 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 4 = 0.385 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 5 = 0.448 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 6 = 0.402 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 7 = 0.41 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 8 = 0.429 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 class 9 = 0.376 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all KL = 0.428 +- 0.271 (in-sample avg dev_std = 0.379)
NEC for r=0.3 all L1 = 0.417 +- 0.227 (in-sample avg dev_std = 0.379)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.236
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.212
NEC for r=0.6 class 0 = 0.603 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 1 = 0.381 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 2 = 0.626 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 3 = 0.614 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 4 = 0.587 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 5 = 0.611 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 6 = 0.623 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 7 = 0.585 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 8 = 0.592 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 class 9 = 0.604 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all KL = 0.633 +- 0.254 (in-sample avg dev_std = 0.357)
NEC for r=0.6 all L1 = 0.58 +- 0.185 (in-sample avg dev_std = 0.357)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.63
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.493
NEC for r=0.9 class 0 = 0.524 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 1 = 0.264 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 2 = 0.612 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 3 = 0.622 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 4 = 0.612 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 5 = 0.704 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 6 = 0.656 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 7 = 0.43 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 8 = 0.599 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 9 = 0.686 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all KL = 0.751 +- 0.279 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all L1 = 0.563 +- 0.244 (in-sample avg dev_std = 0.487)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.95
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.844
NEC for r=1.0 class 0 = 0.102 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 1 = 0.032 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 2 = 0.259 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 3 = 0.304 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 4 = 0.2 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 5 = 0.318 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 6 = 0.325 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 7 = 0.201 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 8 = 0.211 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 class 9 = 0.352 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 all KL = 0.368 +- 0.336 (in-sample avg dev_std = 0.375)
NEC for r=1.0 all L1 = 0.226 +- 0.240 (in-sample avg dev_std = 0.375)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.101
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.413 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 1 = 0.434 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 2 = 0.424 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 3 = 0.392 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 4 = 0.453 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 5 = 0.418 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 6 = 0.421 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 7 = 0.442 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 8 = 0.452 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 class 9 = 0.41 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 all KL = 0.381 +- 0.245 (in-sample avg dev_std = 0.361)
NEC for r=0.3 all L1 = 0.426 +- 0.197 (in-sample avg dev_std = 0.361)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.214
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.194
NEC for r=0.6 class 0 = 0.512 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 1 = 0.4 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 2 = 0.563 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 3 = 0.578 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 4 = 0.605 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 5 = 0.554 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 6 = 0.563 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 7 = 0.512 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 8 = 0.579 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 class 9 = 0.628 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 all KL = 0.565 +- 0.243 (in-sample avg dev_std = 0.358)
NEC for r=0.6 all L1 = 0.547 +- 0.175 (in-sample avg dev_std = 0.358)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.295
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.268
NEC for r=0.9 class 0 = 0.55 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 1 = 0.183 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 2 = 0.597 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 3 = 0.607 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 4 = 0.553 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 5 = 0.652 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 6 = 0.577 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 7 = 0.332 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 8 = 0.604 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 class 9 = 0.596 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all KL = 0.682 +- 0.294 (in-sample avg dev_std = 0.443)
NEC for r=0.9 all L1 = 0.52 +- 0.239 (in-sample avg dev_std = 0.443)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.505
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.48
NEC for r=1.0 class 0 = 0.581 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 1 = 0.053 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 2 = 0.537 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 3 = 0.402 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 4 = 0.461 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 5 = 0.459 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 6 = 0.519 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 7 = 0.316 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 8 = 0.513 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 class 9 = 0.477 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 all KL = 0.478 +- 0.319 (in-sample avg dev_std = 0.361)
NEC for r=1.0 all L1 = 0.428 +- 0.267 (in-sample avg dev_std = 0.361)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 21:32:10 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:32:11 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 152...
[0m[1;37mINFO[0m: [1mCheckpoint 152: 
-----------------------------------
Train ACCURACY: 0.9968
Train Loss: 0.0190
ID Validation ACCURACY: 0.8971
ID Validation Loss: 0.3837
ID Test ACCURACY: 0.8937
ID Test Loss: 0.3798
OOD Validation ACCURACY: 0.8484
OOD Validation Loss: 0.5888
OOD Test ACCURACY: 0.4769
OOD Test Loss: 2.7235

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 108...
[0m[1;37mINFO[0m: [1mCheckpoint 108: 
-----------------------------------
Train ACCURACY: 0.9775
Train Loss: 0.0765
ID Validation ACCURACY: 0.8880
ID Validation Loss: 0.3645
ID Test ACCURACY: 0.8894
ID Test Loss: 0.3649
OOD Validation ACCURACY: 0.8856
OOD Validation Loss: 0.3894
OOD Test ACCURACY: 0.7121
OOD Test Loss: 1.1932

[0m[1;37mINFO[0m: [1mChartInfo 0.8937 0.4769 0.8894 0.7121 0.8880 0.8856[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.127
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.123
SUFF++ for r=0.3 class 0 = 0.349 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 1 = 0.393 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 2 = 0.381 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 3 = 0.428 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 4 = 0.387 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 5 = 0.394 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 6 = 0.397 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 7 = 0.358 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 8 = 0.354 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 class 9 = 0.374 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all KL = 0.283 +- 0.235 (in-sample avg dev_std = 0.490)
SUFF++ for r=0.3 all L1 = 0.381 +- 0.109 (in-sample avg dev_std = 0.490)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.211
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.159
SUFF++ for r=0.6 class 0 = 0.335 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 1 = 0.314 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 2 = 0.363 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 3 = 0.347 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 4 = 0.336 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 5 = 0.358 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 6 = 0.308 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 7 = 0.331 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 8 = 0.328 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 class 9 = 0.304 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all KL = 0.215 +- 0.170 (in-sample avg dev_std = 0.492)
SUFF++ for r=0.6 all L1 = 0.332 +- 0.083 (in-sample avg dev_std = 0.492)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.452
SUFF++ for r=0.9 class 0 = 0.414 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 1 = 0.719 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 2 = 0.454 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 3 = 0.381 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 4 = 0.516 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 5 = 0.312 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 6 = 0.314 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 7 = 0.387 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 8 = 0.352 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 class 9 = 0.382 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 all KL = 0.224 +- 0.257 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.9 all L1 = 0.428 +- 0.219 (in-sample avg dev_std = 0.515)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.482 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 1 = 0.524 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 2 = 0.486 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 3 = 0.522 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 4 = 0.517 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 5 = 0.503 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 6 = 0.535 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 7 = 0.524 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 8 = 0.532 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 class 9 = 0.533 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 all KL = 0.608 +- 0.155 (in-sample avg dev_std = 0.317)
SUFF++ for r=0.3 all L1 = 0.516 +- 0.102 (in-sample avg dev_std = 0.317)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.135
SUFF++ for r=0.6 class 0 = 0.431 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 1 = 0.452 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 2 = 0.449 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 3 = 0.428 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 4 = 0.452 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 5 = 0.463 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 6 = 0.46 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 7 = 0.462 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 8 = 0.435 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 class 9 = 0.436 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all KL = 0.453 +- 0.230 (in-sample avg dev_std = 0.330)
SUFF++ for r=0.6 all L1 = 0.447 +- 0.138 (in-sample avg dev_std = 0.330)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.456
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.411
SUFF++ for r=0.9 class 0 = 0.576 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 1 = 0.918 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 2 = 0.655 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 3 = 0.598 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 4 = 0.662 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 5 = 0.6 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 6 = 0.633 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 7 = 0.732 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 8 = 0.601 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 class 9 = 0.652 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 all KL = 0.673 +- 0.284 (in-sample avg dev_std = 0.371)
SUFF++ for r=0.9 all L1 = 0.666 +- 0.223 (in-sample avg dev_std = 0.371)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.127
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.138
NEC for r=0.3 class 0 = 0.571 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 1 = 0.42 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 2 = 0.557 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 3 = 0.493 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 4 = 0.535 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 5 = 0.511 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 6 = 0.542 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 7 = 0.542 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 8 = 0.551 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 class 9 = 0.568 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all KL = 0.509 +- 0.297 (in-sample avg dev_std = 0.287)
NEC for r=0.3 all L1 = 0.527 +- 0.203 (in-sample avg dev_std = 0.287)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.211
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.212
NEC for r=0.6 class 0 = 0.517 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 1 = 0.536 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 2 = 0.534 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 3 = 0.543 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 4 = 0.509 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 5 = 0.517 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 6 = 0.607 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 7 = 0.559 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 8 = 0.535 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 class 9 = 0.588 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all KL = 0.525 +- 0.313 (in-sample avg dev_std = 0.280)
NEC for r=0.6 all L1 = 0.545 +- 0.188 (in-sample avg dev_std = 0.280)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.53
NEC for r=0.9 class 0 = 0.465 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 1 = 0.234 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 2 = 0.571 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 3 = 0.511 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 4 = 0.537 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 5 = 0.661 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 6 = 0.684 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 7 = 0.521 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 8 = 0.553 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 class 9 = 0.614 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all KL = 0.69 +- 0.288 (in-sample avg dev_std = 0.445)
NEC for r=0.9 all L1 = 0.528 +- 0.241 (in-sample avg dev_std = 0.445)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.956
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.848
NEC for r=1.0 class 0 = 0.086 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 1 = 0.019 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 2 = 0.277 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 3 = 0.261 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 4 = 0.209 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 5 = 0.316 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 6 = 0.34 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 7 = 0.203 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 8 = 0.216 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 9 = 0.339 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all KL = 0.363 +- 0.335 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all L1 = 0.222 +- 0.239 (in-sample avg dev_std = 0.376)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.108
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.107
NEC for r=0.3 class 0 = 0.51 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 1 = 0.439 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 2 = 0.503 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 3 = 0.492 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 4 = 0.477 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 5 = 0.507 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 6 = 0.483 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 7 = 0.486 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 8 = 0.479 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 class 9 = 0.476 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 all KL = 0.368 +- 0.199 (in-sample avg dev_std = 0.254)
NEC for r=0.3 all L1 = 0.485 +- 0.125 (in-sample avg dev_std = 0.254)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.179
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.156
NEC for r=0.6 class 0 = 0.578 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 1 = 0.486 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 2 = 0.54 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 3 = 0.543 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 4 = 0.49 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 5 = 0.559 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 6 = 0.507 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 7 = 0.504 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 8 = 0.504 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 class 9 = 0.502 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 all KL = 0.46 +- 0.225 (in-sample avg dev_std = 0.298)
NEC for r=0.6 all L1 = 0.521 +- 0.148 (in-sample avg dev_std = 0.298)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.456
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.369
NEC for r=0.9 class 0 = 0.601 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 1 = 0.2 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 2 = 0.491 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 3 = 0.55 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 4 = 0.529 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 5 = 0.581 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 6 = 0.604 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 7 = 0.481 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 8 = 0.636 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 class 9 = 0.539 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 all KL = 0.608 +- 0.278 (in-sample avg dev_std = 0.405)
NEC for r=0.9 all L1 = 0.517 +- 0.230 (in-sample avg dev_std = 0.405)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.493
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.452
NEC for r=1.0 class 0 = 0.547 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 1 = 0.074 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 2 = 0.419 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 3 = 0.454 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 4 = 0.509 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 5 = 0.525 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 6 = 0.484 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 7 = 0.324 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 8 = 0.544 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 class 9 = 0.533 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 all KL = 0.502 +- 0.296 (in-sample avg dev_std = 0.392)
NEC for r=1.0 all L1 = 0.436 +- 0.250 (in-sample avg dev_std = 0.392)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 21:45:31 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:32 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:45:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9960
Train Loss: 0.0210
ID Validation ACCURACY: 0.8937
ID Validation Loss: 0.3933
ID Test ACCURACY: 0.8893
ID Test Loss: 0.3974
OOD Validation ACCURACY: 0.8071
OOD Validation Loss: 0.8507
OOD Test ACCURACY: 0.2887
OOD Test Loss: 6.3824

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 70...
[0m[1;37mINFO[0m: [1mCheckpoint 70: 
-----------------------------------
Train ACCURACY: 0.9309
Train Loss: 0.2050
ID Validation ACCURACY: 0.8727
ID Validation Loss: 0.3914
ID Test ACCURACY: 0.8746
ID Test Loss: 0.3866
OOD Validation ACCURACY: 0.8749
OOD Validation Loss: 0.3989
OOD Test ACCURACY: 0.7819
OOD Test Loss: 0.7293

[0m[1;37mINFO[0m: [1mChartInfo 0.8893 0.2887 0.8746 0.7819 0.8727 0.8749[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
SUFF++ for r=0.3 class 0 = 0.849 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 1 = 0.807 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 2 = 0.829 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 3 = 0.878 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 4 = 0.841 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 5 = 0.872 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 6 = 0.811 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 7 = 0.834 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 8 = 0.942 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 class 9 = 0.861 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 all KL = 0.873 +- 0.240 (in-sample avg dev_std = 0.131)
SUFF++ for r=0.3 all L1 = 0.851 +- 0.245 (in-sample avg dev_std = 0.131)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.195
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.16
SUFF++ for r=0.6 class 0 = 0.323 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 1 = 0.539 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 2 = 0.329 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 3 = 0.361 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 4 = 0.374 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 5 = 0.366 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 6 = 0.358 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 7 = 0.351 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 8 = 0.34 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 class 9 = 0.324 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all KL = 0.178 +- 0.292 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.6 all L1 = 0.369 +- 0.235 (in-sample avg dev_std = 0.515)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.752
SUFF++ for r=0.9 class 0 = 0.949 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 1 = 0.986 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 2 = 0.791 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 3 = 0.745 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 4 = 0.822 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 5 = 0.701 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 6 = 0.727 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 7 = 0.811 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 8 = 0.798 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 class 9 = 0.761 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all KL = 0.813 +- 0.265 (in-sample avg dev_std = 0.276)
SUFF++ for r=0.9 all L1 = 0.813 +- 0.222 (in-sample avg dev_std = 0.276)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
SUFF++ for r=0.3 class 0 = 0.877 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 1 = 0.74 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 2 = 0.85 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 3 = 0.897 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 4 = 0.89 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 5 = 0.86 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 6 = 0.911 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 7 = 0.819 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 8 = 0.917 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 class 9 = 0.924 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 all KL = 0.897 +- 0.197 (in-sample avg dev_std = 0.124)
SUFF++ for r=0.3 all L1 = 0.867 +- 0.212 (in-sample avg dev_std = 0.124)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.141
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.108
SUFF++ for r=0.6 class 0 = 0.304 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 1 = 0.369 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 2 = 0.301 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 3 = 0.301 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 4 = 0.293 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 5 = 0.293 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 6 = 0.273 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 7 = 0.326 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 8 = 0.26 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 class 9 = 0.294 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all KL = 0.104 +- 0.185 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.6 all L1 = 0.303 +- 0.159 (in-sample avg dev_std = 0.483)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.317
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.305
SUFF++ for r=0.9 class 0 = 0.721 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 1 = 0.863 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 2 = 0.795 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 3 = 0.806 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 4 = 0.642 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 5 = 0.72 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 6 = 0.659 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 7 = 0.719 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 8 = 0.744 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 class 9 = 0.651 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all KL = 0.769 +- 0.260 (in-sample avg dev_std = 0.316)
SUFF++ for r=0.9 all L1 = 0.735 +- 0.230 (in-sample avg dev_std = 0.316)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
NEC for r=0.3 class 0 = 0.161 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 1 = 0.197 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 2 = 0.174 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 3 = 0.127 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 4 = 0.173 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 5 = 0.133 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 6 = 0.192 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 7 = 0.17 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 8 = 0.064 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 class 9 = 0.146 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all KL = 0.143 +- 0.243 (in-sample avg dev_std = 0.142)
NEC for r=0.3 all L1 = 0.155 +- 0.241 (in-sample avg dev_std = 0.142)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.195
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.18
NEC for r=0.6 class 0 = 0.567 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 1 = 0.456 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 2 = 0.543 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 3 = 0.527 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 4 = 0.552 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 5 = 0.554 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 6 = 0.53 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 7 = 0.56 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 8 = 0.567 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 class 9 = 0.513 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all KL = 0.691 +- 0.284 (in-sample avg dev_std = 0.505)
NEC for r=0.6 all L1 = 0.536 +- 0.220 (in-sample avg dev_std = 0.505)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.816
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.594
NEC for r=0.9 class 0 = 0.261 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 1 = 0.107 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 2 = 0.481 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 3 = 0.498 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 4 = 0.417 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 5 = 0.591 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 6 = 0.547 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 7 = 0.423 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 8 = 0.427 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 class 9 = 0.526 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 all KL = 0.6 +- 0.348 (in-sample avg dev_std = 0.481)
NEC for r=0.9 all L1 = 0.421 +- 0.279 (in-sample avg dev_std = 0.481)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.947
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.824
NEC for r=1.0 class 0 = 0.097 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 1 = 0.007 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 2 = 0.258 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 3 = 0.31 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 4 = 0.23 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 5 = 0.365 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 6 = 0.351 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 7 = 0.244 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 8 = 0.249 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 class 9 = 0.333 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all KL = 0.387 +- 0.352 (in-sample avg dev_std = 0.410)
NEC for r=1.0 all L1 = 0.239 +- 0.248 (in-sample avg dev_std = 0.410)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.111
NEC for r=0.3 class 0 = 0.123 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 1 = 0.275 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 2 = 0.152 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 3 = 0.107 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 4 = 0.116 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 5 = 0.145 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 6 = 0.091 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 7 = 0.175 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 8 = 0.083 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 class 9 = 0.078 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 all KL = 0.106 +- 0.193 (in-sample avg dev_std = 0.095)
NEC for r=0.3 all L1 = 0.136 +- 0.214 (in-sample avg dev_std = 0.095)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.141
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
NEC for r=0.6 class 0 = 0.599 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 1 = 0.519 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 2 = 0.575 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 3 = 0.603 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 4 = 0.609 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 5 = 0.652 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 6 = 0.636 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 7 = 0.559 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 8 = 0.603 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 class 9 = 0.623 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all KL = 0.69 +- 0.250 (in-sample avg dev_std = 0.460)
NEC for r=0.6 all L1 = 0.596 +- 0.177 (in-sample avg dev_std = 0.460)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.317
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.303
NEC for r=0.9 class 0 = 0.519 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 1 = 0.274 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 2 = 0.38 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 3 = 0.416 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 4 = 0.545 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 5 = 0.509 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 6 = 0.607 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 7 = 0.538 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 8 = 0.541 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 class 9 = 0.582 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 all KL = 0.59 +- 0.325 (in-sample avg dev_std = 0.420)
NEC for r=0.9 all L1 = 0.487 +- 0.269 (in-sample avg dev_std = 0.420)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.292
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.315
NEC for r=1.0 class 0 = 0.552 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.316 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.51 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.365 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.558 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.529 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.586 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.469 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.552 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.535 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.602 +- 0.346 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.494 +- 0.283 (in-sample avg dev_std = 0.397)
model_dirname= repr_LECIGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 21:57:49 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:49 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 1
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 09:57:50 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.9969
Train Loss: 0.0182
ID Validation ACCURACY: 0.8953
ID Validation Loss: 0.3890
ID Test ACCURACY: 0.8900
ID Test Loss: 0.3942
OOD Validation ACCURACY: 0.8010
OOD Validation Loss: 0.8657
OOD Test ACCURACY: 0.4243
OOD Test Loss: 3.9165

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 80...
[0m[1;37mINFO[0m: [1mCheckpoint 80: 
-----------------------------------
Train ACCURACY: 0.9430
Train Loss: 0.1711
ID Validation ACCURACY: 0.8791
ID Validation Loss: 0.3738
ID Test ACCURACY: 0.8861
ID Test Loss: 0.3631
OOD Validation ACCURACY: 0.8796
OOD Validation Loss: 0.3851
OOD Test ACCURACY: 0.8004
OOD Test Loss: 0.6347

[0m[1;37mINFO[0m: [1mChartInfo 0.8900 0.4243 0.8861 0.8004 0.8791 0.8796[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.179
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.142
SUFF++ for r=0.3 class 0 = 0.384 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 1 = 0.307 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 2 = 0.388 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 3 = 0.368 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 4 = 0.353 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 5 = 0.361 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 6 = 0.357 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 7 = 0.343 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 8 = 0.335 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 class 9 = 0.333 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 all KL = 0.31 +- 0.223 (in-sample avg dev_std = 0.401)
SUFF++ for r=0.3 all L1 = 0.352 +- 0.110 (in-sample avg dev_std = 0.401)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.282
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.202
SUFF++ for r=0.6 class 0 = 0.298 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 1 = 0.324 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 2 = 0.364 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 3 = 0.352 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 4 = 0.301 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 5 = 0.344 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 6 = 0.309 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 7 = 0.302 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 8 = 0.35 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 class 9 = 0.298 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all KL = 0.197 +- 0.174 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.6 all L1 = 0.324 +- 0.100 (in-sample avg dev_std = 0.467)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.512
SUFF++ for r=0.9 class 0 = 0.45 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 1 = 0.696 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 2 = 0.456 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 3 = 0.373 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 4 = 0.452 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 5 = 0.319 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 6 = 0.316 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 7 = 0.507 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 8 = 0.334 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 class 9 = 0.363 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 all KL = 0.207 +- 0.228 (in-sample avg dev_std = 0.512)
SUFF++ for r=0.9 all L1 = 0.433 +- 0.203 (in-sample avg dev_std = 0.512)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.179
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.144
SUFF++ for r=0.3 class 0 = 0.43 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 1 = 0.304 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 2 = 0.393 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 3 = 0.405 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 4 = 0.35 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 5 = 0.374 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 6 = 0.338 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 7 = 0.343 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 8 = 0.396 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 class 9 = 0.352 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all KL = 0.319 +- 0.237 (in-sample avg dev_std = 0.443)
SUFF++ for r=0.3 all L1 = 0.368 +- 0.115 (in-sample avg dev_std = 0.443)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.207
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.163
SUFF++ for r=0.6 class 0 = 0.353 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 1 = 0.318 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 2 = 0.388 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 3 = 0.376 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 4 = 0.332 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 5 = 0.36 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 6 = 0.302 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 7 = 0.321 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 8 = 0.33 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 class 9 = 0.304 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all KL = 0.239 +- 0.201 (in-sample avg dev_std = 0.478)
SUFF++ for r=0.6 all L1 = 0.339 +- 0.101 (in-sample avg dev_std = 0.478)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.325
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.227
SUFF++ for r=0.9 class 0 = 0.317 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 1 = 0.435 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 2 = 0.449 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 3 = 0.491 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 4 = 0.428 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 5 = 0.37 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 6 = 0.363 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 7 = 0.456 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 8 = 0.407 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 class 9 = 0.363 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 all KL = 0.238 +- 0.234 (in-sample avg dev_std = 0.483)
SUFF++ for r=0.9 all L1 = 0.409 +- 0.177 (in-sample avg dev_std = 0.483)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.179
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.187
NEC for r=0.3 class 0 = 0.586 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 1 = 0.492 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 2 = 0.593 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 3 = 0.584 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 4 = 0.625 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 5 = 0.597 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 6 = 0.62 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 7 = 0.612 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 8 = 0.617 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 class 9 = 0.631 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all KL = 0.608 +- 0.255 (in-sample avg dev_std = 0.338)
NEC for r=0.3 all L1 = 0.594 +- 0.161 (in-sample avg dev_std = 0.338)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.282
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.286
NEC for r=0.6 class 0 = 0.597 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 1 = 0.429 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 2 = 0.613 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 3 = 0.595 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 4 = 0.645 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 5 = 0.638 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 6 = 0.663 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 7 = 0.673 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 8 = 0.616 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 class 9 = 0.652 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all KL = 0.686 +- 0.239 (in-sample avg dev_std = 0.394)
NEC for r=0.6 all L1 = 0.609 +- 0.177 (in-sample avg dev_std = 0.394)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.779
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.649
NEC for r=0.9 class 0 = 0.217 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.196 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.472 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 3 = 0.491 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 4 = 0.471 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 5 = 0.608 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 6 = 0.589 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 7 = 0.457 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 8 = 0.498 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 9 = 0.532 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.59 +- 0.293 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.447 +- 0.248 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.944
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.84
NEC for r=1.0 class 0 = 0.085 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 1 = 0.036 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 2 = 0.307 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 3 = 0.289 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 4 = 0.19 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 5 = 0.289 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 6 = 0.376 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 7 = 0.214 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 8 = 0.251 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 class 9 = 0.256 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all KL = 0.362 +- 0.338 (in-sample avg dev_std = 0.376)
NEC for r=1.0 all L1 = 0.226 +- 0.246 (in-sample avg dev_std = 0.376)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.179
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.181
NEC for r=0.3 class 0 = 0.553 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 1 = 0.506 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 2 = 0.572 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 3 = 0.54 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 4 = 0.593 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 5 = 0.581 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 6 = 0.604 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 7 = 0.607 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 8 = 0.592 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 class 9 = 0.543 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all KL = 0.596 +- 0.256 (in-sample avg dev_std = 0.377)
NEC for r=0.3 all L1 = 0.568 +- 0.170 (in-sample avg dev_std = 0.377)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.207
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.209
NEC for r=0.6 class 0 = 0.617 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 1 = 0.474 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 2 = 0.576 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 3 = 0.56 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 4 = 0.582 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 5 = 0.572 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 6 = 0.64 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 7 = 0.574 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 8 = 0.615 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 class 9 = 0.561 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 all KL = 0.622 +- 0.224 (in-sample avg dev_std = 0.396)
NEC for r=0.6 all L1 = 0.576 +- 0.162 (in-sample avg dev_std = 0.396)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.325
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.294
NEC for r=0.9 class 0 = 0.585 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 1 = 0.361 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 2 = 0.496 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 3 = 0.429 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 4 = 0.537 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 5 = 0.543 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 6 = 0.597 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 7 = 0.444 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 8 = 0.513 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 class 9 = 0.563 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all KL = 0.617 +- 0.274 (in-sample avg dev_std = 0.449)
NEC for r=0.9 all L1 = 0.504 +- 0.226 (in-sample avg dev_std = 0.449)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.416
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.38
NEC for r=1.0 class 0 = 0.539 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 1 = 0.21 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 2 = 0.486 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 3 = 0.421 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 4 = 0.539 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 5 = 0.467 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 6 = 0.532 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 7 = 0.28 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 8 = 0.536 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 class 9 = 0.513 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 all KL = 0.545 +- 0.317 (in-sample avg dev_std = 0.405)
NEC for r=1.0 all L1 = 0.449 +- 0.259 (in-sample avg dev_std = 0.405)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.487, 0.405, 0.815, 1.0], 'all_L1': [0.455, 0.463, 0.818, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.459, 0.348, 0.275, 1.0], 'all_L1': [0.531, 0.414, 0.445, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.283, 0.215, 0.224, 1.0], 'all_L1': [0.381, 0.332, 0.428, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.873, 0.178, 0.813, 1.0], 'all_L1': [0.851, 0.369, 0.813, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.31, 0.197, 0.207, 1.0], 'all_L1': [0.352, 0.324, 0.433, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.459, 0.55, 0.579, 0.4], 'all_L1': [0.5, 0.503, 0.398, 0.239]}), defaultdict(<class 'list'>, {'all_KL': [0.428, 0.633, 0.751, 0.368], 'all_L1': [0.417, 0.58, 0.563, 0.226]}), defaultdict(<class 'list'>, {'all_KL': [0.509, 0.525, 0.69, 0.363], 'all_L1': [0.527, 0.545, 0.528, 0.222]}), defaultdict(<class 'list'>, {'all_KL': [0.143, 0.691, 0.6, 0.387], 'all_L1': [0.155, 0.536, 0.421, 0.239]}), defaultdict(<class 'list'>, {'all_KL': [0.608, 0.686, 0.59, 0.362], 'all_L1': [0.594, 0.609, 0.447, 0.226]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.576, 0.492, 0.778, 1.0], 'all_L1': [0.475, 0.498, 0.736, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.505, 0.392, 0.332, 1.0], 'all_L1': [0.527, 0.433, 0.468, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.608, 0.453, 0.673, 1.0], 'all_L1': [0.516, 0.447, 0.666, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.897, 0.104, 0.769, 1.0], 'all_L1': [0.867, 0.303, 0.735, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.319, 0.239, 0.238, 1.0], 'all_L1': [0.368, 0.339, 0.409, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.365, 0.476, 0.607, 0.553], 'all_L1': [0.473, 0.481, 0.498, 0.432]}), defaultdict(<class 'list'>, {'all_KL': [0.381, 0.565, 0.682, 0.478], 'all_L1': [0.426, 0.547, 0.52, 0.428]}), defaultdict(<class 'list'>, {'all_KL': [0.368, 0.46, 0.608, 0.502], 'all_L1': [0.485, 0.521, 0.517, 0.436]}), defaultdict(<class 'list'>, {'all_KL': [0.106, 0.69, 0.59, 0.602], 'all_L1': [0.136, 0.596, 0.487, 0.494]}), defaultdict(<class 'list'>, {'all_KL': [0.596, 0.622, 0.617, 0.545], 'all_L1': [0.568, 0.576, 0.504, 0.449]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.514 +- 0.180, 0.380 +- 0.052, 0.587 +- 0.186, 1.000 +- 0.000
suff++ class all_KL  =  0.482 +- 0.211, 0.269 +- 0.091, 0.467 +- 0.284, 1.000 +- 0.000
suff++_acc_int  =  0.121 +- 0.013, 0.187 +- 0.023, 0.587 +- 0.146
nec class all_L1  =  0.439 +- 0.153, 0.555 +- 0.037, 0.471 +- 0.063, 0.230 +- 0.007
nec class all_KL  =  0.429 +- 0.156, 0.617 +- 0.068, 0.642 +- 0.067, 0.376 +- 0.015
nec_acc_int  =  0.138 +- 0.027, 0.219 +- 0.035, 0.578 +- 0.058, 0.837 +- 0.009

Eval split test
suff++ class all_L1  =  0.551 +- 0.168, 0.404 +- 0.072, 0.603 +- 0.138, 1.000 +- 0.000
suff++ class all_KL  =  0.581 +- 0.187, 0.336 +- 0.144, 0.558 +- 0.228, 1.000 +- 0.000
suff++_acc_int  =  0.113 +- 0.017, 0.158 +- 0.034, 0.340 +- 0.124
nec class all_L1  =  0.418 +- 0.148, 0.544 +- 0.041, 0.505 +- 0.012, 0.448 +- 0.024
nec class all_KL  =  0.363 +- 0.155, 0.563 +- 0.087, 0.621 +- 0.032, 0.536 +- 0.043
nec_acc_int  =  0.125 +- 0.028, 0.176 +- 0.037, 0.335 +- 0.063, 0.442 +- 0.091


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.476 +- 0.016, 0.467 +- 0.021, 0.529 +- 0.071, 0.615 +- 0.004
Faith. Armon (L1)= 		  =  0.418 +- 0.079, 0.448 +- 0.030, 0.500 +- 0.042, 0.374 +- 0.009
Faith. GMean (L1)= 	  =  0.443 +- 0.041, 0.457 +- 0.025, 0.514 +- 0.056, 0.480 +- 0.007
Faith. Aritm (KL)= 		  =  0.456 +- 0.037, 0.443 +- 0.042, 0.554 +- 0.126, 0.688 +- 0.008
Faith. Armon (KL)= 		  =  0.387 +- 0.079, 0.362 +- 0.079, 0.483 +- 0.167, 0.546 +- 0.016
Faith. GMean (KL)= 	  =  0.417 +- 0.044, 0.399 +- 0.059, 0.516 +- 0.148, 0.613 +- 0.012

Eval split test
Faith. Aritm (L1)= 		  =  0.484 +- 0.014, 0.474 +- 0.017, 0.554 +- 0.066, 0.724 +- 0.012
Faith. Armon (L1)= 		  =  0.425 +- 0.097, 0.456 +- 0.035, 0.541 +- 0.058, 0.618 +- 0.023
Faith. GMean (L1)= 	  =  0.450 +- 0.055, 0.465 +- 0.027, 0.548 +- 0.062, 0.669 +- 0.018
Faith. Aritm (KL)= 		  =  0.472 +- 0.021, 0.449 +- 0.032, 0.589 +- 0.104, 0.768 +- 0.022
Faith. Armon (KL)= 		  =  0.389 +- 0.101, 0.386 +- 0.113, 0.556 +- 0.136, 0.697 +- 0.036
Faith. GMean (KL)= 	  =  0.423 +- 0.059, 0.413 +- 0.080, 0.572 +- 0.121, 0.732 +- 0.029
Computed for split load_split = id



Completed in  1:07:15.837500  for LECIGIN GOODCMNIST/color



DONE LECI GOODCMNIST/color
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 22:14:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 10:14:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.2997
Train Loss: 3.3387
ID Validation ACCURACY: 0.2909
ID Validation Loss: 3.4073
ID Test ACCURACY: 0.2920
ID Test Loss: 3.3954
OOD Validation ACCURACY: 0.2336
OOD Validation Loss: 5.2601
OOD Test ACCURACY: 0.1400
OOD Test Loss: 6.1619

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 90...
[0m[1;37mINFO[0m: [1mCheckpoint 90: 
-----------------------------------
Train ACCURACY: 0.2997
Train Loss: 3.3387
ID Validation ACCURACY: 0.2909
ID Validation Loss: 3.4073
ID Test ACCURACY: 0.2920
ID Test Loss: 3.3954
OOD Validation ACCURACY: 0.2336
OOD Validation Loss: 5.2601
OOD Test ACCURACY: 0.1400
OOD Test Loss: 6.1619

[0m[1;37mINFO[0m: [1mChartInfo 0.2920 0.1400 0.2920 0.1400 0.2909 0.2336[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.284
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.202
SUFF++ for r=0.6 class 0 = 0.611 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 1 = 0.366 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 2 = 0.251 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 3 = 0.258 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 4 = 0.283 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 5 = 0.269 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 6 = 0.307 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 7 = 0.292 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 8 = 0.255 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 class 9 = 0.302 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 all KL = 0.128 +- 0.192 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.6 all L1 = 0.32 +- 0.145 (in-sample avg dev_std = 0.644)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.126
SUFF++ for r=0.6 class 0 = 0.363 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 1 = 0.318 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 2 = 0.38 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 3 = 0.341 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 4 = 0.283 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 5 = 0.398 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 6 = 0.349 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 7 = 0.313 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 8 = 0.296 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 class 9 = 0.306 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 all KL = 0.252 +- 0.229 (in-sample avg dev_std = 0.667)
SUFF++ for r=0.6 all L1 = 0.334 +- 0.126 (in-sample avg dev_std = 0.667)


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.284
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.271
NEC for r=0.6 class 0 = 0.284 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 1 = 0.411 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 2 = 0.585 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 3 = 0.551 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 4 = 0.473 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 5 = 0.578 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 6 = 0.473 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 7 = 0.451 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 8 = 0.575 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 class 9 = 0.415 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all KL = 0.467 +- 0.263 (in-sample avg dev_std = 0.345)
NEC for r=0.6 all L1 = 0.478 +- 0.201 (in-sample avg dev_std = 0.345)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.147
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.159
NEC for r=0.6 class 0 = 0.358 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 1 = 0.318 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 2 = 0.415 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 3 = 0.516 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 4 = 0.474 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 5 = 0.465 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 6 = 0.467 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 7 = 0.507 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 8 = 0.536 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 class 9 = 0.441 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 all KL = 0.402 +- 0.243 (in-sample avg dev_std = 0.355)
NEC for r=0.6 all L1 = 0.447 +- 0.201 (in-sample avg dev_std = 0.355)
model_dirname= repr_CIGAGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 22:19:02 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 10:19:03 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 70...
[0m[1;37mINFO[0m: [1mCheckpoint 70: 
-----------------------------------
Train ACCURACY: 0.6581
Train Loss: 0.9910
ID Validation ACCURACY: 0.6360
ID Validation Loss: 1.0899
ID Test ACCURACY: 0.6253
ID Test Loss: 1.1128
OOD Validation ACCURACY: 0.4889
OOD Validation Loss: 1.6348
OOD Test ACCURACY: 0.2900
OOD Test Loss: 2.5498

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 76...
[0m[1;37mINFO[0m: [1mCheckpoint 76: 
-----------------------------------
Train ACCURACY: 0.5949
Train Loss: 1.2307
ID Validation ACCURACY: 0.5809
ID Validation Loss: 1.3357
ID Test ACCURACY: 0.5690
ID Test Loss: 1.3701
OOD Validation ACCURACY: 0.5664
OOD Validation Loss: 1.3707
OOD Test ACCURACY: 0.3381
OOD Test Loss: 2.4209

[0m[1;37mINFO[0m: [1mChartInfo 0.6253 0.2900 0.5690 0.3381 0.5809 0.5664[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.263
SUFF++ for r=0.6 class 0 = 0.253 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 1 = 0.319 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 2 = 0.312 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 3 = 0.314 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 4 = 0.337 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 5 = 0.304 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 6 = 0.342 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 7 = 0.378 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 8 = 0.333 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 class 9 = 0.306 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 all KL = 0.182 +- 0.155 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.6 all L1 = 0.32 +- 0.083 (in-sample avg dev_std = 0.583)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.29
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.205
SUFF++ for r=0.6 class 0 = 0.338 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 1 = 0.394 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 2 = 0.347 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 3 = 0.34 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 4 = 0.343 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 5 = 0.344 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 6 = 0.36 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 7 = 0.353 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 8 = 0.343 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 class 9 = 0.328 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 all KL = 0.258 +- 0.170 (in-sample avg dev_std = 0.595)
SUFF++ for r=0.6 all L1 = 0.349 +- 0.070 (in-sample avg dev_std = 0.595)


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.64
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.431
NEC for r=0.6 class 0 = 0.64 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 1 = 0.266 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 2 = 0.533 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 3 = 0.537 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 4 = 0.439 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 5 = 0.554 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 6 = 0.564 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 7 = 0.521 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 8 = 0.456 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 class 9 = 0.548 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all KL = 0.484 +- 0.232 (in-sample avg dev_std = 0.330)
NEC for r=0.6 all L1 = 0.503 +- 0.184 (in-sample avg dev_std = 0.330)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.29
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.281
NEC for r=0.6 class 0 = 0.47 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 1 = 0.099 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 2 = 0.461 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 3 = 0.44 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 4 = 0.503 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 5 = 0.47 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 6 = 0.473 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 7 = 0.489 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 8 = 0.451 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 class 9 = 0.483 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all KL = 0.328 +- 0.199 (in-sample avg dev_std = 0.235)
NEC for r=0.6 all L1 = 0.429 +- 0.182 (in-sample avg dev_std = 0.235)
model_dirname= repr_CIGAGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 22:24:04 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:04 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 10:24:05 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 66...
[0m[1;37mINFO[0m: [1mCheckpoint 66: 
-----------------------------------
Train ACCURACY: 0.6698
Train Loss: 0.9467
ID Validation ACCURACY: 0.6491
ID Validation Loss: 1.0314
ID Test ACCURACY: 0.6391
ID Test Loss: 1.0585
OOD Validation ACCURACY: 0.5524
OOD Validation Loss: 1.4077
OOD Test ACCURACY: 0.3830
OOD Test Loss: 2.2401

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 73...
[0m[1;37mINFO[0m: [1mCheckpoint 73: 
-----------------------------------
Train ACCURACY: 0.6334
Train Loss: 1.1120
ID Validation ACCURACY: 0.6076
ID Validation Loss: 1.2323
ID Test ACCURACY: 0.6007
ID Test Loss: 1.2595
OOD Validation ACCURACY: 0.5951
OOD Validation Loss: 1.2541
OOD Test ACCURACY: 0.3426
OOD Test Loss: 2.3810

[0m[1;37mINFO[0m: [1mChartInfo 0.6391 0.3830 0.6007 0.3426 0.6076 0.5951[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.265
SUFF++ for r=0.6 class 0 = 0.252 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 1 = 0.281 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 2 = 0.318 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 3 = 0.304 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 4 = 0.327 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 5 = 0.307 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 6 = 0.29 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 7 = 0.437 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 8 = 0.307 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 class 9 = 0.305 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 all KL = 0.172 +- 0.159 (in-sample avg dev_std = 0.585)
SUFF++ for r=0.6 all L1 = 0.314 +- 0.090 (in-sample avg dev_std = 0.585)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.381
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.252
SUFF++ for r=0.6 class 0 = 0.386 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 1 = 0.368 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 2 = 0.339 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 3 = 0.326 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 4 = 0.339 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 5 = 0.335 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 6 = 0.347 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 7 = 0.39 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 8 = 0.363 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 class 9 = 0.339 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 all KL = 0.233 +- 0.189 (in-sample avg dev_std = 0.592)
SUFF++ for r=0.6 all L1 = 0.354 +- 0.089 (in-sample avg dev_std = 0.592)


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.642
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.425
NEC for r=0.6 class 0 = 0.594 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 1 = 0.45 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 2 = 0.509 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 3 = 0.532 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 4 = 0.425 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 5 = 0.54 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 6 = 0.594 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 7 = 0.48 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 8 = 0.503 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 class 9 = 0.54 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all KL = 0.514 +- 0.236 (in-sample avg dev_std = 0.354)
NEC for r=0.6 all L1 = 0.515 +- 0.169 (in-sample avg dev_std = 0.354)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.381
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.375
NEC for r=0.6 class 0 = 0.33 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 1 = 0.101 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 2 = 0.488 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 3 = 0.517 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 4 = 0.53 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 5 = 0.513 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 6 = 0.507 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 7 = 0.505 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 8 = 0.497 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 class 9 = 0.512 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all KL = 0.37 +- 0.218 (in-sample avg dev_std = 0.284)
NEC for r=0.6 all L1 = 0.445 +- 0.196 (in-sample avg dev_std = 0.284)
model_dirname= repr_CIGAGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 22:29:06 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:06 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 10:29:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 66...
[0m[1;37mINFO[0m: [1mCheckpoint 66: 
-----------------------------------
Train ACCURACY: 0.5377
Train Loss: 1.5075
ID Validation ACCURACY: 0.5361
ID Validation Loss: 1.5713
ID Test ACCURACY: 0.5206
ID Test Loss: 1.6479
OOD Validation ACCURACY: 0.4199
OOD Validation Loss: 2.4982
OOD Test ACCURACY: 0.3477
OOD Test Loss: 3.0782

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 52...
[0m[1;37mINFO[0m: [1mCheckpoint 52: 
-----------------------------------
Train ACCURACY: 0.4893
Train Loss: 1.5757
ID Validation ACCURACY: 0.4821
ID Validation Loss: 1.6006
ID Test ACCURACY: 0.4747
ID Test Loss: 1.6438
OOD Validation ACCURACY: 0.4277
OOD Validation Loss: 1.9595
OOD Test ACCURACY: 0.3373
OOD Test Loss: 2.5935

[0m[1;37mINFO[0m: [1mChartInfo 0.5206 0.3477 0.4747 0.3373 0.4821 0.4277[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.504
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.257
SUFF++ for r=0.6 class 0 = 0.434 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 1 = 0.263 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 2 = 0.294 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 3 = 0.396 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 4 = 0.262 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 5 = 0.317 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 6 = 0.269 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 7 = 0.262 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 8 = 0.387 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 class 9 = 0.272 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 all KL = 0.147 +- 0.180 (in-sample avg dev_std = 0.609)
SUFF++ for r=0.6 all L1 = 0.315 +- 0.118 (in-sample avg dev_std = 0.609)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.361
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.228
SUFF++ for r=0.6 class 0 = 0.377 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 1 = 0.352 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 2 = 0.274 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 3 = 0.305 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 4 = 0.267 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 5 = 0.277 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 6 = 0.304 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 7 = 0.29 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 8 = 0.304 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 9 = 0.267 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 all KL = 0.15 +- 0.162 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 all L1 = 0.303 +- 0.092 (in-sample avg dev_std = 0.653)


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.504
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.386
NEC for r=0.6 class 0 = 0.168 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 1 = 0.629 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 2 = 0.621 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 3 = 0.488 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 4 = 0.563 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 5 = 0.559 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 6 = 0.533 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 7 = 0.526 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 8 = 0.477 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 class 9 = 0.544 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all KL = 0.534 +- 0.276 (in-sample avg dev_std = 0.360)
NEC for r=0.6 all L1 = 0.511 +- 0.215 (in-sample avg dev_std = 0.360)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.361
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.341
NEC for r=0.6 class 0 = 0.281 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 1 = 0.078 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 2 = 0.593 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 3 = 0.584 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 4 = 0.586 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 5 = 0.597 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 6 = 0.568 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 7 = 0.562 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 8 = 0.582 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 class 9 = 0.555 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 all KL = 0.498 +- 0.272 (in-sample avg dev_std = 0.341)
NEC for r=0.6 all L1 = 0.492 +- 0.236 (in-sample avg dev_std = 0.341)
model_dirname= repr_CIGAGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 22:34:11 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1m Init CIGAGIN
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mCreating GINFeatExtractor:  5
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing  3  layers for classifier
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mUsing feature sampling = feat
[0m[1;34mDEBUG[0m: 09/28/2024 10:34:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 78...
[0m[1;37mINFO[0m: [1mCheckpoint 78: 
-----------------------------------
Train ACCURACY: 0.5967
Train Loss: 1.3782
ID Validation ACCURACY: 0.5773
ID Validation Loss: 1.5029
ID Test ACCURACY: 0.5697
ID Test Loss: 1.5503
OOD Validation ACCURACY: 0.4626
OOD Validation Loss: 2.5270
OOD Test ACCURACY: 0.3526
OOD Test Loss: 8.1775

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 57...
[0m[1;37mINFO[0m: [1mCheckpoint 57: 
-----------------------------------
Train ACCURACY: 0.5321
Train Loss: 1.5191
ID Validation ACCURACY: 0.5236
ID Validation Loss: 1.5860
ID Test ACCURACY: 0.5176
ID Test Loss: 1.6001
OOD Validation ACCURACY: 0.4831
OOD Validation Loss: 1.8222
OOD Test ACCURACY: 0.3497
OOD Test Loss: 9.4069

[0m[1;37mINFO[0m: [1mChartInfo 0.5697 0.3526 0.5176 0.3497 0.5236 0.4831[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.574
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.311
SUFF++ for r=0.6 class 0 = 0.54 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 1 = 0.511 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 2 = 0.242 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 3 = 0.283 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 4 = 0.268 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 5 = 0.309 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 6 = 0.27 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 7 = 0.269 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 8 = 0.277 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 class 9 = 0.275 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 all KL = 0.07 +- 0.123 (in-sample avg dev_std = 0.653)
SUFF++ for r=0.6 all L1 = 0.327 +- 0.152 (in-sample avg dev_std = 0.653)



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.351
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.225
SUFF++ for r=0.6 class 0 = 0.349 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 1 = 0.37 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 2 = 0.282 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 3 = 0.283 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 4 = 0.27 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 5 = 0.291 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 6 = 0.286 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 7 = 0.289 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 8 = 0.269 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 class 9 = 0.274 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 all KL = 0.075 +- 0.105 (in-sample avg dev_std = 0.723)
SUFF++ for r=0.6 all L1 = 0.297 +- 0.086 (in-sample avg dev_std = 0.723)


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.574
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.472
NEC for r=0.6 class 0 = 0.251 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 1 = 0.254 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 2 = 0.633 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 3 = 0.495 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 4 = 0.557 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 5 = 0.556 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 6 = 0.518 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 7 = 0.495 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 8 = 0.521 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 class 9 = 0.524 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 all KL = 0.513 +- 0.276 (in-sample avg dev_std = 0.389)
NEC for r=0.6 all L1 = 0.476 +- 0.228 (in-sample avg dev_std = 0.389)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.351
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.339
NEC for r=0.6 class 0 = 0.146 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 1 = 0.064 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 2 = 0.549 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 3 = 0.563 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 4 = 0.546 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 5 = 0.535 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 6 = 0.562 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 7 = 0.542 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 8 = 0.582 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 class 9 = 0.527 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all KL = 0.526 +- 0.343 (in-sample avg dev_std = 0.381)
NEC for r=0.6 all L1 = 0.455 +- 0.284 (in-sample avg dev_std = 0.381)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.128], 'all_L1': [0.32]}), defaultdict(<class 'list'>, {'all_KL': [0.182], 'all_L1': [0.32]}), defaultdict(<class 'list'>, {'all_KL': [0.172], 'all_L1': [0.314]}), defaultdict(<class 'list'>, {'all_KL': [0.147], 'all_L1': [0.315]}), defaultdict(<class 'list'>, {'all_KL': [0.07], 'all_L1': [0.327]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.467], 'all_L1': [0.478]}), defaultdict(<class 'list'>, {'all_KL': [0.484], 'all_L1': [0.503]}), defaultdict(<class 'list'>, {'all_KL': [0.514], 'all_L1': [0.515]}), defaultdict(<class 'list'>, {'all_KL': [0.534], 'all_L1': [0.511]}), defaultdict(<class 'list'>, {'all_KL': [0.513], 'all_L1': [0.476]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.252], 'all_L1': [0.334]}), defaultdict(<class 'list'>, {'all_KL': [0.258], 'all_L1': [0.349]}), defaultdict(<class 'list'>, {'all_KL': [0.233], 'all_L1': [0.354]}), defaultdict(<class 'list'>, {'all_KL': [0.15], 'all_L1': [0.303]}), defaultdict(<class 'list'>, {'all_KL': [0.075], 'all_L1': [0.297]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.402], 'all_L1': [0.447]}), defaultdict(<class 'list'>, {'all_KL': [0.328], 'all_L1': [0.429]}), defaultdict(<class 'list'>, {'all_KL': [0.37], 'all_L1': [0.445]}), defaultdict(<class 'list'>, {'all_KL': [0.498], 'all_L1': [0.492]}), defaultdict(<class 'list'>, {'all_KL': [0.526], 'all_L1': [0.455]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.319 +- 0.005
suff++ class all_KL  =  0.140 +- 0.040
suff++_acc_int  =  0.260 +- 0.035
nec class all_L1  =  0.497 +- 0.016
nec class all_KL  =  0.502 +- 0.024
nec_acc_int  =  0.397 +- 0.068

Eval split test
suff++ class all_L1  =  0.327 +- 0.023
suff++ class all_KL  =  0.194 +- 0.071
suff++_acc_int  =  0.207 +- 0.043
nec class all_L1  =  0.454 +- 0.021
nec class all_KL  =  0.425 +- 0.075
nec_acc_int  =  0.299 +- 0.076


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.408 +- 0.006
Faith. Armon (L1)= 		  =  0.388 +- 0.003
Faith. GMean (L1)= 	  =  0.398 +- 0.004
Faith. Aritm (KL)= 		  =  0.321 +- 0.022
Faith. Armon (KL)= 		  =  0.215 +- 0.051
Faith. GMean (KL)= 	  =  0.262 +- 0.041

Eval split test
Faith. Aritm (L1)= 		  =  0.391 +- 0.008
Faith. Armon (L1)= 		  =  0.379 +- 0.012
Faith. GMean (L1)= 	  =  0.385 +- 0.009
Faith. Aritm (KL)= 		  =  0.309 +- 0.014
Faith. Armon (KL)= 		  =  0.249 +- 0.065
Faith. GMean (KL)= 	  =  0.275 +- 0.041
Computed for split load_split = id



Completed in  0:25:15.368911  for CIGAGIN GOODCMNIST/color



DONE CIGA GOODCMNIST/color
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 22:39:34 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:34 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:34 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:34 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 10:39:35 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9710
Train Loss: 0.0888
ID Validation ACCURACY: 0.8913
ID Validation Loss: 0.3578
ID Test ACCURACY: 0.8891
ID Test Loss: 0.3689
OOD Validation ACCURACY: 0.7710
OOD Validation Loss: 0.8283
OOD Test ACCURACY: 0.2787
OOD Test Loss: 5.7327

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 175...
[0m[1;37mINFO[0m: [1mCheckpoint 175: 
-----------------------------------
Train ACCURACY: 0.9678
Train Loss: 0.0980
ID Validation ACCURACY: 0.8826
ID Validation Loss: 0.3955
ID Test ACCURACY: 0.8830
ID Test Loss: 0.3916
OOD Validation ACCURACY: 0.7823
OOD Validation Loss: 0.8443
OOD Test ACCURACY: 0.3099
OOD Test Loss: 7.0050

[0m[1;37mINFO[0m: [1mChartInfo 0.8891 0.2787 0.8830 0.3099 0.8826 0.7823[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.113
SUFF++ for r=0.3 class 0 = 0.561 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 1 = 0.48 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 2 = 0.597 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 3 = 0.609 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 4 = 0.586 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 5 = 0.695 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 6 = 0.587 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 7 = 0.511 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 8 = 0.518 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 9 = 0.635 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all KL = 0.491 +- 0.311 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all L1 = 0.574 +- 0.275 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.203
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.15
SUFF++ for r=0.6 class 0 = 0.369 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1 = 0.424 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 2 = 0.469 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 3 = 0.456 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 4 = 0.386 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 5 = 0.393 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 6 = 0.444 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 7 = 0.604 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 8 = 0.382 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 9 = 0.433 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.32 +- 0.261 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.439 +- 0.207 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.384
SUFF++ for r=0.9 class 0 = 0.264 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 1 = 0.324 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 2 = 0.292 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 3 = 0.273 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 4 = 0.67 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 5 = 0.268 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 6 = 0.273 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 7 = 0.469 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 8 = 0.315 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 class 9 = 0.286 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 all KL = 0.135 +- 0.247 (in-sample avg dev_std = 0.676)
SUFF++ for r=0.9 all L1 = 0.344 +- 0.186 (in-sample avg dev_std = 0.676)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
SUFF++ for r=0.3 class 0 = 0.591 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 1 = 0.556 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 2 = 0.6 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 3 = 0.657 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 4 = 0.662 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 5 = 0.633 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 6 = 0.651 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 7 = 0.659 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 8 = 0.679 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 class 9 = 0.709 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all KL = 0.511 +- 0.324 (in-sample avg dev_std = 0.372)
SUFF++ for r=0.3 all L1 = 0.638 +- 0.274 (in-sample avg dev_std = 0.372)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.12
SUFF++ for r=0.6 class 0 = 0.41 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 1 = 0.225 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 2 = 0.38 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 3 = 0.349 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 4 = 0.333 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 5 = 0.422 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 6 = 0.363 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 7 = 0.399 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 8 = 0.477 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 class 9 = 0.342 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all KL = 0.253 +- 0.293 (in-sample avg dev_std = 0.403)
SUFF++ for r=0.6 all L1 = 0.368 +- 0.239 (in-sample avg dev_std = 0.403)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.194
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.182
SUFF++ for r=0.9 class 0 = 0.292 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 1 = 0.228 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 2 = 0.275 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 3 = 0.273 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 4 = 0.271 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 5 = 0.268 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 6 = 0.263 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 7 = 0.304 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 8 = 0.253 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 class 9 = 0.258 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 all KL = 0.079 +- 0.139 (in-sample avg dev_std = 0.477)
SUFF++ for r=0.9 all L1 = 0.268 +- 0.123 (in-sample avg dev_std = 0.477)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.104
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.12
NEC for r=0.3 class 0 = 0.477 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 1 = 0.566 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 2 = 0.407 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 3 = 0.42 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 4 = 0.418 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 5 = 0.338 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 6 = 0.442 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 7 = 0.5 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 8 = 0.505 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 class 9 = 0.407 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 all KL = 0.572 +- 0.301 (in-sample avg dev_std = 0.423)
NEC for r=0.3 all L1 = 0.452 +- 0.248 (in-sample avg dev_std = 0.423)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.203
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.181
NEC for r=0.6 class 0 = 0.649 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 1 = 0.601 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 2 = 0.493 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 3 = 0.494 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 4 = 0.463 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 5 = 0.571 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 6 = 0.536 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 7 = 0.363 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 8 = 0.598 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 class 9 = 0.521 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 all KL = 0.615 +- 0.275 (in-sample avg dev_std = 0.466)
NEC for r=0.6 all L1 = 0.527 +- 0.204 (in-sample avg dev_std = 0.466)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.762
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.628
NEC for r=0.9 class 0 = 0.524 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 1 = 0.405 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 2 = 0.544 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 3 = 0.436 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 4 = 0.356 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 5 = 0.574 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 6 = 0.593 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 7 = 0.17 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 8 = 0.335 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 class 9 = 0.563 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all KL = 0.571 +- 0.314 (in-sample avg dev_std = 0.450)
NEC for r=0.9 all L1 = 0.444 +- 0.254 (in-sample avg dev_std = 0.450)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.936
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.845
NEC for r=1.0 class 0 = 0.13 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 1 = 0.041 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 2 = 0.339 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 3 = 0.234 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 4 = 0.226 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 5 = 0.354 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 6 = 0.316 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 7 = 0.197 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 8 = 0.209 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 class 9 = 0.381 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 all KL = 0.346 +- 0.310 (in-sample avg dev_std = 0.350)
NEC for r=1.0 all L1 = 0.237 +- 0.234 (in-sample avg dev_std = 0.350)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.114
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.105
NEC for r=0.3 class 0 = 0.398 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 1 = 0.438 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 2 = 0.453 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 3 = 0.406 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 4 = 0.404 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 5 = 0.413 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 6 = 0.376 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 7 = 0.343 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 8 = 0.359 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 class 9 = 0.31 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all KL = 0.531 +- 0.341 (in-sample avg dev_std = 0.406)
NEC for r=0.3 all L1 = 0.391 +- 0.273 (in-sample avg dev_std = 0.406)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.159
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.139
NEC for r=0.6 class 0 = 0.59 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 1 = 0.745 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 2 = 0.591 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 3 = 0.648 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 4 = 0.662 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 5 = 0.611 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 6 = 0.628 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 7 = 0.579 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 8 = 0.546 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 class 9 = 0.662 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 all KL = 0.75 +- 0.281 (in-sample avg dev_std = 0.408)
NEC for r=0.6 all L1 = 0.627 +- 0.230 (in-sample avg dev_std = 0.408)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.194
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.246
NEC for r=0.9 class 0 = 0.677 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 1 = 0.726 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 2 = 0.584 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 3 = 0.653 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 4 = 0.705 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 5 = 0.666 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 6 = 0.69 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 7 = 0.645 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 8 = 0.692 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 class 9 = 0.757 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all KL = 0.821 +- 0.228 (in-sample avg dev_std = 0.426)
NEC for r=0.9 all L1 = 0.679 +- 0.179 (in-sample avg dev_std = 0.426)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.281
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.367
NEC for r=1.0 class 0 = 0.599 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 1 = 0.665 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 2 = 0.558 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 3 = 0.608 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 4 = 0.646 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 5 = 0.604 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 6 = 0.702 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 7 = 0.561 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 8 = 0.686 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 class 9 = 0.71 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all KL = 0.735 +- 0.276 (in-sample avg dev_std = 0.374)
NEC for r=1.0 all L1 = 0.633 +- 0.215 (in-sample avg dev_std = 0.374)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 22:55:29 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:30 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:30 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:30 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 10:55:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ACCURACY: 0.9697
Train Loss: 0.0910
ID Validation ACCURACY: 0.8901
ID Validation Loss: 0.3680
ID Test ACCURACY: 0.8897
ID Test Loss: 0.3824
OOD Validation ACCURACY: 0.7509
OOD Validation Loss: 1.0322
OOD Test ACCURACY: 0.2683
OOD Test Loss: 5.3981

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 168...
[0m[1;37mINFO[0m: [1mCheckpoint 168: 
-----------------------------------
Train ACCURACY: 0.9635
Train Loss: 0.1083
ID Validation ACCURACY: 0.8834
ID Validation Loss: 0.3827
ID Test ACCURACY: 0.8824
ID Test Loss: 0.3845
OOD Validation ACCURACY: 0.7814
OOD Validation Loss: 0.9042
OOD Test ACCURACY: 0.3949
OOD Test Loss: 2.9563

[0m[1;37mINFO[0m: [1mChartInfo 0.8897 0.2683 0.8824 0.3949 0.8834 0.7814[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.106
SUFF++ for r=0.3 class 0 = 0.487 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 1 = 0.809 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 2 = 0.432 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 3 = 0.459 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 4 = 0.428 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 5 = 0.514 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 6 = 0.479 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 7 = 0.475 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 8 = 0.437 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 class 9 = 0.563 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 all KL = 0.417 +- 0.305 (in-sample avg dev_std = 0.521)
SUFF++ for r=0.3 all L1 = 0.511 +- 0.252 (in-sample avg dev_std = 0.521)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.185
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.138
SUFF++ for r=0.6 class 0 = 0.276 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 1 = 0.74 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 2 = 0.537 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 3 = 0.514 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 4 = 0.403 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 5 = 0.35 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 6 = 0.44 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 7 = 0.613 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 8 = 0.447 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 class 9 = 0.46 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all KL = 0.393 +- 0.312 (in-sample avg dev_std = 0.451)
SUFF++ for r=0.6 all L1 = 0.486 +- 0.265 (in-sample avg dev_std = 0.451)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.66
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.333
SUFF++ for r=0.9 class 0 = 0.24 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 1 = 0.282 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 2 = 0.29 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 3 = 0.245 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 4 = 0.578 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 5 = 0.257 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 6 = 0.272 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 7 = 0.53 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 8 = 0.301 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 class 9 = 0.293 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 all KL = 0.145 +- 0.236 (in-sample avg dev_std = 0.599)
SUFF++ for r=0.9 all L1 = 0.33 +- 0.185 (in-sample avg dev_std = 0.599)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.13
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
SUFF++ for r=0.3 class 0 = 0.582 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 1 = 0.333 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 2 = 0.574 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 3 = 0.568 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 4 = 0.573 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 5 = 0.622 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 6 = 0.607 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 7 = 0.732 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 8 = 0.623 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 class 9 = 0.534 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 all KL = 0.37 +- 0.290 (in-sample avg dev_std = 0.467)
SUFF++ for r=0.3 all L1 = 0.572 +- 0.260 (in-sample avg dev_std = 0.467)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.13
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.106
SUFF++ for r=0.6 class 0 = 0.397 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 1 = 0.24 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 2 = 0.357 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 3 = 0.412 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 4 = 0.401 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 5 = 0.426 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 6 = 0.434 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 7 = 0.438 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 8 = 0.552 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 class 9 = 0.386 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all KL = 0.243 +- 0.254 (in-sample avg dev_std = 0.455)
SUFF++ for r=0.6 all L1 = 0.402 +- 0.232 (in-sample avg dev_std = 0.455)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.225
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.187
SUFF++ for r=0.9 class 0 = 0.254 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 1 = 0.25 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 2 = 0.232 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 3 = 0.23 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 4 = 0.228 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 5 = 0.225 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 6 = 0.248 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 7 = 0.241 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 8 = 0.236 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 class 9 = 0.226 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 all KL = 0.064 +- 0.126 (in-sample avg dev_std = 0.445)
SUFF++ for r=0.9 all L1 = 0.237 +- 0.117 (in-sample avg dev_std = 0.445)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.09
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.109
NEC for r=0.3 class 0 = 0.469 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 1 = 0.233 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 2 = 0.517 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 3 = 0.51 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 4 = 0.516 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 5 = 0.48 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 6 = 0.48 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 7 = 0.494 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 8 = 0.542 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 class 9 = 0.437 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all KL = 0.551 +- 0.311 (in-sample avg dev_std = 0.480)
NEC for r=0.3 all L1 = 0.465 +- 0.245 (in-sample avg dev_std = 0.480)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.185
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.163
NEC for r=0.6 class 0 = 0.687 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 1 = 0.333 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 2 = 0.47 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 3 = 0.498 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 4 = 0.517 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 5 = 0.616 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 6 = 0.554 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 7 = 0.424 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 8 = 0.543 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 class 9 = 0.555 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 all KL = 0.617 +- 0.295 (in-sample avg dev_std = 0.462)
NEC for r=0.6 all L1 = 0.514 +- 0.230 (in-sample avg dev_std = 0.462)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.66
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.525
NEC for r=0.9 class 0 = 0.632 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 1 = 0.477 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 2 = 0.575 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 3 = 0.588 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 4 = 0.455 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 5 = 0.598 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 6 = 0.594 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 7 = 0.245 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 8 = 0.406 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 class 9 = 0.587 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all KL = 0.644 +- 0.291 (in-sample avg dev_std = 0.467)
NEC for r=0.9 all L1 = 0.512 +- 0.240 (in-sample avg dev_std = 0.467)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.934
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.838
NEC for r=1.0 class 0 = 0.137 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 1 = 0.066 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 2 = 0.393 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 3 = 0.322 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 4 = 0.194 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 5 = 0.31 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 6 = 0.27 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 7 = 0.213 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 8 = 0.172 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 9 = 0.373 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all KL = 0.357 +- 0.323 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all L1 = 0.242 +- 0.242 (in-sample avg dev_std = 0.360)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.13
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.11
NEC for r=0.3 class 0 = 0.343 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 1 = 0.629 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 2 = 0.378 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 3 = 0.385 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 4 = 0.408 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 5 = 0.341 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 6 = 0.326 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 7 = 0.199 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 8 = 0.319 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 class 9 = 0.427 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all KL = 0.505 +- 0.374 (in-sample avg dev_std = 0.374)
NEC for r=0.3 all L1 = 0.379 +- 0.311 (in-sample avg dev_std = 0.374)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.13
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.123
NEC for r=0.6 class 0 = 0.57 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 1 = 0.754 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 2 = 0.617 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 3 = 0.599 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 4 = 0.575 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 5 = 0.583 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 6 = 0.511 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 7 = 0.534 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 8 = 0.429 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 class 9 = 0.585 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 all KL = 0.731 +- 0.307 (in-sample avg dev_std = 0.426)
NEC for r=0.6 all L1 = 0.578 +- 0.269 (in-sample avg dev_std = 0.426)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.225
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.255
NEC for r=0.9 class 0 = 0.695 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 1 = 0.548 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 2 = 0.678 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 3 = 0.706 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 4 = 0.726 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 5 = 0.712 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 6 = 0.727 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 7 = 0.735 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 8 = 0.751 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 class 9 = 0.75 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 all KL = 0.868 +- 0.209 (in-sample avg dev_std = 0.413)
NEC for r=0.9 all L1 = 0.7 +- 0.183 (in-sample avg dev_std = 0.413)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.281
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.369
NEC for r=1.0 class 0 = 0.652 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 1 = 0.426 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 2 = 0.618 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 3 = 0.684 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 4 = 0.719 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 5 = 0.594 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 6 = 0.732 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 7 = 0.617 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 8 = 0.682 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 class 9 = 0.697 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all KL = 0.777 +- 0.286 (in-sample avg dev_std = 0.360)
NEC for r=1.0 all L1 = 0.639 +- 0.243 (in-sample avg dev_std = 0.360)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 23:11:28 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:28 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:28 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:28 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 11:11:29 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 158...
[0m[1;37mINFO[0m: [1mCheckpoint 158: 
-----------------------------------
Train ACCURACY: 0.9624
Train Loss: 0.1081
ID Validation ACCURACY: 0.8889
ID Validation Loss: 0.3704
ID Test ACCURACY: 0.8846
ID Test Loss: 0.3894
OOD Validation ACCURACY: 0.7016
OOD Validation Loss: 1.3742
OOD Test ACCURACY: 0.3063
OOD Test Loss: 4.9057

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 166...
[0m[1;37mINFO[0m: [1mCheckpoint 166: 
-----------------------------------
Train ACCURACY: 0.9646
Train Loss: 0.1029
ID Validation ACCURACY: 0.8820
ID Validation Loss: 0.3984
ID Test ACCURACY: 0.8826
ID Test Loss: 0.4026
OOD Validation ACCURACY: 0.7703
OOD Validation Loss: 0.9501
OOD Test ACCURACY: 0.2739
OOD Test Loss: 7.1712

[0m[1;37mINFO[0m: [1mChartInfo 0.8846 0.3063 0.8826 0.2739 0.8820 0.7703[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.174
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.136
SUFF++ for r=0.3 class 0 = 0.308 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 1 = 0.32 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 2 = 0.357 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 3 = 0.334 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 4 = 0.345 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 5 = 0.324 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 6 = 0.323 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 7 = 0.375 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 8 = 0.304 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 class 9 = 0.325 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all KL = 0.172 +- 0.182 (in-sample avg dev_std = 0.611)
SUFF++ for r=0.3 all L1 = 0.332 +- 0.121 (in-sample avg dev_std = 0.611)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.236
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.177
SUFF++ for r=0.6 class 0 = 0.277 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 1 = 0.377 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 2 = 0.351 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 3 = 0.344 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 4 = 0.307 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 5 = 0.28 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 6 = 0.305 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 7 = 0.354 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 8 = 0.295 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 class 9 = 0.313 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 all KL = 0.183 +- 0.204 (in-sample avg dev_std = 0.575)
SUFF++ for r=0.6 all L1 = 0.323 +- 0.148 (in-sample avg dev_std = 0.575)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.756
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.407
SUFF++ for r=0.9 class 0 = 0.246 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 1 = 0.558 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 2 = 0.298 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 3 = 0.246 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 4 = 0.691 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 5 = 0.252 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 6 = 0.294 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 7 = 0.428 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 8 = 0.314 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 class 9 = 0.357 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 all KL = 0.16 +- 0.255 (in-sample avg dev_std = 0.644)
SUFF++ for r=0.9 all L1 = 0.371 +- 0.203 (in-sample avg dev_std = 0.644)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.112
SUFF++ for r=0.3 class 0 = 0.306 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 1 = 0.295 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 2 = 0.308 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 3 = 0.286 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 4 = 0.32 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 5 = 0.315 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 6 = 0.304 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 7 = 0.31 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 8 = 0.303 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 class 9 = 0.289 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 all KL = 0.111 +- 0.146 (in-sample avg dev_std = 0.720)
SUFF++ for r=0.3 all L1 = 0.303 +- 0.104 (in-sample avg dev_std = 0.720)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.126
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.1
SUFF++ for r=0.6 class 0 = 0.278 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 1 = 0.233 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 2 = 0.296 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 3 = 0.328 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 4 = 0.265 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 5 = 0.299 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 6 = 0.341 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 7 = 0.333 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 8 = 0.32 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 class 9 = 0.321 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all KL = 0.134 +- 0.175 (in-sample avg dev_std = 0.476)
SUFF++ for r=0.6 all L1 = 0.3 +- 0.160 (in-sample avg dev_std = 0.476)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.231
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.206
SUFF++ for r=0.9 class 0 = 0.231 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 1 = 0.327 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 2 = 0.237 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 3 = 0.24 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 4 = 0.225 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 5 = 0.241 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 6 = 0.265 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 7 = 0.28 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 8 = 0.232 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 class 9 = 0.253 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 all KL = 0.083 +- 0.124 (in-sample avg dev_std = 0.437)
SUFF++ for r=0.9 all L1 = 0.254 +- 0.112 (in-sample avg dev_std = 0.437)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.174
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.174
NEC for r=0.3 class 0 = 0.65 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 1 = 0.361 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 2 = 0.579 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 3 = 0.598 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 4 = 0.621 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 5 = 0.642 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 6 = 0.613 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 7 = 0.542 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 8 = 0.596 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 class 9 = 0.606 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 all KL = 0.696 +- 0.258 (in-sample avg dev_std = 0.498)
NEC for r=0.3 all L1 = 0.576 +- 0.204 (in-sample avg dev_std = 0.498)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.236
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.239
NEC for r=0.6 class 0 = 0.655 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 1 = 0.562 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 2 = 0.574 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 3 = 0.6 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 4 = 0.495 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 5 = 0.621 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 6 = 0.641 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 7 = 0.623 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 8 = 0.624 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 class 9 = 0.558 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all KL = 0.708 +- 0.239 (in-sample avg dev_std = 0.477)
NEC for r=0.6 all L1 = 0.595 +- 0.180 (in-sample avg dev_std = 0.477)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.756
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.644
NEC for r=0.9 class 0 = 0.59 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 1 = 0.188 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 2 = 0.528 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 3 = 0.469 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 4 = 0.328 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 5 = 0.602 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 6 = 0.513 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 7 = 0.297 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 8 = 0.311 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 class 9 = 0.501 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all KL = 0.54 +- 0.297 (in-sample avg dev_std = 0.429)
NEC for r=0.9 all L1 = 0.426 +- 0.246 (in-sample avg dev_std = 0.429)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.939
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.845
NEC for r=1.0 class 0 = 0.141 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 1 = 0.028 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 2 = 0.342 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 3 = 0.269 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 4 = 0.229 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 5 = 0.365 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 6 = 0.26 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 7 = 0.246 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 8 = 0.131 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 class 9 = 0.361 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 all KL = 0.33 +- 0.307 (in-sample avg dev_std = 0.342)
NEC for r=1.0 all L1 = 0.233 +- 0.238 (in-sample avg dev_std = 0.342)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.119
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.135
NEC for r=0.3 class 0 = 0.568 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 1 = 0.519 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 2 = 0.567 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 3 = 0.592 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 4 = 0.53 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 5 = 0.504 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 6 = 0.506 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 7 = 0.519 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 8 = 0.424 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 class 9 = 0.53 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all KL = 0.668 +- 0.305 (in-sample avg dev_std = 0.493)
NEC for r=0.3 all L1 = 0.526 +- 0.258 (in-sample avg dev_std = 0.493)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.126
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.121
NEC for r=0.6 class 0 = 0.698 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 1 = 0.71 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 2 = 0.682 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 3 = 0.644 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 4 = 0.726 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 5 = 0.619 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 6 = 0.563 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 7 = 0.595 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 8 = 0.624 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 class 9 = 0.654 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 all KL = 0.801 +- 0.270 (in-sample avg dev_std = 0.417)
NEC for r=0.6 all L1 = 0.653 +- 0.230 (in-sample avg dev_std = 0.417)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.231
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.282
NEC for r=0.9 class 0 = 0.745 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 1 = 0.465 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 2 = 0.711 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 3 = 0.727 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 4 = 0.75 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 5 = 0.724 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 6 = 0.743 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 7 = 0.674 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 8 = 0.758 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 class 9 = 0.753 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all KL = 0.86 +- 0.206 (in-sample avg dev_std = 0.393)
NEC for r=0.9 all L1 = 0.702 +- 0.182 (in-sample avg dev_std = 0.393)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.311
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.389
NEC for r=1.0 class 0 = 0.726 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 1 = 0.385 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 2 = 0.577 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 3 = 0.666 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 4 = 0.697 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 5 = 0.599 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 6 = 0.675 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 7 = 0.549 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 8 = 0.662 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 class 9 = 0.634 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all KL = 0.711 +- 0.293 (in-sample avg dev_std = 0.354)
NEC for r=1.0 all L1 = 0.614 +- 0.239 (in-sample avg dev_std = 0.354)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 23:27:32 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 11:27:33 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 196...
[0m[1;37mINFO[0m: [1mCheckpoint 196: 
-----------------------------------
Train ACCURACY: 0.9730
Train Loss: 0.0837
ID Validation ACCURACY: 0.8894
ID Validation Loss: 0.3769
ID Test ACCURACY: 0.8864
ID Test Loss: 0.3922
OOD Validation ACCURACY: 0.6770
OOD Validation Loss: 1.7135
OOD Test ACCURACY: 0.2230
OOD Test Loss: 8.2497

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 143...
[0m[1;37mINFO[0m: [1mCheckpoint 143: 
-----------------------------------
Train ACCURACY: 0.9545
Train Loss: 0.1347
ID Validation ACCURACY: 0.8867
ID Validation Loss: 0.3741
ID Test ACCURACY: 0.8890
ID Test Loss: 0.3766
OOD Validation ACCURACY: 0.7774
OOD Validation Loss: 0.7987
OOD Test ACCURACY: 0.3824
OOD Test Loss: 2.9937

[0m[1;37mINFO[0m: [1mChartInfo 0.8864 0.2230 0.8890 0.3824 0.8867 0.7774[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.108
SUFF++ for r=0.3 class 0 = 0.369 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 1 = 0.292 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 2 = 0.538 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 3 = 0.544 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 4 = 0.432 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 5 = 0.491 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 6 = 0.463 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 7 = 0.462 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 8 = 0.49 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 class 9 = 0.438 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all KL = 0.263 +- 0.241 (in-sample avg dev_std = 0.563)
SUFF++ for r=0.3 all L1 = 0.45 +- 0.196 (in-sample avg dev_std = 0.563)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.162
SUFF++ for r=0.6 class 0 = 0.257 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 1 = 0.41 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 2 = 0.33 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 3 = 0.355 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 4 = 0.327 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 5 = 0.294 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 6 = 0.335 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 7 = 0.405 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 8 = 0.328 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 class 9 = 0.389 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all KL = 0.174 +- 0.195 (in-sample avg dev_std = 0.531)
SUFF++ for r=0.6 all L1 = 0.345 +- 0.150 (in-sample avg dev_std = 0.531)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.744
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.386
SUFF++ for r=0.9 class 0 = 0.235 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 1 = 0.37 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 2 = 0.299 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 3 = 0.247 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 4 = 0.605 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 5 = 0.251 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 6 = 0.296 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 7 = 0.455 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 8 = 0.312 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 class 9 = 0.434 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 all KL = 0.146 +- 0.223 (in-sample avg dev_std = 0.628)
SUFF++ for r=0.9 all L1 = 0.351 +- 0.179 (in-sample avg dev_std = 0.628)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.424 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 1 = 0.245 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 2 = 0.404 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 3 = 0.373 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 4 = 0.325 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 5 = 0.35 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 6 = 0.337 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 7 = 0.349 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 8 = 0.342 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 class 9 = 0.342 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all KL = 0.16 +- 0.226 (in-sample avg dev_std = 0.610)
SUFF++ for r=0.3 all L1 = 0.349 +- 0.180 (in-sample avg dev_std = 0.610)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.094
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.101
SUFF++ for r=0.6 class 0 = 0.242 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 1 = 0.265 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 2 = 0.258 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 3 = 0.234 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 4 = 0.237 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 5 = 0.235 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 6 = 0.201 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 7 = 0.231 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 8 = 0.215 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 class 9 = 0.219 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all KL = 0.03 +- 0.080 (in-sample avg dev_std = 0.543)
SUFF++ for r=0.6 all L1 = 0.234 +- 0.100 (in-sample avg dev_std = 0.543)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.121
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.129
SUFF++ for r=0.9 class 0 = 0.216 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 1 = 0.278 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 2 = 0.259 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 3 = 0.225 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 4 = 0.231 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 5 = 0.233 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 6 = 0.209 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 7 = 0.245 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 8 = 0.216 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 class 9 = 0.223 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 all KL = 0.019 +- 0.064 (in-sample avg dev_std = 0.565)
SUFF++ for r=0.9 all L1 = 0.234 +- 0.103 (in-sample avg dev_std = 0.565)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.112
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.116
NEC for r=0.3 class 0 = 0.627 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 1 = 0.679 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 2 = 0.415 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 3 = 0.358 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 4 = 0.507 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 5 = 0.433 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 6 = 0.503 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 7 = 0.473 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 8 = 0.441 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 class 9 = 0.488 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all KL = 0.636 +- 0.319 (in-sample avg dev_std = 0.485)
NEC for r=0.3 all L1 = 0.494 +- 0.249 (in-sample avg dev_std = 0.485)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.19
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.176
NEC for r=0.6 class 0 = 0.705 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 1 = 0.581 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 2 = 0.603 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 3 = 0.539 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 4 = 0.612 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 5 = 0.606 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 6 = 0.597 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 7 = 0.565 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 8 = 0.586 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 class 9 = 0.526 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 all KL = 0.711 +- 0.254 (in-sample avg dev_std = 0.504)
NEC for r=0.6 all L1 = 0.591 +- 0.184 (in-sample avg dev_std = 0.504)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.744
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.587
NEC for r=0.9 class 0 = 0.648 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 1 = 0.366 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 2 = 0.526 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 3 = 0.553 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 4 = 0.346 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 5 = 0.619 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 6 = 0.587 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 7 = 0.26 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 8 = 0.408 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 class 9 = 0.403 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 all KL = 0.603 +- 0.307 (in-sample avg dev_std = 0.460)
NEC for r=0.9 all L1 = 0.467 +- 0.250 (in-sample avg dev_std = 0.460)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.939
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.827
NEC for r=1.0 class 0 = 0.21 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 1 = 0.046 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 2 = 0.366 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 3 = 0.333 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 4 = 0.214 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 5 = 0.358 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 6 = 0.359 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 7 = 0.231 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 8 = 0.187 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 class 9 = 0.286 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 all KL = 0.388 +- 0.328 (in-sample avg dev_std = 0.384)
NEC for r=1.0 all L1 = 0.255 +- 0.241 (in-sample avg dev_std = 0.384)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.094
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.604 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 1 = 0.719 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 2 = 0.569 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 3 = 0.591 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 4 = 0.507 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 5 = 0.591 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 6 = 0.555 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 7 = 0.567 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 8 = 0.575 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 class 9 = 0.421 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 all KL = 0.737 +- 0.314 (in-sample avg dev_std = 0.515)
NEC for r=0.3 all L1 = 0.572 +- 0.255 (in-sample avg dev_std = 0.515)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.094
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.097
NEC for r=0.6 class 0 = 0.748 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 1 = 0.611 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 2 = 0.67 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 3 = 0.698 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 4 = 0.653 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 5 = 0.693 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 6 = 0.754 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 7 = 0.675 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 8 = 0.687 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 class 9 = 0.677 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 all KL = 0.863 +- 0.228 (in-sample avg dev_std = 0.441)
NEC for r=0.6 all L1 = 0.685 +- 0.188 (in-sample avg dev_std = 0.441)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.121
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.159
NEC for r=0.9 class 0 = 0.691 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 1 = 0.606 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 2 = 0.609 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 3 = 0.616 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 4 = 0.589 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 5 = 0.654 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 6 = 0.677 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 7 = 0.595 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 8 = 0.692 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 class 9 = 0.63 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all KL = 0.817 +- 0.251 (in-sample avg dev_std = 0.463)
NEC for r=0.9 all L1 = 0.635 +- 0.209 (in-sample avg dev_std = 0.463)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.231
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.303
NEC for r=1.0 class 0 = 0.646 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 1 = 0.523 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 2 = 0.675 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 3 = 0.621 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 4 = 0.726 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 5 = 0.698 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 6 = 0.735 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 7 = 0.709 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 8 = 0.654 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 class 9 = 0.677 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all KL = 0.839 +- 0.254 (in-sample avg dev_std = 0.397)
NEC for r=1.0 all L1 = 0.664 +- 0.233 (in-sample avg dev_std = 0.397)
model_dirname= repr_GSATGIN_5l_meanpool_0.5dp_mitig_backboneNone_mitig_samplingfeatavgedgeattnmean

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat Sep 28 23:43:30 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODCMNIST
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mLoading dataset with permuted nodes
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mDataset: {'train': GOODCMNIST(42000), 'id_val': GOODCMNIST(7000), 'id_test': GOODCMNIST(7000), 'val': GOODCMNIST(7000), 'test': GOODCMNIST(7000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1m Data(x=[75, 3], edge_index=[2, 1309], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1309], node_perm=[75])
[0mData(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mInit GINFeatExtractor
[0mUsing BN in BasicEncoder
mitigation_readout =  None
[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mUsing no mitigation (None)
[0mUsing mitigation_expl_scores: default
[1;34mDEBUG[0m: 09/28/2024 11:43:31 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 194...
[0m[1;37mINFO[0m: [1mCheckpoint 194: 
-----------------------------------
Train ACCURACY: 0.9739
Train Loss: 0.0800
ID Validation ACCURACY: 0.8936
ID Validation Loss: 0.3724
ID Test ACCURACY: 0.8870
ID Test Loss: 0.3904
OOD Validation ACCURACY: 0.8023
OOD Validation Loss: 0.7265
OOD Test ACCURACY: 0.2739
OOD Test Loss: 4.8281

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 97...
[0m[1;37mINFO[0m: [1mCheckpoint 97: 
-----------------------------------
Train ACCURACY: 0.9201
Train Loss: 0.2337
ID Validation ACCURACY: 0.8701
ID Validation Loss: 0.4056
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4148
OOD Validation ACCURACY: 0.8056
OOD Validation Loss: 0.6300
OOD Test ACCURACY: 0.4093
OOD Test Loss: 2.5019

[0m[1;37mINFO[0m: [1mChartInfo 0.8870 0.2739 0.8727 0.4093 0.8701 0.8056[0mGOODCMNIST(7000)
Data example from id_val: Data(x=[75, 3], edge_index=[2, 1496], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1496], node_perm=[75])
Label distribution from id_val: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([704, 788, 715, 765, 668, 583, 676, 769, 678, 654]))
/mnt/cimec-storage6/users/steve.azzolin/sedignn/leci_private_fork/GOOD/utils/config_reader.py:166: UserWarning: Argument channel_weight_decay in the chosen config yaml file are not defined in command arguments, which will lead to incomplete code detection and the lack of argument temporary modification by adding command arguments.
  warnings.warn(f'Argument {key} in the chosen config yaml file are not defined in command arguments, '
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan
GOODCMNIST(7000)
Data example from test: Data(x=[75, 3], edge_index=[2, 1431], y=[1], pos=[75, 2], color=[1], env_id=[1], ori_edge_index=[2, 1431], node_perm=[75])
Label distribution from test: (tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), tensor([716, 781, 751, 697, 673, 616, 676, 705, 705, 680]))
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.096
SUFF++ for r=0.3 class 0 = 0.249 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 1 = 0.308 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 2 = 0.338 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 3 = 0.377 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 4 = 0.34 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 5 = 0.357 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 6 = 0.299 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 7 = 0.328 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 8 = 0.314 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 class 9 = 0.335 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all KL = 0.11 +- 0.149 (in-sample avg dev_std = 0.603)
SUFF++ for r=0.3 all L1 = 0.324 +- 0.129 (in-sample avg dev_std = 0.603)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.128
SUFF++ for r=0.6 class 0 = 0.279 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 1 = 0.326 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 2 = 0.294 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 3 = 0.298 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 4 = 0.346 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 5 = 0.286 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 6 = 0.291 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 7 = 0.327 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 8 = 0.281 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 class 9 = 0.333 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 all KL = 0.09 +- 0.125 (in-sample avg dev_std = 0.641)
SUFF++ for r=0.6 all L1 = 0.306 +- 0.102 (in-sample avg dev_std = 0.641)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.355
SUFF++ for r=0.9 class 0 = 0.241 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 1 = 0.266 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 2 = 0.274 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 3 = 0.27 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 4 = 0.755 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 5 = 0.272 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 6 = 0.271 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 7 = 0.385 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 8 = 0.314 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 class 9 = 0.308 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 all KL = 0.138 +- 0.262 (in-sample avg dev_std = 0.669)
SUFF++ for r=0.9 all L1 = 0.334 +- 0.197 (in-sample avg dev_std = 0.669)


ratio=1.0



Zero intervened samples, skipping weight=1.0



--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.099
SUFF++ for r=0.3 class 0 = 0.323 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 1 = 0.278 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 2 = 0.334 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 3 = 0.328 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 4 = 0.297 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 5 = 0.345 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 6 = 0.297 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 7 = 0.311 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 8 = 0.339 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 class 9 = 0.293 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 all KL = 0.12 +- 0.156 (in-sample avg dev_std = 0.583)
SUFF++ for r=0.3 all L1 = 0.314 +- 0.125 (in-sample avg dev_std = 0.583)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.1
SUFF++ for r=0.6 class 0 = 0.302 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 1 = 0.226 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 2 = 0.277 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 3 = 0.283 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 4 = 0.262 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 5 = 0.295 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 6 = 0.259 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 7 = 0.276 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 8 = 0.345 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 class 9 = 0.25 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all KL = 0.097 +- 0.152 (in-sample avg dev_std = 0.509)
SUFF++ for r=0.6 all L1 = 0.277 +- 0.131 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.2
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.165
SUFF++ for r=0.9 class 0 = 0.295 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 1 = 0.232 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 2 = 0.243 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 3 = 0.257 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 4 = 0.236 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 5 = 0.262 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 6 = 0.257 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 7 = 0.261 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 8 = 0.262 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 class 9 = 0.269 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 all KL = 0.091 +- 0.145 (in-sample avg dev_std = 0.448)
SUFF++ for r=0.9 all L1 = 0.257 +- 0.130 (in-sample avg dev_std = 0.448)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over id_val across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.106
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.095
NEC for r=0.3 class 0 = 0.633 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 1 = 0.564 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 2 = 0.621 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 3 = 0.545 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 4 = 0.592 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 5 = 0.566 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 6 = 0.612 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 7 = 0.582 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 8 = 0.611 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 class 9 = 0.566 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 all KL = 0.741 +- 0.258 (in-sample avg dev_std = 0.536)
NEC for r=0.3 all L1 = 0.589 +- 0.200 (in-sample avg dev_std = 0.536)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.162
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.147
NEC for r=0.6 class 0 = 0.687 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 1 = 0.642 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 2 = 0.544 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 3 = 0.566 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 4 = 0.358 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 5 = 0.524 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 6 = 0.608 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 7 = 0.545 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 8 = 0.622 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 class 9 = 0.458 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all KL = 0.666 +- 0.298 (in-sample avg dev_std = 0.484)
NEC for r=0.6 all L1 = 0.558 +- 0.227 (in-sample avg dev_std = 0.484)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.74
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.591
NEC for r=0.9 class 0 = 0.618 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 1 = 0.46 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 2 = 0.581 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 3 = 0.451 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 4 = 0.256 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 5 = 0.64 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 6 = 0.593 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 7 = 0.264 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 8 = 0.351 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 class 9 = 0.512 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all KL = 0.61 +- 0.314 (in-sample avg dev_std = 0.468)
NEC for r=0.9 all L1 = 0.468 +- 0.253 (in-sample avg dev_std = 0.468)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.939
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.858
NEC for r=1.0 class 0 = 0.1 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 1 = 0.051 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 2 = 0.354 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 3 = 0.235 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 4 = 0.215 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 5 = 0.307 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 6 = 0.249 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 7 = 0.221 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 8 = 0.19 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 class 9 = 0.276 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 all KL = 0.32 +- 0.309 (in-sample avg dev_std = 0.352)
NEC for r=1.0 all L1 = 0.216 +- 0.234 (in-sample avg dev_std = 0.352)



--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=True)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.096
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.300 +- 0.000
Model Accuracy over intervened graphs for r=0.3 =  0.102
NEC for r=0.3 class 0 = 0.644 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 1 = 0.714 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 2 = 0.616 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 3 = 0.625 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 4 = 0.631 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 5 = 0.583 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 6 = 0.598 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 7 = 0.605 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 8 = 0.568 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 9 = 0.613 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all KL = 0.772 +- 0.271 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all L1 = 0.621 +- 0.223 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.134
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.600 +- 0.000
Model Accuracy over intervened graphs for r=0.6 =  0.112
NEC for r=0.6 class 0 = 0.667 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 1 = 0.731 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 2 = 0.691 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 3 = 0.667 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 4 = 0.71 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 5 = 0.666 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 6 = 0.713 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 7 = 0.674 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 8 = 0.623 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 class 9 = 0.732 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all KL = 0.853 +- 0.215 (in-sample avg dev_std = 0.488)
NEC for r=0.6 all L1 = 0.688 +- 0.187 (in-sample avg dev_std = 0.488)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.2
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.900 +- 0.000
Model Accuracy over intervened graphs for r=0.9 =  0.215
NEC for r=0.9 class 0 = 0.633 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 1 = 0.607 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 2 = 0.666 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 3 = 0.655 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 4 = 0.712 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 5 = 0.699 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 6 = 0.686 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 7 = 0.687 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 8 = 0.738 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 class 9 = 0.694 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all KL = 0.84 +- 0.225 (in-sample avg dev_std = 0.441)
NEC for r=0.9 all L1 = 0.676 +- 0.203 (in-sample avg dev_std = 0.441)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.265
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.341
NEC for r=1.0 class 0 = 0.631 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 1 = 0.442 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 2 = 0.665 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 3 = 0.676 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 4 = 0.682 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 5 = 0.637 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 6 = 0.644 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 7 = 0.568 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 8 = 0.692 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 class 9 = 0.637 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 all KL = 0.737 +- 0.297 (in-sample avg dev_std = 0.358)
NEC for r=1.0 all L1 = 0.625 +- 0.244 (in-sample avg dev_std = 0.358)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split id_val
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.491, 0.32, 0.135, 1.0], 'all_L1': [0.574, 0.439, 0.344, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.417, 0.393, 0.145, 1.0], 'all_L1': [0.511, 0.486, 0.33, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.172, 0.183, 0.16, 1.0], 'all_L1': [0.332, 0.323, 0.371, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.263, 0.174, 0.146, 1.0], 'all_L1': [0.45, 0.345, 0.351, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.11, 0.09, 0.138, 1.0], 'all_L1': [0.324, 0.306, 0.334, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.572, 0.615, 0.571, 0.346], 'all_L1': [0.452, 0.527, 0.444, 0.237]}), defaultdict(<class 'list'>, {'all_KL': [0.551, 0.617, 0.644, 0.357], 'all_L1': [0.465, 0.514, 0.512, 0.242]}), defaultdict(<class 'list'>, {'all_KL': [0.696, 0.708, 0.54, 0.33], 'all_L1': [0.576, 0.595, 0.426, 0.233]}), defaultdict(<class 'list'>, {'all_KL': [0.636, 0.711, 0.603, 0.388], 'all_L1': [0.494, 0.591, 0.467, 0.255]}), defaultdict(<class 'list'>, {'all_KL': [0.741, 0.666, 0.61, 0.32], 'all_L1': [0.589, 0.558, 0.468, 0.216]})]

Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.511, 0.253, 0.079, 1.0], 'all_L1': [0.638, 0.368, 0.268, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.37, 0.243, 0.064, 1.0], 'all_L1': [0.572, 0.402, 0.237, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.111, 0.134, 0.083, 1.0], 'all_L1': [0.303, 0.3, 0.254, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.16, 0.03, 0.019, 1.0], 'all_L1': [0.349, 0.234, 0.234, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.12, 0.097, 0.091, 1.0], 'all_L1': [0.314, 0.277, 0.257, 1.0], 0: [1.0], 1: [1.0], 2: [1.0], 3: [1.0], 4: [1.0], 5: [1.0], 6: [1.0], 7: [1.0], 8: [1.0], 9: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.531, 0.75, 0.821, 0.735], 'all_L1': [0.391, 0.627, 0.679, 0.633]}), defaultdict(<class 'list'>, {'all_KL': [0.505, 0.731, 0.868, 0.777], 'all_L1': [0.379, 0.578, 0.7, 0.639]}), defaultdict(<class 'list'>, {'all_KL': [0.668, 0.801, 0.86, 0.711], 'all_L1': [0.526, 0.653, 0.702, 0.614]}), defaultdict(<class 'list'>, {'all_KL': [0.737, 0.863, 0.817, 0.839], 'all_L1': [0.572, 0.685, 0.635, 0.664]}), defaultdict(<class 'list'>, {'all_KL': [0.772, 0.853, 0.84, 0.737], 'all_L1': [0.621, 0.688, 0.676, 0.625]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split id_val
suff++ class all_L1  =  0.438 +- 0.098, 0.380 +- 0.070, 0.346 +- 0.015, 1.000 +- 0.000
suff++ class all_KL  =  0.291 +- 0.144, 0.232 +- 0.109, 0.145 +- 0.009, 1.000 +- 0.000
suff++_acc_int  =  0.112 +- 0.013, 0.151 +- 0.017, 0.373 +- 0.026
nec class all_L1  =  0.515 +- 0.057, 0.557 +- 0.033, 0.463 +- 0.029, 0.237 +- 0.013
nec class all_KL  =  0.639 +- 0.072, 0.663 +- 0.042, 0.594 +- 0.035, 0.348 +- 0.024
nec_acc_int  =  0.123 +- 0.027, 0.181 +- 0.031, 0.595 +- 0.041, 0.843 +- 0.010

Eval split test
suff++ class all_L1  =  0.435 +- 0.141, 0.316 +- 0.061, 0.250 +- 0.013, 1.000 +- 0.000
suff++ class all_KL  =  0.254 +- 0.159, 0.151 +- 0.086, 0.067 +- 0.026, 1.000 +- 0.000
suff++_acc_int  =  0.103 +- 0.006, 0.106 +- 0.008, 0.174 +- 0.026
nec class all_L1  =  0.498 +- 0.097, 0.646 +- 0.041, 0.678 +- 0.024, 0.635 +- 0.017
nec class all_KL  =  0.643 +- 0.107, 0.800 +- 0.053, 0.841 +- 0.020, 0.760 +- 0.045
nec_acc_int  =  0.110 +- 0.014, 0.118 +- 0.014, 0.232 +- 0.042, 0.354 +- 0.029


 -------------------------------------------------- 
Computing faithfulness

Eval split id_val
Faith. Aritm (L1)= 		  =  0.477 +- 0.022, 0.468 +- 0.023, 0.405 +- 0.009, 0.618 +- 0.006
Faith. Armon (L1)= 		  =  0.461 +- 0.035, 0.446 +- 0.038, 0.395 +- 0.006, 0.382 +- 0.017
Faith. GMean (L1)= 	  =  0.468 +- 0.028, 0.457 +- 0.031, 0.400 +- 0.007, 0.486 +- 0.013
Faith. Aritm (KL)= 		  =  0.465 +- 0.039, 0.448 +- 0.041, 0.369 +- 0.016, 0.674 +- 0.012
Faith. Armon (KL)= 		  =  0.369 +- 0.124, 0.326 +- 0.113, 0.232 +- 0.010, 0.516 +- 0.026
Faith. GMean (KL)= 	  =  0.410 +- 0.088, 0.379 +- 0.085, 0.293 +- 0.009, 0.590 +- 0.020

Eval split test
Faith. Aritm (L1)= 		  =  0.466 +- 0.032, 0.481 +- 0.013, 0.464 +- 0.015, 0.817 +- 0.008
Faith. Armon (L1)= 		  =  0.435 +- 0.034, 0.419 +- 0.046, 0.365 +- 0.015, 0.777 +- 0.012
Faith. GMean (L1)= 	  =  0.451 +- 0.033, 0.448 +- 0.030, 0.412 +- 0.015, 0.797 +- 0.010
Faith. Aritm (KL)= 		  =  0.449 +- 0.042, 0.475 +- 0.019, 0.454 +- 0.019, 0.880 +- 0.022
Faith. Armon (KL)= 		  =  0.322 +- 0.130, 0.241 +- 0.120, 0.123 +- 0.045, 0.863 +- 0.028
Faith. GMean (KL)= 	  =  0.375 +- 0.091, 0.327 +- 0.100, 0.232 +- 0.055, 0.871 +- 0.025
Computed for split load_split = id



Completed in  1:20:06.815215  for GSATGIN GOODCMNIST/color



DONE GSAT GOODCMNIST/color
