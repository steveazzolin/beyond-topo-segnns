Time to compute metrics!
The PID of this script is: 2377100

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:17:50 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:50 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:50 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:17:51 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 103...
[0m[1;37mINFO[0m: [1mCheckpoint 103: 
-----------------------------------
Train ACCURACY: 0.8598
Train Loss: 0.5235
ID Validation ACCURACY: 0.8683
ID Validation Loss: 0.5030
ID Test ACCURACY: 0.8607
ID Test Loss: 0.5282
OOD Validation ACCURACY: 0.8537
OOD Validation Loss: 0.6475
OOD Test ACCURACY: 0.5690
OOD Test Loss: 1.2550

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 163...
[0m[1;37mINFO[0m: [1mCheckpoint 163: 
-----------------------------------
Train ACCURACY: 0.8449
Train Loss: 0.5037
ID Validation ACCURACY: 0.8490
ID Validation Loss: 0.4950
ID Test ACCURACY: 0.8447
ID Test Loss: 0.5158
OOD Validation ACCURACY: 0.8813
OOD Validation Loss: 0.5724
OOD Test ACCURACY: 0.8553
OOD Test Loss: 0.5144

[0m[1;37mINFO[0m: [1mChartInfo 0.8607 0.5690 0.8447 0.8553 0.8490 0.8813[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.016
WIoU for r=0.3 = 0.009
F1 for r=0.6 = 0.219
WIoU for r=0.6 = 0.148
F1 for r=0.9 = 0.349
WIoU for r=0.9 = 0.225
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.239


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.216
Model XAI F1 of binarized graphs for r=0.3 =  0.01627375
Model XAI WIoU of binarized graphs for r=0.3 =  0.009088750000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.316
SUFF++ for r=0.3 class 0 = 0.458 +- 0.235 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 class 1 = 0.539 +- 0.235 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 class 2 = 0.441 +- 0.235 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 all KL = 0.453 +- 0.235 (in-sample avg dev_std = 0.613)
SUFF++ for r=0.3 all L1 = 0.48 +- 0.142 (in-sample avg dev_std = 0.613)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  0.21949374999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.147865
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.434
SUFF++ for r=0.6 class 0 = 0.619 +- 0.209 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 class 1 = 0.648 +- 0.209 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 class 2 = 0.77 +- 0.209 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 all KL = 0.678 +- 0.209 (in-sample avg dev_std = 0.357)
SUFF++ for r=0.6 all L1 = 0.679 +- 0.194 (in-sample avg dev_std = 0.357)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.571
Model XAI F1 of binarized graphs for r=0.9 =  0.34881500000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.22492499999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.503
SUFF++ for r=0.9 class 0 = 0.74 +- 0.179 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 1 = 0.644 +- 0.179 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 class 2 = 0.823 +- 0.179 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all KL = 0.811 +- 0.179 (in-sample avg dev_std = 0.366)
SUFF++ for r=0.9 all L1 = 0.735 +- 0.182 (in-sample avg dev_std = 0.366)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.216
Model XAI F1 of binarized graphs for r=0.3 =  0.01627375
Model XAI WIoU of binarized graphs for r=0.3 =  0.009088750000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.289
NEC for r=0.3 class 0 = 0.581 +- 0.237 (in-sample avg dev_std = 0.540)
NEC for r=0.3 class 1 = 0.504 +- 0.237 (in-sample avg dev_std = 0.540)
NEC for r=0.3 class 2 = 0.548 +- 0.237 (in-sample avg dev_std = 0.540)
NEC for r=0.3 all KL = 0.552 +- 0.237 (in-sample avg dev_std = 0.540)
NEC for r=0.3 all L1 = 0.544 +- 0.154 (in-sample avg dev_std = 0.540)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.543
Model XAI F1 of binarized graphs for r=0.6 =  0.21949374999999996
Model XAI WIoU of binarized graphs for r=0.6 =  0.147865
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.481
NEC for r=0.6 class 0 = 0.482 +- 0.267 (in-sample avg dev_std = 0.655)
NEC for r=0.6 class 1 = 0.504 +- 0.267 (in-sample avg dev_std = 0.655)
NEC for r=0.6 class 2 = 0.472 +- 0.267 (in-sample avg dev_std = 0.655)
NEC for r=0.6 all KL = 0.573 +- 0.267 (in-sample avg dev_std = 0.655)
NEC for r=0.6 all L1 = 0.486 +- 0.135 (in-sample avg dev_std = 0.655)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.571
Model XAI F1 of binarized graphs for r=0.9 =  0.34881500000000004
Model XAI WIoU of binarized graphs for r=0.9 =  0.22492499999999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.488
NEC for r=0.9 class 0 = 0.398 +- 0.233 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 1 = 0.434 +- 0.233 (in-sample avg dev_std = 0.487)
NEC for r=0.9 class 2 = 0.378 +- 0.233 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all KL = 0.359 +- 0.233 (in-sample avg dev_std = 0.487)
NEC for r=0.9 all L1 = 0.404 +- 0.119 (in-sample avg dev_std = 0.487)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.576
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.238505
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.488
NEC for r=1.0 class 0 = 0.378 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 1 = 0.416 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 class 2 = 0.322 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all KL = 0.351 +- 0.226 (in-sample avg dev_std = 0.456)
NEC for r=1.0 all L1 = 0.372 +- 0.137 (in-sample avg dev_std = 0.456)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:19:01 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:19:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9087
Train Loss: 0.4218
ID Validation ACCURACY: 0.9113
ID Validation Loss: 0.4062
ID Test ACCURACY: 0.9043
ID Test Loss: 0.4406
OOD Validation ACCURACY: 0.9257
OOD Validation Loss: 0.4153
OOD Test ACCURACY: 0.9043
OOD Test Loss: 0.4070

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 107...
[0m[1;37mINFO[0m: [1mCheckpoint 107: 
-----------------------------------
Train ACCURACY: 0.8882
Train Loss: 0.4551
ID Validation ACCURACY: 0.8927
ID Validation Loss: 0.4382
ID Test ACCURACY: 0.8887
ID Test Loss: 0.4541
OOD Validation ACCURACY: 0.9283
OOD Validation Loss: 0.4551
OOD Test ACCURACY: 0.9143
OOD Test Loss: 0.3807

[0m[1;37mINFO[0m: [1mChartInfo 0.9043 0.9043 0.8887 0.9143 0.8927 0.9283[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.717
WIoU for r=0.3 = 0.807
F1 for r=0.6 = 0.561
WIoU for r=0.6 = 0.889
F1 for r=0.9 = 0.421
WIoU for r=0.9 = 0.865
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.865


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  0.71686375
Model XAI WIoU of binarized graphs for r=0.3 =  0.807185
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.568
SUFF++ for r=0.3 class 0 = 0.638 +- 0.287 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 1 = 0.603 +- 0.287 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 2 = 0.525 +- 0.287 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all KL = 0.588 +- 0.287 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all L1 = 0.588 +- 0.210 (in-sample avg dev_std = 0.541)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.56102125
Model XAI WIoU of binarized graphs for r=0.6 =  0.88852875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.73
SUFF++ for r=0.6 class 0 = 0.749 +- 0.364 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 class 1 = 0.64 +- 0.364 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 class 2 = 0.634 +- 0.364 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 all KL = 0.623 +- 0.364 (in-sample avg dev_std = 0.544)
SUFF++ for r=0.6 all L1 = 0.673 +- 0.230 (in-sample avg dev_std = 0.544)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.42074
Model XAI WIoU of binarized graphs for r=0.9 =  0.86543125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.807
SUFF++ for r=0.9 class 0 = 0.779 +- 0.315 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 1 = 0.817 +- 0.315 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 class 2 = 0.919 +- 0.315 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all KL = 0.826 +- 0.315 (in-sample avg dev_std = 0.305)
SUFF++ for r=0.9 all L1 = 0.839 +- 0.234 (in-sample avg dev_std = 0.305)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.639
Model XAI F1 of binarized graphs for r=0.3 =  0.71686375
Model XAI WIoU of binarized graphs for r=0.3 =  0.807185
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.377
NEC for r=0.3 class 0 = 0.55 +- 0.236 (in-sample avg dev_std = 0.571)
NEC for r=0.3 class 1 = 0.528 +- 0.236 (in-sample avg dev_std = 0.571)
NEC for r=0.3 class 2 = 0.646 +- 0.236 (in-sample avg dev_std = 0.571)
NEC for r=0.3 all KL = 0.586 +- 0.236 (in-sample avg dev_std = 0.571)
NEC for r=0.3 all L1 = 0.574 +- 0.122 (in-sample avg dev_std = 0.571)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.902
Model XAI F1 of binarized graphs for r=0.6 =  0.56102125
Model XAI WIoU of binarized graphs for r=0.6 =  0.88852875
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.506
NEC for r=0.6 class 0 = 0.479 +- 0.341 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 1 = 0.518 +- 0.341 (in-sample avg dev_std = 0.513)
NEC for r=0.6 class 2 = 0.483 +- 0.341 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all KL = 0.539 +- 0.341 (in-sample avg dev_std = 0.513)
NEC for r=0.6 all L1 = 0.494 +- 0.229 (in-sample avg dev_std = 0.513)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.902
Model XAI F1 of binarized graphs for r=0.9 =  0.42074
Model XAI WIoU of binarized graphs for r=0.9 =  0.86543125
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.523
NEC for r=0.9 class 0 = 0.464 +- 0.355 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 1 = 0.483 +- 0.355 (in-sample avg dev_std = 0.540)
NEC for r=0.9 class 2 = 0.496 +- 0.355 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all KL = 0.535 +- 0.355 (in-sample avg dev_std = 0.540)
NEC for r=0.9 all L1 = 0.481 +- 0.232 (in-sample avg dev_std = 0.540)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.905
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.86543125
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.627
NEC for r=1.0 class 0 = 0.422 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 class 1 = 0.399 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 class 2 = 0.413 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 all KL = 0.469 +- 0.315 (in-sample avg dev_std = 0.602)
NEC for r=1.0 all L1 = 0.411 +- 0.188 (in-sample avg dev_std = 0.602)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:20:07 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:20:07 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 111...
[0m[1;37mINFO[0m: [1mCheckpoint 111: 
-----------------------------------
Train ACCURACY: 0.8349
Train Loss: 0.5629
ID Validation ACCURACY: 0.8427
ID Validation Loss: 0.5385
ID Test ACCURACY: 0.8290
ID Test Loss: 0.5847
OOD Validation ACCURACY: 0.7613
OOD Validation Loss: 0.7380
OOD Test ACCURACY: 0.7983
OOD Test Loss: 0.5704

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 147...
[0m[1;37mINFO[0m: [1mCheckpoint 147: 
-----------------------------------
Train ACCURACY: 0.8374
Train Loss: 0.5193
ID Validation ACCURACY: 0.8337
ID Validation Loss: 0.5058
ID Test ACCURACY: 0.8260
ID Test Loss: 0.5460
OOD Validation ACCURACY: 0.8300
OOD Validation Loss: 0.6757
OOD Test ACCURACY: 0.8513
OOD Test Loss: 0.4627

[0m[1;37mINFO[0m: [1mChartInfo 0.8290 0.7983 0.8260 0.8513 0.8337 0.8300[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.647
WIoU for r=0.3 = 0.839
F1 for r=0.6 = 0.468
WIoU for r=0.6 = 0.898
F1 for r=0.9 = 0.376
WIoU for r=0.9 = 0.898
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.898


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  0.64666125
Model XAI WIoU of binarized graphs for r=0.3 =  0.8391187500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.547
SUFF++ for r=0.3 class 0 = 0.534 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 1 = 0.787 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 class 2 = 0.621 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all KL = 0.626 +- 0.275 (in-sample avg dev_std = 0.541)
SUFF++ for r=0.3 all L1 = 0.65 +- 0.167 (in-sample avg dev_std = 0.541)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.46787000000000006
Model XAI WIoU of binarized graphs for r=0.6 =  0.8983012499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.725
SUFF++ for r=0.6 class 0 = 0.592 +- 0.165 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 1 = 0.821 +- 0.165 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 class 2 = 0.815 +- 0.165 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all KL = 0.828 +- 0.165 (in-sample avg dev_std = 0.351)
SUFF++ for r=0.6 all L1 = 0.745 +- 0.169 (in-sample avg dev_std = 0.351)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.78
Model XAI F1 of binarized graphs for r=0.9 =  0.37558875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8983012499999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.802
SUFF++ for r=0.9 class 0 = 0.645 +- 0.141 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 1 = 0.909 +- 0.141 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 class 2 = 0.884 +- 0.141 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all KL = 0.897 +- 0.141 (in-sample avg dev_std = 0.235)
SUFF++ for r=0.9 all L1 = 0.815 +- 0.172 (in-sample avg dev_std = 0.235)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.618
Model XAI F1 of binarized graphs for r=0.3 =  0.64666125
Model XAI WIoU of binarized graphs for r=0.3 =  0.8391187500000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.341
NEC for r=0.3 class 0 = 0.47 +- 0.339 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 1 = 0.55 +- 0.339 (in-sample avg dev_std = 0.476)
NEC for r=0.3 class 2 = 0.529 +- 0.339 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all KL = 0.529 +- 0.339 (in-sample avg dev_std = 0.476)
NEC for r=0.3 all L1 = 0.517 +- 0.196 (in-sample avg dev_std = 0.476)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.766
Model XAI F1 of binarized graphs for r=0.6 =  0.46787000000000006
Model XAI WIoU of binarized graphs for r=0.6 =  0.8983012499999999
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.531
NEC for r=0.6 class 0 = 0.345 +- 0.322 (in-sample avg dev_std = 0.506)
NEC for r=0.6 class 1 = 0.363 +- 0.322 (in-sample avg dev_std = 0.506)
NEC for r=0.6 class 2 = 0.505 +- 0.322 (in-sample avg dev_std = 0.506)
NEC for r=0.6 all KL = 0.385 +- 0.322 (in-sample avg dev_std = 0.506)
NEC for r=0.6 all L1 = 0.404 +- 0.219 (in-sample avg dev_std = 0.506)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.78
Model XAI F1 of binarized graphs for r=0.9 =  0.37558875
Model XAI WIoU of binarized graphs for r=0.9 =  0.8983012499999999
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.619
NEC for r=0.9 class 0 = 0.314 +- 0.290 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 1 = 0.33 +- 0.290 (in-sample avg dev_std = 0.509)
NEC for r=0.9 class 2 = 0.442 +- 0.290 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all KL = 0.336 +- 0.290 (in-sample avg dev_std = 0.509)
NEC for r=0.9 all L1 = 0.362 +- 0.195 (in-sample avg dev_std = 0.509)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.789
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.8983012499999999
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.618
NEC for r=1.0 class 0 = 0.312 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 class 1 = 0.339 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 class 2 = 0.424 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 all KL = 0.316 +- 0.273 (in-sample avg dev_std = 0.496)
NEC for r=1.0 all L1 = 0.358 +- 0.185 (in-sample avg dev_std = 0.496)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:21:12 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:21:12 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 0.8396
Train Loss: 0.5054
ID Validation ACCURACY: 0.8567
ID Validation Loss: 0.4677
ID Test ACCURACY: 0.8283
ID Test Loss: 0.5320
OOD Validation ACCURACY: 0.7540
OOD Validation Loss: 0.7147
OOD Test ACCURACY: 0.8567
OOD Test Loss: 0.4681

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 142...
[0m[1;37mINFO[0m: [1mCheckpoint 142: 
-----------------------------------
Train ACCURACY: 0.8396
Train Loss: 0.5054
ID Validation ACCURACY: 0.8567
ID Validation Loss: 0.4677
ID Test ACCURACY: 0.8283
ID Test Loss: 0.5320
OOD Validation ACCURACY: 0.7540
OOD Validation Loss: 0.7147
OOD Test ACCURACY: 0.8567
OOD Test Loss: 0.4681

[0m[1;37mINFO[0m: [1mChartInfo 0.8283 0.8567 0.8283 0.8567 0.8567 0.7540[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.744
WIoU for r=0.3 = 0.890
F1 for r=0.6 = 0.532
WIoU for r=0.6 = 0.955
F1 for r=0.9 = 0.405
WIoU for r=0.9 = 0.955
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.955


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  0.74393
Model XAI WIoU of binarized graphs for r=0.3 =  0.8901175000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.572
SUFF++ for r=0.3 class 0 = 0.615 +- 0.376 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 1 = 0.759 +- 0.376 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 class 2 = 0.622 +- 0.376 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all KL = 0.477 +- 0.376 (in-sample avg dev_std = 0.576)
SUFF++ for r=0.3 all L1 = 0.666 +- 0.186 (in-sample avg dev_std = 0.576)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.53246875
Model XAI WIoU of binarized graphs for r=0.6 =  0.955095
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.799
SUFF++ for r=0.6 class 0 = 0.737 +- 0.219 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 1 = 0.856 +- 0.219 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 class 2 = 0.8 +- 0.219 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all KL = 0.814 +- 0.219 (in-sample avg dev_std = 0.399)
SUFF++ for r=0.6 all L1 = 0.799 +- 0.160 (in-sample avg dev_std = 0.399)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.869
Model XAI F1 of binarized graphs for r=0.9 =  0.40503625
Model XAI WIoU of binarized graphs for r=0.9 =  0.955095
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.83
SUFF++ for r=0.9 class 0 = 0.857 +- 0.096 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 1 = 0.9 +- 0.096 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 class 2 = 0.915 +- 0.096 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all KL = 0.937 +- 0.096 (in-sample avg dev_std = 0.214)
SUFF++ for r=0.9 all L1 = 0.891 +- 0.136 (in-sample avg dev_std = 0.214)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.589
Model XAI F1 of binarized graphs for r=0.3 =  0.74393
Model XAI WIoU of binarized graphs for r=0.3 =  0.8901175000000001
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.434
NEC for r=0.3 class 0 = 0.463 +- 0.336 (in-sample avg dev_std = 0.619)
NEC for r=0.3 class 1 = 0.477 +- 0.336 (in-sample avg dev_std = 0.619)
NEC for r=0.3 class 2 = 0.459 +- 0.336 (in-sample avg dev_std = 0.619)
NEC for r=0.3 all KL = 0.65 +- 0.336 (in-sample avg dev_std = 0.619)
NEC for r=0.3 all L1 = 0.466 +- 0.197 (in-sample avg dev_std = 0.619)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.869
Model XAI F1 of binarized graphs for r=0.6 =  0.53246875
Model XAI WIoU of binarized graphs for r=0.6 =  0.955095
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.547
NEC for r=0.6 class 0 = 0.476 +- 0.366 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 1 = 0.306 +- 0.366 (in-sample avg dev_std = 0.509)
NEC for r=0.6 class 2 = 0.502 +- 0.366 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all KL = 0.472 +- 0.366 (in-sample avg dev_std = 0.509)
NEC for r=0.6 all L1 = 0.426 +- 0.259 (in-sample avg dev_std = 0.509)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.869
Model XAI F1 of binarized graphs for r=0.9 =  0.40503625
Model XAI WIoU of binarized graphs for r=0.9 =  0.955095
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.606
NEC for r=0.9 class 0 = 0.44 +- 0.334 (in-sample avg dev_std = 0.548)
NEC for r=0.9 class 1 = 0.276 +- 0.334 (in-sample avg dev_std = 0.548)
NEC for r=0.9 class 2 = 0.445 +- 0.334 (in-sample avg dev_std = 0.548)
NEC for r=0.9 all KL = 0.432 +- 0.334 (in-sample avg dev_std = 0.548)
NEC for r=0.9 all L1 = 0.385 +- 0.221 (in-sample avg dev_std = 0.548)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.873
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.955095
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.626
NEC for r=1.0 class 0 = 0.431 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 class 1 = 0.282 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 class 2 = 0.426 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 all KL = 0.42 +- 0.334 (in-sample avg dev_std = 0.547)
NEC for r=1.0 all L1 = 0.378 +- 0.217 (in-sample avg dev_std = 0.547)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:22:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODMotif2
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mDataset: {'train': GOODMotif2(18000), 'id_val': GOODMotif2(3000), 'id_test': GOODMotif2(3000), 'val': GOODMotif2(3000), 'test': GOODMotif2(3000), 'task': 'Multi-label classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1m Data(edge_index=[2, 84], x=[29, 1], node_gt=[29], edge_gt=[84], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[0mData(edge_index=[2, 86], x=[29, 1], node_gt=[29], edge_gt=[86], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=29)
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:22:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 183...
[0m[1;37mINFO[0m: [1mCheckpoint 183: 
-----------------------------------
Train ACCURACY: 0.8734
Train Loss: 0.4599
ID Validation ACCURACY: 0.8810
ID Validation Loss: 0.4475
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4786
OOD Validation ACCURACY: 0.8663
OOD Validation Loss: 0.5284
OOD Test ACCURACY: 0.8430
OOD Test Loss: 0.5743

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 187...
[0m[1;37mINFO[0m: [1mCheckpoint 187: 
-----------------------------------
Train ACCURACY: 0.8522
Train Loss: 0.4709
ID Validation ACCURACY: 0.8573
ID Validation Loss: 0.4632
ID Test ACCURACY: 0.8450
ID Test Loss: 0.4949
OOD Validation ACCURACY: 0.9020
OOD Validation Loss: 0.5173
OOD Test ACCURACY: 0.8550
OOD Test Loss: 0.5385

[0m[1;37mINFO[0m: [1mChartInfo 0.8727 0.8430 0.8450 0.8550 0.8573 0.9020[0mGOODMotif2(3000)
Data example from test: Data(edge_index=[2, 70], x=[20, 1], node_gt=[20], edge_gt=[70], basis_id=[1], motif_id=[1], y=[1], env_id=[1], num_nodes=20)
Label distribution from test: (tensor([0, 1, 2]), tensor([ 971, 1026, 1003]))

Gold ratio (test) =  tensor(0.2515) +- tensor(0.1001)
F1 for r=0.3 = 0.196
WIoU for r=0.3 = 0.136
F1 for r=0.6 = 0.280
WIoU for r=0.6 = 0.249
F1 for r=0.9 = 0.371
WIoU for r=0.9 = 0.359
F1 for r=1.0 = 0.392
WIoU for r=1.0 = 0.387


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.365
Model XAI F1 of binarized graphs for r=0.3 =  0.19555
Model XAI WIoU of binarized graphs for r=0.3 =  0.13609125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.283
SUFF++ for r=0.3 class 0 = 0.45 +- 0.260 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 1 = 0.47 +- 0.260 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 class 2 = 0.472 +- 0.260 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all KL = 0.467 +- 0.260 (in-sample avg dev_std = 0.515)
SUFF++ for r=0.3 all L1 = 0.464 +- 0.147 (in-sample avg dev_std = 0.515)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  0.2797825
Model XAI WIoU of binarized graphs for r=0.6 =  0.2487025
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.456
SUFF++ for r=0.6 class 0 = 0.65 +- 0.246 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 1 = 0.616 +- 0.246 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 class 2 = 0.683 +- 0.246 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all KL = 0.659 +- 0.246 (in-sample avg dev_std = 0.435)
SUFF++ for r=0.6 all L1 = 0.65 +- 0.193 (in-sample avg dev_std = 0.435)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.37101875000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.3590625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.611
SUFF++ for r=0.9 class 0 = 0.623 +- 0.246 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 1 = 0.608 +- 0.246 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 class 2 = 0.739 +- 0.246 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all KL = 0.704 +- 0.246 (in-sample avg dev_std = 0.385)
SUFF++ for r=0.9 all L1 = 0.657 +- 0.189 (in-sample avg dev_std = 0.385)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.365
Model XAI F1 of binarized graphs for r=0.3 =  0.19555
Model XAI WIoU of binarized graphs for r=0.3 =  0.13609125
len(reference) = 800
Effective ratio: 0.306 +- 0.006
Model Accuracy over intervened graphs for r=0.3 =  0.392
NEC for r=0.3 class 0 = 0.613 +- 0.250 (in-sample avg dev_std = 0.552)
NEC for r=0.3 class 1 = 0.552 +- 0.250 (in-sample avg dev_std = 0.552)
NEC for r=0.3 class 2 = 0.601 +- 0.250 (in-sample avg dev_std = 0.552)
NEC for r=0.3 all KL = 0.586 +- 0.250 (in-sample avg dev_std = 0.552)
NEC for r=0.3 all L1 = 0.588 +- 0.129 (in-sample avg dev_std = 0.552)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.57
Model XAI F1 of binarized graphs for r=0.6 =  0.2797825
Model XAI WIoU of binarized graphs for r=0.6 =  0.2487025
len(reference) = 800
Effective ratio: 0.608 +- 0.011
Model Accuracy over intervened graphs for r=0.6 =  0.444
NEC for r=0.6 class 0 = 0.472 +- 0.235 (in-sample avg dev_std = 0.558)
NEC for r=0.6 class 1 = 0.519 +- 0.235 (in-sample avg dev_std = 0.558)
NEC for r=0.6 class 2 = 0.443 +- 0.235 (in-sample avg dev_std = 0.558)
NEC for r=0.6 all KL = 0.515 +- 0.235 (in-sample avg dev_std = 0.558)
NEC for r=0.6 all L1 = 0.478 +- 0.146 (in-sample avg dev_std = 0.558)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.73
Model XAI F1 of binarized graphs for r=0.9 =  0.37101875000000006
Model XAI WIoU of binarized graphs for r=0.9 =  0.3590625
len(reference) = 800
Effective ratio: 0.904 +- 0.005
Model Accuracy over intervened graphs for r=0.9 =  0.527
NEC for r=0.9 class 0 = 0.514 +- 0.230 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 1 = 0.505 +- 0.230 (in-sample avg dev_std = 0.439)
NEC for r=0.9 class 2 = 0.424 +- 0.230 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all KL = 0.447 +- 0.230 (in-sample avg dev_std = 0.439)
NEC for r=0.9 all L1 = 0.481 +- 0.135 (in-sample avg dev_std = 0.439)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.849
Model XAI F1 of binarized graphs for r=1.0 =  0.39177750000000006
Model XAI WIoU of binarized graphs for r=1.0 =  0.38667
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.606
NEC for r=1.0 class 0 = 0.527 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 1 = 0.507 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 class 2 = 0.359 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all KL = 0.485 +- 0.224 (in-sample avg dev_std = 0.511)
NEC for r=1.0 all L1 = 0.464 +- 0.159 (in-sample avg dev_std = 0.511)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.453, 0.678, 0.811, 1.0], 'all_L1': [0.48, 0.679, 0.735, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.588, 0.623, 0.826, 1.0], 'all_L1': [0.588, 0.673, 0.839, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.626, 0.828, 0.897, 1.0], 'all_L1': [0.65, 0.745, 0.815, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.477, 0.814, 0.937, 1.0], 'all_L1': [0.666, 0.799, 0.891, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.467, 0.659, 0.704, 1.0], 'all_L1': [0.464, 0.65, 0.657, 1.0], 0: [1.0], 1: [1.0], 2: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.552, 0.573, 0.359, 0.351], 'all_L1': [0.544, 0.486, 0.404, 0.372]}), defaultdict(<class 'list'>, {'all_KL': [0.586, 0.539, 0.535, 0.469], 'all_L1': [0.574, 0.494, 0.481, 0.411]}), defaultdict(<class 'list'>, {'all_KL': [0.529, 0.385, 0.336, 0.316], 'all_L1': [0.517, 0.404, 0.362, 0.358]}), defaultdict(<class 'list'>, {'all_KL': [0.65, 0.472, 0.432, 0.42], 'all_L1': [0.466, 0.426, 0.385, 0.378]}), defaultdict(<class 'list'>, {'all_KL': [0.586, 0.515, 0.447, 0.485], 'all_L1': [0.588, 0.478, 0.481, 0.464]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.570 +- 0.084, 0.709 +- 0.055, 0.787 +- 0.082, 1.000 +- 0.000
suff++ class all_KL  =  0.522 +- 0.071, 0.720 +- 0.084, 0.835 +- 0.080, 1.000 +- 0.000
suff++_acc_int  =  0.457 +- 0.129, 0.629 +- 0.152, 0.711 +- 0.131
nec class all_L1  =  0.538 +- 0.043, 0.458 +- 0.036, 0.423 +- 0.050, 0.397 +- 0.038
nec class all_KL  =  0.581 +- 0.041, 0.497 +- 0.065, 0.422 +- 0.071, 0.408 +- 0.066
nec_acc_int  =  0.367 +- 0.049, 0.502 +- 0.037, 0.553 +- 0.051, 0.593 +- 0.053


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.554 +- 0.029, 0.583 +- 0.016, 0.605 +- 0.037, 0.698 +- 0.019
Faith. Armon (L1)= 		  =  0.547 +- 0.029, 0.553 +- 0.016, 0.545 +- 0.038, 0.567 +- 0.038
Faith. GMean (L1)= 	  =  0.550 +- 0.029, 0.568 +- 0.013, 0.574 +- 0.034, 0.629 +- 0.030
Faith. Aritm (KL)= 		  =  0.551 +- 0.032, 0.609 +- 0.023, 0.628 +- 0.046, 0.704 +- 0.033
Faith. Armon (KL)= 		  =  0.546 +- 0.033, 0.580 +- 0.032, 0.555 +- 0.060, 0.577 +- 0.067
Faith. GMean (KL)= 	  =  0.548 +- 0.032, 0.594 +- 0.023, 0.590 +- 0.051, 0.637 +- 0.052
Computed for split load_split = id



Completed in  0:05:35.625184  for LECIGIN GOODMotif2/basis



DONE LECI GOODMotif2/basis all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:23:42 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/18/2024 02:23:42 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/18/2024 02:24:12 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/18/2024 02:24:21 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/18/2024 02:24:31 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/18/2024 02:24:47 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:25:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.9169
Train Loss: 0.2213
ID Validation ROC-AUC: 0.8917
ID Validation Loss: 0.2544
ID Test ROC-AUC: 0.8970
ID Test Loss: 0.2524
OOD Validation ROC-AUC: 0.6382
OOD Validation Loss: 0.3929
OOD Test ROC-AUC: 0.6940
OOD Test Loss: 0.5070

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 29...
[0m[1;37mINFO[0m: [1mCheckpoint 29: 
-----------------------------------
Train ROC-AUC: 0.8609
Train Loss: 0.2974
ID Validation ROC-AUC: 0.8471
ID Validation Loss: 0.3106
ID Test ROC-AUC: 0.8565
ID Test Loss: 0.3081
OOD Validation ROC-AUC: 0.6770
OOD Validation Loss: 0.3063
OOD Test ROC-AUC: 0.6903
OOD Test Loss: 0.5439

[0m[1;37mINFO[0m: [1mChartInfo 0.8970 0.6940 0.8565 0.6903 0.8471 0.6770[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/18/2024 02:25:03 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.621
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.589
SUFF++ for r=0.3 class 0.0 = 0.748 +- 0.141 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 class 1.0 = 0.811 +- 0.141 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 all KL = 0.877 +- 0.141 (in-sample avg dev_std = 0.295)
SUFF++ for r=0.3 all L1 = 0.801 +- 0.162 (in-sample avg dev_std = 0.295)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.626
SUFF++ for r=0.6 class 0.0 = 0.836 +- 0.087 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 class 1.0 = 0.88 +- 0.087 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 all KL = 0.945 +- 0.087 (in-sample avg dev_std = 0.154)
SUFF++ for r=0.6 all L1 = 0.872 +- 0.138 (in-sample avg dev_std = 0.154)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.676
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.678
SUFF++ for r=0.9 class 0.0 = 0.929 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 class 1.0 = 0.956 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all KL = 0.986 +- 0.035 (in-sample avg dev_std = 0.105)
SUFF++ for r=0.9 all L1 = 0.951 +- 0.070 (in-sample avg dev_std = 0.105)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.613
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.626
NEC for r=0.3 class 0.0 = 0.181 +- 0.108 (in-sample avg dev_std = 0.190)
NEC for r=0.3 class 1.0 = 0.14 +- 0.108 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all KL = 0.068 +- 0.108 (in-sample avg dev_std = 0.190)
NEC for r=0.3 all L1 = 0.147 +- 0.134 (in-sample avg dev_std = 0.190)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.63
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.63
NEC for r=0.6 class 0.0 = 0.165 +- 0.093 (in-sample avg dev_std = 0.177)
NEC for r=0.6 class 1.0 = 0.111 +- 0.093 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all KL = 0.055 +- 0.093 (in-sample avg dev_std = 0.177)
NEC for r=0.6 all L1 = 0.12 +- 0.129 (in-sample avg dev_std = 0.177)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.676
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.661
NEC for r=0.9 class 0.0 = 0.163 +- 0.080 (in-sample avg dev_std = 0.154)
NEC for r=0.9 class 1.0 = 0.108 +- 0.080 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all KL = 0.051 +- 0.080 (in-sample avg dev_std = 0.154)
NEC for r=0.9 all L1 = 0.117 +- 0.131 (in-sample avg dev_std = 0.154)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.705
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.667
NEC for r=1.0 class 0.0 = 0.193 +- 0.091 (in-sample avg dev_std = 0.149)
NEC for r=1.0 class 1.0 = 0.108 +- 0.091 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all KL = 0.054 +- 0.091 (in-sample avg dev_std = 0.149)
NEC for r=1.0 all L1 = 0.122 +- 0.139 (in-sample avg dev_std = 0.149)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:26:17 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/18/2024 02:26:17 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/18/2024 02:26:46 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/18/2024 02:26:56 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:06 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:21 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 184...
[0m[1;37mINFO[0m: [1mCheckpoint 184: 
-----------------------------------
Train ROC-AUC: 0.9177
Train Loss: 0.2213
ID Validation ROC-AUC: 0.8918
ID Validation Loss: 0.2573
ID Test ROC-AUC: 0.8984
ID Test Loss: 0.2518
OOD Validation ROC-AUC: 0.6468
OOD Validation Loss: 0.3762
OOD Test ROC-AUC: 0.6919
OOD Test Loss: 0.5107

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 74...
[0m[1;37mINFO[0m: [1mCheckpoint 74: 
-----------------------------------
Train ROC-AUC: 0.8920
Train Loss: 0.2449
ID Validation ROC-AUC: 0.8753
ID Validation Loss: 0.2636
ID Test ROC-AUC: 0.8793
ID Test Loss: 0.2613
OOD Validation ROC-AUC: 0.6705
OOD Validation Loss: 0.3458
OOD Test ROC-AUC: 0.7046
OOD Test Loss: 0.4816

[0m[1;37mINFO[0m: [1mChartInfo 0.8984 0.6919 0.8793 0.7046 0.8753 0.6705[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/18/2024 02:27:36 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.601
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 783
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.579
SUFF++ for r=0.3 class 0.0 = 0.788 +- 0.121 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 class 1.0 = 0.826 +- 0.121 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all KL = 0.9 +- 0.121 (in-sample avg dev_std = 0.255)
SUFF++ for r=0.3 all L1 = 0.82 +- 0.157 (in-sample avg dev_std = 0.255)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
SUFF++ for r=0.6 class 0.0 = 0.822 +- 0.084 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 class 1.0 = 0.893 +- 0.084 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 all KL = 0.95 +- 0.084 (in-sample avg dev_std = 0.142)
SUFF++ for r=0.6 all L1 = 0.881 +- 0.136 (in-sample avg dev_std = 0.142)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.663
SUFF++ for r=0.9 class 0.0 = 0.933 +- 0.035 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 class 1.0 = 0.96 +- 0.035 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 all KL = 0.987 +- 0.035 (in-sample avg dev_std = 0.101)
SUFF++ for r=0.9 all L1 = 0.956 +- 0.064 (in-sample avg dev_std = 0.101)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.602
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.606
NEC for r=0.3 class 0.0 = 0.171 +- 0.096 (in-sample avg dev_std = 0.185)
NEC for r=0.3 class 1.0 = 0.137 +- 0.096 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all KL = 0.064 +- 0.096 (in-sample avg dev_std = 0.185)
NEC for r=0.3 all L1 = 0.143 +- 0.142 (in-sample avg dev_std = 0.185)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.658
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.639
NEC for r=0.6 class 0.0 = 0.173 +- 0.096 (in-sample avg dev_std = 0.181)
NEC for r=0.6 class 1.0 = 0.105 +- 0.096 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all KL = 0.057 +- 0.096 (in-sample avg dev_std = 0.181)
NEC for r=0.6 all L1 = 0.116 +- 0.132 (in-sample avg dev_std = 0.181)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.668
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.65
NEC for r=0.9 class 0.0 = 0.187 +- 0.098 (in-sample avg dev_std = 0.160)
NEC for r=0.9 class 1.0 = 0.102 +- 0.098 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all KL = 0.058 +- 0.098 (in-sample avg dev_std = 0.160)
NEC for r=0.9 all L1 = 0.116 +- 0.138 (in-sample avg dev_std = 0.160)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.675
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.659
NEC for r=1.0 class 0.0 = 0.19 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=1.0 class 1.0 = 0.116 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all KL = 0.063 +- 0.102 (in-sample avg dev_std = 0.159)
NEC for r=1.0 all L1 = 0.128 +- 0.145 (in-sample avg dev_std = 0.159)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:28:54 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/18/2024 02:28:54 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/18/2024 02:29:24 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/18/2024 02:29:34 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/18/2024 02:29:46 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:01 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 186...
[0m[1;37mINFO[0m: [1mCheckpoint 186: 
-----------------------------------
Train ROC-AUC: 0.9167
Train Loss: 0.2199
ID Validation ROC-AUC: 0.8927
ID Validation Loss: 0.2531
ID Test ROC-AUC: 0.8965
ID Test Loss: 0.2508
OOD Validation ROC-AUC: 0.6401
OOD Validation Loss: 0.3915
OOD Test ROC-AUC: 0.6865
OOD Test Loss: 0.5100

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 36...
[0m[1;37mINFO[0m: [1mCheckpoint 36: 
-----------------------------------
Train ROC-AUC: 0.8702
Train Loss: 0.2826
ID Validation ROC-AUC: 0.8547
ID Validation Loss: 0.2953
ID Test ROC-AUC: 0.8658
ID Test Loss: 0.2920
OOD Validation ROC-AUC: 0.6717
OOD Validation Loss: 0.3020
OOD Test ROC-AUC: 0.6881
OOD Test Loss: 0.5174

[0m[1;37mINFO[0m: [1mChartInfo 0.8965 0.6865 0.8658 0.6881 0.8547 0.6717[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/18/2024 02:30:17 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.583
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 776
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.557
SUFF++ for r=0.3 class 0.0 = 0.774 +- 0.128 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 class 1.0 = 0.832 +- 0.128 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all KL = 0.894 +- 0.128 (in-sample avg dev_std = 0.264)
SUFF++ for r=0.3 all L1 = 0.823 +- 0.157 (in-sample avg dev_std = 0.264)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.623
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.612
SUFF++ for r=0.6 class 0.0 = 0.845 +- 0.079 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 class 1.0 = 0.898 +- 0.079 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all KL = 0.954 +- 0.079 (in-sample avg dev_std = 0.135)
SUFF++ for r=0.6 all L1 = 0.889 +- 0.127 (in-sample avg dev_std = 0.135)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.696
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.685
SUFF++ for r=0.9 class 0.0 = 0.922 +- 0.039 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 class 1.0 = 0.959 +- 0.039 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all KL = 0.985 +- 0.039 (in-sample avg dev_std = 0.104)
SUFF++ for r=0.9 all L1 = 0.953 +- 0.070 (in-sample avg dev_std = 0.104)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.578
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.587
NEC for r=0.3 class 0.0 = 0.165 +- 0.106 (in-sample avg dev_std = 0.191)
NEC for r=0.3 class 1.0 = 0.141 +- 0.106 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all KL = 0.07 +- 0.106 (in-sample avg dev_std = 0.191)
NEC for r=0.3 all L1 = 0.145 +- 0.142 (in-sample avg dev_std = 0.191)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.623
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0.0 = 0.155 +- 0.093 (in-sample avg dev_std = 0.168)
NEC for r=0.6 class 1.0 = 0.105 +- 0.093 (in-sample avg dev_std = 0.168)
NEC for r=0.6 all KL = 0.056 +- 0.093 (in-sample avg dev_std = 0.168)
NEC for r=0.6 all L1 = 0.114 +- 0.129 (in-sample avg dev_std = 0.168)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.696
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.664
NEC for r=0.9 class 0.0 = 0.199 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=0.9 class 1.0 = 0.109 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all KL = 0.066 +- 0.112 (in-sample avg dev_std = 0.162)
NEC for r=0.9 all L1 = 0.124 +- 0.147 (in-sample avg dev_std = 0.162)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.706
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.674
NEC for r=1.0 class 0.0 = 0.207 +- 0.117 (in-sample avg dev_std = 0.173)
NEC for r=1.0 class 1.0 = 0.121 +- 0.117 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all KL = 0.073 +- 0.117 (in-sample avg dev_std = 0.173)
NEC for r=1.0 all L1 = 0.135 +- 0.156 (in-sample avg dev_std = 0.173)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:31:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/18/2024 02:31:38 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/18/2024 02:32:08 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/18/2024 02:32:19 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/18/2024 02:32:29 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/18/2024 02:32:45 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:00 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:33:01 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 197...
[0m[1;37mINFO[0m: [1mCheckpoint 197: 
-----------------------------------
Train ROC-AUC: 0.9170
Train Loss: 0.2226
ID Validation ROC-AUC: 0.8917
ID Validation Loss: 0.2557
ID Test ROC-AUC: 0.8960
ID Test Loss: 0.2545
OOD Validation ROC-AUC: 0.6425
OOD Validation Loss: 0.4071
OOD Test ROC-AUC: 0.6986
OOD Test Loss: 0.5143

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 34...
[0m[1;37mINFO[0m: [1mCheckpoint 34: 
-----------------------------------
Train ROC-AUC: 0.8702
Train Loss: 0.2691
ID Validation ROC-AUC: 0.8562
ID Validation Loss: 0.2805
ID Test ROC-AUC: 0.8672
ID Test Loss: 0.2773
OOD Validation ROC-AUC: 0.6673
OOD Validation Loss: 0.3080
OOD Test ROC-AUC: 0.6889
OOD Test Loss: 0.4959

[0m[1;37mINFO[0m: [1mChartInfo 0.8960 0.6986 0.8672 0.6889 0.8562 0.6673[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/18/2024 02:33:01 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.598
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 781
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.581
SUFF++ for r=0.3 class 0.0 = 0.784 +- 0.120 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 class 1.0 = 0.839 +- 0.120 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all KL = 0.903 +- 0.120 (in-sample avg dev_std = 0.248)
SUFF++ for r=0.3 all L1 = 0.83 +- 0.149 (in-sample avg dev_std = 0.248)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.628
SUFF++ for r=0.6 class 0.0 = 0.839 +- 0.084 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.6 class 1.0 = 0.9 +- 0.084 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.6 all KL = 0.953 +- 0.084 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.6 all L1 = 0.89 +- 0.129 (in-sample avg dev_std = 0.128)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.681
SUFF++ for r=0.9 class 0.0 = 0.919 +- 0.044 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 class 1.0 = 0.955 +- 0.044 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all KL = 0.983 +- 0.044 (in-sample avg dev_std = 0.122)
SUFF++ for r=0.9 all L1 = 0.949 +- 0.074 (in-sample avg dev_std = 0.122)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.595
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.596
NEC for r=0.3 class 0.0 = 0.155 +- 0.116 (in-sample avg dev_std = 0.198)
NEC for r=0.3 class 1.0 = 0.142 +- 0.116 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all KL = 0.073 +- 0.116 (in-sample avg dev_std = 0.198)
NEC for r=0.3 all L1 = 0.144 +- 0.139 (in-sample avg dev_std = 0.198)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.636
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.625
NEC for r=0.6 class 0.0 = 0.159 +- 0.100 (in-sample avg dev_std = 0.183)
NEC for r=0.6 class 1.0 = 0.106 +- 0.100 (in-sample avg dev_std = 0.183)
NEC for r=0.6 all KL = 0.06 +- 0.100 (in-sample avg dev_std = 0.183)
NEC for r=0.6 all L1 = 0.115 +- 0.131 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.681
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.653
NEC for r=0.9 class 0.0 = 0.192 +- 0.116 (in-sample avg dev_std = 0.191)
NEC for r=0.9 class 1.0 = 0.118 +- 0.116 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all KL = 0.072 +- 0.116 (in-sample avg dev_std = 0.191)
NEC for r=0.9 all L1 = 0.13 +- 0.146 (in-sample avg dev_std = 0.191)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.691
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.663
NEC for r=1.0 class 0.0 = 0.218 +- 0.121 (in-sample avg dev_std = 0.194)
NEC for r=1.0 class 1.0 = 0.127 +- 0.121 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all KL = 0.079 +- 0.121 (in-sample avg dev_std = 0.194)
NEC for r=1.0 all L1 = 0.142 +- 0.154 (in-sample avg dev_std = 0.194)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:34:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset LBAPcore
[0m[1;34mDEBUG[0m: 05/18/2024 02:34:23 PM : [1mPermuting node indices to remove explanation bias for train
[0m[1;34mDEBUG[0m: 05/18/2024 02:34:54 PM : [1mPermuting node indices to remove explanation bias for id_val
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:04 PM : [1mPermuting node indices to remove explanation bias for id_test
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:15 PM : [1mPermuting node indices to remove explanation bias for val
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:31 PM : [1mPermuting node indices to remove explanation bias for test
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mDataset: {'train': LBAPcore(34179), 'id_val': LBAPcore(11314), 'id_test': LBAPcore(11683), 'val': LBAPcore(19028), 'test': LBAPcore(19032), 'task': 'Binary classification', 'metric': 'ROC-AUC'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1m Data(x=[31, 39], edge_index=[2, 68], edge_attr=[68, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 68], node_perm=[31])
[0mData(x=[30, 39], edge_index=[2, 66], edge_attr=[66, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 66], node_perm=[30])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0mUsing feature sampling := feat
self.EF = 0.1
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing no mitigation None
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ROC-AUC: 0.9165
Train Loss: 0.2206
ID Validation ROC-AUC: 0.8913
ID Validation Loss: 0.2538
ID Test ROC-AUC: 0.8969
ID Test Loss: 0.2504
OOD Validation ROC-AUC: 0.6290
OOD Validation Loss: 0.3879
OOD Test ROC-AUC: 0.6928
OOD Test Loss: 0.5115

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 34...
[0m[1;37mINFO[0m: [1mCheckpoint 34: 
-----------------------------------
Train ROC-AUC: 0.8628
Train Loss: 0.2911
ID Validation ROC-AUC: 0.8493
ID Validation Loss: 0.3012
ID Test ROC-AUC: 0.8611
ID Test Loss: 0.2996
OOD Validation ROC-AUC: 0.6659
OOD Validation Loss: 0.3055
OOD Test ROC-AUC: 0.6840
OOD Test Loss: 0.5249

[0m[1;37mINFO[0m: [1mChartInfo 0.8969 0.6928 0.8611 0.6840 0.8493 0.6659[0mLBAPcore(19032)
Data example from test: Data(x=[28, 39], edge_index=[2, 64], edge_attr=[64, 10], y=[1, 1], env_id=[1], ori_edge_index=[2, 64], node_perm=[28])
Label distribution from test: (tensor([0., 1.]), tensor([ 3168, 15864]))
[1;34mDEBUG[0m: 05/18/2024 02:35:47 PM : [1mUnbalanced warning for LBAPcore (test)
[0mF1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.604
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 785
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.585
SUFF++ for r=0.3 class 0.0 = 0.795 +- 0.138 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 class 1.0 = 0.841 +- 0.138 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all KL = 0.895 +- 0.138 (in-sample avg dev_std = 0.263)
SUFF++ for r=0.3 all L1 = 0.833 +- 0.157 (in-sample avg dev_std = 0.263)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.617
SUFF++ for r=0.6 class 0.0 = 0.88 +- 0.075 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.6 class 1.0 = 0.925 +- 0.075 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.6 all KL = 0.963 +- 0.075 (in-sample avg dev_std = 0.113)
SUFF++ for r=0.6 all L1 = 0.917 +- 0.117 (in-sample avg dev_std = 0.113)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.679
SUFF++ for r=0.9 class 0.0 = 0.959 +- 0.018 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.9 class 1.0 = 0.981 +- 0.018 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.9 all KL = 0.994 +- 0.018 (in-sample avg dev_std = 0.063)
SUFF++ for r=0.9 all L1 = 0.978 +- 0.042 (in-sample avg dev_std = 0.063)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model ROC-AUC of binarized graphs for r=0.3 =  0.608
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.308 +- 0.006
Model ROC-AUC over intervened graphs for r=0.3 =  0.575
NEC for r=0.3 class 0.0 = 0.174 +- 0.114 (in-sample avg dev_std = 0.188)
NEC for r=0.3 class 1.0 = 0.128 +- 0.114 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all KL = 0.068 +- 0.114 (in-sample avg dev_std = 0.188)
NEC for r=0.3 all L1 = 0.135 +- 0.139 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model ROC-AUC of binarized graphs for r=0.6 =  0.65
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.608 +- 0.006
Model ROC-AUC over intervened graphs for r=0.6 =  0.622
NEC for r=0.6 class 0.0 = 0.142 +- 0.102 (in-sample avg dev_std = 0.164)
NEC for r=0.6 class 1.0 = 0.08 +- 0.102 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all KL = 0.052 +- 0.102 (in-sample avg dev_std = 0.164)
NEC for r=0.6 all L1 = 0.09 +- 0.121 (in-sample avg dev_std = 0.164)


ratio=0.9


Computing with masking

Model ROC-AUC of binarized graphs for r=0.9 =  0.691
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.907 +- 0.005
Model ROC-AUC over intervened graphs for r=0.9 =  0.662
NEC for r=0.9 class 0.0 = 0.112 +- 0.086 (in-sample avg dev_std = 0.125)
NEC for r=0.9 class 1.0 = 0.057 +- 0.086 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all KL = 0.04 +- 0.086 (in-sample avg dev_std = 0.125)
NEC for r=0.9 all L1 = 0.066 +- 0.107 (in-sample avg dev_std = 0.125)


ratio=1.0


Computing with masking

Model ROC-AUC of binarized graphs for r=1.0 =  0.71
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model ROC-AUC over intervened graphs for r=1.0 =  0.681
NEC for r=1.0 class 0.0 = 0.109 +- 0.076 (in-sample avg dev_std = 0.110)
NEC for r=1.0 class 1.0 = 0.054 +- 0.076 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all KL = 0.033 +- 0.076 (in-sample avg dev_std = 0.110)
NEC for r=1.0 all L1 = 0.063 +- 0.102 (in-sample avg dev_std = 0.110)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.877, 0.945, 0.986, 1.0], 'all_L1': [0.801, 0.872, 0.951, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.9, 0.95, 0.987, 1.0], 'all_L1': [0.82, 0.881, 0.956, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.894, 0.954, 0.985, 1.0], 'all_L1': [0.823, 0.889, 0.953, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.903, 0.953, 0.983, 1.0], 'all_L1': [0.83, 0.89, 0.949, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.895, 0.963, 0.994, 1.0], 'all_L1': [0.833, 0.917, 0.978, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.068, 0.055, 0.051, 0.054], 'all_L1': [0.147, 0.12, 0.117, 0.122]}), defaultdict(<class 'list'>, {'all_KL': [0.064, 0.057, 0.058, 0.063], 'all_L1': [0.143, 0.116, 0.116, 0.128]}), defaultdict(<class 'list'>, {'all_KL': [0.07, 0.056, 0.066, 0.073], 'all_L1': [0.145, 0.114, 0.124, 0.135]}), defaultdict(<class 'list'>, {'all_KL': [0.073, 0.06, 0.072, 0.079], 'all_L1': [0.144, 0.115, 0.13, 0.142]}), defaultdict(<class 'list'>, {'all_KL': [0.068, 0.052, 0.04, 0.033], 'all_L1': [0.135, 0.09, 0.066, 0.063]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.821 +- 0.011, 0.890 +- 0.015, 0.957 +- 0.011, 1.000 +- 0.000
suff++ class all_KL  =  0.894 +- 0.009, 0.953 +- 0.006, 0.987 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.578 +- 0.011, 0.625 +- 0.009, 0.677 +- 0.008
nec class all_L1  =  0.143 +- 0.004, 0.111 +- 0.011, 0.111 +- 0.023, 0.118 +- 0.028
nec class all_KL  =  0.069 +- 0.003, 0.056 +- 0.003, 0.057 +- 0.011, 0.060 +- 0.016
nec_acc_int  =  0.598 +- 0.017, 0.628 +- 0.006, 0.658 +- 0.005, 0.669 +- 0.008


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.482 +- 0.004, 0.500 +- 0.003, 0.534 +- 0.006, 0.559 +- 0.014
Faith. Armon (L1)= 		  =  0.243 +- 0.006, 0.197 +- 0.017, 0.197 +- 0.038, 0.210 +- 0.047
Faith. GMean (L1)= 	  =  0.342 +- 0.004, 0.314 +- 0.013, 0.323 +- 0.035, 0.340 +- 0.046
Faith. Aritm (KL)= 		  =  0.481 +- 0.005, 0.504 +- 0.003, 0.522 +- 0.004, 0.530 +- 0.008
Faith. Armon (KL)= 		  =  0.127 +- 0.005, 0.106 +- 0.005, 0.108 +- 0.020, 0.113 +- 0.029
Faith. GMean (KL)= 	  =  0.248 +- 0.006, 0.231 +- 0.005, 0.237 +- 0.023, 0.243 +- 0.035
Computed for split load_split = id



Completed in  0:13:29.073943  for LECIGIN LBAPcore/assay



DONE LECI LBAPcore/assay all mitig

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:37:23 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:37:24 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 178...
[0m[1;37mINFO[0m: [1mCheckpoint 178: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8721
ID Validation Loss: 0.5525
ID Test ACCURACY: 0.8738
ID Test Loss: 0.6177
OOD Validation ACCURACY: 0.8730
OOD Validation Loss: 0.7070
OOD Test ACCURACY: 0.8114
OOD Test Loss: 1.1250

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 182...
[0m[1;37mINFO[0m: [1mCheckpoint 182: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0750
ID Validation ACCURACY: 0.8698
ID Validation Loss: 0.5684
ID Test ACCURACY: 0.8749
ID Test Loss: 0.6247
OOD Validation ACCURACY: 0.8748
OOD Validation Loss: 0.7016
OOD Test ACCURACY: 0.8157
OOD Test Loss: 1.0466

[0m[1;37mINFO[0m: [1mChartInfo 0.8738 0.8114 0.8749 0.8157 0.8698 0.8748[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 1 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.745
SUFF++ for r=0.3 class 0.0 = 0.901 +- 0.101 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 class 1.0 = 0.959 +- 0.101 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 all KL = 0.951 +- 0.101 (in-sample avg dev_std = 0.188)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.106 (in-sample avg dev_std = 0.188)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.78
SUFF++ for r=0.6 class 0.0 = 0.909 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 class 1.0 = 0.962 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all KL = 0.951 +- 0.117 (in-sample avg dev_std = 0.183)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.114 (in-sample avg dev_std = 0.183)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.818
SUFF++ for r=0.9 class 0.0 = 0.962 +- 0.043 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 class 1.0 = 0.985 +- 0.043 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all KL = 0.988 +- 0.043 (in-sample avg dev_std = 0.096)
SUFF++ for r=0.9 all L1 = 0.974 +- 0.066 (in-sample avg dev_std = 0.096)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 1 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.755
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.765
NEC for r=0.3 class 0.0 = 0.114 +- 0.094 (in-sample avg dev_std = 0.106)
NEC for r=0.3 class 1.0 = 0.05 +- 0.094 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all KL = 0.044 +- 0.094 (in-sample avg dev_std = 0.106)
NEC for r=0.3 all L1 = 0.081 +- 0.133 (in-sample avg dev_std = 0.106)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.789
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.793
NEC for r=0.6 class 0.0 = 0.098 +- 0.088 (in-sample avg dev_std = 0.119)
NEC for r=0.6 class 1.0 = 0.042 +- 0.088 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all KL = 0.038 +- 0.088 (in-sample avg dev_std = 0.119)
NEC for r=0.6 all L1 = 0.069 +- 0.123 (in-sample avg dev_std = 0.119)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.826
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.818
NEC for r=0.9 class 0.0 = 0.076 +- 0.100 (in-sample avg dev_std = 0.103)
NEC for r=0.9 class 1.0 = 0.036 +- 0.100 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all KL = 0.033 +- 0.100 (in-sample avg dev_std = 0.103)
NEC for r=0.9 all L1 = 0.055 +- 0.122 (in-sample avg dev_std = 0.103)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.834
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.823
NEC for r=1.0 class 0.0 = 0.072 +- 0.100 (in-sample avg dev_std = 0.116)
NEC for r=1.0 class 1.0 = 0.034 +- 0.100 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all KL = 0.033 +- 0.100 (in-sample avg dev_std = 0.116)
NEC for r=1.0 all L1 = 0.052 +- 0.118 (in-sample avg dev_std = 0.116)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:39:00 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:39:02 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 105...
[0m[1;37mINFO[0m: [1mCheckpoint 105: 
-----------------------------------
Train ACCURACY: 0.9485
Train Loss: 0.0766
ID Validation ACCURACY: 0.8749
ID Validation Loss: 0.5049
ID Test ACCURACY: 0.8668
ID Test Loss: 0.5615
OOD Validation ACCURACY: 0.8653
OOD Validation Loss: 0.6072
OOD Test ACCURACY: 0.7872
OOD Test Loss: 0.9617

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 145...
[0m[1;37mINFO[0m: [1mCheckpoint 145: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0757
ID Validation ACCURACY: 0.8723
ID Validation Loss: 0.5268
ID Test ACCURACY: 0.8719
ID Test Loss: 0.6128
OOD Validation ACCURACY: 0.8778
OOD Validation Loss: 0.6058
OOD Test ACCURACY: 0.8173
OOD Test Loss: 0.8048

[0m[1;37mINFO[0m: [1mChartInfo 0.8668 0.7872 0.8719 0.8173 0.8723 0.8778[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 2 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.724
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.715
SUFF++ for r=0.3 class 0.0 = 0.908 +- 0.089 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.3 class 1.0 = 0.96 +- 0.089 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.3 all KL = 0.961 +- 0.089 (in-sample avg dev_std = 0.159)
SUFF++ for r=0.3 all L1 = 0.935 +- 0.093 (in-sample avg dev_std = 0.159)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.737
SUFF++ for r=0.6 class 0.0 = 0.898 +- 0.084 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 class 1.0 = 0.973 +- 0.084 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all KL = 0.965 +- 0.084 (in-sample avg dev_std = 0.147)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.108 (in-sample avg dev_std = 0.147)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.786
SUFF++ for r=0.9 class 0.0 = 0.951 +- 0.043 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 class 1.0 = 0.986 +- 0.043 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all KL = 0.988 +- 0.043 (in-sample avg dev_std = 0.093)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.066 (in-sample avg dev_std = 0.093)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 2 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.724
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.719
NEC for r=0.3 class 0.0 = 0.122 +- 0.090 (in-sample avg dev_std = 0.113)
NEC for r=0.3 class 1.0 = 0.049 +- 0.090 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all KL = 0.042 +- 0.090 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all L1 = 0.084 +- 0.117 (in-sample avg dev_std = 0.113)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.752
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.739
NEC for r=0.6 class 0.0 = 0.112 +- 0.065 (in-sample avg dev_std = 0.108)
NEC for r=0.6 class 1.0 = 0.035 +- 0.065 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all KL = 0.032 +- 0.065 (in-sample avg dev_std = 0.108)
NEC for r=0.6 all L1 = 0.072 +- 0.107 (in-sample avg dev_std = 0.108)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.795
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.78
NEC for r=0.9 class 0.0 = 0.119 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.9 class 1.0 = 0.041 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all KL = 0.045 +- 0.110 (in-sample avg dev_std = 0.131)
NEC for r=0.9 all L1 = 0.079 +- 0.135 (in-sample avg dev_std = 0.131)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.8
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.789
NEC for r=1.0 class 0.0 = 0.106 +- 0.092 (in-sample avg dev_std = 0.125)
NEC for r=1.0 class 1.0 = 0.037 +- 0.092 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all KL = 0.039 +- 0.092 (in-sample avg dev_std = 0.125)
NEC for r=1.0 all L1 = 0.07 +- 0.125 (in-sample avg dev_std = 0.125)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:40:37 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:40:38 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 155...
[0m[1;37mINFO[0m: [1mCheckpoint 155: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0751
ID Validation ACCURACY: 0.8755
ID Validation Loss: 0.5193
ID Test ACCURACY: 0.8710
ID Test Loss: 0.6143
OOD Validation ACCURACY: 0.8741
OOD Validation Loss: 0.6579
OOD Test ACCURACY: 0.7991
OOD Test Loss: 1.0166

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 144...
[0m[1;37mINFO[0m: [1mCheckpoint 144: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0757
ID Validation ACCURACY: 0.8713
ID Validation Loss: 0.4845
ID Test ACCURACY: 0.8713
ID Test Loss: 0.5534
OOD Validation ACCURACY: 0.8785
OOD Validation Loss: 0.6028
OOD Test ACCURACY: 0.8218
OOD Test Loss: 0.7450

[0m[1;37mINFO[0m: [1mChartInfo 0.8710 0.7991 0.8713 0.8218 0.8713 0.8785[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 3 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.712
SUFF++ for r=0.3 class 0.0 = 0.913 +- 0.102 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 class 1.0 = 0.954 +- 0.102 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all KL = 0.956 +- 0.102 (in-sample avg dev_std = 0.164)
SUFF++ for r=0.3 all L1 = 0.934 +- 0.094 (in-sample avg dev_std = 0.164)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.754
SUFF++ for r=0.6 class 0.0 = 0.905 +- 0.095 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 class 1.0 = 0.967 +- 0.095 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 all KL = 0.961 +- 0.095 (in-sample avg dev_std = 0.161)
SUFF++ for r=0.6 all L1 = 0.937 +- 0.110 (in-sample avg dev_std = 0.161)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.805
SUFF++ for r=0.9 class 0.0 = 0.952 +- 0.067 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 class 1.0 = 0.983 +- 0.067 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all KL = 0.98 +- 0.067 (in-sample avg dev_std = 0.128)
SUFF++ for r=0.9 all L1 = 0.968 +- 0.073 (in-sample avg dev_std = 0.128)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 3 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.714
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.716
NEC for r=0.3 class 0.0 = 0.131 +- 0.124 (in-sample avg dev_std = 0.126)
NEC for r=0.3 class 1.0 = 0.064 +- 0.124 (in-sample avg dev_std = 0.126)
NEC for r=0.3 all KL = 0.06 +- 0.124 (in-sample avg dev_std = 0.126)
NEC for r=0.3 all L1 = 0.096 +- 0.132 (in-sample avg dev_std = 0.126)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.762
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.754
NEC for r=0.6 class 0.0 = 0.122 +- 0.097 (in-sample avg dev_std = 0.127)
NEC for r=0.6 class 1.0 = 0.044 +- 0.097 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all KL = 0.047 +- 0.097 (in-sample avg dev_std = 0.127)
NEC for r=0.6 all L1 = 0.081 +- 0.130 (in-sample avg dev_std = 0.127)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.81
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.799
NEC for r=0.9 class 0.0 = 0.117 +- 0.124 (in-sample avg dev_std = 0.146)
NEC for r=0.9 class 1.0 = 0.039 +- 0.124 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all KL = 0.053 +- 0.124 (in-sample avg dev_std = 0.146)
NEC for r=0.9 all L1 = 0.077 +- 0.138 (in-sample avg dev_std = 0.146)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.814
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.808
NEC for r=1.0 class 0.0 = 0.108 +- 0.120 (in-sample avg dev_std = 0.142)
NEC for r=1.0 class 1.0 = 0.032 +- 0.120 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all KL = 0.047 +- 0.120 (in-sample avg dev_std = 0.142)
NEC for r=1.0 all L1 = 0.069 +- 0.133 (in-sample avg dev_std = 0.142)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:42:13 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:42:14 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0765
ID Validation ACCURACY: 0.8764
ID Validation Loss: 0.4270
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4723
OOD Validation ACCURACY: 0.8786
OOD Validation Loss: 0.5089
OOD Test ACCURACY: 0.8355
OOD Test Loss: 0.5859

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 114...
[0m[1;37mINFO[0m: [1mCheckpoint 114: 
-----------------------------------
Train ACCURACY: 0.9489
Train Loss: 0.0765
ID Validation ACCURACY: 0.8764
ID Validation Loss: 0.4270
ID Test ACCURACY: 0.8727
ID Test Loss: 0.4723
OOD Validation ACCURACY: 0.8786
OOD Validation Loss: 0.5089
OOD Test ACCURACY: 0.8355
OOD Test Loss: 0.5859

[0m[1;37mINFO[0m: [1mChartInfo 0.8727 0.8355 0.8727 0.8355 0.8764 0.8786[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 4 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.748
SUFF++ for r=0.3 class 0.0 = 0.911 +- 0.074 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.3 class 1.0 = 0.951 +- 0.074 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.3 all KL = 0.964 +- 0.074 (in-sample avg dev_std = 0.152)
SUFF++ for r=0.3 all L1 = 0.932 +- 0.086 (in-sample avg dev_std = 0.152)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.808
SUFF++ for r=0.6 class 0.0 = 0.92 +- 0.076 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 class 1.0 = 0.955 +- 0.076 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all KL = 0.968 +- 0.076 (in-sample avg dev_std = 0.141)
SUFF++ for r=0.6 all L1 = 0.938 +- 0.098 (in-sample avg dev_std = 0.141)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.85
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.036 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 class 1.0 = 0.975 +- 0.036 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all KL = 0.989 +- 0.036 (in-sample avg dev_std = 0.083)
SUFF++ for r=0.9 all L1 = 0.969 +- 0.065 (in-sample avg dev_std = 0.083)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 4 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.762
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.757
NEC for r=0.3 class 0.0 = 0.116 +- 0.087 (in-sample avg dev_std = 0.113)
NEC for r=0.3 class 1.0 = 0.066 +- 0.087 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all KL = 0.045 +- 0.087 (in-sample avg dev_std = 0.113)
NEC for r=0.3 all L1 = 0.09 +- 0.114 (in-sample avg dev_std = 0.113)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.821
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.812
NEC for r=0.6 class 0.0 = 0.1 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=0.6 class 1.0 = 0.056 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=0.6 all KL = 0.033 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=0.6 all L1 = 0.078 +- 0.114 (in-sample avg dev_std = 0.100)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.851
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.852
NEC for r=0.9 class 0.0 = 0.084 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 class 1.0 = 0.059 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all KL = 0.037 +- 0.096 (in-sample avg dev_std = 0.106)
NEC for r=0.9 all L1 = 0.071 +- 0.118 (in-sample avg dev_std = 0.106)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.865
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.86
NEC for r=1.0 class 0.0 = 0.072 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=1.0 class 1.0 = 0.049 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all KL = 0.029 +- 0.069 (in-sample avg dev_std = 0.100)
NEC for r=1.0 all L1 = 0.06 +- 0.106 (in-sample avg dev_std = 0.100)

[1;37mINFO[0m: [1m-----------------------------------
    Task: test
Sat May 18 14:43:48 2024
[0m[1;37mINFO[0m: [1mLoad Dataset GOODSST2
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mDataset: {'train': GOODSST2(24744), 'id_val': GOODSST2(5301), 'id_test': GOODSST2(5301), 'val': GOODSST2(17206), 'test': GOODSST2(17490), 'task': 'Binary classification', 'metric': 'Accuracy'}
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1m Data(x=[6, 768], edge_index=[2, 10], y=[1, 1], idx=[1], sentence_tokens=[6], length=[1], domain_id=[1], env_id=[1])
[0mData(x=[3, 768], edge_index=[2, 4], y=[1, 1], idx=[1], sentence_tokens=[3], length=[1], domain_id=[1], env_id=[1])
[1;37mINFO[0m: [1mLoading model...
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0mUsing feature sampling := feat
self.EF = 0.01
mitigation_readout =  None
[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mInit GINFeatExtractor
[0mmitigation_readout =  weighted
[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing the fixed _explain_ functionality
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mUsing no mitigation (None)
[0m[1;34mDEBUG[0m: 05/18/2024 02:43:49 PM : [1mConfig model and output the best checkpoint info...
[0m[1;37mINFO[0m: [1mLoading best In-Domain Checkpoint 106...
[0m[1;37mINFO[0m: [1mCheckpoint 106: 
-----------------------------------
Train ACCURACY: 0.9487
Train Loss: 0.0764
ID Validation ACCURACY: 0.8762
ID Validation Loss: 0.4746
ID Test ACCURACY: 0.8687
ID Test Loss: 0.5282
OOD Validation ACCURACY: 0.8716
OOD Validation Loss: 0.5888
OOD Test ACCURACY: 0.8079
OOD Test Loss: 0.8214

[0m[1;37mINFO[0m: [1mLoading best Out-of-Domain Checkpoint 128...
[0m[1;37mINFO[0m: [1mCheckpoint 128: 
-----------------------------------
Train ACCURACY: 0.9488
Train Loss: 0.0760
ID Validation ACCURACY: 0.8732
ID Validation Loss: 0.4817
ID Test ACCURACY: 0.8685
ID Test Loss: 0.5451
OOD Validation ACCURACY: 0.8787
OOD Validation Loss: 0.5826
OOD Test ACCURACY: 0.8277
OOD Test Loss: 0.6909

[0m[1;37mINFO[0m: [1mChartInfo 0.8687 0.8079 0.8685 0.8277 0.8732 0.8787[0mGOODSST2(17490)
Data example from test: Data(x=[15, 768], edge_index=[2, 28], y=[1, 1], idx=[1], sentence_tokens=[15], length=[1], domain_id=[1])
Label distribution from test: (tensor([0., 1.]), tensor([8463, 9027]))
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. The data of the dataset is already cached, so any modifications to `data` will not be reflected when accessing its elements. Clearing the cache now by removing all elements in `dataset._data_list`. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
/mnt/cimec-storage6/users/steve.azzolin/venv/leci/lib/python3.8/site-packages/torch_geometric/data/in_memory_dataset.py:284: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.
  warnings.warn(msg)
F1 for r=0.3 = nan
WIoU for r=0.3 = nan
F1 for r=0.6 = nan
WIoU for r=0.6 = nan
F1 for r=0.9 = nan
WIoU for r=0.9 = nan
F1 for r=1.0 = nan
WIoU for r=1.0 = nan


Evaluating SUFF++ for seed 5 with load_split id




--------------------------------------------------


#D#Computing SUFF++ over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.741
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.731
SUFF++ for r=0.3 class 0.0 = 0.908 +- 0.084 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 class 1.0 = 0.953 +- 0.084 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 all KL = 0.961 +- 0.084 (in-sample avg dev_std = 0.160)
SUFF++ for r=0.3 all L1 = 0.931 +- 0.094 (in-sample avg dev_std = 0.160)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.765
SUFF++ for r=0.6 class 0.0 = 0.91 +- 0.077 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 class 1.0 = 0.961 +- 0.077 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all KL = 0.967 +- 0.077 (in-sample avg dev_std = 0.139)
SUFF++ for r=0.6 all L1 = 0.936 +- 0.101 (in-sample avg dev_std = 0.139)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.826
SUFF++ for r=0.9 class 0.0 = 0.963 +- 0.030 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 class 1.0 = 0.979 +- 0.030 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all KL = 0.99 +- 0.030 (in-sample avg dev_std = 0.079)
SUFF++ for r=0.9 all L1 = 0.971 +- 0.058 (in-sample avg dev_std = 0.079)


ratio=1.0



Zero intervened samples, skipping weight=1.0


Evaluating NEC for seed 5 with load_split id




--------------------------------------------------


#D#Computing NEC over test across ratios (random_expl=False)


ratio=0.3


Computing with masking

Model Accuracy of binarized graphs for r=0.3 =  0.741
Model XAI F1 of binarized graphs for r=0.3 =  nan
Model XAI WIoU of binarized graphs for r=0.3 =  nan
len(reference) = 800
Effective ratio: 0.311 +- 0.008
Model Accuracy over intervened graphs for r=0.3 =  0.739
NEC for r=0.3 class 0.0 = 0.118 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=0.3 class 1.0 = 0.059 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all KL = 0.041 +- 0.089 (in-sample avg dev_std = 0.105)
NEC for r=0.3 all L1 = 0.087 +- 0.116 (in-sample avg dev_std = 0.105)


ratio=0.6


Computing with masking

Model Accuracy of binarized graphs for r=0.6 =  0.77
Model XAI F1 of binarized graphs for r=0.6 =  nan
Model XAI WIoU of binarized graphs for r=0.6 =  nan
len(reference) = 800
Effective ratio: 0.610 +- 0.008
Model Accuracy over intervened graphs for r=0.6 =  0.769
NEC for r=0.6 class 0.0 = 0.101 +- 0.075 (in-sample avg dev_std = 0.112)
NEC for r=0.6 class 1.0 = 0.049 +- 0.075 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all KL = 0.034 +- 0.075 (in-sample avg dev_std = 0.112)
NEC for r=0.6 all L1 = 0.074 +- 0.111 (in-sample avg dev_std = 0.112)


ratio=0.9


Computing with masking

Model Accuracy of binarized graphs for r=0.9 =  0.831
Model XAI F1 of binarized graphs for r=0.9 =  nan
Model XAI WIoU of binarized graphs for r=0.9 =  nan
len(reference) = 800
Effective ratio: 0.910 +- 0.008
Model Accuracy over intervened graphs for r=0.9 =  0.816
NEC for r=0.9 class 0.0 = 0.098 +- 0.094 (in-sample avg dev_std = 0.119)
NEC for r=0.9 class 1.0 = 0.05 +- 0.094 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all KL = 0.039 +- 0.094 (in-sample avg dev_std = 0.119)
NEC for r=0.9 all L1 = 0.073 +- 0.118 (in-sample avg dev_std = 0.119)


ratio=1.0


Computing with masking

Model Accuracy of binarized graphs for r=1.0 =  0.834
Model XAI F1 of binarized graphs for r=1.0 =  nan
Model XAI WIoU of binarized graphs for r=1.0 =  nan
len(reference) = 800
Effective ratio: 1.000 +- 0.000
Model Accuracy over intervened graphs for r=1.0 =  0.826
NEC for r=1.0 class 0.0 = 0.088 +- 0.082 (in-sample avg dev_std = 0.109)
NEC for r=1.0 class 1.0 = 0.042 +- 0.082 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all KL = 0.034 +- 0.082 (in-sample avg dev_std = 0.109)
NEC for r=1.0 all L1 = 0.065 +- 0.111 (in-sample avg dev_std = 0.109)


 -------------------------------------------------- 
Printing evaluation results for load_split id



Eval split test
suff++ = [defaultdict(<class 'list'>, {'all_KL': [0.951, 0.951, 0.988, 1.0], 'all_L1': [0.931, 0.936, 0.974, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.961, 0.965, 0.988, 1.0], 'all_L1': [0.935, 0.936, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.956, 0.961, 0.98, 1.0], 'all_L1': [0.934, 0.937, 0.968, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.964, 0.968, 0.989, 1.0], 'all_L1': [0.932, 0.938, 0.969, 1.0], 0.0: [1.0], 1.0: [1.0]}), defaultdict(<class 'list'>, {'all_KL': [0.961, 0.967, 0.99, 1.0], 'all_L1': [0.931, 0.936, 0.971, 1.0], 0.0: [1.0], 1.0: [1.0]})]
nec = [defaultdict(<class 'list'>, {'all_KL': [0.044, 0.038, 0.033, 0.033], 'all_L1': [0.081, 0.069, 0.055, 0.052]}), defaultdict(<class 'list'>, {'all_KL': [0.042, 0.032, 0.045, 0.039], 'all_L1': [0.084, 0.072, 0.079, 0.07]}), defaultdict(<class 'list'>, {'all_KL': [0.06, 0.047, 0.053, 0.047], 'all_L1': [0.096, 0.081, 0.077, 0.069]}), defaultdict(<class 'list'>, {'all_KL': [0.045, 0.033, 0.037, 0.029], 'all_L1': [0.09, 0.078, 0.071, 0.06]}), defaultdict(<class 'list'>, {'all_KL': [0.041, 0.034, 0.039, 0.034], 'all_L1': [0.087, 0.074, 0.073, 0.065]})]


 -------------------------------------------------- 
Printing evaluation averaged per seed

Eval split test
suff++ class all_L1  =  0.933 +- 0.002, 0.937 +- 0.001, 0.970 +- 0.002, 1.000 +- 0.000
suff++ class all_KL  =  0.959 +- 0.005, 0.962 +- 0.006, 0.987 +- 0.004, 1.000 +- 0.000
suff++_acc_int  =  0.730 +- 0.015, 0.769 +- 0.024, 0.817 +- 0.022
nec class all_L1  =  0.088 +- 0.005, 0.075 +- 0.004, 0.071 +- 0.008, 0.063 +- 0.007
nec class all_KL  =  0.046 +- 0.007, 0.037 +- 0.005, 0.041 +- 0.007, 0.036 +- 0.006
nec_acc_int  =  0.739 +- 0.019, 0.773 +- 0.026, 0.813 +- 0.024, 0.821 +- 0.024


 -------------------------------------------------- 
Computing faithfulness

Eval split test
Faith. Aritm (L1)= 		  =  0.510 +- 0.003, 0.506 +- 0.002, 0.521 +- 0.003, 0.532 +- 0.003
Faith. Armon (L1)= 		  =  0.160 +- 0.009, 0.139 +- 0.007, 0.132 +- 0.015, 0.119 +- 0.012
Faith. GMean (L1)= 	  =  0.286 +- 0.008, 0.265 +- 0.008, 0.262 +- 0.016, 0.251 +- 0.013
Faith. Aritm (KL)= 		  =  0.502 +- 0.004, 0.500 +- 0.003, 0.514 +- 0.002, 0.518 +- 0.003
Faith. Armon (KL)= 		  =  0.088 +- 0.013, 0.071 +- 0.010, 0.079 +- 0.013, 0.070 +- 0.011
Faith. GMean (KL)= 	  =  0.210 +- 0.015, 0.188 +- 0.013, 0.201 +- 0.016, 0.190 +- 0.016
Computed for split load_split = id



Completed in  0:07:58.619373  for LECIGIN GOODSST2/length



DONE LECI GOODSST2/length all mitig
DONE all :)
